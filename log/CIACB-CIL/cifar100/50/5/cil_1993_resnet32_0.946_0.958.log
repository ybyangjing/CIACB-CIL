2024-09-08 09:50:58,665 [trainer.py] => config: ./configs/cifar/b50inc5.json
2024-09-08 09:50:58,666 [trainer.py] => prefix: cil
2024-09-08 09:50:58,667 [trainer.py] => dataset: cifar100
2024-09-08 09:50:58,667 [trainer.py] => memory_size: 2000
2024-09-08 09:50:58,668 [trainer.py] => memory_per_class: 20
2024-09-08 09:50:58,668 [trainer.py] => fixed_memory: True
2024-09-08 09:50:58,669 [trainer.py] => shuffle: True
2024-09-08 09:50:58,669 [trainer.py] => init_cls: 50
2024-09-08 09:50:58,671 [trainer.py] => increment: 5
2024-09-08 09:50:58,672 [trainer.py] => model_name: foster
2024-09-08 09:50:58,672 [trainer.py] => convnet_type: resnet32
2024-09-08 09:50:58,672 [trainer.py] => device: [device(type='cuda', index=0)]
2024-09-08 09:50:58,672 [trainer.py] => seed: 1993
2024-09-08 09:50:58,672 [trainer.py] => beta1: 0.94
2024-09-08 09:50:58,672 [trainer.py] => beta2: 0.97
2024-09-08 09:50:58,672 [trainer.py] => oofc: ft
2024-09-08 09:50:58,672 [trainer.py] => is_teacher_wa: False
2024-09-08 09:50:58,672 [trainer.py] => is_student_wa: False
2024-09-08 09:50:58,672 [trainer.py] => lambda_okd: 1
2024-09-08 09:50:58,672 [trainer.py] => wa_value: 1
2024-09-08 09:50:58,672 [trainer.py] => init_epochs: 200
2024-09-08 09:50:58,672 [trainer.py] => init_lr: 0.1
2024-09-08 09:50:58,672 [trainer.py] => init_weight_decay: 0.0005
2024-09-08 09:50:58,673 [trainer.py] => boosting_epochs: 170
2024-09-08 09:50:58,673 [trainer.py] => compression_epochs: 130
2024-09-08 09:50:58,673 [trainer.py] => lr: 0.1
2024-09-08 09:50:58,673 [trainer.py] => batch_size: 128
2024-09-08 09:50:58,673 [trainer.py] => weight_decay: 0.0005
2024-09-08 09:50:58,673 [trainer.py] => num_workers: 8
2024-09-08 09:50:58,673 [trainer.py] => T: 2
2024-09-08 09:51:00,880 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-09-08 09:51:00,991 [trainer.py] => All params: 0
2024-09-08 09:51:00,991 [trainer.py] => Trainable params: 0
2024-09-08 09:51:03,164 [foster.py] => Learning on 0-50
2024-09-08 09:51:03,166 [foster.py] => All params: 583774
2024-09-08 09:51:03,167 [foster.py] => Trainable params: 583774
2024-09-08 09:51:36,935 [foster.py] => Task 0, Epoch 1/200 => Loss 3.712, Train_accy 6.01, Test_accy 10.80
2024-09-08 09:51:46,011 [foster.py] => Task 0, Epoch 2/200 => Loss 3.430, Loss1 3.430,Train_accy 11.50
2024-09-08 09:51:55,169 [foster.py] => Task 0, Epoch 3/200 => Loss 3.281, Loss1 3.281,Train_accy 14.58
2024-09-08 09:52:04,437 [foster.py] => Task 0, Epoch 4/200 => Loss 3.147, Loss1 3.147,Train_accy 17.41
2024-09-08 09:52:13,650 [foster.py] => Task 0, Epoch 5/200 => Loss 3.001, Loss1 3.001,Train_accy 20.49
2024-09-08 09:52:23,630 [foster.py] => Task 0, Epoch 6/200 => Loss 2.853, Train_accy 23.28, Test_accy 28.50
2024-09-08 09:52:32,776 [foster.py] => Task 0, Epoch 7/200 => Loss 2.743, Loss1 2.743,Train_accy 25.45
2024-09-08 09:52:42,066 [foster.py] => Task 0, Epoch 8/200 => Loss 2.640, Loss1 2.640,Train_accy 28.15
2024-09-08 09:52:51,167 [foster.py] => Task 0, Epoch 9/200 => Loss 2.527, Loss1 2.527,Train_accy 30.56
2024-09-08 09:53:00,242 [foster.py] => Task 0, Epoch 10/200 => Loss 2.443, Loss1 2.443,Train_accy 32.60
2024-09-08 09:53:10,282 [foster.py] => Task 0, Epoch 11/200 => Loss 2.367, Train_accy 34.49, Test_accy 38.34
2024-09-08 09:53:19,451 [foster.py] => Task 0, Epoch 12/200 => Loss 2.289, Loss1 2.289,Train_accy 36.37
2024-09-08 09:53:28,572 [foster.py] => Task 0, Epoch 13/200 => Loss 2.238, Loss1 2.238,Train_accy 37.77
2024-09-08 09:53:37,705 [foster.py] => Task 0, Epoch 14/200 => Loss 2.183, Loss1 2.183,Train_accy 39.28
2024-09-08 09:53:46,812 [foster.py] => Task 0, Epoch 15/200 => Loss 2.128, Loss1 2.128,Train_accy 40.28
2024-09-08 09:53:56,821 [foster.py] => Task 0, Epoch 16/200 => Loss 2.084, Train_accy 41.38, Test_accy 47.88
2024-09-08 09:54:05,998 [foster.py] => Task 0, Epoch 17/200 => Loss 2.066, Loss1 2.066,Train_accy 42.03
2024-09-08 09:54:15,033 [foster.py] => Task 0, Epoch 18/200 => Loss 2.035, Loss1 2.035,Train_accy 42.83
2024-09-08 09:54:24,166 [foster.py] => Task 0, Epoch 19/200 => Loss 2.013, Loss1 2.013,Train_accy 43.56
2024-09-08 09:54:33,389 [foster.py] => Task 0, Epoch 20/200 => Loss 1.987, Loss1 1.987,Train_accy 44.22
2024-09-08 09:54:43,375 [foster.py] => Task 0, Epoch 21/200 => Loss 1.960, Train_accy 44.88, Test_accy 49.18
2024-09-08 09:54:52,556 [foster.py] => Task 0, Epoch 22/200 => Loss 1.931, Loss1 1.931,Train_accy 45.24
2024-09-08 09:55:01,647 [foster.py] => Task 0, Epoch 23/200 => Loss 1.922, Loss1 1.922,Train_accy 45.60
2024-09-08 09:55:10,854 [foster.py] => Task 0, Epoch 24/200 => Loss 1.894, Loss1 1.894,Train_accy 46.18
2024-09-08 09:55:20,006 [foster.py] => Task 0, Epoch 25/200 => Loss 1.886, Loss1 1.886,Train_accy 47.01
2024-09-08 09:55:30,056 [foster.py] => Task 0, Epoch 26/200 => Loss 1.864, Train_accy 47.30, Test_accy 55.06
2024-09-08 09:55:39,131 [foster.py] => Task 0, Epoch 27/200 => Loss 1.848, Loss1 1.848,Train_accy 47.74
2024-09-08 09:55:48,141 [foster.py] => Task 0, Epoch 28/200 => Loss 1.841, Loss1 1.841,Train_accy 48.00
2024-09-08 09:55:57,254 [foster.py] => Task 0, Epoch 29/200 => Loss 1.832, Loss1 1.832,Train_accy 48.12
2024-09-08 09:56:06,283 [foster.py] => Task 0, Epoch 30/200 => Loss 1.811, Loss1 1.811,Train_accy 49.00
2024-09-08 09:56:16,255 [foster.py] => Task 0, Epoch 31/200 => Loss 1.802, Train_accy 48.98, Test_accy 57.86
2024-09-08 09:56:25,441 [foster.py] => Task 0, Epoch 32/200 => Loss 1.799, Loss1 1.799,Train_accy 48.66
2024-09-08 09:56:34,650 [foster.py] => Task 0, Epoch 33/200 => Loss 1.798, Loss1 1.798,Train_accy 49.45
2024-09-08 09:56:43,879 [foster.py] => Task 0, Epoch 34/200 => Loss 1.770, Loss1 1.770,Train_accy 49.92
2024-09-08 09:56:53,085 [foster.py] => Task 0, Epoch 35/200 => Loss 1.770, Loss1 1.770,Train_accy 49.98
2024-09-08 09:57:03,083 [foster.py] => Task 0, Epoch 36/200 => Loss 1.758, Train_accy 49.85, Test_accy 54.30
2024-09-08 09:57:12,104 [foster.py] => Task 0, Epoch 37/200 => Loss 1.756, Loss1 1.756,Train_accy 50.08
2024-09-08 09:57:21,272 [foster.py] => Task 0, Epoch 38/200 => Loss 1.748, Loss1 1.748,Train_accy 50.47
2024-09-08 09:57:30,424 [foster.py] => Task 0, Epoch 39/200 => Loss 1.735, Loss1 1.735,Train_accy 50.69
2024-09-08 09:57:39,622 [foster.py] => Task 0, Epoch 40/200 => Loss 1.744, Loss1 1.744,Train_accy 50.80
2024-09-08 09:57:49,553 [foster.py] => Task 0, Epoch 41/200 => Loss 1.719, Train_accy 51.19, Test_accy 54.78
2024-09-08 09:57:58,687 [foster.py] => Task 0, Epoch 42/200 => Loss 1.719, Loss1 1.719,Train_accy 51.44
2024-09-08 09:58:07,875 [foster.py] => Task 0, Epoch 43/200 => Loss 1.704, Loss1 1.704,Train_accy 51.76
2024-09-08 09:58:17,027 [foster.py] => Task 0, Epoch 44/200 => Loss 1.707, Loss1 1.707,Train_accy 51.36
2024-09-08 09:58:26,268 [foster.py] => Task 0, Epoch 45/200 => Loss 1.704, Loss1 1.704,Train_accy 51.62
2024-09-08 09:58:36,190 [foster.py] => Task 0, Epoch 46/200 => Loss 1.670, Train_accy 52.21, Test_accy 57.96
2024-09-08 09:58:45,298 [foster.py] => Task 0, Epoch 47/200 => Loss 1.687, Loss1 1.687,Train_accy 51.77
2024-09-08 09:58:54,453 [foster.py] => Task 0, Epoch 48/200 => Loss 1.675, Loss1 1.675,Train_accy 52.53
2024-09-08 09:59:03,580 [foster.py] => Task 0, Epoch 49/200 => Loss 1.669, Loss1 1.669,Train_accy 52.32
2024-09-08 09:59:12,719 [foster.py] => Task 0, Epoch 50/200 => Loss 1.663, Loss1 1.663,Train_accy 52.70
2024-09-08 09:59:22,677 [foster.py] => Task 0, Epoch 51/200 => Loss 1.657, Train_accy 52.59, Test_accy 55.20
2024-09-08 09:59:31,881 [foster.py] => Task 0, Epoch 52/200 => Loss 1.655, Loss1 1.655,Train_accy 52.88
2024-09-08 09:59:41,004 [foster.py] => Task 0, Epoch 53/200 => Loss 1.645, Loss1 1.645,Train_accy 53.02
2024-09-08 09:59:50,220 [foster.py] => Task 0, Epoch 54/200 => Loss 1.637, Loss1 1.637,Train_accy 53.51
2024-09-08 09:59:59,258 [foster.py] => Task 0, Epoch 55/200 => Loss 1.633, Loss1 1.633,Train_accy 53.31
2024-09-08 10:00:09,377 [foster.py] => Task 0, Epoch 56/200 => Loss 1.641, Train_accy 53.24, Test_accy 60.44
2024-09-08 10:00:18,468 [foster.py] => Task 0, Epoch 57/200 => Loss 1.631, Loss1 1.631,Train_accy 53.63
2024-09-08 10:00:27,499 [foster.py] => Task 0, Epoch 58/200 => Loss 1.613, Loss1 1.613,Train_accy 53.87
2024-09-08 10:00:36,708 [foster.py] => Task 0, Epoch 59/200 => Loss 1.625, Loss1 1.625,Train_accy 53.89
2024-09-08 10:00:45,847 [foster.py] => Task 0, Epoch 60/200 => Loss 1.617, Loss1 1.617,Train_accy 54.04
2024-09-08 10:00:55,859 [foster.py] => Task 0, Epoch 61/200 => Loss 1.612, Train_accy 53.99, Test_accy 59.56
2024-09-08 10:01:04,913 [foster.py] => Task 0, Epoch 62/200 => Loss 1.603, Loss1 1.603,Train_accy 54.34
2024-09-08 10:01:14,090 [foster.py] => Task 0, Epoch 63/200 => Loss 1.603, Loss1 1.603,Train_accy 54.24
2024-09-08 10:01:23,242 [foster.py] => Task 0, Epoch 64/200 => Loss 1.591, Loss1 1.591,Train_accy 54.60
2024-09-08 10:01:32,330 [foster.py] => Task 0, Epoch 65/200 => Loss 1.582, Loss1 1.582,Train_accy 54.79
2024-09-08 10:01:42,397 [foster.py] => Task 0, Epoch 66/200 => Loss 1.583, Train_accy 54.93, Test_accy 59.24
2024-09-08 10:01:51,502 [foster.py] => Task 0, Epoch 67/200 => Loss 1.592, Loss1 1.592,Train_accy 54.70
2024-09-08 10:02:00,635 [foster.py] => Task 0, Epoch 68/200 => Loss 1.573, Loss1 1.573,Train_accy 55.06
2024-09-08 10:02:09,834 [foster.py] => Task 0, Epoch 69/200 => Loss 1.571, Loss1 1.571,Train_accy 54.77
2024-09-08 10:02:19,025 [foster.py] => Task 0, Epoch 70/200 => Loss 1.561, Loss1 1.561,Train_accy 55.47
2024-09-08 10:02:28,924 [foster.py] => Task 0, Epoch 71/200 => Loss 1.549, Train_accy 55.55, Test_accy 59.48
2024-09-08 10:02:38,037 [foster.py] => Task 0, Epoch 72/200 => Loss 1.555, Loss1 1.555,Train_accy 55.21
2024-09-08 10:02:47,197 [foster.py] => Task 0, Epoch 73/200 => Loss 1.561, Loss1 1.561,Train_accy 55.36
2024-09-08 10:02:56,358 [foster.py] => Task 0, Epoch 74/200 => Loss 1.524, Loss1 1.524,Train_accy 56.46
2024-09-08 10:03:05,460 [foster.py] => Task 0, Epoch 75/200 => Loss 1.530, Loss1 1.530,Train_accy 56.31
2024-09-08 10:03:15,487 [foster.py] => Task 0, Epoch 76/200 => Loss 1.512, Train_accy 56.85, Test_accy 64.46
2024-09-08 10:03:24,707 [foster.py] => Task 0, Epoch 77/200 => Loss 1.534, Loss1 1.534,Train_accy 56.00
2024-09-08 10:03:33,739 [foster.py] => Task 0, Epoch 78/200 => Loss 1.519, Loss1 1.519,Train_accy 56.76
2024-09-08 10:03:42,641 [foster.py] => Task 0, Epoch 79/200 => Loss 1.519, Loss1 1.519,Train_accy 56.52
2024-09-08 10:03:51,667 [foster.py] => Task 0, Epoch 80/200 => Loss 1.509, Loss1 1.509,Train_accy 56.49
2024-09-08 10:04:01,791 [foster.py] => Task 0, Epoch 81/200 => Loss 1.513, Train_accy 56.38, Test_accy 62.94
2024-09-08 10:04:10,955 [foster.py] => Task 0, Epoch 82/200 => Loss 1.481, Loss1 1.481,Train_accy 57.48
2024-09-08 10:04:20,126 [foster.py] => Task 0, Epoch 83/200 => Loss 1.495, Loss1 1.495,Train_accy 57.19
2024-09-08 10:04:29,312 [foster.py] => Task 0, Epoch 84/200 => Loss 1.484, Loss1 1.484,Train_accy 57.54
2024-09-08 10:04:38,394 [foster.py] => Task 0, Epoch 85/200 => Loss 1.497, Loss1 1.497,Train_accy 57.36
2024-09-08 10:04:48,359 [foster.py] => Task 0, Epoch 86/200 => Loss 1.489, Train_accy 57.41, Test_accy 60.28
2024-09-08 10:04:57,449 [foster.py] => Task 0, Epoch 87/200 => Loss 1.459, Loss1 1.459,Train_accy 58.19
2024-09-08 10:05:06,530 [foster.py] => Task 0, Epoch 88/200 => Loss 1.476, Loss1 1.476,Train_accy 57.80
2024-09-08 10:05:15,645 [foster.py] => Task 0, Epoch 89/200 => Loss 1.460, Loss1 1.460,Train_accy 57.92
2024-09-08 10:05:24,813 [foster.py] => Task 0, Epoch 90/200 => Loss 1.465, Loss1 1.465,Train_accy 58.00
2024-09-08 10:05:34,838 [foster.py] => Task 0, Epoch 91/200 => Loss 1.447, Train_accy 58.25, Test_accy 65.66
2024-09-08 10:05:43,901 [foster.py] => Task 0, Epoch 92/200 => Loss 1.446, Loss1 1.446,Train_accy 58.16
2024-09-08 10:05:53,063 [foster.py] => Task 0, Epoch 93/200 => Loss 1.449, Loss1 1.449,Train_accy 58.33
2024-09-08 10:06:02,311 [foster.py] => Task 0, Epoch 94/200 => Loss 1.435, Loss1 1.435,Train_accy 58.96
2024-09-08 10:06:11,473 [foster.py] => Task 0, Epoch 95/200 => Loss 1.430, Loss1 1.430,Train_accy 58.57
2024-09-08 10:06:21,465 [foster.py] => Task 0, Epoch 96/200 => Loss 1.422, Train_accy 58.78, Test_accy 63.98
2024-09-08 10:06:30,511 [foster.py] => Task 0, Epoch 97/200 => Loss 1.424, Loss1 1.424,Train_accy 59.35
2024-09-08 10:06:39,652 [foster.py] => Task 0, Epoch 98/200 => Loss 1.397, Loss1 1.397,Train_accy 59.49
2024-09-08 10:06:48,674 [foster.py] => Task 0, Epoch 99/200 => Loss 1.395, Loss1 1.395,Train_accy 59.90
2024-09-08 10:06:57,881 [foster.py] => Task 0, Epoch 100/200 => Loss 1.406, Loss1 1.406,Train_accy 59.40
2024-09-08 10:07:07,767 [foster.py] => Task 0, Epoch 101/200 => Loss 1.382, Train_accy 60.14, Test_accy 63.92
2024-09-08 10:07:16,781 [foster.py] => Task 0, Epoch 102/200 => Loss 1.370, Loss1 1.370,Train_accy 60.60
2024-09-08 10:07:25,909 [foster.py] => Task 0, Epoch 103/200 => Loss 1.357, Loss1 1.357,Train_accy 61.02
2024-09-08 10:07:35,024 [foster.py] => Task 0, Epoch 104/200 => Loss 1.360, Loss1 1.360,Train_accy 60.67
2024-09-08 10:07:44,163 [foster.py] => Task 0, Epoch 105/200 => Loss 1.371, Loss1 1.371,Train_accy 60.49
2024-09-08 10:07:54,190 [foster.py] => Task 0, Epoch 106/200 => Loss 1.370, Train_accy 60.28, Test_accy 67.78
2024-09-08 10:08:03,393 [foster.py] => Task 0, Epoch 107/200 => Loss 1.347, Loss1 1.347,Train_accy 61.02
2024-09-08 10:08:12,507 [foster.py] => Task 0, Epoch 108/200 => Loss 1.348, Loss1 1.348,Train_accy 61.25
2024-09-08 10:08:21,554 [foster.py] => Task 0, Epoch 109/200 => Loss 1.341, Loss1 1.341,Train_accy 61.16
2024-09-08 10:08:30,800 [foster.py] => Task 0, Epoch 110/200 => Loss 1.334, Loss1 1.334,Train_accy 61.42
2024-09-08 10:08:40,908 [foster.py] => Task 0, Epoch 111/200 => Loss 1.339, Train_accy 61.46, Test_accy 67.22
2024-09-08 10:08:50,090 [foster.py] => Task 0, Epoch 112/200 => Loss 1.336, Loss1 1.336,Train_accy 61.16
2024-09-08 10:08:59,296 [foster.py] => Task 0, Epoch 113/200 => Loss 1.325, Loss1 1.325,Train_accy 61.74
2024-09-08 10:09:08,388 [foster.py] => Task 0, Epoch 114/200 => Loss 1.295, Loss1 1.295,Train_accy 62.09
2024-09-08 10:09:17,577 [foster.py] => Task 0, Epoch 115/200 => Loss 1.311, Loss1 1.311,Train_accy 62.26
2024-09-08 10:09:27,546 [foster.py] => Task 0, Epoch 116/200 => Loss 1.303, Train_accy 62.14, Test_accy 67.14
2024-09-08 10:09:36,724 [foster.py] => Task 0, Epoch 117/200 => Loss 1.296, Loss1 1.296,Train_accy 62.05
2024-09-08 10:09:45,855 [foster.py] => Task 0, Epoch 118/200 => Loss 1.291, Loss1 1.291,Train_accy 62.59
2024-09-08 10:09:54,949 [foster.py] => Task 0, Epoch 119/200 => Loss 1.276, Loss1 1.276,Train_accy 63.09
2024-09-08 10:10:03,951 [foster.py] => Task 0, Epoch 120/200 => Loss 1.270, Loss1 1.270,Train_accy 63.31
2024-09-08 10:10:13,942 [foster.py] => Task 0, Epoch 121/200 => Loss 1.265, Train_accy 63.20, Test_accy 70.46
2024-09-08 10:10:23,056 [foster.py] => Task 0, Epoch 122/200 => Loss 1.268, Loss1 1.268,Train_accy 63.28
2024-09-08 10:10:32,083 [foster.py] => Task 0, Epoch 123/200 => Loss 1.254, Loss1 1.254,Train_accy 63.43
2024-09-08 10:10:41,004 [foster.py] => Task 0, Epoch 124/200 => Loss 1.254, Loss1 1.254,Train_accy 63.82
2024-09-08 10:10:50,052 [foster.py] => Task 0, Epoch 125/200 => Loss 1.240, Loss1 1.240,Train_accy 64.41
2024-09-08 10:11:00,060 [foster.py] => Task 0, Epoch 126/200 => Loss 1.227, Train_accy 64.56, Test_accy 66.84
2024-09-08 10:11:09,153 [foster.py] => Task 0, Epoch 127/200 => Loss 1.217, Loss1 1.217,Train_accy 64.56
2024-09-08 10:11:18,276 [foster.py] => Task 0, Epoch 128/200 => Loss 1.196, Loss1 1.196,Train_accy 64.81
2024-09-08 10:11:27,424 [foster.py] => Task 0, Epoch 129/200 => Loss 1.207, Loss1 1.207,Train_accy 64.71
2024-09-08 10:11:36,473 [foster.py] => Task 0, Epoch 130/200 => Loss 1.178, Loss1 1.178,Train_accy 65.70
2024-09-08 10:11:46,463 [foster.py] => Task 0, Epoch 131/200 => Loss 1.188, Train_accy 65.38, Test_accy 70.78
2024-09-08 10:11:55,541 [foster.py] => Task 0, Epoch 132/200 => Loss 1.195, Loss1 1.195,Train_accy 65.50
2024-09-08 10:12:04,725 [foster.py] => Task 0, Epoch 133/200 => Loss 1.180, Loss1 1.180,Train_accy 65.72
2024-09-08 10:12:13,837 [foster.py] => Task 0, Epoch 134/200 => Loss 1.168, Loss1 1.168,Train_accy 65.76
2024-09-08 10:12:23,000 [foster.py] => Task 0, Epoch 135/200 => Loss 1.150, Loss1 1.150,Train_accy 66.58
2024-09-08 10:12:32,978 [foster.py] => Task 0, Epoch 136/200 => Loss 1.149, Train_accy 66.54, Test_accy 71.98
2024-09-08 10:12:42,076 [foster.py] => Task 0, Epoch 137/200 => Loss 1.152, Loss1 1.152,Train_accy 66.32
2024-09-08 10:12:51,201 [foster.py] => Task 0, Epoch 138/200 => Loss 1.128, Loss1 1.128,Train_accy 66.98
2024-09-08 10:13:00,254 [foster.py] => Task 0, Epoch 139/200 => Loss 1.130, Loss1 1.130,Train_accy 67.07
2024-09-08 10:13:09,389 [foster.py] => Task 0, Epoch 140/200 => Loss 1.112, Loss1 1.112,Train_accy 67.36
2024-09-08 10:13:19,408 [foster.py] => Task 0, Epoch 141/200 => Loss 1.112, Train_accy 67.59, Test_accy 74.68
2024-09-08 10:13:28,602 [foster.py] => Task 0, Epoch 142/200 => Loss 1.087, Loss1 1.087,Train_accy 68.27
2024-09-08 10:13:37,693 [foster.py] => Task 0, Epoch 143/200 => Loss 1.093, Loss1 1.093,Train_accy 67.99
2024-09-08 10:13:46,875 [foster.py] => Task 0, Epoch 144/200 => Loss 1.065, Loss1 1.065,Train_accy 68.66
2024-09-08 10:13:55,973 [foster.py] => Task 0, Epoch 145/200 => Loss 1.063, Loss1 1.063,Train_accy 68.93
2024-09-08 10:14:05,916 [foster.py] => Task 0, Epoch 146/200 => Loss 1.049, Train_accy 69.30, Test_accy 69.30
2024-09-08 10:14:15,039 [foster.py] => Task 0, Epoch 147/200 => Loss 1.049, Loss1 1.049,Train_accy 69.31
2024-09-08 10:14:24,201 [foster.py] => Task 0, Epoch 148/200 => Loss 1.040, Loss1 1.040,Train_accy 69.52
2024-09-08 10:14:33,348 [foster.py] => Task 0, Epoch 149/200 => Loss 1.028, Loss1 1.028,Train_accy 70.00
2024-09-08 10:14:42,417 [foster.py] => Task 0, Epoch 150/200 => Loss 1.035, Loss1 1.035,Train_accy 69.44
2024-09-08 10:14:52,445 [foster.py] => Task 0, Epoch 151/200 => Loss 1.023, Train_accy 69.92, Test_accy 75.42
2024-09-08 10:15:01,532 [foster.py] => Task 0, Epoch 152/200 => Loss 1.011, Loss1 1.011,Train_accy 70.40
2024-09-08 10:15:10,655 [foster.py] => Task 0, Epoch 153/200 => Loss 1.004, Loss1 1.004,Train_accy 70.64
2024-09-08 10:15:19,813 [foster.py] => Task 0, Epoch 154/200 => Loss 1.000, Loss1 1.000,Train_accy 70.71
2024-09-08 10:15:28,920 [foster.py] => Task 0, Epoch 155/200 => Loss 0.973, Loss1 0.973,Train_accy 71.35
2024-09-08 10:15:39,022 [foster.py] => Task 0, Epoch 156/200 => Loss 0.972, Train_accy 71.60, Test_accy 76.28
2024-09-08 10:15:48,181 [foster.py] => Task 0, Epoch 157/200 => Loss 0.954, Loss1 0.954,Train_accy 72.21
2024-09-08 10:15:57,352 [foster.py] => Task 0, Epoch 158/200 => Loss 0.943, Loss1 0.943,Train_accy 72.51
2024-09-08 10:16:06,458 [foster.py] => Task 0, Epoch 159/200 => Loss 0.935, Loss1 0.935,Train_accy 72.42
2024-09-08 10:16:15,562 [foster.py] => Task 0, Epoch 160/200 => Loss 0.944, Loss1 0.944,Train_accy 72.50
2024-09-08 10:16:25,490 [foster.py] => Task 0, Epoch 161/200 => Loss 0.934, Train_accy 72.40, Test_accy 76.72
2024-09-08 10:16:34,586 [foster.py] => Task 0, Epoch 162/200 => Loss 0.910, Loss1 0.910,Train_accy 73.19
2024-09-08 10:16:43,765 [foster.py] => Task 0, Epoch 163/200 => Loss 0.917, Loss1 0.917,Train_accy 73.12
2024-09-08 10:16:52,874 [foster.py] => Task 0, Epoch 164/200 => Loss 0.885, Loss1 0.885,Train_accy 74.08
2024-09-08 10:17:02,237 [foster.py] => Task 0, Epoch 165/200 => Loss 0.883, Loss1 0.883,Train_accy 74.10
2024-09-08 10:17:12,385 [foster.py] => Task 0, Epoch 166/200 => Loss 0.881, Train_accy 74.03, Test_accy 78.54
2024-09-08 10:17:21,572 [foster.py] => Task 0, Epoch 167/200 => Loss 0.871, Loss1 0.871,Train_accy 74.69
2024-09-08 10:17:30,643 [foster.py] => Task 0, Epoch 168/200 => Loss 0.846, Loss1 0.846,Train_accy 75.22
2024-09-08 10:17:39,586 [foster.py] => Task 0, Epoch 169/200 => Loss 0.864, Loss1 0.864,Train_accy 74.86
2024-09-08 10:17:48,830 [foster.py] => Task 0, Epoch 170/200 => Loss 0.847, Loss1 0.847,Train_accy 75.31
2024-09-08 10:17:58,809 [foster.py] => Task 0, Epoch 171/200 => Loss 0.849, Train_accy 74.99, Test_accy 79.22
2024-09-08 10:18:07,971 [foster.py] => Task 0, Epoch 172/200 => Loss 0.822, Loss1 0.822,Train_accy 75.69
2024-09-08 10:18:16,954 [foster.py] => Task 0, Epoch 173/200 => Loss 0.813, Loss1 0.813,Train_accy 76.08
2024-09-08 10:18:26,002 [foster.py] => Task 0, Epoch 174/200 => Loss 0.812, Loss1 0.812,Train_accy 76.04
2024-09-08 10:18:35,215 [foster.py] => Task 0, Epoch 175/200 => Loss 0.795, Loss1 0.795,Train_accy 76.68
2024-09-08 10:18:45,185 [foster.py] => Task 0, Epoch 176/200 => Loss 0.785, Train_accy 77.04, Test_accy 80.16
2024-09-08 10:18:54,406 [foster.py] => Task 0, Epoch 177/200 => Loss 0.776, Loss1 0.776,Train_accy 76.89
2024-09-08 10:19:03,592 [foster.py] => Task 0, Epoch 178/200 => Loss 0.769, Loss1 0.769,Train_accy 77.22
2024-09-08 10:19:12,781 [foster.py] => Task 0, Epoch 179/200 => Loss 0.755, Loss1 0.755,Train_accy 77.73
2024-09-08 10:19:21,844 [foster.py] => Task 0, Epoch 180/200 => Loss 0.750, Loss1 0.750,Train_accy 77.82
2024-09-08 10:19:31,778 [foster.py] => Task 0, Epoch 181/200 => Loss 0.739, Train_accy 78.32, Test_accy 80.90
2024-09-08 10:19:40,934 [foster.py] => Task 0, Epoch 182/200 => Loss 0.737, Loss1 0.737,Train_accy 78.35
2024-09-08 10:19:50,070 [foster.py] => Task 0, Epoch 183/200 => Loss 0.725, Loss1 0.725,Train_accy 78.63
2024-09-08 10:19:59,201 [foster.py] => Task 0, Epoch 184/200 => Loss 0.714, Loss1 0.714,Train_accy 78.96
2024-09-08 10:20:08,281 [foster.py] => Task 0, Epoch 185/200 => Loss 0.714, Loss1 0.714,Train_accy 78.86
2024-09-08 10:20:18,282 [foster.py] => Task 0, Epoch 186/200 => Loss 0.718, Train_accy 78.61, Test_accy 81.14
2024-09-08 10:20:27,322 [foster.py] => Task 0, Epoch 187/200 => Loss 0.704, Loss1 0.704,Train_accy 79.36
2024-09-08 10:20:36,409 [foster.py] => Task 0, Epoch 188/200 => Loss 0.706, Loss1 0.706,Train_accy 79.37
2024-09-08 10:20:45,466 [foster.py] => Task 0, Epoch 189/200 => Loss 0.702, Loss1 0.702,Train_accy 79.07
2024-09-08 10:20:54,632 [foster.py] => Task 0, Epoch 190/200 => Loss 0.701, Loss1 0.701,Train_accy 79.54
2024-09-08 10:21:04,694 [foster.py] => Task 0, Epoch 191/200 => Loss 0.686, Train_accy 80.04, Test_accy 81.08
2024-09-08 10:21:13,807 [foster.py] => Task 0, Epoch 192/200 => Loss 0.694, Loss1 0.694,Train_accy 79.70
2024-09-08 10:21:23,023 [foster.py] => Task 0, Epoch 193/200 => Loss 0.681, Loss1 0.681,Train_accy 79.90
2024-09-08 10:21:32,115 [foster.py] => Task 0, Epoch 194/200 => Loss 0.683, Loss1 0.683,Train_accy 79.95
2024-09-08 10:21:41,237 [foster.py] => Task 0, Epoch 195/200 => Loss 0.683, Loss1 0.683,Train_accy 79.83
2024-09-08 10:21:51,234 [foster.py] => Task 0, Epoch 196/200 => Loss 0.685, Train_accy 79.74, Test_accy 81.48
2024-09-08 10:22:00,377 [foster.py] => Task 0, Epoch 197/200 => Loss 0.676, Loss1 0.676,Train_accy 80.07
2024-09-08 10:22:09,464 [foster.py] => Task 0, Epoch 198/200 => Loss 0.688, Loss1 0.688,Train_accy 79.74
2024-09-08 10:22:18,548 [foster.py] => Task 0, Epoch 199/200 => Loss 0.682, Loss1 0.682,Train_accy 80.12
2024-09-08 10:22:27,698 [foster.py] => Task 0, Epoch 200/200 => Loss 0.676, Loss1 0.676,Train_accy 79.95
2024-09-08 10:22:27,700 [foster.py] => training time: 1884.4746279716492
2024-09-08 10:22:27,701 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 10:22:57,843 [foster.py] => Exemplar size: 1000
2024-09-08 10:22:57,843 [trainer.py] => CNN: {'total': 81.66, '00-09': 86.2, '10-19': 78.1, '20-29': 83.2, '30-39': 78.2, '40-49': 82.6, 'old': 0, 'new': 81.66}
2024-09-08 10:22:57,844 [trainer.py] => NME: {'total': 80.72, '00-09': 83.4, '10-19': 76.9, '20-29': 83.2, '30-39': 78.4, '40-49': 81.7, 'old': 0, 'new': 80.72}
2024-09-08 10:22:57,844 [trainer.py] => CNN top1 curve: [81.66]
2024-09-08 10:22:57,844 [trainer.py] => CNN top5 curve: [97.02]
2024-09-08 10:22:57,844 [trainer.py] => NME top1 curve: [80.72]
2024-09-08 10:22:57,845 [trainer.py] => NME top5 curve: [96.8]

2024-09-08 10:22:57,845 [trainer.py] => CNN top1 平均值: 81.66
2024-09-08 10:22:57,847 [trainer.py] => All params: 583774
2024-09-08 10:22:57,848 [trainer.py] => Trainable params: 583774
2024-09-08 10:22:57,948 [foster.py] => Learning on 50-55
2024-09-08 10:22:57,951 [foster.py] => All params: 1168468
2024-09-08 10:22:57,953 [foster.py] => Trainable params: 587944
2024-09-08 10:22:58,003 [foster.py] => per cls weights : [1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999 1.03679999
 1.03679999 1.03679999 0.6320001  0.6320001  0.6320001  0.6320001
 0.6320001 ]
2024-09-08 10:23:02,123 [foster.py] => Task 1, Epoch 1/170 => Loss 5.951, Loss_clf 1.846, Loss_fe 1.607, Loss_kd 2.269, Train_accy 55.43
2024-09-08 10:23:07,015 [foster.py] => Task 1, Epoch 2/170 => Loss 4.143, Loss_clf 0.751, Loss_fe 0.932, Loss_kd 2.234, Train_accy 54.37, Test_accy 77.07
2024-09-08 10:23:11,861 [foster.py] => Task 1, Epoch 3/170 => Loss 3.879, Loss_clf 0.651, Loss_fe 0.769, Loss_kd 2.234, Train_accy 56.46, Test_accy 77.45
2024-09-08 10:23:16,750 [foster.py] => Task 1, Epoch 4/170 => Loss 3.896, Loss_clf 0.688, Loss_fe 0.774, Loss_kd 2.212, Train_accy 55.37, Test_accy 77.45
2024-09-08 10:23:21,686 [foster.py] => Task 1, Epoch 5/170 => Loss 3.908, Loss_clf 0.710, Loss_fe 0.744, Loss_kd 2.230, Train_accy 56.46, Test_accy 77.15
2024-09-08 10:23:25,172 [foster.py] => Task 1, Epoch 6/170 => Loss 3.758, Loss_clf 0.630, Loss_fe 0.682, Loss_kd 2.223, Train_accy 56.89
2024-09-08 10:23:30,065 [foster.py] => Task 1, Epoch 7/170 => Loss 3.674, Loss_clf 0.607, Loss_fe 0.626, Loss_kd 2.218, Train_accy 59.66, Test_accy 77.93
2024-09-08 10:23:34,961 [foster.py] => Task 1, Epoch 8/170 => Loss 3.651, Loss_clf 0.589, Loss_fe 0.617, Loss_kd 2.222, Train_accy 62.29, Test_accy 77.36
2024-09-08 10:23:39,859 [foster.py] => Task 1, Epoch 9/170 => Loss 3.676, Loss_clf 0.613, Loss_fe 0.604, Loss_kd 2.234, Train_accy 61.03, Test_accy 78.29
2024-09-08 10:23:44,757 [foster.py] => Task 1, Epoch 10/170 => Loss 3.630, Loss_clf 0.610, Loss_fe 0.590, Loss_kd 2.208, Train_accy 60.60, Test_accy 77.20
2024-09-08 10:23:48,387 [foster.py] => Task 1, Epoch 11/170 => Loss 3.594, Loss_clf 0.586, Loss_fe 0.568, Loss_kd 2.217, Train_accy 60.06
2024-09-08 10:23:53,356 [foster.py] => Task 1, Epoch 12/170 => Loss 3.600, Loss_clf 0.578, Loss_fe 0.579, Loss_kd 2.220, Train_accy 62.00, Test_accy 79.07
2024-09-08 10:23:58,285 [foster.py] => Task 1, Epoch 13/170 => Loss 3.607, Loss_clf 0.582, Loss_fe 0.551, Loss_kd 2.247, Train_accy 62.43, Test_accy 77.76
2024-09-08 10:24:03,136 [foster.py] => Task 1, Epoch 14/170 => Loss 3.492, Loss_clf 0.534, Loss_fe 0.523, Loss_kd 2.213, Train_accy 63.71, Test_accy 78.16
2024-09-08 10:24:08,034 [foster.py] => Task 1, Epoch 15/170 => Loss 3.602, Loss_clf 0.583, Loss_fe 0.545, Loss_kd 2.249, Train_accy 64.20, Test_accy 78.40
2024-09-08 10:24:11,541 [foster.py] => Task 1, Epoch 16/170 => Loss 3.568, Loss_clf 0.570, Loss_fe 0.568, Loss_kd 2.208, Train_accy 63.71
2024-09-08 10:24:16,460 [foster.py] => Task 1, Epoch 17/170 => Loss 3.624, Loss_clf 0.597, Loss_fe 0.574, Loss_kd 2.229, Train_accy 62.46, Test_accy 78.42
2024-09-08 10:24:21,460 [foster.py] => Task 1, Epoch 18/170 => Loss 3.598, Loss_clf 0.584, Loss_fe 0.566, Loss_kd 2.225, Train_accy 62.80, Test_accy 78.22
2024-09-08 10:24:26,398 [foster.py] => Task 1, Epoch 19/170 => Loss 3.484, Loss_clf 0.535, Loss_fe 0.512, Loss_kd 2.214, Train_accy 64.86, Test_accy 77.80
2024-09-08 10:24:31,288 [foster.py] => Task 1, Epoch 20/170 => Loss 3.425, Loss_clf 0.524, Loss_fe 0.476, Loss_kd 2.203, Train_accy 65.97, Test_accy 78.64
2024-09-08 10:24:34,750 [foster.py] => Task 1, Epoch 21/170 => Loss 3.506, Loss_clf 0.547, Loss_fe 0.514, Loss_kd 2.221, Train_accy 64.37
2024-09-08 10:24:39,713 [foster.py] => Task 1, Epoch 22/170 => Loss 3.451, Loss_clf 0.530, Loss_fe 0.480, Loss_kd 2.218, Train_accy 65.23, Test_accy 78.47
2024-09-08 10:24:44,628 [foster.py] => Task 1, Epoch 23/170 => Loss 3.427, Loss_clf 0.509, Loss_fe 0.471, Loss_kd 2.223, Train_accy 67.00, Test_accy 78.27
2024-09-08 10:24:49,515 [foster.py] => Task 1, Epoch 24/170 => Loss 3.444, Loss_clf 0.531, Loss_fe 0.478, Loss_kd 2.213, Train_accy 67.57, Test_accy 77.75
2024-09-08 10:24:54,432 [foster.py] => Task 1, Epoch 25/170 => Loss 3.465, Loss_clf 0.537, Loss_fe 0.487, Loss_kd 2.218, Train_accy 65.11, Test_accy 78.55
2024-09-08 10:24:57,863 [foster.py] => Task 1, Epoch 26/170 => Loss 3.483, Loss_clf 0.541, Loss_fe 0.489, Loss_kd 2.228, Train_accy 64.97
2024-09-08 10:25:02,785 [foster.py] => Task 1, Epoch 27/170 => Loss 3.421, Loss_clf 0.506, Loss_fe 0.468, Loss_kd 2.224, Train_accy 67.57, Test_accy 78.51
2024-09-08 10:25:07,760 [foster.py] => Task 1, Epoch 28/170 => Loss 3.426, Loss_clf 0.518, Loss_fe 0.466, Loss_kd 2.219, Train_accy 67.54, Test_accy 78.62
2024-09-08 10:25:12,649 [foster.py] => Task 1, Epoch 29/170 => Loss 3.440, Loss_clf 0.521, Loss_fe 0.478, Loss_kd 2.218, Train_accy 66.77, Test_accy 78.15
2024-09-08 10:25:17,527 [foster.py] => Task 1, Epoch 30/170 => Loss 3.336, Loss_clf 0.470, Loss_fe 0.429, Loss_kd 2.214, Train_accy 67.40, Test_accy 78.62
2024-09-08 10:25:21,106 [foster.py] => Task 1, Epoch 31/170 => Loss 3.418, Loss_clf 0.518, Loss_fe 0.456, Loss_kd 2.221, Train_accy 67.74
2024-09-08 10:25:25,969 [foster.py] => Task 1, Epoch 32/170 => Loss 3.411, Loss_clf 0.516, Loss_fe 0.444, Loss_kd 2.226, Train_accy 67.20, Test_accy 78.53
2024-09-08 10:25:30,826 [foster.py] => Task 1, Epoch 33/170 => Loss 3.392, Loss_clf 0.512, Loss_fe 0.433, Loss_kd 2.224, Train_accy 68.37, Test_accy 78.91
2024-09-08 10:25:35,744 [foster.py] => Task 1, Epoch 34/170 => Loss 3.417, Loss_clf 0.514, Loss_fe 0.453, Loss_kd 2.226, Train_accy 66.57, Test_accy 78.85
2024-09-08 10:25:40,597 [foster.py] => Task 1, Epoch 35/170 => Loss 3.416, Loss_clf 0.514, Loss_fe 0.444, Loss_kd 2.233, Train_accy 68.54, Test_accy 78.65
2024-09-08 10:25:44,092 [foster.py] => Task 1, Epoch 36/170 => Loss 3.336, Loss_clf 0.481, Loss_fe 0.425, Loss_kd 2.208, Train_accy 68.06
2024-09-08 10:25:49,018 [foster.py] => Task 1, Epoch 37/170 => Loss 3.419, Loss_clf 0.527, Loss_fe 0.445, Loss_kd 2.223, Train_accy 70.31, Test_accy 79.02
2024-09-08 10:25:53,948 [foster.py] => Task 1, Epoch 38/170 => Loss 3.346, Loss_clf 0.477, Loss_fe 0.415, Loss_kd 2.229, Train_accy 66.91, Test_accy 78.91
2024-09-08 10:25:58,834 [foster.py] => Task 1, Epoch 39/170 => Loss 3.326, Loss_clf 0.482, Loss_fe 0.399, Loss_kd 2.222, Train_accy 70.83, Test_accy 79.42
2024-09-08 10:26:03,755 [foster.py] => Task 1, Epoch 40/170 => Loss 3.335, Loss_clf 0.492, Loss_fe 0.399, Loss_kd 2.220, Train_accy 70.37, Test_accy 78.11
2024-09-08 10:26:07,308 [foster.py] => Task 1, Epoch 41/170 => Loss 3.418, Loss_clf 0.524, Loss_fe 0.441, Loss_kd 2.229, Train_accy 68.43
2024-09-08 10:26:12,173 [foster.py] => Task 1, Epoch 42/170 => Loss 3.370, Loss_clf 0.502, Loss_fe 0.422, Loss_kd 2.222, Train_accy 69.23, Test_accy 78.93
2024-09-08 10:26:17,151 [foster.py] => Task 1, Epoch 43/170 => Loss 3.327, Loss_clf 0.479, Loss_fe 0.416, Loss_kd 2.209, Train_accy 68.49, Test_accy 78.80
2024-09-08 10:26:22,113 [foster.py] => Task 1, Epoch 44/170 => Loss 3.312, Loss_clf 0.475, Loss_fe 0.391, Loss_kd 2.221, Train_accy 71.77, Test_accy 79.29
2024-09-08 10:26:27,022 [foster.py] => Task 1, Epoch 45/170 => Loss 3.334, Loss_clf 0.484, Loss_fe 0.412, Loss_kd 2.215, Train_accy 72.03, Test_accy 79.05
2024-09-08 10:26:30,562 [foster.py] => Task 1, Epoch 46/170 => Loss 3.320, Loss_clf 0.481, Loss_fe 0.386, Loss_kd 2.228, Train_accy 69.89
2024-09-08 10:26:35,443 [foster.py] => Task 1, Epoch 47/170 => Loss 3.286, Loss_clf 0.458, Loss_fe 0.391, Loss_kd 2.214, Train_accy 70.60, Test_accy 79.02
2024-09-08 10:26:40,327 [foster.py] => Task 1, Epoch 48/170 => Loss 3.291, Loss_clf 0.460, Loss_fe 0.379, Loss_kd 2.229, Train_accy 70.31, Test_accy 78.65
2024-09-08 10:26:45,188 [foster.py] => Task 1, Epoch 49/170 => Loss 3.322, Loss_clf 0.481, Loss_fe 0.390, Loss_kd 2.227, Train_accy 70.43, Test_accy 78.00
2024-09-08 10:26:50,117 [foster.py] => Task 1, Epoch 50/170 => Loss 3.301, Loss_clf 0.464, Loss_fe 0.377, Loss_kd 2.234, Train_accy 71.80, Test_accy 79.22
2024-09-08 10:26:53,611 [foster.py] => Task 1, Epoch 51/170 => Loss 3.345, Loss_clf 0.480, Loss_fe 0.401, Loss_kd 2.238, Train_accy 72.00
2024-09-08 10:26:58,477 [foster.py] => Task 1, Epoch 52/170 => Loss 3.282, Loss_clf 0.455, Loss_fe 0.391, Loss_kd 2.213, Train_accy 71.49, Test_accy 78.36
2024-09-08 10:27:03,363 [foster.py] => Task 1, Epoch 53/170 => Loss 3.294, Loss_clf 0.464, Loss_fe 0.392, Loss_kd 2.215, Train_accy 70.74, Test_accy 78.56
2024-09-08 10:27:08,224 [foster.py] => Task 1, Epoch 54/170 => Loss 3.297, Loss_clf 0.471, Loss_fe 0.385, Loss_kd 2.217, Train_accy 70.31, Test_accy 79.38
2024-09-08 10:27:13,107 [foster.py] => Task 1, Epoch 55/170 => Loss 3.256, Loss_clf 0.442, Loss_fe 0.365, Loss_kd 2.225, Train_accy 72.46, Test_accy 78.96
2024-09-08 10:27:16,686 [foster.py] => Task 1, Epoch 56/170 => Loss 3.261, Loss_clf 0.459, Loss_fe 0.358, Loss_kd 2.221, Train_accy 71.31
2024-09-08 10:27:21,561 [foster.py] => Task 1, Epoch 57/170 => Loss 3.193, Loss_clf 0.411, Loss_fe 0.341, Loss_kd 2.217, Train_accy 73.17, Test_accy 78.78
2024-09-08 10:27:26,500 [foster.py] => Task 1, Epoch 58/170 => Loss 3.293, Loss_clf 0.464, Loss_fe 0.375, Loss_kd 2.229, Train_accy 71.14, Test_accy 79.07
2024-09-08 10:27:31,362 [foster.py] => Task 1, Epoch 59/170 => Loss 3.161, Loss_clf 0.404, Loss_fe 0.328, Loss_kd 2.208, Train_accy 75.49, Test_accy 78.84
2024-09-08 10:27:36,221 [foster.py] => Task 1, Epoch 60/170 => Loss 3.198, Loss_clf 0.420, Loss_fe 0.334, Loss_kd 2.220, Train_accy 73.80, Test_accy 78.20
2024-09-08 10:27:39,724 [foster.py] => Task 1, Epoch 61/170 => Loss 3.250, Loss_clf 0.447, Loss_fe 0.373, Loss_kd 2.208, Train_accy 72.83
2024-09-08 10:27:44,622 [foster.py] => Task 1, Epoch 62/170 => Loss 3.262, Loss_clf 0.451, Loss_fe 0.351, Loss_kd 2.236, Train_accy 71.31, Test_accy 79.09
2024-09-08 10:27:49,510 [foster.py] => Task 1, Epoch 63/170 => Loss 3.201, Loss_clf 0.424, Loss_fe 0.331, Loss_kd 2.221, Train_accy 73.80, Test_accy 79.02
2024-09-08 10:27:54,383 [foster.py] => Task 1, Epoch 64/170 => Loss 3.204, Loss_clf 0.408, Loss_fe 0.326, Loss_kd 2.244, Train_accy 75.66, Test_accy 79.51
2024-09-08 10:27:59,297 [foster.py] => Task 1, Epoch 65/170 => Loss 3.176, Loss_clf 0.417, Loss_fe 0.327, Loss_kd 2.210, Train_accy 73.34, Test_accy 79.11
2024-09-08 10:28:02,822 [foster.py] => Task 1, Epoch 66/170 => Loss 3.206, Loss_clf 0.430, Loss_fe 0.311, Loss_kd 2.240, Train_accy 74.66
2024-09-08 10:28:07,758 [foster.py] => Task 1, Epoch 67/170 => Loss 3.185, Loss_clf 0.414, Loss_fe 0.317, Loss_kd 2.230, Train_accy 75.29, Test_accy 78.98
2024-09-08 10:28:12,773 [foster.py] => Task 1, Epoch 68/170 => Loss 3.188, Loss_clf 0.423, Loss_fe 0.322, Loss_kd 2.220, Train_accy 74.86, Test_accy 79.24
2024-09-08 10:28:17,674 [foster.py] => Task 1, Epoch 69/170 => Loss 3.209, Loss_clf 0.428, Loss_fe 0.330, Loss_kd 2.227, Train_accy 75.86, Test_accy 79.27
2024-09-08 10:28:22,562 [foster.py] => Task 1, Epoch 70/170 => Loss 3.236, Loss_clf 0.429, Loss_fe 0.356, Loss_kd 2.227, Train_accy 74.09, Test_accy 79.84
2024-09-08 10:28:26,068 [foster.py] => Task 1, Epoch 71/170 => Loss 3.196, Loss_clf 0.426, Loss_fe 0.317, Loss_kd 2.229, Train_accy 74.17
2024-09-08 10:28:30,972 [foster.py] => Task 1, Epoch 72/170 => Loss 3.205, Loss_clf 0.435, Loss_fe 0.320, Loss_kd 2.226, Train_accy 75.77, Test_accy 78.96
2024-09-08 10:28:35,872 [foster.py] => Task 1, Epoch 73/170 => Loss 3.182, Loss_clf 0.427, Loss_fe 0.311, Loss_kd 2.220, Train_accy 74.34, Test_accy 79.11
2024-09-08 10:28:40,811 [foster.py] => Task 1, Epoch 74/170 => Loss 3.173, Loss_clf 0.404, Loss_fe 0.322, Loss_kd 2.223, Train_accy 77.49, Test_accy 79.33
2024-09-08 10:28:45,714 [foster.py] => Task 1, Epoch 75/170 => Loss 3.136, Loss_clf 0.392, Loss_fe 0.307, Loss_kd 2.214, Train_accy 74.83, Test_accy 79.38
2024-09-08 10:28:49,221 [foster.py] => Task 1, Epoch 76/170 => Loss 3.175, Loss_clf 0.416, Loss_fe 0.313, Loss_kd 2.222, Train_accy 75.11
2024-09-08 10:28:54,104 [foster.py] => Task 1, Epoch 77/170 => Loss 3.124, Loss_clf 0.389, Loss_fe 0.303, Loss_kd 2.210, Train_accy 77.06, Test_accy 79.36
2024-09-08 10:28:58,981 [foster.py] => Task 1, Epoch 78/170 => Loss 3.169, Loss_clf 0.423, Loss_fe 0.297, Loss_kd 2.224, Train_accy 75.69, Test_accy 79.49
2024-09-08 10:29:03,893 [foster.py] => Task 1, Epoch 79/170 => Loss 3.200, Loss_clf 0.436, Loss_fe 0.307, Loss_kd 2.232, Train_accy 76.11, Test_accy 79.04
2024-09-08 10:29:08,777 [foster.py] => Task 1, Epoch 80/170 => Loss 3.099, Loss_clf 0.384, Loss_fe 0.284, Loss_kd 2.208, Train_accy 75.97, Test_accy 79.42
2024-09-08 10:29:12,316 [foster.py] => Task 1, Epoch 81/170 => Loss 3.193, Loss_clf 0.434, Loss_fe 0.319, Loss_kd 2.217, Train_accy 76.03
2024-09-08 10:29:17,198 [foster.py] => Task 1, Epoch 82/170 => Loss 3.112, Loss_clf 0.378, Loss_fe 0.292, Loss_kd 2.218, Train_accy 75.37, Test_accy 79.15
2024-09-08 10:29:22,086 [foster.py] => Task 1, Epoch 83/170 => Loss 3.145, Loss_clf 0.409, Loss_fe 0.285, Loss_kd 2.227, Train_accy 75.03, Test_accy 79.18
2024-09-08 10:29:26,947 [foster.py] => Task 1, Epoch 84/170 => Loss 3.173, Loss_clf 0.411, Loss_fe 0.312, Loss_kd 2.226, Train_accy 74.80, Test_accy 79.47
2024-09-08 10:29:31,856 [foster.py] => Task 1, Epoch 85/170 => Loss 3.081, Loss_clf 0.372, Loss_fe 0.272, Loss_kd 2.215, Train_accy 77.14, Test_accy 79.55
2024-09-08 10:29:35,395 [foster.py] => Task 1, Epoch 86/170 => Loss 3.136, Loss_clf 0.396, Loss_fe 0.288, Loss_kd 2.229, Train_accy 76.23
2024-09-08 10:29:40,224 [foster.py] => Task 1, Epoch 87/170 => Loss 3.106, Loss_clf 0.389, Loss_fe 0.288, Loss_kd 2.207, Train_accy 77.46, Test_accy 79.27
2024-09-08 10:29:45,153 [foster.py] => Task 1, Epoch 88/170 => Loss 3.116, Loss_clf 0.393, Loss_fe 0.276, Loss_kd 2.224, Train_accy 77.66, Test_accy 79.53
2024-09-08 10:29:50,136 [foster.py] => Task 1, Epoch 89/170 => Loss 3.057, Loss_clf 0.355, Loss_fe 0.262, Loss_kd 2.216, Train_accy 77.86, Test_accy 79.35
2024-09-08 10:29:55,014 [foster.py] => Task 1, Epoch 90/170 => Loss 3.095, Loss_clf 0.378, Loss_fe 0.267, Loss_kd 2.227, Train_accy 77.71, Test_accy 79.33
2024-09-08 10:29:58,579 [foster.py] => Task 1, Epoch 91/170 => Loss 3.125, Loss_clf 0.396, Loss_fe 0.269, Loss_kd 2.235, Train_accy 79.46
2024-09-08 10:30:03,466 [foster.py] => Task 1, Epoch 92/170 => Loss 3.066, Loss_clf 0.364, Loss_fe 0.255, Loss_kd 2.223, Train_accy 77.71, Test_accy 79.31
2024-09-08 10:30:08,301 [foster.py] => Task 1, Epoch 93/170 => Loss 3.100, Loss_clf 0.381, Loss_fe 0.270, Loss_kd 2.225, Train_accy 78.23, Test_accy 79.76
2024-09-08 10:30:13,165 [foster.py] => Task 1, Epoch 94/170 => Loss 3.089, Loss_clf 0.394, Loss_fe 0.255, Loss_kd 2.217, Train_accy 77.77, Test_accy 79.49
2024-09-08 10:30:18,025 [foster.py] => Task 1, Epoch 95/170 => Loss 3.091, Loss_clf 0.390, Loss_fe 0.242, Loss_kd 2.234, Train_accy 76.51, Test_accy 79.00
2024-09-08 10:30:21,559 [foster.py] => Task 1, Epoch 96/170 => Loss 3.041, Loss_clf 0.365, Loss_fe 0.239, Loss_kd 2.214, Train_accy 77.49
2024-09-08 10:30:26,484 [foster.py] => Task 1, Epoch 97/170 => Loss 3.100, Loss_clf 0.389, Loss_fe 0.257, Loss_kd 2.229, Train_accy 78.51, Test_accy 79.11
2024-09-08 10:30:31,338 [foster.py] => Task 1, Epoch 98/170 => Loss 3.040, Loss_clf 0.363, Loss_fe 0.229, Loss_kd 2.224, Train_accy 78.03, Test_accy 79.73
2024-09-08 10:30:36,206 [foster.py] => Task 1, Epoch 99/170 => Loss 3.030, Loss_clf 0.363, Loss_fe 0.230, Loss_kd 2.214, Train_accy 78.34, Test_accy 79.69
2024-09-08 10:30:41,091 [foster.py] => Task 1, Epoch 100/170 => Loss 3.019, Loss_clf 0.345, Loss_fe 0.231, Loss_kd 2.220, Train_accy 80.14, Test_accy 79.40
2024-09-08 10:30:44,663 [foster.py] => Task 1, Epoch 101/170 => Loss 3.001, Loss_clf 0.350, Loss_fe 0.218, Loss_kd 2.211, Train_accy 80.66
2024-09-08 10:30:49,505 [foster.py] => Task 1, Epoch 102/170 => Loss 3.025, Loss_clf 0.348, Loss_fe 0.225, Loss_kd 2.228, Train_accy 78.89, Test_accy 79.73
2024-09-08 10:30:54,358 [foster.py] => Task 1, Epoch 103/170 => Loss 3.076, Loss_clf 0.378, Loss_fe 0.248, Loss_kd 2.226, Train_accy 79.43, Test_accy 79.55
2024-09-08 10:30:59,241 [foster.py] => Task 1, Epoch 104/170 => Loss 3.032, Loss_clf 0.354, Loss_fe 0.225, Loss_kd 2.229, Train_accy 78.26, Test_accy 79.78
2024-09-08 10:31:04,131 [foster.py] => Task 1, Epoch 105/170 => Loss 3.026, Loss_clf 0.349, Loss_fe 0.222, Loss_kd 2.231, Train_accy 79.26, Test_accy 79.53
2024-09-08 10:31:07,622 [foster.py] => Task 1, Epoch 106/170 => Loss 3.035, Loss_clf 0.355, Loss_fe 0.232, Loss_kd 2.225, Train_accy 79.57
2024-09-08 10:31:12,597 [foster.py] => Task 1, Epoch 107/170 => Loss 3.022, Loss_clf 0.350, Loss_fe 0.237, Loss_kd 2.213, Train_accy 79.14, Test_accy 79.84
2024-09-08 10:31:17,503 [foster.py] => Task 1, Epoch 108/170 => Loss 3.000, Loss_clf 0.349, Loss_fe 0.210, Loss_kd 2.218, Train_accy 79.97, Test_accy 79.85
2024-09-08 10:31:22,337 [foster.py] => Task 1, Epoch 109/170 => Loss 3.017, Loss_clf 0.357, Loss_fe 0.214, Loss_kd 2.223, Train_accy 79.91, Test_accy 79.58
2024-09-08 10:31:27,234 [foster.py] => Task 1, Epoch 110/170 => Loss 3.024, Loss_clf 0.357, Loss_fe 0.211, Loss_kd 2.232, Train_accy 79.74, Test_accy 79.58
2024-09-08 10:31:30,804 [foster.py] => Task 1, Epoch 111/170 => Loss 2.953, Loss_clf 0.319, Loss_fe 0.200, Loss_kd 2.212, Train_accy 82.97
2024-09-08 10:31:35,774 [foster.py] => Task 1, Epoch 112/170 => Loss 3.015, Loss_clf 0.355, Loss_fe 0.215, Loss_kd 2.221, Train_accy 79.23, Test_accy 79.67
2024-09-08 10:31:40,688 [foster.py] => Task 1, Epoch 113/170 => Loss 2.976, Loss_clf 0.327, Loss_fe 0.203, Loss_kd 2.223, Train_accy 81.34, Test_accy 80.13
2024-09-08 10:31:45,526 [foster.py] => Task 1, Epoch 114/170 => Loss 2.996, Loss_clf 0.338, Loss_fe 0.206, Loss_kd 2.227, Train_accy 81.83, Test_accy 79.76
2024-09-08 10:31:50,449 [foster.py] => Task 1, Epoch 115/170 => Loss 2.977, Loss_clf 0.338, Loss_fe 0.203, Loss_kd 2.214, Train_accy 80.71, Test_accy 79.87
2024-09-08 10:31:53,932 [foster.py] => Task 1, Epoch 116/170 => Loss 2.962, Loss_clf 0.327, Loss_fe 0.200, Loss_kd 2.213, Train_accy 82.31
2024-09-08 10:31:58,847 [foster.py] => Task 1, Epoch 117/170 => Loss 2.993, Loss_clf 0.338, Loss_fe 0.207, Loss_kd 2.224, Train_accy 81.51, Test_accy 79.69
2024-09-08 10:32:03,726 [foster.py] => Task 1, Epoch 118/170 => Loss 2.972, Loss_clf 0.337, Loss_fe 0.201, Loss_kd 2.211, Train_accy 80.20, Test_accy 79.95
2024-09-08 10:32:08,609 [foster.py] => Task 1, Epoch 119/170 => Loss 2.935, Loss_clf 0.304, Loss_fe 0.185, Loss_kd 2.222, Train_accy 81.80, Test_accy 80.02
2024-09-08 10:32:13,473 [foster.py] => Task 1, Epoch 120/170 => Loss 2.989, Loss_clf 0.341, Loss_fe 0.198, Loss_kd 2.227, Train_accy 81.49, Test_accy 79.82
2024-09-08 10:32:16,977 [foster.py] => Task 1, Epoch 121/170 => Loss 2.968, Loss_clf 0.332, Loss_fe 0.185, Loss_kd 2.226, Train_accy 81.09
2024-09-08 10:32:21,860 [foster.py] => Task 1, Epoch 122/170 => Loss 2.954, Loss_clf 0.335, Loss_fe 0.179, Loss_kd 2.217, Train_accy 81.77, Test_accy 79.65
2024-09-08 10:32:26,787 [foster.py] => Task 1, Epoch 123/170 => Loss 2.928, Loss_clf 0.304, Loss_fe 0.180, Loss_kd 2.221, Train_accy 83.69, Test_accy 79.96
2024-09-08 10:32:31,747 [foster.py] => Task 1, Epoch 124/170 => Loss 2.960, Loss_clf 0.322, Loss_fe 0.175, Loss_kd 2.238, Train_accy 82.69, Test_accy 79.89
2024-09-08 10:32:36,681 [foster.py] => Task 1, Epoch 125/170 => Loss 2.959, Loss_clf 0.330, Loss_fe 0.184, Loss_kd 2.221, Train_accy 82.14, Test_accy 79.62
2024-09-08 10:32:40,236 [foster.py] => Task 1, Epoch 126/170 => Loss 2.936, Loss_clf 0.307, Loss_fe 0.169, Loss_kd 2.235, Train_accy 83.77
2024-09-08 10:32:45,119 [foster.py] => Task 1, Epoch 127/170 => Loss 2.939, Loss_clf 0.315, Loss_fe 0.180, Loss_kd 2.221, Train_accy 83.40, Test_accy 79.73
2024-09-08 10:32:50,008 [foster.py] => Task 1, Epoch 128/170 => Loss 2.920, Loss_clf 0.307, Loss_fe 0.176, Loss_kd 2.214, Train_accy 82.71, Test_accy 80.35
2024-09-08 10:32:54,897 [foster.py] => Task 1, Epoch 129/170 => Loss 2.929, Loss_clf 0.297, Loss_fe 0.172, Loss_kd 2.235, Train_accy 83.54, Test_accy 80.09
2024-09-08 10:32:59,829 [foster.py] => Task 1, Epoch 130/170 => Loss 2.895, Loss_clf 0.298, Loss_fe 0.164, Loss_kd 2.210, Train_accy 83.20, Test_accy 80.00
2024-09-08 10:33:03,408 [foster.py] => Task 1, Epoch 131/170 => Loss 2.946, Loss_clf 0.325, Loss_fe 0.165, Loss_kd 2.231, Train_accy 82.54
2024-09-08 10:33:08,274 [foster.py] => Task 1, Epoch 132/170 => Loss 2.925, Loss_clf 0.308, Loss_fe 0.168, Loss_kd 2.225, Train_accy 83.91, Test_accy 79.82
2024-09-08 10:33:13,173 [foster.py] => Task 1, Epoch 133/170 => Loss 2.927, Loss_clf 0.314, Loss_fe 0.169, Loss_kd 2.221, Train_accy 82.03, Test_accy 79.84
2024-09-08 10:33:18,072 [foster.py] => Task 1, Epoch 134/170 => Loss 2.984, Loss_clf 0.345, Loss_fe 0.175, Loss_kd 2.239, Train_accy 81.09, Test_accy 79.82
2024-09-08 10:33:22,972 [foster.py] => Task 1, Epoch 135/170 => Loss 2.940, Loss_clf 0.311, Loss_fe 0.165, Loss_kd 2.239, Train_accy 83.00, Test_accy 79.84
2024-09-08 10:33:26,511 [foster.py] => Task 1, Epoch 136/170 => Loss 2.898, Loss_clf 0.299, Loss_fe 0.161, Loss_kd 2.215, Train_accy 84.20
2024-09-08 10:33:31,492 [foster.py] => Task 1, Epoch 137/170 => Loss 2.883, Loss_clf 0.291, Loss_fe 0.153, Loss_kd 2.216, Train_accy 83.69, Test_accy 79.85
2024-09-08 10:33:36,337 [foster.py] => Task 1, Epoch 138/170 => Loss 2.941, Loss_clf 0.313, Loss_fe 0.172, Loss_kd 2.232, Train_accy 83.29, Test_accy 79.93
2024-09-08 10:33:41,250 [foster.py] => Task 1, Epoch 139/170 => Loss 2.876, Loss_clf 0.275, Loss_fe 0.151, Loss_kd 2.225, Train_accy 84.57, Test_accy 79.73
2024-09-08 10:33:46,170 [foster.py] => Task 1, Epoch 140/170 => Loss 2.895, Loss_clf 0.299, Loss_fe 0.144, Loss_kd 2.227, Train_accy 84.34, Test_accy 79.89
2024-09-08 10:33:49,738 [foster.py] => Task 1, Epoch 141/170 => Loss 2.926, Loss_clf 0.313, Loss_fe 0.155, Loss_kd 2.234, Train_accy 84.54
2024-09-08 10:33:54,636 [foster.py] => Task 1, Epoch 142/170 => Loss 2.864, Loss_clf 0.277, Loss_fe 0.144, Loss_kd 2.220, Train_accy 84.14, Test_accy 79.95
2024-09-08 10:33:59,557 [foster.py] => Task 1, Epoch 143/170 => Loss 2.877, Loss_clf 0.293, Loss_fe 0.147, Loss_kd 2.215, Train_accy 84.11, Test_accy 79.82
2024-09-08 10:34:04,466 [foster.py] => Task 1, Epoch 144/170 => Loss 2.855, Loss_clf 0.277, Loss_fe 0.144, Loss_kd 2.211, Train_accy 85.20, Test_accy 79.98
2024-09-08 10:34:09,315 [foster.py] => Task 1, Epoch 145/170 => Loss 2.882, Loss_clf 0.297, Loss_fe 0.150, Loss_kd 2.213, Train_accy 84.31, Test_accy 79.96
2024-09-08 10:34:12,831 [foster.py] => Task 1, Epoch 146/170 => Loss 2.870, Loss_clf 0.285, Loss_fe 0.139, Loss_kd 2.222, Train_accy 85.20
2024-09-08 10:34:17,684 [foster.py] => Task 1, Epoch 147/170 => Loss 2.923, Loss_clf 0.315, Loss_fe 0.152, Loss_kd 2.231, Train_accy 83.54, Test_accy 79.95
2024-09-08 10:34:22,583 [foster.py] => Task 1, Epoch 148/170 => Loss 2.891, Loss_clf 0.295, Loss_fe 0.147, Loss_kd 2.225, Train_accy 83.89, Test_accy 80.11
2024-09-08 10:34:27,440 [foster.py] => Task 1, Epoch 149/170 => Loss 2.888, Loss_clf 0.294, Loss_fe 0.145, Loss_kd 2.225, Train_accy 84.37, Test_accy 79.96
2024-09-08 10:34:32,341 [foster.py] => Task 1, Epoch 150/170 => Loss 2.858, Loss_clf 0.275, Loss_fe 0.147, Loss_kd 2.213, Train_accy 85.34, Test_accy 80.11
2024-09-08 10:34:35,840 [foster.py] => Task 1, Epoch 151/170 => Loss 2.914, Loss_clf 0.302, Loss_fe 0.157, Loss_kd 2.231, Train_accy 84.80
2024-09-08 10:34:40,744 [foster.py] => Task 1, Epoch 152/170 => Loss 2.828, Loss_clf 0.271, Loss_fe 0.132, Loss_kd 2.203, Train_accy 85.06, Test_accy 79.96
2024-09-08 10:34:45,678 [foster.py] => Task 1, Epoch 153/170 => Loss 2.933, Loss_clf 0.303, Loss_fe 0.165, Loss_kd 2.239, Train_accy 84.60, Test_accy 80.11
2024-09-08 10:34:50,605 [foster.py] => Task 1, Epoch 154/170 => Loss 2.896, Loss_clf 0.297, Loss_fe 0.141, Loss_kd 2.234, Train_accy 84.49, Test_accy 80.07
2024-09-08 10:34:55,552 [foster.py] => Task 1, Epoch 155/170 => Loss 2.896, Loss_clf 0.286, Loss_fe 0.155, Loss_kd 2.231, Train_accy 85.00, Test_accy 80.02
2024-09-08 10:34:59,040 [foster.py] => Task 1, Epoch 156/170 => Loss 2.886, Loss_clf 0.297, Loss_fe 0.143, Loss_kd 2.222, Train_accy 85.03
2024-09-08 10:35:04,001 [foster.py] => Task 1, Epoch 157/170 => Loss 2.880, Loss_clf 0.281, Loss_fe 0.149, Loss_kd 2.226, Train_accy 84.89, Test_accy 79.89
2024-09-08 10:35:08,873 [foster.py] => Task 1, Epoch 158/170 => Loss 2.900, Loss_clf 0.298, Loss_fe 0.150, Loss_kd 2.228, Train_accy 84.23, Test_accy 79.89
2024-09-08 10:35:13,767 [foster.py] => Task 1, Epoch 159/170 => Loss 2.904, Loss_clf 0.310, Loss_fe 0.151, Loss_kd 2.219, Train_accy 84.20, Test_accy 79.98
2024-09-08 10:35:18,652 [foster.py] => Task 1, Epoch 160/170 => Loss 2.927, Loss_clf 0.308, Loss_fe 0.160, Loss_kd 2.234, Train_accy 83.57, Test_accy 79.87
2024-09-08 10:35:22,114 [foster.py] => Task 1, Epoch 161/170 => Loss 2.872, Loss_clf 0.284, Loss_fe 0.140, Loss_kd 2.224, Train_accy 84.63
2024-09-08 10:35:26,963 [foster.py] => Task 1, Epoch 162/170 => Loss 2.860, Loss_clf 0.288, Loss_fe 0.150, Loss_kd 2.201, Train_accy 83.86, Test_accy 79.93
2024-09-08 10:35:31,828 [foster.py] => Task 1, Epoch 163/170 => Loss 2.884, Loss_clf 0.293, Loss_fe 0.138, Loss_kd 2.228, Train_accy 85.00, Test_accy 79.89
2024-09-08 10:35:36,727 [foster.py] => Task 1, Epoch 164/170 => Loss 2.894, Loss_clf 0.289, Loss_fe 0.149, Loss_kd 2.231, Train_accy 84.29, Test_accy 79.85
2024-09-08 10:35:41,606 [foster.py] => Task 1, Epoch 165/170 => Loss 2.916, Loss_clf 0.310, Loss_fe 0.149, Loss_kd 2.233, Train_accy 83.97, Test_accy 79.80
2024-09-08 10:35:45,091 [foster.py] => Task 1, Epoch 166/170 => Loss 2.861, Loss_clf 0.278, Loss_fe 0.149, Loss_kd 2.212, Train_accy 85.83
2024-09-08 10:35:50,009 [foster.py] => Task 1, Epoch 167/170 => Loss 2.894, Loss_clf 0.293, Loss_fe 0.143, Loss_kd 2.233, Train_accy 85.06, Test_accy 79.91
2024-09-08 10:35:54,954 [foster.py] => Task 1, Epoch 168/170 => Loss 2.862, Loss_clf 0.282, Loss_fe 0.150, Loss_kd 2.208, Train_accy 85.40, Test_accy 79.96
2024-09-08 10:35:59,871 [foster.py] => Task 1, Epoch 169/170 => Loss 2.852, Loss_clf 0.270, Loss_fe 0.136, Loss_kd 2.223, Train_accy 84.83, Test_accy 79.84
2024-09-08 10:36:04,801 [foster.py] => Task 1, Epoch 170/170 => Loss 2.869, Loss_clf 0.277, Loss_fe 0.141, Loss_kd 2.227, Train_accy 85.77, Test_accy 79.80
2024-09-08 10:36:04,804 [foster.py] => do not weight align teacher!
2024-09-08 10:36:04,805 [foster.py] => per cls weights : [1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116 1.04526116
 1.04526116 1.04526116 0.5473884  0.5473884  0.5473884  0.5473884
 0.5473884 ]
2024-09-08 10:36:11,688 [foster.py] => SNet: Task 1, Epoch 1/130 => Loss 27.709,  Loss1 0.688, Train_accy 24.63, Test_accy 71.98
2024-09-08 10:36:16,608 [foster.py] => SNet: Task 1, Epoch 2/130 => Loss 27.464,  Loss1 0.688, Train_accy 44.80
2024-09-08 10:36:21,520 [foster.py] => SNet: Task 1, Epoch 3/130 => Loss 27.442,  Loss1 0.688, Train_accy 50.57
2024-09-08 10:36:26,446 [foster.py] => SNet: Task 1, Epoch 4/130 => Loss 27.391,  Loss1 0.688, Train_accy 55.80
2024-09-08 10:36:31,342 [foster.py] => SNet: Task 1, Epoch 5/130 => Loss 27.385,  Loss1 0.688, Train_accy 58.23
2024-09-08 10:36:37,155 [foster.py] => SNet: Task 1, Epoch 6/130 => Loss 27.362,  Loss1 0.688, Train_accy 60.89, Test_accy 77.38
2024-09-08 10:36:42,054 [foster.py] => SNet: Task 1, Epoch 7/130 => Loss 27.393,  Loss1 0.688, Train_accy 61.69
2024-09-08 10:36:46,981 [foster.py] => SNet: Task 1, Epoch 8/130 => Loss 27.346,  Loss1 0.688, Train_accy 63.51
2024-09-08 10:36:51,933 [foster.py] => SNet: Task 1, Epoch 9/130 => Loss 27.366,  Loss1 0.688, Train_accy 63.37
2024-09-08 10:36:56,855 [foster.py] => SNet: Task 1, Epoch 10/130 => Loss 27.343,  Loss1 0.688, Train_accy 64.20
2024-09-08 10:37:02,749 [foster.py] => SNet: Task 1, Epoch 11/130 => Loss 27.354,  Loss1 0.688, Train_accy 65.23, Test_accy 77.38
2024-09-08 10:37:07,646 [foster.py] => SNet: Task 1, Epoch 12/130 => Loss 27.314,  Loss1 0.688, Train_accy 63.40
2024-09-08 10:37:12,581 [foster.py] => SNet: Task 1, Epoch 13/130 => Loss 27.381,  Loss1 0.688, Train_accy 64.31
2024-09-08 10:37:17,476 [foster.py] => SNet: Task 1, Epoch 14/130 => Loss 27.361,  Loss1 0.688, Train_accy 66.20
2024-09-08 10:37:22,464 [foster.py] => SNet: Task 1, Epoch 15/130 => Loss 27.334,  Loss1 0.688, Train_accy 65.43
2024-09-08 10:37:28,307 [foster.py] => SNet: Task 1, Epoch 16/130 => Loss 27.298,  Loss1 0.688, Train_accy 65.83, Test_accy 77.76
2024-09-08 10:37:33,252 [foster.py] => SNet: Task 1, Epoch 17/130 => Loss 27.346,  Loss1 0.688, Train_accy 65.09
2024-09-08 10:37:38,183 [foster.py] => SNet: Task 1, Epoch 18/130 => Loss 27.367,  Loss1 0.687, Train_accy 65.23
2024-09-08 10:37:43,105 [foster.py] => SNet: Task 1, Epoch 19/130 => Loss 27.356,  Loss1 0.688, Train_accy 64.54
2024-09-08 10:37:48,064 [foster.py] => SNet: Task 1, Epoch 20/130 => Loss 27.340,  Loss1 0.688, Train_accy 65.69
2024-09-08 10:37:53,898 [foster.py] => SNet: Task 1, Epoch 21/130 => Loss 27.370,  Loss1 0.688, Train_accy 66.14, Test_accy 78.36
2024-09-08 10:37:58,816 [foster.py] => SNet: Task 1, Epoch 22/130 => Loss 27.320,  Loss1 0.688, Train_accy 66.71
2024-09-08 10:38:03,763 [foster.py] => SNet: Task 1, Epoch 23/130 => Loss 27.308,  Loss1 0.688, Train_accy 67.14
2024-09-08 10:38:08,707 [foster.py] => SNet: Task 1, Epoch 24/130 => Loss 27.289,  Loss1 0.688, Train_accy 67.29
2024-09-08 10:38:13,670 [foster.py] => SNet: Task 1, Epoch 25/130 => Loss 27.343,  Loss1 0.689, Train_accy 66.71
2024-09-08 10:38:19,514 [foster.py] => SNet: Task 1, Epoch 26/130 => Loss 27.362,  Loss1 0.688, Train_accy 67.66, Test_accy 77.95
2024-09-08 10:38:24,436 [foster.py] => SNet: Task 1, Epoch 27/130 => Loss 27.295,  Loss1 0.688, Train_accy 67.17
2024-09-08 10:38:29,385 [foster.py] => SNet: Task 1, Epoch 28/130 => Loss 27.331,  Loss1 0.688, Train_accy 67.46
2024-09-08 10:38:34,409 [foster.py] => SNet: Task 1, Epoch 29/130 => Loss 27.317,  Loss1 0.688, Train_accy 67.31
2024-09-08 10:38:39,318 [foster.py] => SNet: Task 1, Epoch 30/130 => Loss 27.355,  Loss1 0.688, Train_accy 66.74
2024-09-08 10:38:45,135 [foster.py] => SNet: Task 1, Epoch 31/130 => Loss 27.348,  Loss1 0.688, Train_accy 66.97, Test_accy 78.00
2024-09-08 10:38:50,055 [foster.py] => SNet: Task 1, Epoch 32/130 => Loss 27.330,  Loss1 0.688, Train_accy 67.09
2024-09-08 10:38:54,991 [foster.py] => SNet: Task 1, Epoch 33/130 => Loss 27.334,  Loss1 0.688, Train_accy 67.46
2024-09-08 10:38:59,922 [foster.py] => SNet: Task 1, Epoch 34/130 => Loss 27.335,  Loss1 0.688, Train_accy 67.74
2024-09-08 10:39:04,888 [foster.py] => SNet: Task 1, Epoch 35/130 => Loss 27.344,  Loss1 0.688, Train_accy 67.31
2024-09-08 10:39:10,722 [foster.py] => SNet: Task 1, Epoch 36/130 => Loss 27.337,  Loss1 0.688, Train_accy 67.37, Test_accy 78.49
2024-09-08 10:39:15,625 [foster.py] => SNet: Task 1, Epoch 37/130 => Loss 27.384,  Loss1 0.688, Train_accy 67.51
2024-09-08 10:39:20,515 [foster.py] => SNet: Task 1, Epoch 38/130 => Loss 27.320,  Loss1 0.688, Train_accy 68.40
2024-09-08 10:39:25,431 [foster.py] => SNet: Task 1, Epoch 39/130 => Loss 27.316,  Loss1 0.688, Train_accy 67.03
2024-09-08 10:39:30,320 [foster.py] => SNet: Task 1, Epoch 40/130 => Loss 27.316,  Loss1 0.688, Train_accy 68.06
2024-09-08 10:39:36,153 [foster.py] => SNet: Task 1, Epoch 41/130 => Loss 27.306,  Loss1 0.688, Train_accy 67.29, Test_accy 78.47
2024-09-08 10:39:41,052 [foster.py] => SNet: Task 1, Epoch 42/130 => Loss 27.317,  Loss1 0.688, Train_accy 68.34
2024-09-08 10:39:46,063 [foster.py] => SNet: Task 1, Epoch 43/130 => Loss 27.311,  Loss1 0.688, Train_accy 69.23
2024-09-08 10:39:51,000 [foster.py] => SNet: Task 1, Epoch 44/130 => Loss 27.337,  Loss1 0.688, Train_accy 69.54
2024-09-08 10:39:55,884 [foster.py] => SNet: Task 1, Epoch 45/130 => Loss 27.294,  Loss1 0.688, Train_accy 69.69
2024-09-08 10:40:01,705 [foster.py] => SNet: Task 1, Epoch 46/130 => Loss 27.289,  Loss1 0.688, Train_accy 68.63, Test_accy 78.04
2024-09-08 10:40:06,624 [foster.py] => SNet: Task 1, Epoch 47/130 => Loss 27.301,  Loss1 0.688, Train_accy 67.66
2024-09-08 10:40:11,534 [foster.py] => SNet: Task 1, Epoch 48/130 => Loss 27.304,  Loss1 0.688, Train_accy 70.06
2024-09-08 10:40:16,463 [foster.py] => SNet: Task 1, Epoch 49/130 => Loss 27.323,  Loss1 0.688, Train_accy 68.94
2024-09-08 10:40:21,406 [foster.py] => SNet: Task 1, Epoch 50/130 => Loss 27.315,  Loss1 0.688, Train_accy 69.26
2024-09-08 10:40:27,249 [foster.py] => SNet: Task 1, Epoch 51/130 => Loss 27.312,  Loss1 0.688, Train_accy 68.57, Test_accy 78.27
2024-09-08 10:40:32,181 [foster.py] => SNet: Task 1, Epoch 52/130 => Loss 27.309,  Loss1 0.688, Train_accy 69.97
2024-09-08 10:40:37,099 [foster.py] => SNet: Task 1, Epoch 53/130 => Loss 27.318,  Loss1 0.688, Train_accy 69.86
2024-09-08 10:40:42,043 [foster.py] => SNet: Task 1, Epoch 54/130 => Loss 27.372,  Loss1 0.688, Train_accy 67.06
2024-09-08 10:40:46,979 [foster.py] => SNet: Task 1, Epoch 55/130 => Loss 27.325,  Loss1 0.688, Train_accy 69.97
2024-09-08 10:40:52,829 [foster.py] => SNet: Task 1, Epoch 56/130 => Loss 27.301,  Loss1 0.688, Train_accy 69.46, Test_accy 78.29
2024-09-08 10:40:57,767 [foster.py] => SNet: Task 1, Epoch 57/130 => Loss 27.307,  Loss1 0.688, Train_accy 70.49
2024-09-08 10:41:02,709 [foster.py] => SNet: Task 1, Epoch 58/130 => Loss 27.291,  Loss1 0.688, Train_accy 69.86
2024-09-08 10:41:07,616 [foster.py] => SNet: Task 1, Epoch 59/130 => Loss 27.298,  Loss1 0.689, Train_accy 69.00
2024-09-08 10:41:12,528 [foster.py] => SNet: Task 1, Epoch 60/130 => Loss 27.313,  Loss1 0.688, Train_accy 70.43
2024-09-08 10:41:18,395 [foster.py] => SNet: Task 1, Epoch 61/130 => Loss 27.310,  Loss1 0.688, Train_accy 68.83, Test_accy 78.89
2024-09-08 10:41:23,286 [foster.py] => SNet: Task 1, Epoch 62/130 => Loss 27.324,  Loss1 0.688, Train_accy 69.00
2024-09-08 10:41:28,234 [foster.py] => SNet: Task 1, Epoch 63/130 => Loss 27.312,  Loss1 0.688, Train_accy 69.29
2024-09-08 10:41:33,202 [foster.py] => SNet: Task 1, Epoch 64/130 => Loss 27.316,  Loss1 0.688, Train_accy 70.77
2024-09-08 10:41:38,077 [foster.py] => SNet: Task 1, Epoch 65/130 => Loss 27.317,  Loss1 0.688, Train_accy 69.94
2024-09-08 10:41:43,891 [foster.py] => SNet: Task 1, Epoch 66/130 => Loss 27.330,  Loss1 0.688, Train_accy 70.57, Test_accy 78.71
2024-09-08 10:41:48,798 [foster.py] => SNet: Task 1, Epoch 67/130 => Loss 27.330,  Loss1 0.688, Train_accy 70.57
2024-09-08 10:41:53,735 [foster.py] => SNet: Task 1, Epoch 68/130 => Loss 27.312,  Loss1 0.688, Train_accy 69.09
2024-09-08 10:41:58,631 [foster.py] => SNet: Task 1, Epoch 69/130 => Loss 27.311,  Loss1 0.688, Train_accy 70.71
2024-09-08 10:42:03,535 [foster.py] => SNet: Task 1, Epoch 70/130 => Loss 27.331,  Loss1 0.688, Train_accy 69.49
2024-09-08 10:42:09,400 [foster.py] => SNet: Task 1, Epoch 71/130 => Loss 27.359,  Loss1 0.688, Train_accy 69.94, Test_accy 78.76
2024-09-08 10:42:14,400 [foster.py] => SNet: Task 1, Epoch 72/130 => Loss 27.330,  Loss1 0.688, Train_accy 69.11
2024-09-08 10:42:19,292 [foster.py] => SNet: Task 1, Epoch 73/130 => Loss 27.315,  Loss1 0.688, Train_accy 69.54
2024-09-08 10:42:24,218 [foster.py] => SNet: Task 1, Epoch 74/130 => Loss 27.298,  Loss1 0.688, Train_accy 70.37
2024-09-08 10:42:29,137 [foster.py] => SNet: Task 1, Epoch 75/130 => Loss 27.321,  Loss1 0.688, Train_accy 69.89
2024-09-08 10:42:34,991 [foster.py] => SNet: Task 1, Epoch 76/130 => Loss 27.306,  Loss1 0.688, Train_accy 69.63, Test_accy 78.76
2024-09-08 10:42:39,916 [foster.py] => SNet: Task 1, Epoch 77/130 => Loss 27.317,  Loss1 0.689, Train_accy 69.71
2024-09-08 10:42:44,824 [foster.py] => SNet: Task 1, Epoch 78/130 => Loss 27.305,  Loss1 0.688, Train_accy 70.57
2024-09-08 10:42:49,744 [foster.py] => SNet: Task 1, Epoch 79/130 => Loss 27.313,  Loss1 0.688, Train_accy 70.11
2024-09-08 10:42:54,693 [foster.py] => SNet: Task 1, Epoch 80/130 => Loss 27.301,  Loss1 0.688, Train_accy 69.86
2024-09-08 10:43:00,544 [foster.py] => SNet: Task 1, Epoch 81/130 => Loss 27.240,  Loss1 0.688, Train_accy 69.60, Test_accy 78.67
2024-09-08 10:43:05,479 [foster.py] => SNet: Task 1, Epoch 82/130 => Loss 27.342,  Loss1 0.688, Train_accy 69.74
2024-09-08 10:43:10,453 [foster.py] => SNet: Task 1, Epoch 83/130 => Loss 27.296,  Loss1 0.688, Train_accy 71.23
2024-09-08 10:43:15,360 [foster.py] => SNet: Task 1, Epoch 84/130 => Loss 27.316,  Loss1 0.688, Train_accy 69.57
2024-09-08 10:43:20,368 [foster.py] => SNet: Task 1, Epoch 85/130 => Loss 27.326,  Loss1 0.688, Train_accy 70.37
2024-09-08 10:43:26,191 [foster.py] => SNet: Task 1, Epoch 86/130 => Loss 27.306,  Loss1 0.688, Train_accy 70.31, Test_accy 78.73
2024-09-08 10:43:31,093 [foster.py] => SNet: Task 1, Epoch 87/130 => Loss 27.320,  Loss1 0.688, Train_accy 69.17
2024-09-08 10:43:35,997 [foster.py] => SNet: Task 1, Epoch 88/130 => Loss 27.368,  Loss1 0.688, Train_accy 71.11
2024-09-08 10:43:40,951 [foster.py] => SNet: Task 1, Epoch 89/130 => Loss 27.308,  Loss1 0.688, Train_accy 69.17
2024-09-08 10:43:45,950 [foster.py] => SNet: Task 1, Epoch 90/130 => Loss 27.287,  Loss1 0.688, Train_accy 70.43
2024-09-08 10:43:51,784 [foster.py] => SNet: Task 1, Epoch 91/130 => Loss 27.332,  Loss1 0.688, Train_accy 70.00, Test_accy 79.07
2024-09-08 10:43:56,684 [foster.py] => SNet: Task 1, Epoch 92/130 => Loss 27.365,  Loss1 0.688, Train_accy 69.40
2024-09-08 10:44:01,631 [foster.py] => SNet: Task 1, Epoch 93/130 => Loss 27.300,  Loss1 0.688, Train_accy 71.40
2024-09-08 10:44:06,541 [foster.py] => SNet: Task 1, Epoch 94/130 => Loss 27.304,  Loss1 0.688, Train_accy 69.94
2024-09-08 10:44:11,434 [foster.py] => SNet: Task 1, Epoch 95/130 => Loss 27.360,  Loss1 0.688, Train_accy 71.31
2024-09-08 10:44:17,289 [foster.py] => SNet: Task 1, Epoch 96/130 => Loss 27.315,  Loss1 0.688, Train_accy 70.03, Test_accy 79.05
2024-09-08 10:44:22,215 [foster.py] => SNet: Task 1, Epoch 97/130 => Loss 27.279,  Loss1 0.688, Train_accy 69.34
2024-09-08 10:44:27,164 [foster.py] => SNet: Task 1, Epoch 98/130 => Loss 27.285,  Loss1 0.688, Train_accy 69.43
2024-09-08 10:44:32,152 [foster.py] => SNet: Task 1, Epoch 99/130 => Loss 27.322,  Loss1 0.688, Train_accy 68.97
2024-09-08 10:44:37,032 [foster.py] => SNet: Task 1, Epoch 100/130 => Loss 27.339,  Loss1 0.688, Train_accy 71.06
2024-09-08 10:44:42,864 [foster.py] => SNet: Task 1, Epoch 101/130 => Loss 27.351,  Loss1 0.688, Train_accy 69.31, Test_accy 78.84
2024-09-08 10:44:47,803 [foster.py] => SNet: Task 1, Epoch 102/130 => Loss 27.261,  Loss1 0.688, Train_accy 71.03
2024-09-08 10:44:52,719 [foster.py] => SNet: Task 1, Epoch 103/130 => Loss 27.299,  Loss1 0.688, Train_accy 70.14
2024-09-08 10:44:57,609 [foster.py] => SNet: Task 1, Epoch 104/130 => Loss 27.302,  Loss1 0.688, Train_accy 70.46
2024-09-08 10:45:02,521 [foster.py] => SNet: Task 1, Epoch 105/130 => Loss 27.319,  Loss1 0.688, Train_accy 69.49
2024-09-08 10:45:08,372 [foster.py] => SNet: Task 1, Epoch 106/130 => Loss 27.346,  Loss1 0.688, Train_accy 69.49, Test_accy 78.98
2024-09-08 10:45:13,293 [foster.py] => SNet: Task 1, Epoch 107/130 => Loss 27.360,  Loss1 0.688, Train_accy 70.06
2024-09-08 10:45:18,233 [foster.py] => SNet: Task 1, Epoch 108/130 => Loss 27.313,  Loss1 0.688, Train_accy 70.06
2024-09-08 10:45:23,148 [foster.py] => SNet: Task 1, Epoch 109/130 => Loss 27.328,  Loss1 0.688, Train_accy 71.09
2024-09-08 10:45:28,032 [foster.py] => SNet: Task 1, Epoch 110/130 => Loss 27.319,  Loss1 0.688, Train_accy 70.29
2024-09-08 10:45:33,851 [foster.py] => SNet: Task 1, Epoch 111/130 => Loss 27.304,  Loss1 0.688, Train_accy 69.89, Test_accy 78.91
2024-09-08 10:45:38,779 [foster.py] => SNet: Task 1, Epoch 112/130 => Loss 27.296,  Loss1 0.688, Train_accy 71.11
2024-09-08 10:45:43,753 [foster.py] => SNet: Task 1, Epoch 113/130 => Loss 27.300,  Loss1 0.689, Train_accy 71.43
2024-09-08 10:45:48,658 [foster.py] => SNet: Task 1, Epoch 114/130 => Loss 27.320,  Loss1 0.688, Train_accy 69.46
2024-09-08 10:45:53,589 [foster.py] => SNet: Task 1, Epoch 115/130 => Loss 27.312,  Loss1 0.688, Train_accy 70.37
2024-09-08 10:45:59,439 [foster.py] => SNet: Task 1, Epoch 116/130 => Loss 27.299,  Loss1 0.688, Train_accy 69.80, Test_accy 78.96
2024-09-08 10:46:04,345 [foster.py] => SNet: Task 1, Epoch 117/130 => Loss 27.322,  Loss1 0.688, Train_accy 70.29
2024-09-08 10:46:09,289 [foster.py] => SNet: Task 1, Epoch 118/130 => Loss 27.286,  Loss1 0.688, Train_accy 71.34
2024-09-08 10:46:14,186 [foster.py] => SNet: Task 1, Epoch 119/130 => Loss 27.325,  Loss1 0.688, Train_accy 69.77
2024-09-08 10:46:19,133 [foster.py] => SNet: Task 1, Epoch 120/130 => Loss 27.299,  Loss1 0.688, Train_accy 70.03
2024-09-08 10:46:25,000 [foster.py] => SNet: Task 1, Epoch 121/130 => Loss 27.279,  Loss1 0.688, Train_accy 70.69, Test_accy 79.11
2024-09-08 10:46:29,950 [foster.py] => SNet: Task 1, Epoch 122/130 => Loss 27.334,  Loss1 0.688, Train_accy 70.40
2024-09-08 10:46:34,876 [foster.py] => SNet: Task 1, Epoch 123/130 => Loss 27.323,  Loss1 0.688, Train_accy 70.80
2024-09-08 10:46:39,812 [foster.py] => SNet: Task 1, Epoch 124/130 => Loss 27.330,  Loss1 0.688, Train_accy 70.20
2024-09-08 10:46:44,732 [foster.py] => SNet: Task 1, Epoch 125/130 => Loss 27.307,  Loss1 0.688, Train_accy 70.03
2024-09-08 10:46:50,569 [foster.py] => SNet: Task 1, Epoch 126/130 => Loss 27.305,  Loss1 0.688, Train_accy 69.26, Test_accy 79.07
2024-09-08 10:46:55,531 [foster.py] => SNet: Task 1, Epoch 127/130 => Loss 27.308,  Loss1 0.688, Train_accy 70.51
2024-09-08 10:47:00,468 [foster.py] => SNet: Task 1, Epoch 128/130 => Loss 27.321,  Loss1 0.688, Train_accy 71.14
2024-09-08 10:47:05,396 [foster.py] => SNet: Task 1, Epoch 129/130 => Loss 27.313,  Loss1 0.688, Train_accy 70.31
2024-09-08 10:47:10,307 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 27.317,  Loss1 0.688, Train_accy 70.09
2024-09-08 10:47:10,308 [foster.py] => do not weight align student!
2024-09-08 10:47:11,213 [foster.py] => darknet eval: 
2024-09-08 10:47:11,214 [foster.py] => CNN top1 curve: 79.04
2024-09-08 10:47:11,214 [foster.py] => CNN top5 curve: 96.62
2024-09-08 10:47:11,215 [foster.py] => CNN top1 平均值: 79.04
2024-09-08 10:47:11,218 [foster.py] => timees : 1453.2340185642242
2024-09-08 10:47:11,219 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 10:47:29,297 [foster.py] => Exemplar size: 1100
2024-09-08 10:47:29,297 [trainer.py] => CNN: {'total': 79.8, '00-09': 84.6, '10-19': 76.6, '20-29': 82.2, '30-39': 77.1, '40-49': 79.4, '50-59': 78.0, 'old': 79.98, 'new': 78.0}
2024-09-08 10:47:29,298 [trainer.py] => NME: {'total': 75.13, '00-09': 77.5, '10-19': 74.0, '20-29': 77.8, '30-39': 72.5, '40-49': 66.4, '50-59': 90.0, 'old': 73.64, 'new': 90.0}
2024-09-08 10:47:29,298 [trainer.py] => CNN top1 curve: [81.66, 79.8]
2024-09-08 10:47:29,298 [trainer.py] => CNN top5 curve: [97.02, 96.93]
2024-09-08 10:47:29,298 [trainer.py] => NME top1 curve: [80.72, 75.13]
2024-09-08 10:47:29,299 [trainer.py] => NME top5 curve: [96.8, 95.58]

2024-09-08 10:47:29,299 [trainer.py] => CNN top1 平均值: 80.73
2024-09-08 10:47:29,302 [trainer.py] => All params: 1168468
2024-09-08 10:47:29,304 [trainer.py] => Trainable params: 587944
2024-09-08 10:47:29,364 [foster.py] => Learning on 55-60
2024-09-08 10:47:29,367 [foster.py] => All params: 1169763
2024-09-08 10:47:29,369 [foster.py] => Trainable params: 588914
2024-09-08 10:47:29,416 [foster.py] => per cls weights : [1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019 1.03363019
 1.03363019 0.63006789 0.63006789 0.63006789 0.63006789 0.63006789]
2024-09-08 10:47:33,216 [foster.py] => Task 2, Epoch 1/170 => Loss 6.783, Loss_clf 2.013, Loss_fe 2.001, Loss_kd 2.537, Train_accy 44.64
2024-09-08 10:47:38,378 [foster.py] => Task 2, Epoch 2/170 => Loss 5.353, Loss_clf 1.328, Loss_fe 1.273, Loss_kd 2.522, Train_accy 51.92, Test_accy 75.10
2024-09-08 10:47:43,529 [foster.py] => Task 2, Epoch 3/170 => Loss 5.087, Loss_clf 1.150, Loss_fe 1.183, Loss_kd 2.524, Train_accy 54.19, Test_accy 75.78
2024-09-08 10:47:48,741 [foster.py] => Task 2, Epoch 4/170 => Loss 5.058, Loss_clf 1.164, Loss_fe 1.147, Loss_kd 2.517, Train_accy 56.08, Test_accy 75.85
2024-09-08 10:47:53,878 [foster.py] => Task 2, Epoch 5/170 => Loss 4.969, Loss_clf 1.139, Loss_fe 1.090, Loss_kd 2.511, Train_accy 57.00, Test_accy 75.78
2024-09-08 10:47:57,548 [foster.py] => Task 2, Epoch 6/170 => Loss 4.906, Loss_clf 1.077, Loss_fe 1.100, Loss_kd 2.501, Train_accy 56.78
2024-09-08 10:48:02,671 [foster.py] => Task 2, Epoch 7/170 => Loss 4.878, Loss_clf 1.083, Loss_fe 1.057, Loss_kd 2.508, Train_accy 57.69, Test_accy 75.13
2024-09-08 10:48:07,824 [foster.py] => Task 2, Epoch 8/170 => Loss 4.888, Loss_clf 1.096, Loss_fe 1.062, Loss_kd 2.501, Train_accy 59.03, Test_accy 74.90
2024-09-08 10:48:12,945 [foster.py] => Task 2, Epoch 9/170 => Loss 4.744, Loss_clf 0.995, Loss_fe 1.012, Loss_kd 2.507, Train_accy 59.78, Test_accy 75.97
2024-09-08 10:48:18,224 [foster.py] => Task 2, Epoch 10/170 => Loss 4.685, Loss_clf 0.996, Loss_fe 0.958, Loss_kd 2.502, Train_accy 60.81, Test_accy 76.32
2024-09-08 10:48:21,825 [foster.py] => Task 2, Epoch 11/170 => Loss 4.666, Loss_clf 0.976, Loss_fe 0.962, Loss_kd 2.499, Train_accy 62.08
2024-09-08 10:48:26,906 [foster.py] => Task 2, Epoch 12/170 => Loss 4.578, Loss_clf 0.930, Loss_fe 0.917, Loss_kd 2.502, Train_accy 63.64, Test_accy 75.97
2024-09-08 10:48:32,017 [foster.py] => Task 2, Epoch 13/170 => Loss 4.598, Loss_clf 0.950, Loss_fe 0.914, Loss_kd 2.505, Train_accy 63.00, Test_accy 76.53
2024-09-08 10:48:37,189 [foster.py] => Task 2, Epoch 14/170 => Loss 4.602, Loss_clf 0.937, Loss_fe 0.925, Loss_kd 2.511, Train_accy 62.58, Test_accy 74.70
2024-09-08 10:48:42,276 [foster.py] => Task 2, Epoch 15/170 => Loss 4.695, Loss_clf 0.993, Loss_fe 0.961, Loss_kd 2.511, Train_accy 61.22, Test_accy 76.13
2024-09-08 10:48:45,880 [foster.py] => Task 2, Epoch 16/170 => Loss 4.576, Loss_clf 0.939, Loss_fe 0.904, Loss_kd 2.504, Train_accy 62.06
2024-09-08 10:48:51,020 [foster.py] => Task 2, Epoch 17/170 => Loss 4.502, Loss_clf 0.908, Loss_fe 0.849, Loss_kd 2.514, Train_accy 62.64, Test_accy 76.10
2024-09-08 10:48:56,176 [foster.py] => Task 2, Epoch 18/170 => Loss 4.493, Loss_clf 0.887, Loss_fe 0.852, Loss_kd 2.523, Train_accy 66.14, Test_accy 76.45
2024-09-08 10:49:01,293 [foster.py] => Task 2, Epoch 19/170 => Loss 4.554, Loss_clf 0.934, Loss_fe 0.903, Loss_kd 2.489, Train_accy 62.72, Test_accy 75.83
2024-09-08 10:49:06,515 [foster.py] => Task 2, Epoch 20/170 => Loss 4.593, Loss_clf 0.945, Loss_fe 0.910, Loss_kd 2.508, Train_accy 63.11, Test_accy 76.32
2024-09-08 10:49:10,255 [foster.py] => Task 2, Epoch 21/170 => Loss 4.483, Loss_clf 0.863, Loss_fe 0.880, Loss_kd 2.510, Train_accy 65.08
2024-09-08 10:49:15,331 [foster.py] => Task 2, Epoch 22/170 => Loss 4.450, Loss_clf 0.891, Loss_fe 0.823, Loss_kd 2.506, Train_accy 64.08, Test_accy 76.53
2024-09-08 10:49:20,438 [foster.py] => Task 2, Epoch 23/170 => Loss 4.404, Loss_clf 0.892, Loss_fe 0.782, Loss_kd 2.500, Train_accy 66.03, Test_accy 76.60
2024-09-08 10:49:25,530 [foster.py] => Task 2, Epoch 24/170 => Loss 4.487, Loss_clf 0.951, Loss_fe 0.810, Loss_kd 2.497, Train_accy 65.83, Test_accy 76.83
2024-09-08 10:49:30,663 [foster.py] => Task 2, Epoch 25/170 => Loss 4.471, Loss_clf 0.895, Loss_fe 0.831, Loss_kd 2.514, Train_accy 65.94, Test_accy 76.70
2024-09-08 10:49:34,353 [foster.py] => Task 2, Epoch 26/170 => Loss 4.452, Loss_clf 0.895, Loss_fe 0.821, Loss_kd 2.507, Train_accy 65.56
2024-09-08 10:49:39,391 [foster.py] => Task 2, Epoch 27/170 => Loss 4.413, Loss_clf 0.850, Loss_fe 0.829, Loss_kd 2.504, Train_accy 66.81, Test_accy 76.70
2024-09-08 10:49:44,553 [foster.py] => Task 2, Epoch 28/170 => Loss 4.481, Loss_clf 0.902, Loss_fe 0.820, Loss_kd 2.528, Train_accy 66.75, Test_accy 77.10
2024-09-08 10:49:49,612 [foster.py] => Task 2, Epoch 29/170 => Loss 4.470, Loss_clf 0.892, Loss_fe 0.820, Loss_kd 2.527, Train_accy 64.92, Test_accy 77.05
2024-09-08 10:49:54,690 [foster.py] => Task 2, Epoch 30/170 => Loss 4.327, Loss_clf 0.812, Loss_fe 0.767, Loss_kd 2.518, Train_accy 66.89, Test_accy 76.55
2024-09-08 10:49:58,391 [foster.py] => Task 2, Epoch 31/170 => Loss 4.341, Loss_clf 0.849, Loss_fe 0.749, Loss_kd 2.513, Train_accy 66.31
2024-09-08 10:50:03,606 [foster.py] => Task 2, Epoch 32/170 => Loss 4.255, Loss_clf 0.780, Loss_fe 0.738, Loss_kd 2.507, Train_accy 70.22, Test_accy 77.52
2024-09-08 10:50:08,673 [foster.py] => Task 2, Epoch 33/170 => Loss 4.447, Loss_clf 0.878, Loss_fe 0.817, Loss_kd 2.521, Train_accy 67.50, Test_accy 77.37
2024-09-08 10:50:13,760 [foster.py] => Task 2, Epoch 34/170 => Loss 4.315, Loss_clf 0.800, Loss_fe 0.773, Loss_kd 2.512, Train_accy 67.36, Test_accy 77.12
2024-09-08 10:50:18,864 [foster.py] => Task 2, Epoch 35/170 => Loss 4.331, Loss_clf 0.822, Loss_fe 0.759, Loss_kd 2.520, Train_accy 67.92, Test_accy 77.03
2024-09-08 10:50:22,491 [foster.py] => Task 2, Epoch 36/170 => Loss 4.352, Loss_clf 0.834, Loss_fe 0.786, Loss_kd 2.502, Train_accy 66.75
2024-09-08 10:50:27,628 [foster.py] => Task 2, Epoch 37/170 => Loss 4.276, Loss_clf 0.803, Loss_fe 0.726, Loss_kd 2.517, Train_accy 67.36, Test_accy 77.13
2024-09-08 10:50:32,722 [foster.py] => Task 2, Epoch 38/170 => Loss 4.204, Loss_clf 0.769, Loss_fe 0.708, Loss_kd 2.499, Train_accy 68.81, Test_accy 77.52
2024-09-08 10:50:37,981 [foster.py] => Task 2, Epoch 39/170 => Loss 4.323, Loss_clf 0.827, Loss_fe 0.762, Loss_kd 2.504, Train_accy 67.94, Test_accy 77.10
2024-09-08 10:50:43,118 [foster.py] => Task 2, Epoch 40/170 => Loss 4.286, Loss_clf 0.800, Loss_fe 0.755, Loss_kd 2.502, Train_accy 67.00, Test_accy 76.77
2024-09-08 10:50:46,794 [foster.py] => Task 2, Epoch 41/170 => Loss 4.206, Loss_clf 0.767, Loss_fe 0.705, Loss_kd 2.505, Train_accy 69.78
2024-09-08 10:50:51,982 [foster.py] => Task 2, Epoch 42/170 => Loss 4.237, Loss_clf 0.779, Loss_fe 0.715, Loss_kd 2.513, Train_accy 69.64, Test_accy 76.55
2024-09-08 10:50:57,140 [foster.py] => Task 2, Epoch 43/170 => Loss 4.388, Loss_clf 0.855, Loss_fe 0.776, Loss_kd 2.526, Train_accy 67.67, Test_accy 76.70
2024-09-08 10:51:02,266 [foster.py] => Task 2, Epoch 44/170 => Loss 4.217, Loss_clf 0.760, Loss_fe 0.722, Loss_kd 2.505, Train_accy 69.92, Test_accy 77.53
2024-09-08 10:51:07,334 [foster.py] => Task 2, Epoch 45/170 => Loss 4.179, Loss_clf 0.753, Loss_fe 0.701, Loss_kd 2.497, Train_accy 71.44, Test_accy 77.43
2024-09-08 10:51:10,950 [foster.py] => Task 2, Epoch 46/170 => Loss 4.288, Loss_clf 0.812, Loss_fe 0.729, Loss_kd 2.516, Train_accy 67.58
2024-09-08 10:51:16,042 [foster.py] => Task 2, Epoch 47/170 => Loss 4.234, Loss_clf 0.780, Loss_fe 0.705, Loss_kd 2.518, Train_accy 70.28, Test_accy 77.38
2024-09-08 10:51:21,238 [foster.py] => Task 2, Epoch 48/170 => Loss 4.072, Loss_clf 0.699, Loss_fe 0.646, Loss_kd 2.498, Train_accy 71.81, Test_accy 77.80
2024-09-08 10:51:26,365 [foster.py] => Task 2, Epoch 49/170 => Loss 4.187, Loss_clf 0.745, Loss_fe 0.689, Loss_kd 2.522, Train_accy 70.58, Test_accy 77.72
2024-09-08 10:51:31,552 [foster.py] => Task 2, Epoch 50/170 => Loss 4.159, Loss_clf 0.729, Loss_fe 0.684, Loss_kd 2.515, Train_accy 71.11, Test_accy 77.15
2024-09-08 10:51:35,205 [foster.py] => Task 2, Epoch 51/170 => Loss 4.055, Loss_clf 0.680, Loss_fe 0.643, Loss_kd 2.503, Train_accy 71.97
2024-09-08 10:51:40,397 [foster.py] => Task 2, Epoch 52/170 => Loss 4.037, Loss_clf 0.674, Loss_fe 0.616, Loss_kd 2.517, Train_accy 73.58, Test_accy 76.98
2024-09-08 10:51:45,616 [foster.py] => Task 2, Epoch 53/170 => Loss 4.052, Loss_clf 0.681, Loss_fe 0.617, Loss_kd 2.523, Train_accy 72.83, Test_accy 77.07
2024-09-08 10:51:50,741 [foster.py] => Task 2, Epoch 54/170 => Loss 4.083, Loss_clf 0.726, Loss_fe 0.641, Loss_kd 2.488, Train_accy 71.39, Test_accy 75.87
2024-09-08 10:51:55,851 [foster.py] => Task 2, Epoch 55/170 => Loss 4.178, Loss_clf 0.759, Loss_fe 0.670, Loss_kd 2.518, Train_accy 71.81, Test_accy 76.78
2024-09-08 10:51:59,585 [foster.py] => Task 2, Epoch 56/170 => Loss 4.205, Loss_clf 0.763, Loss_fe 0.717, Loss_kd 2.496, Train_accy 69.33
2024-09-08 10:52:04,831 [foster.py] => Task 2, Epoch 57/170 => Loss 4.102, Loss_clf 0.723, Loss_fe 0.638, Loss_kd 2.511, Train_accy 70.56, Test_accy 76.92
2024-09-08 10:52:09,990 [foster.py] => Task 2, Epoch 58/170 => Loss 4.060, Loss_clf 0.681, Loss_fe 0.636, Loss_kd 2.514, Train_accy 72.75, Test_accy 77.77
2024-09-08 10:52:15,054 [foster.py] => Task 2, Epoch 59/170 => Loss 4.084, Loss_clf 0.711, Loss_fe 0.634, Loss_kd 2.509, Train_accy 72.67, Test_accy 77.87
2024-09-08 10:52:20,186 [foster.py] => Task 2, Epoch 60/170 => Loss 4.085, Loss_clf 0.705, Loss_fe 0.624, Loss_kd 2.525, Train_accy 72.17, Test_accy 77.75
2024-09-08 10:52:23,783 [foster.py] => Task 2, Epoch 61/170 => Loss 3.987, Loss_clf 0.654, Loss_fe 0.602, Loss_kd 2.501, Train_accy 74.11
2024-09-08 10:52:28,867 [foster.py] => Task 2, Epoch 62/170 => Loss 3.981, Loss_clf 0.659, Loss_fe 0.586, Loss_kd 2.507, Train_accy 73.31, Test_accy 76.93
2024-09-08 10:52:33,966 [foster.py] => Task 2, Epoch 63/170 => Loss 4.000, Loss_clf 0.668, Loss_fe 0.589, Loss_kd 2.512, Train_accy 73.69, Test_accy 77.42
2024-09-08 10:52:39,100 [foster.py] => Task 2, Epoch 64/170 => Loss 4.033, Loss_clf 0.703, Loss_fe 0.595, Loss_kd 2.506, Train_accy 73.58, Test_accy 77.40
2024-09-08 10:52:44,201 [foster.py] => Task 2, Epoch 65/170 => Loss 4.061, Loss_clf 0.699, Loss_fe 0.604, Loss_kd 2.527, Train_accy 73.75, Test_accy 77.88
2024-09-08 10:52:47,805 [foster.py] => Task 2, Epoch 66/170 => Loss 4.038, Loss_clf 0.695, Loss_fe 0.596, Loss_kd 2.516, Train_accy 72.58
2024-09-08 10:52:52,885 [foster.py] => Task 2, Epoch 67/170 => Loss 3.991, Loss_clf 0.678, Loss_fe 0.577, Loss_kd 2.506, Train_accy 73.69, Test_accy 77.62
2024-09-08 10:52:58,012 [foster.py] => Task 2, Epoch 68/170 => Loss 3.916, Loss_clf 0.628, Loss_fe 0.552, Loss_kd 2.507, Train_accy 74.61, Test_accy 77.20
2024-09-08 10:53:03,087 [foster.py] => Task 2, Epoch 69/170 => Loss 3.975, Loss_clf 0.658, Loss_fe 0.568, Loss_kd 2.519, Train_accy 73.92, Test_accy 77.72
2024-09-08 10:53:08,198 [foster.py] => Task 2, Epoch 70/170 => Loss 4.017, Loss_clf 0.681, Loss_fe 0.590, Loss_kd 2.516, Train_accy 73.72, Test_accy 77.60
2024-09-08 10:53:11,805 [foster.py] => Task 2, Epoch 71/170 => Loss 3.928, Loss_clf 0.646, Loss_fe 0.557, Loss_kd 2.497, Train_accy 73.97
2024-09-08 10:53:17,016 [foster.py] => Task 2, Epoch 72/170 => Loss 4.001, Loss_clf 0.680, Loss_fe 0.586, Loss_kd 2.506, Train_accy 74.00, Test_accy 77.25
2024-09-08 10:53:22,098 [foster.py] => Task 2, Epoch 73/170 => Loss 3.943, Loss_clf 0.659, Loss_fe 0.548, Loss_kd 2.507, Train_accy 74.36, Test_accy 77.42
2024-09-08 10:53:27,275 [foster.py] => Task 2, Epoch 74/170 => Loss 3.873, Loss_clf 0.621, Loss_fe 0.520, Loss_kd 2.503, Train_accy 75.97, Test_accy 76.98
2024-09-08 10:53:32,371 [foster.py] => Task 2, Epoch 75/170 => Loss 3.872, Loss_clf 0.631, Loss_fe 0.532, Loss_kd 2.482, Train_accy 74.67, Test_accy 77.63
2024-09-08 10:53:36,001 [foster.py] => Task 2, Epoch 76/170 => Loss 3.841, Loss_clf 0.618, Loss_fe 0.511, Loss_kd 2.484, Train_accy 75.11
2024-09-08 10:53:41,085 [foster.py] => Task 2, Epoch 77/170 => Loss 3.896, Loss_clf 0.631, Loss_fe 0.524, Loss_kd 2.511, Train_accy 76.64, Test_accy 77.53
2024-09-08 10:53:46,191 [foster.py] => Task 2, Epoch 78/170 => Loss 3.969, Loss_clf 0.664, Loss_fe 0.579, Loss_kd 2.498, Train_accy 75.17, Test_accy 77.77
2024-09-08 10:53:51,308 [foster.py] => Task 2, Epoch 79/170 => Loss 3.979, Loss_clf 0.673, Loss_fe 0.569, Loss_kd 2.508, Train_accy 74.19, Test_accy 77.47
2024-09-08 10:53:56,445 [foster.py] => Task 2, Epoch 80/170 => Loss 3.965, Loss_clf 0.651, Loss_fe 0.566, Loss_kd 2.518, Train_accy 73.86, Test_accy 77.42
2024-09-08 10:54:00,065 [foster.py] => Task 2, Epoch 81/170 => Loss 3.898, Loss_clf 0.634, Loss_fe 0.525, Loss_kd 2.510, Train_accy 74.89
2024-09-08 10:54:05,219 [foster.py] => Task 2, Epoch 82/170 => Loss 3.898, Loss_clf 0.622, Loss_fe 0.531, Loss_kd 2.515, Train_accy 75.28, Test_accy 77.87
2024-09-08 10:54:10,327 [foster.py] => Task 2, Epoch 83/170 => Loss 3.858, Loss_clf 0.607, Loss_fe 0.525, Loss_kd 2.497, Train_accy 75.22, Test_accy 77.95
2024-09-08 10:54:15,500 [foster.py] => Task 2, Epoch 84/170 => Loss 3.785, Loss_clf 0.573, Loss_fe 0.483, Loss_kd 2.499, Train_accy 77.08, Test_accy 78.07
2024-09-08 10:54:20,621 [foster.py] => Task 2, Epoch 85/170 => Loss 3.849, Loss_clf 0.604, Loss_fe 0.505, Loss_kd 2.510, Train_accy 77.08, Test_accy 77.72
2024-09-08 10:54:24,281 [foster.py] => Task 2, Epoch 86/170 => Loss 3.866, Loss_clf 0.617, Loss_fe 0.517, Loss_kd 2.503, Train_accy 76.78
2024-09-08 10:54:29,478 [foster.py] => Task 2, Epoch 87/170 => Loss 3.861, Loss_clf 0.599, Loss_fe 0.514, Loss_kd 2.517, Train_accy 75.28, Test_accy 77.62
2024-09-08 10:54:34,727 [foster.py] => Task 2, Epoch 88/170 => Loss 3.855, Loss_clf 0.600, Loss_fe 0.500, Loss_kd 2.524, Train_accy 77.03, Test_accy 77.83
2024-09-08 10:54:39,838 [foster.py] => Task 2, Epoch 89/170 => Loss 3.788, Loss_clf 0.576, Loss_fe 0.459, Loss_kd 2.521, Train_accy 77.81, Test_accy 78.48
2024-09-08 10:54:45,080 [foster.py] => Task 2, Epoch 90/170 => Loss 3.709, Loss_clf 0.540, Loss_fe 0.444, Loss_kd 2.496, Train_accy 77.78, Test_accy 78.02
2024-09-08 10:54:48,714 [foster.py] => Task 2, Epoch 91/170 => Loss 3.796, Loss_clf 0.578, Loss_fe 0.468, Loss_kd 2.520, Train_accy 77.75
2024-09-08 10:54:53,836 [foster.py] => Task 2, Epoch 92/170 => Loss 3.870, Loss_clf 0.614, Loss_fe 0.500, Loss_kd 2.525, Train_accy 77.39, Test_accy 77.53
2024-09-08 10:54:58,953 [foster.py] => Task 2, Epoch 93/170 => Loss 3.874, Loss_clf 0.615, Loss_fe 0.504, Loss_kd 2.523, Train_accy 77.00, Test_accy 77.52
2024-09-08 10:55:04,080 [foster.py] => Task 2, Epoch 94/170 => Loss 3.748, Loss_clf 0.555, Loss_fe 0.453, Loss_kd 2.509, Train_accy 78.19, Test_accy 77.63
2024-09-08 10:55:09,232 [foster.py] => Task 2, Epoch 95/170 => Loss 3.740, Loss_clf 0.559, Loss_fe 0.447, Loss_kd 2.505, Train_accy 77.58, Test_accy 77.82
2024-09-08 10:55:12,860 [foster.py] => Task 2, Epoch 96/170 => Loss 3.692, Loss_clf 0.530, Loss_fe 0.416, Loss_kd 2.515, Train_accy 77.89
2024-09-08 10:55:18,000 [foster.py] => Task 2, Epoch 97/170 => Loss 3.682, Loss_clf 0.521, Loss_fe 0.427, Loss_kd 2.505, Train_accy 80.06, Test_accy 77.68
2024-09-08 10:55:23,081 [foster.py] => Task 2, Epoch 98/170 => Loss 3.781, Loss_clf 0.572, Loss_fe 0.445, Loss_kd 2.532, Train_accy 77.25, Test_accy 78.08
2024-09-08 10:55:28,149 [foster.py] => Task 2, Epoch 99/170 => Loss 3.715, Loss_clf 0.538, Loss_fe 0.440, Loss_kd 2.507, Train_accy 78.39, Test_accy 78.20
2024-09-08 10:55:33,221 [foster.py] => Task 2, Epoch 100/170 => Loss 3.726, Loss_clf 0.546, Loss_fe 0.443, Loss_kd 2.508, Train_accy 78.72, Test_accy 77.87
2024-09-08 10:55:36,830 [foster.py] => Task 2, Epoch 101/170 => Loss 3.630, Loss_clf 0.508, Loss_fe 0.396, Loss_kd 2.497, Train_accy 79.11
2024-09-08 10:55:41,933 [foster.py] => Task 2, Epoch 102/170 => Loss 3.703, Loss_clf 0.528, Loss_fe 0.423, Loss_kd 2.521, Train_accy 79.58, Test_accy 78.12
2024-09-08 10:55:47,107 [foster.py] => Task 2, Epoch 103/170 => Loss 3.664, Loss_clf 0.515, Loss_fe 0.430, Loss_kd 2.491, Train_accy 79.19, Test_accy 77.27
2024-09-08 10:55:52,267 [foster.py] => Task 2, Epoch 104/170 => Loss 3.760, Loss_clf 0.569, Loss_fe 0.453, Loss_kd 2.508, Train_accy 78.17, Test_accy 77.98
2024-09-08 10:55:57,439 [foster.py] => Task 2, Epoch 105/170 => Loss 3.792, Loss_clf 0.588, Loss_fe 0.468, Loss_kd 2.506, Train_accy 78.08, Test_accy 77.87
2024-09-08 10:56:01,150 [foster.py] => Task 2, Epoch 106/170 => Loss 3.756, Loss_clf 0.554, Loss_fe 0.440, Loss_kd 2.531, Train_accy 78.81
2024-09-08 10:56:06,285 [foster.py] => Task 2, Epoch 107/170 => Loss 3.656, Loss_clf 0.512, Loss_fe 0.404, Loss_kd 2.511, Train_accy 80.28, Test_accy 77.28
2024-09-08 10:56:11,359 [foster.py] => Task 2, Epoch 108/170 => Loss 3.627, Loss_clf 0.510, Loss_fe 0.392, Loss_kd 2.496, Train_accy 79.67, Test_accy 77.93
2024-09-08 10:56:16,516 [foster.py] => Task 2, Epoch 109/170 => Loss 3.612, Loss_clf 0.490, Loss_fe 0.387, Loss_kd 2.506, Train_accy 81.36, Test_accy 78.17
2024-09-08 10:56:21,578 [foster.py] => Task 2, Epoch 110/170 => Loss 3.625, Loss_clf 0.502, Loss_fe 0.401, Loss_kd 2.494, Train_accy 80.31, Test_accy 77.92
2024-09-08 10:56:25,259 [foster.py] => Task 2, Epoch 111/170 => Loss 3.651, Loss_clf 0.509, Loss_fe 0.398, Loss_kd 2.513, Train_accy 81.11
2024-09-08 10:56:30,467 [foster.py] => Task 2, Epoch 112/170 => Loss 3.604, Loss_clf 0.497, Loss_fe 0.387, Loss_kd 2.492, Train_accy 79.36, Test_accy 78.47
2024-09-08 10:56:35,571 [foster.py] => Task 2, Epoch 113/170 => Loss 3.649, Loss_clf 0.506, Loss_fe 0.388, Loss_kd 2.524, Train_accy 79.83, Test_accy 77.95
2024-09-08 10:56:40,661 [foster.py] => Task 2, Epoch 114/170 => Loss 3.659, Loss_clf 0.520, Loss_fe 0.385, Loss_kd 2.523, Train_accy 79.39, Test_accy 78.25
2024-09-08 10:56:45,773 [foster.py] => Task 2, Epoch 115/170 => Loss 3.633, Loss_clf 0.493, Loss_fe 0.393, Loss_kd 2.517, Train_accy 79.97, Test_accy 77.98
2024-09-08 10:56:49,533 [foster.py] => Task 2, Epoch 116/170 => Loss 3.612, Loss_clf 0.500, Loss_fe 0.374, Loss_kd 2.509, Train_accy 81.33
2024-09-08 10:56:54,712 [foster.py] => Task 2, Epoch 117/170 => Loss 3.651, Loss_clf 0.498, Loss_fe 0.406, Loss_kd 2.517, Train_accy 80.50, Test_accy 78.02
2024-09-08 10:56:59,927 [foster.py] => Task 2, Epoch 118/170 => Loss 3.544, Loss_clf 0.474, Loss_fe 0.336, Loss_kd 2.505, Train_accy 81.17, Test_accy 77.82
2024-09-08 10:57:05,088 [foster.py] => Task 2, Epoch 119/170 => Loss 3.575, Loss_clf 0.477, Loss_fe 0.364, Loss_kd 2.506, Train_accy 82.42, Test_accy 78.15
2024-09-08 10:57:10,218 [foster.py] => Task 2, Epoch 120/170 => Loss 3.562, Loss_clf 0.474, Loss_fe 0.343, Loss_kd 2.515, Train_accy 81.50, Test_accy 78.18
2024-09-08 10:57:13,843 [foster.py] => Task 2, Epoch 121/170 => Loss 3.599, Loss_clf 0.490, Loss_fe 0.355, Loss_kd 2.522, Train_accy 82.11
2024-09-08 10:57:19,007 [foster.py] => Task 2, Epoch 122/170 => Loss 3.520, Loss_clf 0.443, Loss_fe 0.333, Loss_kd 2.513, Train_accy 83.25, Test_accy 78.02
2024-09-08 10:57:24,137 [foster.py] => Task 2, Epoch 123/170 => Loss 3.526, Loss_clf 0.452, Loss_fe 0.336, Loss_kd 2.508, Train_accy 82.28, Test_accy 78.20
2024-09-08 10:57:29,324 [foster.py] => Task 2, Epoch 124/170 => Loss 3.562, Loss_clf 0.473, Loss_fe 0.348, Loss_kd 2.510, Train_accy 81.92, Test_accy 77.98
2024-09-08 10:57:34,503 [foster.py] => Task 2, Epoch 125/170 => Loss 3.560, Loss_clf 0.472, Loss_fe 0.331, Loss_kd 2.525, Train_accy 82.61, Test_accy 78.38
2024-09-08 10:57:38,165 [foster.py] => Task 2, Epoch 126/170 => Loss 3.523, Loss_clf 0.447, Loss_fe 0.323, Loss_kd 2.523, Train_accy 82.31
2024-09-08 10:57:43,270 [foster.py] => Task 2, Epoch 127/170 => Loss 3.507, Loss_clf 0.447, Loss_fe 0.330, Loss_kd 2.501, Train_accy 82.03, Test_accy 78.33
2024-09-08 10:57:48,415 [foster.py] => Task 2, Epoch 128/170 => Loss 3.500, Loss_clf 0.441, Loss_fe 0.315, Loss_kd 2.515, Train_accy 82.50, Test_accy 77.90
2024-09-08 10:57:53,544 [foster.py] => Task 2, Epoch 129/170 => Loss 3.458, Loss_clf 0.424, Loss_fe 0.312, Loss_kd 2.494, Train_accy 83.89, Test_accy 77.87
2024-09-08 10:57:58,702 [foster.py] => Task 2, Epoch 130/170 => Loss 3.562, Loss_clf 0.476, Loss_fe 0.343, Loss_kd 2.513, Train_accy 82.19, Test_accy 78.05
2024-09-08 10:58:02,438 [foster.py] => Task 2, Epoch 131/170 => Loss 3.564, Loss_clf 0.469, Loss_fe 0.341, Loss_kd 2.523, Train_accy 83.06
2024-09-08 10:58:07,641 [foster.py] => Task 2, Epoch 132/170 => Loss 3.558, Loss_clf 0.467, Loss_fe 0.337, Loss_kd 2.523, Train_accy 82.72, Test_accy 78.25
2024-09-08 10:58:12,846 [foster.py] => Task 2, Epoch 133/170 => Loss 3.427, Loss_clf 0.399, Loss_fe 0.303, Loss_kd 2.497, Train_accy 84.03, Test_accy 78.15
2024-09-08 10:58:17,984 [foster.py] => Task 2, Epoch 134/170 => Loss 3.473, Loss_clf 0.426, Loss_fe 0.309, Loss_kd 2.508, Train_accy 82.72, Test_accy 78.47
2024-09-08 10:58:23,075 [foster.py] => Task 2, Epoch 135/170 => Loss 3.504, Loss_clf 0.444, Loss_fe 0.317, Loss_kd 2.513, Train_accy 82.53, Test_accy 78.40
2024-09-08 10:58:26,688 [foster.py] => Task 2, Epoch 136/170 => Loss 3.494, Loss_clf 0.449, Loss_fe 0.314, Loss_kd 2.502, Train_accy 82.67
2024-09-08 10:58:31,850 [foster.py] => Task 2, Epoch 137/170 => Loss 3.434, Loss_clf 0.410, Loss_fe 0.284, Loss_kd 2.510, Train_accy 83.36, Test_accy 78.12
2024-09-08 10:58:37,027 [foster.py] => Task 2, Epoch 138/170 => Loss 3.490, Loss_clf 0.438, Loss_fe 0.302, Loss_kd 2.520, Train_accy 84.78, Test_accy 78.17
2024-09-08 10:58:42,115 [foster.py] => Task 2, Epoch 139/170 => Loss 3.463, Loss_clf 0.431, Loss_fe 0.306, Loss_kd 2.498, Train_accy 83.69, Test_accy 78.38
2024-09-08 10:58:47,284 [foster.py] => Task 2, Epoch 140/170 => Loss 3.470, Loss_clf 0.427, Loss_fe 0.296, Loss_kd 2.517, Train_accy 83.83, Test_accy 78.32
2024-09-08 10:58:50,923 [foster.py] => Task 2, Epoch 141/170 => Loss 3.461, Loss_clf 0.430, Loss_fe 0.292, Loss_kd 2.509, Train_accy 84.47
2024-09-08 10:58:55,960 [foster.py] => Task 2, Epoch 142/170 => Loss 3.470, Loss_clf 0.424, Loss_fe 0.288, Loss_kd 2.526, Train_accy 83.97, Test_accy 78.35
2024-09-08 10:59:01,107 [foster.py] => Task 2, Epoch 143/170 => Loss 3.508, Loss_clf 0.457, Loss_fe 0.312, Loss_kd 2.510, Train_accy 83.19, Test_accy 78.28
2024-09-08 10:59:06,194 [foster.py] => Task 2, Epoch 144/170 => Loss 3.463, Loss_clf 0.441, Loss_fe 0.297, Loss_kd 2.496, Train_accy 84.19, Test_accy 78.42
2024-09-08 10:59:11,309 [foster.py] => Task 2, Epoch 145/170 => Loss 3.425, Loss_clf 0.418, Loss_fe 0.283, Loss_kd 2.497, Train_accy 83.58, Test_accy 78.42
2024-09-08 10:59:15,048 [foster.py] => Task 2, Epoch 146/170 => Loss 3.438, Loss_clf 0.415, Loss_fe 0.283, Loss_kd 2.510, Train_accy 84.03
2024-09-08 10:59:20,222 [foster.py] => Task 2, Epoch 147/170 => Loss 3.409, Loss_clf 0.395, Loss_fe 0.277, Loss_kd 2.508, Train_accy 85.03, Test_accy 78.47
2024-09-08 10:59:25,341 [foster.py] => Task 2, Epoch 148/170 => Loss 3.453, Loss_clf 0.411, Loss_fe 0.285, Loss_kd 2.525, Train_accy 84.42, Test_accy 78.33
2024-09-08 10:59:30,485 [foster.py] => Task 2, Epoch 149/170 => Loss 3.432, Loss_clf 0.429, Loss_fe 0.279, Loss_kd 2.495, Train_accy 84.53, Test_accy 78.53
2024-09-08 10:59:35,615 [foster.py] => Task 2, Epoch 150/170 => Loss 3.475, Loss_clf 0.440, Loss_fe 0.294, Loss_kd 2.511, Train_accy 83.89, Test_accy 78.40
2024-09-08 10:59:39,231 [foster.py] => Task 2, Epoch 151/170 => Loss 3.428, Loss_clf 0.408, Loss_fe 0.285, Loss_kd 2.506, Train_accy 83.78
2024-09-08 10:59:44,349 [foster.py] => Task 2, Epoch 152/170 => Loss 3.428, Loss_clf 0.421, Loss_fe 0.285, Loss_kd 2.493, Train_accy 84.44, Test_accy 78.38
2024-09-08 10:59:49,416 [foster.py] => Task 2, Epoch 153/170 => Loss 3.442, Loss_clf 0.409, Loss_fe 0.290, Loss_kd 2.514, Train_accy 84.64, Test_accy 78.42
2024-09-08 10:59:54,583 [foster.py] => Task 2, Epoch 154/170 => Loss 3.470, Loss_clf 0.426, Loss_fe 0.281, Loss_kd 2.531, Train_accy 84.81, Test_accy 78.43
2024-09-08 10:59:59,658 [foster.py] => Task 2, Epoch 155/170 => Loss 3.424, Loss_clf 0.413, Loss_fe 0.276, Loss_kd 2.506, Train_accy 84.56, Test_accy 78.40
2024-09-08 11:00:03,258 [foster.py] => Task 2, Epoch 156/170 => Loss 3.467, Loss_clf 0.431, Loss_fe 0.311, Loss_kd 2.497, Train_accy 84.47
2024-09-08 11:00:08,376 [foster.py] => Task 2, Epoch 157/170 => Loss 3.446, Loss_clf 0.428, Loss_fe 0.288, Loss_kd 2.501, Train_accy 83.56, Test_accy 78.42
2024-09-08 11:00:13,536 [foster.py] => Task 2, Epoch 158/170 => Loss 3.363, Loss_clf 0.384, Loss_fe 0.265, Loss_kd 2.487, Train_accy 85.22, Test_accy 78.35
2024-09-08 11:00:18,692 [foster.py] => Task 2, Epoch 159/170 => Loss 3.413, Loss_clf 0.406, Loss_fe 0.274, Loss_kd 2.504, Train_accy 84.86, Test_accy 78.37
2024-09-08 11:00:23,742 [foster.py] => Task 2, Epoch 160/170 => Loss 3.378, Loss_clf 0.392, Loss_fe 0.266, Loss_kd 2.492, Train_accy 84.50, Test_accy 78.43
2024-09-08 11:00:27,364 [foster.py] => Task 2, Epoch 161/170 => Loss 3.435, Loss_clf 0.417, Loss_fe 0.272, Loss_kd 2.516, Train_accy 83.69
2024-09-08 11:00:32,443 [foster.py] => Task 2, Epoch 162/170 => Loss 3.412, Loss_clf 0.401, Loss_fe 0.266, Loss_kd 2.514, Train_accy 84.56, Test_accy 78.43
2024-09-08 11:00:37,482 [foster.py] => Task 2, Epoch 163/170 => Loss 3.406, Loss_clf 0.408, Loss_fe 0.264, Loss_kd 2.505, Train_accy 85.33, Test_accy 78.43
2024-09-08 11:00:42,568 [foster.py] => Task 2, Epoch 164/170 => Loss 3.394, Loss_clf 0.392, Loss_fe 0.268, Loss_kd 2.505, Train_accy 85.06, Test_accy 78.32
2024-09-08 11:00:47,645 [foster.py] => Task 2, Epoch 165/170 => Loss 3.464, Loss_clf 0.431, Loss_fe 0.296, Loss_kd 2.507, Train_accy 84.72, Test_accy 78.53
2024-09-08 11:00:51,329 [foster.py] => Task 2, Epoch 166/170 => Loss 3.424, Loss_clf 0.399, Loss_fe 0.275, Loss_kd 2.520, Train_accy 84.56
2024-09-08 11:00:56,561 [foster.py] => Task 2, Epoch 167/170 => Loss 3.395, Loss_clf 0.394, Loss_fe 0.263, Loss_kd 2.509, Train_accy 84.78, Test_accy 78.48
2024-09-08 11:01:01,781 [foster.py] => Task 2, Epoch 168/170 => Loss 3.503, Loss_clf 0.442, Loss_fe 0.304, Loss_kd 2.526, Train_accy 84.44, Test_accy 78.57
2024-09-08 11:01:07,007 [foster.py] => Task 2, Epoch 169/170 => Loss 3.357, Loss_clf 0.369, Loss_fe 0.248, Loss_kd 2.510, Train_accy 85.50, Test_accy 78.43
2024-09-08 11:01:12,187 [foster.py] => Task 2, Epoch 170/170 => Loss 3.457, Loss_clf 0.417, Loss_fe 0.288, Loss_kd 2.522, Train_accy 84.92, Test_accy 78.50
2024-09-08 11:01:12,190 [foster.py] => do not weight align teacher!
2024-09-08 11:01:12,192 [foster.py] => per cls weights : [1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  1.0413335  1.0413335  1.0413335  1.0413335  1.0413335
 1.0413335  0.54533154 0.54533154 0.54533154 0.54533154 0.54533154]
2024-09-08 11:01:18,499 [foster.py] => SNet: Task 2, Epoch 1/130 => Loss 28.521,  Loss1 0.702, Train_accy 26.03, Test_accy 70.37
2024-09-08 11:01:23,613 [foster.py] => SNet: Task 2, Epoch 2/130 => Loss 28.295,  Loss1 0.704, Train_accy 38.86
2024-09-08 11:01:28,702 [foster.py] => SNet: Task 2, Epoch 3/130 => Loss 28.272,  Loss1 0.704, Train_accy 41.75
2024-09-08 11:01:33,820 [foster.py] => SNet: Task 2, Epoch 4/130 => Loss 28.283,  Loss1 0.705, Train_accy 45.36
2024-09-08 11:01:38,905 [foster.py] => SNet: Task 2, Epoch 5/130 => Loss 28.251,  Loss1 0.705, Train_accy 48.47
2024-09-08 11:01:44,971 [foster.py] => SNet: Task 2, Epoch 6/130 => Loss 28.277,  Loss1 0.705, Train_accy 50.39, Test_accy 74.02
2024-09-08 11:01:50,072 [foster.py] => SNet: Task 2, Epoch 7/130 => Loss 28.236,  Loss1 0.706, Train_accy 53.08
2024-09-08 11:01:55,168 [foster.py] => SNet: Task 2, Epoch 8/130 => Loss 28.240,  Loss1 0.705, Train_accy 53.28
2024-09-08 11:02:00,244 [foster.py] => SNet: Task 2, Epoch 9/130 => Loss 28.228,  Loss1 0.705, Train_accy 54.03
2024-09-08 11:02:05,384 [foster.py] => SNet: Task 2, Epoch 10/130 => Loss 28.217,  Loss1 0.706, Train_accy 56.81
2024-09-08 11:02:11,429 [foster.py] => SNet: Task 2, Epoch 11/130 => Loss 28.224,  Loss1 0.706, Train_accy 56.81, Test_accy 74.63
2024-09-08 11:02:16,535 [foster.py] => SNet: Task 2, Epoch 12/130 => Loss 28.223,  Loss1 0.706, Train_accy 57.00
2024-09-08 11:02:21,637 [foster.py] => SNet: Task 2, Epoch 13/130 => Loss 28.221,  Loss1 0.706, Train_accy 58.03
2024-09-08 11:02:26,740 [foster.py] => SNet: Task 2, Epoch 14/130 => Loss 28.198,  Loss1 0.706, Train_accy 58.44
2024-09-08 11:02:31,833 [foster.py] => SNet: Task 2, Epoch 15/130 => Loss 28.185,  Loss1 0.706, Train_accy 58.39
2024-09-08 11:02:37,876 [foster.py] => SNet: Task 2, Epoch 16/130 => Loss 28.176,  Loss1 0.706, Train_accy 59.86, Test_accy 75.17
2024-09-08 11:02:42,942 [foster.py] => SNet: Task 2, Epoch 17/130 => Loss 28.204,  Loss1 0.706, Train_accy 60.00
2024-09-08 11:02:48,059 [foster.py] => SNet: Task 2, Epoch 18/130 => Loss 28.216,  Loss1 0.706, Train_accy 59.25
2024-09-08 11:02:53,147 [foster.py] => SNet: Task 2, Epoch 19/130 => Loss 28.169,  Loss1 0.706, Train_accy 60.58
2024-09-08 11:02:58,321 [foster.py] => SNet: Task 2, Epoch 20/130 => Loss 28.208,  Loss1 0.706, Train_accy 60.44
2024-09-08 11:03:04,396 [foster.py] => SNet: Task 2, Epoch 21/130 => Loss 28.191,  Loss1 0.707, Train_accy 63.19, Test_accy 75.47
2024-09-08 11:03:09,455 [foster.py] => SNet: Task 2, Epoch 22/130 => Loss 28.250,  Loss1 0.706, Train_accy 60.69
2024-09-08 11:03:14,550 [foster.py] => SNet: Task 2, Epoch 23/130 => Loss 28.198,  Loss1 0.706, Train_accy 61.72
2024-09-08 11:03:19,710 [foster.py] => SNet: Task 2, Epoch 24/130 => Loss 28.224,  Loss1 0.706, Train_accy 62.39
2024-09-08 11:03:24,817 [foster.py] => SNet: Task 2, Epoch 25/130 => Loss 28.182,  Loss1 0.706, Train_accy 61.83
2024-09-08 11:03:30,893 [foster.py] => SNet: Task 2, Epoch 26/130 => Loss 28.189,  Loss1 0.706, Train_accy 62.53, Test_accy 75.43
2024-09-08 11:03:35,979 [foster.py] => SNet: Task 2, Epoch 27/130 => Loss 28.200,  Loss1 0.706, Train_accy 61.67
2024-09-08 11:03:41,063 [foster.py] => SNet: Task 2, Epoch 28/130 => Loss 28.181,  Loss1 0.706, Train_accy 63.64
2024-09-08 11:03:46,146 [foster.py] => SNet: Task 2, Epoch 29/130 => Loss 28.221,  Loss1 0.706, Train_accy 62.72
2024-09-08 11:03:51,257 [foster.py] => SNet: Task 2, Epoch 30/130 => Loss 28.204,  Loss1 0.706, Train_accy 62.94
2024-09-08 11:03:57,340 [foster.py] => SNet: Task 2, Epoch 31/130 => Loss 28.163,  Loss1 0.706, Train_accy 63.42, Test_accy 75.98
2024-09-08 11:04:02,423 [foster.py] => SNet: Task 2, Epoch 32/130 => Loss 28.170,  Loss1 0.707, Train_accy 64.17
2024-09-08 11:04:07,481 [foster.py] => SNet: Task 2, Epoch 33/130 => Loss 28.180,  Loss1 0.706, Train_accy 63.69
2024-09-08 11:04:12,555 [foster.py] => SNet: Task 2, Epoch 34/130 => Loss 28.169,  Loss1 0.707, Train_accy 64.08
2024-09-08 11:04:17,648 [foster.py] => SNet: Task 2, Epoch 35/130 => Loss 28.185,  Loss1 0.707, Train_accy 64.64
2024-09-08 11:04:23,681 [foster.py] => SNet: Task 2, Epoch 36/130 => Loss 28.205,  Loss1 0.706, Train_accy 65.81, Test_accy 75.87
2024-09-08 11:04:28,786 [foster.py] => SNet: Task 2, Epoch 37/130 => Loss 28.172,  Loss1 0.707, Train_accy 64.31
2024-09-08 11:04:33,907 [foster.py] => SNet: Task 2, Epoch 38/130 => Loss 28.177,  Loss1 0.707, Train_accy 66.19
2024-09-08 11:04:38,993 [foster.py] => SNet: Task 2, Epoch 39/130 => Loss 28.221,  Loss1 0.707, Train_accy 65.58
2024-09-08 11:04:44,039 [foster.py] => SNet: Task 2, Epoch 40/130 => Loss 28.187,  Loss1 0.707, Train_accy 64.75
2024-09-08 11:04:50,119 [foster.py] => SNet: Task 2, Epoch 41/130 => Loss 28.164,  Loss1 0.707, Train_accy 66.72, Test_accy 76.47
2024-09-08 11:04:55,226 [foster.py] => SNet: Task 2, Epoch 42/130 => Loss 28.169,  Loss1 0.707, Train_accy 65.86
2024-09-08 11:05:00,297 [foster.py] => SNet: Task 2, Epoch 43/130 => Loss 28.213,  Loss1 0.706, Train_accy 66.31
2024-09-08 11:05:05,414 [foster.py] => SNet: Task 2, Epoch 44/130 => Loss 28.160,  Loss1 0.707, Train_accy 65.86
2024-09-08 11:05:10,515 [foster.py] => SNet: Task 2, Epoch 45/130 => Loss 28.214,  Loss1 0.707, Train_accy 65.61
2024-09-08 11:05:16,565 [foster.py] => SNet: Task 2, Epoch 46/130 => Loss 28.177,  Loss1 0.707, Train_accy 65.92, Test_accy 76.07
2024-09-08 11:05:21,666 [foster.py] => SNet: Task 2, Epoch 47/130 => Loss 28.161,  Loss1 0.707, Train_accy 66.67
2024-09-08 11:05:26,766 [foster.py] => SNet: Task 2, Epoch 48/130 => Loss 28.228,  Loss1 0.706, Train_accy 66.11
2024-09-08 11:05:31,866 [foster.py] => SNet: Task 2, Epoch 49/130 => Loss 28.166,  Loss1 0.707, Train_accy 67.36
2024-09-08 11:05:36,980 [foster.py] => SNet: Task 2, Epoch 50/130 => Loss 28.183,  Loss1 0.707, Train_accy 68.11
2024-09-08 11:05:43,019 [foster.py] => SNet: Task 2, Epoch 51/130 => Loss 28.188,  Loss1 0.707, Train_accy 66.53, Test_accy 75.67
2024-09-08 11:05:48,183 [foster.py] => SNet: Task 2, Epoch 52/130 => Loss 28.127,  Loss1 0.707, Train_accy 66.75
2024-09-08 11:05:53,245 [foster.py] => SNet: Task 2, Epoch 53/130 => Loss 28.199,  Loss1 0.707, Train_accy 67.47
2024-09-08 11:05:58,331 [foster.py] => SNet: Task 2, Epoch 54/130 => Loss 28.174,  Loss1 0.707, Train_accy 66.03
2024-09-08 11:06:03,418 [foster.py] => SNet: Task 2, Epoch 55/130 => Loss 28.207,  Loss1 0.707, Train_accy 67.86
2024-09-08 11:06:09,476 [foster.py] => SNet: Task 2, Epoch 56/130 => Loss 28.127,  Loss1 0.707, Train_accy 67.67, Test_accy 76.03
2024-09-08 11:06:14,513 [foster.py] => SNet: Task 2, Epoch 57/130 => Loss 28.182,  Loss1 0.706, Train_accy 66.94
2024-09-08 11:06:19,610 [foster.py] => SNet: Task 2, Epoch 58/130 => Loss 28.159,  Loss1 0.706, Train_accy 68.22
2024-09-08 11:06:24,721 [foster.py] => SNet: Task 2, Epoch 59/130 => Loss 28.157,  Loss1 0.707, Train_accy 67.39
2024-09-08 11:06:29,822 [foster.py] => SNet: Task 2, Epoch 60/130 => Loss 28.138,  Loss1 0.706, Train_accy 65.81
2024-09-08 11:06:35,860 [foster.py] => SNet: Task 2, Epoch 61/130 => Loss 28.179,  Loss1 0.707, Train_accy 66.97, Test_accy 76.10
2024-09-08 11:06:40,956 [foster.py] => SNet: Task 2, Epoch 62/130 => Loss 28.129,  Loss1 0.707, Train_accy 67.28
2024-09-08 11:06:46,000 [foster.py] => SNet: Task 2, Epoch 63/130 => Loss 28.191,  Loss1 0.707, Train_accy 67.56
2024-09-08 11:06:51,033 [foster.py] => SNet: Task 2, Epoch 64/130 => Loss 28.169,  Loss1 0.707, Train_accy 68.22
2024-09-08 11:06:56,140 [foster.py] => SNet: Task 2, Epoch 65/130 => Loss 28.179,  Loss1 0.707, Train_accy 68.25
2024-09-08 11:07:02,178 [foster.py] => SNet: Task 2, Epoch 66/130 => Loss 28.172,  Loss1 0.706, Train_accy 68.00, Test_accy 76.48
2024-09-08 11:07:07,249 [foster.py] => SNet: Task 2, Epoch 67/130 => Loss 28.144,  Loss1 0.707, Train_accy 67.69
2024-09-08 11:07:12,326 [foster.py] => SNet: Task 2, Epoch 68/130 => Loss 28.144,  Loss1 0.707, Train_accy 69.31
2024-09-08 11:07:17,388 [foster.py] => SNet: Task 2, Epoch 69/130 => Loss 28.153,  Loss1 0.707, Train_accy 68.03
2024-09-08 11:07:22,481 [foster.py] => SNet: Task 2, Epoch 70/130 => Loss 28.139,  Loss1 0.706, Train_accy 68.42
2024-09-08 11:07:28,538 [foster.py] => SNet: Task 2, Epoch 71/130 => Loss 28.170,  Loss1 0.707, Train_accy 68.44, Test_accy 76.35
2024-09-08 11:07:33,674 [foster.py] => SNet: Task 2, Epoch 72/130 => Loss 28.189,  Loss1 0.706, Train_accy 69.14
2024-09-08 11:07:38,752 [foster.py] => SNet: Task 2, Epoch 73/130 => Loss 28.171,  Loss1 0.706, Train_accy 68.31
2024-09-08 11:07:43,825 [foster.py] => SNet: Task 2, Epoch 74/130 => Loss 28.177,  Loss1 0.707, Train_accy 67.53
2024-09-08 11:07:48,923 [foster.py] => SNet: Task 2, Epoch 75/130 => Loss 28.156,  Loss1 0.707, Train_accy 69.39
2024-09-08 11:07:54,971 [foster.py] => SNet: Task 2, Epoch 76/130 => Loss 28.163,  Loss1 0.706, Train_accy 67.31, Test_accy 76.57
2024-09-08 11:08:00,066 [foster.py] => SNet: Task 2, Epoch 77/130 => Loss 28.152,  Loss1 0.706, Train_accy 67.69
2024-09-08 11:08:05,160 [foster.py] => SNet: Task 2, Epoch 78/130 => Loss 28.206,  Loss1 0.707, Train_accy 67.67
2024-09-08 11:08:10,285 [foster.py] => SNet: Task 2, Epoch 79/130 => Loss 28.188,  Loss1 0.707, Train_accy 69.36
2024-09-08 11:08:15,357 [foster.py] => SNet: Task 2, Epoch 80/130 => Loss 28.169,  Loss1 0.707, Train_accy 68.78
2024-09-08 11:08:21,424 [foster.py] => SNet: Task 2, Epoch 81/130 => Loss 28.167,  Loss1 0.707, Train_accy 68.64, Test_accy 76.97
2024-09-08 11:08:26,463 [foster.py] => SNet: Task 2, Epoch 82/130 => Loss 28.166,  Loss1 0.707, Train_accy 68.94
2024-09-08 11:08:31,606 [foster.py] => SNet: Task 2, Epoch 83/130 => Loss 28.139,  Loss1 0.707, Train_accy 69.14
2024-09-08 11:08:36,735 [foster.py] => SNet: Task 2, Epoch 84/130 => Loss 28.143,  Loss1 0.707, Train_accy 68.94
2024-09-08 11:08:41,776 [foster.py] => SNet: Task 2, Epoch 85/130 => Loss 28.171,  Loss1 0.706, Train_accy 69.39
2024-09-08 11:08:47,808 [foster.py] => SNet: Task 2, Epoch 86/130 => Loss 28.152,  Loss1 0.707, Train_accy 68.78, Test_accy 76.62
2024-09-08 11:08:52,876 [foster.py] => SNet: Task 2, Epoch 87/130 => Loss 28.168,  Loss1 0.707, Train_accy 68.78
2024-09-08 11:08:57,950 [foster.py] => SNet: Task 2, Epoch 88/130 => Loss 28.189,  Loss1 0.707, Train_accy 69.22
2024-09-08 11:09:03,040 [foster.py] => SNet: Task 2, Epoch 89/130 => Loss 28.155,  Loss1 0.707, Train_accy 69.19
2024-09-08 11:09:08,123 [foster.py] => SNet: Task 2, Epoch 90/130 => Loss 28.149,  Loss1 0.707, Train_accy 69.11
2024-09-08 11:09:14,162 [foster.py] => SNet: Task 2, Epoch 91/130 => Loss 28.152,  Loss1 0.707, Train_accy 69.14, Test_accy 76.85
2024-09-08 11:09:19,258 [foster.py] => SNet: Task 2, Epoch 92/130 => Loss 28.193,  Loss1 0.706, Train_accy 68.64
2024-09-08 11:09:24,408 [foster.py] => SNet: Task 2, Epoch 93/130 => Loss 28.162,  Loss1 0.707, Train_accy 69.28
2024-09-08 11:09:29,488 [foster.py] => SNet: Task 2, Epoch 94/130 => Loss 28.149,  Loss1 0.707, Train_accy 69.03
2024-09-08 11:09:34,560 [foster.py] => SNet: Task 2, Epoch 95/130 => Loss 28.185,  Loss1 0.707, Train_accy 68.89
2024-09-08 11:09:40,601 [foster.py] => SNet: Task 2, Epoch 96/130 => Loss 28.199,  Loss1 0.707, Train_accy 68.89, Test_accy 76.42
2024-09-08 11:09:45,695 [foster.py] => SNet: Task 2, Epoch 97/130 => Loss 28.098,  Loss1 0.707, Train_accy 70.61
2024-09-08 11:09:50,803 [foster.py] => SNet: Task 2, Epoch 98/130 => Loss 28.158,  Loss1 0.707, Train_accy 70.11
2024-09-08 11:09:55,874 [foster.py] => SNet: Task 2, Epoch 99/130 => Loss 28.165,  Loss1 0.707, Train_accy 69.36
2024-09-08 11:10:00,950 [foster.py] => SNet: Task 2, Epoch 100/130 => Loss 28.130,  Loss1 0.707, Train_accy 69.31
2024-09-08 11:10:07,012 [foster.py] => SNet: Task 2, Epoch 101/130 => Loss 28.160,  Loss1 0.707, Train_accy 69.19, Test_accy 76.67
2024-09-08 11:10:12,127 [foster.py] => SNet: Task 2, Epoch 102/130 => Loss 28.167,  Loss1 0.707, Train_accy 69.97
2024-09-08 11:10:17,248 [foster.py] => SNet: Task 2, Epoch 103/130 => Loss 28.128,  Loss1 0.707, Train_accy 69.33
2024-09-08 11:10:22,297 [foster.py] => SNet: Task 2, Epoch 104/130 => Loss 28.140,  Loss1 0.707, Train_accy 69.39
2024-09-08 11:10:27,404 [foster.py] => SNet: Task 2, Epoch 105/130 => Loss 28.131,  Loss1 0.707, Train_accy 69.58
2024-09-08 11:10:33,443 [foster.py] => SNet: Task 2, Epoch 106/130 => Loss 28.140,  Loss1 0.707, Train_accy 69.44, Test_accy 76.53
2024-09-08 11:10:38,628 [foster.py] => SNet: Task 2, Epoch 107/130 => Loss 28.142,  Loss1 0.707, Train_accy 68.39
2024-09-08 11:10:43,691 [foster.py] => SNet: Task 2, Epoch 108/130 => Loss 28.144,  Loss1 0.707, Train_accy 68.19
2024-09-08 11:10:48,775 [foster.py] => SNet: Task 2, Epoch 109/130 => Loss 28.126,  Loss1 0.707, Train_accy 68.33
2024-09-08 11:10:53,877 [foster.py] => SNet: Task 2, Epoch 110/130 => Loss 28.152,  Loss1 0.706, Train_accy 70.08
2024-09-08 11:10:59,931 [foster.py] => SNet: Task 2, Epoch 111/130 => Loss 28.133,  Loss1 0.707, Train_accy 69.36, Test_accy 76.52
2024-09-08 11:11:05,026 [foster.py] => SNet: Task 2, Epoch 112/130 => Loss 28.154,  Loss1 0.706, Train_accy 68.39
2024-09-08 11:11:10,083 [foster.py] => SNet: Task 2, Epoch 113/130 => Loss 28.124,  Loss1 0.707, Train_accy 69.67
2024-09-08 11:11:15,140 [foster.py] => SNet: Task 2, Epoch 114/130 => Loss 28.144,  Loss1 0.706, Train_accy 69.81
2024-09-08 11:11:20,232 [foster.py] => SNet: Task 2, Epoch 115/130 => Loss 28.174,  Loss1 0.707, Train_accy 68.31
2024-09-08 11:11:26,303 [foster.py] => SNet: Task 2, Epoch 116/130 => Loss 28.196,  Loss1 0.707, Train_accy 68.61, Test_accy 76.48
2024-09-08 11:11:31,362 [foster.py] => SNet: Task 2, Epoch 117/130 => Loss 28.157,  Loss1 0.707, Train_accy 69.11
2024-09-08 11:11:36,463 [foster.py] => SNet: Task 2, Epoch 118/130 => Loss 28.172,  Loss1 0.707, Train_accy 68.47
2024-09-08 11:11:41,533 [foster.py] => SNet: Task 2, Epoch 119/130 => Loss 28.119,  Loss1 0.707, Train_accy 69.19
2024-09-08 11:11:46,664 [foster.py] => SNet: Task 2, Epoch 120/130 => Loss 28.156,  Loss1 0.707, Train_accy 69.72
2024-09-08 11:11:52,715 [foster.py] => SNet: Task 2, Epoch 121/130 => Loss 28.145,  Loss1 0.707, Train_accy 70.50, Test_accy 76.92
2024-09-08 11:11:57,781 [foster.py] => SNet: Task 2, Epoch 122/130 => Loss 28.121,  Loss1 0.707, Train_accy 70.33
2024-09-08 11:12:02,860 [foster.py] => SNet: Task 2, Epoch 123/130 => Loss 28.178,  Loss1 0.707, Train_accy 69.06
2024-09-08 11:12:07,978 [foster.py] => SNet: Task 2, Epoch 124/130 => Loss 28.170,  Loss1 0.706, Train_accy 69.22
2024-09-08 11:12:13,057 [foster.py] => SNet: Task 2, Epoch 125/130 => Loss 28.161,  Loss1 0.707, Train_accy 70.36
2024-09-08 11:12:19,119 [foster.py] => SNet: Task 2, Epoch 126/130 => Loss 28.156,  Loss1 0.707, Train_accy 69.78, Test_accy 76.85
2024-09-08 11:12:24,207 [foster.py] => SNet: Task 2, Epoch 127/130 => Loss 28.108,  Loss1 0.706, Train_accy 69.67
2024-09-08 11:12:29,290 [foster.py] => SNet: Task 2, Epoch 128/130 => Loss 28.143,  Loss1 0.707, Train_accy 70.11
2024-09-08 11:12:34,360 [foster.py] => SNet: Task 2, Epoch 129/130 => Loss 28.156,  Loss1 0.707, Train_accy 69.25
2024-09-08 11:12:39,421 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 28.149,  Loss1 0.707, Train_accy 68.78
2024-09-08 11:12:39,422 [foster.py] => do not weight align student!
2024-09-08 11:12:40,385 [foster.py] => darknet eval: 
2024-09-08 11:12:40,385 [foster.py] => CNN top1 curve: 76.52
2024-09-08 11:12:40,385 [foster.py] => CNN top5 curve: 95.43
2024-09-08 11:12:40,385 [foster.py] => CNN top1 平均值: 76.52
2024-09-08 11:12:40,389 [foster.py] => timees : 1510.9920489788055
2024-09-08 11:12:40,390 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 11:13:00,035 [foster.py] => Exemplar size: 1200
2024-09-08 11:13:00,035 [trainer.py] => CNN: {'total': 78.5, '00-09': 82.6, '10-19': 74.5, '20-29': 81.2, '30-39': 77.0, '40-49': 80.2, '50-59': 75.5, 'old': 78.55, 'new': 78.0}
2024-09-08 11:13:00,035 [trainer.py] => NME: {'total': 74.22, '00-09': 76.1, '10-19': 70.4, '20-29': 76.9, '30-39': 73.4, '40-49': 77.4, '50-59': 71.1, 'old': 73.44, 'new': 82.8}
2024-09-08 11:13:00,035 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5]
2024-09-08 11:13:00,035 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97]
2024-09-08 11:13:00,035 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22]
2024-09-08 11:13:00,035 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4]

2024-09-08 11:13:00,035 [trainer.py] => CNN top1 平均值: 79.99
2024-09-08 11:13:00,038 [trainer.py] => All params: 1169763
2024-09-08 11:13:00,040 [trainer.py] => Trainable params: 588914
2024-09-08 11:13:00,099 [foster.py] => Learning on 60-65
2024-09-08 11:13:00,103 [foster.py] => All params: 1171058
2024-09-08 11:13:00,105 [foster.py] => Trainable params: 589884
2024-09-08 11:13:00,152 [foster.py] => per cls weights : [1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315 1.03096315
 0.62844215 0.62844215 0.62844215 0.62844215 0.62844215]
2024-09-08 11:13:03,924 [foster.py] => Task 3, Epoch 1/170 => Loss 6.087, Loss_clf 1.592, Loss_fe 1.654, Loss_kd 2.621, Train_accy 56.43
2024-09-08 11:13:09,219 [foster.py] => Task 3, Epoch 2/170 => Loss 4.559, Loss_clf 0.826, Loss_fe 0.914, Loss_kd 2.601, Train_accy 64.08, Test_accy 73.95
2024-09-08 11:13:14,398 [foster.py] => Task 3, Epoch 3/170 => Loss 4.420, Loss_clf 0.775, Loss_fe 0.839, Loss_kd 2.589, Train_accy 64.70, Test_accy 73.66
2024-09-08 11:13:19,694 [foster.py] => Task 3, Epoch 4/170 => Loss 4.275, Loss_clf 0.726, Loss_fe 0.742, Loss_kd 2.591, Train_accy 68.73, Test_accy 74.43
2024-09-08 11:13:24,896 [foster.py] => Task 3, Epoch 5/170 => Loss 4.173, Loss_clf 0.677, Loss_fe 0.705, Loss_kd 2.574, Train_accy 68.49, Test_accy 74.20
2024-09-08 11:13:28,579 [foster.py] => Task 3, Epoch 6/170 => Loss 4.229, Loss_clf 0.703, Loss_fe 0.722, Loss_kd 2.587, Train_accy 67.30
2024-09-08 11:13:33,779 [foster.py] => Task 3, Epoch 7/170 => Loss 4.175, Loss_clf 0.688, Loss_fe 0.686, Loss_kd 2.584, Train_accy 69.22, Test_accy 74.42
2024-09-08 11:13:39,009 [foster.py] => Task 3, Epoch 8/170 => Loss 4.145, Loss_clf 0.660, Loss_fe 0.675, Loss_kd 2.593, Train_accy 70.27, Test_accy 74.62
2024-09-08 11:13:44,228 [foster.py] => Task 3, Epoch 9/170 => Loss 4.154, Loss_clf 0.673, Loss_fe 0.672, Loss_kd 2.591, Train_accy 69.11, Test_accy 73.75
2024-09-08 11:13:49,428 [foster.py] => Task 3, Epoch 10/170 => Loss 4.117, Loss_clf 0.670, Loss_fe 0.647, Loss_kd 2.583, Train_accy 70.00, Test_accy 74.45
2024-09-08 11:13:53,042 [foster.py] => Task 3, Epoch 11/170 => Loss 4.112, Loss_clf 0.671, Loss_fe 0.649, Loss_kd 2.577, Train_accy 68.35
2024-09-08 11:13:58,244 [foster.py] => Task 3, Epoch 12/170 => Loss 4.124, Loss_clf 0.683, Loss_fe 0.641, Loss_kd 2.583, Train_accy 70.43, Test_accy 74.92
2024-09-08 11:14:03,433 [foster.py] => Task 3, Epoch 13/170 => Loss 4.065, Loss_clf 0.647, Loss_fe 0.611, Loss_kd 2.590, Train_accy 70.57, Test_accy 74.86
2024-09-08 11:14:08,679 [foster.py] => Task 3, Epoch 14/170 => Loss 4.009, Loss_clf 0.619, Loss_fe 0.585, Loss_kd 2.588, Train_accy 72.19, Test_accy 75.14
2024-09-08 11:14:13,949 [foster.py] => Task 3, Epoch 15/170 => Loss 4.050, Loss_clf 0.633, Loss_fe 0.623, Loss_kd 2.578, Train_accy 71.32, Test_accy 74.49
2024-09-08 11:14:17,562 [foster.py] => Task 3, Epoch 16/170 => Loss 4.003, Loss_clf 0.616, Loss_fe 0.598, Loss_kd 2.573, Train_accy 70.51
2024-09-08 11:14:22,820 [foster.py] => Task 3, Epoch 17/170 => Loss 3.965, Loss_clf 0.598, Loss_fe 0.575, Loss_kd 2.576, Train_accy 73.41, Test_accy 74.37
2024-09-08 11:14:28,016 [foster.py] => Task 3, Epoch 18/170 => Loss 3.951, Loss_clf 0.600, Loss_fe 0.569, Loss_kd 2.566, Train_accy 72.16, Test_accy 74.62
2024-09-08 11:14:33,257 [foster.py] => Task 3, Epoch 19/170 => Loss 3.943, Loss_clf 0.609, Loss_fe 0.547, Loss_kd 2.571, Train_accy 72.86, Test_accy 74.54
2024-09-08 11:14:38,517 [foster.py] => Task 3, Epoch 20/170 => Loss 3.945, Loss_clf 0.588, Loss_fe 0.564, Loss_kd 2.577, Train_accy 72.41, Test_accy 74.92
2024-09-08 11:14:42,226 [foster.py] => Task 3, Epoch 21/170 => Loss 4.037, Loss_clf 0.642, Loss_fe 0.596, Loss_kd 2.583, Train_accy 71.92
2024-09-08 11:14:47,440 [foster.py] => Task 3, Epoch 22/170 => Loss 3.940, Loss_clf 0.583, Loss_fe 0.544, Loss_kd 2.595, Train_accy 73.68, Test_accy 74.49
2024-09-08 11:14:52,624 [foster.py] => Task 3, Epoch 23/170 => Loss 3.868, Loss_clf 0.557, Loss_fe 0.522, Loss_kd 2.573, Train_accy 73.35, Test_accy 75.15
2024-09-08 11:14:57,864 [foster.py] => Task 3, Epoch 24/170 => Loss 3.967, Loss_clf 0.612, Loss_fe 0.544, Loss_kd 2.593, Train_accy 72.32, Test_accy 75.35
2024-09-08 11:15:03,081 [foster.py] => Task 3, Epoch 25/170 => Loss 3.925, Loss_clf 0.593, Loss_fe 0.537, Loss_kd 2.579, Train_accy 72.89, Test_accy 74.83
2024-09-08 11:15:06,810 [foster.py] => Task 3, Epoch 26/170 => Loss 3.896, Loss_clf 0.574, Loss_fe 0.530, Loss_kd 2.576, Train_accy 73.68
2024-09-08 11:15:12,011 [foster.py] => Task 3, Epoch 27/170 => Loss 3.912, Loss_clf 0.578, Loss_fe 0.526, Loss_kd 2.591, Train_accy 72.97, Test_accy 75.06
2024-09-08 11:15:17,290 [foster.py] => Task 3, Epoch 28/170 => Loss 3.910, Loss_clf 0.567, Loss_fe 0.535, Loss_kd 2.592, Train_accy 73.65, Test_accy 75.15
2024-09-08 11:15:22,512 [foster.py] => Task 3, Epoch 29/170 => Loss 3.894, Loss_clf 0.572, Loss_fe 0.527, Loss_kd 2.579, Train_accy 74.05, Test_accy 75.37
2024-09-08 11:15:27,715 [foster.py] => Task 3, Epoch 30/170 => Loss 3.916, Loss_clf 0.580, Loss_fe 0.537, Loss_kd 2.582, Train_accy 73.16, Test_accy 75.15
2024-09-08 11:15:31,377 [foster.py] => Task 3, Epoch 31/170 => Loss 3.864, Loss_clf 0.565, Loss_fe 0.507, Loss_kd 2.576, Train_accy 73.78
2024-09-08 11:15:36,667 [foster.py] => Task 3, Epoch 32/170 => Loss 3.808, Loss_clf 0.528, Loss_fe 0.483, Loss_kd 2.580, Train_accy 76.89, Test_accy 75.45
2024-09-08 11:15:41,973 [foster.py] => Task 3, Epoch 33/170 => Loss 3.891, Loss_clf 0.555, Loss_fe 0.519, Loss_kd 2.599, Train_accy 75.27, Test_accy 75.03
2024-09-08 11:15:47,222 [foster.py] => Task 3, Epoch 34/170 => Loss 3.824, Loss_clf 0.538, Loss_fe 0.512, Loss_kd 2.558, Train_accy 74.68, Test_accy 74.34
2024-09-08 11:15:52,420 [foster.py] => Task 3, Epoch 35/170 => Loss 3.855, Loss_clf 0.552, Loss_fe 0.489, Loss_kd 2.595, Train_accy 74.54, Test_accy 74.74
2024-09-08 11:15:56,057 [foster.py] => Task 3, Epoch 36/170 => Loss 3.846, Loss_clf 0.555, Loss_fe 0.499, Loss_kd 2.576, Train_accy 74.51
2024-09-08 11:16:01,295 [foster.py] => Task 3, Epoch 37/170 => Loss 3.780, Loss_clf 0.524, Loss_fe 0.468, Loss_kd 2.572, Train_accy 76.51, Test_accy 74.88
2024-09-08 11:16:06,519 [foster.py] => Task 3, Epoch 38/170 => Loss 3.856, Loss_clf 0.562, Loss_fe 0.492, Loss_kd 2.586, Train_accy 75.81, Test_accy 75.63
2024-09-08 11:16:11,684 [foster.py] => Task 3, Epoch 39/170 => Loss 3.841, Loss_clf 0.556, Loss_fe 0.492, Loss_kd 2.577, Train_accy 74.86, Test_accy 74.75
2024-09-08 11:16:16,998 [foster.py] => Task 3, Epoch 40/170 => Loss 3.794, Loss_clf 0.536, Loss_fe 0.465, Loss_kd 2.576, Train_accy 77.11, Test_accy 75.25
2024-09-08 11:16:20,633 [foster.py] => Task 3, Epoch 41/170 => Loss 3.756, Loss_clf 0.510, Loss_fe 0.455, Loss_kd 2.574, Train_accy 76.24
2024-09-08 11:16:25,846 [foster.py] => Task 3, Epoch 42/170 => Loss 3.782, Loss_clf 0.532, Loss_fe 0.466, Loss_kd 2.568, Train_accy 76.51, Test_accy 74.80
2024-09-08 11:16:31,050 [foster.py] => Task 3, Epoch 43/170 => Loss 3.792, Loss_clf 0.523, Loss_fe 0.473, Loss_kd 2.579, Train_accy 77.35, Test_accy 75.34
2024-09-08 11:16:36,249 [foster.py] => Task 3, Epoch 44/170 => Loss 3.779, Loss_clf 0.519, Loss_fe 0.463, Loss_kd 2.581, Train_accy 76.65, Test_accy 74.97
2024-09-08 11:16:41,470 [foster.py] => Task 3, Epoch 45/170 => Loss 3.805, Loss_clf 0.544, Loss_fe 0.455, Loss_kd 2.589, Train_accy 76.19, Test_accy 75.02
2024-09-08 11:16:45,132 [foster.py] => Task 3, Epoch 46/170 => Loss 3.750, Loss_clf 0.509, Loss_fe 0.440, Loss_kd 2.584, Train_accy 77.30
2024-09-08 11:16:50,467 [foster.py] => Task 3, Epoch 47/170 => Loss 3.760, Loss_clf 0.511, Loss_fe 0.452, Loss_kd 2.581, Train_accy 76.81, Test_accy 75.11
2024-09-08 11:16:55,682 [foster.py] => Task 3, Epoch 48/170 => Loss 3.716, Loss_clf 0.490, Loss_fe 0.427, Loss_kd 2.583, Train_accy 78.08, Test_accy 75.48
2024-09-08 11:17:00,946 [foster.py] => Task 3, Epoch 49/170 => Loss 3.731, Loss_clf 0.489, Loss_fe 0.450, Loss_kd 2.576, Train_accy 78.05, Test_accy 74.86
2024-09-08 11:17:06,268 [foster.py] => Task 3, Epoch 50/170 => Loss 3.761, Loss_clf 0.524, Loss_fe 0.445, Loss_kd 2.576, Train_accy 77.46, Test_accy 73.82
2024-09-08 11:17:09,885 [foster.py] => Task 3, Epoch 51/170 => Loss 3.753, Loss_clf 0.523, Loss_fe 0.430, Loss_kd 2.583, Train_accy 77.43
2024-09-08 11:17:15,129 [foster.py] => Task 3, Epoch 52/170 => Loss 3.731, Loss_clf 0.513, Loss_fe 0.419, Loss_kd 2.582, Train_accy 77.08, Test_accy 75.97
2024-09-08 11:17:20,338 [foster.py] => Task 3, Epoch 53/170 => Loss 3.701, Loss_clf 0.489, Loss_fe 0.418, Loss_kd 2.578, Train_accy 78.41, Test_accy 74.80
2024-09-08 11:17:25,631 [foster.py] => Task 3, Epoch 54/170 => Loss 3.778, Loss_clf 0.525, Loss_fe 0.424, Loss_kd 2.610, Train_accy 77.95, Test_accy 75.29
2024-09-08 11:17:30,861 [foster.py] => Task 3, Epoch 55/170 => Loss 3.691, Loss_clf 0.496, Loss_fe 0.402, Loss_kd 2.576, Train_accy 77.89, Test_accy 75.55
2024-09-08 11:17:34,463 [foster.py] => Task 3, Epoch 56/170 => Loss 3.702, Loss_clf 0.486, Loss_fe 0.409, Loss_kd 2.589, Train_accy 78.92
2024-09-08 11:17:39,646 [foster.py] => Task 3, Epoch 57/170 => Loss 3.742, Loss_clf 0.507, Loss_fe 0.428, Loss_kd 2.590, Train_accy 78.57, Test_accy 74.95
2024-09-08 11:17:44,947 [foster.py] => Task 3, Epoch 58/170 => Loss 3.694, Loss_clf 0.482, Loss_fe 0.412, Loss_kd 2.583, Train_accy 78.38, Test_accy 74.86
2024-09-08 11:17:50,196 [foster.py] => Task 3, Epoch 59/170 => Loss 3.694, Loss_clf 0.481, Loss_fe 0.411, Loss_kd 2.585, Train_accy 78.86, Test_accy 75.58
2024-09-08 11:17:55,436 [foster.py] => Task 3, Epoch 60/170 => Loss 3.681, Loss_clf 0.492, Loss_fe 0.396, Loss_kd 2.577, Train_accy 78.38, Test_accy 75.28
2024-09-08 11:17:59,084 [foster.py] => Task 3, Epoch 61/170 => Loss 3.691, Loss_clf 0.490, Loss_fe 0.398, Loss_kd 2.586, Train_accy 78.30
2024-09-08 11:18:04,283 [foster.py] => Task 3, Epoch 62/170 => Loss 3.671, Loss_clf 0.485, Loss_fe 0.397, Loss_kd 2.573, Train_accy 79.43, Test_accy 75.55
2024-09-08 11:18:09,505 [foster.py] => Task 3, Epoch 63/170 => Loss 3.584, Loss_clf 0.433, Loss_fe 0.365, Loss_kd 2.570, Train_accy 80.57, Test_accy 75.52
2024-09-08 11:18:14,690 [foster.py] => Task 3, Epoch 64/170 => Loss 3.620, Loss_clf 0.451, Loss_fe 0.380, Loss_kd 2.572, Train_accy 80.54, Test_accy 75.26
2024-09-08 11:18:19,939 [foster.py] => Task 3, Epoch 65/170 => Loss 3.679, Loss_clf 0.486, Loss_fe 0.389, Loss_kd 2.587, Train_accy 78.78, Test_accy 75.15
2024-09-08 11:18:23,577 [foster.py] => Task 3, Epoch 66/170 => Loss 3.635, Loss_clf 0.460, Loss_fe 0.390, Loss_kd 2.570, Train_accy 79.49
2024-09-08 11:18:28,787 [foster.py] => Task 3, Epoch 67/170 => Loss 3.628, Loss_clf 0.457, Loss_fe 0.383, Loss_kd 2.572, Train_accy 80.51, Test_accy 75.38
2024-09-08 11:18:34,011 [foster.py] => Task 3, Epoch 68/170 => Loss 3.630, Loss_clf 0.454, Loss_fe 0.377, Loss_kd 2.583, Train_accy 81.14, Test_accy 75.43
2024-09-08 11:18:39,214 [foster.py] => Task 3, Epoch 69/170 => Loss 3.647, Loss_clf 0.482, Loss_fe 0.375, Loss_kd 2.574, Train_accy 79.11, Test_accy 74.51
2024-09-08 11:18:44,444 [foster.py] => Task 3, Epoch 70/170 => Loss 3.610, Loss_clf 0.450, Loss_fe 0.358, Loss_kd 2.585, Train_accy 81.32, Test_accy 75.86
2024-09-08 11:18:48,106 [foster.py] => Task 3, Epoch 71/170 => Loss 3.612, Loss_clf 0.452, Loss_fe 0.359, Loss_kd 2.584, Train_accy 79.65
2024-09-08 11:18:53,339 [foster.py] => Task 3, Epoch 72/170 => Loss 3.609, Loss_clf 0.449, Loss_fe 0.356, Loss_kd 2.587, Train_accy 81.32, Test_accy 75.98
2024-09-08 11:18:58,559 [foster.py] => Task 3, Epoch 73/170 => Loss 3.579, Loss_clf 0.440, Loss_fe 0.351, Loss_kd 2.572, Train_accy 81.81, Test_accy 75.40
2024-09-08 11:19:03,835 [foster.py] => Task 3, Epoch 74/170 => Loss 3.688, Loss_clf 0.495, Loss_fe 0.371, Loss_kd 2.604, Train_accy 80.49, Test_accy 75.80
2024-09-08 11:19:08,994 [foster.py] => Task 3, Epoch 75/170 => Loss 3.606, Loss_clf 0.461, Loss_fe 0.344, Loss_kd 2.585, Train_accy 81.46, Test_accy 75.18
2024-09-08 11:19:12,637 [foster.py] => Task 3, Epoch 76/170 => Loss 3.581, Loss_clf 0.443, Loss_fe 0.339, Loss_kd 2.583, Train_accy 81.46
2024-09-08 11:19:17,881 [foster.py] => Task 3, Epoch 77/170 => Loss 3.608, Loss_clf 0.452, Loss_fe 0.351, Loss_kd 2.588, Train_accy 81.78, Test_accy 75.51
2024-09-08 11:19:23,073 [foster.py] => Task 3, Epoch 78/170 => Loss 3.592, Loss_clf 0.449, Loss_fe 0.345, Loss_kd 2.581, Train_accy 79.78, Test_accy 75.88
2024-09-08 11:19:28,318 [foster.py] => Task 3, Epoch 79/170 => Loss 3.570, Loss_clf 0.433, Loss_fe 0.347, Loss_kd 2.574, Train_accy 81.70, Test_accy 75.58
2024-09-08 11:19:33,510 [foster.py] => Task 3, Epoch 80/170 => Loss 3.573, Loss_clf 0.445, Loss_fe 0.337, Loss_kd 2.575, Train_accy 80.32, Test_accy 74.97
2024-09-08 11:19:37,237 [foster.py] => Task 3, Epoch 81/170 => Loss 3.607, Loss_clf 0.444, Loss_fe 0.359, Loss_kd 2.587, Train_accy 81.46
2024-09-08 11:19:42,420 [foster.py] => Task 3, Epoch 82/170 => Loss 3.533, Loss_clf 0.428, Loss_fe 0.306, Loss_kd 2.582, Train_accy 82.00, Test_accy 75.68
2024-09-08 11:19:47,692 [foster.py] => Task 3, Epoch 83/170 => Loss 3.608, Loss_clf 0.459, Loss_fe 0.332, Loss_kd 2.599, Train_accy 81.62, Test_accy 75.48
2024-09-08 11:19:52,919 [foster.py] => Task 3, Epoch 84/170 => Loss 3.538, Loss_clf 0.426, Loss_fe 0.300, Loss_kd 2.594, Train_accy 81.86, Test_accy 75.28
2024-09-08 11:19:58,186 [foster.py] => Task 3, Epoch 85/170 => Loss 3.582, Loss_clf 0.449, Loss_fe 0.324, Loss_kd 2.591, Train_accy 82.00, Test_accy 75.57
2024-09-08 11:20:01,886 [foster.py] => Task 3, Epoch 86/170 => Loss 3.555, Loss_clf 0.437, Loss_fe 0.313, Loss_kd 2.588, Train_accy 82.51
2024-09-08 11:20:07,137 [foster.py] => Task 3, Epoch 87/170 => Loss 3.517, Loss_clf 0.420, Loss_fe 0.309, Loss_kd 2.573, Train_accy 82.30, Test_accy 75.08
2024-09-08 11:20:12,448 [foster.py] => Task 3, Epoch 88/170 => Loss 3.529, Loss_clf 0.421, Loss_fe 0.309, Loss_kd 2.583, Train_accy 82.73, Test_accy 76.00
2024-09-08 11:20:17,742 [foster.py] => Task 3, Epoch 89/170 => Loss 3.562, Loss_clf 0.452, Loss_fe 0.311, Loss_kd 2.583, Train_accy 82.76, Test_accy 74.14
2024-09-08 11:20:22,915 [foster.py] => Task 3, Epoch 90/170 => Loss 3.520, Loss_clf 0.408, Loss_fe 0.305, Loss_kd 2.589, Train_accy 83.14, Test_accy 75.35
2024-09-08 11:20:26,588 [foster.py] => Task 3, Epoch 91/170 => Loss 3.503, Loss_clf 0.420, Loss_fe 0.292, Loss_kd 2.576, Train_accy 82.86
2024-09-08 11:20:31,872 [foster.py] => Task 3, Epoch 92/170 => Loss 3.544, Loss_clf 0.439, Loss_fe 0.302, Loss_kd 2.587, Train_accy 82.46, Test_accy 75.62
2024-09-08 11:20:37,168 [foster.py] => Task 3, Epoch 93/170 => Loss 3.517, Loss_clf 0.412, Loss_fe 0.300, Loss_kd 2.588, Train_accy 83.49, Test_accy 75.95
2024-09-08 11:20:42,326 [foster.py] => Task 3, Epoch 94/170 => Loss 3.446, Loss_clf 0.380, Loss_fe 0.263, Loss_kd 2.586, Train_accy 84.05, Test_accy 75.58
2024-09-08 11:20:47,550 [foster.py] => Task 3, Epoch 95/170 => Loss 3.464, Loss_clf 0.396, Loss_fe 0.268, Loss_kd 2.583, Train_accy 84.35, Test_accy 75.91
2024-09-08 11:20:51,180 [foster.py] => Task 3, Epoch 96/170 => Loss 3.473, Loss_clf 0.401, Loss_fe 0.279, Loss_kd 2.577, Train_accy 83.95
2024-09-08 11:20:56,499 [foster.py] => Task 3, Epoch 97/170 => Loss 3.447, Loss_clf 0.376, Loss_fe 0.271, Loss_kd 2.582, Train_accy 83.73, Test_accy 75.86
2024-09-08 11:21:01,762 [foster.py] => Task 3, Epoch 98/170 => Loss 3.442, Loss_clf 0.378, Loss_fe 0.265, Loss_kd 2.583, Train_accy 83.86, Test_accy 76.08
2024-09-08 11:21:07,078 [foster.py] => Task 3, Epoch 99/170 => Loss 3.472, Loss_clf 0.399, Loss_fe 0.271, Loss_kd 2.585, Train_accy 83.27, Test_accy 75.46
2024-09-08 11:21:12,261 [foster.py] => Task 3, Epoch 100/170 => Loss 3.445, Loss_clf 0.384, Loss_fe 0.265, Loss_kd 2.580, Train_accy 83.92, Test_accy 76.02
2024-09-08 11:21:15,916 [foster.py] => Task 3, Epoch 101/170 => Loss 3.465, Loss_clf 0.386, Loss_fe 0.274, Loss_kd 2.587, Train_accy 85.19
2024-09-08 11:21:21,124 [foster.py] => Task 3, Epoch 102/170 => Loss 3.423, Loss_clf 0.383, Loss_fe 0.227, Loss_kd 2.594, Train_accy 84.46, Test_accy 75.51
2024-09-08 11:21:26,309 [foster.py] => Task 3, Epoch 103/170 => Loss 3.491, Loss_clf 0.413, Loss_fe 0.266, Loss_kd 2.593, Train_accy 83.54, Test_accy 75.83
2024-09-08 11:21:31,655 [foster.py] => Task 3, Epoch 104/170 => Loss 3.424, Loss_clf 0.376, Loss_fe 0.247, Loss_kd 2.584, Train_accy 85.38, Test_accy 75.89
2024-09-08 11:21:36,936 [foster.py] => Task 3, Epoch 105/170 => Loss 3.430, Loss_clf 0.383, Loss_fe 0.256, Loss_kd 2.575, Train_accy 84.35, Test_accy 75.97
2024-09-08 11:21:40,494 [foster.py] => Task 3, Epoch 106/170 => Loss 3.395, Loss_clf 0.362, Loss_fe 0.235, Loss_kd 2.581, Train_accy 85.51
2024-09-08 11:21:45,791 [foster.py] => Task 3, Epoch 107/170 => Loss 3.398, Loss_clf 0.369, Loss_fe 0.230, Loss_kd 2.582, Train_accy 85.30, Test_accy 75.83
2024-09-08 11:21:51,042 [foster.py] => Task 3, Epoch 108/170 => Loss 3.436, Loss_clf 0.381, Loss_fe 0.253, Loss_kd 2.585, Train_accy 84.68, Test_accy 75.45
2024-09-08 11:21:56,218 [foster.py] => Task 3, Epoch 109/170 => Loss 3.407, Loss_clf 0.370, Loss_fe 0.227, Loss_kd 2.592, Train_accy 85.22, Test_accy 76.15
2024-09-08 11:22:01,441 [foster.py] => Task 3, Epoch 110/170 => Loss 3.455, Loss_clf 0.392, Loss_fe 0.248, Loss_kd 2.597, Train_accy 84.65, Test_accy 75.69
2024-09-08 11:22:05,122 [foster.py] => Task 3, Epoch 111/170 => Loss 3.432, Loss_clf 0.386, Loss_fe 0.243, Loss_kd 2.586, Train_accy 84.57
2024-09-08 11:22:10,388 [foster.py] => Task 3, Epoch 112/170 => Loss 3.393, Loss_clf 0.366, Loss_fe 0.228, Loss_kd 2.583, Train_accy 86.08, Test_accy 75.82
2024-09-08 11:22:15,712 [foster.py] => Task 3, Epoch 113/170 => Loss 3.387, Loss_clf 0.366, Loss_fe 0.232, Loss_kd 2.573, Train_accy 84.57, Test_accy 76.02
2024-09-08 11:22:20,907 [foster.py] => Task 3, Epoch 114/170 => Loss 3.352, Loss_clf 0.354, Loss_fe 0.206, Loss_kd 2.576, Train_accy 86.05, Test_accy 76.20
2024-09-08 11:22:26,144 [foster.py] => Task 3, Epoch 115/170 => Loss 3.393, Loss_clf 0.368, Loss_fe 0.221, Loss_kd 2.587, Train_accy 85.49, Test_accy 76.03
2024-09-08 11:22:29,796 [foster.py] => Task 3, Epoch 116/170 => Loss 3.350, Loss_clf 0.340, Loss_fe 0.217, Loss_kd 2.577, Train_accy 86.97
2024-09-08 11:22:35,035 [foster.py] => Task 3, Epoch 117/170 => Loss 3.394, Loss_clf 0.364, Loss_fe 0.226, Loss_kd 2.587, Train_accy 85.57, Test_accy 75.82
2024-09-08 11:22:40,290 [foster.py] => Task 3, Epoch 118/170 => Loss 3.391, Loss_clf 0.373, Loss_fe 0.224, Loss_kd 2.578, Train_accy 85.41, Test_accy 75.92
2024-09-08 11:22:45,478 [foster.py] => Task 3, Epoch 119/170 => Loss 3.397, Loss_clf 0.371, Loss_fe 0.224, Loss_kd 2.585, Train_accy 85.65, Test_accy 75.80
2024-09-08 11:22:50,702 [foster.py] => Task 3, Epoch 120/170 => Loss 3.362, Loss_clf 0.356, Loss_fe 0.209, Loss_kd 2.580, Train_accy 85.95, Test_accy 75.86
2024-09-08 11:22:54,379 [foster.py] => Task 3, Epoch 121/170 => Loss 3.327, Loss_clf 0.338, Loss_fe 0.208, Loss_kd 2.566, Train_accy 86.78
2024-09-08 11:22:59,609 [foster.py] => Task 3, Epoch 122/170 => Loss 3.315, Loss_clf 0.324, Loss_fe 0.194, Loss_kd 2.581, Train_accy 87.35, Test_accy 75.80
2024-09-08 11:23:04,803 [foster.py] => Task 3, Epoch 123/170 => Loss 3.357, Loss_clf 0.352, Loss_fe 0.201, Loss_kd 2.586, Train_accy 87.19, Test_accy 75.74
2024-09-08 11:23:10,018 [foster.py] => Task 3, Epoch 124/170 => Loss 3.400, Loss_clf 0.377, Loss_fe 0.208, Loss_kd 2.597, Train_accy 86.24, Test_accy 76.12
2024-09-08 11:23:15,255 [foster.py] => Task 3, Epoch 125/170 => Loss 3.286, Loss_clf 0.315, Loss_fe 0.184, Loss_kd 2.571, Train_accy 87.00, Test_accy 76.14
2024-09-08 11:23:18,864 [foster.py] => Task 3, Epoch 126/170 => Loss 3.362, Loss_clf 0.357, Loss_fe 0.207, Loss_kd 2.581, Train_accy 86.76
2024-09-08 11:23:24,060 [foster.py] => Task 3, Epoch 127/170 => Loss 3.335, Loss_clf 0.349, Loss_fe 0.198, Loss_kd 2.572, Train_accy 86.81, Test_accy 76.05
2024-09-08 11:23:29,247 [foster.py] => Task 3, Epoch 128/170 => Loss 3.311, Loss_clf 0.323, Loss_fe 0.183, Loss_kd 2.588, Train_accy 88.19, Test_accy 75.94
2024-09-08 11:23:34,599 [foster.py] => Task 3, Epoch 129/170 => Loss 3.330, Loss_clf 0.343, Loss_fe 0.194, Loss_kd 2.577, Train_accy 86.49, Test_accy 75.83
2024-09-08 11:23:39,858 [foster.py] => Task 3, Epoch 130/170 => Loss 3.338, Loss_clf 0.343, Loss_fe 0.193, Loss_kd 2.585, Train_accy 87.30, Test_accy 75.85
2024-09-08 11:23:43,494 [foster.py] => Task 3, Epoch 131/170 => Loss 3.289, Loss_clf 0.320, Loss_fe 0.173, Loss_kd 2.579, Train_accy 87.76
2024-09-08 11:23:48,726 [foster.py] => Task 3, Epoch 132/170 => Loss 3.276, Loss_clf 0.314, Loss_fe 0.169, Loss_kd 2.577, Train_accy 88.41, Test_accy 75.82
2024-09-08 11:23:53,941 [foster.py] => Task 3, Epoch 133/170 => Loss 3.338, Loss_clf 0.339, Loss_fe 0.196, Loss_kd 2.586, Train_accy 87.62, Test_accy 76.05
2024-09-08 11:23:59,176 [foster.py] => Task 3, Epoch 134/170 => Loss 3.310, Loss_clf 0.327, Loss_fe 0.173, Loss_kd 2.592, Train_accy 87.73, Test_accy 76.02
2024-09-08 11:24:04,359 [foster.py] => Task 3, Epoch 135/170 => Loss 3.277, Loss_clf 0.308, Loss_fe 0.167, Loss_kd 2.586, Train_accy 88.59, Test_accy 75.72
2024-09-08 11:24:08,031 [foster.py] => Task 3, Epoch 136/170 => Loss 3.286, Loss_clf 0.323, Loss_fe 0.177, Loss_kd 2.570, Train_accy 87.84
2024-09-08 11:24:13,285 [foster.py] => Task 3, Epoch 137/170 => Loss 3.309, Loss_clf 0.325, Loss_fe 0.190, Loss_kd 2.578, Train_accy 87.84, Test_accy 75.62
2024-09-08 11:24:18,541 [foster.py] => Task 3, Epoch 138/170 => Loss 3.250, Loss_clf 0.305, Loss_fe 0.156, Loss_kd 2.573, Train_accy 88.35, Test_accy 76.03
2024-09-08 11:24:23,706 [foster.py] => Task 3, Epoch 139/170 => Loss 3.335, Loss_clf 0.339, Loss_fe 0.192, Loss_kd 2.587, Train_accy 87.22, Test_accy 76.05
2024-09-08 11:24:28,912 [foster.py] => Task 3, Epoch 140/170 => Loss 3.320, Loss_clf 0.335, Loss_fe 0.178, Loss_kd 2.590, Train_accy 87.24, Test_accy 75.97
2024-09-08 11:24:32,622 [foster.py] => Task 3, Epoch 141/170 => Loss 3.325, Loss_clf 0.338, Loss_fe 0.185, Loss_kd 2.585, Train_accy 87.65
2024-09-08 11:24:37,926 [foster.py] => Task 3, Epoch 142/170 => Loss 3.302, Loss_clf 0.330, Loss_fe 0.168, Loss_kd 2.587, Train_accy 87.35, Test_accy 75.92
2024-09-08 11:24:43,170 [foster.py] => Task 3, Epoch 143/170 => Loss 3.310, Loss_clf 0.327, Loss_fe 0.177, Loss_kd 2.589, Train_accy 88.76, Test_accy 75.92
2024-09-08 11:24:48,462 [foster.py] => Task 3, Epoch 144/170 => Loss 3.277, Loss_clf 0.309, Loss_fe 0.164, Loss_kd 2.587, Train_accy 88.59, Test_accy 75.94
2024-09-08 11:24:53,780 [foster.py] => Task 3, Epoch 145/170 => Loss 3.281, Loss_clf 0.321, Loss_fe 0.160, Loss_kd 2.583, Train_accy 87.62, Test_accy 76.03
2024-09-08 11:24:57,424 [foster.py] => Task 3, Epoch 146/170 => Loss 3.303, Loss_clf 0.338, Loss_fe 0.167, Loss_kd 2.581, Train_accy 88.00
2024-09-08 11:25:02,612 [foster.py] => Task 3, Epoch 147/170 => Loss 3.304, Loss_clf 0.328, Loss_fe 0.167, Loss_kd 2.591, Train_accy 88.62, Test_accy 75.94
2024-09-08 11:25:07,924 [foster.py] => Task 3, Epoch 148/170 => Loss 3.302, Loss_clf 0.334, Loss_fe 0.169, Loss_kd 2.581, Train_accy 87.89, Test_accy 75.92
2024-09-08 11:25:13,154 [foster.py] => Task 3, Epoch 149/170 => Loss 3.286, Loss_clf 0.319, Loss_fe 0.161, Loss_kd 2.589, Train_accy 88.70, Test_accy 75.92
2024-09-08 11:25:18,352 [foster.py] => Task 3, Epoch 150/170 => Loss 3.266, Loss_clf 0.308, Loss_fe 0.164, Loss_kd 2.578, Train_accy 88.51, Test_accy 75.82
2024-09-08 11:25:21,970 [foster.py] => Task 3, Epoch 151/170 => Loss 3.290, Loss_clf 0.318, Loss_fe 0.170, Loss_kd 2.586, Train_accy 88.14
2024-09-08 11:25:27,244 [foster.py] => Task 3, Epoch 152/170 => Loss 3.249, Loss_clf 0.317, Loss_fe 0.157, Loss_kd 2.561, Train_accy 88.65, Test_accy 75.97
2024-09-08 11:25:32,496 [foster.py] => Task 3, Epoch 153/170 => Loss 3.321, Loss_clf 0.336, Loss_fe 0.179, Loss_kd 2.589, Train_accy 87.78, Test_accy 75.91
2024-09-08 11:25:37,723 [foster.py] => Task 3, Epoch 154/170 => Loss 3.268, Loss_clf 0.319, Loss_fe 0.156, Loss_kd 2.577, Train_accy 88.00, Test_accy 76.05
2024-09-08 11:25:42,901 [foster.py] => Task 3, Epoch 155/170 => Loss 3.280, Loss_clf 0.312, Loss_fe 0.157, Loss_kd 2.594, Train_accy 88.68, Test_accy 75.94
2024-09-08 11:25:46,562 [foster.py] => Task 3, Epoch 156/170 => Loss 3.266, Loss_clf 0.324, Loss_fe 0.150, Loss_kd 2.576, Train_accy 87.81
2024-09-08 11:25:51,783 [foster.py] => Task 3, Epoch 157/170 => Loss 3.273, Loss_clf 0.315, Loss_fe 0.159, Loss_kd 2.582, Train_accy 88.70, Test_accy 76.03
2024-09-08 11:25:57,032 [foster.py] => Task 3, Epoch 158/170 => Loss 3.283, Loss_clf 0.321, Loss_fe 0.164, Loss_kd 2.581, Train_accy 88.46, Test_accy 76.02
2024-09-08 11:26:02,234 [foster.py] => Task 3, Epoch 159/170 => Loss 3.316, Loss_clf 0.339, Loss_fe 0.167, Loss_kd 2.592, Train_accy 88.03, Test_accy 76.03
2024-09-08 11:26:07,433 [foster.py] => Task 3, Epoch 160/170 => Loss 3.261, Loss_clf 0.313, Loss_fe 0.158, Loss_kd 2.574, Train_accy 88.14, Test_accy 76.12
2024-09-08 11:26:11,147 [foster.py] => Task 3, Epoch 161/170 => Loss 3.263, Loss_clf 0.311, Loss_fe 0.152, Loss_kd 2.583, Train_accy 89.24
2024-09-08 11:26:16,410 [foster.py] => Task 3, Epoch 162/170 => Loss 3.246, Loss_clf 0.304, Loss_fe 0.146, Loss_kd 2.580, Train_accy 88.41, Test_accy 76.00
2024-09-08 11:26:21,596 [foster.py] => Task 3, Epoch 163/170 => Loss 3.266, Loss_clf 0.300, Loss_fe 0.160, Loss_kd 2.588, Train_accy 88.68, Test_accy 76.02
2024-09-08 11:26:26,771 [foster.py] => Task 3, Epoch 164/170 => Loss 3.256, Loss_clf 0.316, Loss_fe 0.158, Loss_kd 2.568, Train_accy 88.05, Test_accy 76.02
2024-09-08 11:26:31,953 [foster.py] => Task 3, Epoch 165/170 => Loss 3.248, Loss_clf 0.299, Loss_fe 0.153, Loss_kd 2.580, Train_accy 88.70, Test_accy 76.05
2024-09-08 11:26:35,626 [foster.py] => Task 3, Epoch 166/170 => Loss 3.239, Loss_clf 0.295, Loss_fe 0.137, Loss_kd 2.590, Train_accy 88.65
2024-09-08 11:26:40,799 [foster.py] => Task 3, Epoch 167/170 => Loss 3.256, Loss_clf 0.315, Loss_fe 0.148, Loss_kd 2.577, Train_accy 88.41, Test_accy 75.86
2024-09-08 11:26:46,037 [foster.py] => Task 3, Epoch 168/170 => Loss 3.256, Loss_clf 0.291, Loss_fe 0.158, Loss_kd 2.589, Train_accy 90.00, Test_accy 76.05
2024-09-08 11:26:51,225 [foster.py] => Task 3, Epoch 169/170 => Loss 3.250, Loss_clf 0.301, Loss_fe 0.153, Loss_kd 2.580, Train_accy 88.59, Test_accy 76.08
2024-09-08 11:26:56,441 [foster.py] => Task 3, Epoch 170/170 => Loss 3.255, Loss_clf 0.295, Loss_fe 0.164, Loss_kd 2.580, Train_accy 89.57, Test_accy 76.05
2024-09-08 11:26:56,444 [foster.py] => do not weight align teacher!
2024-09-08 11:26:56,446 [foster.py] => per cls weights : [1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307 1.03803307
 0.54360315 0.54360315 0.54360315 0.54360315 0.54360315]
2024-09-08 11:27:02,813 [foster.py] => SNet: Task 3, Epoch 1/130 => Loss 29.032,  Loss1 0.713, Train_accy 31.00, Test_accy 69.74
2024-09-08 11:27:07,954 [foster.py] => SNet: Task 3, Epoch 2/130 => Loss 28.802,  Loss1 0.713, Train_accy 53.62
2024-09-08 11:27:13,103 [foster.py] => SNet: Task 3, Epoch 3/130 => Loss 28.782,  Loss1 0.713, Train_accy 58.38
2024-09-08 11:27:18,229 [foster.py] => SNet: Task 3, Epoch 4/130 => Loss 28.747,  Loss1 0.713, Train_accy 60.16
2024-09-08 11:27:23,360 [foster.py] => SNet: Task 3, Epoch 5/130 => Loss 28.708,  Loss1 0.713, Train_accy 63.11
2024-09-08 11:27:29,521 [foster.py] => SNet: Task 3, Epoch 6/130 => Loss 28.744,  Loss1 0.713, Train_accy 64.59, Test_accy 73.37
2024-09-08 11:27:34,638 [foster.py] => SNet: Task 3, Epoch 7/130 => Loss 28.655,  Loss1 0.713, Train_accy 66.86
2024-09-08 11:27:39,794 [foster.py] => SNet: Task 3, Epoch 8/130 => Loss 28.691,  Loss1 0.713, Train_accy 67.03
2024-09-08 11:27:44,980 [foster.py] => SNet: Task 3, Epoch 9/130 => Loss 28.708,  Loss1 0.713, Train_accy 68.05
2024-09-08 11:27:50,064 [foster.py] => SNet: Task 3, Epoch 10/130 => Loss 28.696,  Loss1 0.714, Train_accy 67.76
2024-09-08 11:27:56,281 [foster.py] => SNet: Task 3, Epoch 11/130 => Loss 28.687,  Loss1 0.713, Train_accy 69.49, Test_accy 73.77
2024-09-08 11:28:01,404 [foster.py] => SNet: Task 3, Epoch 12/130 => Loss 28.724,  Loss1 0.714, Train_accy 67.92
2024-09-08 11:28:06,556 [foster.py] => SNet: Task 3, Epoch 13/130 => Loss 28.689,  Loss1 0.714, Train_accy 69.43
2024-09-08 11:28:11,685 [foster.py] => SNet: Task 3, Epoch 14/130 => Loss 28.697,  Loss1 0.714, Train_accy 69.89
2024-09-08 11:28:16,804 [foster.py] => SNet: Task 3, Epoch 15/130 => Loss 28.687,  Loss1 0.714, Train_accy 69.32
2024-09-08 11:28:22,967 [foster.py] => SNet: Task 3, Epoch 16/130 => Loss 28.712,  Loss1 0.714, Train_accy 69.81, Test_accy 73.51
2024-09-08 11:28:28,039 [foster.py] => SNet: Task 3, Epoch 17/130 => Loss 28.723,  Loss1 0.714, Train_accy 69.73
2024-09-08 11:28:33,155 [foster.py] => SNet: Task 3, Epoch 18/130 => Loss 28.699,  Loss1 0.714, Train_accy 70.14
2024-09-08 11:28:38,237 [foster.py] => SNet: Task 3, Epoch 19/130 => Loss 28.663,  Loss1 0.714, Train_accy 70.27
2024-09-08 11:28:43,378 [foster.py] => SNet: Task 3, Epoch 20/130 => Loss 28.696,  Loss1 0.713, Train_accy 72.35
2024-09-08 11:28:49,532 [foster.py] => SNet: Task 3, Epoch 21/130 => Loss 28.671,  Loss1 0.714, Train_accy 71.00, Test_accy 74.29
2024-09-08 11:28:54,632 [foster.py] => SNet: Task 3, Epoch 22/130 => Loss 28.688,  Loss1 0.714, Train_accy 71.49
2024-09-08 11:28:59,741 [foster.py] => SNet: Task 3, Epoch 23/130 => Loss 28.693,  Loss1 0.714, Train_accy 72.11
2024-09-08 11:29:04,863 [foster.py] => SNet: Task 3, Epoch 24/130 => Loss 28.663,  Loss1 0.714, Train_accy 72.30
2024-09-08 11:29:09,983 [foster.py] => SNet: Task 3, Epoch 25/130 => Loss 28.654,  Loss1 0.714, Train_accy 72.51
2024-09-08 11:29:16,115 [foster.py] => SNet: Task 3, Epoch 26/130 => Loss 28.684,  Loss1 0.714, Train_accy 72.00, Test_accy 74.05
2024-09-08 11:29:21,238 [foster.py] => SNet: Task 3, Epoch 27/130 => Loss 28.687,  Loss1 0.714, Train_accy 72.16
2024-09-08 11:29:26,379 [foster.py] => SNet: Task 3, Epoch 28/130 => Loss 28.661,  Loss1 0.714, Train_accy 72.27
2024-09-08 11:29:31,564 [foster.py] => SNet: Task 3, Epoch 29/130 => Loss 28.685,  Loss1 0.714, Train_accy 72.08
2024-09-08 11:29:36,751 [foster.py] => SNet: Task 3, Epoch 30/130 => Loss 28.668,  Loss1 0.714, Train_accy 72.27
2024-09-08 11:29:42,929 [foster.py] => SNet: Task 3, Epoch 31/130 => Loss 28.675,  Loss1 0.714, Train_accy 72.00, Test_accy 74.42
2024-09-08 11:29:48,037 [foster.py] => SNet: Task 3, Epoch 32/130 => Loss 28.696,  Loss1 0.714, Train_accy 73.86
2024-09-08 11:29:53,186 [foster.py] => SNet: Task 3, Epoch 33/130 => Loss 28.674,  Loss1 0.714, Train_accy 73.49
2024-09-08 11:29:58,292 [foster.py] => SNet: Task 3, Epoch 34/130 => Loss 28.660,  Loss1 0.714, Train_accy 72.81
2024-09-08 11:30:03,408 [foster.py] => SNet: Task 3, Epoch 35/130 => Loss 28.661,  Loss1 0.714, Train_accy 74.62
2024-09-08 11:30:09,548 [foster.py] => SNet: Task 3, Epoch 36/130 => Loss 28.651,  Loss1 0.714, Train_accy 72.68, Test_accy 74.25
2024-09-08 11:30:14,698 [foster.py] => SNet: Task 3, Epoch 37/130 => Loss 28.688,  Loss1 0.714, Train_accy 73.54
2024-09-08 11:30:19,871 [foster.py] => SNet: Task 3, Epoch 38/130 => Loss 28.697,  Loss1 0.714, Train_accy 73.49
2024-09-08 11:30:25,007 [foster.py] => SNet: Task 3, Epoch 39/130 => Loss 28.681,  Loss1 0.714, Train_accy 72.89
2024-09-08 11:30:30,111 [foster.py] => SNet: Task 3, Epoch 40/130 => Loss 28.647,  Loss1 0.714, Train_accy 74.62
2024-09-08 11:30:36,287 [foster.py] => SNet: Task 3, Epoch 41/130 => Loss 28.681,  Loss1 0.714, Train_accy 74.14, Test_accy 74.57
2024-09-08 11:30:41,373 [foster.py] => SNet: Task 3, Epoch 42/130 => Loss 28.705,  Loss1 0.714, Train_accy 73.84
2024-09-08 11:30:46,524 [foster.py] => SNet: Task 3, Epoch 43/130 => Loss 28.668,  Loss1 0.714, Train_accy 74.46
2024-09-08 11:30:51,737 [foster.py] => SNet: Task 3, Epoch 44/130 => Loss 28.670,  Loss1 0.714, Train_accy 73.22
2024-09-08 11:30:56,878 [foster.py] => SNet: Task 3, Epoch 45/130 => Loss 28.685,  Loss1 0.714, Train_accy 74.19
2024-09-08 11:31:03,103 [foster.py] => SNet: Task 3, Epoch 46/130 => Loss 28.681,  Loss1 0.714, Train_accy 75.19, Test_accy 74.46
2024-09-08 11:31:08,240 [foster.py] => SNet: Task 3, Epoch 47/130 => Loss 28.664,  Loss1 0.714, Train_accy 74.16
2024-09-08 11:31:13,407 [foster.py] => SNet: Task 3, Epoch 48/130 => Loss 28.665,  Loss1 0.714, Train_accy 73.89
2024-09-08 11:31:18,485 [foster.py] => SNet: Task 3, Epoch 49/130 => Loss 28.686,  Loss1 0.714, Train_accy 74.30
2024-09-08 11:31:23,630 [foster.py] => SNet: Task 3, Epoch 50/130 => Loss 28.713,  Loss1 0.714, Train_accy 73.62
2024-09-08 11:31:29,760 [foster.py] => SNet: Task 3, Epoch 51/130 => Loss 28.675,  Loss1 0.714, Train_accy 75.16, Test_accy 74.32
2024-09-08 11:31:34,958 [foster.py] => SNet: Task 3, Epoch 52/130 => Loss 28.662,  Loss1 0.714, Train_accy 75.11
2024-09-08 11:31:40,080 [foster.py] => SNet: Task 3, Epoch 53/130 => Loss 28.674,  Loss1 0.714, Train_accy 75.11
2024-09-08 11:31:45,171 [foster.py] => SNet: Task 3, Epoch 54/130 => Loss 28.649,  Loss1 0.714, Train_accy 75.65
2024-09-08 11:31:50,317 [foster.py] => SNet: Task 3, Epoch 55/130 => Loss 28.683,  Loss1 0.714, Train_accy 74.81
2024-09-08 11:31:56,433 [foster.py] => SNet: Task 3, Epoch 56/130 => Loss 28.629,  Loss1 0.714, Train_accy 75.46, Test_accy 74.46
2024-09-08 11:32:01,621 [foster.py] => SNet: Task 3, Epoch 57/130 => Loss 28.666,  Loss1 0.714, Train_accy 74.76
2024-09-08 11:32:06,743 [foster.py] => SNet: Task 3, Epoch 58/130 => Loss 28.654,  Loss1 0.714, Train_accy 74.81
2024-09-08 11:32:11,815 [foster.py] => SNet: Task 3, Epoch 59/130 => Loss 28.658,  Loss1 0.714, Train_accy 74.92
2024-09-08 11:32:16,925 [foster.py] => SNet: Task 3, Epoch 60/130 => Loss 28.692,  Loss1 0.714, Train_accy 74.38
2024-09-08 11:32:23,063 [foster.py] => SNet: Task 3, Epoch 61/130 => Loss 28.664,  Loss1 0.714, Train_accy 75.22, Test_accy 74.69
2024-09-08 11:32:28,182 [foster.py] => SNet: Task 3, Epoch 62/130 => Loss 28.666,  Loss1 0.714, Train_accy 75.57
2024-09-08 11:32:33,331 [foster.py] => SNet: Task 3, Epoch 63/130 => Loss 28.670,  Loss1 0.714, Train_accy 74.89
2024-09-08 11:32:38,443 [foster.py] => SNet: Task 3, Epoch 64/130 => Loss 28.655,  Loss1 0.714, Train_accy 75.68
2024-09-08 11:32:43,550 [foster.py] => SNet: Task 3, Epoch 65/130 => Loss 28.637,  Loss1 0.714, Train_accy 75.86
2024-09-08 11:32:49,700 [foster.py] => SNet: Task 3, Epoch 66/130 => Loss 28.664,  Loss1 0.714, Train_accy 74.68, Test_accy 74.57
2024-09-08 11:32:54,793 [foster.py] => SNet: Task 3, Epoch 67/130 => Loss 28.682,  Loss1 0.714, Train_accy 74.54
2024-09-08 11:32:59,902 [foster.py] => SNet: Task 3, Epoch 68/130 => Loss 28.681,  Loss1 0.714, Train_accy 75.41
2024-09-08 11:33:05,032 [foster.py] => SNet: Task 3, Epoch 69/130 => Loss 28.661,  Loss1 0.714, Train_accy 75.81
2024-09-08 11:33:10,134 [foster.py] => SNet: Task 3, Epoch 70/130 => Loss 28.656,  Loss1 0.714, Train_accy 76.84
2024-09-08 11:33:16,302 [foster.py] => SNet: Task 3, Epoch 71/130 => Loss 28.644,  Loss1 0.714, Train_accy 75.76, Test_accy 74.78
2024-09-08 11:33:21,393 [foster.py] => SNet: Task 3, Epoch 72/130 => Loss 28.676,  Loss1 0.714, Train_accy 75.62
2024-09-08 11:33:26,493 [foster.py] => SNet: Task 3, Epoch 73/130 => Loss 28.667,  Loss1 0.714, Train_accy 74.43
2024-09-08 11:33:31,630 [foster.py] => SNet: Task 3, Epoch 74/130 => Loss 28.687,  Loss1 0.714, Train_accy 75.92
2024-09-08 11:33:36,744 [foster.py] => SNet: Task 3, Epoch 75/130 => Loss 28.674,  Loss1 0.714, Train_accy 74.65
2024-09-08 11:33:42,898 [foster.py] => SNet: Task 3, Epoch 76/130 => Loss 28.663,  Loss1 0.714, Train_accy 74.86, Test_accy 74.95
2024-09-08 11:33:48,005 [foster.py] => SNet: Task 3, Epoch 77/130 => Loss 28.667,  Loss1 0.714, Train_accy 76.35
2024-09-08 11:33:53,111 [foster.py] => SNet: Task 3, Epoch 78/130 => Loss 28.666,  Loss1 0.714, Train_accy 75.24
2024-09-08 11:33:58,245 [foster.py] => SNet: Task 3, Epoch 79/130 => Loss 28.667,  Loss1 0.714, Train_accy 76.22
2024-09-08 11:34:03,364 [foster.py] => SNet: Task 3, Epoch 80/130 => Loss 28.629,  Loss1 0.714, Train_accy 75.38
2024-09-08 11:34:09,508 [foster.py] => SNet: Task 3, Epoch 81/130 => Loss 28.659,  Loss1 0.715, Train_accy 75.57, Test_accy 74.72
2024-09-08 11:34:14,659 [foster.py] => SNet: Task 3, Epoch 82/130 => Loss 28.653,  Loss1 0.714, Train_accy 75.68
2024-09-08 11:34:19,784 [foster.py] => SNet: Task 3, Epoch 83/130 => Loss 28.666,  Loss1 0.714, Train_accy 75.86
2024-09-08 11:34:24,905 [foster.py] => SNet: Task 3, Epoch 84/130 => Loss 28.697,  Loss1 0.714, Train_accy 75.41
2024-09-08 11:34:30,091 [foster.py] => SNet: Task 3, Epoch 85/130 => Loss 28.647,  Loss1 0.714, Train_accy 76.00
2024-09-08 11:34:36,231 [foster.py] => SNet: Task 3, Epoch 86/130 => Loss 28.655,  Loss1 0.714, Train_accy 75.32, Test_accy 74.62
2024-09-08 11:34:41,364 [foster.py] => SNet: Task 3, Epoch 87/130 => Loss 28.670,  Loss1 0.714, Train_accy 76.38
2024-09-08 11:34:46,486 [foster.py] => SNet: Task 3, Epoch 88/130 => Loss 28.628,  Loss1 0.714, Train_accy 75.57
2024-09-08 11:34:51,625 [foster.py] => SNet: Task 3, Epoch 89/130 => Loss 28.661,  Loss1 0.714, Train_accy 75.57
2024-09-08 11:34:56,747 [foster.py] => SNet: Task 3, Epoch 90/130 => Loss 28.698,  Loss1 0.714, Train_accy 75.76
2024-09-08 11:35:02,954 [foster.py] => SNet: Task 3, Epoch 91/130 => Loss 28.665,  Loss1 0.714, Train_accy 76.11, Test_accy 74.77
2024-09-08 11:35:08,100 [foster.py] => SNet: Task 3, Epoch 92/130 => Loss 28.651,  Loss1 0.714, Train_accy 75.57
2024-09-08 11:35:13,224 [foster.py] => SNet: Task 3, Epoch 93/130 => Loss 28.647,  Loss1 0.714, Train_accy 76.62
2024-09-08 11:35:18,340 [foster.py] => SNet: Task 3, Epoch 94/130 => Loss 28.667,  Loss1 0.714, Train_accy 76.11
2024-09-08 11:35:23,456 [foster.py] => SNet: Task 3, Epoch 95/130 => Loss 28.654,  Loss1 0.714, Train_accy 75.95
2024-09-08 11:35:29,539 [foster.py] => SNet: Task 3, Epoch 96/130 => Loss 28.648,  Loss1 0.714, Train_accy 75.76, Test_accy 74.75
2024-09-08 11:35:34,608 [foster.py] => SNet: Task 3, Epoch 97/130 => Loss 28.662,  Loss1 0.714, Train_accy 76.03
2024-09-08 11:35:39,818 [foster.py] => SNet: Task 3, Epoch 98/130 => Loss 28.641,  Loss1 0.714, Train_accy 75.49
2024-09-08 11:35:44,924 [foster.py] => SNet: Task 3, Epoch 99/130 => Loss 28.652,  Loss1 0.714, Train_accy 76.38
2024-09-08 11:35:50,053 [foster.py] => SNet: Task 3, Epoch 100/130 => Loss 28.678,  Loss1 0.714, Train_accy 75.89
2024-09-08 11:35:56,165 [foster.py] => SNet: Task 3, Epoch 101/130 => Loss 28.666,  Loss1 0.714, Train_accy 76.30, Test_accy 74.68
2024-09-08 11:36:01,306 [foster.py] => SNet: Task 3, Epoch 102/130 => Loss 28.671,  Loss1 0.714, Train_accy 75.51
2024-09-08 11:36:06,458 [foster.py] => SNet: Task 3, Epoch 103/130 => Loss 28.645,  Loss1 0.714, Train_accy 75.41
2024-09-08 11:36:11,595 [foster.py] => SNet: Task 3, Epoch 104/130 => Loss 28.670,  Loss1 0.715, Train_accy 77.46
2024-09-08 11:36:16,717 [foster.py] => SNet: Task 3, Epoch 105/130 => Loss 28.654,  Loss1 0.714, Train_accy 75.16
2024-09-08 11:36:22,883 [foster.py] => SNet: Task 3, Epoch 106/130 => Loss 28.659,  Loss1 0.714, Train_accy 75.78, Test_accy 74.75
2024-09-08 11:36:28,011 [foster.py] => SNet: Task 3, Epoch 107/130 => Loss 28.691,  Loss1 0.714, Train_accy 76.00
2024-09-08 11:36:33,153 [foster.py] => SNet: Task 3, Epoch 108/130 => Loss 28.633,  Loss1 0.714, Train_accy 76.24
2024-09-08 11:36:38,292 [foster.py] => SNet: Task 3, Epoch 109/130 => Loss 28.665,  Loss1 0.714, Train_accy 76.22
2024-09-08 11:36:43,409 [foster.py] => SNet: Task 3, Epoch 110/130 => Loss 28.670,  Loss1 0.714, Train_accy 76.22
2024-09-08 11:36:49,563 [foster.py] => SNet: Task 3, Epoch 111/130 => Loss 28.690,  Loss1 0.714, Train_accy 76.59, Test_accy 74.74
2024-09-08 11:36:54,823 [foster.py] => SNet: Task 3, Epoch 112/130 => Loss 28.637,  Loss1 0.714, Train_accy 76.41
2024-09-08 11:36:59,919 [foster.py] => SNet: Task 3, Epoch 113/130 => Loss 28.645,  Loss1 0.714, Train_accy 76.70
2024-09-08 11:37:05,059 [foster.py] => SNet: Task 3, Epoch 114/130 => Loss 28.675,  Loss1 0.714, Train_accy 76.68
2024-09-08 11:37:10,169 [foster.py] => SNet: Task 3, Epoch 115/130 => Loss 28.676,  Loss1 0.714, Train_accy 76.30
2024-09-08 11:37:16,260 [foster.py] => SNet: Task 3, Epoch 116/130 => Loss 28.674,  Loss1 0.714, Train_accy 75.78, Test_accy 74.82
2024-09-08 11:37:21,346 [foster.py] => SNet: Task 3, Epoch 117/130 => Loss 28.677,  Loss1 0.714, Train_accy 76.46
2024-09-08 11:37:26,454 [foster.py] => SNet: Task 3, Epoch 118/130 => Loss 28.669,  Loss1 0.714, Train_accy 76.49
2024-09-08 11:37:31,574 [foster.py] => SNet: Task 3, Epoch 119/130 => Loss 28.672,  Loss1 0.714, Train_accy 75.43
2024-09-08 11:37:36,672 [foster.py] => SNet: Task 3, Epoch 120/130 => Loss 28.668,  Loss1 0.714, Train_accy 76.92
2024-09-08 11:37:42,829 [foster.py] => SNet: Task 3, Epoch 121/130 => Loss 28.646,  Loss1 0.714, Train_accy 75.03, Test_accy 74.60
2024-09-08 11:37:47,993 [foster.py] => SNet: Task 3, Epoch 122/130 => Loss 28.674,  Loss1 0.714, Train_accy 75.70
2024-09-08 11:37:53,141 [foster.py] => SNet: Task 3, Epoch 123/130 => Loss 28.678,  Loss1 0.714, Train_accy 76.16
2024-09-08 11:37:58,277 [foster.py] => SNet: Task 3, Epoch 124/130 => Loss 28.667,  Loss1 0.714, Train_accy 75.54
2024-09-08 11:38:03,458 [foster.py] => SNet: Task 3, Epoch 125/130 => Loss 28.651,  Loss1 0.714, Train_accy 75.49
2024-09-08 11:38:09,652 [foster.py] => SNet: Task 3, Epoch 126/130 => Loss 28.666,  Loss1 0.714, Train_accy 76.00, Test_accy 74.82
2024-09-08 11:38:14,760 [foster.py] => SNet: Task 3, Epoch 127/130 => Loss 28.653,  Loss1 0.714, Train_accy 74.97
2024-09-08 11:38:19,893 [foster.py] => SNet: Task 3, Epoch 128/130 => Loss 28.673,  Loss1 0.714, Train_accy 76.00
2024-09-08 11:38:25,030 [foster.py] => SNet: Task 3, Epoch 129/130 => Loss 28.678,  Loss1 0.714, Train_accy 76.57
2024-09-08 11:38:30,195 [foster.py] => SNet: Task 3, Epoch 130/130 => Loss 28.677,  Loss1 0.714, Train_accy 76.30
2024-09-08 11:38:30,196 [foster.py] => do not weight align student!
2024-09-08 11:38:31,211 [foster.py] => darknet eval: 
2024-09-08 11:38:31,211 [foster.py] => CNN top1 curve: 74.97
2024-09-08 11:38:31,212 [foster.py] => CNN top5 curve: 94.35
2024-09-08 11:38:31,212 [foster.py] => CNN top1 平均值: 74.97
2024-09-08 11:38:31,217 [foster.py] => timees : 1531.0838820934296
2024-09-08 11:38:31,217 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 11:38:52,421 [foster.py] => Exemplar size: 1300
2024-09-08 11:38:52,421 [trainer.py] => CNN: {'total': 76.05, '00-09': 82.9, '10-19': 72.4, '20-29': 79.4, '30-39': 76.2, '40-49': 79.1, '50-59': 63.8, '60-69': 81.0, 'old': 75.63, 'new': 81.0}
2024-09-08 11:38:52,421 [trainer.py] => NME: {'total': 70.89, '00-09': 77.1, '10-19': 68.5, '20-29': 78.2, '30-39': 70.8, '40-49': 73.6, '50-59': 48.5, '60-69': 88.2, 'old': 69.45, 'new': 88.2}
2024-09-08 11:38:52,421 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05]
2024-09-08 11:38:52,421 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85]
2024-09-08 11:38:52,421 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89]
2024-09-08 11:38:52,421 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29]

2024-09-08 11:38:52,421 [trainer.py] => CNN top1 平均值: 79.00
2024-09-08 11:38:52,424 [trainer.py] => All params: 1171058
2024-09-08 11:38:52,426 [trainer.py] => Trainable params: 589884
2024-09-08 11:38:52,487 [foster.py] => Learning on 65-70
2024-09-08 11:38:52,490 [foster.py] => All params: 1172353
2024-09-08 11:38:52,492 [foster.py] => Trainable params: 590854
2024-09-08 11:38:52,541 [foster.py] => per cls weights : [1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805
 1.02868805 1.02868805 1.02868805 1.02868805 1.02868805 0.62705532
 0.62705532 0.62705532 0.62705532 0.62705532]
2024-09-08 11:38:56,428 [foster.py] => Task 4, Epoch 1/170 => Loss 5.919, Loss_clf 1.614, Loss_fe 1.541, Loss_kd 2.565, Train_accy 58.63
2024-09-08 11:39:01,799 [foster.py] => Task 4, Epoch 2/170 => Loss 4.374, Loss_clf 0.763, Loss_fe 0.875, Loss_kd 2.539, Train_accy 65.29, Test_accy 72.01
2024-09-08 11:39:07,206 [foster.py] => Task 4, Epoch 3/170 => Loss 4.140, Loss_clf 0.660, Loss_fe 0.755, Loss_kd 2.529, Train_accy 66.74, Test_accy 72.23
2024-09-08 11:39:12,665 [foster.py] => Task 4, Epoch 4/170 => Loss 4.124, Loss_clf 0.657, Loss_fe 0.732, Loss_kd 2.538, Train_accy 67.24, Test_accy 73.29
2024-09-08 11:39:18,164 [foster.py] => Task 4, Epoch 5/170 => Loss 3.983, Loss_clf 0.621, Loss_fe 0.643, Loss_kd 2.523, Train_accy 66.55, Test_accy 72.07
2024-09-08 11:39:21,990 [foster.py] => Task 4, Epoch 6/170 => Loss 4.045, Loss_clf 0.650, Loss_fe 0.668, Loss_kd 2.531, Train_accy 68.50
2024-09-08 11:39:27,512 [foster.py] => Task 4, Epoch 7/170 => Loss 4.040, Loss_clf 0.652, Loss_fe 0.653, Loss_kd 2.538, Train_accy 67.18, Test_accy 73.51
2024-09-08 11:39:33,040 [foster.py] => Task 4, Epoch 8/170 => Loss 3.986, Loss_clf 0.616, Loss_fe 0.623, Loss_kd 2.549, Train_accy 68.32, Test_accy 71.04
2024-09-08 11:39:38,469 [foster.py] => Task 4, Epoch 9/170 => Loss 3.943, Loss_clf 0.608, Loss_fe 0.615, Loss_kd 2.524, Train_accy 69.97, Test_accy 73.10
2024-09-08 11:39:43,885 [foster.py] => Task 4, Epoch 10/170 => Loss 3.952, Loss_clf 0.607, Loss_fe 0.601, Loss_kd 2.547, Train_accy 70.32, Test_accy 73.70
2024-09-08 11:39:47,635 [foster.py] => Task 4, Epoch 11/170 => Loss 3.856, Loss_clf 0.556, Loss_fe 0.581, Loss_kd 2.523, Train_accy 71.53
2024-09-08 11:39:53,050 [foster.py] => Task 4, Epoch 12/170 => Loss 3.841, Loss_clf 0.557, Loss_fe 0.564, Loss_kd 2.525, Train_accy 71.89, Test_accy 73.29
2024-09-08 11:39:58,538 [foster.py] => Task 4, Epoch 13/170 => Loss 3.885, Loss_clf 0.589, Loss_fe 0.569, Loss_kd 2.530, Train_accy 70.47, Test_accy 72.61
2024-09-08 11:40:03,954 [foster.py] => Task 4, Epoch 14/170 => Loss 3.874, Loss_clf 0.577, Loss_fe 0.570, Loss_kd 2.530, Train_accy 70.55, Test_accy 72.74
2024-09-08 11:40:09,379 [foster.py] => Task 4, Epoch 15/170 => Loss 3.896, Loss_clf 0.597, Loss_fe 0.552, Loss_kd 2.550, Train_accy 70.34, Test_accy 74.04
2024-09-08 11:40:13,120 [foster.py] => Task 4, Epoch 16/170 => Loss 3.839, Loss_clf 0.549, Loss_fe 0.557, Loss_kd 2.536, Train_accy 72.18
2024-09-08 11:40:18,653 [foster.py] => Task 4, Epoch 17/170 => Loss 3.859, Loss_clf 0.569, Loss_fe 0.549, Loss_kd 2.544, Train_accy 70.76, Test_accy 73.24
2024-09-08 11:40:24,126 [foster.py] => Task 4, Epoch 18/170 => Loss 3.802, Loss_clf 0.555, Loss_fe 0.526, Loss_kd 2.525, Train_accy 71.21, Test_accy 73.60
2024-09-08 11:40:29,543 [foster.py] => Task 4, Epoch 19/170 => Loss 3.824, Loss_clf 0.554, Loss_fe 0.545, Loss_kd 2.528, Train_accy 72.87, Test_accy 73.86
2024-09-08 11:40:34,982 [foster.py] => Task 4, Epoch 20/170 => Loss 3.817, Loss_clf 0.574, Loss_fe 0.511, Loss_kd 2.535, Train_accy 72.26, Test_accy 72.64
2024-09-08 11:40:38,750 [foster.py] => Task 4, Epoch 21/170 => Loss 3.752, Loss_clf 0.530, Loss_fe 0.482, Loss_kd 2.543, Train_accy 73.87
2024-09-08 11:40:44,212 [foster.py] => Task 4, Epoch 22/170 => Loss 3.788, Loss_clf 0.546, Loss_fe 0.507, Loss_kd 2.538, Train_accy 74.32, Test_accy 72.06
2024-09-08 11:40:49,685 [foster.py] => Task 4, Epoch 23/170 => Loss 3.731, Loss_clf 0.520, Loss_fe 0.499, Loss_kd 2.516, Train_accy 74.16, Test_accy 73.46
2024-09-08 11:40:55,213 [foster.py] => Task 4, Epoch 24/170 => Loss 3.724, Loss_clf 0.513, Loss_fe 0.494, Loss_kd 2.522, Train_accy 74.42, Test_accy 72.77
2024-09-08 11:41:00,616 [foster.py] => Task 4, Epoch 25/170 => Loss 3.729, Loss_clf 0.526, Loss_fe 0.481, Loss_kd 2.526, Train_accy 73.76, Test_accy 73.99
2024-09-08 11:41:04,359 [foster.py] => Task 4, Epoch 26/170 => Loss 3.793, Loss_clf 0.556, Loss_fe 0.496, Loss_kd 2.545, Train_accy 73.84
2024-09-08 11:41:09,822 [foster.py] => Task 4, Epoch 27/170 => Loss 3.731, Loss_clf 0.517, Loss_fe 0.494, Loss_kd 2.524, Train_accy 75.39, Test_accy 74.16
2024-09-08 11:41:15,308 [foster.py] => Task 4, Epoch 28/170 => Loss 3.742, Loss_clf 0.532, Loss_fe 0.474, Loss_kd 2.539, Train_accy 73.74, Test_accy 74.03
2024-09-08 11:41:20,720 [foster.py] => Task 4, Epoch 29/170 => Loss 3.701, Loss_clf 0.517, Loss_fe 0.461, Loss_kd 2.527, Train_accy 75.82, Test_accy 73.30
2024-09-08 11:41:26,259 [foster.py] => Task 4, Epoch 30/170 => Loss 3.745, Loss_clf 0.528, Loss_fe 0.484, Loss_kd 2.537, Train_accy 74.03, Test_accy 73.73
2024-09-08 11:41:29,983 [foster.py] => Task 4, Epoch 31/170 => Loss 3.689, Loss_clf 0.521, Loss_fe 0.444, Loss_kd 2.528, Train_accy 75.82
2024-09-08 11:41:35,450 [foster.py] => Task 4, Epoch 32/170 => Loss 3.710, Loss_clf 0.508, Loss_fe 0.458, Loss_kd 2.547, Train_accy 75.26, Test_accy 73.19
2024-09-08 11:41:40,955 [foster.py] => Task 4, Epoch 33/170 => Loss 3.736, Loss_clf 0.538, Loss_fe 0.474, Loss_kd 2.527, Train_accy 73.32, Test_accy 73.74
2024-09-08 11:41:46,414 [foster.py] => Task 4, Epoch 34/170 => Loss 3.701, Loss_clf 0.513, Loss_fe 0.451, Loss_kd 2.540, Train_accy 74.71, Test_accy 72.90
2024-09-08 11:41:51,925 [foster.py] => Task 4, Epoch 35/170 => Loss 3.655, Loss_clf 0.508, Loss_fe 0.422, Loss_kd 2.529, Train_accy 76.89, Test_accy 73.97
2024-09-08 11:41:55,755 [foster.py] => Task 4, Epoch 36/170 => Loss 3.674, Loss_clf 0.504, Loss_fe 0.435, Loss_kd 2.538, Train_accy 75.08
2024-09-08 11:42:01,184 [foster.py] => Task 4, Epoch 37/170 => Loss 3.639, Loss_clf 0.480, Loss_fe 0.426, Loss_kd 2.537, Train_accy 76.29, Test_accy 73.90
2024-09-08 11:42:06,647 [foster.py] => Task 4, Epoch 38/170 => Loss 3.626, Loss_clf 0.486, Loss_fe 0.403, Loss_kd 2.540, Train_accy 76.79, Test_accy 74.00
2024-09-08 11:42:12,088 [foster.py] => Task 4, Epoch 39/170 => Loss 3.654, Loss_clf 0.498, Loss_fe 0.430, Loss_kd 2.529, Train_accy 77.37, Test_accy 73.99
2024-09-08 11:42:17,468 [foster.py] => Task 4, Epoch 40/170 => Loss 3.605, Loss_clf 0.474, Loss_fe 0.404, Loss_kd 2.531, Train_accy 76.87, Test_accy 73.91
2024-09-08 11:42:21,203 [foster.py] => Task 4, Epoch 41/170 => Loss 3.683, Loss_clf 0.509, Loss_fe 0.447, Loss_kd 2.531, Train_accy 76.21
2024-09-08 11:42:26,585 [foster.py] => Task 4, Epoch 42/170 => Loss 3.617, Loss_clf 0.470, Loss_fe 0.412, Loss_kd 2.538, Train_accy 77.34, Test_accy 74.01
2024-09-08 11:42:32,087 [foster.py] => Task 4, Epoch 43/170 => Loss 3.636, Loss_clf 0.478, Loss_fe 0.437, Loss_kd 2.525, Train_accy 77.13, Test_accy 73.97
2024-09-08 11:42:37,595 [foster.py] => Task 4, Epoch 44/170 => Loss 3.641, Loss_clf 0.489, Loss_fe 0.412, Loss_kd 2.543, Train_accy 76.42, Test_accy 73.04
2024-09-08 11:42:43,085 [foster.py] => Task 4, Epoch 45/170 => Loss 3.615, Loss_clf 0.490, Loss_fe 0.396, Loss_kd 2.532, Train_accy 75.58, Test_accy 73.86
2024-09-08 11:42:46,889 [foster.py] => Task 4, Epoch 46/170 => Loss 3.598, Loss_clf 0.468, Loss_fe 0.395, Loss_kd 2.538, Train_accy 77.68
2024-09-08 11:42:52,366 [foster.py] => Task 4, Epoch 47/170 => Loss 3.621, Loss_clf 0.478, Loss_fe 0.412, Loss_kd 2.535, Train_accy 78.26, Test_accy 74.19
2024-09-08 11:42:57,784 [foster.py] => Task 4, Epoch 48/170 => Loss 3.585, Loss_clf 0.461, Loss_fe 0.389, Loss_kd 2.538, Train_accy 77.58, Test_accy 74.14
2024-09-08 11:43:03,178 [foster.py] => Task 4, Epoch 49/170 => Loss 3.567, Loss_clf 0.468, Loss_fe 0.375, Loss_kd 2.528, Train_accy 76.79, Test_accy 72.74
2024-09-08 11:43:08,685 [foster.py] => Task 4, Epoch 50/170 => Loss 3.595, Loss_clf 0.481, Loss_fe 0.389, Loss_kd 2.528, Train_accy 77.58, Test_accy 73.46
2024-09-08 11:43:12,489 [foster.py] => Task 4, Epoch 51/170 => Loss 3.638, Loss_clf 0.498, Loss_fe 0.399, Loss_kd 2.543, Train_accy 76.89
2024-09-08 11:43:17,977 [foster.py] => Task 4, Epoch 52/170 => Loss 3.591, Loss_clf 0.494, Loss_fe 0.378, Loss_kd 2.523, Train_accy 78.26, Test_accy 74.06
2024-09-08 11:43:23,467 [foster.py] => Task 4, Epoch 53/170 => Loss 3.628, Loss_clf 0.506, Loss_fe 0.386, Loss_kd 2.540, Train_accy 77.13, Test_accy 74.27
2024-09-08 11:43:29,029 [foster.py] => Task 4, Epoch 54/170 => Loss 3.568, Loss_clf 0.463, Loss_fe 0.378, Loss_kd 2.531, Train_accy 78.08, Test_accy 73.89
2024-09-08 11:43:34,470 [foster.py] => Task 4, Epoch 55/170 => Loss 3.542, Loss_clf 0.451, Loss_fe 0.374, Loss_kd 2.522, Train_accy 79.26, Test_accy 74.29
2024-09-08 11:43:38,233 [foster.py] => Task 4, Epoch 56/170 => Loss 3.510, Loss_clf 0.432, Loss_fe 0.350, Loss_kd 2.532, Train_accy 79.84
2024-09-08 11:43:43,666 [foster.py] => Task 4, Epoch 57/170 => Loss 3.500, Loss_clf 0.439, Loss_fe 0.345, Loss_kd 2.520, Train_accy 80.29, Test_accy 73.64
2024-09-08 11:43:49,051 [foster.py] => Task 4, Epoch 58/170 => Loss 3.511, Loss_clf 0.438, Loss_fe 0.341, Loss_kd 2.535, Train_accy 78.18, Test_accy 74.59
2024-09-08 11:43:54,575 [foster.py] => Task 4, Epoch 59/170 => Loss 3.539, Loss_clf 0.453, Loss_fe 0.356, Loss_kd 2.534, Train_accy 78.68, Test_accy 74.37
2024-09-08 11:44:00,000 [foster.py] => Task 4, Epoch 60/170 => Loss 3.558, Loss_clf 0.453, Loss_fe 0.363, Loss_kd 2.545, Train_accy 79.42, Test_accy 74.29
2024-09-08 11:44:03,770 [foster.py] => Task 4, Epoch 61/170 => Loss 3.505, Loss_clf 0.443, Loss_fe 0.342, Loss_kd 2.524, Train_accy 79.87
2024-09-08 11:44:09,234 [foster.py] => Task 4, Epoch 62/170 => Loss 3.465, Loss_clf 0.420, Loss_fe 0.333, Loss_kd 2.516, Train_accy 79.45, Test_accy 74.19
2024-09-08 11:44:14,638 [foster.py] => Task 4, Epoch 63/170 => Loss 3.489, Loss_clf 0.435, Loss_fe 0.334, Loss_kd 2.524, Train_accy 79.26, Test_accy 74.04
2024-09-08 11:44:20,084 [foster.py] => Task 4, Epoch 64/170 => Loss 3.470, Loss_clf 0.421, Loss_fe 0.335, Loss_kd 2.520, Train_accy 81.03, Test_accy 74.56
2024-09-08 11:44:25,499 [foster.py] => Task 4, Epoch 65/170 => Loss 3.562, Loss_clf 0.464, Loss_fe 0.355, Loss_kd 2.546, Train_accy 78.32, Test_accy 74.47
2024-09-08 11:44:29,276 [foster.py] => Task 4, Epoch 66/170 => Loss 3.473, Loss_clf 0.417, Loss_fe 0.324, Loss_kd 2.536, Train_accy 80.42
2024-09-08 11:44:34,650 [foster.py] => Task 4, Epoch 67/170 => Loss 3.445, Loss_clf 0.408, Loss_fe 0.323, Loss_kd 2.519, Train_accy 81.37, Test_accy 74.73
2024-09-08 11:44:40,176 [foster.py] => Task 4, Epoch 68/170 => Loss 3.520, Loss_clf 0.449, Loss_fe 0.317, Loss_kd 2.556, Train_accy 80.61, Test_accy 73.70
2024-09-08 11:44:45,648 [foster.py] => Task 4, Epoch 69/170 => Loss 3.499, Loss_clf 0.443, Loss_fe 0.309, Loss_kd 2.550, Train_accy 80.05, Test_accy 74.71
2024-09-08 11:44:50,997 [foster.py] => Task 4, Epoch 70/170 => Loss 3.516, Loss_clf 0.452, Loss_fe 0.330, Loss_kd 2.538, Train_accy 79.97, Test_accy 74.66
2024-09-08 11:44:54,754 [foster.py] => Task 4, Epoch 71/170 => Loss 3.506, Loss_clf 0.451, Loss_fe 0.324, Loss_kd 2.534, Train_accy 79.66
2024-09-08 11:45:00,237 [foster.py] => Task 4, Epoch 72/170 => Loss 3.463, Loss_clf 0.426, Loss_fe 0.318, Loss_kd 2.523, Train_accy 79.84, Test_accy 73.94
2024-09-08 11:45:05,709 [foster.py] => Task 4, Epoch 73/170 => Loss 3.500, Loss_clf 0.445, Loss_fe 0.319, Loss_kd 2.539, Train_accy 79.37, Test_accy 74.06
2024-09-08 11:45:11,109 [foster.py] => Task 4, Epoch 74/170 => Loss 3.448, Loss_clf 0.423, Loss_fe 0.304, Loss_kd 2.524, Train_accy 80.55, Test_accy 74.87
2024-09-08 11:45:16,568 [foster.py] => Task 4, Epoch 75/170 => Loss 3.460, Loss_clf 0.419, Loss_fe 0.307, Loss_kd 2.537, Train_accy 80.34, Test_accy 74.39
2024-09-08 11:45:20,287 [foster.py] => Task 4, Epoch 76/170 => Loss 3.492, Loss_clf 0.445, Loss_fe 0.313, Loss_kd 2.538, Train_accy 80.32
2024-09-08 11:45:25,694 [foster.py] => Task 4, Epoch 77/170 => Loss 3.461, Loss_clf 0.447, Loss_fe 0.292, Loss_kd 2.526, Train_accy 80.42, Test_accy 73.94
2024-09-08 11:45:31,156 [foster.py] => Task 4, Epoch 78/170 => Loss 3.457, Loss_clf 0.420, Loss_fe 0.306, Loss_kd 2.534, Train_accy 80.76, Test_accy 74.16
2024-09-08 11:45:36,578 [foster.py] => Task 4, Epoch 79/170 => Loss 3.482, Loss_clf 0.427, Loss_fe 0.309, Loss_kd 2.548, Train_accy 80.66, Test_accy 74.21
2024-09-08 11:45:42,045 [foster.py] => Task 4, Epoch 80/170 => Loss 3.431, Loss_clf 0.409, Loss_fe 0.289, Loss_kd 2.537, Train_accy 80.89, Test_accy 74.51
2024-09-08 11:45:45,774 [foster.py] => Task 4, Epoch 81/170 => Loss 3.427, Loss_clf 0.416, Loss_fe 0.297, Loss_kd 2.519, Train_accy 81.71
2024-09-08 11:45:51,226 [foster.py] => Task 4, Epoch 82/170 => Loss 3.399, Loss_clf 0.396, Loss_fe 0.277, Loss_kd 2.530, Train_accy 81.05, Test_accy 74.03
2024-09-08 11:45:56,822 [foster.py] => Task 4, Epoch 83/170 => Loss 3.423, Loss_clf 0.413, Loss_fe 0.291, Loss_kd 2.523, Train_accy 80.13, Test_accy 73.21
2024-09-08 11:46:02,272 [foster.py] => Task 4, Epoch 84/170 => Loss 3.496, Loss_clf 0.449, Loss_fe 0.302, Loss_kd 2.547, Train_accy 80.84, Test_accy 74.47
2024-09-08 11:46:07,679 [foster.py] => Task 4, Epoch 85/170 => Loss 3.417, Loss_clf 0.409, Loss_fe 0.276, Loss_kd 2.535, Train_accy 82.37, Test_accy 74.34
2024-09-08 11:46:11,545 [foster.py] => Task 4, Epoch 86/170 => Loss 3.392, Loss_clf 0.385, Loss_fe 0.269, Loss_kd 2.541, Train_accy 82.82
2024-09-08 11:46:17,032 [foster.py] => Task 4, Epoch 87/170 => Loss 3.387, Loss_clf 0.395, Loss_fe 0.270, Loss_kd 2.526, Train_accy 82.79, Test_accy 74.56
2024-09-08 11:46:22,439 [foster.py] => Task 4, Epoch 88/170 => Loss 3.385, Loss_clf 0.390, Loss_fe 0.270, Loss_kd 2.530, Train_accy 83.45, Test_accy 74.73
2024-09-08 11:46:27,901 [foster.py] => Task 4, Epoch 89/170 => Loss 3.437, Loss_clf 0.412, Loss_fe 0.277, Loss_kd 2.550, Train_accy 81.95, Test_accy 74.70
2024-09-08 11:46:33,337 [foster.py] => Task 4, Epoch 90/170 => Loss 3.406, Loss_clf 0.395, Loss_fe 0.275, Loss_kd 2.539, Train_accy 82.08, Test_accy 74.74
2024-09-08 11:46:37,086 [foster.py] => Task 4, Epoch 91/170 => Loss 3.393, Loss_clf 0.390, Loss_fe 0.262, Loss_kd 2.544, Train_accy 82.39
2024-09-08 11:46:42,508 [foster.py] => Task 4, Epoch 92/170 => Loss 3.389, Loss_clf 0.390, Loss_fe 0.264, Loss_kd 2.539, Train_accy 82.47, Test_accy 74.27
2024-09-08 11:46:47,971 [foster.py] => Task 4, Epoch 93/170 => Loss 3.344, Loss_clf 0.370, Loss_fe 0.246, Loss_kd 2.531, Train_accy 83.13, Test_accy 74.63
2024-09-08 11:46:53,423 [foster.py] => Task 4, Epoch 94/170 => Loss 3.401, Loss_clf 0.404, Loss_fe 0.270, Loss_kd 2.531, Train_accy 82.45, Test_accy 74.21
2024-09-08 11:46:58,821 [foster.py] => Task 4, Epoch 95/170 => Loss 3.334, Loss_clf 0.371, Loss_fe 0.243, Loss_kd 2.525, Train_accy 82.76, Test_accy 74.61
2024-09-08 11:47:02,594 [foster.py] => Task 4, Epoch 96/170 => Loss 3.383, Loss_clf 0.394, Loss_fe 0.259, Loss_kd 2.534, Train_accy 81.97
2024-09-08 11:47:08,035 [foster.py] => Task 4, Epoch 97/170 => Loss 3.366, Loss_clf 0.388, Loss_fe 0.245, Loss_kd 2.537, Train_accy 82.00, Test_accy 74.21
2024-09-08 11:47:13,529 [foster.py] => Task 4, Epoch 98/170 => Loss 3.383, Loss_clf 0.399, Loss_fe 0.260, Loss_kd 2.528, Train_accy 83.37, Test_accy 74.44
2024-09-08 11:47:18,974 [foster.py] => Task 4, Epoch 99/170 => Loss 3.394, Loss_clf 0.406, Loss_fe 0.258, Loss_kd 2.533, Train_accy 82.32, Test_accy 74.00
2024-09-08 11:47:24,438 [foster.py] => Task 4, Epoch 100/170 => Loss 3.402, Loss_clf 0.408, Loss_fe 0.240, Loss_kd 2.556, Train_accy 83.37, Test_accy 74.73
2024-09-08 11:47:28,242 [foster.py] => Task 4, Epoch 101/170 => Loss 3.353, Loss_clf 0.392, Loss_fe 0.241, Loss_kd 2.525, Train_accy 83.82
2024-09-08 11:47:33,774 [foster.py] => Task 4, Epoch 102/170 => Loss 3.353, Loss_clf 0.386, Loss_fe 0.233, Loss_kd 2.537, Train_accy 83.11, Test_accy 74.69
2024-09-08 11:47:39,222 [foster.py] => Task 4, Epoch 103/170 => Loss 3.276, Loss_clf 0.335, Loss_fe 0.223, Loss_kd 2.522, Train_accy 85.26, Test_accy 74.54
2024-09-08 11:47:44,638 [foster.py] => Task 4, Epoch 104/170 => Loss 3.314, Loss_clf 0.369, Loss_fe 0.220, Loss_kd 2.529, Train_accy 83.66, Test_accy 74.54
2024-09-08 11:47:50,091 [foster.py] => Task 4, Epoch 105/170 => Loss 3.298, Loss_clf 0.346, Loss_fe 0.216, Loss_kd 2.538, Train_accy 84.79, Test_accy 74.61
2024-09-08 11:47:53,857 [foster.py] => Task 4, Epoch 106/170 => Loss 3.325, Loss_clf 0.373, Loss_fe 0.225, Loss_kd 2.531, Train_accy 83.71
2024-09-08 11:47:59,330 [foster.py] => Task 4, Epoch 107/170 => Loss 3.311, Loss_clf 0.353, Loss_fe 0.216, Loss_kd 2.545, Train_accy 85.16, Test_accy 74.89
2024-09-08 11:48:04,813 [foster.py] => Task 4, Epoch 108/170 => Loss 3.314, Loss_clf 0.367, Loss_fe 0.219, Loss_kd 2.531, Train_accy 83.26, Test_accy 74.81
2024-09-08 11:48:10,182 [foster.py] => Task 4, Epoch 109/170 => Loss 3.302, Loss_clf 0.363, Loss_fe 0.210, Loss_kd 2.533, Train_accy 84.58, Test_accy 74.66
2024-09-08 11:48:15,610 [foster.py] => Task 4, Epoch 110/170 => Loss 3.322, Loss_clf 0.368, Loss_fe 0.215, Loss_kd 2.542, Train_accy 83.47, Test_accy 74.69
2024-09-08 11:48:19,380 [foster.py] => Task 4, Epoch 111/170 => Loss 3.340, Loss_clf 0.377, Loss_fe 0.232, Loss_kd 2.535, Train_accy 83.97
2024-09-08 11:48:24,803 [foster.py] => Task 4, Epoch 112/170 => Loss 3.282, Loss_clf 0.356, Loss_fe 0.210, Loss_kd 2.521, Train_accy 84.84, Test_accy 75.13
2024-09-08 11:48:30,262 [foster.py] => Task 4, Epoch 113/170 => Loss 3.308, Loss_clf 0.365, Loss_fe 0.217, Loss_kd 2.530, Train_accy 85.21, Test_accy 74.83
2024-09-08 11:48:35,772 [foster.py] => Task 4, Epoch 114/170 => Loss 3.295, Loss_clf 0.360, Loss_fe 0.209, Loss_kd 2.530, Train_accy 84.00, Test_accy 74.81
2024-09-08 11:48:41,213 [foster.py] => Task 4, Epoch 115/170 => Loss 3.266, Loss_clf 0.347, Loss_fe 0.192, Loss_kd 2.530, Train_accy 85.74, Test_accy 74.87
2024-09-08 11:48:45,020 [foster.py] => Task 4, Epoch 116/170 => Loss 3.264, Loss_clf 0.350, Loss_fe 0.190, Loss_kd 2.529, Train_accy 84.79
2024-09-08 11:48:50,487 [foster.py] => Task 4, Epoch 117/170 => Loss 3.239, Loss_clf 0.329, Loss_fe 0.185, Loss_kd 2.529, Train_accy 85.61, Test_accy 74.66
2024-09-08 11:48:55,951 [foster.py] => Task 4, Epoch 118/170 => Loss 3.249, Loss_clf 0.339, Loss_fe 0.197, Loss_kd 2.518, Train_accy 84.66, Test_accy 74.49
2024-09-08 11:49:01,433 [foster.py] => Task 4, Epoch 119/170 => Loss 3.254, Loss_clf 0.348, Loss_fe 0.181, Loss_kd 2.529, Train_accy 85.82, Test_accy 74.80
2024-09-08 11:49:06,854 [foster.py] => Task 4, Epoch 120/170 => Loss 3.241, Loss_clf 0.338, Loss_fe 0.182, Loss_kd 2.525, Train_accy 85.00, Test_accy 74.77
2024-09-08 11:49:10,607 [foster.py] => Task 4, Epoch 121/170 => Loss 3.244, Loss_clf 0.333, Loss_fe 0.184, Loss_kd 2.531, Train_accy 86.42
2024-09-08 11:49:16,027 [foster.py] => Task 4, Epoch 122/170 => Loss 3.255, Loss_clf 0.334, Loss_fe 0.190, Loss_kd 2.533, Train_accy 85.37, Test_accy 75.16
2024-09-08 11:49:21,460 [foster.py] => Task 4, Epoch 123/170 => Loss 3.268, Loss_clf 0.346, Loss_fe 0.184, Loss_kd 2.541, Train_accy 85.00, Test_accy 74.79
2024-09-08 11:49:26,896 [foster.py] => Task 4, Epoch 124/170 => Loss 3.301, Loss_clf 0.352, Loss_fe 0.204, Loss_kd 2.547, Train_accy 85.92, Test_accy 74.97
2024-09-08 11:49:32,403 [foster.py] => Task 4, Epoch 125/170 => Loss 3.278, Loss_clf 0.352, Loss_fe 0.187, Loss_kd 2.543, Train_accy 85.34, Test_accy 74.57
2024-09-08 11:49:36,219 [foster.py] => Task 4, Epoch 126/170 => Loss 3.211, Loss_clf 0.320, Loss_fe 0.164, Loss_kd 2.530, Train_accy 86.00
2024-09-08 11:49:41,646 [foster.py] => Task 4, Epoch 127/170 => Loss 3.243, Loss_clf 0.335, Loss_fe 0.181, Loss_kd 2.530, Train_accy 86.21, Test_accy 74.80
2024-09-08 11:49:47,168 [foster.py] => Task 4, Epoch 128/170 => Loss 3.271, Loss_clf 0.352, Loss_fe 0.182, Loss_kd 2.540, Train_accy 84.92, Test_accy 74.89
2024-09-08 11:49:52,701 [foster.py] => Task 4, Epoch 129/170 => Loss 3.281, Loss_clf 0.356, Loss_fe 0.170, Loss_kd 2.558, Train_accy 86.34, Test_accy 74.77
2024-09-08 11:49:58,146 [foster.py] => Task 4, Epoch 130/170 => Loss 3.279, Loss_clf 0.359, Loss_fe 0.184, Loss_kd 2.540, Train_accy 85.21, Test_accy 74.90
2024-09-08 11:50:01,914 [foster.py] => Task 4, Epoch 131/170 => Loss 3.270, Loss_clf 0.348, Loss_fe 0.181, Loss_kd 2.544, Train_accy 86.05
2024-09-08 11:50:07,272 [foster.py] => Task 4, Epoch 132/170 => Loss 3.231, Loss_clf 0.318, Loss_fe 0.171, Loss_kd 2.545, Train_accy 86.79, Test_accy 74.96
2024-09-08 11:50:12,665 [foster.py] => Task 4, Epoch 133/170 => Loss 3.189, Loss_clf 0.320, Loss_fe 0.152, Loss_kd 2.521, Train_accy 87.05, Test_accy 74.83
2024-09-08 11:50:18,030 [foster.py] => Task 4, Epoch 134/170 => Loss 3.215, Loss_clf 0.328, Loss_fe 0.155, Loss_kd 2.535, Train_accy 86.68, Test_accy 74.91
2024-09-08 11:50:23,566 [foster.py] => Task 4, Epoch 135/170 => Loss 3.220, Loss_clf 0.321, Loss_fe 0.166, Loss_kd 2.536, Train_accy 86.50, Test_accy 74.83
2024-09-08 11:50:27,339 [foster.py] => Task 4, Epoch 136/170 => Loss 3.196, Loss_clf 0.312, Loss_fe 0.152, Loss_kd 2.536, Train_accy 87.37
2024-09-08 11:50:32,801 [foster.py] => Task 4, Epoch 137/170 => Loss 3.229, Loss_clf 0.331, Loss_fe 0.167, Loss_kd 2.535, Train_accy 86.53, Test_accy 74.81
2024-09-08 11:50:38,239 [foster.py] => Task 4, Epoch 138/170 => Loss 3.204, Loss_clf 0.325, Loss_fe 0.157, Loss_kd 2.526, Train_accy 86.66, Test_accy 74.67
2024-09-08 11:50:43,656 [foster.py] => Task 4, Epoch 139/170 => Loss 3.207, Loss_clf 0.325, Loss_fe 0.163, Loss_kd 2.523, Train_accy 86.84, Test_accy 74.67
2024-09-08 11:50:49,084 [foster.py] => Task 4, Epoch 140/170 => Loss 3.193, Loss_clf 0.317, Loss_fe 0.156, Loss_kd 2.525, Train_accy 87.53, Test_accy 74.81
2024-09-08 11:50:52,855 [foster.py] => Task 4, Epoch 141/170 => Loss 3.227, Loss_clf 0.334, Loss_fe 0.156, Loss_kd 2.540, Train_accy 86.42
2024-09-08 11:50:58,277 [foster.py] => Task 4, Epoch 142/170 => Loss 3.216, Loss_clf 0.322, Loss_fe 0.157, Loss_kd 2.541, Train_accy 87.13, Test_accy 74.90
2024-09-08 11:51:03,744 [foster.py] => Task 4, Epoch 143/170 => Loss 3.235, Loss_clf 0.327, Loss_fe 0.168, Loss_kd 2.542, Train_accy 86.76, Test_accy 74.90
2024-09-08 11:51:09,253 [foster.py] => Task 4, Epoch 144/170 => Loss 3.168, Loss_clf 0.306, Loss_fe 0.139, Loss_kd 2.526, Train_accy 87.53, Test_accy 74.89
2024-09-08 11:51:14,735 [foster.py] => Task 4, Epoch 145/170 => Loss 3.220, Loss_clf 0.335, Loss_fe 0.151, Loss_kd 2.537, Train_accy 86.92, Test_accy 74.77
2024-09-08 11:51:18,509 [foster.py] => Task 4, Epoch 146/170 => Loss 3.188, Loss_clf 0.309, Loss_fe 0.144, Loss_kd 2.538, Train_accy 87.11
2024-09-08 11:51:23,987 [foster.py] => Task 4, Epoch 147/170 => Loss 3.187, Loss_clf 0.310, Loss_fe 0.138, Loss_kd 2.542, Train_accy 87.82, Test_accy 74.70
2024-09-08 11:51:29,386 [foster.py] => Task 4, Epoch 148/170 => Loss 3.170, Loss_clf 0.312, Loss_fe 0.138, Loss_kd 2.525, Train_accy 87.84, Test_accy 74.80
2024-09-08 11:51:34,782 [foster.py] => Task 4, Epoch 149/170 => Loss 3.184, Loss_clf 0.311, Loss_fe 0.144, Loss_kd 2.533, Train_accy 87.47, Test_accy 74.87
2024-09-08 11:51:40,189 [foster.py] => Task 4, Epoch 150/170 => Loss 3.203, Loss_clf 0.318, Loss_fe 0.158, Loss_kd 2.531, Train_accy 87.68, Test_accy 74.93
2024-09-08 11:51:43,928 [foster.py] => Task 4, Epoch 151/170 => Loss 3.194, Loss_clf 0.323, Loss_fe 0.146, Loss_kd 2.529, Train_accy 86.13
2024-09-08 11:51:49,415 [foster.py] => Task 4, Epoch 152/170 => Loss 3.207, Loss_clf 0.316, Loss_fe 0.148, Loss_kd 2.546, Train_accy 87.29, Test_accy 74.93
2024-09-08 11:51:54,864 [foster.py] => Task 4, Epoch 153/170 => Loss 3.196, Loss_clf 0.318, Loss_fe 0.149, Loss_kd 2.533, Train_accy 87.29, Test_accy 74.93
2024-09-08 11:52:00,277 [foster.py] => Task 4, Epoch 154/170 => Loss 3.208, Loss_clf 0.323, Loss_fe 0.150, Loss_kd 2.538, Train_accy 86.76, Test_accy 75.00
2024-09-08 11:52:05,707 [foster.py] => Task 4, Epoch 155/170 => Loss 3.187, Loss_clf 0.309, Loss_fe 0.137, Loss_kd 2.544, Train_accy 87.71, Test_accy 74.97
2024-09-08 11:52:09,497 [foster.py] => Task 4, Epoch 156/170 => Loss 3.226, Loss_clf 0.328, Loss_fe 0.150, Loss_kd 2.550, Train_accy 86.68
2024-09-08 11:52:14,958 [foster.py] => Task 4, Epoch 157/170 => Loss 3.189, Loss_clf 0.318, Loss_fe 0.146, Loss_kd 2.529, Train_accy 87.03, Test_accy 74.87
2024-09-08 11:52:20,341 [foster.py] => Task 4, Epoch 158/170 => Loss 3.201, Loss_clf 0.318, Loss_fe 0.153, Loss_kd 2.534, Train_accy 87.61, Test_accy 74.87
2024-09-08 11:52:25,979 [foster.py] => Task 4, Epoch 159/170 => Loss 3.190, Loss_clf 0.310, Loss_fe 0.144, Loss_kd 2.539, Train_accy 87.42, Test_accy 74.99
2024-09-08 11:52:31,400 [foster.py] => Task 4, Epoch 160/170 => Loss 3.180, Loss_clf 0.309, Loss_fe 0.139, Loss_kd 2.535, Train_accy 87.53, Test_accy 74.94
2024-09-08 11:52:35,167 [foster.py] => Task 4, Epoch 161/170 => Loss 3.206, Loss_clf 0.322, Loss_fe 0.153, Loss_kd 2.535, Train_accy 87.11
2024-09-08 11:52:40,562 [foster.py] => Task 4, Epoch 162/170 => Loss 3.140, Loss_clf 0.291, Loss_fe 0.136, Loss_kd 2.517, Train_accy 88.24, Test_accy 74.86
2024-09-08 11:52:46,063 [foster.py] => Task 4, Epoch 163/170 => Loss 3.182, Loss_clf 0.317, Loss_fe 0.144, Loss_kd 2.526, Train_accy 87.00, Test_accy 74.90
2024-09-08 11:52:51,552 [foster.py] => Task 4, Epoch 164/170 => Loss 3.208, Loss_clf 0.325, Loss_fe 0.155, Loss_kd 2.532, Train_accy 87.11, Test_accy 74.91
2024-09-08 11:52:57,048 [foster.py] => Task 4, Epoch 165/170 => Loss 3.200, Loss_clf 0.331, Loss_fe 0.144, Loss_kd 2.528, Train_accy 86.68, Test_accy 74.96
2024-09-08 11:53:00,818 [foster.py] => Task 4, Epoch 166/170 => Loss 3.156, Loss_clf 0.296, Loss_fe 0.129, Loss_kd 2.535, Train_accy 88.47
2024-09-08 11:53:06,240 [foster.py] => Task 4, Epoch 167/170 => Loss 3.166, Loss_clf 0.300, Loss_fe 0.141, Loss_kd 2.529, Train_accy 88.82, Test_accy 74.97
2024-09-08 11:53:11,783 [foster.py] => Task 4, Epoch 168/170 => Loss 3.115, Loss_clf 0.278, Loss_fe 0.130, Loss_kd 2.512, Train_accy 88.32, Test_accy 74.87
2024-09-08 11:53:17,249 [foster.py] => Task 4, Epoch 169/170 => Loss 3.222, Loss_clf 0.329, Loss_fe 0.151, Loss_kd 2.545, Train_accy 87.08, Test_accy 74.86
2024-09-08 11:53:22,677 [foster.py] => Task 4, Epoch 170/170 => Loss 3.250, Loss_clf 0.338, Loss_fe 0.155, Loss_kd 2.560, Train_accy 86.55, Test_accy 74.90
2024-09-08 11:53:22,681 [foster.py] => do not weight align teacher!
2024-09-08 11:53:22,684 [foster.py] => per cls weights : [1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074
 1.03522074 1.03522074 1.03522074 1.03522074 1.03522074 0.54213038
 0.54213038 0.54213038 0.54213038 0.54213038]
2024-09-08 11:53:29,278 [foster.py] => SNet: Task 4, Epoch 1/130 => Loss 29.355,  Loss1 0.731, Train_accy 36.55, Test_accy 67.19
2024-09-08 11:53:34,558 [foster.py] => SNet: Task 4, Epoch 2/130 => Loss 29.158,  Loss1 0.730, Train_accy 56.24
2024-09-08 11:53:39,852 [foster.py] => SNet: Task 4, Epoch 3/130 => Loss 29.124,  Loss1 0.730, Train_accy 60.39
2024-09-08 11:53:45,175 [foster.py] => SNet: Task 4, Epoch 4/130 => Loss 29.117,  Loss1 0.730, Train_accy 63.50
2024-09-08 11:53:50,432 [foster.py] => SNet: Task 4, Epoch 5/130 => Loss 29.103,  Loss1 0.730, Train_accy 64.61
2024-09-08 11:53:56,781 [foster.py] => SNet: Task 4, Epoch 6/130 => Loss 29.114,  Loss1 0.730, Train_accy 66.95, Test_accy 71.79
2024-09-08 11:54:02,056 [foster.py] => SNet: Task 4, Epoch 7/130 => Loss 29.119,  Loss1 0.730, Train_accy 66.82
2024-09-08 11:54:07,324 [foster.py] => SNet: Task 4, Epoch 8/130 => Loss 29.111,  Loss1 0.730, Train_accy 66.24
2024-09-08 11:54:12,613 [foster.py] => SNet: Task 4, Epoch 9/130 => Loss 29.107,  Loss1 0.730, Train_accy 67.29
2024-09-08 11:54:17,878 [foster.py] => SNet: Task 4, Epoch 10/130 => Loss 29.125,  Loss1 0.730, Train_accy 68.71
2024-09-08 11:54:24,277 [foster.py] => SNet: Task 4, Epoch 11/130 => Loss 29.107,  Loss1 0.730, Train_accy 67.32, Test_accy 72.13
2024-09-08 11:54:29,526 [foster.py] => SNet: Task 4, Epoch 12/130 => Loss 29.094,  Loss1 0.730, Train_accy 69.37
2024-09-08 11:54:34,804 [foster.py] => SNet: Task 4, Epoch 13/130 => Loss 29.094,  Loss1 0.730, Train_accy 70.68
2024-09-08 11:54:40,146 [foster.py] => SNet: Task 4, Epoch 14/130 => Loss 29.098,  Loss1 0.730, Train_accy 68.74
2024-09-08 11:54:45,427 [foster.py] => SNet: Task 4, Epoch 15/130 => Loss 29.109,  Loss1 0.730, Train_accy 69.47
2024-09-08 11:54:51,817 [foster.py] => SNet: Task 4, Epoch 16/130 => Loss 29.092,  Loss1 0.730, Train_accy 71.55, Test_accy 72.79
2024-09-08 11:54:57,120 [foster.py] => SNet: Task 4, Epoch 17/130 => Loss 29.088,  Loss1 0.730, Train_accy 70.53
2024-09-08 11:55:02,458 [foster.py] => SNet: Task 4, Epoch 18/130 => Loss 29.093,  Loss1 0.730, Train_accy 71.47
2024-09-08 11:55:07,715 [foster.py] => SNet: Task 4, Epoch 19/130 => Loss 29.089,  Loss1 0.730, Train_accy 70.61
2024-09-08 11:55:13,038 [foster.py] => SNet: Task 4, Epoch 20/130 => Loss 29.072,  Loss1 0.730, Train_accy 72.11
2024-09-08 11:55:19,407 [foster.py] => SNet: Task 4, Epoch 21/130 => Loss 29.087,  Loss1 0.730, Train_accy 71.39, Test_accy 72.33
2024-09-08 11:55:24,691 [foster.py] => SNet: Task 4, Epoch 22/130 => Loss 29.059,  Loss1 0.730, Train_accy 72.58
2024-09-08 11:55:29,954 [foster.py] => SNet: Task 4, Epoch 23/130 => Loss 29.102,  Loss1 0.730, Train_accy 71.21
2024-09-08 11:55:35,234 [foster.py] => SNet: Task 4, Epoch 24/130 => Loss 29.083,  Loss1 0.730, Train_accy 71.84
2024-09-08 11:55:40,543 [foster.py] => SNet: Task 4, Epoch 25/130 => Loss 29.106,  Loss1 0.730, Train_accy 71.92
2024-09-08 11:55:46,942 [foster.py] => SNet: Task 4, Epoch 26/130 => Loss 29.122,  Loss1 0.730, Train_accy 72.26, Test_accy 72.41
2024-09-08 11:55:52,211 [foster.py] => SNet: Task 4, Epoch 27/130 => Loss 29.089,  Loss1 0.730, Train_accy 71.82
2024-09-08 11:55:57,556 [foster.py] => SNet: Task 4, Epoch 28/130 => Loss 29.074,  Loss1 0.730, Train_accy 72.03
2024-09-08 11:56:02,821 [foster.py] => SNet: Task 4, Epoch 29/130 => Loss 29.099,  Loss1 0.730, Train_accy 73.21
2024-09-08 11:56:08,070 [foster.py] => SNet: Task 4, Epoch 30/130 => Loss 29.063,  Loss1 0.730, Train_accy 72.26
2024-09-08 11:56:14,402 [foster.py] => SNet: Task 4, Epoch 31/130 => Loss 29.083,  Loss1 0.730, Train_accy 71.61, Test_accy 72.90
2024-09-08 11:56:19,713 [foster.py] => SNet: Task 4, Epoch 32/130 => Loss 29.080,  Loss1 0.730, Train_accy 73.13
2024-09-08 11:56:25,030 [foster.py] => SNet: Task 4, Epoch 33/130 => Loss 29.064,  Loss1 0.730, Train_accy 73.76
2024-09-08 11:56:30,301 [foster.py] => SNet: Task 4, Epoch 34/130 => Loss 29.063,  Loss1 0.730, Train_accy 73.21
2024-09-08 11:56:35,607 [foster.py] => SNet: Task 4, Epoch 35/130 => Loss 29.078,  Loss1 0.730, Train_accy 72.68
2024-09-08 11:56:41,966 [foster.py] => SNet: Task 4, Epoch 36/130 => Loss 29.093,  Loss1 0.730, Train_accy 74.21, Test_accy 72.54
2024-09-08 11:56:47,220 [foster.py] => SNet: Task 4, Epoch 37/130 => Loss 29.097,  Loss1 0.730, Train_accy 73.18
2024-09-08 11:56:52,495 [foster.py] => SNet: Task 4, Epoch 38/130 => Loss 29.090,  Loss1 0.730, Train_accy 73.37
2024-09-08 11:56:57,786 [foster.py] => SNet: Task 4, Epoch 39/130 => Loss 29.057,  Loss1 0.730, Train_accy 73.76
2024-09-08 11:57:03,044 [foster.py] => SNet: Task 4, Epoch 40/130 => Loss 29.081,  Loss1 0.730, Train_accy 73.92
2024-09-08 11:57:09,437 [foster.py] => SNet: Task 4, Epoch 41/130 => Loss 29.073,  Loss1 0.729, Train_accy 73.05, Test_accy 73.23
2024-09-08 11:57:14,683 [foster.py] => SNet: Task 4, Epoch 42/130 => Loss 29.083,  Loss1 0.730, Train_accy 74.66
2024-09-08 11:57:19,999 [foster.py] => SNet: Task 4, Epoch 43/130 => Loss 29.076,  Loss1 0.730, Train_accy 72.47
2024-09-08 11:57:25,270 [foster.py] => SNet: Task 4, Epoch 44/130 => Loss 29.093,  Loss1 0.729, Train_accy 73.13
2024-09-08 11:57:30,575 [foster.py] => SNet: Task 4, Epoch 45/130 => Loss 29.006,  Loss1 0.730, Train_accy 74.39
2024-09-08 11:57:36,975 [foster.py] => SNet: Task 4, Epoch 46/130 => Loss 29.085,  Loss1 0.730, Train_accy 74.21, Test_accy 73.27
2024-09-08 11:57:42,207 [foster.py] => SNet: Task 4, Epoch 47/130 => Loss 29.071,  Loss1 0.730, Train_accy 75.16
2024-09-08 11:57:47,468 [foster.py] => SNet: Task 4, Epoch 48/130 => Loss 29.054,  Loss1 0.730, Train_accy 74.08
2024-09-08 11:57:52,760 [foster.py] => SNet: Task 4, Epoch 49/130 => Loss 29.048,  Loss1 0.730, Train_accy 73.03
2024-09-08 11:57:58,044 [foster.py] => SNet: Task 4, Epoch 50/130 => Loss 29.073,  Loss1 0.730, Train_accy 74.42
2024-09-08 11:58:04,399 [foster.py] => SNet: Task 4, Epoch 51/130 => Loss 29.070,  Loss1 0.730, Train_accy 74.61, Test_accy 73.11
2024-09-08 11:58:09,688 [foster.py] => SNet: Task 4, Epoch 52/130 => Loss 29.066,  Loss1 0.730, Train_accy 74.50
2024-09-08 11:58:14,970 [foster.py] => SNet: Task 4, Epoch 53/130 => Loss 29.038,  Loss1 0.730, Train_accy 75.63
2024-09-08 11:58:20,381 [foster.py] => SNet: Task 4, Epoch 54/130 => Loss 29.067,  Loss1 0.730, Train_accy 74.97
2024-09-08 11:58:25,682 [foster.py] => SNet: Task 4, Epoch 55/130 => Loss 29.048,  Loss1 0.730, Train_accy 75.18
2024-09-08 11:58:32,026 [foster.py] => SNet: Task 4, Epoch 56/130 => Loss 29.089,  Loss1 0.730, Train_accy 74.79, Test_accy 72.99
2024-09-08 11:58:37,325 [foster.py] => SNet: Task 4, Epoch 57/130 => Loss 29.066,  Loss1 0.730, Train_accy 73.84
2024-09-08 11:58:42,625 [foster.py] => SNet: Task 4, Epoch 58/130 => Loss 29.054,  Loss1 0.730, Train_accy 73.79
2024-09-08 11:58:47,895 [foster.py] => SNet: Task 4, Epoch 59/130 => Loss 29.085,  Loss1 0.730, Train_accy 73.89
2024-09-08 11:58:53,168 [foster.py] => SNet: Task 4, Epoch 60/130 => Loss 29.042,  Loss1 0.730, Train_accy 74.95
2024-09-08 11:58:59,499 [foster.py] => SNet: Task 4, Epoch 61/130 => Loss 29.065,  Loss1 0.730, Train_accy 75.00, Test_accy 73.06
2024-09-08 11:59:04,835 [foster.py] => SNet: Task 4, Epoch 62/130 => Loss 29.075,  Loss1 0.730, Train_accy 73.50
2024-09-08 11:59:10,160 [foster.py] => SNet: Task 4, Epoch 63/130 => Loss 29.095,  Loss1 0.730, Train_accy 73.92
2024-09-08 11:59:15,436 [foster.py] => SNet: Task 4, Epoch 64/130 => Loss 29.070,  Loss1 0.730, Train_accy 74.16
2024-09-08 11:59:20,742 [foster.py] => SNet: Task 4, Epoch 65/130 => Loss 29.074,  Loss1 0.730, Train_accy 75.13
2024-09-08 11:59:27,078 [foster.py] => SNet: Task 4, Epoch 66/130 => Loss 29.038,  Loss1 0.730, Train_accy 76.66, Test_accy 73.10
2024-09-08 11:59:32,473 [foster.py] => SNet: Task 4, Epoch 67/130 => Loss 29.031,  Loss1 0.730, Train_accy 74.53
2024-09-08 11:59:37,769 [foster.py] => SNet: Task 4, Epoch 68/130 => Loss 29.026,  Loss1 0.730, Train_accy 75.11
2024-09-08 11:59:43,077 [foster.py] => SNet: Task 4, Epoch 69/130 => Loss 29.013,  Loss1 0.730, Train_accy 76.08
2024-09-08 11:59:48,327 [foster.py] => SNet: Task 4, Epoch 70/130 => Loss 29.056,  Loss1 0.730, Train_accy 75.53
2024-09-08 11:59:54,698 [foster.py] => SNet: Task 4, Epoch 71/130 => Loss 29.065,  Loss1 0.730, Train_accy 74.45, Test_accy 73.24
2024-09-08 12:00:00,002 [foster.py] => SNet: Task 4, Epoch 72/130 => Loss 29.049,  Loss1 0.730, Train_accy 75.37
2024-09-08 12:00:05,352 [foster.py] => SNet: Task 4, Epoch 73/130 => Loss 29.070,  Loss1 0.730, Train_accy 75.00
2024-09-08 12:00:10,645 [foster.py] => SNet: Task 4, Epoch 74/130 => Loss 29.074,  Loss1 0.730, Train_accy 75.92
2024-09-08 12:00:15,924 [foster.py] => SNet: Task 4, Epoch 75/130 => Loss 29.070,  Loss1 0.730, Train_accy 74.08
2024-09-08 12:00:22,295 [foster.py] => SNet: Task 4, Epoch 76/130 => Loss 29.104,  Loss1 0.730, Train_accy 76.39, Test_accy 73.34
2024-09-08 12:00:27,584 [foster.py] => SNet: Task 4, Epoch 77/130 => Loss 29.050,  Loss1 0.730, Train_accy 75.76
2024-09-08 12:00:32,906 [foster.py] => SNet: Task 4, Epoch 78/130 => Loss 29.069,  Loss1 0.730, Train_accy 75.55
2024-09-08 12:00:38,170 [foster.py] => SNet: Task 4, Epoch 79/130 => Loss 29.055,  Loss1 0.730, Train_accy 75.13
2024-09-08 12:00:43,451 [foster.py] => SNet: Task 4, Epoch 80/130 => Loss 29.063,  Loss1 0.730, Train_accy 75.45
2024-09-08 12:00:49,844 [foster.py] => SNet: Task 4, Epoch 81/130 => Loss 29.070,  Loss1 0.730, Train_accy 75.42, Test_accy 73.23
2024-09-08 12:00:55,139 [foster.py] => SNet: Task 4, Epoch 82/130 => Loss 29.084,  Loss1 0.730, Train_accy 74.82
2024-09-08 12:01:00,461 [foster.py] => SNet: Task 4, Epoch 83/130 => Loss 29.065,  Loss1 0.730, Train_accy 75.05
2024-09-08 12:01:05,755 [foster.py] => SNet: Task 4, Epoch 84/130 => Loss 29.097,  Loss1 0.730, Train_accy 75.34
2024-09-08 12:01:11,052 [foster.py] => SNet: Task 4, Epoch 85/130 => Loss 29.093,  Loss1 0.730, Train_accy 74.66
2024-09-08 12:01:17,408 [foster.py] => SNet: Task 4, Epoch 86/130 => Loss 29.047,  Loss1 0.730, Train_accy 75.61, Test_accy 73.63
2024-09-08 12:01:22,664 [foster.py] => SNet: Task 4, Epoch 87/130 => Loss 29.050,  Loss1 0.730, Train_accy 73.79
2024-09-08 12:01:27,936 [foster.py] => SNet: Task 4, Epoch 88/130 => Loss 29.078,  Loss1 0.730, Train_accy 74.39
2024-09-08 12:01:33,240 [foster.py] => SNet: Task 4, Epoch 89/130 => Loss 29.072,  Loss1 0.730, Train_accy 75.08
2024-09-08 12:01:38,552 [foster.py] => SNet: Task 4, Epoch 90/130 => Loss 29.067,  Loss1 0.730, Train_accy 74.21
2024-09-08 12:01:44,940 [foster.py] => SNet: Task 4, Epoch 91/130 => Loss 29.066,  Loss1 0.730, Train_accy 75.39, Test_accy 73.43
2024-09-08 12:01:50,256 [foster.py] => SNet: Task 4, Epoch 92/130 => Loss 29.090,  Loss1 0.730, Train_accy 74.63
2024-09-08 12:01:55,547 [foster.py] => SNet: Task 4, Epoch 93/130 => Loss 29.086,  Loss1 0.730, Train_accy 75.61
2024-09-08 12:02:00,898 [foster.py] => SNet: Task 4, Epoch 94/130 => Loss 29.054,  Loss1 0.730, Train_accy 75.16
2024-09-08 12:02:06,169 [foster.py] => SNet: Task 4, Epoch 95/130 => Loss 29.036,  Loss1 0.730, Train_accy 75.63
2024-09-08 12:02:12,514 [foster.py] => SNet: Task 4, Epoch 96/130 => Loss 29.056,  Loss1 0.730, Train_accy 76.00, Test_accy 73.13
2024-09-08 12:02:17,789 [foster.py] => SNet: Task 4, Epoch 97/130 => Loss 29.069,  Loss1 0.730, Train_accy 75.08
2024-09-08 12:02:23,067 [foster.py] => SNet: Task 4, Epoch 98/130 => Loss 29.068,  Loss1 0.730, Train_accy 74.84
2024-09-08 12:02:28,402 [foster.py] => SNet: Task 4, Epoch 99/130 => Loss 29.038,  Loss1 0.730, Train_accy 76.32
2024-09-08 12:02:33,685 [foster.py] => SNet: Task 4, Epoch 100/130 => Loss 29.078,  Loss1 0.730, Train_accy 75.76
2024-09-08 12:02:40,016 [foster.py] => SNet: Task 4, Epoch 101/130 => Loss 29.068,  Loss1 0.730, Train_accy 75.76, Test_accy 73.04
2024-09-08 12:02:45,331 [foster.py] => SNet: Task 4, Epoch 102/130 => Loss 29.065,  Loss1 0.730, Train_accy 75.92
2024-09-08 12:02:50,593 [foster.py] => SNet: Task 4, Epoch 103/130 => Loss 29.083,  Loss1 0.730, Train_accy 75.61
2024-09-08 12:02:55,885 [foster.py] => SNet: Task 4, Epoch 104/130 => Loss 29.042,  Loss1 0.730, Train_accy 76.47
2024-09-08 12:03:01,168 [foster.py] => SNet: Task 4, Epoch 105/130 => Loss 29.079,  Loss1 0.730, Train_accy 75.29
2024-09-08 12:03:07,522 [foster.py] => SNet: Task 4, Epoch 106/130 => Loss 29.091,  Loss1 0.730, Train_accy 74.87, Test_accy 73.39
2024-09-08 12:03:12,842 [foster.py] => SNet: Task 4, Epoch 107/130 => Loss 29.070,  Loss1 0.730, Train_accy 75.32
2024-09-08 12:03:18,128 [foster.py] => SNet: Task 4, Epoch 108/130 => Loss 29.067,  Loss1 0.730, Train_accy 74.45
2024-09-08 12:03:23,417 [foster.py] => SNet: Task 4, Epoch 109/130 => Loss 29.082,  Loss1 0.730, Train_accy 76.45
2024-09-08 12:03:28,750 [foster.py] => SNet: Task 4, Epoch 110/130 => Loss 29.050,  Loss1 0.730, Train_accy 75.58
2024-09-08 12:03:35,099 [foster.py] => SNet: Task 4, Epoch 111/130 => Loss 29.040,  Loss1 0.730, Train_accy 75.29, Test_accy 73.31
2024-09-08 12:03:40,439 [foster.py] => SNet: Task 4, Epoch 112/130 => Loss 29.059,  Loss1 0.730, Train_accy 75.26
2024-09-08 12:03:45,759 [foster.py] => SNet: Task 4, Epoch 113/130 => Loss 29.067,  Loss1 0.730, Train_accy 75.21
2024-09-08 12:03:51,042 [foster.py] => SNet: Task 4, Epoch 114/130 => Loss 29.081,  Loss1 0.730, Train_accy 75.53
2024-09-08 12:03:56,294 [foster.py] => SNet: Task 4, Epoch 115/130 => Loss 29.038,  Loss1 0.730, Train_accy 75.74
2024-09-08 12:04:02,580 [foster.py] => SNet: Task 4, Epoch 116/130 => Loss 29.068,  Loss1 0.730, Train_accy 75.61, Test_accy 73.43
2024-09-08 12:04:07,843 [foster.py] => SNet: Task 4, Epoch 117/130 => Loss 29.064,  Loss1 0.730, Train_accy 74.55
2024-09-08 12:04:13,164 [foster.py] => SNet: Task 4, Epoch 118/130 => Loss 29.086,  Loss1 0.729, Train_accy 75.82
2024-09-08 12:04:18,452 [foster.py] => SNet: Task 4, Epoch 119/130 => Loss 28.992,  Loss1 0.730, Train_accy 75.89
2024-09-08 12:04:23,775 [foster.py] => SNet: Task 4, Epoch 120/130 => Loss 29.043,  Loss1 0.730, Train_accy 74.16
2024-09-08 12:04:30,116 [foster.py] => SNet: Task 4, Epoch 121/130 => Loss 29.054,  Loss1 0.730, Train_accy 75.79, Test_accy 73.26
2024-09-08 12:04:35,394 [foster.py] => SNet: Task 4, Epoch 122/130 => Loss 29.064,  Loss1 0.730, Train_accy 76.16
2024-09-08 12:04:40,647 [foster.py] => SNet: Task 4, Epoch 123/130 => Loss 29.053,  Loss1 0.730, Train_accy 76.26
2024-09-08 12:04:45,946 [foster.py] => SNet: Task 4, Epoch 124/130 => Loss 29.051,  Loss1 0.730, Train_accy 76.05
2024-09-08 12:04:51,249 [foster.py] => SNet: Task 4, Epoch 125/130 => Loss 29.053,  Loss1 0.730, Train_accy 76.00
2024-09-08 12:04:57,643 [foster.py] => SNet: Task 4, Epoch 126/130 => Loss 29.042,  Loss1 0.730, Train_accy 76.29, Test_accy 73.34
2024-09-08 12:05:02,904 [foster.py] => SNet: Task 4, Epoch 127/130 => Loss 29.053,  Loss1 0.730, Train_accy 76.26
2024-09-08 12:05:08,213 [foster.py] => SNet: Task 4, Epoch 128/130 => Loss 29.028,  Loss1 0.730, Train_accy 75.63
2024-09-08 12:05:13,482 [foster.py] => SNet: Task 4, Epoch 129/130 => Loss 29.063,  Loss1 0.730, Train_accy 75.37
2024-09-08 12:05:18,830 [foster.py] => SNet: Task 4, Epoch 130/130 => Loss 29.062,  Loss1 0.730, Train_accy 76.37
2024-09-08 12:05:18,831 [foster.py] => do not weight align student!
2024-09-08 12:05:19,926 [foster.py] => darknet eval: 
2024-09-08 12:05:19,926 [foster.py] => CNN top1 curve: 73.36
2024-09-08 12:05:19,926 [foster.py] => CNN top5 curve: 93.47
2024-09-08 12:05:19,926 [foster.py] => CNN top1 平均值: 73.36
2024-09-08 12:05:19,929 [foster.py] => timees : 1587.4075763225555
2024-09-08 12:05:19,930 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 12:05:42,653 [foster.py] => Exemplar size: 1400
2024-09-08 12:05:42,653 [trainer.py] => CNN: {'total': 74.9, '00-09': 80.4, '10-19': 68.3, '20-29': 78.4, '30-39': 74.9, '40-49': 77.8, '50-59': 67.4, '60-69': 77.1, 'old': 74.22, 'new': 83.8}
2024-09-08 12:05:42,653 [trainer.py] => NME: {'total': 69.97, '00-09': 73.5, '10-19': 61.6, '20-29': 74.3, '30-39': 67.8, '40-49': 73.9, '50-59': 68.5, '60-69': 70.2, 'old': 68.26, 'new': 92.2}
2024-09-08 12:05:42,653 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9]
2024-09-08 12:05:42,653 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14]
2024-09-08 12:05:42,653 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97]
2024-09-08 12:05:42,653 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57]

2024-09-08 12:05:42,653 [trainer.py] => CNN top1 平均值: 78.18
2024-09-08 12:05:42,656 [trainer.py] => All params: 1172353
2024-09-08 12:05:42,658 [trainer.py] => Trainable params: 590854
2024-09-08 12:05:42,722 [foster.py] => Learning on 70-75
2024-09-08 12:05:42,725 [foster.py] => All params: 1173648
2024-09-08 12:05:42,727 [foster.py] => Trainable params: 591824
2024-09-08 12:05:42,776 [foster.py] => per cls weights : [1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  1.0267244  1.0267244
 1.0267244  1.0267244  1.0267244  1.0267244  0.62585834 0.62585834
 0.62585834 0.62585834 0.62585834]
2024-09-08 12:05:46,767 [foster.py] => Task 5, Epoch 1/170 => Loss 5.966, Loss_clf 1.456, Loss_fe 1.577, Loss_kd 2.736, Train_accy 60.56
2024-09-08 12:05:52,578 [foster.py] => Task 5, Epoch 2/170 => Loss 4.598, Loss_clf 0.771, Loss_fe 0.944, Loss_kd 2.689, Train_accy 66.85, Test_accy 70.53
2024-09-08 12:05:58,254 [foster.py] => Task 5, Epoch 3/170 => Loss 4.456, Loss_clf 0.740, Loss_fe 0.820, Loss_kd 2.702, Train_accy 67.67, Test_accy 70.55
2024-09-08 12:06:03,925 [foster.py] => Task 5, Epoch 4/170 => Loss 4.380, Loss_clf 0.726, Loss_fe 0.767, Loss_kd 2.693, Train_accy 66.59, Test_accy 69.64
2024-09-08 12:06:09,637 [foster.py] => Task 5, Epoch 5/170 => Loss 4.343, Loss_clf 0.690, Loss_fe 0.764, Loss_kd 2.695, Train_accy 68.41, Test_accy 71.47
2024-09-08 12:06:13,512 [foster.py] => Task 5, Epoch 6/170 => Loss 4.304, Loss_clf 0.696, Loss_fe 0.723, Loss_kd 2.691, Train_accy 69.49
2024-09-08 12:06:19,187 [foster.py] => Task 5, Epoch 7/170 => Loss 4.279, Loss_clf 0.687, Loss_fe 0.720, Loss_kd 2.679, Train_accy 70.82, Test_accy 71.00
2024-09-08 12:06:24,839 [foster.py] => Task 5, Epoch 8/170 => Loss 4.306, Loss_clf 0.700, Loss_fe 0.724, Loss_kd 2.688, Train_accy 69.00, Test_accy 70.81
2024-09-08 12:06:30,491 [foster.py] => Task 5, Epoch 9/170 => Loss 4.246, Loss_clf 0.673, Loss_fe 0.672, Loss_kd 2.706, Train_accy 69.56, Test_accy 71.20
2024-09-08 12:06:36,200 [foster.py] => Task 5, Epoch 10/170 => Loss 4.258, Loss_clf 0.683, Loss_fe 0.695, Loss_kd 2.686, Train_accy 70.33, Test_accy 71.07
2024-09-08 12:06:40,122 [foster.py] => Task 5, Epoch 11/170 => Loss 4.181, Loss_clf 0.639, Loss_fe 0.663, Loss_kd 2.685, Train_accy 70.92
2024-09-08 12:06:45,863 [foster.py] => Task 5, Epoch 12/170 => Loss 4.236, Loss_clf 0.683, Loss_fe 0.663, Loss_kd 2.695, Train_accy 69.49, Test_accy 70.33
2024-09-08 12:06:51,497 [foster.py] => Task 5, Epoch 13/170 => Loss 4.248, Loss_clf 0.682, Loss_fe 0.671, Loss_kd 2.700, Train_accy 70.92, Test_accy 71.31
2024-09-08 12:06:57,130 [foster.py] => Task 5, Epoch 14/170 => Loss 4.134, Loss_clf 0.639, Loss_fe 0.628, Loss_kd 2.675, Train_accy 71.97, Test_accy 69.79
2024-09-08 12:07:02,808 [foster.py] => Task 5, Epoch 15/170 => Loss 4.178, Loss_clf 0.644, Loss_fe 0.646, Loss_kd 2.694, Train_accy 71.18, Test_accy 71.61
2024-09-08 12:07:06,678 [foster.py] => Task 5, Epoch 16/170 => Loss 4.145, Loss_clf 0.638, Loss_fe 0.635, Loss_kd 2.679, Train_accy 72.05
2024-09-08 12:07:12,453 [foster.py] => Task 5, Epoch 17/170 => Loss 4.150, Loss_clf 0.645, Loss_fe 0.603, Loss_kd 2.706, Train_accy 72.56, Test_accy 71.39
2024-09-08 12:07:18,169 [foster.py] => Task 5, Epoch 18/170 => Loss 4.117, Loss_clf 0.630, Loss_fe 0.601, Loss_kd 2.692, Train_accy 72.72, Test_accy 71.55
2024-09-08 12:07:23,823 [foster.py] => Task 5, Epoch 19/170 => Loss 4.131, Loss_clf 0.633, Loss_fe 0.600, Loss_kd 2.703, Train_accy 72.38, Test_accy 71.56
2024-09-08 12:07:29,451 [foster.py] => Task 5, Epoch 20/170 => Loss 4.090, Loss_clf 0.626, Loss_fe 0.576, Loss_kd 2.694, Train_accy 72.95, Test_accy 69.79
2024-09-08 12:07:33,335 [foster.py] => Task 5, Epoch 21/170 => Loss 4.073, Loss_clf 0.615, Loss_fe 0.584, Loss_kd 2.682, Train_accy 74.33
2024-09-08 12:07:38,984 [foster.py] => Task 5, Epoch 22/170 => Loss 4.104, Loss_clf 0.615, Loss_fe 0.604, Loss_kd 2.692, Train_accy 73.64, Test_accy 70.93
2024-09-08 12:07:44,694 [foster.py] => Task 5, Epoch 23/170 => Loss 4.010, Loss_clf 0.590, Loss_fe 0.556, Loss_kd 2.671, Train_accy 73.85, Test_accy 70.12
2024-09-08 12:07:50,350 [foster.py] => Task 5, Epoch 24/170 => Loss 4.052, Loss_clf 0.611, Loss_fe 0.568, Loss_kd 2.680, Train_accy 73.62, Test_accy 70.44
2024-09-08 12:07:56,027 [foster.py] => Task 5, Epoch 25/170 => Loss 4.052, Loss_clf 0.614, Loss_fe 0.547, Loss_kd 2.696, Train_accy 74.87, Test_accy 71.01
2024-09-08 12:07:59,891 [foster.py] => Task 5, Epoch 26/170 => Loss 4.073, Loss_clf 0.604, Loss_fe 0.573, Loss_kd 2.701, Train_accy 74.18
2024-09-08 12:08:05,500 [foster.py] => Task 5, Epoch 27/170 => Loss 4.026, Loss_clf 0.576, Loss_fe 0.565, Loss_kd 2.691, Train_accy 74.44, Test_accy 70.39
2024-09-08 12:08:11,250 [foster.py] => Task 5, Epoch 28/170 => Loss 4.060, Loss_clf 0.613, Loss_fe 0.547, Loss_kd 2.705, Train_accy 74.41, Test_accy 70.08
2024-09-08 12:08:16,883 [foster.py] => Task 5, Epoch 29/170 => Loss 4.025, Loss_clf 0.596, Loss_fe 0.533, Loss_kd 2.702, Train_accy 75.72, Test_accy 71.69
2024-09-08 12:08:22,486 [foster.py] => Task 5, Epoch 30/170 => Loss 3.980, Loss_clf 0.577, Loss_fe 0.513, Loss_kd 2.696, Train_accy 75.56, Test_accy 71.48
2024-09-08 12:08:26,407 [foster.py] => Task 5, Epoch 31/170 => Loss 4.024, Loss_clf 0.609, Loss_fe 0.530, Loss_kd 2.691, Train_accy 74.00
2024-09-08 12:08:32,080 [foster.py] => Task 5, Epoch 32/170 => Loss 4.007, Loss_clf 0.589, Loss_fe 0.536, Loss_kd 2.688, Train_accy 75.90, Test_accy 71.43
2024-09-08 12:08:37,776 [foster.py] => Task 5, Epoch 33/170 => Loss 3.965, Loss_clf 0.573, Loss_fe 0.522, Loss_kd 2.677, Train_accy 75.49, Test_accy 71.36
2024-09-08 12:08:43,406 [foster.py] => Task 5, Epoch 34/170 => Loss 3.964, Loss_clf 0.581, Loss_fe 0.506, Loss_kd 2.685, Train_accy 75.08, Test_accy 71.12
2024-09-08 12:08:49,118 [foster.py] => Task 5, Epoch 35/170 => Loss 3.973, Loss_clf 0.578, Loss_fe 0.505, Loss_kd 2.695, Train_accy 75.92, Test_accy 71.44
2024-09-08 12:08:53,025 [foster.py] => Task 5, Epoch 36/170 => Loss 3.965, Loss_clf 0.579, Loss_fe 0.504, Loss_kd 2.688, Train_accy 76.03
2024-09-08 12:08:58,668 [foster.py] => Task 5, Epoch 37/170 => Loss 4.006, Loss_clf 0.591, Loss_fe 0.522, Loss_kd 2.699, Train_accy 76.31, Test_accy 70.96
2024-09-08 12:09:04,289 [foster.py] => Task 5, Epoch 38/170 => Loss 3.978, Loss_clf 0.572, Loss_fe 0.527, Loss_kd 2.685, Train_accy 74.87, Test_accy 70.75
2024-09-08 12:09:09,875 [foster.py] => Task 5, Epoch 39/170 => Loss 3.898, Loss_clf 0.544, Loss_fe 0.481, Loss_kd 2.680, Train_accy 77.74, Test_accy 71.71
2024-09-08 12:09:15,597 [foster.py] => Task 5, Epoch 40/170 => Loss 3.934, Loss_clf 0.563, Loss_fe 0.499, Loss_kd 2.679, Train_accy 75.87, Test_accy 71.48
2024-09-08 12:09:19,506 [foster.py] => Task 5, Epoch 41/170 => Loss 3.938, Loss_clf 0.570, Loss_fe 0.473, Loss_kd 2.700, Train_accy 76.77
2024-09-08 12:09:25,126 [foster.py] => Task 5, Epoch 42/170 => Loss 3.902, Loss_clf 0.543, Loss_fe 0.481, Loss_kd 2.685, Train_accy 76.64, Test_accy 71.83
2024-09-08 12:09:30,803 [foster.py] => Task 5, Epoch 43/170 => Loss 3.936, Loss_clf 0.554, Loss_fe 0.496, Loss_kd 2.692, Train_accy 76.77, Test_accy 71.65
2024-09-08 12:09:36,453 [foster.py] => Task 5, Epoch 44/170 => Loss 3.943, Loss_clf 0.565, Loss_fe 0.476, Loss_kd 2.706, Train_accy 76.28, Test_accy 71.88
2024-09-08 12:09:42,066 [foster.py] => Task 5, Epoch 45/170 => Loss 3.891, Loss_clf 0.532, Loss_fe 0.463, Loss_kd 2.701, Train_accy 78.21, Test_accy 71.87
2024-09-08 12:09:45,920 [foster.py] => Task 5, Epoch 46/170 => Loss 3.900, Loss_clf 0.551, Loss_fe 0.461, Loss_kd 2.694, Train_accy 77.77
2024-09-08 12:09:51,610 [foster.py] => Task 5, Epoch 47/170 => Loss 3.861, Loss_clf 0.527, Loss_fe 0.461, Loss_kd 2.680, Train_accy 78.72, Test_accy 71.23
2024-09-08 12:09:57,272 [foster.py] => Task 5, Epoch 48/170 => Loss 3.907, Loss_clf 0.550, Loss_fe 0.471, Loss_kd 2.693, Train_accy 77.23, Test_accy 71.64
2024-09-08 12:10:02,949 [foster.py] => Task 5, Epoch 49/170 => Loss 3.890, Loss_clf 0.538, Loss_fe 0.456, Loss_kd 2.702, Train_accy 77.92, Test_accy 71.35
2024-09-08 12:10:08,601 [foster.py] => Task 5, Epoch 50/170 => Loss 3.838, Loss_clf 0.515, Loss_fe 0.428, Loss_kd 2.701, Train_accy 77.13, Test_accy 71.88
2024-09-08 12:10:12,450 [foster.py] => Task 5, Epoch 51/170 => Loss 3.918, Loss_clf 0.556, Loss_fe 0.463, Loss_kd 2.704, Train_accy 77.41
2024-09-08 12:10:18,170 [foster.py] => Task 5, Epoch 52/170 => Loss 3.839, Loss_clf 0.514, Loss_fe 0.438, Loss_kd 2.694, Train_accy 77.33, Test_accy 71.53
2024-09-08 12:10:23,873 [foster.py] => Task 5, Epoch 53/170 => Loss 3.857, Loss_clf 0.541, Loss_fe 0.431, Loss_kd 2.691, Train_accy 77.90, Test_accy 70.52
2024-09-08 12:10:29,569 [foster.py] => Task 5, Epoch 54/170 => Loss 3.795, Loss_clf 0.501, Loss_fe 0.408, Loss_kd 2.692, Train_accy 79.51, Test_accy 71.47
2024-09-08 12:10:35,184 [foster.py] => Task 5, Epoch 55/170 => Loss 3.824, Loss_clf 0.518, Loss_fe 0.427, Loss_kd 2.686, Train_accy 78.97, Test_accy 72.01
2024-09-08 12:10:39,001 [foster.py] => Task 5, Epoch 56/170 => Loss 3.868, Loss_clf 0.534, Loss_fe 0.444, Loss_kd 2.695, Train_accy 78.77
2024-09-08 12:10:44,637 [foster.py] => Task 5, Epoch 57/170 => Loss 3.813, Loss_clf 0.513, Loss_fe 0.415, Loss_kd 2.691, Train_accy 78.72, Test_accy 71.37
2024-09-08 12:10:50,272 [foster.py] => Task 5, Epoch 58/170 => Loss 3.851, Loss_clf 0.532, Loss_fe 0.433, Loss_kd 2.692, Train_accy 78.92, Test_accy 71.29
2024-09-08 12:10:55,846 [foster.py] => Task 5, Epoch 59/170 => Loss 3.817, Loss_clf 0.519, Loss_fe 0.415, Loss_kd 2.690, Train_accy 79.15, Test_accy 70.77
2024-09-08 12:11:01,440 [foster.py] => Task 5, Epoch 60/170 => Loss 3.748, Loss_clf 0.476, Loss_fe 0.397, Loss_kd 2.682, Train_accy 79.97, Test_accy 71.15
2024-09-08 12:11:05,316 [foster.py] => Task 5, Epoch 61/170 => Loss 3.775, Loss_clf 0.508, Loss_fe 0.380, Loss_kd 2.693, Train_accy 79.59
2024-09-08 12:11:11,113 [foster.py] => Task 5, Epoch 62/170 => Loss 3.841, Loss_clf 0.519, Loss_fe 0.425, Loss_kd 2.703, Train_accy 79.13, Test_accy 72.03
2024-09-08 12:11:16,833 [foster.py] => Task 5, Epoch 63/170 => Loss 3.752, Loss_clf 0.477, Loss_fe 0.387, Loss_kd 2.694, Train_accy 79.33, Test_accy 70.12
2024-09-08 12:11:22,425 [foster.py] => Task 5, Epoch 64/170 => Loss 3.770, Loss_clf 0.486, Loss_fe 0.399, Loss_kd 2.692, Train_accy 80.13, Test_accy 71.07
2024-09-08 12:11:28,106 [foster.py] => Task 5, Epoch 65/170 => Loss 3.767, Loss_clf 0.503, Loss_fe 0.387, Loss_kd 2.684, Train_accy 78.72, Test_accy 71.89
2024-09-08 12:11:31,938 [foster.py] => Task 5, Epoch 66/170 => Loss 3.767, Loss_clf 0.506, Loss_fe 0.371, Loss_kd 2.696, Train_accy 79.79
2024-09-08 12:11:37,542 [foster.py] => Task 5, Epoch 67/170 => Loss 3.785, Loss_clf 0.487, Loss_fe 0.412, Loss_kd 2.692, Train_accy 79.95, Test_accy 71.12
2024-09-08 12:11:43,166 [foster.py] => Task 5, Epoch 68/170 => Loss 3.778, Loss_clf 0.498, Loss_fe 0.395, Loss_kd 2.691, Train_accy 80.03, Test_accy 71.68
2024-09-08 12:11:48,737 [foster.py] => Task 5, Epoch 69/170 => Loss 3.757, Loss_clf 0.488, Loss_fe 0.378, Loss_kd 2.697, Train_accy 80.62, Test_accy 71.92
2024-09-08 12:11:54,385 [foster.py] => Task 5, Epoch 70/170 => Loss 3.767, Loss_clf 0.502, Loss_fe 0.382, Loss_kd 2.689, Train_accy 79.56, Test_accy 71.91
2024-09-08 12:11:58,240 [foster.py] => Task 5, Epoch 71/170 => Loss 3.734, Loss_clf 0.482, Loss_fe 0.371, Loss_kd 2.688, Train_accy 81.18
2024-09-08 12:12:03,920 [foster.py] => Task 5, Epoch 72/170 => Loss 3.706, Loss_clf 0.463, Loss_fe 0.359, Loss_kd 2.690, Train_accy 80.90, Test_accy 71.48
2024-09-08 12:12:09,597 [foster.py] => Task 5, Epoch 73/170 => Loss 3.745, Loss_clf 0.477, Loss_fe 0.373, Loss_kd 2.701, Train_accy 81.59, Test_accy 70.39
2024-09-08 12:12:15,298 [foster.py] => Task 5, Epoch 74/170 => Loss 3.767, Loss_clf 0.498, Loss_fe 0.375, Loss_kd 2.700, Train_accy 80.85, Test_accy 71.97
2024-09-08 12:12:20,919 [foster.py] => Task 5, Epoch 75/170 => Loss 3.739, Loss_clf 0.489, Loss_fe 0.357, Loss_kd 2.699, Train_accy 81.10, Test_accy 72.01
2024-09-08 12:12:24,787 [foster.py] => Task 5, Epoch 76/170 => Loss 3.738, Loss_clf 0.485, Loss_fe 0.374, Loss_kd 2.685, Train_accy 80.87
2024-09-08 12:12:30,496 [foster.py] => Task 5, Epoch 77/170 => Loss 3.733, Loss_clf 0.475, Loss_fe 0.370, Loss_kd 2.694, Train_accy 80.46, Test_accy 72.28
2024-09-08 12:12:36,207 [foster.py] => Task 5, Epoch 78/170 => Loss 3.717, Loss_clf 0.479, Loss_fe 0.347, Loss_kd 2.697, Train_accy 81.28, Test_accy 71.35
2024-09-08 12:12:41,846 [foster.py] => Task 5, Epoch 79/170 => Loss 3.687, Loss_clf 0.463, Loss_fe 0.334, Loss_kd 2.696, Train_accy 82.23, Test_accy 71.97
2024-09-08 12:12:47,485 [foster.py] => Task 5, Epoch 80/170 => Loss 3.721, Loss_clf 0.471, Loss_fe 0.352, Loss_kd 2.703, Train_accy 80.69, Test_accy 72.49
2024-09-08 12:12:51,390 [foster.py] => Task 5, Epoch 81/170 => Loss 3.687, Loss_clf 0.465, Loss_fe 0.322, Loss_kd 2.705, Train_accy 82.00
2024-09-08 12:12:57,025 [foster.py] => Task 5, Epoch 82/170 => Loss 3.669, Loss_clf 0.449, Loss_fe 0.332, Loss_kd 2.694, Train_accy 81.79, Test_accy 71.65
2024-09-08 12:13:02,673 [foster.py] => Task 5, Epoch 83/170 => Loss 3.736, Loss_clf 0.484, Loss_fe 0.343, Loss_kd 2.713, Train_accy 81.46, Test_accy 72.31
2024-09-08 12:13:08,270 [foster.py] => Task 5, Epoch 84/170 => Loss 3.695, Loss_clf 0.453, Loss_fe 0.338, Loss_kd 2.708, Train_accy 81.69, Test_accy 71.28
2024-09-08 12:13:13,901 [foster.py] => Task 5, Epoch 85/170 => Loss 3.646, Loss_clf 0.446, Loss_fe 0.313, Loss_kd 2.693, Train_accy 82.03, Test_accy 72.23
2024-09-08 12:13:17,753 [foster.py] => Task 5, Epoch 86/170 => Loss 3.642, Loss_clf 0.448, Loss_fe 0.312, Loss_kd 2.689, Train_accy 83.08
2024-09-08 12:13:23,359 [foster.py] => Task 5, Epoch 87/170 => Loss 3.661, Loss_clf 0.461, Loss_fe 0.320, Loss_kd 2.687, Train_accy 81.33, Test_accy 72.07
2024-09-08 12:13:29,072 [foster.py] => Task 5, Epoch 88/170 => Loss 3.636, Loss_clf 0.445, Loss_fe 0.311, Loss_kd 2.687, Train_accy 83.26, Test_accy 71.87
2024-09-08 12:13:34,688 [foster.py] => Task 5, Epoch 89/170 => Loss 3.629, Loss_clf 0.436, Loss_fe 0.320, Loss_kd 2.680, Train_accy 82.31, Test_accy 71.73
2024-09-08 12:13:40,378 [foster.py] => Task 5, Epoch 90/170 => Loss 3.627, Loss_clf 0.431, Loss_fe 0.317, Loss_kd 2.686, Train_accy 83.15, Test_accy 71.83
2024-09-08 12:13:44,236 [foster.py] => Task 5, Epoch 91/170 => Loss 3.626, Loss_clf 0.437, Loss_fe 0.301, Loss_kd 2.694, Train_accy 83.85
2024-09-08 12:13:49,883 [foster.py] => Task 5, Epoch 92/170 => Loss 3.616, Loss_clf 0.425, Loss_fe 0.306, Loss_kd 2.691, Train_accy 82.77, Test_accy 72.49
2024-09-08 12:13:55,734 [foster.py] => Task 5, Epoch 93/170 => Loss 3.569, Loss_clf 0.418, Loss_fe 0.278, Loss_kd 2.679, Train_accy 83.74, Test_accy 71.71
2024-09-08 12:14:01,396 [foster.py] => Task 5, Epoch 94/170 => Loss 3.599, Loss_clf 0.432, Loss_fe 0.289, Loss_kd 2.684, Train_accy 83.54, Test_accy 71.59
2024-09-08 12:14:07,011 [foster.py] => Task 5, Epoch 95/170 => Loss 3.603, Loss_clf 0.420, Loss_fe 0.288, Loss_kd 2.700, Train_accy 84.15, Test_accy 72.20
2024-09-08 12:14:10,902 [foster.py] => Task 5, Epoch 96/170 => Loss 3.563, Loss_clf 0.415, Loss_fe 0.268, Loss_kd 2.686, Train_accy 83.67
2024-09-08 12:14:16,537 [foster.py] => Task 5, Epoch 97/170 => Loss 3.635, Loss_clf 0.440, Loss_fe 0.298, Loss_kd 2.702, Train_accy 83.85, Test_accy 72.08
2024-09-08 12:14:22,159 [foster.py] => Task 5, Epoch 98/170 => Loss 3.617, Loss_clf 0.436, Loss_fe 0.291, Loss_kd 2.696, Train_accy 83.36, Test_accy 71.39
2024-09-08 12:14:27,789 [foster.py] => Task 5, Epoch 99/170 => Loss 3.562, Loss_clf 0.417, Loss_fe 0.266, Loss_kd 2.686, Train_accy 84.13, Test_accy 71.97
2024-09-08 12:14:33,474 [foster.py] => Task 5, Epoch 100/170 => Loss 3.552, Loss_clf 0.408, Loss_fe 0.264, Loss_kd 2.686, Train_accy 85.18, Test_accy 72.25
2024-09-08 12:14:37,332 [foster.py] => Task 5, Epoch 101/170 => Loss 3.579, Loss_clf 0.409, Loss_fe 0.277, Loss_kd 2.699, Train_accy 84.62
2024-09-08 12:14:43,044 [foster.py] => Task 5, Epoch 102/170 => Loss 3.610, Loss_clf 0.426, Loss_fe 0.276, Loss_kd 2.712, Train_accy 84.05, Test_accy 72.64
2024-09-08 12:14:48,674 [foster.py] => Task 5, Epoch 103/170 => Loss 3.599, Loss_clf 0.430, Loss_fe 0.272, Loss_kd 2.702, Train_accy 83.21, Test_accy 71.84
2024-09-08 12:14:54,312 [foster.py] => Task 5, Epoch 104/170 => Loss 3.586, Loss_clf 0.427, Loss_fe 0.271, Loss_kd 2.695, Train_accy 84.00, Test_accy 71.57
2024-09-08 12:14:59,952 [foster.py] => Task 5, Epoch 105/170 => Loss 3.556, Loss_clf 0.402, Loss_fe 0.263, Loss_kd 2.698, Train_accy 84.31, Test_accy 72.47
2024-09-08 12:15:03,849 [foster.py] => Task 5, Epoch 106/170 => Loss 3.500, Loss_clf 0.384, Loss_fe 0.241, Loss_kd 2.682, Train_accy 84.72
2024-09-08 12:15:09,555 [foster.py] => Task 5, Epoch 107/170 => Loss 3.582, Loss_clf 0.434, Loss_fe 0.258, Loss_kd 2.696, Train_accy 84.51, Test_accy 72.75
2024-09-08 12:15:15,313 [foster.py] => Task 5, Epoch 108/170 => Loss 3.567, Loss_clf 0.417, Loss_fe 0.260, Loss_kd 2.696, Train_accy 83.31, Test_accy 72.45
2024-09-08 12:15:20,950 [foster.py] => Task 5, Epoch 109/170 => Loss 3.582, Loss_clf 0.413, Loss_fe 0.269, Loss_kd 2.705, Train_accy 84.36, Test_accy 72.51
2024-09-08 12:15:26,593 [foster.py] => Task 5, Epoch 110/170 => Loss 3.564, Loss_clf 0.424, Loss_fe 0.256, Loss_kd 2.690, Train_accy 84.18, Test_accy 72.31
2024-09-08 12:15:30,539 [foster.py] => Task 5, Epoch 111/170 => Loss 3.526, Loss_clf 0.405, Loss_fe 0.238, Loss_kd 2.689, Train_accy 85.21
2024-09-08 12:15:36,186 [foster.py] => Task 5, Epoch 112/170 => Loss 3.515, Loss_clf 0.396, Loss_fe 0.227, Loss_kd 2.698, Train_accy 85.92, Test_accy 71.52
2024-09-08 12:15:41,795 [foster.py] => Task 5, Epoch 113/170 => Loss 3.538, Loss_clf 0.404, Loss_fe 0.247, Loss_kd 2.693, Train_accy 85.72, Test_accy 72.11
2024-09-08 12:15:47,502 [foster.py] => Task 5, Epoch 114/170 => Loss 3.527, Loss_clf 0.400, Loss_fe 0.235, Loss_kd 2.698, Train_accy 86.03, Test_accy 71.84
2024-09-08 12:15:53,156 [foster.py] => Task 5, Epoch 115/170 => Loss 3.524, Loss_clf 0.398, Loss_fe 0.235, Loss_kd 2.697, Train_accy 86.03, Test_accy 72.48
2024-09-08 12:15:56,995 [foster.py] => Task 5, Epoch 116/170 => Loss 3.489, Loss_clf 0.382, Loss_fe 0.223, Loss_kd 2.690, Train_accy 86.33
2024-09-08 12:16:02,603 [foster.py] => Task 5, Epoch 117/170 => Loss 3.486, Loss_clf 0.371, Loss_fe 0.229, Loss_kd 2.692, Train_accy 86.13, Test_accy 72.49
2024-09-08 12:16:08,278 [foster.py] => Task 5, Epoch 118/170 => Loss 3.531, Loss_clf 0.400, Loss_fe 0.227, Loss_kd 2.709, Train_accy 85.56, Test_accy 72.21
2024-09-08 12:16:13,887 [foster.py] => Task 5, Epoch 119/170 => Loss 3.519, Loss_clf 0.398, Loss_fe 0.225, Loss_kd 2.701, Train_accy 85.26, Test_accy 72.44
2024-09-08 12:16:19,534 [foster.py] => Task 5, Epoch 120/170 => Loss 3.529, Loss_clf 0.400, Loss_fe 0.230, Loss_kd 2.704, Train_accy 85.23, Test_accy 72.32
2024-09-08 12:16:23,445 [foster.py] => Task 5, Epoch 121/170 => Loss 3.512, Loss_clf 0.387, Loss_fe 0.231, Loss_kd 2.699, Train_accy 86.38
2024-09-08 12:16:29,107 [foster.py] => Task 5, Epoch 122/170 => Loss 3.448, Loss_clf 0.362, Loss_fe 0.211, Loss_kd 2.682, Train_accy 85.64, Test_accy 72.28
2024-09-08 12:16:34,712 [foster.py] => Task 5, Epoch 123/170 => Loss 3.483, Loss_clf 0.369, Loss_fe 0.217, Loss_kd 2.703, Train_accy 86.18, Test_accy 72.43
2024-09-08 12:16:40,479 [foster.py] => Task 5, Epoch 124/170 => Loss 3.452, Loss_clf 0.361, Loss_fe 0.202, Loss_kd 2.695, Train_accy 86.54, Test_accy 72.37
2024-09-08 12:16:46,141 [foster.py] => Task 5, Epoch 125/170 => Loss 3.469, Loss_clf 0.372, Loss_fe 0.206, Loss_kd 2.697, Train_accy 86.26, Test_accy 72.51
2024-09-08 12:16:50,040 [foster.py] => Task 5, Epoch 126/170 => Loss 3.481, Loss_clf 0.378, Loss_fe 0.206, Loss_kd 2.702, Train_accy 86.64
2024-09-08 12:16:55,681 [foster.py] => Task 5, Epoch 127/170 => Loss 3.483, Loss_clf 0.383, Loss_fe 0.210, Loss_kd 2.696, Train_accy 86.13, Test_accy 72.43
2024-09-08 12:17:01,332 [foster.py] => Task 5, Epoch 128/170 => Loss 3.459, Loss_clf 0.373, Loss_fe 0.206, Loss_kd 2.687, Train_accy 86.33, Test_accy 72.44
2024-09-08 12:17:06,957 [foster.py] => Task 5, Epoch 129/170 => Loss 3.467, Loss_clf 0.367, Loss_fe 0.204, Loss_kd 2.701, Train_accy 86.67, Test_accy 72.40
2024-09-08 12:17:12,652 [foster.py] => Task 5, Epoch 130/170 => Loss 3.500, Loss_clf 0.389, Loss_fe 0.220, Loss_kd 2.697, Train_accy 86.26, Test_accy 72.45
2024-09-08 12:17:16,549 [foster.py] => Task 5, Epoch 131/170 => Loss 3.464, Loss_clf 0.374, Loss_fe 0.205, Loss_kd 2.691, Train_accy 86.46
2024-09-08 12:17:22,202 [foster.py] => Task 5, Epoch 132/170 => Loss 3.464, Loss_clf 0.375, Loss_fe 0.201, Loss_kd 2.693, Train_accy 86.87, Test_accy 72.37
2024-09-08 12:17:27,941 [foster.py] => Task 5, Epoch 133/170 => Loss 3.404, Loss_clf 0.348, Loss_fe 0.179, Loss_kd 2.683, Train_accy 87.51, Test_accy 72.35
2024-09-08 12:17:33,583 [foster.py] => Task 5, Epoch 134/170 => Loss 3.455, Loss_clf 0.365, Loss_fe 0.196, Loss_kd 2.699, Train_accy 86.85, Test_accy 72.31
2024-09-08 12:17:39,185 [foster.py] => Task 5, Epoch 135/170 => Loss 3.442, Loss_clf 0.365, Loss_fe 0.193, Loss_kd 2.690, Train_accy 87.13, Test_accy 72.61
2024-09-08 12:17:42,988 [foster.py] => Task 5, Epoch 136/170 => Loss 3.431, Loss_clf 0.364, Loss_fe 0.186, Loss_kd 2.687, Train_accy 86.03
2024-09-08 12:17:48,532 [foster.py] => Task 5, Epoch 137/170 => Loss 3.415, Loss_clf 0.345, Loss_fe 0.173, Loss_kd 2.702, Train_accy 87.82, Test_accy 72.20
2024-09-08 12:17:54,130 [foster.py] => Task 5, Epoch 138/170 => Loss 3.420, Loss_clf 0.352, Loss_fe 0.185, Loss_kd 2.690, Train_accy 87.54, Test_accy 72.60
2024-09-08 12:17:59,769 [foster.py] => Task 5, Epoch 139/170 => Loss 3.438, Loss_clf 0.368, Loss_fe 0.177, Loss_kd 2.699, Train_accy 86.92, Test_accy 72.21
2024-09-08 12:18:05,434 [foster.py] => Task 5, Epoch 140/170 => Loss 3.420, Loss_clf 0.350, Loss_fe 0.179, Loss_kd 2.697, Train_accy 87.51, Test_accy 72.44
2024-09-08 12:18:09,380 [foster.py] => Task 5, Epoch 141/170 => Loss 3.429, Loss_clf 0.363, Loss_fe 0.169, Loss_kd 2.703, Train_accy 86.62
2024-09-08 12:18:14,989 [foster.py] => Task 5, Epoch 142/170 => Loss 3.381, Loss_clf 0.343, Loss_fe 0.162, Loss_kd 2.682, Train_accy 88.59, Test_accy 72.47
2024-09-08 12:18:20,741 [foster.py] => Task 5, Epoch 143/170 => Loss 3.397, Loss_clf 0.344, Loss_fe 0.179, Loss_kd 2.682, Train_accy 87.95, Test_accy 72.69
2024-09-08 12:18:26,383 [foster.py] => Task 5, Epoch 144/170 => Loss 3.464, Loss_clf 0.377, Loss_fe 0.186, Loss_kd 2.706, Train_accy 86.87, Test_accy 72.65
2024-09-08 12:18:32,060 [foster.py] => Task 5, Epoch 145/170 => Loss 3.451, Loss_clf 0.375, Loss_fe 0.179, Loss_kd 2.703, Train_accy 87.54, Test_accy 72.72
2024-09-08 12:18:35,948 [foster.py] => Task 5, Epoch 146/170 => Loss 3.464, Loss_clf 0.382, Loss_fe 0.179, Loss_kd 2.708, Train_accy 86.95
2024-09-08 12:18:41,717 [foster.py] => Task 5, Epoch 147/170 => Loss 3.439, Loss_clf 0.362, Loss_fe 0.180, Loss_kd 2.703, Train_accy 88.18, Test_accy 72.64
2024-09-08 12:18:47,396 [foster.py] => Task 5, Epoch 148/170 => Loss 3.350, Loss_clf 0.314, Loss_fe 0.148, Loss_kd 2.694, Train_accy 89.44, Test_accy 72.59
2024-09-08 12:18:53,126 [foster.py] => Task 5, Epoch 149/170 => Loss 3.419, Loss_clf 0.354, Loss_fe 0.176, Loss_kd 2.695, Train_accy 87.95, Test_accy 72.47
2024-09-08 12:18:58,777 [foster.py] => Task 5, Epoch 150/170 => Loss 3.389, Loss_clf 0.334, Loss_fe 0.165, Loss_kd 2.696, Train_accy 88.54, Test_accy 72.53
2024-09-08 12:19:02,675 [foster.py] => Task 5, Epoch 151/170 => Loss 3.366, Loss_clf 0.333, Loss_fe 0.157, Loss_kd 2.683, Train_accy 88.54
2024-09-08 12:19:08,457 [foster.py] => Task 5, Epoch 152/170 => Loss 3.369, Loss_clf 0.340, Loss_fe 0.163, Loss_kd 2.674, Train_accy 88.03, Test_accy 72.56
2024-09-08 12:19:14,118 [foster.py] => Task 5, Epoch 153/170 => Loss 3.403, Loss_clf 0.336, Loss_fe 0.172, Loss_kd 2.701, Train_accy 88.64, Test_accy 72.61
2024-09-08 12:19:19,830 [foster.py] => Task 5, Epoch 154/170 => Loss 3.427, Loss_clf 0.361, Loss_fe 0.171, Loss_kd 2.701, Train_accy 87.49, Test_accy 72.65
2024-09-08 12:19:25,425 [foster.py] => Task 5, Epoch 155/170 => Loss 3.410, Loss_clf 0.353, Loss_fe 0.174, Loss_kd 2.689, Train_accy 88.21, Test_accy 72.69
2024-09-08 12:19:29,295 [foster.py] => Task 5, Epoch 156/170 => Loss 3.414, Loss_clf 0.351, Loss_fe 0.169, Loss_kd 2.700, Train_accy 87.90
2024-09-08 12:19:34,955 [foster.py] => Task 5, Epoch 157/170 => Loss 3.372, Loss_clf 0.329, Loss_fe 0.154, Loss_kd 2.695, Train_accy 88.36, Test_accy 72.59
2024-09-08 12:19:40,620 [foster.py] => Task 5, Epoch 158/170 => Loss 3.383, Loss_clf 0.338, Loss_fe 0.164, Loss_kd 2.688, Train_accy 88.41, Test_accy 72.75
2024-09-08 12:19:46,233 [foster.py] => Task 5, Epoch 159/170 => Loss 3.423, Loss_clf 0.350, Loss_fe 0.179, Loss_kd 2.699, Train_accy 87.08, Test_accy 72.71
2024-09-08 12:19:51,840 [foster.py] => Task 5, Epoch 160/170 => Loss 3.389, Loss_clf 0.341, Loss_fe 0.161, Loss_kd 2.693, Train_accy 88.31, Test_accy 72.69
2024-09-08 12:19:55,778 [foster.py] => Task 5, Epoch 161/170 => Loss 3.381, Loss_clf 0.328, Loss_fe 0.161, Loss_kd 2.697, Train_accy 88.49
2024-09-08 12:20:01,372 [foster.py] => Task 5, Epoch 162/170 => Loss 3.384, Loss_clf 0.343, Loss_fe 0.166, Loss_kd 2.682, Train_accy 87.41, Test_accy 72.71
2024-09-08 12:20:06,954 [foster.py] => Task 5, Epoch 163/170 => Loss 3.338, Loss_clf 0.321, Loss_fe 0.139, Loss_kd 2.685, Train_accy 88.69, Test_accy 72.69
2024-09-08 12:20:12,572 [foster.py] => Task 5, Epoch 164/170 => Loss 3.384, Loss_clf 0.342, Loss_fe 0.167, Loss_kd 2.682, Train_accy 87.82, Test_accy 72.64
2024-09-08 12:20:18,184 [foster.py] => Task 5, Epoch 165/170 => Loss 3.413, Loss_clf 0.357, Loss_fe 0.169, Loss_kd 2.693, Train_accy 87.21, Test_accy 72.67
2024-09-08 12:20:22,024 [foster.py] => Task 5, Epoch 166/170 => Loss 3.326, Loss_clf 0.313, Loss_fe 0.139, Loss_kd 2.680, Train_accy 89.10
2024-09-08 12:20:27,643 [foster.py] => Task 5, Epoch 167/170 => Loss 3.373, Loss_clf 0.329, Loss_fe 0.158, Loss_kd 2.692, Train_accy 88.46, Test_accy 72.60
2024-09-08 12:20:33,298 [foster.py] => Task 5, Epoch 168/170 => Loss 3.412, Loss_clf 0.356, Loss_fe 0.162, Loss_kd 2.700, Train_accy 88.00, Test_accy 72.72
2024-09-08 12:20:39,009 [foster.py] => Task 5, Epoch 169/170 => Loss 3.375, Loss_clf 0.337, Loss_fe 0.154, Loss_kd 2.690, Train_accy 88.15, Test_accy 72.67
2024-09-08 12:20:44,627 [foster.py] => Task 5, Epoch 170/170 => Loss 3.383, Loss_clf 0.333, Loss_fe 0.165, Loss_kd 2.691, Train_accy 87.77, Test_accy 72.67
2024-09-08 12:20:44,630 [foster.py] => do not weight align teacher!
2024-09-08 12:20:44,632 [foster.py] => per cls weights : [1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569 1.03279569
 1.03279569 1.03279569 1.03279569 1.03279569 0.54086041 0.54086041
 0.54086041 0.54086041 0.54086041]
2024-09-08 12:20:51,446 [foster.py] => SNet: Task 5, Epoch 1/130 => Loss 29.884,  Loss1 0.741, Train_accy 38.23, Test_accy 66.72
2024-09-08 12:20:56,866 [foster.py] => SNet: Task 5, Epoch 2/130 => Loss 29.755,  Loss1 0.741, Train_accy 56.97
2024-09-08 12:21:02,353 [foster.py] => SNet: Task 5, Epoch 3/130 => Loss 29.689,  Loss1 0.741, Train_accy 62.00
2024-09-08 12:21:07,820 [foster.py] => SNet: Task 5, Epoch 4/130 => Loss 29.718,  Loss1 0.741, Train_accy 64.18
2024-09-08 12:21:13,283 [foster.py] => SNet: Task 5, Epoch 5/130 => Loss 29.699,  Loss1 0.740, Train_accy 67.64
2024-09-08 12:21:19,850 [foster.py] => SNet: Task 5, Epoch 6/130 => Loss 29.662,  Loss1 0.740, Train_accy 68.36, Test_accy 70.08
2024-09-08 12:21:25,289 [foster.py] => SNet: Task 5, Epoch 7/130 => Loss 29.661,  Loss1 0.740, Train_accy 68.54
2024-09-08 12:21:30,717 [foster.py] => SNet: Task 5, Epoch 8/130 => Loss 29.641,  Loss1 0.740, Train_accy 69.38
2024-09-08 12:21:36,191 [foster.py] => SNet: Task 5, Epoch 9/130 => Loss 29.664,  Loss1 0.740, Train_accy 70.36
2024-09-08 12:21:41,683 [foster.py] => SNet: Task 5, Epoch 10/130 => Loss 29.682,  Loss1 0.740, Train_accy 70.21
2024-09-08 12:21:48,291 [foster.py] => SNet: Task 5, Epoch 11/130 => Loss 29.687,  Loss1 0.740, Train_accy 70.97, Test_accy 70.40
2024-09-08 12:21:53,747 [foster.py] => SNet: Task 5, Epoch 12/130 => Loss 29.664,  Loss1 0.740, Train_accy 70.72
2024-09-08 12:21:59,205 [foster.py] => SNet: Task 5, Epoch 13/130 => Loss 29.630,  Loss1 0.740, Train_accy 72.08
2024-09-08 12:22:04,651 [foster.py] => SNet: Task 5, Epoch 14/130 => Loss 29.630,  Loss1 0.740, Train_accy 72.36
2024-09-08 12:22:10,111 [foster.py] => SNet: Task 5, Epoch 15/130 => Loss 29.620,  Loss1 0.740, Train_accy 71.77
2024-09-08 12:22:16,650 [foster.py] => SNet: Task 5, Epoch 16/130 => Loss 29.651,  Loss1 0.740, Train_accy 72.95, Test_accy 70.75
2024-09-08 12:22:22,092 [foster.py] => SNet: Task 5, Epoch 17/130 => Loss 29.667,  Loss1 0.739, Train_accy 71.87
2024-09-08 12:22:27,479 [foster.py] => SNet: Task 5, Epoch 18/130 => Loss 29.629,  Loss1 0.740, Train_accy 71.92
2024-09-08 12:22:32,932 [foster.py] => SNet: Task 5, Epoch 19/130 => Loss 29.649,  Loss1 0.739, Train_accy 72.08
2024-09-08 12:22:38,401 [foster.py] => SNet: Task 5, Epoch 20/130 => Loss 29.646,  Loss1 0.740, Train_accy 73.46
2024-09-08 12:22:44,945 [foster.py] => SNet: Task 5, Epoch 21/130 => Loss 29.681,  Loss1 0.739, Train_accy 72.49, Test_accy 70.44
2024-09-08 12:22:50,462 [foster.py] => SNet: Task 5, Epoch 22/130 => Loss 29.643,  Loss1 0.739, Train_accy 73.95
2024-09-08 12:22:55,936 [foster.py] => SNet: Task 5, Epoch 23/130 => Loss 29.630,  Loss1 0.740, Train_accy 73.85
2024-09-08 12:23:01,385 [foster.py] => SNet: Task 5, Epoch 24/130 => Loss 29.680,  Loss1 0.739, Train_accy 72.46
2024-09-08 12:23:06,829 [foster.py] => SNet: Task 5, Epoch 25/130 => Loss 29.662,  Loss1 0.739, Train_accy 73.41
2024-09-08 12:23:13,456 [foster.py] => SNet: Task 5, Epoch 26/130 => Loss 29.658,  Loss1 0.739, Train_accy 74.15, Test_accy 70.32
2024-09-08 12:23:18,899 [foster.py] => SNet: Task 5, Epoch 27/130 => Loss 29.668,  Loss1 0.739, Train_accy 74.56
2024-09-08 12:23:24,361 [foster.py] => SNet: Task 5, Epoch 28/130 => Loss 29.606,  Loss1 0.739, Train_accy 74.49
2024-09-08 12:23:29,801 [foster.py] => SNet: Task 5, Epoch 29/130 => Loss 29.647,  Loss1 0.740, Train_accy 74.64
2024-09-08 12:23:35,274 [foster.py] => SNet: Task 5, Epoch 30/130 => Loss 29.636,  Loss1 0.740, Train_accy 74.79
2024-09-08 12:23:41,848 [foster.py] => SNet: Task 5, Epoch 31/130 => Loss 29.636,  Loss1 0.739, Train_accy 73.77, Test_accy 70.75
2024-09-08 12:23:47,365 [foster.py] => SNet: Task 5, Epoch 32/130 => Loss 29.630,  Loss1 0.739, Train_accy 74.82
2024-09-08 12:23:52,835 [foster.py] => SNet: Task 5, Epoch 33/130 => Loss 29.664,  Loss1 0.739, Train_accy 74.72
2024-09-08 12:23:58,274 [foster.py] => SNet: Task 5, Epoch 34/130 => Loss 29.620,  Loss1 0.739, Train_accy 75.46
2024-09-08 12:24:03,756 [foster.py] => SNet: Task 5, Epoch 35/130 => Loss 29.648,  Loss1 0.739, Train_accy 74.77
2024-09-08 12:24:10,326 [foster.py] => SNet: Task 5, Epoch 36/130 => Loss 29.646,  Loss1 0.739, Train_accy 74.44, Test_accy 70.67
2024-09-08 12:24:15,738 [foster.py] => SNet: Task 5, Epoch 37/130 => Loss 29.652,  Loss1 0.739, Train_accy 75.62
2024-09-08 12:24:21,206 [foster.py] => SNet: Task 5, Epoch 38/130 => Loss 29.670,  Loss1 0.740, Train_accy 75.33
2024-09-08 12:24:26,635 [foster.py] => SNet: Task 5, Epoch 39/130 => Loss 29.655,  Loss1 0.740, Train_accy 74.67
2024-09-08 12:24:32,160 [foster.py] => SNet: Task 5, Epoch 40/130 => Loss 29.632,  Loss1 0.739, Train_accy 75.26
2024-09-08 12:24:38,720 [foster.py] => SNet: Task 5, Epoch 41/130 => Loss 29.665,  Loss1 0.739, Train_accy 74.44, Test_accy 70.99
2024-09-08 12:24:44,172 [foster.py] => SNet: Task 5, Epoch 42/130 => Loss 29.663,  Loss1 0.739, Train_accy 76.54
2024-09-08 12:24:49,635 [foster.py] => SNet: Task 5, Epoch 43/130 => Loss 29.661,  Loss1 0.739, Train_accy 75.18
2024-09-08 12:24:55,070 [foster.py] => SNet: Task 5, Epoch 44/130 => Loss 29.655,  Loss1 0.739, Train_accy 75.59
2024-09-08 12:25:00,521 [foster.py] => SNet: Task 5, Epoch 45/130 => Loss 29.654,  Loss1 0.739, Train_accy 74.97
2024-09-08 12:25:07,092 [foster.py] => SNet: Task 5, Epoch 46/130 => Loss 29.671,  Loss1 0.739, Train_accy 75.46, Test_accy 71.13
2024-09-08 12:25:12,531 [foster.py] => SNet: Task 5, Epoch 47/130 => Loss 29.624,  Loss1 0.739, Train_accy 76.72
2024-09-08 12:25:18,024 [foster.py] => SNet: Task 5, Epoch 48/130 => Loss 29.650,  Loss1 0.739, Train_accy 76.18
2024-09-08 12:25:23,497 [foster.py] => SNet: Task 5, Epoch 49/130 => Loss 29.621,  Loss1 0.739, Train_accy 75.85
2024-09-08 12:25:28,999 [foster.py] => SNet: Task 5, Epoch 50/130 => Loss 29.647,  Loss1 0.739, Train_accy 76.56
2024-09-08 12:25:35,582 [foster.py] => SNet: Task 5, Epoch 51/130 => Loss 29.658,  Loss1 0.739, Train_accy 75.72, Test_accy 71.16
2024-09-08 12:25:41,000 [foster.py] => SNet: Task 5, Epoch 52/130 => Loss 29.654,  Loss1 0.739, Train_accy 75.49
2024-09-08 12:25:46,438 [foster.py] => SNet: Task 5, Epoch 53/130 => Loss 29.612,  Loss1 0.739, Train_accy 75.46
2024-09-08 12:25:51,866 [foster.py] => SNet: Task 5, Epoch 54/130 => Loss 29.620,  Loss1 0.739, Train_accy 77.49
2024-09-08 12:25:57,314 [foster.py] => SNet: Task 5, Epoch 55/130 => Loss 29.611,  Loss1 0.739, Train_accy 76.90
2024-09-08 12:26:04,004 [foster.py] => SNet: Task 5, Epoch 56/130 => Loss 29.648,  Loss1 0.739, Train_accy 74.49, Test_accy 71.09
2024-09-08 12:26:09,467 [foster.py] => SNet: Task 5, Epoch 57/130 => Loss 29.673,  Loss1 0.739, Train_accy 75.77
2024-09-08 12:26:14,935 [foster.py] => SNet: Task 5, Epoch 58/130 => Loss 29.665,  Loss1 0.739, Train_accy 76.59
2024-09-08 12:26:20,367 [foster.py] => SNet: Task 5, Epoch 59/130 => Loss 29.649,  Loss1 0.739, Train_accy 76.23
2024-09-08 12:26:25,796 [foster.py] => SNet: Task 5, Epoch 60/130 => Loss 29.648,  Loss1 0.739, Train_accy 75.74
2024-09-08 12:26:32,437 [foster.py] => SNet: Task 5, Epoch 61/130 => Loss 29.628,  Loss1 0.739, Train_accy 77.74, Test_accy 70.72
2024-09-08 12:26:37,872 [foster.py] => SNet: Task 5, Epoch 62/130 => Loss 29.646,  Loss1 0.739, Train_accy 75.67
2024-09-08 12:26:43,307 [foster.py] => SNet: Task 5, Epoch 63/130 => Loss 29.650,  Loss1 0.739, Train_accy 77.13
2024-09-08 12:26:48,762 [foster.py] => SNet: Task 5, Epoch 64/130 => Loss 29.640,  Loss1 0.739, Train_accy 76.79
2024-09-08 12:26:54,199 [foster.py] => SNet: Task 5, Epoch 65/130 => Loss 29.612,  Loss1 0.739, Train_accy 76.00
2024-09-08 12:27:00,749 [foster.py] => SNet: Task 5, Epoch 66/130 => Loss 29.634,  Loss1 0.739, Train_accy 76.26, Test_accy 70.95
2024-09-08 12:27:06,197 [foster.py] => SNet: Task 5, Epoch 67/130 => Loss 29.630,  Loss1 0.739, Train_accy 76.21
2024-09-08 12:27:11,636 [foster.py] => SNet: Task 5, Epoch 68/130 => Loss 29.625,  Loss1 0.740, Train_accy 75.87
2024-09-08 12:27:17,065 [foster.py] => SNet: Task 5, Epoch 69/130 => Loss 29.638,  Loss1 0.740, Train_accy 76.49
2024-09-08 12:27:22,477 [foster.py] => SNet: Task 5, Epoch 70/130 => Loss 29.603,  Loss1 0.739, Train_accy 76.31
2024-09-08 12:27:29,030 [foster.py] => SNet: Task 5, Epoch 71/130 => Loss 29.628,  Loss1 0.739, Train_accy 75.46, Test_accy 71.09
2024-09-08 12:27:34,498 [foster.py] => SNet: Task 5, Epoch 72/130 => Loss 29.618,  Loss1 0.739, Train_accy 76.67
2024-09-08 12:27:39,927 [foster.py] => SNet: Task 5, Epoch 73/130 => Loss 29.627,  Loss1 0.739, Train_accy 75.90
2024-09-08 12:27:45,438 [foster.py] => SNet: Task 5, Epoch 74/130 => Loss 29.634,  Loss1 0.739, Train_accy 77.33
2024-09-08 12:27:50,911 [foster.py] => SNet: Task 5, Epoch 75/130 => Loss 29.634,  Loss1 0.739, Train_accy 75.97
2024-09-08 12:27:57,496 [foster.py] => SNet: Task 5, Epoch 76/130 => Loss 29.653,  Loss1 0.739, Train_accy 75.56, Test_accy 71.15
2024-09-08 12:28:02,935 [foster.py] => SNet: Task 5, Epoch 77/130 => Loss 29.616,  Loss1 0.739, Train_accy 77.36
2024-09-08 12:28:08,382 [foster.py] => SNet: Task 5, Epoch 78/130 => Loss 29.616,  Loss1 0.739, Train_accy 76.21
2024-09-08 12:28:13,848 [foster.py] => SNet: Task 5, Epoch 79/130 => Loss 29.644,  Loss1 0.739, Train_accy 76.62
2024-09-08 12:28:19,262 [foster.py] => SNet: Task 5, Epoch 80/130 => Loss 29.661,  Loss1 0.739, Train_accy 75.77
2024-09-08 12:28:25,810 [foster.py] => SNet: Task 5, Epoch 81/130 => Loss 29.650,  Loss1 0.739, Train_accy 76.49, Test_accy 70.97
2024-09-08 12:28:31,249 [foster.py] => SNet: Task 5, Epoch 82/130 => Loss 29.661,  Loss1 0.739, Train_accy 75.56
2024-09-08 12:28:36,730 [foster.py] => SNet: Task 5, Epoch 83/130 => Loss 29.640,  Loss1 0.739, Train_accy 77.00
2024-09-08 12:28:42,217 [foster.py] => SNet: Task 5, Epoch 84/130 => Loss 29.642,  Loss1 0.739, Train_accy 77.56
2024-09-08 12:28:47,677 [foster.py] => SNet: Task 5, Epoch 85/130 => Loss 29.672,  Loss1 0.739, Train_accy 76.56
2024-09-08 12:28:54,242 [foster.py] => SNet: Task 5, Epoch 86/130 => Loss 29.662,  Loss1 0.739, Train_accy 76.97, Test_accy 71.32
2024-09-08 12:28:59,712 [foster.py] => SNet: Task 5, Epoch 87/130 => Loss 29.659,  Loss1 0.739, Train_accy 76.74
2024-09-08 12:29:05,114 [foster.py] => SNet: Task 5, Epoch 88/130 => Loss 29.622,  Loss1 0.739, Train_accy 77.15
2024-09-08 12:29:10,582 [foster.py] => SNet: Task 5, Epoch 89/130 => Loss 29.628,  Loss1 0.739, Train_accy 77.28
2024-09-08 12:29:16,030 [foster.py] => SNet: Task 5, Epoch 90/130 => Loss 29.661,  Loss1 0.739, Train_accy 76.67
2024-09-08 12:29:22,625 [foster.py] => SNet: Task 5, Epoch 91/130 => Loss 29.639,  Loss1 0.739, Train_accy 76.95, Test_accy 71.17
2024-09-08 12:29:28,074 [foster.py] => SNet: Task 5, Epoch 92/130 => Loss 29.623,  Loss1 0.739, Train_accy 77.64
2024-09-08 12:29:33,542 [foster.py] => SNet: Task 5, Epoch 93/130 => Loss 29.659,  Loss1 0.739, Train_accy 75.87
2024-09-08 12:29:38,967 [foster.py] => SNet: Task 5, Epoch 94/130 => Loss 29.663,  Loss1 0.739, Train_accy 76.87
2024-09-08 12:29:44,390 [foster.py] => SNet: Task 5, Epoch 95/130 => Loss 29.617,  Loss1 0.739, Train_accy 76.72
2024-09-08 12:29:50,958 [foster.py] => SNet: Task 5, Epoch 96/130 => Loss 29.643,  Loss1 0.739, Train_accy 77.05, Test_accy 71.56
2024-09-08 12:29:56,364 [foster.py] => SNet: Task 5, Epoch 97/130 => Loss 29.599,  Loss1 0.739, Train_accy 78.05
2024-09-08 12:30:01,819 [foster.py] => SNet: Task 5, Epoch 98/130 => Loss 29.627,  Loss1 0.739, Train_accy 77.18
2024-09-08 12:30:07,262 [foster.py] => SNet: Task 5, Epoch 99/130 => Loss 29.662,  Loss1 0.739, Train_accy 76.08
2024-09-08 12:30:12,728 [foster.py] => SNet: Task 5, Epoch 100/130 => Loss 29.636,  Loss1 0.739, Train_accy 76.13
2024-09-08 12:30:19,284 [foster.py] => SNet: Task 5, Epoch 101/130 => Loss 29.637,  Loss1 0.739, Train_accy 75.18, Test_accy 71.35
2024-09-08 12:30:24,713 [foster.py] => SNet: Task 5, Epoch 102/130 => Loss 29.644,  Loss1 0.739, Train_accy 76.36
2024-09-08 12:30:30,199 [foster.py] => SNet: Task 5, Epoch 103/130 => Loss 29.652,  Loss1 0.739, Train_accy 77.41
2024-09-08 12:30:35,666 [foster.py] => SNet: Task 5, Epoch 104/130 => Loss 29.623,  Loss1 0.739, Train_accy 76.03
2024-09-08 12:30:41,149 [foster.py] => SNet: Task 5, Epoch 105/130 => Loss 29.608,  Loss1 0.739, Train_accy 77.97
2024-09-08 12:30:47,757 [foster.py] => SNet: Task 5, Epoch 106/130 => Loss 29.608,  Loss1 0.739, Train_accy 77.23, Test_accy 71.17
2024-09-08 12:30:53,183 [foster.py] => SNet: Task 5, Epoch 107/130 => Loss 29.641,  Loss1 0.739, Train_accy 76.21
2024-09-08 12:30:58,668 [foster.py] => SNet: Task 5, Epoch 108/130 => Loss 29.619,  Loss1 0.739, Train_accy 76.77
2024-09-08 12:31:04,115 [foster.py] => SNet: Task 5, Epoch 109/130 => Loss 29.636,  Loss1 0.739, Train_accy 78.05
2024-09-08 12:31:09,546 [foster.py] => SNet: Task 5, Epoch 110/130 => Loss 29.668,  Loss1 0.739, Train_accy 77.13
2024-09-08 12:31:16,135 [foster.py] => SNet: Task 5, Epoch 111/130 => Loss 29.618,  Loss1 0.739, Train_accy 76.54, Test_accy 71.47
2024-09-08 12:31:21,566 [foster.py] => SNet: Task 5, Epoch 112/130 => Loss 29.642,  Loss1 0.739, Train_accy 77.18
2024-09-08 12:31:27,063 [foster.py] => SNet: Task 5, Epoch 113/130 => Loss 29.632,  Loss1 0.739, Train_accy 77.77
2024-09-08 12:31:32,484 [foster.py] => SNet: Task 5, Epoch 114/130 => Loss 29.610,  Loss1 0.739, Train_accy 77.79
2024-09-08 12:31:37,890 [foster.py] => SNet: Task 5, Epoch 115/130 => Loss 29.623,  Loss1 0.739, Train_accy 76.18
2024-09-08 12:31:44,445 [foster.py] => SNet: Task 5, Epoch 116/130 => Loss 29.628,  Loss1 0.739, Train_accy 77.21, Test_accy 71.28
2024-09-08 12:31:49,858 [foster.py] => SNet: Task 5, Epoch 117/130 => Loss 29.625,  Loss1 0.739, Train_accy 76.74
2024-09-08 12:31:55,297 [foster.py] => SNet: Task 5, Epoch 118/130 => Loss 29.654,  Loss1 0.739, Train_accy 76.18
2024-09-08 12:32:00,804 [foster.py] => SNet: Task 5, Epoch 119/130 => Loss 29.635,  Loss1 0.739, Train_accy 77.28
2024-09-08 12:32:06,224 [foster.py] => SNet: Task 5, Epoch 120/130 => Loss 29.619,  Loss1 0.739, Train_accy 77.05
2024-09-08 12:32:12,816 [foster.py] => SNet: Task 5, Epoch 121/130 => Loss 29.656,  Loss1 0.739, Train_accy 77.03, Test_accy 71.41
2024-09-08 12:32:18,261 [foster.py] => SNet: Task 5, Epoch 122/130 => Loss 29.624,  Loss1 0.739, Train_accy 75.90
2024-09-08 12:32:23,721 [foster.py] => SNet: Task 5, Epoch 123/130 => Loss 29.589,  Loss1 0.739, Train_accy 77.85
2024-09-08 12:32:29,156 [foster.py] => SNet: Task 5, Epoch 124/130 => Loss 29.634,  Loss1 0.739, Train_accy 76.85
2024-09-08 12:32:34,583 [foster.py] => SNet: Task 5, Epoch 125/130 => Loss 29.635,  Loss1 0.739, Train_accy 75.87
2024-09-08 12:32:41,159 [foster.py] => SNet: Task 5, Epoch 126/130 => Loss 29.645,  Loss1 0.739, Train_accy 76.67, Test_accy 71.44
2024-09-08 12:32:46,601 [foster.py] => SNet: Task 5, Epoch 127/130 => Loss 29.666,  Loss1 0.739, Train_accy 76.67
2024-09-08 12:32:52,081 [foster.py] => SNet: Task 5, Epoch 128/130 => Loss 29.650,  Loss1 0.739, Train_accy 76.62
2024-09-08 12:32:57,503 [foster.py] => SNet: Task 5, Epoch 129/130 => Loss 29.618,  Loss1 0.739, Train_accy 77.31
2024-09-08 12:33:02,990 [foster.py] => SNet: Task 5, Epoch 130/130 => Loss 29.626,  Loss1 0.739, Train_accy 77.00
2024-09-08 12:33:02,991 [foster.py] => do not weight align student!
2024-09-08 12:33:04,120 [foster.py] => darknet eval: 
2024-09-08 12:33:04,120 [foster.py] => CNN top1 curve: 71.17
2024-09-08 12:33:04,120 [foster.py] => CNN top5 curve: 92.61
2024-09-08 12:33:04,120 [foster.py] => CNN top1 平均值: 71.17
2024-09-08 12:33:04,123 [foster.py] => timees : 1641.3661000728607
2024-09-08 12:33:04,124 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 12:33:28,340 [foster.py] => Exemplar size: 1500
2024-09-08 12:33:28,340 [trainer.py] => CNN: {'total': 72.67, '00-09': 79.0, '10-19': 65.7, '20-29': 78.0, '30-39': 72.2, '40-49': 75.6, '50-59': 60.7, '60-69': 74.3, '70-79': 79.0, 'old': 72.21, 'new': 79.0}
2024-09-08 12:33:28,340 [trainer.py] => NME: {'total': 67.83, '00-09': 72.7, '10-19': 62.6, '20-29': 73.1, '30-39': 66.7, '40-49': 71.4, '50-59': 59.7, '60-69': 58.6, '70-79': 87.8, 'old': 66.4, 'new': 87.8}
2024-09-08 12:33:28,340 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67]
2024-09-08 12:33:28,340 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05]
2024-09-08 12:33:28,340 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83]
2024-09-08 12:33:28,340 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79]

2024-09-08 12:33:28,340 [trainer.py] => CNN top1 平均值: 77.26
2024-09-08 12:33:28,343 [trainer.py] => All params: 1173648
2024-09-08 12:33:28,345 [trainer.py] => Trainable params: 591824
2024-09-08 12:33:28,406 [foster.py] => Learning on 75-80
2024-09-08 12:33:28,409 [foster.py] => All params: 1174943
2024-09-08 12:33:28,411 [foster.py] => Trainable params: 592794
2024-09-08 12:33:28,462 [foster.py] => per cls weights : [1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235 1.02501235
 1.02501235 1.02501235 1.02501235 0.62481473 0.62481473 0.62481473
 0.62481473 0.62481473]
2024-09-08 12:33:32,599 [foster.py] => Task 6, Epoch 1/170 => Loss 5.944, Loss_clf 1.507, Loss_fe 1.568, Loss_kd 2.689, Train_accy 56.12
2024-09-08 12:33:38,444 [foster.py] => Task 6, Epoch 2/170 => Loss 4.533, Loss_clf 0.806, Loss_fe 0.898, Loss_kd 2.651, Train_accy 60.70, Test_accy 67.55
2024-09-08 12:33:44,305 [foster.py] => Task 6, Epoch 3/170 => Loss 4.332, Loss_clf 0.731, Loss_fe 0.787, Loss_kd 2.635, Train_accy 59.60, Test_accy 68.92
2024-09-08 12:33:50,140 [foster.py] => Task 6, Epoch 4/170 => Loss 4.267, Loss_clf 0.707, Loss_fe 0.745, Loss_kd 2.638, Train_accy 61.78, Test_accy 69.31
2024-09-08 12:33:55,972 [foster.py] => Task 6, Epoch 5/170 => Loss 4.292, Loss_clf 0.719, Loss_fe 0.746, Loss_kd 2.649, Train_accy 61.35, Test_accy 68.50
2024-09-08 12:34:00,000 [foster.py] => Task 6, Epoch 6/170 => Loss 4.263, Loss_clf 0.715, Loss_fe 0.710, Loss_kd 2.659, Train_accy 62.85
2024-09-08 12:34:05,885 [foster.py] => Task 6, Epoch 7/170 => Loss 4.245, Loss_clf 0.682, Loss_fe 0.735, Loss_kd 2.649, Train_accy 61.42, Test_accy 68.58
2024-09-08 12:34:11,725 [foster.py] => Task 6, Epoch 8/170 => Loss 4.164, Loss_clf 0.665, Loss_fe 0.674, Loss_kd 2.648, Train_accy 64.60, Test_accy 68.95
2024-09-08 12:34:17,697 [foster.py] => Task 6, Epoch 9/170 => Loss 4.133, Loss_clf 0.652, Loss_fe 0.663, Loss_kd 2.640, Train_accy 64.72, Test_accy 68.89
2024-09-08 12:34:23,550 [foster.py] => Task 6, Epoch 10/170 => Loss 4.159, Loss_clf 0.661, Loss_fe 0.674, Loss_kd 2.646, Train_accy 64.15, Test_accy 68.51
2024-09-08 12:34:27,501 [foster.py] => Task 6, Epoch 11/170 => Loss 4.192, Loss_clf 0.700, Loss_fe 0.657, Loss_kd 2.657, Train_accy 64.25
2024-09-08 12:34:33,397 [foster.py] => Task 6, Epoch 12/170 => Loss 4.106, Loss_clf 0.658, Loss_fe 0.628, Loss_kd 2.642, Train_accy 65.82, Test_accy 68.20
2024-09-08 12:34:39,282 [foster.py] => Task 6, Epoch 13/170 => Loss 4.101, Loss_clf 0.648, Loss_fe 0.610, Loss_kd 2.664, Train_accy 64.38, Test_accy 68.53
2024-09-08 12:34:45,175 [foster.py] => Task 6, Epoch 14/170 => Loss 4.102, Loss_clf 0.646, Loss_fe 0.605, Loss_kd 2.671, Train_accy 64.42, Test_accy 68.47
2024-09-08 12:34:51,026 [foster.py] => Task 6, Epoch 15/170 => Loss 4.143, Loss_clf 0.672, Loss_fe 0.637, Loss_kd 2.656, Train_accy 65.55, Test_accy 68.50
2024-09-08 12:34:54,996 [foster.py] => Task 6, Epoch 16/170 => Loss 4.035, Loss_clf 0.616, Loss_fe 0.601, Loss_kd 2.640, Train_accy 65.85
2024-09-08 12:35:00,839 [foster.py] => Task 6, Epoch 17/170 => Loss 4.112, Loss_clf 0.645, Loss_fe 0.641, Loss_kd 2.647, Train_accy 64.95, Test_accy 69.05
2024-09-08 12:35:06,750 [foster.py] => Task 6, Epoch 18/170 => Loss 4.020, Loss_clf 0.608, Loss_fe 0.593, Loss_kd 2.641, Train_accy 67.05, Test_accy 69.00
2024-09-08 12:35:12,629 [foster.py] => Task 6, Epoch 19/170 => Loss 4.074, Loss_clf 0.653, Loss_fe 0.591, Loss_kd 2.651, Train_accy 67.10, Test_accy 68.80
2024-09-08 12:35:18,494 [foster.py] => Task 6, Epoch 20/170 => Loss 4.027, Loss_clf 0.624, Loss_fe 0.582, Loss_kd 2.644, Train_accy 65.22, Test_accy 68.41
2024-09-08 12:35:22,506 [foster.py] => Task 6, Epoch 21/170 => Loss 3.954, Loss_clf 0.578, Loss_fe 0.565, Loss_kd 2.634, Train_accy 68.28
2024-09-08 12:35:28,402 [foster.py] => Task 6, Epoch 22/170 => Loss 3.985, Loss_clf 0.589, Loss_fe 0.583, Loss_kd 2.635, Train_accy 66.25, Test_accy 68.58
2024-09-08 12:35:34,224 [foster.py] => Task 6, Epoch 23/170 => Loss 3.887, Loss_clf 0.572, Loss_fe 0.515, Loss_kd 2.623, Train_accy 67.58, Test_accy 69.51
2024-09-08 12:35:40,153 [foster.py] => Task 6, Epoch 24/170 => Loss 3.915, Loss_clf 0.568, Loss_fe 0.531, Loss_kd 2.638, Train_accy 68.80, Test_accy 67.92
2024-09-08 12:35:45,992 [foster.py] => Task 6, Epoch 25/170 => Loss 4.034, Loss_clf 0.621, Loss_fe 0.576, Loss_kd 2.658, Train_accy 66.08, Test_accy 68.62
2024-09-08 12:35:50,042 [foster.py] => Task 6, Epoch 26/170 => Loss 4.008, Loss_clf 0.620, Loss_fe 0.565, Loss_kd 2.645, Train_accy 66.32
2024-09-08 12:35:55,878 [foster.py] => Task 6, Epoch 27/170 => Loss 3.951, Loss_clf 0.595, Loss_fe 0.528, Loss_kd 2.649, Train_accy 68.30, Test_accy 69.05
2024-09-08 12:36:01,790 [foster.py] => Task 6, Epoch 28/170 => Loss 3.952, Loss_clf 0.586, Loss_fe 0.530, Loss_kd 2.657, Train_accy 67.50, Test_accy 68.96
2024-09-08 12:36:07,630 [foster.py] => Task 6, Epoch 29/170 => Loss 4.029, Loss_clf 0.628, Loss_fe 0.559, Loss_kd 2.663, Train_accy 68.28, Test_accy 68.97
2024-09-08 12:36:13,515 [foster.py] => Task 6, Epoch 30/170 => Loss 3.965, Loss_clf 0.591, Loss_fe 0.549, Loss_kd 2.646, Train_accy 67.62, Test_accy 68.66
2024-09-08 12:36:17,594 [foster.py] => Task 6, Epoch 31/170 => Loss 3.979, Loss_clf 0.609, Loss_fe 0.536, Loss_kd 2.656, Train_accy 69.70
2024-09-08 12:36:23,524 [foster.py] => Task 6, Epoch 32/170 => Loss 3.935, Loss_clf 0.576, Loss_fe 0.526, Loss_kd 2.654, Train_accy 69.32, Test_accy 68.97
2024-09-08 12:36:29,353 [foster.py] => Task 6, Epoch 33/170 => Loss 3.979, Loss_clf 0.620, Loss_fe 0.536, Loss_kd 2.645, Train_accy 68.00, Test_accy 69.41
2024-09-08 12:36:35,168 [foster.py] => Task 6, Epoch 34/170 => Loss 3.947, Loss_clf 0.596, Loss_fe 0.514, Loss_kd 2.659, Train_accy 68.38, Test_accy 69.05
2024-09-08 12:36:41,056 [foster.py] => Task 6, Epoch 35/170 => Loss 3.861, Loss_clf 0.556, Loss_fe 0.486, Loss_kd 2.641, Train_accy 69.92, Test_accy 69.09
2024-09-08 12:36:45,003 [foster.py] => Task 6, Epoch 36/170 => Loss 3.850, Loss_clf 0.558, Loss_fe 0.474, Loss_kd 2.640, Train_accy 70.03
2024-09-08 12:36:50,964 [foster.py] => Task 6, Epoch 37/170 => Loss 3.861, Loss_clf 0.555, Loss_fe 0.484, Loss_kd 2.644, Train_accy 70.40, Test_accy 68.78
2024-09-08 12:36:56,915 [foster.py] => Task 6, Epoch 38/170 => Loss 3.886, Loss_clf 0.562, Loss_fe 0.500, Loss_kd 2.646, Train_accy 71.42, Test_accy 69.14
2024-09-08 12:37:02,746 [foster.py] => Task 6, Epoch 39/170 => Loss 3.844, Loss_clf 0.548, Loss_fe 0.470, Loss_kd 2.648, Train_accy 69.58, Test_accy 68.71
2024-09-08 12:37:08,600 [foster.py] => Task 6, Epoch 40/170 => Loss 3.908, Loss_clf 0.562, Loss_fe 0.501, Loss_kd 2.665, Train_accy 70.65, Test_accy 68.25
2024-09-08 12:37:12,569 [foster.py] => Task 6, Epoch 41/170 => Loss 3.914, Loss_clf 0.578, Loss_fe 0.504, Loss_kd 2.654, Train_accy 70.15
2024-09-08 12:37:18,448 [foster.py] => Task 6, Epoch 42/170 => Loss 3.857, Loss_clf 0.553, Loss_fe 0.483, Loss_kd 2.644, Train_accy 69.47, Test_accy 69.30
2024-09-08 12:37:24,303 [foster.py] => Task 6, Epoch 43/170 => Loss 3.802, Loss_clf 0.521, Loss_fe 0.469, Loss_kd 2.635, Train_accy 71.40, Test_accy 68.80
2024-09-08 12:37:30,184 [foster.py] => Task 6, Epoch 44/170 => Loss 3.881, Loss_clf 0.570, Loss_fe 0.485, Loss_kd 2.647, Train_accy 70.88, Test_accy 69.35
2024-09-08 12:37:36,054 [foster.py] => Task 6, Epoch 45/170 => Loss 3.876, Loss_clf 0.564, Loss_fe 0.490, Loss_kd 2.645, Train_accy 68.62, Test_accy 68.54
2024-09-08 12:37:40,047 [foster.py] => Task 6, Epoch 46/170 => Loss 3.831, Loss_clf 0.551, Loss_fe 0.457, Loss_kd 2.645, Train_accy 71.60
2024-09-08 12:37:45,861 [foster.py] => Task 6, Epoch 47/170 => Loss 3.808, Loss_clf 0.537, Loss_fe 0.450, Loss_kd 2.643, Train_accy 71.58, Test_accy 69.59
2024-09-08 12:37:51,769 [foster.py] => Task 6, Epoch 48/170 => Loss 3.936, Loss_clf 0.581, Loss_fe 0.521, Loss_kd 2.655, Train_accy 70.70, Test_accy 69.86
2024-09-08 12:37:57,609 [foster.py] => Task 6, Epoch 49/170 => Loss 3.867, Loss_clf 0.567, Loss_fe 0.469, Loss_kd 2.652, Train_accy 69.88, Test_accy 68.99
2024-09-08 12:38:03,483 [foster.py] => Task 6, Epoch 50/170 => Loss 3.746, Loss_clf 0.507, Loss_fe 0.432, Loss_kd 2.630, Train_accy 74.03, Test_accy 69.69
2024-09-08 12:38:07,534 [foster.py] => Task 6, Epoch 51/170 => Loss 3.809, Loss_clf 0.533, Loss_fe 0.443, Loss_kd 2.655, Train_accy 72.97
2024-09-08 12:38:13,418 [foster.py] => Task 6, Epoch 52/170 => Loss 3.915, Loss_clf 0.588, Loss_fe 0.487, Loss_kd 2.660, Train_accy 71.82, Test_accy 69.14
2024-09-08 12:38:19,322 [foster.py] => Task 6, Epoch 53/170 => Loss 3.831, Loss_clf 0.558, Loss_fe 0.448, Loss_kd 2.647, Train_accy 70.75, Test_accy 69.01
2024-09-08 12:38:25,146 [foster.py] => Task 6, Epoch 54/170 => Loss 3.813, Loss_clf 0.542, Loss_fe 0.440, Loss_kd 2.653, Train_accy 72.30, Test_accy 68.49
2024-09-08 12:38:31,081 [foster.py] => Task 6, Epoch 55/170 => Loss 3.803, Loss_clf 0.543, Loss_fe 0.445, Loss_kd 2.638, Train_accy 71.25, Test_accy 69.55
2024-09-08 12:38:35,092 [foster.py] => Task 6, Epoch 56/170 => Loss 3.766, Loss_clf 0.515, Loss_fe 0.423, Loss_kd 2.650, Train_accy 72.60
2024-09-08 12:38:40,944 [foster.py] => Task 6, Epoch 57/170 => Loss 3.808, Loss_clf 0.541, Loss_fe 0.435, Loss_kd 2.654, Train_accy 71.62, Test_accy 68.80
2024-09-08 12:38:46,806 [foster.py] => Task 6, Epoch 58/170 => Loss 3.764, Loss_clf 0.521, Loss_fe 0.421, Loss_kd 2.644, Train_accy 73.45, Test_accy 69.22
2024-09-08 12:38:52,671 [foster.py] => Task 6, Epoch 59/170 => Loss 3.771, Loss_clf 0.526, Loss_fe 0.416, Loss_kd 2.650, Train_accy 72.62, Test_accy 68.55
2024-09-08 12:38:58,562 [foster.py] => Task 6, Epoch 60/170 => Loss 3.749, Loss_clf 0.514, Loss_fe 0.409, Loss_kd 2.647, Train_accy 73.47, Test_accy 69.50
2024-09-08 12:39:02,563 [foster.py] => Task 6, Epoch 61/170 => Loss 3.755, Loss_clf 0.508, Loss_fe 0.418, Loss_kd 2.651, Train_accy 73.97
2024-09-08 12:39:08,487 [foster.py] => Task 6, Epoch 62/170 => Loss 3.760, Loss_clf 0.512, Loss_fe 0.420, Loss_kd 2.649, Train_accy 72.80, Test_accy 68.81
2024-09-08 12:39:14,302 [foster.py] => Task 6, Epoch 63/170 => Loss 3.821, Loss_clf 0.555, Loss_fe 0.437, Loss_kd 2.650, Train_accy 72.42, Test_accy 69.38
2024-09-08 12:39:20,197 [foster.py] => Task 6, Epoch 64/170 => Loss 3.731, Loss_clf 0.503, Loss_fe 0.403, Loss_kd 2.647, Train_accy 74.20, Test_accy 69.00
2024-09-08 12:39:26,099 [foster.py] => Task 6, Epoch 65/170 => Loss 3.715, Loss_clf 0.500, Loss_fe 0.380, Loss_kd 2.657, Train_accy 74.00, Test_accy 69.08
2024-09-08 12:39:30,054 [foster.py] => Task 6, Epoch 66/170 => Loss 3.741, Loss_clf 0.509, Loss_fe 0.412, Loss_kd 2.642, Train_accy 74.15
2024-09-08 12:39:35,924 [foster.py] => Task 6, Epoch 67/170 => Loss 3.732, Loss_clf 0.505, Loss_fe 0.377, Loss_kd 2.669, Train_accy 74.35, Test_accy 69.29
2024-09-08 12:39:41,731 [foster.py] => Task 6, Epoch 68/170 => Loss 3.687, Loss_clf 0.488, Loss_fe 0.386, Loss_kd 2.635, Train_accy 74.30, Test_accy 68.99
2024-09-08 12:39:47,674 [foster.py] => Task 6, Epoch 69/170 => Loss 3.672, Loss_clf 0.477, Loss_fe 0.369, Loss_kd 2.647, Train_accy 75.53, Test_accy 69.68
2024-09-08 12:39:53,566 [foster.py] => Task 6, Epoch 70/170 => Loss 3.771, Loss_clf 0.520, Loss_fe 0.417, Loss_kd 2.656, Train_accy 73.75, Test_accy 69.46
2024-09-08 12:39:57,604 [foster.py] => Task 6, Epoch 71/170 => Loss 3.712, Loss_clf 0.493, Loss_fe 0.380, Loss_kd 2.660, Train_accy 75.10
2024-09-08 12:40:03,506 [foster.py] => Task 6, Epoch 72/170 => Loss 3.718, Loss_clf 0.501, Loss_fe 0.397, Loss_kd 2.642, Train_accy 73.47, Test_accy 68.64
2024-09-08 12:40:09,436 [foster.py] => Task 6, Epoch 73/170 => Loss 3.662, Loss_clf 0.480, Loss_fe 0.358, Loss_kd 2.646, Train_accy 76.53, Test_accy 68.84
2024-09-08 12:40:15,344 [foster.py] => Task 6, Epoch 74/170 => Loss 3.644, Loss_clf 0.475, Loss_fe 0.364, Loss_kd 2.628, Train_accy 75.40, Test_accy 69.01
2024-09-08 12:40:21,227 [foster.py] => Task 6, Epoch 75/170 => Loss 3.770, Loss_clf 0.525, Loss_fe 0.404, Loss_kd 2.662, Train_accy 74.72, Test_accy 69.28
2024-09-08 12:40:25,247 [foster.py] => Task 6, Epoch 76/170 => Loss 3.706, Loss_clf 0.494, Loss_fe 0.378, Loss_kd 2.656, Train_accy 76.60
2024-09-08 12:40:31,082 [foster.py] => Task 6, Epoch 77/170 => Loss 3.697, Loss_clf 0.496, Loss_fe 0.363, Loss_kd 2.659, Train_accy 75.82, Test_accy 69.60
2024-09-08 12:40:37,014 [foster.py] => Task 6, Epoch 78/170 => Loss 3.709, Loss_clf 0.497, Loss_fe 0.378, Loss_kd 2.655, Train_accy 76.03, Test_accy 69.47
2024-09-08 12:40:42,922 [foster.py] => Task 6, Epoch 79/170 => Loss 3.662, Loss_clf 0.474, Loss_fe 0.367, Loss_kd 2.643, Train_accy 75.80, Test_accy 69.32
2024-09-08 12:40:48,728 [foster.py] => Task 6, Epoch 80/170 => Loss 3.671, Loss_clf 0.486, Loss_fe 0.360, Loss_kd 2.646, Train_accy 76.38, Test_accy 69.24
2024-09-08 12:40:52,746 [foster.py] => Task 6, Epoch 81/170 => Loss 3.666, Loss_clf 0.493, Loss_fe 0.344, Loss_kd 2.651, Train_accy 75.75
2024-09-08 12:40:58,685 [foster.py] => Task 6, Epoch 82/170 => Loss 3.682, Loss_clf 0.486, Loss_fe 0.359, Loss_kd 2.658, Train_accy 75.42, Test_accy 69.35
2024-09-08 12:41:04,584 [foster.py] => Task 6, Epoch 83/170 => Loss 3.659, Loss_clf 0.487, Loss_fe 0.334, Loss_kd 2.660, Train_accy 75.68, Test_accy 69.51
2024-09-08 12:41:10,444 [foster.py] => Task 6, Epoch 84/170 => Loss 3.591, Loss_clf 0.440, Loss_fe 0.327, Loss_kd 2.646, Train_accy 76.70, Test_accy 68.97
2024-09-08 12:41:16,251 [foster.py] => Task 6, Epoch 85/170 => Loss 3.598, Loss_clf 0.452, Loss_fe 0.324, Loss_kd 2.644, Train_accy 76.22, Test_accy 69.20
2024-09-08 12:41:20,194 [foster.py] => Task 6, Epoch 86/170 => Loss 3.563, Loss_clf 0.442, Loss_fe 0.303, Loss_kd 2.640, Train_accy 77.47
2024-09-08 12:41:26,074 [foster.py] => Task 6, Epoch 87/170 => Loss 3.567, Loss_clf 0.442, Loss_fe 0.316, Loss_kd 2.631, Train_accy 76.88, Test_accy 69.35
2024-09-08 12:41:31,965 [foster.py] => Task 6, Epoch 88/170 => Loss 3.635, Loss_clf 0.475, Loss_fe 0.329, Loss_kd 2.653, Train_accy 76.20, Test_accy 69.42
2024-09-08 12:41:37,774 [foster.py] => Task 6, Epoch 89/170 => Loss 3.556, Loss_clf 0.435, Loss_fe 0.311, Loss_kd 2.634, Train_accy 76.97, Test_accy 69.66
2024-09-08 12:41:43,653 [foster.py] => Task 6, Epoch 90/170 => Loss 3.598, Loss_clf 0.452, Loss_fe 0.314, Loss_kd 2.653, Train_accy 77.05, Test_accy 69.69
2024-09-08 12:41:47,619 [foster.py] => Task 6, Epoch 91/170 => Loss 3.632, Loss_clf 0.472, Loss_fe 0.328, Loss_kd 2.654, Train_accy 76.18
2024-09-08 12:41:53,479 [foster.py] => Task 6, Epoch 92/170 => Loss 3.601, Loss_clf 0.462, Loss_fe 0.308, Loss_kd 2.653, Train_accy 77.20, Test_accy 69.59
2024-09-08 12:41:59,448 [foster.py] => Task 6, Epoch 93/170 => Loss 3.565, Loss_clf 0.431, Loss_fe 0.298, Loss_kd 2.657, Train_accy 78.58, Test_accy 69.64
2024-09-08 12:42:05,432 [foster.py] => Task 6, Epoch 94/170 => Loss 3.527, Loss_clf 0.418, Loss_fe 0.286, Loss_kd 2.645, Train_accy 79.58, Test_accy 69.39
2024-09-08 12:42:11,248 [foster.py] => Task 6, Epoch 95/170 => Loss 3.562, Loss_clf 0.439, Loss_fe 0.288, Loss_kd 2.656, Train_accy 79.35, Test_accy 69.55
2024-09-08 12:42:15,289 [foster.py] => Task 6, Epoch 96/170 => Loss 3.566, Loss_clf 0.443, Loss_fe 0.301, Loss_kd 2.644, Train_accy 77.45
2024-09-08 12:42:21,338 [foster.py] => Task 6, Epoch 97/170 => Loss 3.536, Loss_clf 0.445, Loss_fe 0.280, Loss_kd 2.634, Train_accy 79.55, Test_accy 69.26
2024-09-08 12:42:27,350 [foster.py] => Task 6, Epoch 98/170 => Loss 3.517, Loss_clf 0.424, Loss_fe 0.282, Loss_kd 2.634, Train_accy 78.45, Test_accy 69.38
2024-09-08 12:42:33,163 [foster.py] => Task 6, Epoch 99/170 => Loss 3.529, Loss_clf 0.426, Loss_fe 0.295, Loss_kd 2.631, Train_accy 79.65, Test_accy 69.14
2024-09-08 12:42:38,958 [foster.py] => Task 6, Epoch 100/170 => Loss 3.530, Loss_clf 0.425, Loss_fe 0.292, Loss_kd 2.636, Train_accy 77.95, Test_accy 69.55
2024-09-08 12:42:43,017 [foster.py] => Task 6, Epoch 101/170 => Loss 3.553, Loss_clf 0.440, Loss_fe 0.301, Loss_kd 2.634, Train_accy 79.15
2024-09-08 12:42:48,900 [foster.py] => Task 6, Epoch 102/170 => Loss 3.535, Loss_clf 0.420, Loss_fe 0.285, Loss_kd 2.652, Train_accy 80.25, Test_accy 69.47
2024-09-08 12:42:54,753 [foster.py] => Task 6, Epoch 103/170 => Loss 3.543, Loss_clf 0.437, Loss_fe 0.277, Loss_kd 2.650, Train_accy 77.68, Test_accy 69.31
2024-09-08 12:43:00,558 [foster.py] => Task 6, Epoch 104/170 => Loss 3.556, Loss_clf 0.440, Loss_fe 0.285, Loss_kd 2.653, Train_accy 79.30, Test_accy 69.28
2024-09-08 12:43:06,366 [foster.py] => Task 6, Epoch 105/170 => Loss 3.498, Loss_clf 0.406, Loss_fe 0.280, Loss_kd 2.635, Train_accy 79.50, Test_accy 69.00
2024-09-08 12:43:10,349 [foster.py] => Task 6, Epoch 106/170 => Loss 3.518, Loss_clf 0.422, Loss_fe 0.269, Loss_kd 2.649, Train_accy 80.78
2024-09-08 12:43:16,188 [foster.py] => Task 6, Epoch 107/170 => Loss 3.515, Loss_clf 0.424, Loss_fe 0.263, Loss_kd 2.651, Train_accy 78.95, Test_accy 69.44
2024-09-08 12:43:22,165 [foster.py] => Task 6, Epoch 108/170 => Loss 3.484, Loss_clf 0.402, Loss_fe 0.250, Loss_kd 2.654, Train_accy 80.22, Test_accy 69.66
2024-09-08 12:43:28,084 [foster.py] => Task 6, Epoch 109/170 => Loss 3.476, Loss_clf 0.408, Loss_fe 0.243, Loss_kd 2.647, Train_accy 80.72, Test_accy 69.92
2024-09-08 12:43:33,935 [foster.py] => Task 6, Epoch 110/170 => Loss 3.491, Loss_clf 0.416, Loss_fe 0.248, Loss_kd 2.649, Train_accy 80.45, Test_accy 69.20
2024-09-08 12:43:37,920 [foster.py] => Task 6, Epoch 111/170 => Loss 3.525, Loss_clf 0.434, Loss_fe 0.264, Loss_kd 2.649, Train_accy 79.35
2024-09-08 12:43:43,908 [foster.py] => Task 6, Epoch 112/170 => Loss 3.489, Loss_clf 0.413, Loss_fe 0.250, Loss_kd 2.648, Train_accy 79.90, Test_accy 69.28
2024-09-08 12:43:49,779 [foster.py] => Task 6, Epoch 113/170 => Loss 3.484, Loss_clf 0.415, Loss_fe 0.253, Loss_kd 2.638, Train_accy 80.35, Test_accy 69.78
2024-09-08 12:43:55,647 [foster.py] => Task 6, Epoch 114/170 => Loss 3.419, Loss_clf 0.373, Loss_fe 0.226, Loss_kd 2.642, Train_accy 80.90, Test_accy 69.42
2024-09-08 12:44:01,527 [foster.py] => Task 6, Epoch 115/170 => Loss 3.448, Loss_clf 0.382, Loss_fe 0.242, Loss_kd 2.646, Train_accy 81.50, Test_accy 69.49
2024-09-08 12:44:05,512 [foster.py] => Task 6, Epoch 116/170 => Loss 3.440, Loss_clf 0.391, Loss_fe 0.235, Loss_kd 2.637, Train_accy 81.98
2024-09-08 12:44:11,407 [foster.py] => Task 6, Epoch 117/170 => Loss 3.444, Loss_clf 0.397, Loss_fe 0.228, Loss_kd 2.640, Train_accy 80.50, Test_accy 69.65
2024-09-08 12:44:17,387 [foster.py] => Task 6, Epoch 118/170 => Loss 3.420, Loss_clf 0.386, Loss_fe 0.225, Loss_kd 2.631, Train_accy 82.25, Test_accy 69.31
2024-09-08 12:44:23,237 [foster.py] => Task 6, Epoch 119/170 => Loss 3.463, Loss_clf 0.404, Loss_fe 0.232, Loss_kd 2.649, Train_accy 81.12, Test_accy 69.46
2024-09-08 12:44:29,106 [foster.py] => Task 6, Epoch 120/170 => Loss 3.459, Loss_clf 0.411, Loss_fe 0.207, Loss_kd 2.662, Train_accy 80.90, Test_accy 69.51
2024-09-08 12:44:33,053 [foster.py] => Task 6, Epoch 121/170 => Loss 3.421, Loss_clf 0.375, Loss_fe 0.225, Loss_kd 2.644, Train_accy 83.55
2024-09-08 12:44:38,936 [foster.py] => Task 6, Epoch 122/170 => Loss 3.419, Loss_clf 0.383, Loss_fe 0.214, Loss_kd 2.644, Train_accy 82.12, Test_accy 69.75
2024-09-08 12:44:44,795 [foster.py] => Task 6, Epoch 123/170 => Loss 3.399, Loss_clf 0.376, Loss_fe 0.210, Loss_kd 2.635, Train_accy 82.48, Test_accy 69.44
2024-09-08 12:44:50,674 [foster.py] => Task 6, Epoch 124/170 => Loss 3.425, Loss_clf 0.380, Loss_fe 0.211, Loss_kd 2.655, Train_accy 82.70, Test_accy 69.69
2024-09-08 12:44:56,502 [foster.py] => Task 6, Epoch 125/170 => Loss 3.420, Loss_clf 0.379, Loss_fe 0.205, Loss_kd 2.657, Train_accy 83.35, Test_accy 69.49
2024-09-08 12:45:00,493 [foster.py] => Task 6, Epoch 126/170 => Loss 3.400, Loss_clf 0.368, Loss_fe 0.202, Loss_kd 2.652, Train_accy 82.65
2024-09-08 12:45:06,371 [foster.py] => Task 6, Epoch 127/170 => Loss 3.406, Loss_clf 0.389, Loss_fe 0.211, Loss_kd 2.629, Train_accy 83.45, Test_accy 69.70
2024-09-08 12:45:12,241 [foster.py] => Task 6, Epoch 128/170 => Loss 3.416, Loss_clf 0.379, Loss_fe 0.202, Loss_kd 2.656, Train_accy 83.82, Test_accy 69.54
2024-09-08 12:45:18,055 [foster.py] => Task 6, Epoch 129/170 => Loss 3.410, Loss_clf 0.380, Loss_fe 0.204, Loss_kd 2.647, Train_accy 83.05, Test_accy 69.47
2024-09-08 12:45:23,915 [foster.py] => Task 6, Epoch 130/170 => Loss 3.409, Loss_clf 0.373, Loss_fe 0.193, Loss_kd 2.664, Train_accy 83.20, Test_accy 70.10
2024-09-08 12:45:27,869 [foster.py] => Task 6, Epoch 131/170 => Loss 3.435, Loss_clf 0.396, Loss_fe 0.208, Loss_kd 2.653, Train_accy 82.60
2024-09-08 12:45:33,678 [foster.py] => Task 6, Epoch 132/170 => Loss 3.402, Loss_clf 0.368, Loss_fe 0.204, Loss_kd 2.652, Train_accy 83.68, Test_accy 70.04
2024-09-08 12:45:39,491 [foster.py] => Task 6, Epoch 133/170 => Loss 3.400, Loss_clf 0.380, Loss_fe 0.188, Loss_kd 2.654, Train_accy 82.98, Test_accy 69.70
2024-09-08 12:45:45,376 [foster.py] => Task 6, Epoch 134/170 => Loss 3.393, Loss_clf 0.374, Loss_fe 0.196, Loss_kd 2.645, Train_accy 83.40, Test_accy 69.60
2024-09-08 12:45:51,249 [foster.py] => Task 6, Epoch 135/170 => Loss 3.359, Loss_clf 0.356, Loss_fe 0.185, Loss_kd 2.641, Train_accy 84.35, Test_accy 69.54
2024-09-08 12:45:55,228 [foster.py] => Task 6, Epoch 136/170 => Loss 3.421, Loss_clf 0.392, Loss_fe 0.197, Loss_kd 2.654, Train_accy 83.35
2024-09-08 12:46:01,068 [foster.py] => Task 6, Epoch 137/170 => Loss 3.359, Loss_clf 0.354, Loss_fe 0.177, Loss_kd 2.649, Train_accy 83.32, Test_accy 69.69
2024-09-08 12:46:06,923 [foster.py] => Task 6, Epoch 138/170 => Loss 3.363, Loss_clf 0.363, Loss_fe 0.180, Loss_kd 2.642, Train_accy 83.48, Test_accy 69.75
2024-09-08 12:46:12,725 [foster.py] => Task 6, Epoch 139/170 => Loss 3.370, Loss_clf 0.364, Loss_fe 0.181, Loss_kd 2.647, Train_accy 83.52, Test_accy 69.69
2024-09-08 12:46:18,589 [foster.py] => Task 6, Epoch 140/170 => Loss 3.340, Loss_clf 0.343, Loss_fe 0.169, Loss_kd 2.649, Train_accy 85.62, Test_accy 69.75
2024-09-08 12:46:22,541 [foster.py] => Task 6, Epoch 141/170 => Loss 3.395, Loss_clf 0.370, Loss_fe 0.193, Loss_kd 2.654, Train_accy 85.28
2024-09-08 12:46:28,420 [foster.py] => Task 6, Epoch 142/170 => Loss 3.336, Loss_clf 0.342, Loss_fe 0.173, Loss_kd 2.644, Train_accy 84.38, Test_accy 69.82
2024-09-08 12:46:34,349 [foster.py] => Task 6, Epoch 143/170 => Loss 3.368, Loss_clf 0.363, Loss_fe 0.183, Loss_kd 2.644, Train_accy 83.68, Test_accy 69.95
2024-09-08 12:46:40,126 [foster.py] => Task 6, Epoch 144/170 => Loss 3.371, Loss_clf 0.361, Loss_fe 0.179, Loss_kd 2.654, Train_accy 83.85, Test_accy 69.86
2024-09-08 12:46:46,022 [foster.py] => Task 6, Epoch 145/170 => Loss 3.398, Loss_clf 0.365, Loss_fe 0.180, Loss_kd 2.673, Train_accy 84.52, Test_accy 69.97
2024-09-08 12:46:49,961 [foster.py] => Task 6, Epoch 146/170 => Loss 3.345, Loss_clf 0.348, Loss_fe 0.177, Loss_kd 2.642, Train_accy 84.35
2024-09-08 12:46:55,799 [foster.py] => Task 6, Epoch 147/170 => Loss 3.367, Loss_clf 0.360, Loss_fe 0.174, Loss_kd 2.654, Train_accy 84.55, Test_accy 69.71
2024-09-08 12:47:01,571 [foster.py] => Task 6, Epoch 148/170 => Loss 3.322, Loss_clf 0.341, Loss_fe 0.171, Loss_kd 2.634, Train_accy 84.75, Test_accy 69.76
2024-09-08 12:47:07,386 [foster.py] => Task 6, Epoch 149/170 => Loss 3.401, Loss_clf 0.368, Loss_fe 0.189, Loss_kd 2.664, Train_accy 84.82, Test_accy 69.82
2024-09-08 12:47:13,220 [foster.py] => Task 6, Epoch 150/170 => Loss 3.383, Loss_clf 0.364, Loss_fe 0.178, Loss_kd 2.662, Train_accy 83.90, Test_accy 69.81
2024-09-08 12:47:17,160 [foster.py] => Task 6, Epoch 151/170 => Loss 3.390, Loss_clf 0.361, Loss_fe 0.175, Loss_kd 2.675, Train_accy 84.50
2024-09-08 12:47:22,988 [foster.py] => Task 6, Epoch 152/170 => Loss 3.360, Loss_clf 0.358, Loss_fe 0.169, Loss_kd 2.654, Train_accy 84.95, Test_accy 69.80
2024-09-08 12:47:28,814 [foster.py] => Task 6, Epoch 153/170 => Loss 3.292, Loss_clf 0.318, Loss_fe 0.156, Loss_kd 2.640, Train_accy 86.72, Test_accy 69.76
2024-09-08 12:47:34,694 [foster.py] => Task 6, Epoch 154/170 => Loss 3.323, Loss_clf 0.336, Loss_fe 0.164, Loss_kd 2.645, Train_accy 85.65, Test_accy 69.88
2024-09-08 12:47:40,540 [foster.py] => Task 6, Epoch 155/170 => Loss 3.331, Loss_clf 0.348, Loss_fe 0.158, Loss_kd 2.647, Train_accy 84.88, Test_accy 69.89
2024-09-08 12:47:44,531 [foster.py] => Task 6, Epoch 156/170 => Loss 3.320, Loss_clf 0.341, Loss_fe 0.165, Loss_kd 2.637, Train_accy 85.08
2024-09-08 12:47:50,461 [foster.py] => Task 6, Epoch 157/170 => Loss 3.366, Loss_clf 0.353, Loss_fe 0.164, Loss_kd 2.670, Train_accy 84.22, Test_accy 69.82
2024-09-08 12:47:56,346 [foster.py] => Task 6, Epoch 158/170 => Loss 3.351, Loss_clf 0.358, Loss_fe 0.169, Loss_kd 2.646, Train_accy 85.42, Test_accy 69.84
2024-09-08 12:48:02,165 [foster.py] => Task 6, Epoch 159/170 => Loss 3.323, Loss_clf 0.344, Loss_fe 0.165, Loss_kd 2.637, Train_accy 84.88, Test_accy 69.90
2024-09-08 12:48:07,992 [foster.py] => Task 6, Epoch 160/170 => Loss 3.301, Loss_clf 0.326, Loss_fe 0.149, Loss_kd 2.648, Train_accy 85.90, Test_accy 69.81
2024-09-08 12:48:11,978 [foster.py] => Task 6, Epoch 161/170 => Loss 3.332, Loss_clf 0.354, Loss_fe 0.170, Loss_kd 2.631, Train_accy 84.50
2024-09-08 12:48:17,869 [foster.py] => Task 6, Epoch 162/170 => Loss 3.338, Loss_clf 0.351, Loss_fe 0.169, Loss_kd 2.640, Train_accy 84.35, Test_accy 69.84
2024-09-08 12:48:23,728 [foster.py] => Task 6, Epoch 163/170 => Loss 3.323, Loss_clf 0.347, Loss_fe 0.149, Loss_kd 2.649, Train_accy 85.22, Test_accy 69.78
2024-09-08 12:48:29,536 [foster.py] => Task 6, Epoch 164/170 => Loss 3.299, Loss_clf 0.327, Loss_fe 0.156, Loss_kd 2.638, Train_accy 85.22, Test_accy 69.85
2024-09-08 12:48:35,453 [foster.py] => Task 6, Epoch 165/170 => Loss 3.307, Loss_clf 0.333, Loss_fe 0.160, Loss_kd 2.636, Train_accy 85.40, Test_accy 69.81
2024-09-08 12:48:39,394 [foster.py] => Task 6, Epoch 166/170 => Loss 3.315, Loss_clf 0.334, Loss_fe 0.162, Loss_kd 2.641, Train_accy 85.20
2024-09-08 12:48:45,240 [foster.py] => Task 6, Epoch 167/170 => Loss 3.341, Loss_clf 0.346, Loss_fe 0.164, Loss_kd 2.653, Train_accy 84.10, Test_accy 69.84
2024-09-08 12:48:51,062 [foster.py] => Task 6, Epoch 168/170 => Loss 3.343, Loss_clf 0.351, Loss_fe 0.159, Loss_kd 2.655, Train_accy 84.95, Test_accy 69.88
2024-09-08 12:48:56,904 [foster.py] => Task 6, Epoch 169/170 => Loss 3.319, Loss_clf 0.340, Loss_fe 0.164, Loss_kd 2.637, Train_accy 83.92, Test_accy 69.69
2024-09-08 12:49:02,748 [foster.py] => Task 6, Epoch 170/170 => Loss 3.340, Loss_clf 0.356, Loss_fe 0.165, Loss_kd 2.641, Train_accy 85.12, Test_accy 69.88
2024-09-08 12:49:02,750 [foster.py] => do not weight align teacher!
2024-09-08 12:49:02,751 [foster.py] => per cls weights : [1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306 1.03068306
 1.03068306 1.03068306 1.03068306 0.53975406 0.53975406 0.53975406
 0.53975406 0.53975406]
2024-09-08 12:49:09,780 [foster.py] => SNet: Task 6, Epoch 1/130 => Loss 30.250,  Loss1 0.750, Train_accy 37.65, Test_accy 64.55
2024-09-08 12:49:15,384 [foster.py] => SNet: Task 6, Epoch 2/130 => Loss 30.113,  Loss1 0.750, Train_accy 48.58
2024-09-08 12:49:21,026 [foster.py] => SNet: Task 6, Epoch 3/130 => Loss 30.127,  Loss1 0.751, Train_accy 54.18
2024-09-08 12:49:26,678 [foster.py] => SNet: Task 6, Epoch 4/130 => Loss 30.074,  Loss1 0.751, Train_accy 56.80
2024-09-08 12:49:32,251 [foster.py] => SNet: Task 6, Epoch 5/130 => Loss 30.074,  Loss1 0.751, Train_accy 57.60
2024-09-08 12:49:38,992 [foster.py] => SNet: Task 6, Epoch 6/130 => Loss 30.039,  Loss1 0.751, Train_accy 60.00, Test_accy 67.62
2024-09-08 12:49:44,575 [foster.py] => SNet: Task 6, Epoch 7/130 => Loss 30.035,  Loss1 0.751, Train_accy 60.72
2024-09-08 12:49:50,159 [foster.py] => SNet: Task 6, Epoch 8/130 => Loss 30.028,  Loss1 0.751, Train_accy 61.28
2024-09-08 12:49:55,757 [foster.py] => SNet: Task 6, Epoch 9/130 => Loss 30.056,  Loss1 0.751, Train_accy 61.40
2024-09-08 12:50:01,353 [foster.py] => SNet: Task 6, Epoch 10/130 => Loss 30.042,  Loss1 0.751, Train_accy 63.35
2024-09-08 12:50:08,206 [foster.py] => SNet: Task 6, Epoch 11/130 => Loss 30.044,  Loss1 0.751, Train_accy 63.58, Test_accy 67.75
2024-09-08 12:50:13,819 [foster.py] => SNet: Task 6, Epoch 12/130 => Loss 30.049,  Loss1 0.751, Train_accy 63.02
2024-09-08 12:50:19,451 [foster.py] => SNet: Task 6, Epoch 13/130 => Loss 30.038,  Loss1 0.751, Train_accy 62.72
2024-09-08 12:50:25,043 [foster.py] => SNet: Task 6, Epoch 14/130 => Loss 30.028,  Loss1 0.751, Train_accy 64.92
2024-09-08 12:50:30,663 [foster.py] => SNet: Task 6, Epoch 15/130 => Loss 29.996,  Loss1 0.751, Train_accy 65.58
2024-09-08 12:50:37,494 [foster.py] => SNet: Task 6, Epoch 16/130 => Loss 30.030,  Loss1 0.751, Train_accy 66.42, Test_accy 67.76
2024-09-08 12:50:43,134 [foster.py] => SNet: Task 6, Epoch 17/130 => Loss 30.020,  Loss1 0.751, Train_accy 66.28
2024-09-08 12:50:48,774 [foster.py] => SNet: Task 6, Epoch 18/130 => Loss 30.028,  Loss1 0.751, Train_accy 65.97
2024-09-08 12:50:54,363 [foster.py] => SNet: Task 6, Epoch 19/130 => Loss 30.000,  Loss1 0.751, Train_accy 66.32
2024-09-08 12:50:59,956 [foster.py] => SNet: Task 6, Epoch 20/130 => Loss 30.019,  Loss1 0.751, Train_accy 67.12
2024-09-08 12:51:06,713 [foster.py] => SNet: Task 6, Epoch 21/130 => Loss 30.050,  Loss1 0.751, Train_accy 64.97, Test_accy 68.05
2024-09-08 12:51:12,347 [foster.py] => SNet: Task 6, Epoch 22/130 => Loss 30.015,  Loss1 0.750, Train_accy 66.95
2024-09-08 12:51:17,979 [foster.py] => SNet: Task 6, Epoch 23/130 => Loss 30.038,  Loss1 0.751, Train_accy 66.25
2024-09-08 12:51:23,666 [foster.py] => SNet: Task 6, Epoch 24/130 => Loss 30.015,  Loss1 0.751, Train_accy 66.90
2024-09-08 12:51:29,288 [foster.py] => SNet: Task 6, Epoch 25/130 => Loss 30.038,  Loss1 0.751, Train_accy 66.88
2024-09-08 12:51:36,029 [foster.py] => SNet: Task 6, Epoch 26/130 => Loss 30.065,  Loss1 0.751, Train_accy 67.62, Test_accy 68.65
2024-09-08 12:51:41,629 [foster.py] => SNet: Task 6, Epoch 27/130 => Loss 30.052,  Loss1 0.751, Train_accy 66.50
2024-09-08 12:51:47,211 [foster.py] => SNet: Task 6, Epoch 28/130 => Loss 30.045,  Loss1 0.751, Train_accy 66.92
2024-09-08 12:51:52,850 [foster.py] => SNet: Task 6, Epoch 29/130 => Loss 30.029,  Loss1 0.751, Train_accy 67.58
2024-09-08 12:51:58,414 [foster.py] => SNet: Task 6, Epoch 30/130 => Loss 30.016,  Loss1 0.751, Train_accy 69.12
2024-09-08 12:52:05,188 [foster.py] => SNet: Task 6, Epoch 31/130 => Loss 30.009,  Loss1 0.751, Train_accy 67.97, Test_accy 68.41
2024-09-08 12:52:10,824 [foster.py] => SNet: Task 6, Epoch 32/130 => Loss 30.047,  Loss1 0.751, Train_accy 68.50
2024-09-08 12:52:16,491 [foster.py] => SNet: Task 6, Epoch 33/130 => Loss 30.035,  Loss1 0.751, Train_accy 69.28
2024-09-08 12:52:22,031 [foster.py] => SNet: Task 6, Epoch 34/130 => Loss 30.048,  Loss1 0.751, Train_accy 67.25
2024-09-08 12:52:27,593 [foster.py] => SNet: Task 6, Epoch 35/130 => Loss 30.002,  Loss1 0.751, Train_accy 67.65
2024-09-08 12:52:34,359 [foster.py] => SNet: Task 6, Epoch 36/130 => Loss 30.023,  Loss1 0.751, Train_accy 68.90, Test_accy 68.51
2024-09-08 12:52:40,056 [foster.py] => SNet: Task 6, Epoch 37/130 => Loss 30.022,  Loss1 0.751, Train_accy 67.92
2024-09-08 12:52:45,666 [foster.py] => SNet: Task 6, Epoch 38/130 => Loss 30.037,  Loss1 0.751, Train_accy 68.42
2024-09-08 12:52:51,312 [foster.py] => SNet: Task 6, Epoch 39/130 => Loss 30.019,  Loss1 0.751, Train_accy 67.75
2024-09-08 12:52:56,923 [foster.py] => SNet: Task 6, Epoch 40/130 => Loss 30.000,  Loss1 0.751, Train_accy 67.55
2024-09-08 12:53:03,716 [foster.py] => SNet: Task 6, Epoch 41/130 => Loss 30.048,  Loss1 0.751, Train_accy 67.70, Test_accy 68.65
2024-09-08 12:53:09,335 [foster.py] => SNet: Task 6, Epoch 42/130 => Loss 30.044,  Loss1 0.751, Train_accy 69.92
2024-09-08 12:53:14,897 [foster.py] => SNet: Task 6, Epoch 43/130 => Loss 29.994,  Loss1 0.751, Train_accy 68.00
2024-09-08 12:53:20,483 [foster.py] => SNet: Task 6, Epoch 44/130 => Loss 30.003,  Loss1 0.751, Train_accy 69.28
2024-09-08 12:53:26,054 [foster.py] => SNet: Task 6, Epoch 45/130 => Loss 30.002,  Loss1 0.751, Train_accy 68.88
2024-09-08 12:53:32,811 [foster.py] => SNet: Task 6, Epoch 46/130 => Loss 30.008,  Loss1 0.751, Train_accy 69.32, Test_accy 68.54
2024-09-08 12:53:38,396 [foster.py] => SNet: Task 6, Epoch 47/130 => Loss 29.994,  Loss1 0.751, Train_accy 68.47
2024-09-08 12:53:44,000 [foster.py] => SNet: Task 6, Epoch 48/130 => Loss 30.029,  Loss1 0.751, Train_accy 69.22
2024-09-08 12:53:49,668 [foster.py] => SNet: Task 6, Epoch 49/130 => Loss 30.033,  Loss1 0.751, Train_accy 68.97
2024-09-08 12:53:55,287 [foster.py] => SNet: Task 6, Epoch 50/130 => Loss 30.046,  Loss1 0.751, Train_accy 69.25
2024-09-08 12:54:02,031 [foster.py] => SNet: Task 6, Epoch 51/130 => Loss 30.007,  Loss1 0.751, Train_accy 68.95, Test_accy 68.26
2024-09-08 12:54:07,651 [foster.py] => SNet: Task 6, Epoch 52/130 => Loss 30.038,  Loss1 0.751, Train_accy 69.25
2024-09-08 12:54:13,272 [foster.py] => SNet: Task 6, Epoch 53/130 => Loss 30.013,  Loss1 0.751, Train_accy 68.75
2024-09-08 12:54:18,889 [foster.py] => SNet: Task 6, Epoch 54/130 => Loss 30.044,  Loss1 0.751, Train_accy 68.22
2024-09-08 12:54:24,482 [foster.py] => SNet: Task 6, Epoch 55/130 => Loss 30.019,  Loss1 0.751, Train_accy 69.47
2024-09-08 12:54:31,260 [foster.py] => SNet: Task 6, Epoch 56/130 => Loss 30.012,  Loss1 0.751, Train_accy 68.68, Test_accy 68.40
2024-09-08 12:54:36,873 [foster.py] => SNet: Task 6, Epoch 57/130 => Loss 30.011,  Loss1 0.751, Train_accy 70.40
2024-09-08 12:54:42,492 [foster.py] => SNet: Task 6, Epoch 58/130 => Loss 30.000,  Loss1 0.751, Train_accy 69.60
2024-09-08 12:54:48,120 [foster.py] => SNet: Task 6, Epoch 59/130 => Loss 30.001,  Loss1 0.751, Train_accy 69.60
2024-09-08 12:54:53,699 [foster.py] => SNet: Task 6, Epoch 60/130 => Loss 29.969,  Loss1 0.751, Train_accy 69.03
2024-09-08 12:55:00,467 [foster.py] => SNet: Task 6, Epoch 61/130 => Loss 30.011,  Loss1 0.751, Train_accy 68.80, Test_accy 68.44
2024-09-08 12:55:06,139 [foster.py] => SNet: Task 6, Epoch 62/130 => Loss 30.011,  Loss1 0.751, Train_accy 70.88
2024-09-08 12:55:11,735 [foster.py] => SNet: Task 6, Epoch 63/130 => Loss 30.031,  Loss1 0.751, Train_accy 70.08
2024-09-08 12:55:17,368 [foster.py] => SNet: Task 6, Epoch 64/130 => Loss 30.041,  Loss1 0.751, Train_accy 69.82
2024-09-08 12:55:22,954 [foster.py] => SNet: Task 6, Epoch 65/130 => Loss 30.044,  Loss1 0.751, Train_accy 69.68
2024-09-08 12:55:29,736 [foster.py] => SNet: Task 6, Epoch 66/130 => Loss 29.989,  Loss1 0.751, Train_accy 69.42, Test_accy 68.68
2024-09-08 12:55:35,396 [foster.py] => SNet: Task 6, Epoch 67/130 => Loss 30.017,  Loss1 0.751, Train_accy 71.10
2024-09-08 12:55:41,018 [foster.py] => SNet: Task 6, Epoch 68/130 => Loss 30.037,  Loss1 0.751, Train_accy 69.10
2024-09-08 12:55:46,630 [foster.py] => SNet: Task 6, Epoch 69/130 => Loss 30.009,  Loss1 0.751, Train_accy 69.60
2024-09-08 12:55:52,234 [foster.py] => SNet: Task 6, Epoch 70/130 => Loss 30.032,  Loss1 0.751, Train_accy 71.28
2024-09-08 12:55:58,977 [foster.py] => SNet: Task 6, Epoch 71/130 => Loss 29.996,  Loss1 0.751, Train_accy 70.22, Test_accy 68.44
2024-09-08 12:56:04,657 [foster.py] => SNet: Task 6, Epoch 72/130 => Loss 29.993,  Loss1 0.751, Train_accy 70.92
2024-09-08 12:56:10,270 [foster.py] => SNet: Task 6, Epoch 73/130 => Loss 30.008,  Loss1 0.751, Train_accy 70.58
2024-09-08 12:56:15,888 [foster.py] => SNet: Task 6, Epoch 74/130 => Loss 29.986,  Loss1 0.751, Train_accy 70.30
2024-09-08 12:56:21,519 [foster.py] => SNet: Task 6, Epoch 75/130 => Loss 29.998,  Loss1 0.751, Train_accy 70.62
2024-09-08 12:56:28,306 [foster.py] => SNet: Task 6, Epoch 76/130 => Loss 29.974,  Loss1 0.751, Train_accy 70.95, Test_accy 68.66
2024-09-08 12:56:33,931 [foster.py] => SNet: Task 6, Epoch 77/130 => Loss 30.044,  Loss1 0.751, Train_accy 70.58
2024-09-08 12:56:39,538 [foster.py] => SNet: Task 6, Epoch 78/130 => Loss 30.000,  Loss1 0.751, Train_accy 69.92
2024-09-08 12:56:45,153 [foster.py] => SNet: Task 6, Epoch 79/130 => Loss 30.052,  Loss1 0.751, Train_accy 69.60
2024-09-08 12:56:50,822 [foster.py] => SNet: Task 6, Epoch 80/130 => Loss 30.014,  Loss1 0.751, Train_accy 70.70
2024-09-08 12:56:57,613 [foster.py] => SNet: Task 6, Epoch 81/130 => Loss 30.037,  Loss1 0.751, Train_accy 71.05, Test_accy 68.59
2024-09-08 12:57:03,220 [foster.py] => SNet: Task 6, Epoch 82/130 => Loss 30.025,  Loss1 0.751, Train_accy 70.80
2024-09-08 12:57:08,799 [foster.py] => SNet: Task 6, Epoch 83/130 => Loss 30.013,  Loss1 0.751, Train_accy 70.50
2024-09-08 12:57:14,371 [foster.py] => SNet: Task 6, Epoch 84/130 => Loss 30.022,  Loss1 0.751, Train_accy 69.20
2024-09-08 12:57:19,964 [foster.py] => SNet: Task 6, Epoch 85/130 => Loss 30.003,  Loss1 0.751, Train_accy 71.40
2024-09-08 12:57:26,726 [foster.py] => SNet: Task 6, Epoch 86/130 => Loss 29.987,  Loss1 0.751, Train_accy 71.12, Test_accy 68.65
2024-09-08 12:57:32,401 [foster.py] => SNet: Task 6, Epoch 87/130 => Loss 29.981,  Loss1 0.751, Train_accy 70.00
2024-09-08 12:57:38,015 [foster.py] => SNet: Task 6, Epoch 88/130 => Loss 30.015,  Loss1 0.751, Train_accy 70.78
2024-09-08 12:57:43,644 [foster.py] => SNet: Task 6, Epoch 89/130 => Loss 30.019,  Loss1 0.751, Train_accy 70.03
2024-09-08 12:57:49,246 [foster.py] => SNet: Task 6, Epoch 90/130 => Loss 30.001,  Loss1 0.751, Train_accy 70.88
2024-09-08 12:57:56,058 [foster.py] => SNet: Task 6, Epoch 91/130 => Loss 29.980,  Loss1 0.751, Train_accy 69.68, Test_accy 68.64
2024-09-08 12:58:01,657 [foster.py] => SNet: Task 6, Epoch 92/130 => Loss 29.990,  Loss1 0.751, Train_accy 69.85
2024-09-08 12:58:07,275 [foster.py] => SNet: Task 6, Epoch 93/130 => Loss 30.006,  Loss1 0.751, Train_accy 71.75
2024-09-08 12:58:12,890 [foster.py] => SNet: Task 6, Epoch 94/130 => Loss 30.010,  Loss1 0.751, Train_accy 70.47
2024-09-08 12:58:18,516 [foster.py] => SNet: Task 6, Epoch 95/130 => Loss 30.026,  Loss1 0.751, Train_accy 70.78
2024-09-08 12:58:25,286 [foster.py] => SNet: Task 6, Epoch 96/130 => Loss 29.952,  Loss1 0.751, Train_accy 70.05, Test_accy 68.92
2024-09-08 12:58:30,890 [foster.py] => SNet: Task 6, Epoch 97/130 => Loss 30.004,  Loss1 0.751, Train_accy 70.85
2024-09-08 12:58:36,479 [foster.py] => SNet: Task 6, Epoch 98/130 => Loss 29.986,  Loss1 0.751, Train_accy 70.45
2024-09-08 12:58:42,040 [foster.py] => SNet: Task 6, Epoch 99/130 => Loss 30.039,  Loss1 0.751, Train_accy 71.40
2024-09-08 12:58:47,694 [foster.py] => SNet: Task 6, Epoch 100/130 => Loss 29.989,  Loss1 0.751, Train_accy 70.72
2024-09-08 12:58:54,515 [foster.py] => SNet: Task 6, Epoch 101/130 => Loss 30.012,  Loss1 0.751, Train_accy 71.50, Test_accy 69.00
2024-09-08 12:59:00,091 [foster.py] => SNet: Task 6, Epoch 102/130 => Loss 30.023,  Loss1 0.751, Train_accy 70.72
2024-09-08 12:59:05,741 [foster.py] => SNet: Task 6, Epoch 103/130 => Loss 29.989,  Loss1 0.751, Train_accy 70.38
2024-09-08 12:59:11,313 [foster.py] => SNet: Task 6, Epoch 104/130 => Loss 30.011,  Loss1 0.751, Train_accy 70.50
2024-09-08 12:59:16,957 [foster.py] => SNet: Task 6, Epoch 105/130 => Loss 30.008,  Loss1 0.751, Train_accy 69.62
2024-09-08 12:59:23,751 [foster.py] => SNet: Task 6, Epoch 106/130 => Loss 30.002,  Loss1 0.750, Train_accy 70.25, Test_accy 68.86
2024-09-08 12:59:29,344 [foster.py] => SNet: Task 6, Epoch 107/130 => Loss 30.005,  Loss1 0.751, Train_accy 70.75
2024-09-08 12:59:34,998 [foster.py] => SNet: Task 6, Epoch 108/130 => Loss 30.030,  Loss1 0.751, Train_accy 71.47
2024-09-08 12:59:40,588 [foster.py] => SNet: Task 6, Epoch 109/130 => Loss 30.001,  Loss1 0.751, Train_accy 69.70
2024-09-08 12:59:46,183 [foster.py] => SNet: Task 6, Epoch 110/130 => Loss 30.024,  Loss1 0.751, Train_accy 70.10
2024-09-08 12:59:53,004 [foster.py] => SNet: Task 6, Epoch 111/130 => Loss 30.004,  Loss1 0.751, Train_accy 70.35, Test_accy 68.56
2024-09-08 12:59:58,668 [foster.py] => SNet: Task 6, Epoch 112/130 => Loss 29.982,  Loss1 0.751, Train_accy 70.50
2024-09-08 13:00:04,270 [foster.py] => SNet: Task 6, Epoch 113/130 => Loss 30.030,  Loss1 0.751, Train_accy 70.80
2024-09-08 13:00:09,880 [foster.py] => SNet: Task 6, Epoch 114/130 => Loss 29.970,  Loss1 0.751, Train_accy 70.22
2024-09-08 13:00:15,503 [foster.py] => SNet: Task 6, Epoch 115/130 => Loss 30.041,  Loss1 0.751, Train_accy 71.40
2024-09-08 13:00:22,282 [foster.py] => SNet: Task 6, Epoch 116/130 => Loss 29.995,  Loss1 0.751, Train_accy 70.95, Test_accy 68.96
2024-09-08 13:00:27,880 [foster.py] => SNet: Task 6, Epoch 117/130 => Loss 29.993,  Loss1 0.751, Train_accy 70.22
2024-09-08 13:00:33,490 [foster.py] => SNet: Task 6, Epoch 118/130 => Loss 29.992,  Loss1 0.751, Train_accy 70.55
2024-09-08 13:00:39,094 [foster.py] => SNet: Task 6, Epoch 119/130 => Loss 30.015,  Loss1 0.751, Train_accy 70.82
2024-09-08 13:00:44,694 [foster.py] => SNet: Task 6, Epoch 120/130 => Loss 30.017,  Loss1 0.751, Train_accy 71.12
2024-09-08 13:00:51,493 [foster.py] => SNet: Task 6, Epoch 121/130 => Loss 29.985,  Loss1 0.751, Train_accy 70.50, Test_accy 68.97
2024-09-08 13:00:57,109 [foster.py] => SNet: Task 6, Epoch 122/130 => Loss 30.010,  Loss1 0.751, Train_accy 70.88
2024-09-08 13:01:02,717 [foster.py] => SNet: Task 6, Epoch 123/130 => Loss 29.981,  Loss1 0.751, Train_accy 71.97
2024-09-08 13:01:08,299 [foster.py] => SNet: Task 6, Epoch 124/130 => Loss 30.005,  Loss1 0.751, Train_accy 70.03
2024-09-08 13:01:13,976 [foster.py] => SNet: Task 6, Epoch 125/130 => Loss 29.985,  Loss1 0.751, Train_accy 70.70
2024-09-08 13:01:20,744 [foster.py] => SNet: Task 6, Epoch 126/130 => Loss 29.982,  Loss1 0.751, Train_accy 72.03, Test_accy 69.01
2024-09-08 13:01:26,374 [foster.py] => SNet: Task 6, Epoch 127/130 => Loss 30.032,  Loss1 0.751, Train_accy 70.08
2024-09-08 13:01:31,985 [foster.py] => SNet: Task 6, Epoch 128/130 => Loss 30.049,  Loss1 0.751, Train_accy 70.40
2024-09-08 13:01:37,605 [foster.py] => SNet: Task 6, Epoch 129/130 => Loss 30.041,  Loss1 0.751, Train_accy 69.92
2024-09-08 13:01:43,172 [foster.py] => SNet: Task 6, Epoch 130/130 => Loss 29.979,  Loss1 0.751, Train_accy 69.78
2024-09-08 13:01:43,172 [foster.py] => do not weight align student!
2024-09-08 13:01:44,354 [foster.py] => darknet eval: 
2024-09-08 13:01:44,355 [foster.py] => CNN top1 curve: 68.96
2024-09-08 13:01:44,355 [foster.py] => CNN top5 curve: 91.76
2024-09-08 13:01:44,355 [foster.py] => CNN top1 平均值: 68.96
2024-09-08 13:01:44,360 [foster.py] => timees : 1695.9177496433258
2024-09-08 13:01:44,362 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 13:02:10,126 [foster.py] => Exemplar size: 1600
2024-09-08 13:02:10,126 [trainer.py] => CNN: {'total': 69.88, '00-09': 76.8, '10-19': 62.9, '20-29': 77.2, '30-39': 69.4, '40-49': 72.1, '50-59': 57.1, '60-69': 73.8, '70-79': 69.7, 'old': 69.65, 'new': 73.2}
2024-09-08 13:02:10,126 [trainer.py] => NME: {'total': 64.05, '00-09': 69.5, '10-19': 57.6, '20-29': 71.2, '30-39': 62.5, '40-49': 63.8, '50-59': 53.2, '60-69': 69.2, '70-79': 65.4, 'old': 62.45, 'new': 88.0}
2024-09-08 13:02:10,126 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67, 69.88]
2024-09-08 13:02:10,126 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05, 92.24]
2024-09-08 13:02:10,126 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83, 64.05]
2024-09-08 13:02:10,126 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79, 89.66]

2024-09-08 13:02:10,126 [trainer.py] => CNN top1 平均值: 76.21
2024-09-08 13:02:10,129 [trainer.py] => All params: 1174943
2024-09-08 13:02:10,131 [trainer.py] => Trainable params: 592794
2024-09-08 13:02:10,191 [foster.py] => Learning on 80-85
2024-09-08 13:02:10,194 [foster.py] => All params: 1176238
2024-09-08 13:02:10,196 [foster.py] => Trainable params: 593764
2024-09-08 13:02:10,248 [foster.py] => per cls weights : [1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645 1.02350645
 1.02350645 1.02350645 0.62389678 0.62389678 0.62389678 0.62389678
 0.62389678]
2024-09-08 13:02:14,596 [foster.py] => Task 7, Epoch 1/170 => Loss 5.744, Loss_clf 1.310, Loss_fe 1.483, Loss_kd 2.775, Train_accy 61.24
2024-09-08 13:02:20,661 [foster.py] => Task 7, Epoch 2/170 => Loss 4.653, Loss_clf 0.784, Loss_fe 0.930, Loss_kd 2.764, Train_accy 67.34, Test_accy 66.45
2024-09-08 13:02:26,744 [foster.py] => Task 7, Epoch 3/170 => Loss 4.708, Loss_clf 0.792, Loss_fe 0.996, Loss_kd 2.746, Train_accy 64.00, Test_accy 66.51
2024-09-08 13:02:32,808 [foster.py] => Task 7, Epoch 4/170 => Loss 4.861, Loss_clf 0.786, Loss_fe 1.159, Loss_kd 2.743, Train_accy 61.88, Test_accy 64.04
2024-09-08 13:02:38,847 [foster.py] => Task 7, Epoch 5/170 => Loss 4.751, Loss_clf 0.834, Loss_fe 0.981, Loss_kd 2.762, Train_accy 65.93, Test_accy 66.76
2024-09-08 13:02:42,976 [foster.py] => Task 7, Epoch 6/170 => Loss 4.766, Loss_clf 0.785, Loss_fe 1.036, Loss_kd 2.771, Train_accy 64.05
2024-09-08 13:02:49,026 [foster.py] => Task 7, Epoch 7/170 => Loss 4.723, Loss_clf 0.804, Loss_fe 1.005, Loss_kd 2.741, Train_accy 64.39, Test_accy 67.34
2024-09-08 13:02:55,117 [foster.py] => Task 7, Epoch 8/170 => Loss 4.432, Loss_clf 0.699, Loss_fe 0.838, Loss_kd 2.723, Train_accy 66.51, Test_accy 67.25
2024-09-08 13:03:01,201 [foster.py] => Task 7, Epoch 9/170 => Loss 4.377, Loss_clf 0.676, Loss_fe 0.806, Loss_kd 2.723, Train_accy 68.71, Test_accy 67.16
2024-09-08 13:03:07,400 [foster.py] => Task 7, Epoch 10/170 => Loss 4.421, Loss_clf 0.669, Loss_fe 0.797, Loss_kd 2.779, Train_accy 69.68, Test_accy 66.76
2024-09-08 13:03:11,565 [foster.py] => Task 7, Epoch 11/170 => Loss 4.499, Loss_clf 0.731, Loss_fe 0.831, Loss_kd 2.762, Train_accy 67.24
2024-09-08 13:03:17,788 [foster.py] => Task 7, Epoch 12/170 => Loss 4.435, Loss_clf 0.697, Loss_fe 0.817, Loss_kd 2.747, Train_accy 67.32, Test_accy 66.92
2024-09-08 13:03:23,813 [foster.py] => Task 7, Epoch 13/170 => Loss 4.330, Loss_clf 0.679, Loss_fe 0.711, Loss_kd 2.766, Train_accy 67.49, Test_accy 67.07
2024-09-08 13:03:29,896 [foster.py] => Task 7, Epoch 14/170 => Loss 4.417, Loss_clf 0.710, Loss_fe 0.794, Loss_kd 2.739, Train_accy 67.85, Test_accy 66.55
2024-09-08 13:03:35,986 [foster.py] => Task 7, Epoch 15/170 => Loss 4.386, Loss_clf 0.690, Loss_fe 0.766, Loss_kd 2.756, Train_accy 68.29, Test_accy 67.12
2024-09-08 13:03:40,089 [foster.py] => Task 7, Epoch 16/170 => Loss 4.272, Loss_clf 0.646, Loss_fe 0.699, Loss_kd 2.753, Train_accy 70.29
2024-09-08 13:03:46,115 [foster.py] => Task 7, Epoch 17/170 => Loss 4.352, Loss_clf 0.672, Loss_fe 0.728, Loss_kd 2.777, Train_accy 69.80, Test_accy 66.98
2024-09-08 13:03:52,191 [foster.py] => Task 7, Epoch 18/170 => Loss 4.437, Loss_clf 0.717, Loss_fe 0.781, Loss_kd 2.764, Train_accy 70.22, Test_accy 66.94
2024-09-08 13:03:58,266 [foster.py] => Task 7, Epoch 19/170 => Loss 4.417, Loss_clf 0.710, Loss_fe 0.776, Loss_kd 2.757, Train_accy 66.88, Test_accy 66.36
2024-09-08 13:04:04,333 [foster.py] => Task 7, Epoch 20/170 => Loss 4.306, Loss_clf 0.666, Loss_fe 0.704, Loss_kd 2.762, Train_accy 70.93, Test_accy 67.21
2024-09-08 13:04:08,561 [foster.py] => Task 7, Epoch 21/170 => Loss 4.603, Loss_clf 0.785, Loss_fe 0.891, Loss_kd 2.753, Train_accy 66.93
2024-09-08 13:04:14,731 [foster.py] => Task 7, Epoch 22/170 => Loss 4.375, Loss_clf 0.649, Loss_fe 0.789, Loss_kd 2.762, Train_accy 69.00, Test_accy 67.01
2024-09-08 13:04:20,769 [foster.py] => Task 7, Epoch 23/170 => Loss 4.419, Loss_clf 0.669, Loss_fe 0.796, Loss_kd 2.779, Train_accy 70.27, Test_accy 66.45
2024-09-08 13:04:26,830 [foster.py] => Task 7, Epoch 24/170 => Loss 4.307, Loss_clf 0.635, Loss_fe 0.746, Loss_kd 2.753, Train_accy 69.98, Test_accy 67.47
2024-09-08 13:04:32,967 [foster.py] => Task 7, Epoch 25/170 => Loss 4.320, Loss_clf 0.654, Loss_fe 0.733, Loss_kd 2.759, Train_accy 70.20, Test_accy 67.48
2024-09-08 13:04:37,040 [foster.py] => Task 7, Epoch 26/170 => Loss 4.407, Loss_clf 0.705, Loss_fe 0.766, Loss_kd 2.761, Train_accy 69.93
2024-09-08 13:04:43,077 [foster.py] => Task 7, Epoch 27/170 => Loss 4.462, Loss_clf 0.776, Loss_fe 0.751, Loss_kd 2.761, Train_accy 71.37, Test_accy 66.62
2024-09-08 13:04:49,204 [foster.py] => Task 7, Epoch 28/170 => Loss 4.431, Loss_clf 0.698, Loss_fe 0.800, Loss_kd 2.758, Train_accy 70.10, Test_accy 67.13
2024-09-08 13:04:55,381 [foster.py] => Task 7, Epoch 29/170 => Loss 4.293, Loss_clf 0.666, Loss_fe 0.705, Loss_kd 2.748, Train_accy 69.41, Test_accy 66.93
2024-09-08 13:05:01,426 [foster.py] => Task 7, Epoch 30/170 => Loss 4.172, Loss_clf 0.635, Loss_fe 0.610, Loss_kd 2.753, Train_accy 70.83, Test_accy 67.78
2024-09-08 13:05:05,584 [foster.py] => Task 7, Epoch 31/170 => Loss 4.104, Loss_clf 0.604, Loss_fe 0.585, Loss_kd 2.742, Train_accy 72.10
2024-09-08 13:05:11,701 [foster.py] => Task 7, Epoch 32/170 => Loss 4.144, Loss_clf 0.589, Loss_fe 0.613, Loss_kd 2.767, Train_accy 74.24, Test_accy 67.60
2024-09-08 13:05:17,711 [foster.py] => Task 7, Epoch 33/170 => Loss 4.192, Loss_clf 0.620, Loss_fe 0.650, Loss_kd 2.749, Train_accy 73.27, Test_accy 67.69
2024-09-08 13:05:23,756 [foster.py] => Task 7, Epoch 34/170 => Loss 4.318, Loss_clf 0.650, Loss_fe 0.767, Loss_kd 2.729, Train_accy 71.10, Test_accy 67.13
2024-09-08 13:05:29,908 [foster.py] => Task 7, Epoch 35/170 => Loss 4.185, Loss_clf 0.616, Loss_fe 0.633, Loss_kd 2.761, Train_accy 71.93, Test_accy 67.41
2024-09-08 13:05:34,025 [foster.py] => Task 7, Epoch 36/170 => Loss 4.116, Loss_clf 0.604, Loss_fe 0.588, Loss_kd 2.751, Train_accy 73.22
2024-09-08 13:05:40,117 [foster.py] => Task 7, Epoch 37/170 => Loss 4.130, Loss_clf 0.625, Loss_fe 0.604, Loss_kd 2.729, Train_accy 73.68, Test_accy 67.49
2024-09-08 13:05:46,240 [foster.py] => Task 7, Epoch 38/170 => Loss 4.080, Loss_clf 0.581, Loss_fe 0.573, Loss_kd 2.753, Train_accy 73.78, Test_accy 67.44
2024-09-08 13:05:52,321 [foster.py] => Task 7, Epoch 39/170 => Loss 4.186, Loss_clf 0.630, Loss_fe 0.632, Loss_kd 2.751, Train_accy 73.20, Test_accy 67.65
2024-09-08 13:05:58,367 [foster.py] => Task 7, Epoch 40/170 => Loss 4.398, Loss_clf 0.749, Loss_fe 0.728, Loss_kd 2.747, Train_accy 70.76, Test_accy 67.32
2024-09-08 13:06:02,473 [foster.py] => Task 7, Epoch 41/170 => Loss 4.247, Loss_clf 0.677, Loss_fe 0.651, Loss_kd 2.746, Train_accy 71.12
2024-09-08 13:06:08,530 [foster.py] => Task 7, Epoch 42/170 => Loss 4.162, Loss_clf 0.625, Loss_fe 0.615, Loss_kd 2.749, Train_accy 70.71, Test_accy 67.00
2024-09-08 13:06:14,591 [foster.py] => Task 7, Epoch 43/170 => Loss 4.088, Loss_clf 0.592, Loss_fe 0.576, Loss_kd 2.747, Train_accy 73.63, Test_accy 67.53
2024-09-08 13:06:20,692 [foster.py] => Task 7, Epoch 44/170 => Loss 4.175, Loss_clf 0.611, Loss_fe 0.664, Loss_kd 2.728, Train_accy 72.90, Test_accy 67.06
2024-09-08 13:06:26,733 [foster.py] => Task 7, Epoch 45/170 => Loss 4.106, Loss_clf 0.587, Loss_fe 0.605, Loss_kd 2.741, Train_accy 71.56, Test_accy 67.52
2024-09-08 13:06:30,796 [foster.py] => Task 7, Epoch 46/170 => Loss 4.072, Loss_clf 0.579, Loss_fe 0.564, Loss_kd 2.756, Train_accy 73.00
2024-09-08 13:06:36,789 [foster.py] => Task 7, Epoch 47/170 => Loss 4.062, Loss_clf 0.571, Loss_fe 0.582, Loss_kd 2.736, Train_accy 75.15, Test_accy 67.42
2024-09-08 13:06:42,898 [foster.py] => Task 7, Epoch 48/170 => Loss 4.134, Loss_clf 0.596, Loss_fe 0.591, Loss_kd 2.772, Train_accy 72.71, Test_accy 67.32
2024-09-08 13:06:48,970 [foster.py] => Task 7, Epoch 49/170 => Loss 4.214, Loss_clf 0.636, Loss_fe 0.664, Loss_kd 2.741, Train_accy 73.27, Test_accy 67.62
2024-09-08 13:06:55,048 [foster.py] => Task 7, Epoch 50/170 => Loss 4.154, Loss_clf 0.627, Loss_fe 0.583, Loss_kd 2.769, Train_accy 73.41, Test_accy 67.08
2024-09-08 13:06:59,179 [foster.py] => Task 7, Epoch 51/170 => Loss 4.415, Loss_clf 0.783, Loss_fe 0.691, Loss_kd 2.766, Train_accy 70.24
2024-09-08 13:07:05,234 [foster.py] => Task 7, Epoch 52/170 => Loss 4.376, Loss_clf 0.756, Loss_fe 0.665, Loss_kd 2.779, Train_accy 70.32, Test_accy 66.75
2024-09-08 13:07:11,272 [foster.py] => Task 7, Epoch 53/170 => Loss 4.035, Loss_clf 0.575, Loss_fe 0.546, Loss_kd 2.741, Train_accy 74.51, Test_accy 67.64
2024-09-08 13:07:17,328 [foster.py] => Task 7, Epoch 54/170 => Loss 4.036, Loss_clf 0.559, Loss_fe 0.533, Loss_kd 2.770, Train_accy 75.61, Test_accy 67.51
2024-09-08 13:07:23,462 [foster.py] => Task 7, Epoch 55/170 => Loss 4.396, Loss_clf 0.677, Loss_fe 0.774, Loss_kd 2.770, Train_accy 69.83, Test_accy 66.69
2024-09-08 13:07:27,634 [foster.py] => Task 7, Epoch 56/170 => Loss 4.353, Loss_clf 0.677, Loss_fe 0.727, Loss_kd 2.773, Train_accy 69.80
2024-09-08 13:07:33,706 [foster.py] => Task 7, Epoch 57/170 => Loss 4.161, Loss_clf 0.610, Loss_fe 0.644, Loss_kd 2.734, Train_accy 71.27, Test_accy 67.89
2024-09-08 13:07:39,776 [foster.py] => Task 7, Epoch 58/170 => Loss 4.144, Loss_clf 0.594, Loss_fe 0.611, Loss_kd 2.764, Train_accy 71.07, Test_accy 67.39
2024-09-08 13:07:45,863 [foster.py] => Task 7, Epoch 59/170 => Loss 4.123, Loss_clf 0.586, Loss_fe 0.608, Loss_kd 2.755, Train_accy 72.78, Test_accy 67.80
2024-09-08 13:07:51,950 [foster.py] => Task 7, Epoch 60/170 => Loss 3.990, Loss_clf 0.555, Loss_fe 0.546, Loss_kd 2.718, Train_accy 73.39, Test_accy 67.53
2024-09-08 13:07:56,123 [foster.py] => Task 7, Epoch 61/170 => Loss 4.067, Loss_clf 0.558, Loss_fe 0.556, Loss_kd 2.778, Train_accy 71.76
2024-09-08 13:08:02,126 [foster.py] => Task 7, Epoch 62/170 => Loss 4.245, Loss_clf 0.665, Loss_fe 0.645, Loss_kd 2.761, Train_accy 71.54, Test_accy 67.38
2024-09-08 13:08:08,171 [foster.py] => Task 7, Epoch 63/170 => Loss 4.125, Loss_clf 0.611, Loss_fe 0.567, Loss_kd 2.773, Train_accy 71.05, Test_accy 67.72
2024-09-08 13:08:14,200 [foster.py] => Task 7, Epoch 64/170 => Loss 4.053, Loss_clf 0.596, Loss_fe 0.555, Loss_kd 2.730, Train_accy 72.73, Test_accy 67.46
2024-09-08 13:08:20,256 [foster.py] => Task 7, Epoch 65/170 => Loss 4.026, Loss_clf 0.601, Loss_fe 0.492, Loss_kd 2.759, Train_accy 73.34, Test_accy 67.84
2024-09-08 13:08:24,313 [foster.py] => Task 7, Epoch 66/170 => Loss 4.015, Loss_clf 0.560, Loss_fe 0.533, Loss_kd 2.748, Train_accy 74.20
2024-09-08 13:08:30,378 [foster.py] => Task 7, Epoch 67/170 => Loss 3.980, Loss_clf 0.552, Loss_fe 0.492, Loss_kd 2.763, Train_accy 75.17, Test_accy 67.42
2024-09-08 13:08:36,451 [foster.py] => Task 7, Epoch 68/170 => Loss 3.919, Loss_clf 0.530, Loss_fe 0.487, Loss_kd 2.731, Train_accy 75.37, Test_accy 67.61
2024-09-08 13:08:42,506 [foster.py] => Task 7, Epoch 69/170 => Loss 4.036, Loss_clf 0.579, Loss_fe 0.520, Loss_kd 2.763, Train_accy 73.39, Test_accy 67.99
2024-09-08 13:08:48,595 [foster.py] => Task 7, Epoch 70/170 => Loss 4.117, Loss_clf 0.603, Loss_fe 0.555, Loss_kd 2.784, Train_accy 75.56, Test_accy 67.15
2024-09-08 13:08:52,694 [foster.py] => Task 7, Epoch 71/170 => Loss 4.182, Loss_clf 0.594, Loss_fe 0.641, Loss_kd 2.771, Train_accy 72.32
2024-09-08 13:08:58,792 [foster.py] => Task 7, Epoch 72/170 => Loss 4.461, Loss_clf 0.695, Loss_fe 0.820, Loss_kd 2.771, Train_accy 70.02, Test_accy 67.15
2024-09-08 13:09:04,845 [foster.py] => Task 7, Epoch 73/170 => Loss 4.449, Loss_clf 0.773, Loss_fe 0.754, Loss_kd 2.748, Train_accy 68.63, Test_accy 67.26
2024-09-08 13:09:11,001 [foster.py] => Task 7, Epoch 74/170 => Loss 4.158, Loss_clf 0.607, Loss_fe 0.619, Loss_kd 2.758, Train_accy 70.90, Test_accy 67.16
2024-09-08 13:09:17,038 [foster.py] => Task 7, Epoch 75/170 => Loss 4.010, Loss_clf 0.555, Loss_fe 0.566, Loss_kd 2.718, Train_accy 72.27, Test_accy 66.96
2024-09-08 13:09:21,151 [foster.py] => Task 7, Epoch 76/170 => Loss 4.068, Loss_clf 0.572, Loss_fe 0.567, Loss_kd 2.756, Train_accy 72.61
2024-09-08 13:09:27,302 [foster.py] => Task 7, Epoch 77/170 => Loss 4.067, Loss_clf 0.606, Loss_fe 0.561, Loss_kd 2.728, Train_accy 72.80, Test_accy 67.73
2024-09-08 13:09:33,391 [foster.py] => Task 7, Epoch 78/170 => Loss 4.261, Loss_clf 0.633, Loss_fe 0.675, Loss_kd 2.777, Train_accy 72.41, Test_accy 66.85
2024-09-08 13:09:39,561 [foster.py] => Task 7, Epoch 79/170 => Loss 4.125, Loss_clf 0.584, Loss_fe 0.610, Loss_kd 2.757, Train_accy 72.22, Test_accy 67.61
2024-09-08 13:09:45,727 [foster.py] => Task 7, Epoch 80/170 => Loss 4.197, Loss_clf 0.639, Loss_fe 0.623, Loss_kd 2.761, Train_accy 70.37, Test_accy 67.26
2024-09-08 13:09:49,782 [foster.py] => Task 7, Epoch 81/170 => Loss 3.994, Loss_clf 0.539, Loss_fe 0.539, Loss_kd 2.743, Train_accy 74.54
2024-09-08 13:09:55,831 [foster.py] => Task 7, Epoch 82/170 => Loss 4.060, Loss_clf 0.584, Loss_fe 0.545, Loss_kd 2.757, Train_accy 74.24, Test_accy 68.00
2024-09-08 13:10:01,929 [foster.py] => Task 7, Epoch 83/170 => Loss 3.880, Loss_clf 0.517, Loss_fe 0.484, Loss_kd 2.709, Train_accy 74.10, Test_accy 67.81
2024-09-08 13:10:07,979 [foster.py] => Task 7, Epoch 84/170 => Loss 3.970, Loss_clf 0.554, Loss_fe 0.483, Loss_kd 2.758, Train_accy 75.68, Test_accy 67.40
2024-09-08 13:10:14,041 [foster.py] => Task 7, Epoch 85/170 => Loss 4.269, Loss_clf 0.642, Loss_fe 0.709, Loss_kd 2.745, Train_accy 72.00, Test_accy 67.39
2024-09-08 13:10:18,084 [foster.py] => Task 7, Epoch 86/170 => Loss 4.299, Loss_clf 0.644, Loss_fe 0.708, Loss_kd 2.772, Train_accy 72.54
2024-09-08 13:10:24,182 [foster.py] => Task 7, Epoch 87/170 => Loss 4.122, Loss_clf 0.604, Loss_fe 0.572, Loss_kd 2.771, Train_accy 72.24, Test_accy 67.52
2024-09-08 13:10:30,283 [foster.py] => Task 7, Epoch 88/170 => Loss 4.004, Loss_clf 0.560, Loss_fe 0.514, Loss_kd 2.756, Train_accy 72.66, Test_accy 67.87
2024-09-08 13:10:36,328 [foster.py] => Task 7, Epoch 89/170 => Loss 4.061, Loss_clf 0.588, Loss_fe 0.531, Loss_kd 2.767, Train_accy 73.66, Test_accy 66.98
2024-09-08 13:10:42,441 [foster.py] => Task 7, Epoch 90/170 => Loss 4.018, Loss_clf 0.568, Loss_fe 0.514, Loss_kd 2.761, Train_accy 74.24, Test_accy 67.58
2024-09-08 13:10:46,524 [foster.py] => Task 7, Epoch 91/170 => Loss 3.886, Loss_clf 0.520, Loss_fe 0.446, Loss_kd 2.746, Train_accy 75.85
2024-09-08 13:10:52,577 [foster.py] => Task 7, Epoch 92/170 => Loss 3.885, Loss_clf 0.523, Loss_fe 0.424, Loss_kd 2.763, Train_accy 76.98, Test_accy 67.76
2024-09-08 13:10:58,691 [foster.py] => Task 7, Epoch 93/170 => Loss 3.966, Loss_clf 0.549, Loss_fe 0.484, Loss_kd 2.758, Train_accy 77.68, Test_accy 67.64
2024-09-08 13:11:04,740 [foster.py] => Task 7, Epoch 94/170 => Loss 4.224, Loss_clf 0.620, Loss_fe 0.673, Loss_kd 2.757, Train_accy 72.20, Test_accy 66.52
2024-09-08 13:11:10,853 [foster.py] => Task 7, Epoch 95/170 => Loss 4.020, Loss_clf 0.538, Loss_fe 0.558, Loss_kd 2.750, Train_accy 73.61, Test_accy 67.27
2024-09-08 13:11:14,958 [foster.py] => Task 7, Epoch 96/170 => Loss 3.966, Loss_clf 0.526, Loss_fe 0.515, Loss_kd 2.751, Train_accy 75.00
2024-09-08 13:11:21,105 [foster.py] => Task 7, Epoch 97/170 => Loss 4.188, Loss_clf 0.632, Loss_fe 0.611, Loss_kd 2.770, Train_accy 71.85, Test_accy 67.72
2024-09-08 13:11:27,188 [foster.py] => Task 7, Epoch 98/170 => Loss 4.119, Loss_clf 0.604, Loss_fe 0.574, Loss_kd 2.766, Train_accy 71.63, Test_accy 67.46
2024-09-08 13:11:33,419 [foster.py] => Task 7, Epoch 99/170 => Loss 3.937, Loss_clf 0.533, Loss_fe 0.505, Loss_kd 2.727, Train_accy 72.83, Test_accy 67.45
2024-09-08 13:11:39,430 [foster.py] => Task 7, Epoch 100/170 => Loss 3.941, Loss_clf 0.532, Loss_fe 0.476, Loss_kd 2.758, Train_accy 75.76, Test_accy 67.79
2024-09-08 13:11:43,478 [foster.py] => Task 7, Epoch 101/170 => Loss 3.952, Loss_clf 0.540, Loss_fe 0.456, Loss_kd 2.781, Train_accy 76.61
2024-09-08 13:11:49,572 [foster.py] => Task 7, Epoch 102/170 => Loss 3.951, Loss_clf 0.521, Loss_fe 0.481, Loss_kd 2.774, Train_accy 74.76, Test_accy 67.72
2024-09-08 13:11:55,622 [foster.py] => Task 7, Epoch 103/170 => Loss 3.956, Loss_clf 0.555, Loss_fe 0.473, Loss_kd 2.754, Train_accy 75.02, Test_accy 67.62
2024-09-08 13:12:01,626 [foster.py] => Task 7, Epoch 104/170 => Loss 3.930, Loss_clf 0.514, Loss_fe 0.497, Loss_kd 2.745, Train_accy 76.12, Test_accy 67.54
2024-09-08 13:12:07,719 [foster.py] => Task 7, Epoch 105/170 => Loss 3.910, Loss_clf 0.522, Loss_fe 0.449, Loss_kd 2.764, Train_accy 75.07, Test_accy 67.74
2024-09-08 13:12:11,789 [foster.py] => Task 7, Epoch 106/170 => Loss 3.944, Loss_clf 0.517, Loss_fe 0.490, Loss_kd 2.763, Train_accy 76.83
2024-09-08 13:12:17,876 [foster.py] => Task 7, Epoch 107/170 => Loss 3.815, Loss_clf 0.496, Loss_fe 0.441, Loss_kd 2.707, Train_accy 75.56, Test_accy 67.56
2024-09-08 13:12:24,005 [foster.py] => Task 7, Epoch 108/170 => Loss 3.797, Loss_clf 0.488, Loss_fe 0.403, Loss_kd 2.733, Train_accy 76.39, Test_accy 67.60
2024-09-08 13:12:30,099 [foster.py] => Task 7, Epoch 109/170 => Loss 3.890, Loss_clf 0.523, Loss_fe 0.429, Loss_kd 2.764, Train_accy 75.80, Test_accy 68.22
2024-09-08 13:12:36,245 [foster.py] => Task 7, Epoch 110/170 => Loss 3.841, Loss_clf 0.490, Loss_fe 0.378, Loss_kd 2.797, Train_accy 77.49, Test_accy 67.91
2024-09-08 13:12:40,365 [foster.py] => Task 7, Epoch 111/170 => Loss 3.733, Loss_clf 0.466, Loss_fe 0.376, Loss_kd 2.719, Train_accy 76.41
2024-09-08 13:12:46,487 [foster.py] => Task 7, Epoch 112/170 => Loss 3.730, Loss_clf 0.466, Loss_fe 0.353, Loss_kd 2.739, Train_accy 78.17, Test_accy 68.24
2024-09-08 13:12:52,664 [foster.py] => Task 7, Epoch 113/170 => Loss 3.827, Loss_clf 0.494, Loss_fe 0.387, Loss_kd 2.772, Train_accy 78.73, Test_accy 67.60
2024-09-08 13:12:58,819 [foster.py] => Task 7, Epoch 114/170 => Loss 3.802, Loss_clf 0.494, Loss_fe 0.410, Loss_kd 2.726, Train_accy 76.80, Test_accy 67.45
2024-09-08 13:13:04,919 [foster.py] => Task 7, Epoch 115/170 => Loss 3.807, Loss_clf 0.501, Loss_fe 0.404, Loss_kd 2.730, Train_accy 77.17, Test_accy 67.44
2024-09-08 13:13:09,030 [foster.py] => Task 7, Epoch 116/170 => Loss 3.830, Loss_clf 0.491, Loss_fe 0.406, Loss_kd 2.759, Train_accy 77.61
2024-09-08 13:13:15,103 [foster.py] => Task 7, Epoch 117/170 => Loss 3.883, Loss_clf 0.491, Loss_fe 0.457, Loss_kd 2.760, Train_accy 76.37, Test_accy 67.65
2024-09-08 13:13:21,149 [foster.py] => Task 7, Epoch 118/170 => Loss 3.768, Loss_clf 0.475, Loss_fe 0.390, Loss_kd 2.732, Train_accy 78.39, Test_accy 67.95
2024-09-08 13:13:27,319 [foster.py] => Task 7, Epoch 119/170 => Loss 3.868, Loss_clf 0.523, Loss_fe 0.405, Loss_kd 2.766, Train_accy 77.24, Test_accy 68.04
2024-09-08 13:13:33,490 [foster.py] => Task 7, Epoch 120/170 => Loss 3.765, Loss_clf 0.461, Loss_fe 0.357, Loss_kd 2.772, Train_accy 78.66, Test_accy 67.68
2024-09-08 13:13:37,685 [foster.py] => Task 7, Epoch 121/170 => Loss 3.777, Loss_clf 0.480, Loss_fe 0.374, Loss_kd 2.750, Train_accy 78.46
2024-09-08 13:13:43,892 [foster.py] => Task 7, Epoch 122/170 => Loss 3.741, Loss_clf 0.460, Loss_fe 0.355, Loss_kd 2.751, Train_accy 78.93, Test_accy 67.80
2024-09-08 13:13:49,955 [foster.py] => Task 7, Epoch 123/170 => Loss 3.726, Loss_clf 0.454, Loss_fe 0.327, Loss_kd 2.770, Train_accy 79.66, Test_accy 67.85
2024-09-08 13:13:56,068 [foster.py] => Task 7, Epoch 124/170 => Loss 3.696, Loss_clf 0.458, Loss_fe 0.339, Loss_kd 2.726, Train_accy 80.41, Test_accy 67.59
2024-09-08 13:14:02,164 [foster.py] => Task 7, Epoch 125/170 => Loss 3.707, Loss_clf 0.451, Loss_fe 0.359, Loss_kd 2.726, Train_accy 78.73, Test_accy 67.75
2024-09-08 13:14:06,216 [foster.py] => Task 7, Epoch 126/170 => Loss 3.704, Loss_clf 0.454, Loss_fe 0.343, Loss_kd 2.734, Train_accy 80.27
2024-09-08 13:14:12,339 [foster.py] => Task 7, Epoch 127/170 => Loss 3.862, Loss_clf 0.511, Loss_fe 0.397, Loss_kd 2.778, Train_accy 77.56, Test_accy 67.74
2024-09-08 13:14:18,427 [foster.py] => Task 7, Epoch 128/170 => Loss 3.789, Loss_clf 0.482, Loss_fe 0.366, Loss_kd 2.766, Train_accy 80.07, Test_accy 67.92
2024-09-08 13:14:24,515 [foster.py] => Task 7, Epoch 129/170 => Loss 3.775, Loss_clf 0.465, Loss_fe 0.396, Loss_kd 2.741, Train_accy 79.00, Test_accy 67.85
2024-09-08 13:14:30,645 [foster.py] => Task 7, Epoch 130/170 => Loss 3.725, Loss_clf 0.447, Loss_fe 0.366, Loss_kd 2.739, Train_accy 80.34, Test_accy 67.89
2024-09-08 13:14:34,739 [foster.py] => Task 7, Epoch 131/170 => Loss 3.735, Loss_clf 0.449, Loss_fe 0.355, Loss_kd 2.757, Train_accy 78.68
2024-09-08 13:14:40,832 [foster.py] => Task 7, Epoch 132/170 => Loss 3.772, Loss_clf 0.476, Loss_fe 0.362, Loss_kd 2.760, Train_accy 79.71, Test_accy 68.00
2024-09-08 13:14:46,897 [foster.py] => Task 7, Epoch 133/170 => Loss 3.754, Loss_clf 0.482, Loss_fe 0.334, Loss_kd 2.763, Train_accy 78.71, Test_accy 67.92
2024-09-08 13:14:52,945 [foster.py] => Task 7, Epoch 134/170 => Loss 3.675, Loss_clf 0.457, Loss_fe 0.317, Loss_kd 2.729, Train_accy 79.39, Test_accy 67.81
2024-09-08 13:14:58,944 [foster.py] => Task 7, Epoch 135/170 => Loss 3.767, Loss_clf 0.492, Loss_fe 0.332, Loss_kd 2.768, Train_accy 79.37, Test_accy 67.91
2024-09-08 13:15:03,125 [foster.py] => Task 7, Epoch 136/170 => Loss 3.720, Loss_clf 0.452, Loss_fe 0.321, Loss_kd 2.772, Train_accy 79.76
2024-09-08 13:15:09,135 [foster.py] => Task 7, Epoch 137/170 => Loss 3.720, Loss_clf 0.464, Loss_fe 0.341, Loss_kd 2.742, Train_accy 79.98, Test_accy 67.93
2024-09-08 13:15:15,160 [foster.py] => Task 7, Epoch 138/170 => Loss 3.826, Loss_clf 0.477, Loss_fe 0.396, Loss_kd 2.778, Train_accy 77.85, Test_accy 67.91
2024-09-08 13:15:21,243 [foster.py] => Task 7, Epoch 139/170 => Loss 3.742, Loss_clf 0.467, Loss_fe 0.366, Loss_kd 2.736, Train_accy 79.85, Test_accy 68.09
2024-09-08 13:15:27,274 [foster.py] => Task 7, Epoch 140/170 => Loss 3.818, Loss_clf 0.481, Loss_fe 0.383, Loss_kd 2.779, Train_accy 79.73, Test_accy 68.00
2024-09-08 13:15:31,432 [foster.py] => Task 7, Epoch 141/170 => Loss 3.658, Loss_clf 0.424, Loss_fe 0.338, Loss_kd 2.724, Train_accy 79.73
2024-09-08 13:15:37,525 [foster.py] => Task 7, Epoch 142/170 => Loss 3.710, Loss_clf 0.463, Loss_fe 0.339, Loss_kd 2.735, Train_accy 79.39, Test_accy 67.94
2024-09-08 13:15:43,628 [foster.py] => Task 7, Epoch 143/170 => Loss 3.709, Loss_clf 0.439, Loss_fe 0.338, Loss_kd 2.758, Train_accy 80.10, Test_accy 68.08
2024-09-08 13:15:49,678 [foster.py] => Task 7, Epoch 144/170 => Loss 3.760, Loss_clf 0.468, Loss_fe 0.358, Loss_kd 2.760, Train_accy 80.51, Test_accy 68.05
2024-09-08 13:15:55,747 [foster.py] => Task 7, Epoch 145/170 => Loss 3.786, Loss_clf 0.483, Loss_fe 0.359, Loss_kd 2.769, Train_accy 80.68, Test_accy 68.09
2024-09-08 13:15:59,930 [foster.py] => Task 7, Epoch 146/170 => Loss 3.732, Loss_clf 0.460, Loss_fe 0.328, Loss_kd 2.769, Train_accy 79.80
2024-09-08 13:16:06,065 [foster.py] => Task 7, Epoch 147/170 => Loss 3.738, Loss_clf 0.475, Loss_fe 0.337, Loss_kd 2.752, Train_accy 79.80, Test_accy 68.02
2024-09-08 13:16:12,124 [foster.py] => Task 7, Epoch 148/170 => Loss 3.627, Loss_clf 0.423, Loss_fe 0.296, Loss_kd 2.735, Train_accy 79.49, Test_accy 68.22
2024-09-08 13:16:18,262 [foster.py] => Task 7, Epoch 149/170 => Loss 3.827, Loss_clf 0.529, Loss_fe 0.381, Loss_kd 2.744, Train_accy 78.73, Test_accy 68.16
2024-09-08 13:16:24,335 [foster.py] => Task 7, Epoch 150/170 => Loss 3.700, Loss_clf 0.452, Loss_fe 0.334, Loss_kd 2.742, Train_accy 81.02, Test_accy 68.13
2024-09-08 13:16:28,472 [foster.py] => Task 7, Epoch 151/170 => Loss 3.702, Loss_clf 0.424, Loss_fe 0.337, Loss_kd 2.767, Train_accy 81.22
2024-09-08 13:16:34,564 [foster.py] => Task 7, Epoch 152/170 => Loss 3.711, Loss_clf 0.459, Loss_fe 0.327, Loss_kd 2.751, Train_accy 80.34, Test_accy 67.99
2024-09-08 13:16:40,634 [foster.py] => Task 7, Epoch 153/170 => Loss 3.702, Loss_clf 0.464, Loss_fe 0.307, Loss_kd 2.757, Train_accy 80.07, Test_accy 67.99
2024-09-08 13:16:46,736 [foster.py] => Task 7, Epoch 154/170 => Loss 3.722, Loss_clf 0.446, Loss_fe 0.352, Loss_kd 2.751, Train_accy 80.05, Test_accy 68.21
2024-09-08 13:16:52,798 [foster.py] => Task 7, Epoch 155/170 => Loss 3.716, Loss_clf 0.458, Loss_fe 0.323, Loss_kd 2.760, Train_accy 79.80, Test_accy 67.91
2024-09-08 13:16:56,831 [foster.py] => Task 7, Epoch 156/170 => Loss 3.661, Loss_clf 0.440, Loss_fe 0.288, Loss_kd 2.759, Train_accy 80.17
2024-09-08 13:17:02,855 [foster.py] => Task 7, Epoch 157/170 => Loss 3.806, Loss_clf 0.496, Loss_fe 0.359, Loss_kd 2.776, Train_accy 80.78, Test_accy 68.07
2024-09-08 13:17:08,947 [foster.py] => Task 7, Epoch 158/170 => Loss 3.693, Loss_clf 0.471, Loss_fe 0.297, Loss_kd 2.751, Train_accy 79.78, Test_accy 68.06
2024-09-08 13:17:15,064 [foster.py] => Task 7, Epoch 159/170 => Loss 3.707, Loss_clf 0.460, Loss_fe 0.304, Loss_kd 2.768, Train_accy 80.63, Test_accy 68.11
2024-09-08 13:17:21,129 [foster.py] => Task 7, Epoch 160/170 => Loss 3.704, Loss_clf 0.454, Loss_fe 0.321, Loss_kd 2.756, Train_accy 79.98, Test_accy 68.13
2024-09-08 13:17:25,271 [foster.py] => Task 7, Epoch 161/170 => Loss 3.667, Loss_clf 0.425, Loss_fe 0.319, Loss_kd 2.749, Train_accy 81.39
2024-09-08 13:17:31,313 [foster.py] => Task 7, Epoch 162/170 => Loss 3.735, Loss_clf 0.479, Loss_fe 0.316, Loss_kd 2.765, Train_accy 80.83, Test_accy 68.07
2024-09-08 13:17:37,403 [foster.py] => Task 7, Epoch 163/170 => Loss 3.703, Loss_clf 0.458, Loss_fe 0.332, Loss_kd 2.740, Train_accy 80.22, Test_accy 67.99
2024-09-08 13:17:43,492 [foster.py] => Task 7, Epoch 164/170 => Loss 3.688, Loss_clf 0.439, Loss_fe 0.330, Loss_kd 2.745, Train_accy 81.34, Test_accy 68.01
2024-09-08 13:17:49,609 [foster.py] => Task 7, Epoch 165/170 => Loss 3.656, Loss_clf 0.436, Loss_fe 0.303, Loss_kd 2.744, Train_accy 80.78, Test_accy 68.01
2024-09-08 13:17:53,660 [foster.py] => Task 7, Epoch 166/170 => Loss 3.647, Loss_clf 0.419, Loss_fe 0.296, Loss_kd 2.758, Train_accy 80.27
2024-09-08 13:17:59,698 [foster.py] => Task 7, Epoch 167/170 => Loss 3.550, Loss_clf 0.401, Loss_fe 0.270, Loss_kd 2.708, Train_accy 81.20, Test_accy 68.06
2024-09-08 13:18:05,837 [foster.py] => Task 7, Epoch 168/170 => Loss 3.655, Loss_clf 0.437, Loss_fe 0.297, Loss_kd 2.748, Train_accy 81.46, Test_accy 68.02
2024-09-08 13:18:11,885 [foster.py] => Task 7, Epoch 169/170 => Loss 3.803, Loss_clf 0.475, Loss_fe 0.379, Loss_kd 2.774, Train_accy 80.68, Test_accy 68.12
2024-09-08 13:18:17,907 [foster.py] => Task 7, Epoch 170/170 => Loss 3.654, Loss_clf 0.422, Loss_fe 0.301, Loss_kd 2.757, Train_accy 80.71, Test_accy 68.00
2024-09-08 13:18:17,911 [foster.py] => do not weight align teacher!
2024-09-08 13:18:17,914 [foster.py] => per cls weights : [1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615 1.02882615
 1.02882615 1.02882615 0.53878162 0.53878162 0.53878162 0.53878162
 0.53878162]
2024-09-08 13:18:25,096 [foster.py] => SNet: Task 7, Epoch 1/130 => Loss 30.773,  Loss1 0.768, Train_accy 38.22, Test_accy 63.24
2024-09-08 13:18:30,905 [foster.py] => SNet: Task 7, Epoch 2/130 => Loss 30.627,  Loss1 0.768, Train_accy 48.78
2024-09-08 13:18:36,746 [foster.py] => SNet: Task 7, Epoch 3/130 => Loss 30.631,  Loss1 0.767, Train_accy 52.37
2024-09-08 13:18:42,510 [foster.py] => SNet: Task 7, Epoch 4/130 => Loss 30.601,  Loss1 0.768, Train_accy 54.05
2024-09-08 13:18:48,351 [foster.py] => SNet: Task 7, Epoch 5/130 => Loss 30.581,  Loss1 0.767, Train_accy 56.93
2024-09-08 13:18:55,368 [foster.py] => SNet: Task 7, Epoch 6/130 => Loss 30.611,  Loss1 0.767, Train_accy 57.02, Test_accy 63.51
2024-09-08 13:19:01,087 [foster.py] => SNet: Task 7, Epoch 7/130 => Loss 30.574,  Loss1 0.768, Train_accy 57.80
2024-09-08 13:19:06,854 [foster.py] => SNet: Task 7, Epoch 8/130 => Loss 30.655,  Loss1 0.767, Train_accy 57.15
2024-09-08 13:19:12,672 [foster.py] => SNet: Task 7, Epoch 9/130 => Loss 30.651,  Loss1 0.767, Train_accy 55.71
2024-09-08 13:19:18,496 [foster.py] => SNet: Task 7, Epoch 10/130 => Loss 30.610,  Loss1 0.767, Train_accy 58.39
2024-09-08 13:19:25,493 [foster.py] => SNet: Task 7, Epoch 11/130 => Loss 30.592,  Loss1 0.767, Train_accy 60.37, Test_accy 64.36
2024-09-08 13:19:31,297 [foster.py] => SNet: Task 7, Epoch 12/130 => Loss 30.588,  Loss1 0.767, Train_accy 61.80
2024-09-08 13:19:37,078 [foster.py] => SNet: Task 7, Epoch 13/130 => Loss 30.622,  Loss1 0.767, Train_accy 60.49
2024-09-08 13:19:42,840 [foster.py] => SNet: Task 7, Epoch 14/130 => Loss 30.633,  Loss1 0.767, Train_accy 60.93
2024-09-08 13:19:48,624 [foster.py] => SNet: Task 7, Epoch 15/130 => Loss 30.647,  Loss1 0.767, Train_accy 59.71
2024-09-08 13:19:55,610 [foster.py] => SNet: Task 7, Epoch 16/130 => Loss 30.619,  Loss1 0.767, Train_accy 59.76, Test_accy 63.56
2024-09-08 13:20:01,454 [foster.py] => SNet: Task 7, Epoch 17/130 => Loss 30.644,  Loss1 0.767, Train_accy 62.12
2024-09-08 13:20:07,251 [foster.py] => SNet: Task 7, Epoch 18/130 => Loss 30.660,  Loss1 0.766, Train_accy 60.63
2024-09-08 13:20:13,004 [foster.py] => SNet: Task 7, Epoch 19/130 => Loss 30.578,  Loss1 0.767, Train_accy 62.17
2024-09-08 13:20:18,801 [foster.py] => SNet: Task 7, Epoch 20/130 => Loss 30.582,  Loss1 0.767, Train_accy 60.39
2024-09-08 13:20:25,790 [foster.py] => SNet: Task 7, Epoch 21/130 => Loss 30.605,  Loss1 0.767, Train_accy 60.93, Test_accy 63.40
2024-09-08 13:20:31,535 [foster.py] => SNet: Task 7, Epoch 22/130 => Loss 30.647,  Loss1 0.767, Train_accy 60.63
2024-09-08 13:20:37,300 [foster.py] => SNet: Task 7, Epoch 23/130 => Loss 30.632,  Loss1 0.767, Train_accy 63.32
2024-09-08 13:20:43,082 [foster.py] => SNet: Task 7, Epoch 24/130 => Loss 30.597,  Loss1 0.767, Train_accy 64.44
2024-09-08 13:20:48,835 [foster.py] => SNet: Task 7, Epoch 25/130 => Loss 30.566,  Loss1 0.768, Train_accy 63.24
2024-09-08 13:20:55,830 [foster.py] => SNet: Task 7, Epoch 26/130 => Loss 30.585,  Loss1 0.767, Train_accy 62.95, Test_accy 65.26
2024-09-08 13:21:01,627 [foster.py] => SNet: Task 7, Epoch 27/130 => Loss 30.602,  Loss1 0.767, Train_accy 62.41
2024-09-08 13:21:07,413 [foster.py] => SNet: Task 7, Epoch 28/130 => Loss 30.580,  Loss1 0.767, Train_accy 64.37
2024-09-08 13:21:13,140 [foster.py] => SNet: Task 7, Epoch 29/130 => Loss 30.604,  Loss1 0.766, Train_accy 64.15
2024-09-08 13:21:18,989 [foster.py] => SNet: Task 7, Epoch 30/130 => Loss 30.585,  Loss1 0.767, Train_accy 63.83
2024-09-08 13:21:26,009 [foster.py] => SNet: Task 7, Epoch 31/130 => Loss 30.614,  Loss1 0.767, Train_accy 65.85, Test_accy 66.01
2024-09-08 13:21:31,751 [foster.py] => SNet: Task 7, Epoch 32/130 => Loss 30.605,  Loss1 0.767, Train_accy 64.00
2024-09-08 13:21:37,542 [foster.py] => SNet: Task 7, Epoch 33/130 => Loss 30.603,  Loss1 0.766, Train_accy 64.61
2024-09-08 13:21:43,311 [foster.py] => SNet: Task 7, Epoch 34/130 => Loss 30.624,  Loss1 0.767, Train_accy 62.51
2024-09-08 13:21:49,052 [foster.py] => SNet: Task 7, Epoch 35/130 => Loss 30.623,  Loss1 0.767, Train_accy 64.17
2024-09-08 13:21:55,989 [foster.py] => SNet: Task 7, Epoch 36/130 => Loss 30.581,  Loss1 0.767, Train_accy 63.66, Test_accy 65.58
2024-09-08 13:22:01,704 [foster.py] => SNet: Task 7, Epoch 37/130 => Loss 30.589,  Loss1 0.766, Train_accy 64.49
2024-09-08 13:22:07,418 [foster.py] => SNet: Task 7, Epoch 38/130 => Loss 30.585,  Loss1 0.767, Train_accy 64.07
2024-09-08 13:22:13,271 [foster.py] => SNet: Task 7, Epoch 39/130 => Loss 30.591,  Loss1 0.767, Train_accy 65.39
2024-09-08 13:22:19,064 [foster.py] => SNet: Task 7, Epoch 40/130 => Loss 30.583,  Loss1 0.767, Train_accy 65.71
2024-09-08 13:22:26,107 [foster.py] => SNet: Task 7, Epoch 41/130 => Loss 30.580,  Loss1 0.767, Train_accy 63.98, Test_accy 65.04
2024-09-08 13:22:31,940 [foster.py] => SNet: Task 7, Epoch 42/130 => Loss 30.625,  Loss1 0.767, Train_accy 63.44
2024-09-08 13:22:37,686 [foster.py] => SNet: Task 7, Epoch 43/130 => Loss 30.566,  Loss1 0.767, Train_accy 65.56
2024-09-08 13:22:43,465 [foster.py] => SNet: Task 7, Epoch 44/130 => Loss 30.592,  Loss1 0.767, Train_accy 64.78
2024-09-08 13:22:49,205 [foster.py] => SNet: Task 7, Epoch 45/130 => Loss 30.584,  Loss1 0.767, Train_accy 63.95
2024-09-08 13:22:56,218 [foster.py] => SNet: Task 7, Epoch 46/130 => Loss 30.588,  Loss1 0.767, Train_accy 65.49, Test_accy 64.68
2024-09-08 13:23:01,990 [foster.py] => SNet: Task 7, Epoch 47/130 => Loss 30.548,  Loss1 0.767, Train_accy 66.15
2024-09-08 13:23:07,767 [foster.py] => SNet: Task 7, Epoch 48/130 => Loss 30.600,  Loss1 0.767, Train_accy 65.78
2024-09-08 13:23:13,511 [foster.py] => SNet: Task 7, Epoch 49/130 => Loss 30.572,  Loss1 0.768, Train_accy 64.95
2024-09-08 13:23:19,270 [foster.py] => SNet: Task 7, Epoch 50/130 => Loss 30.599,  Loss1 0.767, Train_accy 67.22
2024-09-08 13:23:26,286 [foster.py] => SNet: Task 7, Epoch 51/130 => Loss 30.585,  Loss1 0.767, Train_accy 64.22, Test_accy 64.91
2024-09-08 13:23:32,075 [foster.py] => SNet: Task 7, Epoch 52/130 => Loss 30.548,  Loss1 0.767, Train_accy 66.12
2024-09-08 13:23:37,843 [foster.py] => SNet: Task 7, Epoch 53/130 => Loss 30.568,  Loss1 0.767, Train_accy 65.59
2024-09-08 13:23:43,696 [foster.py] => SNet: Task 7, Epoch 54/130 => Loss 30.557,  Loss1 0.767, Train_accy 65.61
2024-09-08 13:23:49,450 [foster.py] => SNet: Task 7, Epoch 55/130 => Loss 30.597,  Loss1 0.767, Train_accy 66.34
2024-09-08 13:23:56,411 [foster.py] => SNet: Task 7, Epoch 56/130 => Loss 30.540,  Loss1 0.767, Train_accy 65.78, Test_accy 65.71
2024-09-08 13:24:02,166 [foster.py] => SNet: Task 7, Epoch 57/130 => Loss 30.596,  Loss1 0.767, Train_accy 65.73
2024-09-08 13:24:07,889 [foster.py] => SNet: Task 7, Epoch 58/130 => Loss 30.567,  Loss1 0.767, Train_accy 64.83
2024-09-08 13:24:13,645 [foster.py] => SNet: Task 7, Epoch 59/130 => Loss 30.581,  Loss1 0.766, Train_accy 66.10
2024-09-08 13:24:19,437 [foster.py] => SNet: Task 7, Epoch 60/130 => Loss 30.549,  Loss1 0.767, Train_accy 66.78
2024-09-08 13:24:26,451 [foster.py] => SNet: Task 7, Epoch 61/130 => Loss 30.567,  Loss1 0.767, Train_accy 64.98, Test_accy 65.60
2024-09-08 13:24:32,239 [foster.py] => SNet: Task 7, Epoch 62/130 => Loss 30.605,  Loss1 0.768, Train_accy 66.05
2024-09-08 13:24:37,998 [foster.py] => SNet: Task 7, Epoch 63/130 => Loss 30.576,  Loss1 0.767, Train_accy 67.22
2024-09-08 13:24:43,750 [foster.py] => SNet: Task 7, Epoch 64/130 => Loss 30.587,  Loss1 0.767, Train_accy 65.39
2024-09-08 13:24:49,526 [foster.py] => SNet: Task 7, Epoch 65/130 => Loss 30.550,  Loss1 0.767, Train_accy 66.07
2024-09-08 13:24:56,490 [foster.py] => SNet: Task 7, Epoch 66/130 => Loss 30.570,  Loss1 0.767, Train_accy 66.27, Test_accy 65.75
2024-09-08 13:25:02,333 [foster.py] => SNet: Task 7, Epoch 67/130 => Loss 30.549,  Loss1 0.767, Train_accy 66.44
2024-09-08 13:25:08,060 [foster.py] => SNet: Task 7, Epoch 68/130 => Loss 30.597,  Loss1 0.767, Train_accy 65.56
2024-09-08 13:25:13,787 [foster.py] => SNet: Task 7, Epoch 69/130 => Loss 30.597,  Loss1 0.767, Train_accy 67.61
2024-09-08 13:25:19,565 [foster.py] => SNet: Task 7, Epoch 70/130 => Loss 30.566,  Loss1 0.767, Train_accy 67.51
2024-09-08 13:25:26,563 [foster.py] => SNet: Task 7, Epoch 71/130 => Loss 30.590,  Loss1 0.766, Train_accy 67.02, Test_accy 66.09
2024-09-08 13:25:32,347 [foster.py] => SNet: Task 7, Epoch 72/130 => Loss 30.567,  Loss1 0.767, Train_accy 66.54
2024-09-08 13:25:38,102 [foster.py] => SNet: Task 7, Epoch 73/130 => Loss 30.538,  Loss1 0.767, Train_accy 65.02
2024-09-08 13:25:43,850 [foster.py] => SNet: Task 7, Epoch 74/130 => Loss 30.547,  Loss1 0.767, Train_accy 68.20
2024-09-08 13:25:49,605 [foster.py] => SNet: Task 7, Epoch 75/130 => Loss 30.535,  Loss1 0.766, Train_accy 67.12
2024-09-08 13:25:56,593 [foster.py] => SNet: Task 7, Epoch 76/130 => Loss 30.599,  Loss1 0.766, Train_accy 65.95, Test_accy 66.09
2024-09-08 13:26:02,349 [foster.py] => SNet: Task 7, Epoch 77/130 => Loss 30.544,  Loss1 0.767, Train_accy 67.32
2024-09-08 13:26:08,108 [foster.py] => SNet: Task 7, Epoch 78/130 => Loss 30.549,  Loss1 0.766, Train_accy 66.80
2024-09-08 13:26:13,917 [foster.py] => SNet: Task 7, Epoch 79/130 => Loss 30.567,  Loss1 0.767, Train_accy 65.73
2024-09-08 13:26:19,668 [foster.py] => SNet: Task 7, Epoch 80/130 => Loss 30.541,  Loss1 0.767, Train_accy 67.07
2024-09-08 13:26:26,649 [foster.py] => SNet: Task 7, Epoch 81/130 => Loss 30.572,  Loss1 0.767, Train_accy 66.98, Test_accy 66.20
2024-09-08 13:26:32,416 [foster.py] => SNet: Task 7, Epoch 82/130 => Loss 30.581,  Loss1 0.767, Train_accy 66.27
2024-09-08 13:26:38,172 [foster.py] => SNet: Task 7, Epoch 83/130 => Loss 30.565,  Loss1 0.767, Train_accy 67.63
2024-09-08 13:26:43,935 [foster.py] => SNet: Task 7, Epoch 84/130 => Loss 30.540,  Loss1 0.767, Train_accy 67.80
2024-09-08 13:26:49,735 [foster.py] => SNet: Task 7, Epoch 85/130 => Loss 30.551,  Loss1 0.767, Train_accy 68.20
2024-09-08 13:26:56,738 [foster.py] => SNet: Task 7, Epoch 86/130 => Loss 30.560,  Loss1 0.767, Train_accy 68.61, Test_accy 66.34
2024-09-08 13:27:02,505 [foster.py] => SNet: Task 7, Epoch 87/130 => Loss 30.541,  Loss1 0.767, Train_accy 67.20
2024-09-08 13:27:08,258 [foster.py] => SNet: Task 7, Epoch 88/130 => Loss 30.539,  Loss1 0.767, Train_accy 66.46
2024-09-08 13:27:14,019 [foster.py] => SNet: Task 7, Epoch 89/130 => Loss 30.564,  Loss1 0.766, Train_accy 69.29
2024-09-08 13:27:19,761 [foster.py] => SNet: Task 7, Epoch 90/130 => Loss 30.573,  Loss1 0.767, Train_accy 68.02
2024-09-08 13:27:26,768 [foster.py] => SNet: Task 7, Epoch 91/130 => Loss 30.545,  Loss1 0.767, Train_accy 66.46, Test_accy 66.62
2024-09-08 13:27:32,602 [foster.py] => SNet: Task 7, Epoch 92/130 => Loss 30.558,  Loss1 0.767, Train_accy 67.41
2024-09-08 13:27:38,359 [foster.py] => SNet: Task 7, Epoch 93/130 => Loss 30.520,  Loss1 0.767, Train_accy 67.68
2024-09-08 13:27:44,110 [foster.py] => SNet: Task 7, Epoch 94/130 => Loss 30.550,  Loss1 0.767, Train_accy 66.54
2024-09-08 13:27:49,826 [foster.py] => SNet: Task 7, Epoch 95/130 => Loss 30.543,  Loss1 0.767, Train_accy 67.56
2024-09-08 13:27:56,831 [foster.py] => SNet: Task 7, Epoch 96/130 => Loss 30.537,  Loss1 0.767, Train_accy 68.15, Test_accy 66.19
2024-09-08 13:28:02,636 [foster.py] => SNet: Task 7, Epoch 97/130 => Loss 30.540,  Loss1 0.767, Train_accy 66.93
2024-09-08 13:28:08,374 [foster.py] => SNet: Task 7, Epoch 98/130 => Loss 30.519,  Loss1 0.767, Train_accy 68.17
2024-09-08 13:28:14,134 [foster.py] => SNet: Task 7, Epoch 99/130 => Loss 30.558,  Loss1 0.767, Train_accy 68.66
2024-09-08 13:28:19,901 [foster.py] => SNet: Task 7, Epoch 100/130 => Loss 30.540,  Loss1 0.767, Train_accy 68.20
2024-09-08 13:28:26,947 [foster.py] => SNet: Task 7, Epoch 101/130 => Loss 30.563,  Loss1 0.767, Train_accy 67.12, Test_accy 66.19
2024-09-08 13:28:32,710 [foster.py] => SNet: Task 7, Epoch 102/130 => Loss 30.529,  Loss1 0.767, Train_accy 68.56
2024-09-08 13:28:38,462 [foster.py] => SNet: Task 7, Epoch 103/130 => Loss 30.535,  Loss1 0.767, Train_accy 67.93
2024-09-08 13:28:44,249 [foster.py] => SNet: Task 7, Epoch 104/130 => Loss 30.610,  Loss1 0.767, Train_accy 66.41
2024-09-08 13:28:49,927 [foster.py] => SNet: Task 7, Epoch 105/130 => Loss 30.528,  Loss1 0.767, Train_accy 67.05
2024-09-08 13:28:56,871 [foster.py] => SNet: Task 7, Epoch 106/130 => Loss 30.508,  Loss1 0.767, Train_accy 67.95, Test_accy 66.29
2024-09-08 13:29:02,614 [foster.py] => SNet: Task 7, Epoch 107/130 => Loss 30.582,  Loss1 0.767, Train_accy 67.12
2024-09-08 13:29:08,387 [foster.py] => SNet: Task 7, Epoch 108/130 => Loss 30.529,  Loss1 0.767, Train_accy 67.46
2024-09-08 13:29:14,167 [foster.py] => SNet: Task 7, Epoch 109/130 => Loss 30.570,  Loss1 0.767, Train_accy 66.80
2024-09-08 13:29:19,945 [foster.py] => SNet: Task 7, Epoch 110/130 => Loss 30.526,  Loss1 0.767, Train_accy 67.39
2024-09-08 13:29:26,941 [foster.py] => SNet: Task 7, Epoch 111/130 => Loss 30.556,  Loss1 0.767, Train_accy 67.85, Test_accy 66.91
2024-09-08 13:29:32,720 [foster.py] => SNet: Task 7, Epoch 112/130 => Loss 30.564,  Loss1 0.767, Train_accy 67.46
2024-09-08 13:29:38,488 [foster.py] => SNet: Task 7, Epoch 113/130 => Loss 30.558,  Loss1 0.767, Train_accy 67.49
2024-09-08 13:29:44,285 [foster.py] => SNet: Task 7, Epoch 114/130 => Loss 30.582,  Loss1 0.767, Train_accy 66.71
2024-09-08 13:29:50,047 [foster.py] => SNet: Task 7, Epoch 115/130 => Loss 30.519,  Loss1 0.767, Train_accy 67.44
2024-09-08 13:29:57,154 [foster.py] => SNet: Task 7, Epoch 116/130 => Loss 30.547,  Loss1 0.767, Train_accy 67.12, Test_accy 66.67
2024-09-08 13:30:02,999 [foster.py] => SNet: Task 7, Epoch 117/130 => Loss 30.553,  Loss1 0.767, Train_accy 67.46
2024-09-08 13:30:08,770 [foster.py] => SNet: Task 7, Epoch 118/130 => Loss 30.517,  Loss1 0.767, Train_accy 67.29
2024-09-08 13:30:14,536 [foster.py] => SNet: Task 7, Epoch 119/130 => Loss 30.569,  Loss1 0.767, Train_accy 67.95
2024-09-08 13:30:20,244 [foster.py] => SNet: Task 7, Epoch 120/130 => Loss 30.516,  Loss1 0.767, Train_accy 67.61
2024-09-08 13:30:27,196 [foster.py] => SNet: Task 7, Epoch 121/130 => Loss 30.547,  Loss1 0.767, Train_accy 67.34, Test_accy 66.51
2024-09-08 13:30:32,993 [foster.py] => SNet: Task 7, Epoch 122/130 => Loss 30.540,  Loss1 0.767, Train_accy 67.34
2024-09-08 13:30:38,744 [foster.py] => SNet: Task 7, Epoch 123/130 => Loss 30.529,  Loss1 0.767, Train_accy 66.83
2024-09-08 13:30:44,520 [foster.py] => SNet: Task 7, Epoch 124/130 => Loss 30.525,  Loss1 0.767, Train_accy 67.61
2024-09-08 13:30:50,294 [foster.py] => SNet: Task 7, Epoch 125/130 => Loss 30.529,  Loss1 0.767, Train_accy 68.15
2024-09-08 13:30:57,350 [foster.py] => SNet: Task 7, Epoch 126/130 => Loss 30.505,  Loss1 0.767, Train_accy 66.76, Test_accy 66.33
2024-09-08 13:31:03,123 [foster.py] => SNet: Task 7, Epoch 127/130 => Loss 30.537,  Loss1 0.767, Train_accy 67.10
2024-09-08 13:31:08,899 [foster.py] => SNet: Task 7, Epoch 128/130 => Loss 30.564,  Loss1 0.767, Train_accy 68.17
2024-09-08 13:31:14,713 [foster.py] => SNet: Task 7, Epoch 129/130 => Loss 30.528,  Loss1 0.767, Train_accy 68.41
2024-09-08 13:31:20,472 [foster.py] => SNet: Task 7, Epoch 130/130 => Loss 30.569,  Loss1 0.767, Train_accy 68.59
2024-09-08 13:31:20,473 [foster.py] => do not weight align student!
2024-09-08 13:31:21,694 [foster.py] => darknet eval: 
2024-09-08 13:31:21,694 [foster.py] => CNN top1 curve: 66.75
2024-09-08 13:31:21,694 [foster.py] => CNN top5 curve: 90.93
2024-09-08 13:31:21,694 [foster.py] => CNN top1 平均值: 66.75
2024-09-08 13:31:21,697 [foster.py] => timees : 1751.4687058925629
2024-09-08 13:31:21,698 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 13:31:49,067 [foster.py] => Exemplar size: 1700
2024-09-08 13:31:49,068 [trainer.py] => CNN: {'total': 68.0, '00-09': 75.6, '10-19': 60.0, '20-29': 73.4, '30-39': 66.0, '40-49': 71.7, '50-59': 54.2, '60-69': 69.6, '70-79': 68.7, '80-89': 77.6, 'old': 67.4, 'new': 77.6}
2024-09-08 13:31:49,068 [trainer.py] => NME: {'total': 62.79, '00-09': 66.7, '10-19': 52.9, '20-29': 65.1, '30-39': 60.0, '40-49': 64.8, '50-59': 55.2, '60-69': 64.6, '70-79': 62.2, '80-89': 84.4, 'old': 61.44, 'new': 84.4}
2024-09-08 13:31:49,068 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67, 69.88, 68.0]
2024-09-08 13:31:49,068 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05, 92.24, 91.41]
2024-09-08 13:31:49,068 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83, 64.05, 62.79]
2024-09-08 13:31:49,068 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79, 89.66, 89.24]

2024-09-08 13:31:49,068 [trainer.py] => CNN top1 平均值: 75.18
2024-09-08 13:31:49,070 [trainer.py] => All params: 1176238
2024-09-08 13:31:49,073 [trainer.py] => Trainable params: 593764
2024-09-08 13:31:49,134 [foster.py] => Learning on 85-90
2024-09-08 13:31:49,137 [foster.py] => All params: 1177533
2024-09-08 13:31:49,139 [foster.py] => Trainable params: 594734
2024-09-08 13:31:49,193 [foster.py] => per cls weights : [1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158 1.02217158
 1.02217158 0.62308309 0.62308309 0.62308309 0.62308309 0.62308309]
2024-09-08 13:31:53,520 [foster.py] => Task 8, Epoch 1/170 => Loss 6.402, Loss_clf 1.512, Loss_fe 1.819, Loss_kd 2.898, Train_accy 52.21
2024-09-08 13:31:59,783 [foster.py] => Task 8, Epoch 2/170 => Loss 5.141, Loss_clf 1.045, Loss_fe 1.032, Loss_kd 2.892, Train_accy 61.29, Test_accy 64.37
2024-09-08 13:32:05,994 [foster.py] => Task 8, Epoch 3/170 => Loss 4.949, Loss_clf 0.964, Loss_fe 0.924, Loss_kd 2.888, Train_accy 64.45, Test_accy 64.18
2024-09-08 13:32:12,222 [foster.py] => Task 8, Epoch 4/170 => Loss 4.846, Loss_clf 0.936, Loss_fe 0.872, Loss_kd 2.867, Train_accy 65.60, Test_accy 64.76
2024-09-08 13:32:18,388 [foster.py] => Task 8, Epoch 5/170 => Loss 4.765, Loss_clf 0.883, Loss_fe 0.835, Loss_kd 2.876, Train_accy 67.10, Test_accy 64.93
2024-09-08 13:32:22,478 [foster.py] => Task 8, Epoch 6/170 => Loss 4.792, Loss_clf 0.906, Loss_fe 0.829, Loss_kd 2.885, Train_accy 65.33
2024-09-08 13:32:28,646 [foster.py] => Task 8, Epoch 7/170 => Loss 4.737, Loss_clf 0.886, Loss_fe 0.797, Loss_kd 2.883, Train_accy 65.98, Test_accy 65.11
2024-09-08 13:32:34,775 [foster.py] => Task 8, Epoch 8/170 => Loss 4.597, Loss_clf 0.812, Loss_fe 0.742, Loss_kd 2.873, Train_accy 68.71, Test_accy 64.94
2024-09-08 13:32:40,999 [foster.py] => Task 8, Epoch 9/170 => Loss 4.656, Loss_clf 0.845, Loss_fe 0.756, Loss_kd 2.884, Train_accy 67.05, Test_accy 65.24
2024-09-08 13:32:47,339 [foster.py] => Task 8, Epoch 10/170 => Loss 4.651, Loss_clf 0.844, Loss_fe 0.743, Loss_kd 2.892, Train_accy 68.26, Test_accy 65.49
2024-09-08 13:32:51,544 [foster.py] => Task 8, Epoch 11/170 => Loss 4.588, Loss_clf 0.809, Loss_fe 0.726, Loss_kd 2.882, Train_accy 69.02
2024-09-08 13:32:57,691 [foster.py] => Task 8, Epoch 12/170 => Loss 4.671, Loss_clf 0.862, Loss_fe 0.745, Loss_kd 2.891, Train_accy 69.14, Test_accy 65.53
2024-09-08 13:33:03,941 [foster.py] => Task 8, Epoch 13/170 => Loss 4.619, Loss_clf 0.851, Loss_fe 0.710, Loss_kd 2.887, Train_accy 68.79, Test_accy 64.10
2024-09-08 13:33:10,127 [foster.py] => Task 8, Epoch 14/170 => Loss 4.551, Loss_clf 0.814, Loss_fe 0.698, Loss_kd 2.869, Train_accy 70.29, Test_accy 65.20
2024-09-08 13:33:16,371 [foster.py] => Task 8, Epoch 15/170 => Loss 4.521, Loss_clf 0.795, Loss_fe 0.684, Loss_kd 2.872, Train_accy 69.21, Test_accy 65.70
2024-09-08 13:33:20,492 [foster.py] => Task 8, Epoch 16/170 => Loss 4.470, Loss_clf 0.754, Loss_fe 0.678, Loss_kd 2.867, Train_accy 71.71
2024-09-08 13:33:26,672 [foster.py] => Task 8, Epoch 17/170 => Loss 4.499, Loss_clf 0.787, Loss_fe 0.655, Loss_kd 2.885, Train_accy 70.24, Test_accy 65.77
2024-09-08 13:33:32,888 [foster.py] => Task 8, Epoch 18/170 => Loss 4.508, Loss_clf 0.774, Loss_fe 0.686, Loss_kd 2.877, Train_accy 71.62, Test_accy 64.93
2024-09-08 13:33:39,061 [foster.py] => Task 8, Epoch 19/170 => Loss 4.449, Loss_clf 0.738, Loss_fe 0.654, Loss_kd 2.886, Train_accy 71.38, Test_accy 65.43
2024-09-08 13:33:45,223 [foster.py] => Task 8, Epoch 20/170 => Loss 4.433, Loss_clf 0.722, Loss_fe 0.662, Loss_kd 2.878, Train_accy 72.69, Test_accy 65.28
2024-09-08 13:33:49,316 [foster.py] => Task 8, Epoch 21/170 => Loss 4.385, Loss_clf 0.721, Loss_fe 0.628, Loss_kd 2.865, Train_accy 72.02
2024-09-08 13:33:55,585 [foster.py] => Task 8, Epoch 22/170 => Loss 4.390, Loss_clf 0.714, Loss_fe 0.624, Loss_kd 2.881, Train_accy 72.12, Test_accy 65.11
2024-09-08 13:34:01,812 [foster.py] => Task 8, Epoch 23/170 => Loss 4.446, Loss_clf 0.762, Loss_fe 0.625, Loss_kd 2.887, Train_accy 71.79, Test_accy 65.16
2024-09-08 13:34:07,955 [foster.py] => Task 8, Epoch 24/170 => Loss 4.447, Loss_clf 0.759, Loss_fe 0.639, Loss_kd 2.878, Train_accy 71.38, Test_accy 64.68
2024-09-08 13:34:14,152 [foster.py] => Task 8, Epoch 25/170 => Loss 4.399, Loss_clf 0.731, Loss_fe 0.634, Loss_kd 2.863, Train_accy 72.55, Test_accy 65.82
2024-09-08 13:34:18,318 [foster.py] => Task 8, Epoch 26/170 => Loss 4.353, Loss_clf 0.709, Loss_fe 0.607, Loss_kd 2.866, Train_accy 73.98
2024-09-08 13:34:24,450 [foster.py] => Task 8, Epoch 27/170 => Loss 4.370, Loss_clf 0.717, Loss_fe 0.613, Loss_kd 2.869, Train_accy 73.29, Test_accy 65.31
2024-09-08 13:34:30,601 [foster.py] => Task 8, Epoch 28/170 => Loss 4.367, Loss_clf 0.728, Loss_fe 0.605, Loss_kd 2.864, Train_accy 72.36, Test_accy 64.62
2024-09-08 13:34:36,778 [foster.py] => Task 8, Epoch 29/170 => Loss 4.356, Loss_clf 0.711, Loss_fe 0.595, Loss_kd 2.878, Train_accy 73.02, Test_accy 64.66
2024-09-08 13:34:42,950 [foster.py] => Task 8, Epoch 30/170 => Loss 4.356, Loss_clf 0.708, Loss_fe 0.599, Loss_kd 2.877, Train_accy 73.21, Test_accy 65.24
2024-09-08 13:34:47,152 [foster.py] => Task 8, Epoch 31/170 => Loss 4.347, Loss_clf 0.700, Loss_fe 0.585, Loss_kd 2.890, Train_accy 73.36
2024-09-08 13:34:53,360 [foster.py] => Task 8, Epoch 32/170 => Loss 4.380, Loss_clf 0.734, Loss_fe 0.590, Loss_kd 2.884, Train_accy 72.52, Test_accy 65.23
2024-09-08 13:34:59,583 [foster.py] => Task 8, Epoch 33/170 => Loss 4.354, Loss_clf 0.724, Loss_fe 0.583, Loss_kd 2.876, Train_accy 73.36, Test_accy 65.59
2024-09-08 13:35:05,726 [foster.py] => Task 8, Epoch 34/170 => Loss 4.246, Loss_clf 0.664, Loss_fe 0.543, Loss_kd 2.868, Train_accy 74.69, Test_accy 63.79
2024-09-08 13:35:11,990 [foster.py] => Task 8, Epoch 35/170 => Loss 4.269, Loss_clf 0.671, Loss_fe 0.543, Loss_kd 2.883, Train_accy 75.07, Test_accy 65.39
2024-09-08 13:35:16,080 [foster.py] => Task 8, Epoch 36/170 => Loss 4.316, Loss_clf 0.695, Loss_fe 0.582, Loss_kd 2.869, Train_accy 74.69
2024-09-08 13:35:22,255 [foster.py] => Task 8, Epoch 37/170 => Loss 4.319, Loss_clf 0.718, Loss_fe 0.555, Loss_kd 2.875, Train_accy 74.02, Test_accy 65.54
2024-09-08 13:35:28,486 [foster.py] => Task 8, Epoch 38/170 => Loss 4.236, Loss_clf 0.657, Loss_fe 0.536, Loss_kd 2.872, Train_accy 74.26, Test_accy 65.96
2024-09-08 13:35:34,622 [foster.py] => Task 8, Epoch 39/170 => Loss 4.210, Loss_clf 0.646, Loss_fe 0.524, Loss_kd 2.870, Train_accy 76.33, Test_accy 65.48
2024-09-08 13:35:40,865 [foster.py] => Task 8, Epoch 40/170 => Loss 4.314, Loss_clf 0.698, Loss_fe 0.553, Loss_kd 2.892, Train_accy 74.21, Test_accy 65.26
2024-09-08 13:35:45,001 [foster.py] => Task 8, Epoch 41/170 => Loss 4.250, Loss_clf 0.678, Loss_fe 0.541, Loss_kd 2.861, Train_accy 75.40
2024-09-08 13:35:51,164 [foster.py] => Task 8, Epoch 42/170 => Loss 4.221, Loss_clf 0.662, Loss_fe 0.515, Loss_kd 2.872, Train_accy 74.21, Test_accy 65.37
2024-09-08 13:35:57,377 [foster.py] => Task 8, Epoch 43/170 => Loss 4.230, Loss_clf 0.642, Loss_fe 0.541, Loss_kd 2.876, Train_accy 75.31, Test_accy 65.70
2024-09-08 13:36:03,626 [foster.py] => Task 8, Epoch 44/170 => Loss 4.206, Loss_clf 0.666, Loss_fe 0.502, Loss_kd 2.868, Train_accy 76.21, Test_accy 65.20
2024-09-08 13:36:09,954 [foster.py] => Task 8, Epoch 45/170 => Loss 4.260, Loss_clf 0.688, Loss_fe 0.526, Loss_kd 2.876, Train_accy 74.21, Test_accy 64.09
2024-09-08 13:36:14,074 [foster.py] => Task 8, Epoch 46/170 => Loss 4.284, Loss_clf 0.713, Loss_fe 0.518, Loss_kd 2.881, Train_accy 74.90
2024-09-08 13:36:20,231 [foster.py] => Task 8, Epoch 47/170 => Loss 4.306, Loss_clf 0.699, Loss_fe 0.564, Loss_kd 2.872, Train_accy 74.00, Test_accy 65.74
2024-09-08 13:36:26,441 [foster.py] => Task 8, Epoch 48/170 => Loss 4.180, Loss_clf 0.639, Loss_fe 0.502, Loss_kd 2.868, Train_accy 76.79, Test_accy 65.70
2024-09-08 13:36:32,605 [foster.py] => Task 8, Epoch 49/170 => Loss 4.227, Loss_clf 0.664, Loss_fe 0.515, Loss_kd 2.877, Train_accy 75.74, Test_accy 66.08
2024-09-08 13:36:38,718 [foster.py] => Task 8, Epoch 50/170 => Loss 4.091, Loss_clf 0.608, Loss_fe 0.457, Loss_kd 2.856, Train_accy 76.79, Test_accy 66.04
2024-09-08 13:36:42,929 [foster.py] => Task 8, Epoch 51/170 => Loss 4.139, Loss_clf 0.614, Loss_fe 0.479, Loss_kd 2.874, Train_accy 76.33
2024-09-08 13:36:48,993 [foster.py] => Task 8, Epoch 52/170 => Loss 4.164, Loss_clf 0.626, Loss_fe 0.500, Loss_kd 2.868, Train_accy 76.05, Test_accy 65.54
2024-09-08 13:36:55,055 [foster.py] => Task 8, Epoch 53/170 => Loss 4.127, Loss_clf 0.616, Loss_fe 0.462, Loss_kd 2.878, Train_accy 76.31, Test_accy 65.01
2024-09-08 13:37:01,413 [foster.py] => Task 8, Epoch 54/170 => Loss 4.168, Loss_clf 0.633, Loss_fe 0.501, Loss_kd 2.865, Train_accy 75.69, Test_accy 64.67
2024-09-08 13:37:07,601 [foster.py] => Task 8, Epoch 55/170 => Loss 4.163, Loss_clf 0.632, Loss_fe 0.476, Loss_kd 2.884, Train_accy 76.12, Test_accy 65.73
2024-09-08 13:37:11,700 [foster.py] => Task 8, Epoch 56/170 => Loss 4.069, Loss_clf 0.575, Loss_fe 0.469, Loss_kd 2.855, Train_accy 77.29
2024-09-08 13:37:17,873 [foster.py] => Task 8, Epoch 57/170 => Loss 4.148, Loss_clf 0.624, Loss_fe 0.484, Loss_kd 2.870, Train_accy 76.00, Test_accy 66.00
2024-09-08 13:37:24,144 [foster.py] => Task 8, Epoch 58/170 => Loss 4.047, Loss_clf 0.568, Loss_fe 0.444, Loss_kd 2.864, Train_accy 78.21, Test_accy 65.81
2024-09-08 13:37:30,418 [foster.py] => Task 8, Epoch 59/170 => Loss 4.117, Loss_clf 0.599, Loss_fe 0.474, Loss_kd 2.873, Train_accy 77.31, Test_accy 65.81
2024-09-08 13:37:36,572 [foster.py] => Task 8, Epoch 60/170 => Loss 4.104, Loss_clf 0.599, Loss_fe 0.451, Loss_kd 2.884, Train_accy 76.57, Test_accy 65.99
2024-09-08 13:37:40,740 [foster.py] => Task 8, Epoch 61/170 => Loss 4.059, Loss_clf 0.576, Loss_fe 0.453, Loss_kd 2.860, Train_accy 78.17
2024-09-08 13:37:46,909 [foster.py] => Task 8, Epoch 62/170 => Loss 4.024, Loss_clf 0.560, Loss_fe 0.434, Loss_kd 2.859, Train_accy 79.02, Test_accy 65.96
2024-09-08 13:37:53,048 [foster.py] => Task 8, Epoch 63/170 => Loss 4.079, Loss_clf 0.586, Loss_fe 0.456, Loss_kd 2.866, Train_accy 77.31, Test_accy 65.34
2024-09-08 13:37:59,255 [foster.py] => Task 8, Epoch 64/170 => Loss 4.085, Loss_clf 0.603, Loss_fe 0.437, Loss_kd 2.874, Train_accy 77.12, Test_accy 65.98
2024-09-08 13:38:05,497 [foster.py] => Task 8, Epoch 65/170 => Loss 4.067, Loss_clf 0.586, Loss_fe 0.452, Loss_kd 2.858, Train_accy 77.31, Test_accy 65.62
2024-09-08 13:38:09,625 [foster.py] => Task 8, Epoch 66/170 => Loss 4.007, Loss_clf 0.553, Loss_fe 0.405, Loss_kd 2.878, Train_accy 79.86
2024-09-08 13:38:15,785 [foster.py] => Task 8, Epoch 67/170 => Loss 4.097, Loss_clf 0.613, Loss_fe 0.420, Loss_kd 2.892, Train_accy 76.76, Test_accy 65.50
2024-09-08 13:38:21,929 [foster.py] => Task 8, Epoch 68/170 => Loss 4.076, Loss_clf 0.588, Loss_fe 0.432, Loss_kd 2.884, Train_accy 78.55, Test_accy 65.79
2024-09-08 13:38:28,161 [foster.py] => Task 8, Epoch 69/170 => Loss 4.010, Loss_clf 0.557, Loss_fe 0.407, Loss_kd 2.875, Train_accy 79.14, Test_accy 64.86
2024-09-08 13:38:34,317 [foster.py] => Task 8, Epoch 70/170 => Loss 4.044, Loss_clf 0.572, Loss_fe 0.425, Loss_kd 2.876, Train_accy 78.55, Test_accy 65.91
2024-09-08 13:38:38,511 [foster.py] => Task 8, Epoch 71/170 => Loss 4.098, Loss_clf 0.602, Loss_fe 0.440, Loss_kd 2.885, Train_accy 77.60
2024-09-08 13:38:44,642 [foster.py] => Task 8, Epoch 72/170 => Loss 4.029, Loss_clf 0.582, Loss_fe 0.402, Loss_kd 2.874, Train_accy 78.69, Test_accy 65.52
2024-09-08 13:38:50,945 [foster.py] => Task 8, Epoch 73/170 => Loss 4.042, Loss_clf 0.579, Loss_fe 0.414, Loss_kd 2.878, Train_accy 79.00, Test_accy 65.71
2024-09-08 13:38:57,160 [foster.py] => Task 8, Epoch 74/170 => Loss 4.036, Loss_clf 0.583, Loss_fe 0.403, Loss_kd 2.879, Train_accy 78.48, Test_accy 65.50
2024-09-08 13:39:03,333 [foster.py] => Task 8, Epoch 75/170 => Loss 4.020, Loss_clf 0.569, Loss_fe 0.416, Loss_kd 2.864, Train_accy 78.79, Test_accy 66.24
2024-09-08 13:39:07,446 [foster.py] => Task 8, Epoch 76/170 => Loss 4.023, Loss_clf 0.587, Loss_fe 0.386, Loss_kd 2.879, Train_accy 78.10
2024-09-08 13:39:13,656 [foster.py] => Task 8, Epoch 77/170 => Loss 4.051, Loss_clf 0.587, Loss_fe 0.410, Loss_kd 2.883, Train_accy 78.10, Test_accy 66.17
2024-09-08 13:39:19,956 [foster.py] => Task 8, Epoch 78/170 => Loss 4.014, Loss_clf 0.557, Loss_fe 0.401, Loss_kd 2.884, Train_accy 79.88, Test_accy 66.24
2024-09-08 13:39:26,161 [foster.py] => Task 8, Epoch 79/170 => Loss 3.968, Loss_clf 0.549, Loss_fe 0.389, Loss_kd 2.860, Train_accy 78.76, Test_accy 66.27
2024-09-08 13:39:32,380 [foster.py] => Task 8, Epoch 80/170 => Loss 3.973, Loss_clf 0.545, Loss_fe 0.386, Loss_kd 2.871, Train_accy 78.69, Test_accy 65.91
2024-09-08 13:39:36,465 [foster.py] => Task 8, Epoch 81/170 => Loss 3.938, Loss_clf 0.538, Loss_fe 0.371, Loss_kd 2.859, Train_accy 80.05
2024-09-08 13:39:42,628 [foster.py] => Task 8, Epoch 82/170 => Loss 3.943, Loss_clf 0.534, Loss_fe 0.372, Loss_kd 2.867, Train_accy 80.07, Test_accy 65.98
2024-09-08 13:39:48,810 [foster.py] => Task 8, Epoch 83/170 => Loss 3.917, Loss_clf 0.532, Loss_fe 0.352, Loss_kd 2.863, Train_accy 81.26, Test_accy 65.93
2024-09-08 13:39:55,150 [foster.py] => Task 8, Epoch 84/170 => Loss 3.898, Loss_clf 0.517, Loss_fe 0.340, Loss_kd 2.871, Train_accy 80.36, Test_accy 65.82
2024-09-08 13:40:01,407 [foster.py] => Task 8, Epoch 85/170 => Loss 3.946, Loss_clf 0.542, Loss_fe 0.366, Loss_kd 2.868, Train_accy 79.67, Test_accy 65.93
2024-09-08 13:40:05,515 [foster.py] => Task 8, Epoch 86/170 => Loss 3.966, Loss_clf 0.544, Loss_fe 0.375, Loss_kd 2.875, Train_accy 80.76
2024-09-08 13:40:11,650 [foster.py] => Task 8, Epoch 87/170 => Loss 3.921, Loss_clf 0.536, Loss_fe 0.357, Loss_kd 2.858, Train_accy 80.38, Test_accy 66.17
2024-09-08 13:40:17,840 [foster.py] => Task 8, Epoch 88/170 => Loss 3.949, Loss_clf 0.535, Loss_fe 0.362, Loss_kd 2.881, Train_accy 80.40, Test_accy 66.24
2024-09-08 13:40:24,000 [foster.py] => Task 8, Epoch 89/170 => Loss 3.977, Loss_clf 0.554, Loss_fe 0.372, Loss_kd 2.879, Train_accy 79.86, Test_accy 66.29
2024-09-08 13:40:30,254 [foster.py] => Task 8, Epoch 90/170 => Loss 3.911, Loss_clf 0.519, Loss_fe 0.350, Loss_kd 2.871, Train_accy 80.88, Test_accy 66.24
2024-09-08 13:40:34,375 [foster.py] => Task 8, Epoch 91/170 => Loss 3.878, Loss_clf 0.507, Loss_fe 0.327, Loss_kd 2.873, Train_accy 81.31
2024-09-08 13:40:40,559 [foster.py] => Task 8, Epoch 92/170 => Loss 3.964, Loss_clf 0.549, Loss_fe 0.360, Loss_kd 2.884, Train_accy 80.62, Test_accy 65.99
2024-09-08 13:40:46,762 [foster.py] => Task 8, Epoch 93/170 => Loss 3.845, Loss_clf 0.489, Loss_fe 0.320, Loss_kd 2.866, Train_accy 81.81, Test_accy 66.39
2024-09-08 13:40:52,932 [foster.py] => Task 8, Epoch 94/170 => Loss 3.876, Loss_clf 0.502, Loss_fe 0.329, Loss_kd 2.875, Train_accy 81.81, Test_accy 66.06
2024-09-08 13:40:59,120 [foster.py] => Task 8, Epoch 95/170 => Loss 3.856, Loss_clf 0.500, Loss_fe 0.319, Loss_kd 2.867, Train_accy 81.24, Test_accy 66.03
2024-09-08 13:41:03,320 [foster.py] => Task 8, Epoch 96/170 => Loss 3.892, Loss_clf 0.518, Loss_fe 0.325, Loss_kd 2.879, Train_accy 81.50
2024-09-08 13:41:09,508 [foster.py] => Task 8, Epoch 97/170 => Loss 3.875, Loss_clf 0.518, Loss_fe 0.315, Loss_kd 2.872, Train_accy 81.05, Test_accy 66.43
2024-09-08 13:41:15,777 [foster.py] => Task 8, Epoch 98/170 => Loss 3.977, Loss_clf 0.562, Loss_fe 0.356, Loss_kd 2.888, Train_accy 80.60, Test_accy 65.96
2024-09-08 13:41:21,892 [foster.py] => Task 8, Epoch 99/170 => Loss 3.913, Loss_clf 0.521, Loss_fe 0.337, Loss_kd 2.884, Train_accy 81.10, Test_accy 65.88
2024-09-08 13:41:28,076 [foster.py] => Task 8, Epoch 100/170 => Loss 3.888, Loss_clf 0.525, Loss_fe 0.324, Loss_kd 2.869, Train_accy 81.76, Test_accy 65.92
2024-09-08 13:41:32,283 [foster.py] => Task 8, Epoch 101/170 => Loss 3.814, Loss_clf 0.469, Loss_fe 0.303, Loss_kd 2.872, Train_accy 82.64
2024-09-08 13:41:38,426 [foster.py] => Task 8, Epoch 102/170 => Loss 3.820, Loss_clf 0.479, Loss_fe 0.294, Loss_kd 2.876, Train_accy 82.43, Test_accy 66.38
2024-09-08 13:41:44,588 [foster.py] => Task 8, Epoch 103/170 => Loss 3.862, Loss_clf 0.497, Loss_fe 0.306, Loss_kd 2.887, Train_accy 82.38, Test_accy 66.46
2024-09-08 13:41:50,785 [foster.py] => Task 8, Epoch 104/170 => Loss 3.853, Loss_clf 0.506, Loss_fe 0.308, Loss_kd 2.869, Train_accy 81.19, Test_accy 66.60
2024-09-08 13:41:56,963 [foster.py] => Task 8, Epoch 105/170 => Loss 3.843, Loss_clf 0.489, Loss_fe 0.310, Loss_kd 2.874, Train_accy 82.62, Test_accy 66.33
2024-09-08 13:42:01,123 [foster.py] => Task 8, Epoch 106/170 => Loss 3.824, Loss_clf 0.478, Loss_fe 0.300, Loss_kd 2.875, Train_accy 83.71
2024-09-08 13:42:07,359 [foster.py] => Task 8, Epoch 107/170 => Loss 3.798, Loss_clf 0.480, Loss_fe 0.282, Loss_kd 2.865, Train_accy 82.90, Test_accy 66.32
2024-09-08 13:42:13,503 [foster.py] => Task 8, Epoch 108/170 => Loss 3.819, Loss_clf 0.486, Loss_fe 0.294, Loss_kd 2.869, Train_accy 82.33, Test_accy 66.44
2024-09-08 13:42:19,673 [foster.py] => Task 8, Epoch 109/170 => Loss 3.754, Loss_clf 0.459, Loss_fe 0.259, Loss_kd 2.866, Train_accy 83.29, Test_accy 66.41
2024-09-08 13:42:25,859 [foster.py] => Task 8, Epoch 110/170 => Loss 3.788, Loss_clf 0.467, Loss_fe 0.272, Loss_kd 2.878, Train_accy 83.79, Test_accy 66.21
2024-09-08 13:42:30,019 [foster.py] => Task 8, Epoch 111/170 => Loss 3.774, Loss_clf 0.461, Loss_fe 0.267, Loss_kd 2.876, Train_accy 83.62
2024-09-08 13:42:36,389 [foster.py] => Task 8, Epoch 112/170 => Loss 3.752, Loss_clf 0.455, Loss_fe 0.254, Loss_kd 2.872, Train_accy 83.52, Test_accy 66.22
2024-09-08 13:42:42,646 [foster.py] => Task 8, Epoch 113/170 => Loss 3.796, Loss_clf 0.469, Loss_fe 0.276, Loss_kd 2.880, Train_accy 83.21, Test_accy 66.39
2024-09-08 13:42:48,910 [foster.py] => Task 8, Epoch 114/170 => Loss 3.759, Loss_clf 0.458, Loss_fe 0.253, Loss_kd 2.877, Train_accy 83.38, Test_accy 66.36
2024-09-08 13:42:55,052 [foster.py] => Task 8, Epoch 115/170 => Loss 3.761, Loss_clf 0.459, Loss_fe 0.260, Loss_kd 2.872, Train_accy 83.81, Test_accy 66.36
2024-09-08 13:42:59,186 [foster.py] => Task 8, Epoch 116/170 => Loss 3.767, Loss_clf 0.467, Loss_fe 0.258, Loss_kd 2.871, Train_accy 84.10
2024-09-08 13:43:05,359 [foster.py] => Task 8, Epoch 117/170 => Loss 3.754, Loss_clf 0.448, Loss_fe 0.256, Loss_kd 2.878, Train_accy 83.64, Test_accy 66.51
2024-09-08 13:43:11,512 [foster.py] => Task 8, Epoch 118/170 => Loss 3.796, Loss_clf 0.477, Loss_fe 0.263, Loss_kd 2.885, Train_accy 83.29, Test_accy 66.23
2024-09-08 13:43:17,787 [foster.py] => Task 8, Epoch 119/170 => Loss 3.732, Loss_clf 0.444, Loss_fe 0.251, Loss_kd 2.866, Train_accy 84.55, Test_accy 66.37
2024-09-08 13:43:23,926 [foster.py] => Task 8, Epoch 120/170 => Loss 3.770, Loss_clf 0.468, Loss_fe 0.249, Loss_kd 2.882, Train_accy 84.81, Test_accy 66.58
2024-09-08 13:43:28,021 [foster.py] => Task 8, Epoch 121/170 => Loss 3.734, Loss_clf 0.438, Loss_fe 0.251, Loss_kd 2.874, Train_accy 84.48
2024-09-08 13:43:34,102 [foster.py] => Task 8, Epoch 122/170 => Loss 3.748, Loss_clf 0.453, Loss_fe 0.254, Loss_kd 2.871, Train_accy 84.21, Test_accy 66.37
2024-09-08 13:43:40,235 [foster.py] => Task 8, Epoch 123/170 => Loss 3.743, Loss_clf 0.450, Loss_fe 0.236, Loss_kd 2.887, Train_accy 84.64, Test_accy 66.40
2024-09-08 13:43:46,486 [foster.py] => Task 8, Epoch 124/170 => Loss 3.735, Loss_clf 0.454, Loss_fe 0.242, Loss_kd 2.869, Train_accy 85.05, Test_accy 66.30
2024-09-08 13:43:52,821 [foster.py] => Task 8, Epoch 125/170 => Loss 3.725, Loss_clf 0.450, Loss_fe 0.244, Loss_kd 2.862, Train_accy 84.81, Test_accy 66.19
2024-09-08 13:43:56,945 [foster.py] => Task 8, Epoch 126/170 => Loss 3.728, Loss_clf 0.448, Loss_fe 0.245, Loss_kd 2.865, Train_accy 84.76
2024-09-08 13:44:03,152 [foster.py] => Task 8, Epoch 127/170 => Loss 3.792, Loss_clf 0.475, Loss_fe 0.257, Loss_kd 2.888, Train_accy 83.83, Test_accy 66.51
2024-09-08 13:44:09,357 [foster.py] => Task 8, Epoch 128/170 => Loss 3.716, Loss_clf 0.446, Loss_fe 0.233, Loss_kd 2.866, Train_accy 83.79, Test_accy 66.57
2024-09-08 13:44:15,599 [foster.py] => Task 8, Epoch 129/170 => Loss 3.682, Loss_clf 0.430, Loss_fe 0.222, Loss_kd 2.860, Train_accy 84.69, Test_accy 66.42
2024-09-08 13:44:21,796 [foster.py] => Task 8, Epoch 130/170 => Loss 3.693, Loss_clf 0.426, Loss_fe 0.227, Loss_kd 2.869, Train_accy 84.86, Test_accy 66.39
2024-09-08 13:44:25,902 [foster.py] => Task 8, Epoch 131/170 => Loss 3.729, Loss_clf 0.449, Loss_fe 0.230, Loss_kd 2.880, Train_accy 84.21
2024-09-08 13:44:32,040 [foster.py] => Task 8, Epoch 132/170 => Loss 3.762, Loss_clf 0.464, Loss_fe 0.250, Loss_kd 2.878, Train_accy 84.31, Test_accy 66.53
2024-09-08 13:44:38,247 [foster.py] => Task 8, Epoch 133/170 => Loss 3.686, Loss_clf 0.428, Loss_fe 0.222, Loss_kd 2.865, Train_accy 84.79, Test_accy 66.48
2024-09-08 13:44:44,438 [foster.py] => Task 8, Epoch 134/170 => Loss 3.686, Loss_clf 0.435, Loss_fe 0.210, Loss_kd 2.870, Train_accy 84.33, Test_accy 66.63
2024-09-08 13:44:50,597 [foster.py] => Task 8, Epoch 135/170 => Loss 3.706, Loss_clf 0.443, Loss_fe 0.228, Loss_kd 2.864, Train_accy 84.79, Test_accy 66.70
2024-09-08 13:44:54,724 [foster.py] => Task 8, Epoch 136/170 => Loss 3.674, Loss_clf 0.419, Loss_fe 0.219, Loss_kd 2.865, Train_accy 85.74
2024-09-08 13:45:00,936 [foster.py] => Task 8, Epoch 137/170 => Loss 3.672, Loss_clf 0.414, Loss_fe 0.216, Loss_kd 2.872, Train_accy 85.98, Test_accy 66.57
2024-09-08 13:45:07,118 [foster.py] => Task 8, Epoch 138/170 => Loss 3.701, Loss_clf 0.424, Loss_fe 0.225, Loss_kd 2.880, Train_accy 84.81, Test_accy 66.67
2024-09-08 13:45:13,350 [foster.py] => Task 8, Epoch 139/170 => Loss 3.650, Loss_clf 0.412, Loss_fe 0.206, Loss_kd 2.862, Train_accy 86.48, Test_accy 66.74
2024-09-08 13:45:19,533 [foster.py] => Task 8, Epoch 140/170 => Loss 3.676, Loss_clf 0.416, Loss_fe 0.219, Loss_kd 2.870, Train_accy 86.14, Test_accy 66.73
2024-09-08 13:45:23,638 [foster.py] => Task 8, Epoch 141/170 => Loss 3.676, Loss_clf 0.422, Loss_fe 0.199, Loss_kd 2.884, Train_accy 86.50
2024-09-08 13:45:29,946 [foster.py] => Task 8, Epoch 142/170 => Loss 3.674, Loss_clf 0.426, Loss_fe 0.205, Loss_kd 2.873, Train_accy 85.67, Test_accy 66.61
2024-09-08 13:45:36,126 [foster.py] => Task 8, Epoch 143/170 => Loss 3.719, Loss_clf 0.459, Loss_fe 0.211, Loss_kd 2.877, Train_accy 85.38, Test_accy 66.67
2024-09-08 13:45:42,248 [foster.py] => Task 8, Epoch 144/170 => Loss 3.678, Loss_clf 0.428, Loss_fe 0.205, Loss_kd 2.874, Train_accy 85.67, Test_accy 66.64
2024-09-08 13:45:48,412 [foster.py] => Task 8, Epoch 145/170 => Loss 3.647, Loss_clf 0.413, Loss_fe 0.208, Loss_kd 2.856, Train_accy 86.02, Test_accy 66.73
2024-09-08 13:45:52,570 [foster.py] => Task 8, Epoch 146/170 => Loss 3.670, Loss_clf 0.423, Loss_fe 0.211, Loss_kd 2.865, Train_accy 86.02
2024-09-08 13:45:58,749 [foster.py] => Task 8, Epoch 147/170 => Loss 3.694, Loss_clf 0.429, Loss_fe 0.214, Loss_kd 2.881, Train_accy 85.93, Test_accy 66.74
2024-09-08 13:46:04,901 [foster.py] => Task 8, Epoch 148/170 => Loss 3.704, Loss_clf 0.440, Loss_fe 0.208, Loss_kd 2.885, Train_accy 86.14, Test_accy 66.67
2024-09-08 13:46:11,052 [foster.py] => Task 8, Epoch 149/170 => Loss 3.641, Loss_clf 0.398, Loss_fe 0.184, Loss_kd 2.887, Train_accy 85.86, Test_accy 66.72
2024-09-08 13:46:17,303 [foster.py] => Task 8, Epoch 150/170 => Loss 3.706, Loss_clf 0.438, Loss_fe 0.210, Loss_kd 2.887, Train_accy 85.33, Test_accy 66.74
2024-09-08 13:46:21,406 [foster.py] => Task 8, Epoch 151/170 => Loss 3.616, Loss_clf 0.399, Loss_fe 0.186, Loss_kd 2.861, Train_accy 86.12
2024-09-08 13:46:27,660 [foster.py] => Task 8, Epoch 152/170 => Loss 3.620, Loss_clf 0.390, Loss_fe 0.189, Loss_kd 2.870, Train_accy 86.55, Test_accy 66.69
2024-09-08 13:46:33,802 [foster.py] => Task 8, Epoch 153/170 => Loss 3.639, Loss_clf 0.404, Loss_fe 0.195, Loss_kd 2.869, Train_accy 86.50, Test_accy 66.69
2024-09-08 13:46:39,911 [foster.py] => Task 8, Epoch 154/170 => Loss 3.633, Loss_clf 0.401, Loss_fe 0.191, Loss_kd 2.871, Train_accy 86.21, Test_accy 66.70
2024-09-08 13:46:46,095 [foster.py] => Task 8, Epoch 155/170 => Loss 3.683, Loss_clf 0.426, Loss_fe 0.206, Loss_kd 2.879, Train_accy 86.14, Test_accy 66.70
2024-09-08 13:46:50,142 [foster.py] => Task 8, Epoch 156/170 => Loss 3.653, Loss_clf 0.413, Loss_fe 0.200, Loss_kd 2.870, Train_accy 86.10
2024-09-08 13:46:56,506 [foster.py] => Task 8, Epoch 157/170 => Loss 3.663, Loss_clf 0.425, Loss_fe 0.197, Loss_kd 2.870, Train_accy 86.31, Test_accy 66.73
2024-09-08 13:47:02,798 [foster.py] => Task 8, Epoch 158/170 => Loss 3.668, Loss_clf 0.430, Loss_fe 0.197, Loss_kd 2.871, Train_accy 85.29, Test_accy 66.73
2024-09-08 13:47:09,068 [foster.py] => Task 8, Epoch 159/170 => Loss 3.589, Loss_clf 0.392, Loss_fe 0.177, Loss_kd 2.849, Train_accy 85.57, Test_accy 66.78
2024-09-08 13:47:15,217 [foster.py] => Task 8, Epoch 160/170 => Loss 3.672, Loss_clf 0.431, Loss_fe 0.187, Loss_kd 2.883, Train_accy 85.67, Test_accy 66.71
2024-09-08 13:47:19,415 [foster.py] => Task 8, Epoch 161/170 => Loss 3.633, Loss_clf 0.408, Loss_fe 0.189, Loss_kd 2.866, Train_accy 86.55
2024-09-08 13:47:25,634 [foster.py] => Task 8, Epoch 162/170 => Loss 3.682, Loss_clf 0.429, Loss_fe 0.195, Loss_kd 2.886, Train_accy 85.74, Test_accy 66.63
2024-09-08 13:47:31,877 [foster.py] => Task 8, Epoch 163/170 => Loss 3.643, Loss_clf 0.411, Loss_fe 0.186, Loss_kd 2.875, Train_accy 86.05, Test_accy 66.82
2024-09-08 13:47:37,996 [foster.py] => Task 8, Epoch 164/170 => Loss 3.587, Loss_clf 0.381, Loss_fe 0.183, Loss_kd 2.853, Train_accy 86.43, Test_accy 66.77
2024-09-08 13:47:44,112 [foster.py] => Task 8, Epoch 165/170 => Loss 3.668, Loss_clf 0.427, Loss_fe 0.195, Loss_kd 2.875, Train_accy 85.52, Test_accy 66.74
2024-09-08 13:47:48,304 [foster.py] => Task 8, Epoch 166/170 => Loss 3.613, Loss_clf 0.392, Loss_fe 0.185, Loss_kd 2.866, Train_accy 85.62
2024-09-08 13:47:54,488 [foster.py] => Task 8, Epoch 167/170 => Loss 3.689, Loss_clf 0.426, Loss_fe 0.204, Loss_kd 2.888, Train_accy 85.81, Test_accy 66.73
2024-09-08 13:48:00,725 [foster.py] => Task 8, Epoch 168/170 => Loss 3.646, Loss_clf 0.412, Loss_fe 0.186, Loss_kd 2.877, Train_accy 86.48, Test_accy 66.70
2024-09-08 13:48:06,933 [foster.py] => Task 8, Epoch 169/170 => Loss 3.709, Loss_clf 0.441, Loss_fe 0.207, Loss_kd 2.889, Train_accy 85.52, Test_accy 66.69
2024-09-08 13:48:13,135 [foster.py] => Task 8, Epoch 170/170 => Loss 3.669, Loss_clf 0.424, Loss_fe 0.191, Loss_kd 2.883, Train_accy 86.02, Test_accy 66.68
2024-09-08 13:48:13,136 [foster.py] => do not weight align teacher!
2024-09-08 13:48:13,138 [foster.py] => per cls weights : [1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117 1.02718117
 1.02718117 0.53792017 0.53792017 0.53792017 0.53792017 0.53792017]
2024-09-08 13:48:20,519 [foster.py] => SNet: Task 8, Epoch 1/130 => Loss 31.219,  Loss1 0.772, Train_accy 40.64, Test_accy 60.86
2024-09-08 13:48:26,275 [foster.py] => SNet: Task 8, Epoch 2/130 => Loss 31.033,  Loss1 0.771, Train_accy 52.17
2024-09-08 13:48:32,046 [foster.py] => SNet: Task 8, Epoch 3/130 => Loss 31.031,  Loss1 0.771, Train_accy 56.10
2024-09-08 13:48:37,849 [foster.py] => SNet: Task 8, Epoch 4/130 => Loss 31.027,  Loss1 0.772, Train_accy 60.14
2024-09-08 13:48:43,626 [foster.py] => SNet: Task 8, Epoch 5/130 => Loss 31.020,  Loss1 0.772, Train_accy 59.64
2024-09-08 13:48:50,726 [foster.py] => SNet: Task 8, Epoch 6/130 => Loss 30.987,  Loss1 0.771, Train_accy 61.83, Test_accy 63.96
2024-09-08 13:48:56,512 [foster.py] => SNet: Task 8, Epoch 7/130 => Loss 30.991,  Loss1 0.772, Train_accy 63.62
2024-09-08 13:49:02,344 [foster.py] => SNet: Task 8, Epoch 8/130 => Loss 30.992,  Loss1 0.772, Train_accy 62.69
2024-09-08 13:49:08,133 [foster.py] => SNet: Task 8, Epoch 9/130 => Loss 31.008,  Loss1 0.772, Train_accy 64.31
2024-09-08 13:49:13,958 [foster.py] => SNet: Task 8, Epoch 10/130 => Loss 30.997,  Loss1 0.772, Train_accy 65.60
2024-09-08 13:49:21,058 [foster.py] => SNet: Task 8, Epoch 11/130 => Loss 30.974,  Loss1 0.772, Train_accy 65.31, Test_accy 64.28
2024-09-08 13:49:26,938 [foster.py] => SNet: Task 8, Epoch 12/130 => Loss 30.990,  Loss1 0.772, Train_accy 65.45
2024-09-08 13:49:32,763 [foster.py] => SNet: Task 8, Epoch 13/130 => Loss 30.991,  Loss1 0.772, Train_accy 67.38
2024-09-08 13:49:38,535 [foster.py] => SNet: Task 8, Epoch 14/130 => Loss 30.978,  Loss1 0.772, Train_accy 67.43
2024-09-08 13:49:44,324 [foster.py] => SNet: Task 8, Epoch 15/130 => Loss 31.001,  Loss1 0.772, Train_accy 67.76
2024-09-08 13:49:51,431 [foster.py] => SNet: Task 8, Epoch 16/130 => Loss 30.963,  Loss1 0.772, Train_accy 68.00, Test_accy 64.80
2024-09-08 13:49:57,228 [foster.py] => SNet: Task 8, Epoch 17/130 => Loss 30.981,  Loss1 0.771, Train_accy 68.24
2024-09-08 13:50:03,060 [foster.py] => SNet: Task 8, Epoch 18/130 => Loss 30.995,  Loss1 0.772, Train_accy 67.52
2024-09-08 13:50:08,845 [foster.py] => SNet: Task 8, Epoch 19/130 => Loss 30.986,  Loss1 0.772, Train_accy 68.48
2024-09-08 13:50:14,638 [foster.py] => SNet: Task 8, Epoch 20/130 => Loss 30.961,  Loss1 0.772, Train_accy 68.95
2024-09-08 13:50:21,686 [foster.py] => SNet: Task 8, Epoch 21/130 => Loss 30.986,  Loss1 0.772, Train_accy 68.57, Test_accy 65.30
2024-09-08 13:50:27,448 [foster.py] => SNet: Task 8, Epoch 22/130 => Loss 30.961,  Loss1 0.772, Train_accy 70.17
2024-09-08 13:50:33,217 [foster.py] => SNet: Task 8, Epoch 23/130 => Loss 30.960,  Loss1 0.772, Train_accy 70.17
2024-09-08 13:50:39,085 [foster.py] => SNet: Task 8, Epoch 24/130 => Loss 30.973,  Loss1 0.772, Train_accy 68.79
2024-09-08 13:50:44,901 [foster.py] => SNet: Task 8, Epoch 25/130 => Loss 30.921,  Loss1 0.772, Train_accy 69.40
2024-09-08 13:50:51,975 [foster.py] => SNet: Task 8, Epoch 26/130 => Loss 30.959,  Loss1 0.772, Train_accy 70.57, Test_accy 65.03
2024-09-08 13:50:57,759 [foster.py] => SNet: Task 8, Epoch 27/130 => Loss 30.944,  Loss1 0.772, Train_accy 69.69
2024-09-08 13:51:03,575 [foster.py] => SNet: Task 8, Epoch 28/130 => Loss 30.964,  Loss1 0.772, Train_accy 71.48
2024-09-08 13:51:09,362 [foster.py] => SNet: Task 8, Epoch 29/130 => Loss 30.967,  Loss1 0.772, Train_accy 70.67
2024-09-08 13:51:15,174 [foster.py] => SNet: Task 8, Epoch 30/130 => Loss 30.930,  Loss1 0.772, Train_accy 70.95
2024-09-08 13:51:22,257 [foster.py] => SNet: Task 8, Epoch 31/130 => Loss 30.985,  Loss1 0.772, Train_accy 70.05, Test_accy 64.90
2024-09-08 13:51:28,089 [foster.py] => SNet: Task 8, Epoch 32/130 => Loss 30.988,  Loss1 0.772, Train_accy 70.90
2024-09-08 13:51:33,894 [foster.py] => SNet: Task 8, Epoch 33/130 => Loss 30.955,  Loss1 0.772, Train_accy 71.33
2024-09-08 13:51:39,717 [foster.py] => SNet: Task 8, Epoch 34/130 => Loss 30.959,  Loss1 0.772, Train_accy 70.93
2024-09-08 13:51:45,487 [foster.py] => SNet: Task 8, Epoch 35/130 => Loss 30.963,  Loss1 0.772, Train_accy 71.10
2024-09-08 13:51:52,642 [foster.py] => SNet: Task 8, Epoch 36/130 => Loss 30.980,  Loss1 0.772, Train_accy 70.81, Test_accy 65.13
2024-09-08 13:51:58,471 [foster.py] => SNet: Task 8, Epoch 37/130 => Loss 30.995,  Loss1 0.772, Train_accy 71.52
2024-09-08 13:52:04,322 [foster.py] => SNet: Task 8, Epoch 38/130 => Loss 30.941,  Loss1 0.772, Train_accy 70.62
2024-09-08 13:52:10,121 [foster.py] => SNet: Task 8, Epoch 39/130 => Loss 30.928,  Loss1 0.772, Train_accy 72.00
2024-09-08 13:52:15,974 [foster.py] => SNet: Task 8, Epoch 40/130 => Loss 30.945,  Loss1 0.772, Train_accy 70.76
2024-09-08 13:52:23,079 [foster.py] => SNet: Task 8, Epoch 41/130 => Loss 30.943,  Loss1 0.772, Train_accy 71.17, Test_accy 64.82
2024-09-08 13:52:28,913 [foster.py] => SNet: Task 8, Epoch 42/130 => Loss 30.942,  Loss1 0.771, Train_accy 72.24
2024-09-08 13:52:34,697 [foster.py] => SNet: Task 8, Epoch 43/130 => Loss 30.931,  Loss1 0.772, Train_accy 71.62
2024-09-08 13:52:40,534 [foster.py] => SNet: Task 8, Epoch 44/130 => Loss 31.000,  Loss1 0.772, Train_accy 71.00
2024-09-08 13:52:46,336 [foster.py] => SNet: Task 8, Epoch 45/130 => Loss 30.973,  Loss1 0.772, Train_accy 72.90
2024-09-08 13:52:53,409 [foster.py] => SNet: Task 8, Epoch 46/130 => Loss 30.935,  Loss1 0.771, Train_accy 71.83, Test_accy 65.24
2024-09-08 13:52:59,221 [foster.py] => SNet: Task 8, Epoch 47/130 => Loss 30.955,  Loss1 0.772, Train_accy 72.33
2024-09-08 13:53:05,042 [foster.py] => SNet: Task 8, Epoch 48/130 => Loss 30.959,  Loss1 0.772, Train_accy 73.64
2024-09-08 13:53:10,989 [foster.py] => SNet: Task 8, Epoch 49/130 => Loss 30.954,  Loss1 0.772, Train_accy 71.57
2024-09-08 13:53:16,748 [foster.py] => SNet: Task 8, Epoch 50/130 => Loss 30.947,  Loss1 0.772, Train_accy 72.79
2024-09-08 13:53:23,828 [foster.py] => SNet: Task 8, Epoch 51/130 => Loss 30.980,  Loss1 0.772, Train_accy 72.57, Test_accy 64.94
2024-09-08 13:53:29,621 [foster.py] => SNet: Task 8, Epoch 52/130 => Loss 30.954,  Loss1 0.772, Train_accy 71.64
2024-09-08 13:53:35,382 [foster.py] => SNet: Task 8, Epoch 53/130 => Loss 30.937,  Loss1 0.772, Train_accy 73.07
2024-09-08 13:53:41,160 [foster.py] => SNet: Task 8, Epoch 54/130 => Loss 30.985,  Loss1 0.772, Train_accy 72.24
2024-09-08 13:53:46,947 [foster.py] => SNet: Task 8, Epoch 55/130 => Loss 30.959,  Loss1 0.772, Train_accy 72.83
2024-09-08 13:53:54,017 [foster.py] => SNet: Task 8, Epoch 56/130 => Loss 30.935,  Loss1 0.772, Train_accy 72.76, Test_accy 65.43
2024-09-08 13:53:59,792 [foster.py] => SNet: Task 8, Epoch 57/130 => Loss 30.958,  Loss1 0.772, Train_accy 71.93
2024-09-08 13:54:05,566 [foster.py] => SNet: Task 8, Epoch 58/130 => Loss 30.992,  Loss1 0.772, Train_accy 72.26
2024-09-08 13:54:11,374 [foster.py] => SNet: Task 8, Epoch 59/130 => Loss 30.958,  Loss1 0.772, Train_accy 72.24
2024-09-08 13:54:17,216 [foster.py] => SNet: Task 8, Epoch 60/130 => Loss 30.976,  Loss1 0.772, Train_accy 72.69
2024-09-08 13:54:24,325 [foster.py] => SNet: Task 8, Epoch 61/130 => Loss 30.965,  Loss1 0.772, Train_accy 73.00, Test_accy 65.59
2024-09-08 13:54:30,129 [foster.py] => SNet: Task 8, Epoch 62/130 => Loss 30.980,  Loss1 0.772, Train_accy 73.31
2024-09-08 13:54:35,921 [foster.py] => SNet: Task 8, Epoch 63/130 => Loss 30.947,  Loss1 0.772, Train_accy 74.36
2024-09-08 13:54:41,738 [foster.py] => SNet: Task 8, Epoch 64/130 => Loss 30.968,  Loss1 0.772, Train_accy 71.98
2024-09-08 13:54:47,581 [foster.py] => SNet: Task 8, Epoch 65/130 => Loss 30.947,  Loss1 0.772, Train_accy 73.83
2024-09-08 13:54:54,681 [foster.py] => SNet: Task 8, Epoch 66/130 => Loss 30.948,  Loss1 0.772, Train_accy 72.29, Test_accy 65.50
2024-09-08 13:55:00,482 [foster.py] => SNet: Task 8, Epoch 67/130 => Loss 30.957,  Loss1 0.772, Train_accy 73.64
2024-09-08 13:55:06,278 [foster.py] => SNet: Task 8, Epoch 68/130 => Loss 30.933,  Loss1 0.772, Train_accy 73.33
2024-09-08 13:55:12,061 [foster.py] => SNet: Task 8, Epoch 69/130 => Loss 30.960,  Loss1 0.772, Train_accy 74.81
2024-09-08 13:55:17,862 [foster.py] => SNet: Task 8, Epoch 70/130 => Loss 30.921,  Loss1 0.772, Train_accy 73.48
2024-09-08 13:55:24,925 [foster.py] => SNet: Task 8, Epoch 71/130 => Loss 30.962,  Loss1 0.771, Train_accy 73.76, Test_accy 65.41
2024-09-08 13:55:30,727 [foster.py] => SNet: Task 8, Epoch 72/130 => Loss 30.946,  Loss1 0.772, Train_accy 73.14
2024-09-08 13:55:36,556 [foster.py] => SNet: Task 8, Epoch 73/130 => Loss 30.950,  Loss1 0.772, Train_accy 74.26
2024-09-08 13:55:42,416 [foster.py] => SNet: Task 8, Epoch 74/130 => Loss 30.935,  Loss1 0.772, Train_accy 73.19
2024-09-08 13:55:48,265 [foster.py] => SNet: Task 8, Epoch 75/130 => Loss 30.925,  Loss1 0.772, Train_accy 73.57
2024-09-08 13:55:55,344 [foster.py] => SNet: Task 8, Epoch 76/130 => Loss 30.949,  Loss1 0.772, Train_accy 73.36, Test_accy 65.23
2024-09-08 13:56:01,123 [foster.py] => SNet: Task 8, Epoch 77/130 => Loss 30.962,  Loss1 0.772, Train_accy 73.07
2024-09-08 13:56:06,883 [foster.py] => SNet: Task 8, Epoch 78/130 => Loss 30.964,  Loss1 0.772, Train_accy 74.48
2024-09-08 13:56:12,692 [foster.py] => SNet: Task 8, Epoch 79/130 => Loss 30.958,  Loss1 0.772, Train_accy 73.57
2024-09-08 13:56:18,504 [foster.py] => SNet: Task 8, Epoch 80/130 => Loss 30.936,  Loss1 0.772, Train_accy 74.17
2024-09-08 13:56:25,572 [foster.py] => SNet: Task 8, Epoch 81/130 => Loss 30.967,  Loss1 0.772, Train_accy 73.52, Test_accy 65.60
2024-09-08 13:56:31,397 [foster.py] => SNet: Task 8, Epoch 82/130 => Loss 30.952,  Loss1 0.772, Train_accy 73.98
2024-09-08 13:56:37,248 [foster.py] => SNet: Task 8, Epoch 83/130 => Loss 30.935,  Loss1 0.772, Train_accy 74.83
2024-09-08 13:56:43,041 [foster.py] => SNet: Task 8, Epoch 84/130 => Loss 30.952,  Loss1 0.771, Train_accy 73.86
2024-09-08 13:56:48,801 [foster.py] => SNet: Task 8, Epoch 85/130 => Loss 30.929,  Loss1 0.772, Train_accy 74.26
2024-09-08 13:56:55,965 [foster.py] => SNet: Task 8, Epoch 86/130 => Loss 30.949,  Loss1 0.772, Train_accy 73.93, Test_accy 65.69
2024-09-08 13:57:01,812 [foster.py] => SNet: Task 8, Epoch 87/130 => Loss 30.951,  Loss1 0.772, Train_accy 73.98
2024-09-08 13:57:07,621 [foster.py] => SNet: Task 8, Epoch 88/130 => Loss 30.952,  Loss1 0.772, Train_accy 73.52
2024-09-08 13:57:13,423 [foster.py] => SNet: Task 8, Epoch 89/130 => Loss 30.948,  Loss1 0.771, Train_accy 73.74
2024-09-08 13:57:19,238 [foster.py] => SNet: Task 8, Epoch 90/130 => Loss 30.958,  Loss1 0.772, Train_accy 72.60
2024-09-08 13:57:26,268 [foster.py] => SNet: Task 8, Epoch 91/130 => Loss 30.955,  Loss1 0.772, Train_accy 73.71, Test_accy 65.23
2024-09-08 13:57:32,018 [foster.py] => SNet: Task 8, Epoch 92/130 => Loss 30.950,  Loss1 0.772, Train_accy 74.48
2024-09-08 13:57:37,815 [foster.py] => SNet: Task 8, Epoch 93/130 => Loss 30.923,  Loss1 0.772, Train_accy 74.43
2024-09-08 13:57:43,650 [foster.py] => SNet: Task 8, Epoch 94/130 => Loss 30.985,  Loss1 0.772, Train_accy 73.83
2024-09-08 13:57:49,494 [foster.py] => SNet: Task 8, Epoch 95/130 => Loss 30.946,  Loss1 0.772, Train_accy 73.83
2024-09-08 13:57:56,555 [foster.py] => SNet: Task 8, Epoch 96/130 => Loss 30.953,  Loss1 0.772, Train_accy 74.00, Test_accy 65.47
2024-09-08 13:58:02,369 [foster.py] => SNet: Task 8, Epoch 97/130 => Loss 30.958,  Loss1 0.772, Train_accy 73.00
2024-09-08 13:58:08,205 [foster.py] => SNet: Task 8, Epoch 98/130 => Loss 30.926,  Loss1 0.771, Train_accy 73.38
2024-09-08 13:58:13,997 [foster.py] => SNet: Task 8, Epoch 99/130 => Loss 30.932,  Loss1 0.772, Train_accy 74.38
2024-09-08 13:58:19,788 [foster.py] => SNet: Task 8, Epoch 100/130 => Loss 30.938,  Loss1 0.772, Train_accy 74.45
2024-09-08 13:58:26,802 [foster.py] => SNet: Task 8, Epoch 101/130 => Loss 30.924,  Loss1 0.772, Train_accy 74.74, Test_accy 65.56
2024-09-08 13:58:32,633 [foster.py] => SNet: Task 8, Epoch 102/130 => Loss 30.929,  Loss1 0.772, Train_accy 74.14
2024-09-08 13:58:38,434 [foster.py] => SNet: Task 8, Epoch 103/130 => Loss 30.965,  Loss1 0.772, Train_accy 73.12
2024-09-08 13:58:44,239 [foster.py] => SNet: Task 8, Epoch 104/130 => Loss 30.924,  Loss1 0.772, Train_accy 75.26
2024-09-08 13:58:50,068 [foster.py] => SNet: Task 8, Epoch 105/130 => Loss 30.958,  Loss1 0.772, Train_accy 74.81
2024-09-08 13:58:57,164 [foster.py] => SNet: Task 8, Epoch 106/130 => Loss 30.952,  Loss1 0.772, Train_accy 73.62, Test_accy 65.60
2024-09-08 13:59:02,971 [foster.py] => SNet: Task 8, Epoch 107/130 => Loss 30.950,  Loss1 0.772, Train_accy 74.02
2024-09-08 13:59:08,806 [foster.py] => SNet: Task 8, Epoch 108/130 => Loss 30.967,  Loss1 0.772, Train_accy 73.69
2024-09-08 13:59:14,633 [foster.py] => SNet: Task 8, Epoch 109/130 => Loss 30.926,  Loss1 0.772, Train_accy 74.79
2024-09-08 13:59:20,495 [foster.py] => SNet: Task 8, Epoch 110/130 => Loss 30.961,  Loss1 0.772, Train_accy 74.83
2024-09-08 13:59:27,621 [foster.py] => SNet: Task 8, Epoch 111/130 => Loss 30.937,  Loss1 0.772, Train_accy 74.48, Test_accy 65.69
2024-09-08 13:59:33,404 [foster.py] => SNet: Task 8, Epoch 112/130 => Loss 30.955,  Loss1 0.772, Train_accy 72.88
2024-09-08 13:59:39,178 [foster.py] => SNet: Task 8, Epoch 113/130 => Loss 30.957,  Loss1 0.772, Train_accy 74.95
2024-09-08 13:59:45,020 [foster.py] => SNet: Task 8, Epoch 114/130 => Loss 30.964,  Loss1 0.772, Train_accy 74.71
2024-09-08 13:59:50,850 [foster.py] => SNet: Task 8, Epoch 115/130 => Loss 30.925,  Loss1 0.772, Train_accy 75.17
2024-09-08 13:59:57,869 [foster.py] => SNet: Task 8, Epoch 116/130 => Loss 30.968,  Loss1 0.772, Train_accy 73.62, Test_accy 65.47
2024-09-08 14:00:03,688 [foster.py] => SNet: Task 8, Epoch 117/130 => Loss 30.916,  Loss1 0.772, Train_accy 74.69
2024-09-08 14:00:09,468 [foster.py] => SNet: Task 8, Epoch 118/130 => Loss 30.949,  Loss1 0.772, Train_accy 74.83
2024-09-08 14:00:15,285 [foster.py] => SNet: Task 8, Epoch 119/130 => Loss 30.926,  Loss1 0.772, Train_accy 73.26
2024-09-08 14:00:21,067 [foster.py] => SNet: Task 8, Epoch 120/130 => Loss 30.963,  Loss1 0.772, Train_accy 73.98
2024-09-08 14:00:28,145 [foster.py] => SNet: Task 8, Epoch 121/130 => Loss 30.938,  Loss1 0.772, Train_accy 74.12, Test_accy 65.53
2024-09-08 14:00:33,928 [foster.py] => SNet: Task 8, Epoch 122/130 => Loss 30.935,  Loss1 0.772, Train_accy 74.12
2024-09-08 14:00:39,820 [foster.py] => SNet: Task 8, Epoch 123/130 => Loss 30.925,  Loss1 0.772, Train_accy 74.12
2024-09-08 14:00:45,663 [foster.py] => SNet: Task 8, Epoch 124/130 => Loss 30.946,  Loss1 0.772, Train_accy 73.93
2024-09-08 14:00:51,436 [foster.py] => SNet: Task 8, Epoch 125/130 => Loss 30.947,  Loss1 0.772, Train_accy 73.62
2024-09-08 14:00:58,540 [foster.py] => SNet: Task 8, Epoch 126/130 => Loss 30.942,  Loss1 0.772, Train_accy 74.12, Test_accy 65.72
2024-09-08 14:01:04,341 [foster.py] => SNet: Task 8, Epoch 127/130 => Loss 30.941,  Loss1 0.772, Train_accy 73.57
2024-09-08 14:01:10,170 [foster.py] => SNet: Task 8, Epoch 128/130 => Loss 30.948,  Loss1 0.772, Train_accy 73.98
2024-09-08 14:01:15,980 [foster.py] => SNet: Task 8, Epoch 129/130 => Loss 30.960,  Loss1 0.771, Train_accy 73.93
2024-09-08 14:01:21,749 [foster.py] => SNet: Task 8, Epoch 130/130 => Loss 30.950,  Loss1 0.772, Train_accy 74.21
2024-09-08 14:01:21,750 [foster.py] => do not weight align student!
2024-09-08 14:01:23,024 [foster.py] => darknet eval: 
2024-09-08 14:01:23,024 [foster.py] => CNN top1 curve: 65.71
2024-09-08 14:01:23,024 [foster.py] => CNN top5 curve: 89.77
2024-09-08 14:01:23,024 [foster.py] => CNN top1 平均值: 65.71
2024-09-08 14:01:23,028 [foster.py] => timees : 1773.8542504310608
2024-09-08 14:01:23,029 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 14:01:51,784 [foster.py] => Exemplar size: 1800
2024-09-08 14:01:51,784 [trainer.py] => CNN: {'total': 66.68, '00-09': 73.9, '10-19': 57.5, '20-29': 73.8, '30-39': 65.2, '40-49': 72.1, '50-59': 52.0, '60-69': 67.7, '70-79': 64.9, '80-89': 73.0, 'old': 66.01, 'new': 78.0}
2024-09-08 14:01:51,784 [trainer.py] => NME: {'total': 62.28, '00-09': 64.0, '10-19': 51.8, '20-29': 66.8, '30-39': 57.8, '40-49': 65.5, '50-59': 53.8, '60-69': 66.1, '70-79': 65.7, '80-89': 69.0, 'old': 61.12, 'new': 82.0}
2024-09-08 14:01:51,784 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67, 69.88, 68.0, 66.68]
2024-09-08 14:01:51,784 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05, 92.24, 91.41, 90.32]
2024-09-08 14:01:51,784 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83, 64.05, 62.79, 62.28]
2024-09-08 14:01:51,784 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79, 89.66, 89.24, 87.61]

2024-09-08 14:01:51,784 [trainer.py] => CNN top1 平均值: 74.24
2024-09-08 14:01:51,787 [trainer.py] => All params: 1177533
2024-09-08 14:01:51,789 [trainer.py] => Trainable params: 594734
2024-09-08 14:01:51,855 [foster.py] => Learning on 90-95
2024-09-08 14:01:51,858 [foster.py] => All params: 1178828
2024-09-08 14:01:51,860 [foster.py] => Trainable params: 595704
2024-09-08 14:01:51,915 [foster.py] => per cls weights : [1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018 1.02098018
 0.62235685 0.62235685 0.62235685 0.62235685 0.62235685]
2024-09-08 14:01:56,177 [foster.py] => Task 9, Epoch 1/170 => Loss 6.339, Loss_clf 1.600, Loss_fe 1.620, Loss_kd 2.954, Train_accy 57.00
2024-09-08 14:02:02,687 [foster.py] => Task 9, Epoch 2/170 => Loss 4.909, Loss_clf 0.889, Loss_fe 0.935, Loss_kd 2.921, Train_accy 67.28, Test_accy 62.51
2024-09-08 14:02:09,257 [foster.py] => Task 9, Epoch 3/170 => Loss 4.762, Loss_clf 0.864, Loss_fe 0.812, Loss_kd 2.922, Train_accy 68.19, Test_accy 63.79
2024-09-08 14:02:15,648 [foster.py] => Task 9, Epoch 4/170 => Loss 4.647, Loss_clf 0.793, Loss_fe 0.764, Loss_kd 2.925, Train_accy 69.49, Test_accy 64.11
2024-09-08 14:02:22,034 [foster.py] => Task 9, Epoch 5/170 => Loss 4.657, Loss_clf 0.801, Loss_fe 0.773, Loss_kd 2.919, Train_accy 69.09, Test_accy 63.40
2024-09-08 14:02:26,303 [foster.py] => Task 9, Epoch 6/170 => Loss 4.583, Loss_clf 0.785, Loss_fe 0.722, Loss_kd 2.912, Train_accy 69.58
2024-09-08 14:02:32,732 [foster.py] => Task 9, Epoch 7/170 => Loss 4.580, Loss_clf 0.778, Loss_fe 0.722, Loss_kd 2.917, Train_accy 70.60, Test_accy 63.40
2024-09-08 14:02:39,197 [foster.py] => Task 9, Epoch 8/170 => Loss 4.557, Loss_clf 0.763, Loss_fe 0.703, Loss_kd 2.927, Train_accy 71.51, Test_accy 63.27
2024-09-08 14:02:45,697 [foster.py] => Task 9, Epoch 9/170 => Loss 4.511, Loss_clf 0.758, Loss_fe 0.672, Loss_kd 2.917, Train_accy 71.21, Test_accy 64.75
2024-09-08 14:02:52,114 [foster.py] => Task 9, Epoch 10/170 => Loss 4.440, Loss_clf 0.716, Loss_fe 0.638, Loss_kd 2.921, Train_accy 72.53, Test_accy 64.81
2024-09-08 14:02:56,293 [foster.py] => Task 9, Epoch 11/170 => Loss 4.455, Loss_clf 0.727, Loss_fe 0.656, Loss_kd 2.908, Train_accy 72.28
2024-09-08 14:03:02,787 [foster.py] => Task 9, Epoch 12/170 => Loss 4.485, Loss_clf 0.750, Loss_fe 0.650, Loss_kd 2.921, Train_accy 72.44, Test_accy 64.53
2024-09-08 14:03:09,294 [foster.py] => Task 9, Epoch 13/170 => Loss 4.416, Loss_clf 0.711, Loss_fe 0.631, Loss_kd 2.911, Train_accy 73.49, Test_accy 64.45
2024-09-08 14:03:15,659 [foster.py] => Task 9, Epoch 14/170 => Loss 4.387, Loss_clf 0.697, Loss_fe 0.625, Loss_kd 2.902, Train_accy 73.79, Test_accy 64.25
2024-09-08 14:03:22,135 [foster.py] => Task 9, Epoch 15/170 => Loss 4.385, Loss_clf 0.694, Loss_fe 0.609, Loss_kd 2.918, Train_accy 73.70, Test_accy 64.78
2024-09-08 14:03:26,457 [foster.py] => Task 9, Epoch 16/170 => Loss 4.410, Loss_clf 0.700, Loss_fe 0.619, Loss_kd 2.926, Train_accy 73.86
2024-09-08 14:03:33,001 [foster.py] => Task 9, Epoch 17/170 => Loss 4.366, Loss_clf 0.683, Loss_fe 0.597, Loss_kd 2.922, Train_accy 73.37, Test_accy 64.09
2024-09-08 14:03:39,484 [foster.py] => Task 9, Epoch 18/170 => Loss 4.347, Loss_clf 0.683, Loss_fe 0.605, Loss_kd 2.896, Train_accy 74.33, Test_accy 63.74
2024-09-08 14:03:45,866 [foster.py] => Task 9, Epoch 19/170 => Loss 4.410, Loss_clf 0.709, Loss_fe 0.616, Loss_kd 2.921, Train_accy 73.28, Test_accy 63.82
2024-09-08 14:03:52,284 [foster.py] => Task 9, Epoch 20/170 => Loss 4.365, Loss_clf 0.689, Loss_fe 0.603, Loss_kd 2.909, Train_accy 73.77, Test_accy 64.24
2024-09-08 14:03:56,604 [foster.py] => Task 9, Epoch 21/170 => Loss 4.366, Loss_clf 0.689, Loss_fe 0.587, Loss_kd 2.926, Train_accy 74.40
2024-09-08 14:04:03,057 [foster.py] => Task 9, Epoch 22/170 => Loss 4.305, Loss_clf 0.674, Loss_fe 0.550, Loss_kd 2.917, Train_accy 74.07, Test_accy 64.05
2024-09-08 14:04:09,468 [foster.py] => Task 9, Epoch 23/170 => Loss 4.315, Loss_clf 0.662, Loss_fe 0.568, Loss_kd 2.921, Train_accy 75.65, Test_accy 64.24
2024-09-08 14:04:15,784 [foster.py] => Task 9, Epoch 24/170 => Loss 4.237, Loss_clf 0.630, Loss_fe 0.543, Loss_kd 2.902, Train_accy 75.33, Test_accy 64.29
2024-09-08 14:04:22,076 [foster.py] => Task 9, Epoch 25/170 => Loss 4.220, Loss_clf 0.620, Loss_fe 0.532, Loss_kd 2.905, Train_accy 76.26, Test_accy 64.23
2024-09-08 14:04:26,258 [foster.py] => Task 9, Epoch 26/170 => Loss 4.261, Loss_clf 0.649, Loss_fe 0.543, Loss_kd 2.906, Train_accy 75.23
2024-09-08 14:04:32,723 [foster.py] => Task 9, Epoch 27/170 => Loss 4.287, Loss_clf 0.660, Loss_fe 0.538, Loss_kd 2.925, Train_accy 74.81, Test_accy 64.55
2024-09-08 14:04:39,169 [foster.py] => Task 9, Epoch 28/170 => Loss 4.228, Loss_clf 0.641, Loss_fe 0.506, Loss_kd 2.916, Train_accy 76.33, Test_accy 65.06
2024-09-08 14:04:45,647 [foster.py] => Task 9, Epoch 29/170 => Loss 4.255, Loss_clf 0.642, Loss_fe 0.531, Loss_kd 2.919, Train_accy 75.88, Test_accy 64.31
2024-09-08 14:04:52,052 [foster.py] => Task 9, Epoch 30/170 => Loss 4.249, Loss_clf 0.646, Loss_fe 0.526, Loss_kd 2.912, Train_accy 75.84, Test_accy 63.91
2024-09-08 14:04:56,494 [foster.py] => Task 9, Epoch 31/170 => Loss 4.260, Loss_clf 0.645, Loss_fe 0.528, Loss_kd 2.923, Train_accy 74.95
2024-09-08 14:05:02,874 [foster.py] => Task 9, Epoch 32/170 => Loss 4.273, Loss_clf 0.650, Loss_fe 0.520, Loss_kd 2.937, Train_accy 75.37, Test_accy 64.18
2024-09-08 14:05:09,252 [foster.py] => Task 9, Epoch 33/170 => Loss 4.189, Loss_clf 0.625, Loss_fe 0.490, Loss_kd 2.911, Train_accy 77.40, Test_accy 64.73
2024-09-08 14:05:15,658 [foster.py] => Task 9, Epoch 34/170 => Loss 4.245, Loss_clf 0.639, Loss_fe 0.526, Loss_kd 2.917, Train_accy 76.35, Test_accy 64.43
2024-09-08 14:05:22,083 [foster.py] => Task 9, Epoch 35/170 => Loss 4.212, Loss_clf 0.628, Loss_fe 0.497, Loss_kd 2.923, Train_accy 77.12, Test_accy 63.48
2024-09-08 14:05:26,322 [foster.py] => Task 9, Epoch 36/170 => Loss 4.192, Loss_clf 0.618, Loss_fe 0.489, Loss_kd 2.921, Train_accy 77.33
2024-09-08 14:05:32,730 [foster.py] => Task 9, Epoch 37/170 => Loss 4.139, Loss_clf 0.586, Loss_fe 0.483, Loss_kd 2.907, Train_accy 77.79, Test_accy 64.62
2024-09-08 14:05:39,107 [foster.py] => Task 9, Epoch 38/170 => Loss 4.274, Loss_clf 0.663, Loss_fe 0.523, Loss_kd 2.924, Train_accy 75.56, Test_accy 64.88
2024-09-08 14:05:45,561 [foster.py] => Task 9, Epoch 39/170 => Loss 4.206, Loss_clf 0.642, Loss_fe 0.485, Loss_kd 2.914, Train_accy 75.56, Test_accy 64.86
2024-09-08 14:05:51,955 [foster.py] => Task 9, Epoch 40/170 => Loss 4.211, Loss_clf 0.643, Loss_fe 0.505, Loss_kd 2.900, Train_accy 75.40, Test_accy 64.94
2024-09-08 14:05:56,213 [foster.py] => Task 9, Epoch 41/170 => Loss 4.198, Loss_clf 0.635, Loss_fe 0.486, Loss_kd 2.913, Train_accy 77.05
2024-09-08 14:06:02,577 [foster.py] => Task 9, Epoch 42/170 => Loss 4.180, Loss_clf 0.623, Loss_fe 0.472, Loss_kd 2.921, Train_accy 77.74, Test_accy 64.51
2024-09-08 14:06:09,036 [foster.py] => Task 9, Epoch 43/170 => Loss 4.116, Loss_clf 0.589, Loss_fe 0.460, Loss_kd 2.904, Train_accy 77.02, Test_accy 64.40
2024-09-08 14:06:15,416 [foster.py] => Task 9, Epoch 44/170 => Loss 4.187, Loss_clf 0.619, Loss_fe 0.474, Loss_kd 2.930, Train_accy 77.58, Test_accy 64.53
2024-09-08 14:06:21,946 [foster.py] => Task 9, Epoch 45/170 => Loss 4.155, Loss_clf 0.597, Loss_fe 0.482, Loss_kd 2.912, Train_accy 78.09, Test_accy 65.14
2024-09-08 14:06:26,183 [foster.py] => Task 9, Epoch 46/170 => Loss 4.125, Loss_clf 0.589, Loss_fe 0.452, Loss_kd 2.919, Train_accy 75.91
2024-09-08 14:06:32,583 [foster.py] => Task 9, Epoch 47/170 => Loss 4.022, Loss_clf 0.531, Loss_fe 0.416, Loss_kd 2.911, Train_accy 80.07, Test_accy 64.15
2024-09-08 14:06:38,977 [foster.py] => Task 9, Epoch 48/170 => Loss 4.138, Loss_clf 0.612, Loss_fe 0.450, Loss_kd 2.913, Train_accy 77.35, Test_accy 64.66
2024-09-08 14:06:45,326 [foster.py] => Task 9, Epoch 49/170 => Loss 4.110, Loss_clf 0.582, Loss_fe 0.445, Loss_kd 2.918, Train_accy 77.58, Test_accy 64.84
2024-09-08 14:06:51,694 [foster.py] => Task 9, Epoch 50/170 => Loss 4.051, Loss_clf 0.542, Loss_fe 0.431, Loss_kd 2.914, Train_accy 78.07, Test_accy 64.20
2024-09-08 14:06:55,902 [foster.py] => Task 9, Epoch 51/170 => Loss 4.076, Loss_clf 0.569, Loss_fe 0.433, Loss_kd 2.910, Train_accy 78.40
2024-09-08 14:07:02,360 [foster.py] => Task 9, Epoch 52/170 => Loss 4.099, Loss_clf 0.576, Loss_fe 0.443, Loss_kd 2.916, Train_accy 77.72, Test_accy 65.12
2024-09-08 14:07:08,806 [foster.py] => Task 9, Epoch 53/170 => Loss 4.055, Loss_clf 0.558, Loss_fe 0.430, Loss_kd 2.904, Train_accy 78.58, Test_accy 65.33
2024-09-08 14:07:15,175 [foster.py] => Task 9, Epoch 54/170 => Loss 4.050, Loss_clf 0.560, Loss_fe 0.416, Loss_kd 2.911, Train_accy 80.09, Test_accy 65.17
2024-09-08 14:07:21,610 [foster.py] => Task 9, Epoch 55/170 => Loss 4.115, Loss_clf 0.596, Loss_fe 0.434, Loss_kd 2.921, Train_accy 78.42, Test_accy 64.72
2024-09-08 14:07:25,930 [foster.py] => Task 9, Epoch 56/170 => Loss 4.064, Loss_clf 0.569, Loss_fe 0.419, Loss_kd 2.912, Train_accy 78.19
2024-09-08 14:07:32,293 [foster.py] => Task 9, Epoch 57/170 => Loss 3.998, Loss_clf 0.526, Loss_fe 0.419, Loss_kd 2.890, Train_accy 80.23, Test_accy 64.86
2024-09-08 14:07:38,655 [foster.py] => Task 9, Epoch 58/170 => Loss 4.031, Loss_clf 0.571, Loss_fe 0.396, Loss_kd 2.901, Train_accy 78.16, Test_accy 65.07
2024-09-08 14:07:45,041 [foster.py] => Task 9, Epoch 59/170 => Loss 4.083, Loss_clf 0.574, Loss_fe 0.418, Loss_kd 2.926, Train_accy 78.42, Test_accy 64.85
2024-09-08 14:07:51,478 [foster.py] => Task 9, Epoch 60/170 => Loss 4.043, Loss_clf 0.572, Loss_fe 0.398, Loss_kd 2.909, Train_accy 78.53, Test_accy 64.62
2024-09-08 14:07:55,730 [foster.py] => Task 9, Epoch 61/170 => Loss 4.025, Loss_clf 0.557, Loss_fe 0.401, Loss_kd 2.904, Train_accy 79.00
2024-09-08 14:08:02,129 [foster.py] => Task 9, Epoch 62/170 => Loss 4.056, Loss_clf 0.558, Loss_fe 0.421, Loss_kd 2.913, Train_accy 78.93, Test_accy 64.63
2024-09-08 14:08:08,464 [foster.py] => Task 9, Epoch 63/170 => Loss 4.092, Loss_clf 0.586, Loss_fe 0.413, Loss_kd 2.929, Train_accy 77.81, Test_accy 65.22
2024-09-08 14:08:14,862 [foster.py] => Task 9, Epoch 64/170 => Loss 4.025, Loss_clf 0.554, Loss_fe 0.386, Loss_kd 2.920, Train_accy 79.53, Test_accy 65.13
2024-09-08 14:08:21,338 [foster.py] => Task 9, Epoch 65/170 => Loss 4.015, Loss_clf 0.559, Loss_fe 0.385, Loss_kd 2.907, Train_accy 78.88, Test_accy 64.05
2024-09-08 14:08:25,599 [foster.py] => Task 9, Epoch 66/170 => Loss 3.973, Loss_clf 0.541, Loss_fe 0.359, Loss_kd 2.910, Train_accy 79.93
2024-09-08 14:08:32,022 [foster.py] => Task 9, Epoch 67/170 => Loss 4.026, Loss_clf 0.556, Loss_fe 0.383, Loss_kd 2.923, Train_accy 79.72, Test_accy 64.84
2024-09-08 14:08:38,471 [foster.py] => Task 9, Epoch 68/170 => Loss 3.982, Loss_clf 0.534, Loss_fe 0.375, Loss_kd 2.910, Train_accy 79.67, Test_accy 64.99
2024-09-08 14:08:44,904 [foster.py] => Task 9, Epoch 69/170 => Loss 4.036, Loss_clf 0.564, Loss_fe 0.392, Loss_kd 2.916, Train_accy 80.12, Test_accy 64.49
2024-09-08 14:08:51,439 [foster.py] => Task 9, Epoch 70/170 => Loss 3.932, Loss_clf 0.512, Loss_fe 0.356, Loss_kd 2.900, Train_accy 80.93, Test_accy 65.21
2024-09-08 14:08:55,630 [foster.py] => Task 9, Epoch 71/170 => Loss 3.991, Loss_clf 0.531, Loss_fe 0.372, Loss_kd 2.924, Train_accy 80.51
2024-09-08 14:09:02,026 [foster.py] => Task 9, Epoch 72/170 => Loss 3.968, Loss_clf 0.528, Loss_fe 0.373, Loss_kd 2.905, Train_accy 79.93, Test_accy 64.66
2024-09-08 14:09:08,424 [foster.py] => Task 9, Epoch 73/170 => Loss 3.989, Loss_clf 0.532, Loss_fe 0.383, Loss_kd 2.910, Train_accy 80.21, Test_accy 65.23
2024-09-08 14:09:14,842 [foster.py] => Task 9, Epoch 74/170 => Loss 3.939, Loss_clf 0.520, Loss_fe 0.350, Loss_kd 2.906, Train_accy 80.63, Test_accy 64.44
2024-09-08 14:09:21,177 [foster.py] => Task 9, Epoch 75/170 => Loss 3.946, Loss_clf 0.517, Loss_fe 0.356, Loss_kd 2.910, Train_accy 80.95, Test_accy 65.13
2024-09-08 14:09:25,429 [foster.py] => Task 9, Epoch 76/170 => Loss 3.967, Loss_clf 0.525, Loss_fe 0.362, Loss_kd 2.917, Train_accy 80.42
2024-09-08 14:09:31,769 [foster.py] => Task 9, Epoch 77/170 => Loss 3.964, Loss_clf 0.532, Loss_fe 0.348, Loss_kd 2.920, Train_accy 80.60, Test_accy 65.22
2024-09-08 14:09:38,191 [foster.py] => Task 9, Epoch 78/170 => Loss 3.923, Loss_clf 0.513, Loss_fe 0.331, Loss_kd 2.915, Train_accy 80.35, Test_accy 65.08
2024-09-08 14:09:44,576 [foster.py] => Task 9, Epoch 79/170 => Loss 3.908, Loss_clf 0.507, Loss_fe 0.330, Loss_kd 2.908, Train_accy 81.60, Test_accy 64.86
2024-09-08 14:09:50,981 [foster.py] => Task 9, Epoch 80/170 => Loss 3.895, Loss_clf 0.506, Loss_fe 0.319, Loss_kd 2.906, Train_accy 81.42, Test_accy 65.15
2024-09-08 14:09:55,198 [foster.py] => Task 9, Epoch 81/170 => Loss 3.914, Loss_clf 0.517, Loss_fe 0.329, Loss_kd 2.905, Train_accy 81.21
2024-09-08 14:10:01,584 [foster.py] => Task 9, Epoch 82/170 => Loss 3.903, Loss_clf 0.512, Loss_fe 0.325, Loss_kd 2.902, Train_accy 81.28, Test_accy 65.07
2024-09-08 14:10:07,961 [foster.py] => Task 9, Epoch 83/170 => Loss 3.916, Loss_clf 0.506, Loss_fe 0.327, Loss_kd 2.919, Train_accy 80.93, Test_accy 65.14
2024-09-08 14:10:14,367 [foster.py] => Task 9, Epoch 84/170 => Loss 3.884, Loss_clf 0.495, Loss_fe 0.308, Loss_kd 2.917, Train_accy 82.51, Test_accy 64.95
2024-09-08 14:10:20,878 [foster.py] => Task 9, Epoch 85/170 => Loss 3.908, Loss_clf 0.509, Loss_fe 0.323, Loss_kd 2.913, Train_accy 81.49, Test_accy 65.84
2024-09-08 14:10:25,124 [foster.py] => Task 9, Epoch 86/170 => Loss 3.955, Loss_clf 0.526, Loss_fe 0.324, Loss_kd 2.939, Train_accy 81.47
2024-09-08 14:10:31,521 [foster.py] => Task 9, Epoch 87/170 => Loss 3.884, Loss_clf 0.498, Loss_fe 0.308, Loss_kd 2.915, Train_accy 81.63, Test_accy 65.37
2024-09-08 14:10:37,972 [foster.py] => Task 9, Epoch 88/170 => Loss 3.881, Loss_clf 0.495, Loss_fe 0.303, Loss_kd 2.919, Train_accy 82.19, Test_accy 65.42
2024-09-08 14:10:44,355 [foster.py] => Task 9, Epoch 89/170 => Loss 3.924, Loss_clf 0.522, Loss_fe 0.313, Loss_kd 2.925, Train_accy 81.35, Test_accy 65.32
2024-09-08 14:10:50,676 [foster.py] => Task 9, Epoch 90/170 => Loss 3.859, Loss_clf 0.491, Loss_fe 0.279, Loss_kd 2.925, Train_accy 82.88, Test_accy 65.23
2024-09-08 14:10:55,032 [foster.py] => Task 9, Epoch 91/170 => Loss 3.893, Loss_clf 0.505, Loss_fe 0.312, Loss_kd 2.913, Train_accy 82.30
2024-09-08 14:11:01,414 [foster.py] => Task 9, Epoch 92/170 => Loss 3.870, Loss_clf 0.498, Loss_fe 0.301, Loss_kd 2.908, Train_accy 81.93, Test_accy 65.11
2024-09-08 14:11:07,843 [foster.py] => Task 9, Epoch 93/170 => Loss 3.828, Loss_clf 0.461, Loss_fe 0.271, Loss_kd 2.931, Train_accy 82.37, Test_accy 65.24
2024-09-08 14:11:14,332 [foster.py] => Task 9, Epoch 94/170 => Loss 3.793, Loss_clf 0.455, Loss_fe 0.276, Loss_kd 2.899, Train_accy 83.35, Test_accy 65.39
2024-09-08 14:11:20,808 [foster.py] => Task 9, Epoch 95/170 => Loss 3.770, Loss_clf 0.442, Loss_fe 0.256, Loss_kd 2.908, Train_accy 83.63, Test_accy 65.28
2024-09-08 14:11:25,054 [foster.py] => Task 9, Epoch 96/170 => Loss 3.828, Loss_clf 0.475, Loss_fe 0.275, Loss_kd 2.915, Train_accy 83.44
2024-09-08 14:11:31,504 [foster.py] => Task 9, Epoch 97/170 => Loss 3.806, Loss_clf 0.463, Loss_fe 0.269, Loss_kd 2.911, Train_accy 83.65, Test_accy 64.68
2024-09-08 14:11:37,853 [foster.py] => Task 9, Epoch 98/170 => Loss 3.875, Loss_clf 0.488, Loss_fe 0.293, Loss_kd 2.928, Train_accy 83.09, Test_accy 65.22
2024-09-08 14:11:44,303 [foster.py] => Task 9, Epoch 99/170 => Loss 3.880, Loss_clf 0.494, Loss_fe 0.293, Loss_kd 2.929, Train_accy 83.16, Test_accy 65.57
2024-09-08 14:11:50,640 [foster.py] => Task 9, Epoch 100/170 => Loss 3.839, Loss_clf 0.477, Loss_fe 0.286, Loss_kd 2.912, Train_accy 83.16, Test_accy 65.54
2024-09-08 14:11:54,893 [foster.py] => Task 9, Epoch 101/170 => Loss 3.853, Loss_clf 0.483, Loss_fe 0.283, Loss_kd 2.922, Train_accy 82.47
2024-09-08 14:12:01,314 [foster.py] => Task 9, Epoch 102/170 => Loss 3.782, Loss_clf 0.454, Loss_fe 0.253, Loss_kd 2.911, Train_accy 83.84, Test_accy 65.57
2024-09-08 14:12:07,780 [foster.py] => Task 9, Epoch 103/170 => Loss 3.867, Loss_clf 0.494, Loss_fe 0.274, Loss_kd 2.934, Train_accy 82.93, Test_accy 65.18
2024-09-08 14:12:14,057 [foster.py] => Task 9, Epoch 104/170 => Loss 3.765, Loss_clf 0.447, Loss_fe 0.255, Loss_kd 2.901, Train_accy 85.47, Test_accy 65.44
2024-09-08 14:12:20,553 [foster.py] => Task 9, Epoch 105/170 => Loss 3.832, Loss_clf 0.478, Loss_fe 0.270, Loss_kd 2.920, Train_accy 83.23, Test_accy 65.47
2024-09-08 14:12:24,867 [foster.py] => Task 9, Epoch 106/170 => Loss 3.800, Loss_clf 0.456, Loss_fe 0.251, Loss_kd 2.928, Train_accy 83.86
2024-09-08 14:12:31,343 [foster.py] => Task 9, Epoch 107/170 => Loss 3.834, Loss_clf 0.481, Loss_fe 0.267, Loss_kd 2.922, Train_accy 84.26, Test_accy 64.91
2024-09-08 14:12:37,728 [foster.py] => Task 9, Epoch 108/170 => Loss 3.786, Loss_clf 0.455, Loss_fe 0.266, Loss_kd 2.901, Train_accy 84.42, Test_accy 65.51
2024-09-08 14:12:44,155 [foster.py] => Task 9, Epoch 109/170 => Loss 3.765, Loss_clf 0.444, Loss_fe 0.246, Loss_kd 2.912, Train_accy 84.74, Test_accy 65.28
2024-09-08 14:12:50,543 [foster.py] => Task 9, Epoch 110/170 => Loss 3.749, Loss_clf 0.441, Loss_fe 0.237, Loss_kd 2.908, Train_accy 84.21, Test_accy 65.61
2024-09-08 14:12:54,741 [foster.py] => Task 9, Epoch 111/170 => Loss 3.757, Loss_clf 0.448, Loss_fe 0.227, Loss_kd 2.918, Train_accy 84.35
2024-09-08 14:13:01,209 [foster.py] => Task 9, Epoch 112/170 => Loss 3.714, Loss_clf 0.424, Loss_fe 0.214, Loss_kd 2.913, Train_accy 84.93, Test_accy 65.75
2024-09-08 14:13:07,713 [foster.py] => Task 9, Epoch 113/170 => Loss 3.750, Loss_clf 0.452, Loss_fe 0.224, Loss_kd 2.910, Train_accy 84.33, Test_accy 65.33
2024-09-08 14:13:14,247 [foster.py] => Task 9, Epoch 114/170 => Loss 3.792, Loss_clf 0.459, Loss_fe 0.243, Loss_kd 2.925, Train_accy 84.91, Test_accy 65.45
2024-09-08 14:13:20,588 [foster.py] => Task 9, Epoch 115/170 => Loss 3.761, Loss_clf 0.444, Loss_fe 0.227, Loss_kd 2.925, Train_accy 84.88, Test_accy 65.75
2024-09-08 14:13:24,746 [foster.py] => Task 9, Epoch 116/170 => Loss 3.759, Loss_clf 0.443, Loss_fe 0.231, Loss_kd 2.921, Train_accy 84.95
2024-09-08 14:13:31,171 [foster.py] => Task 9, Epoch 117/170 => Loss 3.765, Loss_clf 0.440, Loss_fe 0.229, Loss_kd 2.931, Train_accy 84.58, Test_accy 65.20
2024-09-08 14:13:37,575 [foster.py] => Task 9, Epoch 118/170 => Loss 3.748, Loss_clf 0.448, Loss_fe 0.216, Loss_kd 2.921, Train_accy 85.26, Test_accy 65.56
2024-09-08 14:13:43,906 [foster.py] => Task 9, Epoch 119/170 => Loss 3.710, Loss_clf 0.424, Loss_fe 0.214, Loss_kd 2.908, Train_accy 84.51, Test_accy 65.23
2024-09-08 14:13:50,424 [foster.py] => Task 9, Epoch 120/170 => Loss 3.680, Loss_clf 0.407, Loss_fe 0.199, Loss_kd 2.911, Train_accy 86.81, Test_accy 65.63
2024-09-08 14:13:54,643 [foster.py] => Task 9, Epoch 121/170 => Loss 3.700, Loss_clf 0.420, Loss_fe 0.199, Loss_kd 2.917, Train_accy 86.16
2024-09-08 14:14:01,061 [foster.py] => Task 9, Epoch 122/170 => Loss 3.742, Loss_clf 0.439, Loss_fe 0.217, Loss_kd 2.922, Train_accy 85.30, Test_accy 65.79
2024-09-08 14:14:07,442 [foster.py] => Task 9, Epoch 123/170 => Loss 3.695, Loss_clf 0.408, Loss_fe 0.201, Loss_kd 2.922, Train_accy 86.00, Test_accy 65.85
2024-09-08 14:14:13,787 [foster.py] => Task 9, Epoch 124/170 => Loss 3.715, Loss_clf 0.431, Loss_fe 0.215, Loss_kd 2.906, Train_accy 85.70, Test_accy 65.93
2024-09-08 14:14:20,154 [foster.py] => Task 9, Epoch 125/170 => Loss 3.665, Loss_clf 0.410, Loss_fe 0.192, Loss_kd 2.900, Train_accy 85.21, Test_accy 65.61
2024-09-08 14:14:24,314 [foster.py] => Task 9, Epoch 126/170 => Loss 3.684, Loss_clf 0.417, Loss_fe 0.204, Loss_kd 2.900, Train_accy 85.84
2024-09-08 14:14:30,754 [foster.py] => Task 9, Epoch 127/170 => Loss 3.685, Loss_clf 0.409, Loss_fe 0.198, Loss_kd 2.914, Train_accy 86.70, Test_accy 65.61
2024-09-08 14:14:37,068 [foster.py] => Task 9, Epoch 128/170 => Loss 3.707, Loss_clf 0.433, Loss_fe 0.202, Loss_kd 2.909, Train_accy 85.93, Test_accy 65.81
2024-09-08 14:14:43,431 [foster.py] => Task 9, Epoch 129/170 => Loss 3.697, Loss_clf 0.412, Loss_fe 0.200, Loss_kd 2.921, Train_accy 86.53, Test_accy 65.78
2024-09-08 14:14:49,900 [foster.py] => Task 9, Epoch 130/170 => Loss 3.740, Loss_clf 0.435, Loss_fe 0.220, Loss_kd 2.921, Train_accy 85.72, Test_accy 65.45
2024-09-08 14:14:54,151 [foster.py] => Task 9, Epoch 131/170 => Loss 3.702, Loss_clf 0.422, Loss_fe 0.176, Loss_kd 2.938, Train_accy 86.07
2024-09-08 14:15:00,588 [foster.py] => Task 9, Epoch 132/170 => Loss 3.660, Loss_clf 0.412, Loss_fe 0.175, Loss_kd 2.910, Train_accy 85.72, Test_accy 66.07
2024-09-08 14:15:07,035 [foster.py] => Task 9, Epoch 133/170 => Loss 3.711, Loss_clf 0.418, Loss_fe 0.196, Loss_kd 2.933, Train_accy 86.26, Test_accy 65.94
2024-09-08 14:15:13,386 [foster.py] => Task 9, Epoch 134/170 => Loss 3.685, Loss_clf 0.421, Loss_fe 0.184, Loss_kd 2.916, Train_accy 86.77, Test_accy 66.02
2024-09-08 14:15:19,750 [foster.py] => Task 9, Epoch 135/170 => Loss 3.712, Loss_clf 0.424, Loss_fe 0.196, Loss_kd 2.927, Train_accy 85.98, Test_accy 65.81
2024-09-08 14:15:23,966 [foster.py] => Task 9, Epoch 136/170 => Loss 3.664, Loss_clf 0.406, Loss_fe 0.176, Loss_kd 2.918, Train_accy 87.28
2024-09-08 14:15:30,355 [foster.py] => Task 9, Epoch 137/170 => Loss 3.687, Loss_clf 0.411, Loss_fe 0.182, Loss_kd 2.930, Train_accy 86.47, Test_accy 65.75
2024-09-08 14:15:36,820 [foster.py] => Task 9, Epoch 138/170 => Loss 3.687, Loss_clf 0.413, Loss_fe 0.185, Loss_kd 2.925, Train_accy 86.79, Test_accy 65.80
2024-09-08 14:15:43,239 [foster.py] => Task 9, Epoch 139/170 => Loss 3.736, Loss_clf 0.444, Loss_fe 0.195, Loss_kd 2.932, Train_accy 85.77, Test_accy 65.97
2024-09-08 14:15:49,629 [foster.py] => Task 9, Epoch 140/170 => Loss 3.689, Loss_clf 0.422, Loss_fe 0.187, Loss_kd 2.916, Train_accy 86.00, Test_accy 65.78
2024-09-08 14:15:53,865 [foster.py] => Task 9, Epoch 141/170 => Loss 3.658, Loss_clf 0.388, Loss_fe 0.171, Loss_kd 2.935, Train_accy 88.02
2024-09-08 14:16:00,233 [foster.py] => Task 9, Epoch 142/170 => Loss 3.653, Loss_clf 0.397, Loss_fe 0.180, Loss_kd 2.912, Train_accy 86.81, Test_accy 65.89
2024-09-08 14:16:06,611 [foster.py] => Task 9, Epoch 143/170 => Loss 3.606, Loss_clf 0.387, Loss_fe 0.155, Loss_kd 2.901, Train_accy 87.65, Test_accy 65.93
2024-09-08 14:16:13,002 [foster.py] => Task 9, Epoch 144/170 => Loss 3.628, Loss_clf 0.396, Loss_fe 0.164, Loss_kd 2.905, Train_accy 87.14, Test_accy 65.86
2024-09-08 14:16:19,351 [foster.py] => Task 9, Epoch 145/170 => Loss 3.655, Loss_clf 0.412, Loss_fe 0.173, Loss_kd 2.907, Train_accy 86.65, Test_accy 66.00
2024-09-08 14:16:23,594 [foster.py] => Task 9, Epoch 146/170 => Loss 3.668, Loss_clf 0.415, Loss_fe 0.177, Loss_kd 2.912, Train_accy 86.26
2024-09-08 14:16:29,961 [foster.py] => Task 9, Epoch 147/170 => Loss 3.701, Loss_clf 0.425, Loss_fe 0.181, Loss_kd 2.930, Train_accy 85.72, Test_accy 65.85
2024-09-08 14:16:36,360 [foster.py] => Task 9, Epoch 148/170 => Loss 3.615, Loss_clf 0.376, Loss_fe 0.156, Loss_kd 2.918, Train_accy 87.37, Test_accy 65.96
2024-09-08 14:16:42,752 [foster.py] => Task 9, Epoch 149/170 => Loss 3.658, Loss_clf 0.397, Loss_fe 0.168, Loss_kd 2.928, Train_accy 87.19, Test_accy 65.87
2024-09-08 14:16:49,258 [foster.py] => Task 9, Epoch 150/170 => Loss 3.665, Loss_clf 0.405, Loss_fe 0.184, Loss_kd 2.913, Train_accy 86.98, Test_accy 65.86
2024-09-08 14:16:53,481 [foster.py] => Task 9, Epoch 151/170 => Loss 3.635, Loss_clf 0.391, Loss_fe 0.160, Loss_kd 2.919, Train_accy 87.00
2024-09-08 14:16:59,837 [foster.py] => Task 9, Epoch 152/170 => Loss 3.671, Loss_clf 0.411, Loss_fe 0.168, Loss_kd 2.927, Train_accy 87.47, Test_accy 65.91
2024-09-08 14:17:06,237 [foster.py] => Task 9, Epoch 153/170 => Loss 3.678, Loss_clf 0.408, Loss_fe 0.180, Loss_kd 2.926, Train_accy 86.88, Test_accy 65.95
2024-09-08 14:17:12,668 [foster.py] => Task 9, Epoch 154/170 => Loss 3.665, Loss_clf 0.415, Loss_fe 0.173, Loss_kd 2.914, Train_accy 86.79, Test_accy 65.93
2024-09-08 14:17:19,082 [foster.py] => Task 9, Epoch 155/170 => Loss 3.670, Loss_clf 0.406, Loss_fe 0.177, Loss_kd 2.922, Train_accy 86.74, Test_accy 65.96
2024-09-08 14:17:23,295 [foster.py] => Task 9, Epoch 156/170 => Loss 3.619, Loss_clf 0.393, Loss_fe 0.150, Loss_kd 2.912, Train_accy 86.84
2024-09-08 14:17:29,727 [foster.py] => Task 9, Epoch 157/170 => Loss 3.669, Loss_clf 0.408, Loss_fe 0.168, Loss_kd 2.930, Train_accy 86.91, Test_accy 66.08
2024-09-08 14:17:36,261 [foster.py] => Task 9, Epoch 158/170 => Loss 3.623, Loss_clf 0.388, Loss_fe 0.168, Loss_kd 2.904, Train_accy 87.81, Test_accy 66.05
2024-09-08 14:17:42,718 [foster.py] => Task 9, Epoch 159/170 => Loss 3.611, Loss_clf 0.378, Loss_fe 0.158, Loss_kd 2.910, Train_accy 87.07, Test_accy 66.07
2024-09-08 14:17:49,076 [foster.py] => Task 9, Epoch 160/170 => Loss 3.620, Loss_clf 0.386, Loss_fe 0.161, Loss_kd 2.910, Train_accy 87.14, Test_accy 65.99
2024-09-08 14:17:53,350 [foster.py] => Task 9, Epoch 161/170 => Loss 3.653, Loss_clf 0.392, Loss_fe 0.163, Loss_kd 2.933, Train_accy 87.30
2024-09-08 14:17:59,766 [foster.py] => Task 9, Epoch 162/170 => Loss 3.626, Loss_clf 0.382, Loss_fe 0.160, Loss_kd 2.920, Train_accy 88.09, Test_accy 66.13
2024-09-08 14:18:06,158 [foster.py] => Task 9, Epoch 163/170 => Loss 3.625, Loss_clf 0.378, Loss_fe 0.180, Loss_kd 2.905, Train_accy 87.88, Test_accy 66.04
2024-09-08 14:18:12,474 [foster.py] => Task 9, Epoch 164/170 => Loss 3.618, Loss_clf 0.372, Loss_fe 0.158, Loss_kd 2.924, Train_accy 87.86, Test_accy 66.07
2024-09-08 14:18:18,944 [foster.py] => Task 9, Epoch 165/170 => Loss 3.658, Loss_clf 0.409, Loss_fe 0.161, Loss_kd 2.923, Train_accy 86.81, Test_accy 66.06
2024-09-08 14:18:23,227 [foster.py] => Task 9, Epoch 166/170 => Loss 3.626, Loss_clf 0.383, Loss_fe 0.164, Loss_kd 2.914, Train_accy 86.98
2024-09-08 14:18:29,579 [foster.py] => Task 9, Epoch 167/170 => Loss 3.627, Loss_clf 0.388, Loss_fe 0.159, Loss_kd 2.917, Train_accy 86.81, Test_accy 66.04
2024-09-08 14:18:36,093 [foster.py] => Task 9, Epoch 168/170 => Loss 3.607, Loss_clf 0.382, Loss_fe 0.152, Loss_kd 2.909, Train_accy 87.47, Test_accy 66.03
2024-09-08 14:18:42,466 [foster.py] => Task 9, Epoch 169/170 => Loss 3.625, Loss_clf 0.386, Loss_fe 0.163, Loss_kd 2.912, Train_accy 88.16, Test_accy 66.02
2024-09-08 14:18:48,883 [foster.py] => Task 9, Epoch 170/170 => Loss 3.628, Loss_clf 0.383, Loss_fe 0.161, Loss_kd 2.921, Train_accy 87.51, Test_accy 65.99
2024-09-08 14:18:48,884 [foster.py] => do not weight align teacher!
2024-09-08 14:18:48,886 [foster.py] => per cls weights : [1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379 1.02571379
 0.53715172 0.53715172 0.53715172 0.53715172 0.53715172]
2024-09-08 14:18:56,452 [foster.py] => SNet: Task 9, Epoch 1/130 => Loss 31.517,  Loss1 0.776, Train_accy 42.35, Test_accy 60.72
2024-09-08 14:19:02,372 [foster.py] => SNet: Task 9, Epoch 2/130 => Loss 31.385,  Loss1 0.775, Train_accy 55.58
2024-09-08 14:19:08,280 [foster.py] => SNet: Task 9, Epoch 3/130 => Loss 31.359,  Loss1 0.775, Train_accy 60.14
2024-09-08 14:19:14,213 [foster.py] => SNet: Task 9, Epoch 4/130 => Loss 31.356,  Loss1 0.775, Train_accy 62.28
2024-09-08 14:19:20,204 [foster.py] => SNet: Task 9, Epoch 5/130 => Loss 31.375,  Loss1 0.775, Train_accy 65.21
2024-09-08 14:19:27,553 [foster.py] => SNet: Task 9, Epoch 6/130 => Loss 31.339,  Loss1 0.775, Train_accy 66.67, Test_accy 63.39
2024-09-08 14:19:33,563 [foster.py] => SNet: Task 9, Epoch 7/130 => Loss 31.358,  Loss1 0.775, Train_accy 67.05
2024-09-08 14:19:39,521 [foster.py] => SNet: Task 9, Epoch 8/130 => Loss 31.326,  Loss1 0.775, Train_accy 67.95
2024-09-08 14:19:45,476 [foster.py] => SNet: Task 9, Epoch 9/130 => Loss 31.339,  Loss1 0.774, Train_accy 68.19
2024-09-08 14:19:51,466 [foster.py] => SNet: Task 9, Epoch 10/130 => Loss 31.308,  Loss1 0.774, Train_accy 69.40
2024-09-08 14:19:58,750 [foster.py] => SNet: Task 9, Epoch 11/130 => Loss 31.344,  Loss1 0.774, Train_accy 69.79, Test_accy 63.38
2024-09-08 14:20:04,718 [foster.py] => SNet: Task 9, Epoch 12/130 => Loss 31.285,  Loss1 0.774, Train_accy 69.35
2024-09-08 14:20:10,752 [foster.py] => SNet: Task 9, Epoch 13/130 => Loss 31.328,  Loss1 0.774, Train_accy 70.60
2024-09-08 14:20:16,715 [foster.py] => SNet: Task 9, Epoch 14/130 => Loss 31.313,  Loss1 0.774, Train_accy 71.40
2024-09-08 14:20:22,699 [foster.py] => SNet: Task 9, Epoch 15/130 => Loss 31.336,  Loss1 0.774, Train_accy 70.95
2024-09-08 14:20:29,967 [foster.py] => SNet: Task 9, Epoch 16/130 => Loss 31.332,  Loss1 0.774, Train_accy 69.93, Test_accy 63.56
2024-09-08 14:20:35,932 [foster.py] => SNet: Task 9, Epoch 17/130 => Loss 31.302,  Loss1 0.774, Train_accy 71.09
2024-09-08 14:20:41,831 [foster.py] => SNet: Task 9, Epoch 18/130 => Loss 31.322,  Loss1 0.774, Train_accy 71.70
2024-09-08 14:20:47,814 [foster.py] => SNet: Task 9, Epoch 19/130 => Loss 31.296,  Loss1 0.774, Train_accy 72.12
2024-09-08 14:20:53,838 [foster.py] => SNet: Task 9, Epoch 20/130 => Loss 31.272,  Loss1 0.774, Train_accy 72.30
2024-09-08 14:21:01,175 [foster.py] => SNet: Task 9, Epoch 21/130 => Loss 31.319,  Loss1 0.774, Train_accy 73.02, Test_accy 63.68
2024-09-08 14:21:07,211 [foster.py] => SNet: Task 9, Epoch 22/130 => Loss 31.335,  Loss1 0.774, Train_accy 72.47
2024-09-08 14:21:13,205 [foster.py] => SNet: Task 9, Epoch 23/130 => Loss 31.299,  Loss1 0.774, Train_accy 72.40
2024-09-08 14:21:19,203 [foster.py] => SNet: Task 9, Epoch 24/130 => Loss 31.300,  Loss1 0.774, Train_accy 73.23
2024-09-08 14:21:25,168 [foster.py] => SNet: Task 9, Epoch 25/130 => Loss 31.319,  Loss1 0.774, Train_accy 71.79
2024-09-08 14:21:32,421 [foster.py] => SNet: Task 9, Epoch 26/130 => Loss 31.328,  Loss1 0.774, Train_accy 73.00, Test_accy 63.58
2024-09-08 14:21:38,412 [foster.py] => SNet: Task 9, Epoch 27/130 => Loss 31.321,  Loss1 0.774, Train_accy 71.98
2024-09-08 14:21:44,361 [foster.py] => SNet: Task 9, Epoch 28/130 => Loss 31.300,  Loss1 0.774, Train_accy 73.40
2024-09-08 14:21:50,327 [foster.py] => SNet: Task 9, Epoch 29/130 => Loss 31.279,  Loss1 0.774, Train_accy 72.81
2024-09-08 14:21:56,284 [foster.py] => SNet: Task 9, Epoch 30/130 => Loss 31.328,  Loss1 0.774, Train_accy 74.63
2024-09-08 14:22:03,606 [foster.py] => SNet: Task 9, Epoch 31/130 => Loss 31.320,  Loss1 0.774, Train_accy 72.53, Test_accy 64.13
2024-09-08 14:22:09,540 [foster.py] => SNet: Task 9, Epoch 32/130 => Loss 31.273,  Loss1 0.774, Train_accy 74.35
2024-09-08 14:22:15,540 [foster.py] => SNet: Task 9, Epoch 33/130 => Loss 31.311,  Loss1 0.774, Train_accy 73.77
2024-09-08 14:22:21,461 [foster.py] => SNet: Task 9, Epoch 34/130 => Loss 31.303,  Loss1 0.774, Train_accy 75.21
2024-09-08 14:22:27,429 [foster.py] => SNet: Task 9, Epoch 35/130 => Loss 31.323,  Loss1 0.774, Train_accy 73.67
2024-09-08 14:22:34,726 [foster.py] => SNet: Task 9, Epoch 36/130 => Loss 31.336,  Loss1 0.774, Train_accy 74.09, Test_accy 63.64
2024-09-08 14:22:40,756 [foster.py] => SNet: Task 9, Epoch 37/130 => Loss 31.291,  Loss1 0.774, Train_accy 74.53
2024-09-08 14:22:46,771 [foster.py] => SNet: Task 9, Epoch 38/130 => Loss 31.316,  Loss1 0.774, Train_accy 73.19
2024-09-08 14:22:52,736 [foster.py] => SNet: Task 9, Epoch 39/130 => Loss 31.280,  Loss1 0.774, Train_accy 75.05
2024-09-08 14:22:58,659 [foster.py] => SNet: Task 9, Epoch 40/130 => Loss 31.331,  Loss1 0.774, Train_accy 74.28
2024-09-08 14:23:05,939 [foster.py] => SNet: Task 9, Epoch 41/130 => Loss 31.297,  Loss1 0.774, Train_accy 75.16, Test_accy 64.16
2024-09-08 14:23:11,913 [foster.py] => SNet: Task 9, Epoch 42/130 => Loss 31.289,  Loss1 0.774, Train_accy 74.09
2024-09-08 14:23:17,906 [foster.py] => SNet: Task 9, Epoch 43/130 => Loss 31.327,  Loss1 0.774, Train_accy 74.67
2024-09-08 14:23:23,848 [foster.py] => SNet: Task 9, Epoch 44/130 => Loss 31.320,  Loss1 0.774, Train_accy 74.23
2024-09-08 14:23:29,809 [foster.py] => SNet: Task 9, Epoch 45/130 => Loss 31.301,  Loss1 0.774, Train_accy 75.37
2024-09-08 14:23:37,106 [foster.py] => SNet: Task 9, Epoch 46/130 => Loss 31.301,  Loss1 0.774, Train_accy 74.21, Test_accy 64.14
2024-09-08 14:23:43,013 [foster.py] => SNet: Task 9, Epoch 47/130 => Loss 31.276,  Loss1 0.774, Train_accy 73.86
2024-09-08 14:23:48,964 [foster.py] => SNet: Task 9, Epoch 48/130 => Loss 31.311,  Loss1 0.774, Train_accy 74.51
2024-09-08 14:23:54,983 [foster.py] => SNet: Task 9, Epoch 49/130 => Loss 31.311,  Loss1 0.774, Train_accy 75.74
2024-09-08 14:24:00,967 [foster.py] => SNet: Task 9, Epoch 50/130 => Loss 31.297,  Loss1 0.774, Train_accy 75.53
2024-09-08 14:24:08,258 [foster.py] => SNet: Task 9, Epoch 51/130 => Loss 31.296,  Loss1 0.774, Train_accy 75.30, Test_accy 63.87
2024-09-08 14:24:14,229 [foster.py] => SNet: Task 9, Epoch 52/130 => Loss 31.301,  Loss1 0.774, Train_accy 74.56
2024-09-08 14:24:20,201 [foster.py] => SNet: Task 9, Epoch 53/130 => Loss 31.296,  Loss1 0.774, Train_accy 75.81
2024-09-08 14:24:26,131 [foster.py] => SNet: Task 9, Epoch 54/130 => Loss 31.314,  Loss1 0.774, Train_accy 75.74
2024-09-08 14:24:32,135 [foster.py] => SNet: Task 9, Epoch 55/130 => Loss 31.301,  Loss1 0.774, Train_accy 74.65
2024-09-08 14:24:39,461 [foster.py] => SNet: Task 9, Epoch 56/130 => Loss 31.307,  Loss1 0.774, Train_accy 75.12, Test_accy 63.99
2024-09-08 14:24:45,418 [foster.py] => SNet: Task 9, Epoch 57/130 => Loss 31.281,  Loss1 0.774, Train_accy 76.00
2024-09-08 14:24:51,406 [foster.py] => SNet: Task 9, Epoch 58/130 => Loss 31.290,  Loss1 0.774, Train_accy 75.33
2024-09-08 14:24:57,325 [foster.py] => SNet: Task 9, Epoch 59/130 => Loss 31.327,  Loss1 0.774, Train_accy 75.70
2024-09-08 14:25:03,328 [foster.py] => SNet: Task 9, Epoch 60/130 => Loss 31.291,  Loss1 0.774, Train_accy 76.26
2024-09-08 14:25:10,663 [foster.py] => SNet: Task 9, Epoch 61/130 => Loss 31.302,  Loss1 0.774, Train_accy 75.77, Test_accy 64.29
2024-09-08 14:25:16,675 [foster.py] => SNet: Task 9, Epoch 62/130 => Loss 31.298,  Loss1 0.774, Train_accy 75.23
2024-09-08 14:25:22,708 [foster.py] => SNet: Task 9, Epoch 63/130 => Loss 31.303,  Loss1 0.774, Train_accy 75.37
2024-09-08 14:25:28,715 [foster.py] => SNet: Task 9, Epoch 64/130 => Loss 31.317,  Loss1 0.774, Train_accy 76.35
2024-09-08 14:25:34,625 [foster.py] => SNet: Task 9, Epoch 65/130 => Loss 31.326,  Loss1 0.774, Train_accy 74.53
2024-09-08 14:25:41,913 [foster.py] => SNet: Task 9, Epoch 66/130 => Loss 31.271,  Loss1 0.774, Train_accy 76.42, Test_accy 63.87
2024-09-08 14:25:47,880 [foster.py] => SNet: Task 9, Epoch 67/130 => Loss 31.291,  Loss1 0.773, Train_accy 75.51
2024-09-08 14:25:53,828 [foster.py] => SNet: Task 9, Epoch 68/130 => Loss 31.314,  Loss1 0.774, Train_accy 75.88
2024-09-08 14:25:59,734 [foster.py] => SNet: Task 9, Epoch 69/130 => Loss 31.282,  Loss1 0.774, Train_accy 75.49
2024-09-08 14:26:05,761 [foster.py] => SNet: Task 9, Epoch 70/130 => Loss 31.275,  Loss1 0.774, Train_accy 76.14
2024-09-08 14:26:13,038 [foster.py] => SNet: Task 9, Epoch 71/130 => Loss 31.269,  Loss1 0.773, Train_accy 76.05, Test_accy 63.91
2024-09-08 14:26:19,083 [foster.py] => SNet: Task 9, Epoch 72/130 => Loss 31.292,  Loss1 0.774, Train_accy 77.56
2024-09-08 14:26:25,172 [foster.py] => SNet: Task 9, Epoch 73/130 => Loss 31.316,  Loss1 0.774, Train_accy 74.65
2024-09-08 14:26:31,126 [foster.py] => SNet: Task 9, Epoch 74/130 => Loss 31.307,  Loss1 0.774, Train_accy 76.58
2024-09-08 14:26:37,132 [foster.py] => SNet: Task 9, Epoch 75/130 => Loss 31.282,  Loss1 0.774, Train_accy 76.98
2024-09-08 14:26:44,393 [foster.py] => SNet: Task 9, Epoch 76/130 => Loss 31.297,  Loss1 0.773, Train_accy 76.16, Test_accy 64.05
2024-09-08 14:26:50,346 [foster.py] => SNet: Task 9, Epoch 77/130 => Loss 31.285,  Loss1 0.774, Train_accy 75.58
2024-09-08 14:26:56,304 [foster.py] => SNet: Task 9, Epoch 78/130 => Loss 31.325,  Loss1 0.774, Train_accy 75.98
2024-09-08 14:27:02,318 [foster.py] => SNet: Task 9, Epoch 79/130 => Loss 31.320,  Loss1 0.774, Train_accy 76.23
2024-09-08 14:27:08,301 [foster.py] => SNet: Task 9, Epoch 80/130 => Loss 31.289,  Loss1 0.774, Train_accy 75.09
2024-09-08 14:27:15,591 [foster.py] => SNet: Task 9, Epoch 81/130 => Loss 31.305,  Loss1 0.774, Train_accy 77.60, Test_accy 63.88
2024-09-08 14:27:21,583 [foster.py] => SNet: Task 9, Epoch 82/130 => Loss 31.279,  Loss1 0.774, Train_accy 75.53
2024-09-08 14:27:27,538 [foster.py] => SNet: Task 9, Epoch 83/130 => Loss 31.293,  Loss1 0.774, Train_accy 76.35
2024-09-08 14:27:33,510 [foster.py] => SNet: Task 9, Epoch 84/130 => Loss 31.273,  Loss1 0.774, Train_accy 75.91
2024-09-08 14:27:39,532 [foster.py] => SNet: Task 9, Epoch 85/130 => Loss 31.308,  Loss1 0.774, Train_accy 75.93
2024-09-08 14:27:46,851 [foster.py] => SNet: Task 9, Epoch 86/130 => Loss 31.305,  Loss1 0.774, Train_accy 76.98, Test_accy 64.04
2024-09-08 14:27:52,788 [foster.py] => SNet: Task 9, Epoch 87/130 => Loss 31.314,  Loss1 0.774, Train_accy 76.51
2024-09-08 14:27:58,755 [foster.py] => SNet: Task 9, Epoch 88/130 => Loss 31.266,  Loss1 0.773, Train_accy 76.07
2024-09-08 14:28:04,732 [foster.py] => SNet: Task 9, Epoch 89/130 => Loss 31.304,  Loss1 0.774, Train_accy 78.00
2024-09-08 14:28:10,733 [foster.py] => SNet: Task 9, Epoch 90/130 => Loss 31.304,  Loss1 0.774, Train_accy 75.86
2024-09-08 14:28:18,066 [foster.py] => SNet: Task 9, Epoch 91/130 => Loss 31.266,  Loss1 0.774, Train_accy 76.49, Test_accy 64.18
2024-09-08 14:28:24,050 [foster.py] => SNet: Task 9, Epoch 92/130 => Loss 31.326,  Loss1 0.774, Train_accy 75.65
2024-09-08 14:28:30,007 [foster.py] => SNet: Task 9, Epoch 93/130 => Loss 31.319,  Loss1 0.774, Train_accy 76.70
2024-09-08 14:28:35,917 [foster.py] => SNet: Task 9, Epoch 94/130 => Loss 31.291,  Loss1 0.774, Train_accy 76.42
2024-09-08 14:28:41,929 [foster.py] => SNet: Task 9, Epoch 95/130 => Loss 31.294,  Loss1 0.774, Train_accy 76.37
2024-09-08 14:28:49,236 [foster.py] => SNet: Task 9, Epoch 96/130 => Loss 31.291,  Loss1 0.774, Train_accy 76.00, Test_accy 63.84
2024-09-08 14:28:55,263 [foster.py] => SNet: Task 9, Epoch 97/130 => Loss 31.299,  Loss1 0.773, Train_accy 76.19
2024-09-08 14:29:01,215 [foster.py] => SNet: Task 9, Epoch 98/130 => Loss 31.304,  Loss1 0.774, Train_accy 76.30
2024-09-08 14:29:07,159 [foster.py] => SNet: Task 9, Epoch 99/130 => Loss 31.300,  Loss1 0.773, Train_accy 76.86
2024-09-08 14:29:13,094 [foster.py] => SNet: Task 9, Epoch 100/130 => Loss 31.300,  Loss1 0.774, Train_accy 75.65
2024-09-08 14:29:20,374 [foster.py] => SNet: Task 9, Epoch 101/130 => Loss 31.305,  Loss1 0.774, Train_accy 76.53, Test_accy 63.77
2024-09-08 14:29:26,308 [foster.py] => SNet: Task 9, Epoch 102/130 => Loss 31.280,  Loss1 0.774, Train_accy 76.88
2024-09-08 14:29:32,277 [foster.py] => SNet: Task 9, Epoch 103/130 => Loss 31.288,  Loss1 0.774, Train_accy 76.44
2024-09-08 14:29:38,244 [foster.py] => SNet: Task 9, Epoch 104/130 => Loss 31.308,  Loss1 0.773, Train_accy 76.56
2024-09-08 14:29:44,175 [foster.py] => SNet: Task 9, Epoch 105/130 => Loss 31.312,  Loss1 0.774, Train_accy 76.53
2024-09-08 14:29:51,449 [foster.py] => SNet: Task 9, Epoch 106/130 => Loss 31.289,  Loss1 0.774, Train_accy 77.12, Test_accy 64.33
2024-09-08 14:29:57,411 [foster.py] => SNet: Task 9, Epoch 107/130 => Loss 31.289,  Loss1 0.774, Train_accy 76.70
2024-09-08 14:30:03,380 [foster.py] => SNet: Task 9, Epoch 108/130 => Loss 31.302,  Loss1 0.774, Train_accy 76.23
2024-09-08 14:30:09,372 [foster.py] => SNet: Task 9, Epoch 109/130 => Loss 31.289,  Loss1 0.774, Train_accy 77.33
2024-09-08 14:30:15,313 [foster.py] => SNet: Task 9, Epoch 110/130 => Loss 31.262,  Loss1 0.774, Train_accy 76.12
2024-09-08 14:30:22,615 [foster.py] => SNet: Task 9, Epoch 111/130 => Loss 31.312,  Loss1 0.774, Train_accy 75.88, Test_accy 64.05
2024-09-08 14:30:28,581 [foster.py] => SNet: Task 9, Epoch 112/130 => Loss 31.299,  Loss1 0.773, Train_accy 76.79
2024-09-08 14:30:34,541 [foster.py] => SNet: Task 9, Epoch 113/130 => Loss 31.290,  Loss1 0.774, Train_accy 76.56
2024-09-08 14:30:40,545 [foster.py] => SNet: Task 9, Epoch 114/130 => Loss 31.296,  Loss1 0.774, Train_accy 76.63
2024-09-08 14:30:46,518 [foster.py] => SNet: Task 9, Epoch 115/130 => Loss 31.320,  Loss1 0.774, Train_accy 77.14
2024-09-08 14:30:53,805 [foster.py] => SNet: Task 9, Epoch 116/130 => Loss 31.314,  Loss1 0.774, Train_accy 76.98, Test_accy 64.15
2024-09-08 14:30:59,796 [foster.py] => SNet: Task 9, Epoch 117/130 => Loss 31.275,  Loss1 0.774, Train_accy 76.63
2024-09-08 14:31:05,772 [foster.py] => SNet: Task 9, Epoch 118/130 => Loss 31.270,  Loss1 0.774, Train_accy 77.40
2024-09-08 14:31:11,717 [foster.py] => SNet: Task 9, Epoch 119/130 => Loss 31.289,  Loss1 0.774, Train_accy 76.86
2024-09-08 14:31:17,696 [foster.py] => SNet: Task 9, Epoch 120/130 => Loss 31.248,  Loss1 0.774, Train_accy 76.77
2024-09-08 14:31:25,093 [foster.py] => SNet: Task 9, Epoch 121/130 => Loss 31.286,  Loss1 0.774, Train_accy 76.37, Test_accy 64.41
2024-09-08 14:31:31,012 [foster.py] => SNet: Task 9, Epoch 122/130 => Loss 31.277,  Loss1 0.774, Train_accy 76.95
2024-09-08 14:31:36,981 [foster.py] => SNet: Task 9, Epoch 123/130 => Loss 31.315,  Loss1 0.774, Train_accy 76.05
2024-09-08 14:31:42,934 [foster.py] => SNet: Task 9, Epoch 124/130 => Loss 31.308,  Loss1 0.774, Train_accy 76.09
2024-09-08 14:31:48,894 [foster.py] => SNet: Task 9, Epoch 125/130 => Loss 31.282,  Loss1 0.774, Train_accy 77.44
2024-09-08 14:31:56,200 [foster.py] => SNet: Task 9, Epoch 126/130 => Loss 31.296,  Loss1 0.774, Train_accy 77.33, Test_accy 64.29
2024-09-08 14:32:02,166 [foster.py] => SNet: Task 9, Epoch 127/130 => Loss 31.303,  Loss1 0.774, Train_accy 75.91
2024-09-08 14:32:08,114 [foster.py] => SNet: Task 9, Epoch 128/130 => Loss 31.297,  Loss1 0.774, Train_accy 77.26
2024-09-08 14:32:14,080 [foster.py] => SNet: Task 9, Epoch 129/130 => Loss 31.303,  Loss1 0.774, Train_accy 75.09
2024-09-08 14:32:20,088 [foster.py] => SNet: Task 9, Epoch 130/130 => Loss 31.279,  Loss1 0.773, Train_accy 76.88
2024-09-08 14:32:20,089 [foster.py] => do not weight align student!
2024-09-08 14:32:21,433 [foster.py] => darknet eval: 
2024-09-08 14:32:21,433 [foster.py] => CNN top1 curve: 64.06
2024-09-08 14:32:21,434 [foster.py] => CNN top5 curve: 88.99
2024-09-08 14:32:21,434 [foster.py] => CNN top1 平均值: 64.06
2024-09-08 14:32:21,439 [foster.py] => timees : 1829.543729543686
2024-09-08 14:32:21,440 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 14:32:51,798 [foster.py] => Exemplar size: 1900
2024-09-08 14:32:51,798 [trainer.py] => CNN: {'total': 65.99, '00-09': 71.8, '10-19': 58.0, '20-29': 70.7, '30-39': 63.5, '40-49': 69.8, '50-59': 53.7, '60-69': 67.7, '70-79': 64.5, '80-89': 68.2, '90-99': 78.0, 'old': 65.32, 'new': 78.0}
2024-09-08 14:32:51,799 [trainer.py] => NME: {'total': 61.0, '00-09': 61.2, '10-19': 50.7, '20-29': 64.8, '30-39': 57.7, '40-49': 64.1, '50-59': 53.6, '60-69': 65.8, '70-79': 65.9, '80-89': 55.0, '90-99': 81.4, 'old': 59.87, 'new': 81.4}
2024-09-08 14:32:51,799 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67, 69.88, 68.0, 66.68, 65.99]
2024-09-08 14:32:51,799 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05, 92.24, 91.41, 90.32, 89.67]
2024-09-08 14:32:51,800 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83, 64.05, 62.79, 62.28, 61.0]
2024-09-08 14:32:51,800 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79, 89.66, 89.24, 87.61, 86.41]

2024-09-08 14:32:51,800 [trainer.py] => CNN top1 平均值: 73.41
2024-09-08 14:32:51,803 [trainer.py] => All params: 1178828
2024-09-08 14:32:51,806 [trainer.py] => Trainable params: 595704
2024-09-08 14:32:51,866 [foster.py] => Learning on 95-100
2024-09-08 14:32:51,870 [foster.py] => All params: 1180123
2024-09-08 14:32:51,872 [foster.py] => Trainable params: 596674
2024-09-08 14:32:51,927 [foster.py] => per cls weights : [1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028
 1.01991028 1.01991028 1.01991028 1.01991028 1.01991028 0.62170467
 0.62170467 0.62170467 0.62170467 0.62170467]
2024-09-08 14:32:56,359 [foster.py] => Task 10, Epoch 1/170 => Loss 6.271, Loss_clf 1.510, Loss_fe 1.591, Loss_kd 3.009, Train_accy 57.57
2024-09-08 14:33:03,040 [foster.py] => Task 10, Epoch 2/170 => Loss 4.915, Loss_clf 0.863, Loss_fe 0.914, Loss_kd 2.979, Train_accy 67.34, Test_accy 62.29
2024-09-08 14:33:09,578 [foster.py] => Task 10, Epoch 3/170 => Loss 4.724, Loss_clf 0.800, Loss_fe 0.809, Loss_kd 2.957, Train_accy 69.02, Test_accy 63.01
2024-09-08 14:33:16,172 [foster.py] => Task 10, Epoch 4/170 => Loss 4.722, Loss_clf 0.809, Loss_fe 0.786, Loss_kd 2.969, Train_accy 70.57, Test_accy 62.42
2024-09-08 14:33:22,793 [foster.py] => Task 10, Epoch 5/170 => Loss 4.594, Loss_clf 0.759, Loss_fe 0.732, Loss_kd 2.946, Train_accy 70.64, Test_accy 63.09
2024-09-08 14:33:27,195 [foster.py] => Task 10, Epoch 6/170 => Loss 4.558, Loss_clf 0.737, Loss_fe 0.710, Loss_kd 2.954, Train_accy 71.86
2024-09-08 14:33:33,812 [foster.py] => Task 10, Epoch 7/170 => Loss 4.596, Loss_clf 0.778, Loss_fe 0.703, Loss_kd 2.957, Train_accy 70.00, Test_accy 62.78
2024-09-08 14:33:40,448 [foster.py] => Task 10, Epoch 8/170 => Loss 4.538, Loss_clf 0.743, Loss_fe 0.681, Loss_kd 2.956, Train_accy 71.70, Test_accy 63.25
2024-09-08 14:33:47,152 [foster.py] => Task 10, Epoch 9/170 => Loss 4.568, Loss_clf 0.756, Loss_fe 0.699, Loss_kd 2.955, Train_accy 71.95, Test_accy 63.17
2024-09-08 14:33:53,752 [foster.py] => Task 10, Epoch 10/170 => Loss 4.529, Loss_clf 0.744, Loss_fe 0.667, Loss_kd 2.961, Train_accy 71.80, Test_accy 61.78
2024-09-08 14:33:58,068 [foster.py] => Task 10, Epoch 11/170 => Loss 4.449, Loss_clf 0.694, Loss_fe 0.658, Loss_kd 2.940, Train_accy 72.84
2024-09-08 14:34:04,618 [foster.py] => Task 10, Epoch 12/170 => Loss 4.483, Loss_clf 0.724, Loss_fe 0.640, Loss_kd 2.961, Train_accy 73.02, Test_accy 62.18
2024-09-08 14:34:11,218 [foster.py] => Task 10, Epoch 13/170 => Loss 4.544, Loss_clf 0.744, Loss_fe 0.676, Loss_kd 2.966, Train_accy 71.84, Test_accy 62.25
2024-09-08 14:34:17,809 [foster.py] => Task 10, Epoch 14/170 => Loss 4.502, Loss_clf 0.719, Loss_fe 0.647, Loss_kd 2.976, Train_accy 73.48, Test_accy 63.14
2024-09-08 14:34:24,511 [foster.py] => Task 10, Epoch 15/170 => Loss 4.439, Loss_clf 0.702, Loss_fe 0.628, Loss_kd 2.952, Train_accy 73.45, Test_accy 63.31
2024-09-08 14:34:28,833 [foster.py] => Task 10, Epoch 16/170 => Loss 4.491, Loss_clf 0.733, Loss_fe 0.634, Loss_kd 2.966, Train_accy 72.64
2024-09-08 14:34:35,408 [foster.py] => Task 10, Epoch 17/170 => Loss 4.426, Loss_clf 0.700, Loss_fe 0.612, Loss_kd 2.956, Train_accy 72.89, Test_accy 63.11
2024-09-08 14:34:41,972 [foster.py] => Task 10, Epoch 18/170 => Loss 4.397, Loss_clf 0.683, Loss_fe 0.606, Loss_kd 2.951, Train_accy 73.98, Test_accy 62.54
2024-09-08 14:34:48,599 [foster.py] => Task 10, Epoch 19/170 => Loss 4.383, Loss_clf 0.681, Loss_fe 0.595, Loss_kd 2.950, Train_accy 73.07, Test_accy 63.09
2024-09-08 14:34:55,172 [foster.py] => Task 10, Epoch 20/170 => Loss 4.438, Loss_clf 0.706, Loss_fe 0.607, Loss_kd 2.967, Train_accy 73.39, Test_accy 62.34
2024-09-08 14:34:59,515 [foster.py] => Task 10, Epoch 21/170 => Loss 4.452, Loss_clf 0.716, Loss_fe 0.622, Loss_kd 2.956, Train_accy 71.95
2024-09-08 14:35:06,134 [foster.py] => Task 10, Epoch 22/170 => Loss 4.368, Loss_clf 0.670, Loss_fe 0.583, Loss_kd 2.957, Train_accy 73.95, Test_accy 62.73
2024-09-08 14:35:12,813 [foster.py] => Task 10, Epoch 23/170 => Loss 4.368, Loss_clf 0.675, Loss_fe 0.575, Loss_kd 2.960, Train_accy 74.27, Test_accy 62.84
2024-09-08 14:35:19,516 [foster.py] => Task 10, Epoch 24/170 => Loss 4.463, Loss_clf 0.718, Loss_fe 0.605, Loss_kd 2.982, Train_accy 73.45, Test_accy 63.44
2024-09-08 14:35:26,049 [foster.py] => Task 10, Epoch 25/170 => Loss 4.365, Loss_clf 0.688, Loss_fe 0.573, Loss_kd 2.947, Train_accy 74.34, Test_accy 63.22
2024-09-08 14:35:30,437 [foster.py] => Task 10, Epoch 26/170 => Loss 4.371, Loss_clf 0.676, Loss_fe 0.568, Loss_kd 2.968, Train_accy 74.43
2024-09-08 14:35:37,048 [foster.py] => Task 10, Epoch 27/170 => Loss 4.370, Loss_clf 0.677, Loss_fe 0.566, Loss_kd 2.969, Train_accy 73.68, Test_accy 62.58
2024-09-08 14:35:43,603 [foster.py] => Task 10, Epoch 28/170 => Loss 4.326, Loss_clf 0.665, Loss_fe 0.547, Loss_kd 2.956, Train_accy 75.45, Test_accy 63.18
2024-09-08 14:35:50,198 [foster.py] => Task 10, Epoch 29/170 => Loss 4.379, Loss_clf 0.705, Loss_fe 0.557, Loss_kd 2.960, Train_accy 74.14, Test_accy 63.50
2024-09-08 14:35:56,803 [foster.py] => Task 10, Epoch 30/170 => Loss 4.358, Loss_clf 0.668, Loss_fe 0.547, Loss_kd 2.985, Train_accy 74.73, Test_accy 63.38
2024-09-08 14:36:01,188 [foster.py] => Task 10, Epoch 31/170 => Loss 4.349, Loss_clf 0.682, Loss_fe 0.554, Loss_kd 2.955, Train_accy 75.25
2024-09-08 14:36:07,791 [foster.py] => Task 10, Epoch 32/170 => Loss 4.333, Loss_clf 0.673, Loss_fe 0.547, Loss_kd 2.955, Train_accy 73.61, Test_accy 63.70
2024-09-08 14:36:14,427 [foster.py] => Task 10, Epoch 33/170 => Loss 4.260, Loss_clf 0.638, Loss_fe 0.512, Loss_kd 2.952, Train_accy 75.45, Test_accy 62.93
2024-09-08 14:36:21,096 [foster.py] => Task 10, Epoch 34/170 => Loss 4.273, Loss_clf 0.650, Loss_fe 0.510, Loss_kd 2.955, Train_accy 74.68, Test_accy 62.91
2024-09-08 14:36:27,685 [foster.py] => Task 10, Epoch 35/170 => Loss 4.315, Loss_clf 0.657, Loss_fe 0.531, Loss_kd 2.969, Train_accy 75.52, Test_accy 63.81
2024-09-08 14:36:32,108 [foster.py] => Task 10, Epoch 36/170 => Loss 4.296, Loss_clf 0.650, Loss_fe 0.526, Loss_kd 2.962, Train_accy 76.30
2024-09-08 14:36:38,891 [foster.py] => Task 10, Epoch 37/170 => Loss 4.263, Loss_clf 0.629, Loss_fe 0.521, Loss_kd 2.956, Train_accy 75.66, Test_accy 62.46
2024-09-08 14:36:45,557 [foster.py] => Task 10, Epoch 38/170 => Loss 4.241, Loss_clf 0.619, Loss_fe 0.515, Loss_kd 2.950, Train_accy 75.64, Test_accy 61.26
2024-09-08 14:36:52,118 [foster.py] => Task 10, Epoch 39/170 => Loss 4.290, Loss_clf 0.647, Loss_fe 0.520, Loss_kd 2.966, Train_accy 75.43, Test_accy 63.63
2024-09-08 14:36:58,730 [foster.py] => Task 10, Epoch 40/170 => Loss 4.267, Loss_clf 0.637, Loss_fe 0.513, Loss_kd 2.958, Train_accy 75.18, Test_accy 62.56
2024-09-08 14:37:03,191 [foster.py] => Task 10, Epoch 41/170 => Loss 4.270, Loss_clf 0.649, Loss_fe 0.506, Loss_kd 2.958, Train_accy 75.52
2024-09-08 14:37:09,912 [foster.py] => Task 10, Epoch 42/170 => Loss 4.253, Loss_clf 0.621, Loss_fe 0.507, Loss_kd 2.967, Train_accy 76.43, Test_accy 63.14
2024-09-08 14:37:16,667 [foster.py] => Task 10, Epoch 43/170 => Loss 4.286, Loss_clf 0.652, Loss_fe 0.491, Loss_kd 2.985, Train_accy 75.20, Test_accy 62.97
2024-09-08 14:37:23,215 [foster.py] => Task 10, Epoch 44/170 => Loss 4.244, Loss_clf 0.627, Loss_fe 0.515, Loss_kd 2.946, Train_accy 75.70, Test_accy 63.23
2024-09-08 14:37:29,837 [foster.py] => Task 10, Epoch 45/170 => Loss 4.201, Loss_clf 0.612, Loss_fe 0.469, Loss_kd 2.962, Train_accy 76.98, Test_accy 63.09
2024-09-08 14:37:34,200 [foster.py] => Task 10, Epoch 46/170 => Loss 4.212, Loss_clf 0.631, Loss_fe 0.462, Loss_kd 2.961, Train_accy 76.55
2024-09-08 14:37:40,771 [foster.py] => Task 10, Epoch 47/170 => Loss 4.192, Loss_clf 0.616, Loss_fe 0.474, Loss_kd 2.946, Train_accy 77.16, Test_accy 63.53
2024-09-08 14:37:47,354 [foster.py] => Task 10, Epoch 48/170 => Loss 4.275, Loss_clf 0.648, Loss_fe 0.507, Loss_kd 2.962, Train_accy 74.91, Test_accy 62.24
2024-09-08 14:37:53,905 [foster.py] => Task 10, Epoch 49/170 => Loss 4.242, Loss_clf 0.624, Loss_fe 0.496, Loss_kd 2.964, Train_accy 76.43, Test_accy 63.03
2024-09-08 14:38:00,467 [foster.py] => Task 10, Epoch 50/170 => Loss 4.270, Loss_clf 0.648, Loss_fe 0.480, Loss_kd 2.983, Train_accy 76.52, Test_accy 63.53
2024-09-08 14:38:04,803 [foster.py] => Task 10, Epoch 51/170 => Loss 4.165, Loss_clf 0.589, Loss_fe 0.463, Loss_kd 2.955, Train_accy 77.80
2024-09-08 14:38:11,398 [foster.py] => Task 10, Epoch 52/170 => Loss 4.184, Loss_clf 0.610, Loss_fe 0.462, Loss_kd 2.955, Train_accy 76.43, Test_accy 63.03
2024-09-08 14:38:17,988 [foster.py] => Task 10, Epoch 53/170 => Loss 4.192, Loss_clf 0.600, Loss_fe 0.470, Loss_kd 2.964, Train_accy 77.30, Test_accy 62.76
2024-09-08 14:38:24,594 [foster.py] => Task 10, Epoch 54/170 => Loss 4.207, Loss_clf 0.608, Loss_fe 0.474, Loss_kd 2.967, Train_accy 76.84, Test_accy 63.68
2024-09-08 14:38:31,195 [foster.py] => Task 10, Epoch 55/170 => Loss 4.192, Loss_clf 0.607, Loss_fe 0.458, Loss_kd 2.969, Train_accy 77.09, Test_accy 63.18
2024-09-08 14:38:35,530 [foster.py] => Task 10, Epoch 56/170 => Loss 4.195, Loss_clf 0.619, Loss_fe 0.456, Loss_kd 2.962, Train_accy 76.95
2024-09-08 14:38:42,326 [foster.py] => Task 10, Epoch 57/170 => Loss 4.215, Loss_clf 0.609, Loss_fe 0.490, Loss_kd 2.959, Train_accy 76.34, Test_accy 63.27
2024-09-08 14:38:49,016 [foster.py] => Task 10, Epoch 58/170 => Loss 4.159, Loss_clf 0.602, Loss_fe 0.452, Loss_kd 2.948, Train_accy 76.82, Test_accy 63.63
2024-09-08 14:38:55,613 [foster.py] => Task 10, Epoch 59/170 => Loss 4.147, Loss_clf 0.588, Loss_fe 0.449, Loss_kd 2.954, Train_accy 77.84, Test_accy 63.04
2024-09-08 14:39:02,325 [foster.py] => Task 10, Epoch 60/170 => Loss 4.151, Loss_clf 0.593, Loss_fe 0.439, Loss_kd 2.961, Train_accy 77.98, Test_accy 62.70
2024-09-08 14:39:06,635 [foster.py] => Task 10, Epoch 61/170 => Loss 4.155, Loss_clf 0.600, Loss_fe 0.432, Loss_kd 2.966, Train_accy 76.80
2024-09-08 14:39:13,210 [foster.py] => Task 10, Epoch 62/170 => Loss 4.112, Loss_clf 0.576, Loss_fe 0.425, Loss_kd 2.953, Train_accy 77.80, Test_accy 63.59
2024-09-08 14:39:19,881 [foster.py] => Task 10, Epoch 63/170 => Loss 4.127, Loss_clf 0.581, Loss_fe 0.419, Loss_kd 2.969, Train_accy 78.18, Test_accy 63.21
2024-09-08 14:39:26,449 [foster.py] => Task 10, Epoch 64/170 => Loss 4.175, Loss_clf 0.607, Loss_fe 0.449, Loss_kd 2.961, Train_accy 77.57, Test_accy 63.82
2024-09-08 14:39:33,115 [foster.py] => Task 10, Epoch 65/170 => Loss 4.095, Loss_clf 0.574, Loss_fe 0.418, Loss_kd 2.946, Train_accy 77.45, Test_accy 63.33
2024-09-08 14:39:37,413 [foster.py] => Task 10, Epoch 66/170 => Loss 4.113, Loss_clf 0.587, Loss_fe 0.420, Loss_kd 2.949, Train_accy 76.89
2024-09-08 14:39:44,113 [foster.py] => Task 10, Epoch 67/170 => Loss 4.164, Loss_clf 0.604, Loss_fe 0.424, Loss_kd 2.977, Train_accy 76.48, Test_accy 63.43
2024-09-08 14:39:50,646 [foster.py] => Task 10, Epoch 68/170 => Loss 4.077, Loss_clf 0.565, Loss_fe 0.411, Loss_kd 2.944, Train_accy 78.70, Test_accy 63.55
2024-09-08 14:39:57,151 [foster.py] => Task 10, Epoch 69/170 => Loss 4.055, Loss_clf 0.556, Loss_fe 0.380, Loss_kd 2.961, Train_accy 78.30, Test_accy 63.60
2024-09-08 14:40:03,747 [foster.py] => Task 10, Epoch 70/170 => Loss 4.082, Loss_clf 0.561, Loss_fe 0.415, Loss_kd 2.950, Train_accy 77.66, Test_accy 63.23
2024-09-08 14:40:08,141 [foster.py] => Task 10, Epoch 71/170 => Loss 4.155, Loss_clf 0.603, Loss_fe 0.421, Loss_kd 2.973, Train_accy 77.80
2024-09-08 14:40:14,717 [foster.py] => Task 10, Epoch 72/170 => Loss 4.151, Loss_clf 0.605, Loss_fe 0.433, Loss_kd 2.956, Train_accy 77.23, Test_accy 63.44
2024-09-08 14:40:21,313 [foster.py] => Task 10, Epoch 73/170 => Loss 4.024, Loss_clf 0.540, Loss_fe 0.394, Loss_kd 2.934, Train_accy 78.39, Test_accy 63.64
2024-09-08 14:40:27,914 [foster.py] => Task 10, Epoch 74/170 => Loss 4.095, Loss_clf 0.577, Loss_fe 0.386, Loss_kd 2.974, Train_accy 78.11, Test_accy 63.45
2024-09-08 14:40:34,583 [foster.py] => Task 10, Epoch 75/170 => Loss 4.047, Loss_clf 0.541, Loss_fe 0.392, Loss_kd 2.957, Train_accy 79.64, Test_accy 63.03
2024-09-08 14:40:38,895 [foster.py] => Task 10, Epoch 76/170 => Loss 4.052, Loss_clf 0.554, Loss_fe 0.379, Loss_kd 2.962, Train_accy 78.68
2024-09-08 14:40:45,474 [foster.py] => Task 10, Epoch 77/170 => Loss 4.064, Loss_clf 0.562, Loss_fe 0.386, Loss_kd 2.958, Train_accy 79.50, Test_accy 63.60
2024-09-08 14:40:52,046 [foster.py] => Task 10, Epoch 78/170 => Loss 4.110, Loss_clf 0.569, Loss_fe 0.410, Loss_kd 2.973, Train_accy 78.70, Test_accy 63.75
2024-09-08 14:40:58,728 [foster.py] => Task 10, Epoch 79/170 => Loss 4.021, Loss_clf 0.543, Loss_fe 0.351, Loss_kd 2.969, Train_accy 79.23, Test_accy 63.66
2024-09-08 14:41:05,396 [foster.py] => Task 10, Epoch 80/170 => Loss 4.066, Loss_clf 0.557, Loss_fe 0.361, Loss_kd 2.989, Train_accy 78.86, Test_accy 63.78
2024-09-08 14:41:09,753 [foster.py] => Task 10, Epoch 81/170 => Loss 4.008, Loss_clf 0.546, Loss_fe 0.363, Loss_kd 2.942, Train_accy 79.93
2024-09-08 14:41:16,357 [foster.py] => Task 10, Epoch 82/170 => Loss 4.054, Loss_clf 0.564, Loss_fe 0.369, Loss_kd 2.963, Train_accy 78.48, Test_accy 63.65
2024-09-08 14:41:22,953 [foster.py] => Task 10, Epoch 83/170 => Loss 4.027, Loss_clf 0.538, Loss_fe 0.382, Loss_kd 2.949, Train_accy 79.80, Test_accy 63.80
2024-09-08 14:41:29,619 [foster.py] => Task 10, Epoch 84/170 => Loss 4.018, Loss_clf 0.533, Loss_fe 0.365, Loss_kd 2.962, Train_accy 78.91, Test_accy 63.75
2024-09-08 14:41:36,330 [foster.py] => Task 10, Epoch 85/170 => Loss 4.031, Loss_clf 0.550, Loss_fe 0.368, Loss_kd 2.956, Train_accy 80.52, Test_accy 63.82
2024-09-08 14:41:40,651 [foster.py] => Task 10, Epoch 86/170 => Loss 4.013, Loss_clf 0.546, Loss_fe 0.356, Loss_kd 2.953, Train_accy 78.84
2024-09-08 14:41:47,369 [foster.py] => Task 10, Epoch 87/170 => Loss 4.019, Loss_clf 0.548, Loss_fe 0.367, Loss_kd 2.947, Train_accy 78.84, Test_accy 63.40
2024-09-08 14:41:53,911 [foster.py] => Task 10, Epoch 88/170 => Loss 3.972, Loss_clf 0.525, Loss_fe 0.342, Loss_kd 2.948, Train_accy 80.09, Test_accy 63.60
2024-09-08 14:42:00,502 [foster.py] => Task 10, Epoch 89/170 => Loss 3.990, Loss_clf 0.534, Loss_fe 0.339, Loss_kd 2.960, Train_accy 79.32, Test_accy 63.58
2024-09-08 14:42:07,160 [foster.py] => Task 10, Epoch 90/170 => Loss 3.963, Loss_clf 0.507, Loss_fe 0.328, Loss_kd 2.969, Train_accy 80.93, Test_accy 63.96
2024-09-08 14:42:11,455 [foster.py] => Task 10, Epoch 91/170 => Loss 3.941, Loss_clf 0.509, Loss_fe 0.326, Loss_kd 2.949, Train_accy 81.50
2024-09-08 14:42:18,094 [foster.py] => Task 10, Epoch 92/170 => Loss 3.930, Loss_clf 0.501, Loss_fe 0.309, Loss_kd 2.962, Train_accy 80.59, Test_accy 63.75
2024-09-08 14:42:24,642 [foster.py] => Task 10, Epoch 93/170 => Loss 3.953, Loss_clf 0.525, Loss_fe 0.317, Loss_kd 2.954, Train_accy 79.95, Test_accy 63.91
2024-09-08 14:42:31,403 [foster.py] => Task 10, Epoch 94/170 => Loss 4.015, Loss_clf 0.541, Loss_fe 0.341, Loss_kd 2.975, Train_accy 80.61, Test_accy 63.75
2024-09-08 14:42:37,994 [foster.py] => Task 10, Epoch 95/170 => Loss 3.963, Loss_clf 0.514, Loss_fe 0.339, Loss_kd 2.953, Train_accy 81.48, Test_accy 63.29
2024-09-08 14:42:42,338 [foster.py] => Task 10, Epoch 96/170 => Loss 3.954, Loss_clf 0.520, Loss_fe 0.308, Loss_kd 2.967, Train_accy 81.27
2024-09-08 14:42:48,960 [foster.py] => Task 10, Epoch 97/170 => Loss 3.958, Loss_clf 0.517, Loss_fe 0.331, Loss_kd 2.953, Train_accy 81.11, Test_accy 63.74
2024-09-08 14:42:55,650 [foster.py] => Task 10, Epoch 98/170 => Loss 3.926, Loss_clf 0.496, Loss_fe 0.315, Loss_kd 2.958, Train_accy 80.80, Test_accy 63.36
2024-09-08 14:43:02,384 [foster.py] => Task 10, Epoch 99/170 => Loss 3.974, Loss_clf 0.527, Loss_fe 0.322, Loss_kd 2.967, Train_accy 81.32, Test_accy 63.75
2024-09-08 14:43:08,951 [foster.py] => Task 10, Epoch 100/170 => Loss 3.913, Loss_clf 0.501, Loss_fe 0.298, Loss_kd 2.957, Train_accy 81.43, Test_accy 63.47
2024-09-08 14:43:13,371 [foster.py] => Task 10, Epoch 101/170 => Loss 3.910, Loss_clf 0.489, Loss_fe 0.299, Loss_kd 2.964, Train_accy 81.80
2024-09-08 14:43:20,002 [foster.py] => Task 10, Epoch 102/170 => Loss 3.931, Loss_clf 0.501, Loss_fe 0.307, Loss_kd 2.965, Train_accy 81.93, Test_accy 63.84
2024-09-08 14:43:26,604 [foster.py] => Task 10, Epoch 103/170 => Loss 3.963, Loss_clf 0.530, Loss_fe 0.305, Loss_kd 2.969, Train_accy 81.14, Test_accy 63.89
2024-09-08 14:43:33,188 [foster.py] => Task 10, Epoch 104/170 => Loss 3.916, Loss_clf 0.494, Loss_fe 0.294, Loss_kd 2.971, Train_accy 81.84, Test_accy 63.86
2024-09-08 14:43:39,868 [foster.py] => Task 10, Epoch 105/170 => Loss 3.934, Loss_clf 0.509, Loss_fe 0.301, Loss_kd 2.966, Train_accy 81.02, Test_accy 63.96
2024-09-08 14:43:44,185 [foster.py] => Task 10, Epoch 106/170 => Loss 3.883, Loss_clf 0.482, Loss_fe 0.286, Loss_kd 2.957, Train_accy 81.91
2024-09-08 14:43:50,805 [foster.py] => Task 10, Epoch 107/170 => Loss 3.899, Loss_clf 0.490, Loss_fe 0.283, Loss_kd 2.968, Train_accy 82.00, Test_accy 64.36
2024-09-08 14:43:57,350 [foster.py] => Task 10, Epoch 108/170 => Loss 3.885, Loss_clf 0.489, Loss_fe 0.276, Loss_kd 2.963, Train_accy 82.43, Test_accy 63.80
2024-09-08 14:44:03,923 [foster.py] => Task 10, Epoch 109/170 => Loss 3.892, Loss_clf 0.491, Loss_fe 0.296, Loss_kd 2.949, Train_accy 82.45, Test_accy 63.66
2024-09-08 14:44:10,586 [foster.py] => Task 10, Epoch 110/170 => Loss 3.860, Loss_clf 0.473, Loss_fe 0.275, Loss_kd 2.955, Train_accy 82.11, Test_accy 63.96
2024-09-08 14:44:14,920 [foster.py] => Task 10, Epoch 111/170 => Loss 3.828, Loss_clf 0.460, Loss_fe 0.270, Loss_kd 2.941, Train_accy 82.73
2024-09-08 14:44:21,490 [foster.py] => Task 10, Epoch 112/170 => Loss 3.846, Loss_clf 0.478, Loss_fe 0.252, Loss_kd 2.959, Train_accy 83.30, Test_accy 63.85
2024-09-08 14:44:28,245 [foster.py] => Task 10, Epoch 113/170 => Loss 3.864, Loss_clf 0.485, Loss_fe 0.256, Loss_kd 2.966, Train_accy 83.25, Test_accy 63.88
2024-09-08 14:44:34,868 [foster.py] => Task 10, Epoch 114/170 => Loss 3.924, Loss_clf 0.501, Loss_fe 0.281, Loss_kd 2.983, Train_accy 82.95, Test_accy 63.75
2024-09-08 14:44:41,453 [foster.py] => Task 10, Epoch 115/170 => Loss 3.875, Loss_clf 0.479, Loss_fe 0.272, Loss_kd 2.966, Train_accy 82.91, Test_accy 64.32
2024-09-08 14:44:45,846 [foster.py] => Task 10, Epoch 116/170 => Loss 3.866, Loss_clf 0.491, Loss_fe 0.260, Loss_kd 2.957, Train_accy 83.16
2024-09-08 14:44:52,422 [foster.py] => Task 10, Epoch 117/170 => Loss 3.849, Loss_clf 0.471, Loss_fe 0.264, Loss_kd 2.957, Train_accy 82.82, Test_accy 64.06
2024-09-08 14:44:58,998 [foster.py] => Task 10, Epoch 118/170 => Loss 3.892, Loss_clf 0.500, Loss_fe 0.263, Loss_kd 2.971, Train_accy 82.93, Test_accy 64.35
2024-09-08 14:45:05,604 [foster.py] => Task 10, Epoch 119/170 => Loss 3.819, Loss_clf 0.460, Loss_fe 0.236, Loss_kd 2.965, Train_accy 83.27, Test_accy 64.15
2024-09-08 14:45:12,157 [foster.py] => Task 10, Epoch 120/170 => Loss 3.805, Loss_clf 0.460, Loss_fe 0.230, Loss_kd 2.958, Train_accy 84.00, Test_accy 64.29
2024-09-08 14:45:16,556 [foster.py] => Task 10, Epoch 121/170 => Loss 3.812, Loss_clf 0.456, Loss_fe 0.243, Loss_kd 2.956, Train_accy 84.48
2024-09-08 14:45:23,223 [foster.py] => Task 10, Epoch 122/170 => Loss 3.847, Loss_clf 0.490, Loss_fe 0.242, Loss_kd 2.958, Train_accy 82.98, Test_accy 64.10
2024-09-08 14:45:29,866 [foster.py] => Task 10, Epoch 123/170 => Loss 3.872, Loss_clf 0.498, Loss_fe 0.244, Loss_kd 2.972, Train_accy 82.82, Test_accy 64.19
2024-09-08 14:45:36,534 [foster.py] => Task 10, Epoch 124/170 => Loss 3.803, Loss_clf 0.456, Loss_fe 0.229, Loss_kd 2.960, Train_accy 83.91, Test_accy 64.32
2024-09-08 14:45:43,167 [foster.py] => Task 10, Epoch 125/170 => Loss 3.791, Loss_clf 0.442, Loss_fe 0.232, Loss_kd 2.958, Train_accy 84.93, Test_accy 64.06
2024-09-08 14:45:47,552 [foster.py] => Task 10, Epoch 126/170 => Loss 3.829, Loss_clf 0.459, Loss_fe 0.246, Loss_kd 2.966, Train_accy 84.30
2024-09-08 14:45:54,193 [foster.py] => Task 10, Epoch 127/170 => Loss 3.846, Loss_clf 0.476, Loss_fe 0.242, Loss_kd 2.969, Train_accy 83.18, Test_accy 64.01
2024-09-08 14:46:00,868 [foster.py] => Task 10, Epoch 128/170 => Loss 3.819, Loss_clf 0.468, Loss_fe 0.232, Loss_kd 2.961, Train_accy 83.89, Test_accy 64.34
2024-09-08 14:46:07,575 [foster.py] => Task 10, Epoch 129/170 => Loss 3.749, Loss_clf 0.429, Loss_fe 0.224, Loss_kd 2.940, Train_accy 84.00, Test_accy 64.07
2024-09-08 14:46:14,206 [foster.py] => Task 10, Epoch 130/170 => Loss 3.824, Loss_clf 0.462, Loss_fe 0.228, Loss_kd 2.976, Train_accy 83.73, Test_accy 64.35
2024-09-08 14:46:18,551 [foster.py] => Task 10, Epoch 131/170 => Loss 3.766, Loss_clf 0.436, Loss_fe 0.213, Loss_kd 2.960, Train_accy 84.75
2024-09-08 14:46:25,228 [foster.py] => Task 10, Epoch 132/170 => Loss 3.774, Loss_clf 0.440, Loss_fe 0.218, Loss_kd 2.958, Train_accy 84.66, Test_accy 64.41
2024-09-08 14:46:31,742 [foster.py] => Task 10, Epoch 133/170 => Loss 3.773, Loss_clf 0.447, Loss_fe 0.216, Loss_kd 2.953, Train_accy 83.66, Test_accy 64.21
2024-09-08 14:46:38,469 [foster.py] => Task 10, Epoch 134/170 => Loss 3.799, Loss_clf 0.458, Loss_fe 0.222, Loss_kd 2.961, Train_accy 84.02, Test_accy 64.27
2024-09-08 14:46:45,031 [foster.py] => Task 10, Epoch 135/170 => Loss 3.790, Loss_clf 0.444, Loss_fe 0.218, Loss_kd 2.970, Train_accy 84.64, Test_accy 64.15
2024-09-08 14:46:49,345 [foster.py] => Task 10, Epoch 136/170 => Loss 3.690, Loss_clf 0.393, Loss_fe 0.192, Loss_kd 2.948, Train_accy 85.23
2024-09-08 14:46:55,968 [foster.py] => Task 10, Epoch 137/170 => Loss 3.726, Loss_clf 0.415, Loss_fe 0.199, Loss_kd 2.954, Train_accy 85.14, Test_accy 64.35
2024-09-08 14:47:02,619 [foster.py] => Task 10, Epoch 138/170 => Loss 3.775, Loss_clf 0.450, Loss_fe 0.208, Loss_kd 2.959, Train_accy 83.86, Test_accy 64.23
2024-09-08 14:47:09,247 [foster.py] => Task 10, Epoch 139/170 => Loss 3.735, Loss_clf 0.427, Loss_fe 0.195, Loss_kd 2.956, Train_accy 84.95, Test_accy 64.18
2024-09-08 14:47:15,913 [foster.py] => Task 10, Epoch 140/170 => Loss 3.744, Loss_clf 0.430, Loss_fe 0.190, Loss_kd 2.967, Train_accy 85.48, Test_accy 64.21
2024-09-08 14:47:20,383 [foster.py] => Task 10, Epoch 141/170 => Loss 3.748, Loss_clf 0.432, Loss_fe 0.197, Loss_kd 2.961, Train_accy 86.00
2024-09-08 14:47:26,961 [foster.py] => Task 10, Epoch 142/170 => Loss 3.789, Loss_clf 0.452, Loss_fe 0.204, Loss_kd 2.974, Train_accy 85.02, Test_accy 64.22
2024-09-08 14:47:33,520 [foster.py] => Task 10, Epoch 143/170 => Loss 3.776, Loss_clf 0.440, Loss_fe 0.199, Loss_kd 2.978, Train_accy 84.61, Test_accy 64.09
2024-09-08 14:47:40,034 [foster.py] => Task 10, Epoch 144/170 => Loss 3.747, Loss_clf 0.429, Loss_fe 0.195, Loss_kd 2.965, Train_accy 85.91, Test_accy 64.30
2024-09-08 14:47:46,692 [foster.py] => Task 10, Epoch 145/170 => Loss 3.716, Loss_clf 0.419, Loss_fe 0.186, Loss_kd 2.953, Train_accy 85.23, Test_accy 64.35
2024-09-08 14:47:50,962 [foster.py] => Task 10, Epoch 146/170 => Loss 3.716, Loss_clf 0.417, Loss_fe 0.180, Loss_kd 2.962, Train_accy 85.80
2024-09-08 14:47:57,624 [foster.py] => Task 10, Epoch 147/170 => Loss 3.732, Loss_clf 0.430, Loss_fe 0.186, Loss_kd 2.959, Train_accy 84.86, Test_accy 64.48
2024-09-08 14:48:04,212 [foster.py] => Task 10, Epoch 148/170 => Loss 3.733, Loss_clf 0.416, Loss_fe 0.192, Loss_kd 2.968, Train_accy 85.75, Test_accy 64.56
2024-09-08 14:48:10,786 [foster.py] => Task 10, Epoch 149/170 => Loss 3.714, Loss_clf 0.418, Loss_fe 0.175, Loss_kd 2.963, Train_accy 85.45, Test_accy 64.36
2024-09-08 14:48:17,471 [foster.py] => Task 10, Epoch 150/170 => Loss 3.701, Loss_clf 0.410, Loss_fe 0.174, Loss_kd 2.960, Train_accy 85.52, Test_accy 64.40
2024-09-08 14:48:21,819 [foster.py] => Task 10, Epoch 151/170 => Loss 3.711, Loss_clf 0.417, Loss_fe 0.182, Loss_kd 2.955, Train_accy 85.55
2024-09-08 14:48:28,520 [foster.py] => Task 10, Epoch 152/170 => Loss 3.742, Loss_clf 0.431, Loss_fe 0.191, Loss_kd 2.963, Train_accy 85.34, Test_accy 64.43
2024-09-08 14:48:35,112 [foster.py] => Task 10, Epoch 153/170 => Loss 3.727, Loss_clf 0.425, Loss_fe 0.180, Loss_kd 2.964, Train_accy 85.16, Test_accy 64.39
2024-09-08 14:48:41,736 [foster.py] => Task 10, Epoch 154/170 => Loss 3.714, Loss_clf 0.416, Loss_fe 0.179, Loss_kd 2.960, Train_accy 85.39, Test_accy 64.34
2024-09-08 14:48:48,456 [foster.py] => Task 10, Epoch 155/170 => Loss 3.705, Loss_clf 0.414, Loss_fe 0.183, Loss_kd 2.951, Train_accy 85.86, Test_accy 64.42
2024-09-08 14:48:52,889 [foster.py] => Task 10, Epoch 156/170 => Loss 3.735, Loss_clf 0.423, Loss_fe 0.193, Loss_kd 2.962, Train_accy 85.45
2024-09-08 14:48:59,496 [foster.py] => Task 10, Epoch 157/170 => Loss 3.686, Loss_clf 0.405, Loss_fe 0.173, Loss_kd 2.952, Train_accy 85.98, Test_accy 64.49
2024-09-08 14:49:06,118 [foster.py] => Task 10, Epoch 158/170 => Loss 3.737, Loss_clf 0.426, Loss_fe 0.186, Loss_kd 2.968, Train_accy 85.80, Test_accy 64.48
2024-09-08 14:49:12,779 [foster.py] => Task 10, Epoch 159/170 => Loss 3.715, Loss_clf 0.418, Loss_fe 0.176, Loss_kd 2.963, Train_accy 85.68, Test_accy 64.56
2024-09-08 14:49:19,444 [foster.py] => Task 10, Epoch 160/170 => Loss 3.739, Loss_clf 0.429, Loss_fe 0.177, Loss_kd 2.975, Train_accy 85.82, Test_accy 64.45
2024-09-08 14:49:23,706 [foster.py] => Task 10, Epoch 161/170 => Loss 3.722, Loss_clf 0.418, Loss_fe 0.191, Loss_kd 2.956, Train_accy 85.61
2024-09-08 14:49:30,325 [foster.py] => Task 10, Epoch 162/170 => Loss 3.710, Loss_clf 0.422, Loss_fe 0.176, Loss_kd 2.954, Train_accy 85.64, Test_accy 64.46
2024-09-08 14:49:37,074 [foster.py] => Task 10, Epoch 163/170 => Loss 3.697, Loss_clf 0.416, Loss_fe 0.174, Loss_kd 2.950, Train_accy 85.55, Test_accy 64.55
2024-09-08 14:49:43,681 [foster.py] => Task 10, Epoch 164/170 => Loss 3.720, Loss_clf 0.425, Loss_fe 0.180, Loss_kd 2.957, Train_accy 85.39, Test_accy 64.49
2024-09-08 14:49:50,314 [foster.py] => Task 10, Epoch 165/170 => Loss 3.737, Loss_clf 0.423, Loss_fe 0.177, Loss_kd 2.977, Train_accy 85.82, Test_accy 64.44
2024-09-08 14:49:54,595 [foster.py] => Task 10, Epoch 166/170 => Loss 3.751, Loss_clf 0.444, Loss_fe 0.184, Loss_kd 2.965, Train_accy 85.16
2024-09-08 14:50:01,150 [foster.py] => Task 10, Epoch 167/170 => Loss 3.748, Loss_clf 0.437, Loss_fe 0.185, Loss_kd 2.968, Train_accy 85.80, Test_accy 64.50
2024-09-08 14:50:07,774 [foster.py] => Task 10, Epoch 168/170 => Loss 3.748, Loss_clf 0.434, Loss_fe 0.194, Loss_kd 2.962, Train_accy 85.23, Test_accy 64.48
2024-09-08 14:50:14,417 [foster.py] => Task 10, Epoch 169/170 => Loss 3.699, Loss_clf 0.404, Loss_fe 0.179, Loss_kd 2.959, Train_accy 85.77, Test_accy 64.46
2024-09-08 14:50:20,984 [foster.py] => Task 10, Epoch 170/170 => Loss 3.707, Loss_clf 0.417, Loss_fe 0.195, Loss_kd 2.940, Train_accy 85.52, Test_accy 64.42
2024-09-08 14:50:20,986 [foster.py] => do not weight align teacher!
2024-09-08 14:50:20,988 [foster.py] => per cls weights : [1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674
 1.02439674 1.02439674 1.02439674 1.02439674 1.02439674 0.536462
 0.536462   0.536462   0.536462   0.536462  ]
2024-09-08 14:50:28,691 [foster.py] => SNet: Task 10, Epoch 1/130 => Loss 31.842,  Loss1 0.792, Train_accy 44.07, Test_accy 60.44
2024-09-08 14:50:34,802 [foster.py] => SNet: Task 10, Epoch 2/130 => Loss 31.780,  Loss1 0.791, Train_accy 55.80
2024-09-08 14:50:40,910 [foster.py] => SNet: Task 10, Epoch 3/130 => Loss 31.757,  Loss1 0.791, Train_accy 58.77
2024-09-08 14:50:47,012 [foster.py] => SNet: Task 10, Epoch 4/130 => Loss 31.766,  Loss1 0.791, Train_accy 62.00
2024-09-08 14:50:53,111 [foster.py] => SNet: Task 10, Epoch 5/130 => Loss 31.736,  Loss1 0.791, Train_accy 62.66
2024-09-08 14:51:00,624 [foster.py] => SNet: Task 10, Epoch 6/130 => Loss 31.741,  Loss1 0.791, Train_accy 64.77, Test_accy 61.84
2024-09-08 14:51:06,727 [foster.py] => SNet: Task 10, Epoch 7/130 => Loss 31.743,  Loss1 0.791, Train_accy 64.50
2024-09-08 14:51:12,899 [foster.py] => SNet: Task 10, Epoch 8/130 => Loss 31.711,  Loss1 0.791, Train_accy 65.02
2024-09-08 14:51:19,009 [foster.py] => SNet: Task 10, Epoch 9/130 => Loss 31.730,  Loss1 0.791, Train_accy 65.41
2024-09-08 14:51:25,135 [foster.py] => SNet: Task 10, Epoch 10/130 => Loss 31.753,  Loss1 0.791, Train_accy 66.16
2024-09-08 14:51:32,637 [foster.py] => SNet: Task 10, Epoch 11/130 => Loss 31.721,  Loss1 0.791, Train_accy 66.98, Test_accy 62.67
2024-09-08 14:51:38,755 [foster.py] => SNet: Task 10, Epoch 12/130 => Loss 31.734,  Loss1 0.791, Train_accy 67.77
2024-09-08 14:51:44,867 [foster.py] => SNet: Task 10, Epoch 13/130 => Loss 31.715,  Loss1 0.791, Train_accy 67.07
2024-09-08 14:51:50,996 [foster.py] => SNet: Task 10, Epoch 14/130 => Loss 31.739,  Loss1 0.791, Train_accy 67.93
2024-09-08 14:51:57,124 [foster.py] => SNet: Task 10, Epoch 15/130 => Loss 31.740,  Loss1 0.791, Train_accy 68.05
2024-09-08 14:52:04,632 [foster.py] => SNet: Task 10, Epoch 16/130 => Loss 31.726,  Loss1 0.791, Train_accy 68.18, Test_accy 63.01
2024-09-08 14:52:10,783 [foster.py] => SNet: Task 10, Epoch 17/130 => Loss 31.724,  Loss1 0.791, Train_accy 69.77
2024-09-08 14:52:16,881 [foster.py] => SNet: Task 10, Epoch 18/130 => Loss 31.748,  Loss1 0.791, Train_accy 68.32
2024-09-08 14:52:22,995 [foster.py] => SNet: Task 10, Epoch 19/130 => Loss 31.748,  Loss1 0.791, Train_accy 68.52
2024-09-08 14:52:29,149 [foster.py] => SNet: Task 10, Epoch 20/130 => Loss 31.726,  Loss1 0.791, Train_accy 68.18
2024-09-08 14:52:36,693 [foster.py] => SNet: Task 10, Epoch 21/130 => Loss 31.683,  Loss1 0.791, Train_accy 69.23, Test_accy 63.19
2024-09-08 14:52:42,802 [foster.py] => SNet: Task 10, Epoch 22/130 => Loss 31.662,  Loss1 0.791, Train_accy 69.20
2024-09-08 14:52:48,938 [foster.py] => SNet: Task 10, Epoch 23/130 => Loss 31.694,  Loss1 0.791, Train_accy 68.61
2024-09-08 14:52:55,090 [foster.py] => SNet: Task 10, Epoch 24/130 => Loss 31.700,  Loss1 0.791, Train_accy 69.86
2024-09-08 14:53:01,238 [foster.py] => SNet: Task 10, Epoch 25/130 => Loss 31.702,  Loss1 0.791, Train_accy 69.98
2024-09-08 14:53:08,804 [foster.py] => SNet: Task 10, Epoch 26/130 => Loss 31.722,  Loss1 0.792, Train_accy 69.73, Test_accy 62.98
2024-09-08 14:53:14,943 [foster.py] => SNet: Task 10, Epoch 27/130 => Loss 31.723,  Loss1 0.791, Train_accy 68.84
2024-09-08 14:53:21,041 [foster.py] => SNet: Task 10, Epoch 28/130 => Loss 31.708,  Loss1 0.791, Train_accy 69.43
2024-09-08 14:53:27,168 [foster.py] => SNet: Task 10, Epoch 29/130 => Loss 31.696,  Loss1 0.791, Train_accy 71.00
2024-09-08 14:53:33,355 [foster.py] => SNet: Task 10, Epoch 30/130 => Loss 31.704,  Loss1 0.791, Train_accy 71.00
2024-09-08 14:53:40,964 [foster.py] => SNet: Task 10, Epoch 31/130 => Loss 31.733,  Loss1 0.791, Train_accy 70.68, Test_accy 62.85
2024-09-08 14:53:47,075 [foster.py] => SNet: Task 10, Epoch 32/130 => Loss 31.712,  Loss1 0.791, Train_accy 70.27
2024-09-08 14:53:53,201 [foster.py] => SNet: Task 10, Epoch 33/130 => Loss 31.684,  Loss1 0.791, Train_accy 70.25
2024-09-08 14:53:59,366 [foster.py] => SNet: Task 10, Epoch 34/130 => Loss 31.677,  Loss1 0.791, Train_accy 70.55
2024-09-08 14:54:05,547 [foster.py] => SNet: Task 10, Epoch 35/130 => Loss 31.673,  Loss1 0.792, Train_accy 70.36
2024-09-08 14:54:13,053 [foster.py] => SNet: Task 10, Epoch 36/130 => Loss 31.708,  Loss1 0.791, Train_accy 71.36, Test_accy 63.04
2024-09-08 14:54:19,176 [foster.py] => SNet: Task 10, Epoch 37/130 => Loss 31.679,  Loss1 0.791, Train_accy 70.93
2024-09-08 14:54:25,306 [foster.py] => SNet: Task 10, Epoch 38/130 => Loss 31.706,  Loss1 0.791, Train_accy 71.36
2024-09-08 14:54:31,405 [foster.py] => SNet: Task 10, Epoch 39/130 => Loss 31.714,  Loss1 0.791, Train_accy 71.20
2024-09-08 14:54:37,530 [foster.py] => SNet: Task 10, Epoch 40/130 => Loss 31.712,  Loss1 0.791, Train_accy 70.91
2024-09-08 14:54:44,955 [foster.py] => SNet: Task 10, Epoch 41/130 => Loss 31.720,  Loss1 0.791, Train_accy 71.18, Test_accy 63.01
2024-09-08 14:54:51,115 [foster.py] => SNet: Task 10, Epoch 42/130 => Loss 31.698,  Loss1 0.791, Train_accy 70.98
2024-09-08 14:54:57,256 [foster.py] => SNet: Task 10, Epoch 43/130 => Loss 31.671,  Loss1 0.791, Train_accy 72.07
2024-09-08 14:55:03,389 [foster.py] => SNet: Task 10, Epoch 44/130 => Loss 31.713,  Loss1 0.791, Train_accy 71.18
2024-09-08 14:55:09,488 [foster.py] => SNet: Task 10, Epoch 45/130 => Loss 31.684,  Loss1 0.792, Train_accy 71.36
2024-09-08 14:55:17,000 [foster.py] => SNet: Task 10, Epoch 46/130 => Loss 31.673,  Loss1 0.791, Train_accy 72.18, Test_accy 62.92
2024-09-08 14:55:23,114 [foster.py] => SNet: Task 10, Epoch 47/130 => Loss 31.691,  Loss1 0.791, Train_accy 71.23
2024-09-08 14:55:29,176 [foster.py] => SNet: Task 10, Epoch 48/130 => Loss 31.710,  Loss1 0.791, Train_accy 71.36
2024-09-08 14:55:35,345 [foster.py] => SNet: Task 10, Epoch 49/130 => Loss 31.700,  Loss1 0.791, Train_accy 70.91
2024-09-08 14:55:41,475 [foster.py] => SNet: Task 10, Epoch 50/130 => Loss 31.707,  Loss1 0.791, Train_accy 70.89
2024-09-08 14:55:48,983 [foster.py] => SNet: Task 10, Epoch 51/130 => Loss 31.718,  Loss1 0.791, Train_accy 70.64, Test_accy 63.33
2024-09-08 14:55:55,123 [foster.py] => SNet: Task 10, Epoch 52/130 => Loss 31.701,  Loss1 0.791, Train_accy 71.66
2024-09-08 14:56:01,234 [foster.py] => SNet: Task 10, Epoch 53/130 => Loss 31.720,  Loss1 0.791, Train_accy 70.93
2024-09-08 14:56:07,368 [foster.py] => SNet: Task 10, Epoch 54/130 => Loss 31.686,  Loss1 0.791, Train_accy 71.84
2024-09-08 14:56:13,473 [foster.py] => SNet: Task 10, Epoch 55/130 => Loss 31.718,  Loss1 0.791, Train_accy 71.00
2024-09-08 14:56:20,949 [foster.py] => SNet: Task 10, Epoch 56/130 => Loss 31.727,  Loss1 0.791, Train_accy 72.70, Test_accy 62.88
2024-09-08 14:56:27,044 [foster.py] => SNet: Task 10, Epoch 57/130 => Loss 31.700,  Loss1 0.791, Train_accy 71.43
2024-09-08 14:56:33,237 [foster.py] => SNet: Task 10, Epoch 58/130 => Loss 31.712,  Loss1 0.791, Train_accy 72.00
2024-09-08 14:56:39,375 [foster.py] => SNet: Task 10, Epoch 59/130 => Loss 31.743,  Loss1 0.791, Train_accy 72.39
2024-09-08 14:56:45,473 [foster.py] => SNet: Task 10, Epoch 60/130 => Loss 31.684,  Loss1 0.791, Train_accy 72.11
2024-09-08 14:56:52,963 [foster.py] => SNet: Task 10, Epoch 61/130 => Loss 31.694,  Loss1 0.791, Train_accy 71.48, Test_accy 63.26
2024-09-08 14:56:59,046 [foster.py] => SNet: Task 10, Epoch 62/130 => Loss 31.693,  Loss1 0.791, Train_accy 73.48
2024-09-08 14:57:05,164 [foster.py] => SNet: Task 10, Epoch 63/130 => Loss 31.693,  Loss1 0.791, Train_accy 72.23
2024-09-08 14:57:11,289 [foster.py] => SNet: Task 10, Epoch 64/130 => Loss 31.698,  Loss1 0.791, Train_accy 71.52
2024-09-08 14:57:17,458 [foster.py] => SNet: Task 10, Epoch 65/130 => Loss 31.680,  Loss1 0.791, Train_accy 71.95
2024-09-08 14:57:24,985 [foster.py] => SNet: Task 10, Epoch 66/130 => Loss 31.687,  Loss1 0.791, Train_accy 73.05, Test_accy 63.14
2024-09-08 14:57:31,090 [foster.py] => SNet: Task 10, Epoch 67/130 => Loss 31.679,  Loss1 0.791, Train_accy 72.98
2024-09-08 14:57:37,197 [foster.py] => SNet: Task 10, Epoch 68/130 => Loss 31.725,  Loss1 0.791, Train_accy 71.09
2024-09-08 14:57:43,313 [foster.py] => SNet: Task 10, Epoch 69/130 => Loss 31.675,  Loss1 0.791, Train_accy 72.48
2024-09-08 14:57:49,411 [foster.py] => SNet: Task 10, Epoch 70/130 => Loss 31.699,  Loss1 0.791, Train_accy 72.30
2024-09-08 14:57:56,950 [foster.py] => SNet: Task 10, Epoch 71/130 => Loss 31.680,  Loss1 0.791, Train_accy 72.05, Test_accy 63.15
2024-09-08 14:58:03,122 [foster.py] => SNet: Task 10, Epoch 72/130 => Loss 31.716,  Loss1 0.791, Train_accy 72.66
2024-09-08 14:58:09,242 [foster.py] => SNet: Task 10, Epoch 73/130 => Loss 31.677,  Loss1 0.791, Train_accy 72.95
2024-09-08 14:58:15,366 [foster.py] => SNet: Task 10, Epoch 74/130 => Loss 31.704,  Loss1 0.791, Train_accy 72.30
2024-09-08 14:58:21,454 [foster.py] => SNet: Task 10, Epoch 75/130 => Loss 31.695,  Loss1 0.791, Train_accy 72.93
2024-09-08 14:58:29,024 [foster.py] => SNet: Task 10, Epoch 76/130 => Loss 31.709,  Loss1 0.791, Train_accy 71.89, Test_accy 63.09
2024-09-08 14:58:35,191 [foster.py] => SNet: Task 10, Epoch 77/130 => Loss 31.700,  Loss1 0.791, Train_accy 72.82
2024-09-08 14:58:41,352 [foster.py] => SNet: Task 10, Epoch 78/130 => Loss 31.703,  Loss1 0.791, Train_accy 72.91
2024-09-08 14:58:47,451 [foster.py] => SNet: Task 10, Epoch 79/130 => Loss 31.681,  Loss1 0.791, Train_accy 72.00
2024-09-08 14:58:53,611 [foster.py] => SNet: Task 10, Epoch 80/130 => Loss 31.711,  Loss1 0.791, Train_accy 72.66
2024-09-08 14:59:01,163 [foster.py] => SNet: Task 10, Epoch 81/130 => Loss 31.671,  Loss1 0.791, Train_accy 72.00, Test_accy 63.17
2024-09-08 14:59:07,242 [foster.py] => SNet: Task 10, Epoch 82/130 => Loss 31.679,  Loss1 0.791, Train_accy 72.84
2024-09-08 14:59:13,326 [foster.py] => SNet: Task 10, Epoch 83/130 => Loss 31.711,  Loss1 0.791, Train_accy 71.86
2024-09-08 14:59:19,460 [foster.py] => SNet: Task 10, Epoch 84/130 => Loss 31.712,  Loss1 0.791, Train_accy 71.50
2024-09-08 14:59:25,568 [foster.py] => SNet: Task 10, Epoch 85/130 => Loss 31.717,  Loss1 0.791, Train_accy 72.70
2024-09-08 14:59:33,118 [foster.py] => SNet: Task 10, Epoch 86/130 => Loss 31.673,  Loss1 0.791, Train_accy 72.14, Test_accy 63.22
2024-09-08 14:59:39,256 [foster.py] => SNet: Task 10, Epoch 87/130 => Loss 31.712,  Loss1 0.791, Train_accy 72.48
2024-09-08 14:59:45,380 [foster.py] => SNet: Task 10, Epoch 88/130 => Loss 31.698,  Loss1 0.791, Train_accy 72.93
2024-09-08 14:59:51,552 [foster.py] => SNet: Task 10, Epoch 89/130 => Loss 31.690,  Loss1 0.791, Train_accy 73.16
2024-09-08 14:59:57,660 [foster.py] => SNet: Task 10, Epoch 90/130 => Loss 31.671,  Loss1 0.791, Train_accy 72.75
2024-09-08 15:00:05,158 [foster.py] => SNet: Task 10, Epoch 91/130 => Loss 31.692,  Loss1 0.791, Train_accy 72.07, Test_accy 63.14
2024-09-08 15:00:11,342 [foster.py] => SNet: Task 10, Epoch 92/130 => Loss 31.673,  Loss1 0.791, Train_accy 72.68
2024-09-08 15:00:17,407 [foster.py] => SNet: Task 10, Epoch 93/130 => Loss 31.685,  Loss1 0.791, Train_accy 71.18
2024-09-08 15:00:23,473 [foster.py] => SNet: Task 10, Epoch 94/130 => Loss 31.720,  Loss1 0.791, Train_accy 71.82
2024-09-08 15:00:29,593 [foster.py] => SNet: Task 10, Epoch 95/130 => Loss 31.696,  Loss1 0.791, Train_accy 73.77
2024-09-08 15:00:37,098 [foster.py] => SNet: Task 10, Epoch 96/130 => Loss 31.694,  Loss1 0.791, Train_accy 72.64, Test_accy 62.95
2024-09-08 15:00:43,241 [foster.py] => SNet: Task 10, Epoch 97/130 => Loss 31.671,  Loss1 0.791, Train_accy 73.36
2024-09-08 15:00:49,365 [foster.py] => SNet: Task 10, Epoch 98/130 => Loss 31.671,  Loss1 0.791, Train_accy 72.59
2024-09-08 15:00:55,543 [foster.py] => SNet: Task 10, Epoch 99/130 => Loss 31.690,  Loss1 0.791, Train_accy 73.32
2024-09-08 15:01:01,641 [foster.py] => SNet: Task 10, Epoch 100/130 => Loss 31.662,  Loss1 0.791, Train_accy 73.18
2024-09-08 15:01:09,231 [foster.py] => SNet: Task 10, Epoch 101/130 => Loss 31.713,  Loss1 0.791, Train_accy 72.84, Test_accy 63.30
2024-09-08 15:01:15,373 [foster.py] => SNet: Task 10, Epoch 102/130 => Loss 31.683,  Loss1 0.791, Train_accy 72.93
2024-09-08 15:01:21,475 [foster.py] => SNet: Task 10, Epoch 103/130 => Loss 31.702,  Loss1 0.791, Train_accy 73.27
2024-09-08 15:01:27,573 [foster.py] => SNet: Task 10, Epoch 104/130 => Loss 31.699,  Loss1 0.791, Train_accy 73.30
2024-09-08 15:01:33,678 [foster.py] => SNet: Task 10, Epoch 105/130 => Loss 31.699,  Loss1 0.791, Train_accy 72.66
2024-09-08 15:01:41,141 [foster.py] => SNet: Task 10, Epoch 106/130 => Loss 31.707,  Loss1 0.791, Train_accy 72.57, Test_accy 63.24
2024-09-08 15:01:47,317 [foster.py] => SNet: Task 10, Epoch 107/130 => Loss 31.717,  Loss1 0.791, Train_accy 72.93
2024-09-08 15:01:53,446 [foster.py] => SNet: Task 10, Epoch 108/130 => Loss 31.716,  Loss1 0.791, Train_accy 72.20
2024-09-08 15:01:59,594 [foster.py] => SNet: Task 10, Epoch 109/130 => Loss 31.685,  Loss1 0.791, Train_accy 72.98
2024-09-08 15:02:05,679 [foster.py] => SNet: Task 10, Epoch 110/130 => Loss 31.701,  Loss1 0.791, Train_accy 72.50
2024-09-08 15:02:13,160 [foster.py] => SNet: Task 10, Epoch 111/130 => Loss 31.688,  Loss1 0.791, Train_accy 73.23, Test_accy 63.36
2024-09-08 15:02:19,297 [foster.py] => SNet: Task 10, Epoch 112/130 => Loss 31.691,  Loss1 0.791, Train_accy 72.89
2024-09-08 15:02:25,389 [foster.py] => SNet: Task 10, Epoch 113/130 => Loss 31.696,  Loss1 0.791, Train_accy 73.34
2024-09-08 15:02:31,492 [foster.py] => SNet: Task 10, Epoch 114/130 => Loss 31.660,  Loss1 0.791, Train_accy 72.80
2024-09-08 15:02:37,588 [foster.py] => SNet: Task 10, Epoch 115/130 => Loss 31.711,  Loss1 0.791, Train_accy 72.70
2024-09-08 15:02:45,085 [foster.py] => SNet: Task 10, Epoch 116/130 => Loss 31.710,  Loss1 0.791, Train_accy 72.95, Test_accy 63.16
2024-09-08 15:02:51,179 [foster.py] => SNet: Task 10, Epoch 117/130 => Loss 31.670,  Loss1 0.791, Train_accy 72.77
2024-09-08 15:02:57,322 [foster.py] => SNet: Task 10, Epoch 118/130 => Loss 31.712,  Loss1 0.791, Train_accy 73.25
2024-09-08 15:03:03,452 [foster.py] => SNet: Task 10, Epoch 119/130 => Loss 31.685,  Loss1 0.791, Train_accy 72.52
2024-09-08 15:03:09,596 [foster.py] => SNet: Task 10, Epoch 120/130 => Loss 31.688,  Loss1 0.791, Train_accy 73.32
2024-09-08 15:03:17,143 [foster.py] => SNet: Task 10, Epoch 121/130 => Loss 31.674,  Loss1 0.791, Train_accy 71.98, Test_accy 63.21
2024-09-08 15:03:23,267 [foster.py] => SNet: Task 10, Epoch 122/130 => Loss 31.677,  Loss1 0.791, Train_accy 72.30
2024-09-08 15:03:29,357 [foster.py] => SNet: Task 10, Epoch 123/130 => Loss 31.669,  Loss1 0.791, Train_accy 72.14
2024-09-08 15:03:35,486 [foster.py] => SNet: Task 10, Epoch 124/130 => Loss 31.675,  Loss1 0.791, Train_accy 72.45
2024-09-08 15:03:41,640 [foster.py] => SNet: Task 10, Epoch 125/130 => Loss 31.701,  Loss1 0.791, Train_accy 70.95
2024-09-08 15:03:49,131 [foster.py] => SNet: Task 10, Epoch 126/130 => Loss 31.687,  Loss1 0.791, Train_accy 72.43, Test_accy 63.22
2024-09-08 15:03:55,297 [foster.py] => SNet: Task 10, Epoch 127/130 => Loss 31.692,  Loss1 0.792, Train_accy 73.84
2024-09-08 15:04:01,425 [foster.py] => SNet: Task 10, Epoch 128/130 => Loss 31.702,  Loss1 0.791, Train_accy 72.80
2024-09-08 15:04:07,550 [foster.py] => SNet: Task 10, Epoch 129/130 => Loss 31.699,  Loss1 0.791, Train_accy 72.59
2024-09-08 15:04:13,673 [foster.py] => SNet: Task 10, Epoch 130/130 => Loss 31.688,  Loss1 0.791, Train_accy 73.14
2024-09-08 15:04:13,674 [foster.py] => do not weight align student!
2024-09-08 15:04:15,064 [foster.py] => darknet eval: 
2024-09-08 15:04:15,065 [foster.py] => CNN top1 curve: 63.35
2024-09-08 15:04:15,065 [foster.py] => CNN top5 curve: 88.29
2024-09-08 15:04:15,065 [foster.py] => CNN top1 平均值: 63.35
2024-09-08 15:04:15,068 [foster.py] => timees : 1883.1599299907684
2024-09-08 15:04:15,069 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-09-08 15:04:46,967 [foster.py] => Exemplar size: 2000
2024-09-08 15:04:46,967 [trainer.py] => CNN: {'total': 64.42, '00-09': 71.2, '10-19': 53.7, '20-29': 68.6, '30-39': 60.3, '40-49': 67.3, '50-59': 52.2, '60-69': 65.7, '70-79': 61.8, '80-89': 69.1, '90-99': 74.3, 'old': 63.73, 'new': 77.6}
2024-09-08 15:04:46,968 [trainer.py] => NME: {'total': 59.89, '00-09': 57.8, '10-19': 46.6, '20-29': 61.7, '30-39': 56.2, '40-49': 63.1, '50-59': 49.3, '60-69': 65.0, '70-79': 62.9, '80-89': 70.1, '90-99': 66.2, 'old': 58.65, 'new': 83.4}
2024-09-08 15:04:46,968 [trainer.py] => CNN top1 curve: [81.66, 79.8, 78.5, 76.05, 74.9, 72.67, 69.88, 68.0, 66.68, 65.99, 64.42]
2024-09-08 15:04:46,968 [trainer.py] => CNN top5 curve: [97.02, 96.93, 95.97, 94.85, 94.14, 93.05, 92.24, 91.41, 90.32, 89.67, 88.65]
2024-09-08 15:04:46,969 [trainer.py] => NME top1 curve: [80.72, 75.13, 74.22, 70.89, 69.97, 67.83, 64.05, 62.79, 62.28, 61.0, 59.89]
2024-09-08 15:04:46,969 [trainer.py] => NME top5 curve: [96.8, 95.58, 94.4, 92.29, 91.57, 90.79, 89.66, 89.24, 87.61, 86.41, 85.52]

2024-09-08 15:04:46,969 [trainer.py] => CNN top1 平均值: 72.60