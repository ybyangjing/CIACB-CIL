2024-08-02 12:33:36,643 [trainer.py] => config: ./configs/cifar/b50inc2.json
2024-08-02 12:33:36,644 [trainer.py] => prefix: cil
2024-08-02 12:33:36,644 [trainer.py] => dataset: cifar100
2024-08-02 12:33:36,644 [trainer.py] => memory_size: 2000
2024-08-02 12:33:36,644 [trainer.py] => memory_per_class: 20
2024-08-02 12:33:36,644 [trainer.py] => fixed_memory: True
2024-08-02 12:33:36,644 [trainer.py] => shuffle: True
2024-08-02 12:33:36,645 [trainer.py] => init_cls: 50
2024-08-02 12:33:36,645 [trainer.py] => increment: 2
2024-08-02 12:33:36,645 [trainer.py] => model_name: foster
2024-08-02 12:33:36,645 [trainer.py] => convnet_type: resnet32
2024-08-02 12:33:36,645 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-02 12:33:36,645 [trainer.py] => seed: 1993
2024-08-02 12:33:36,645 [trainer.py] => beta1: 0.955
2024-08-02 12:33:36,645 [trainer.py] => beta2: 0.97
2024-08-02 12:33:36,645 [trainer.py] => oofc: ft
2024-08-02 12:33:36,645 [trainer.py] => is_teacher_wa: False
2024-08-02 12:33:36,646 [trainer.py] => is_student_wa: False
2024-08-02 12:33:36,646 [trainer.py] => lambda_okd: 1
2024-08-02 12:33:36,646 [trainer.py] => wa_value: 1
2024-08-02 12:33:36,646 [trainer.py] => init_epochs: 200
2024-08-02 12:33:36,646 [trainer.py] => init_lr: 0.1
2024-08-02 12:33:36,646 [trainer.py] => init_weight_decay: 0.0005
2024-08-02 12:33:36,646 [trainer.py] => boosting_epochs: 170
2024-08-02 12:33:36,646 [trainer.py] => compression_epochs: 130
2024-08-02 12:33:36,646 [trainer.py] => lr: 0.1
2024-08-02 12:33:36,646 [trainer.py] => batch_size: 128
2024-08-02 12:33:36,647 [trainer.py] => weight_decay: 0.0005
2024-08-02 12:33:36,647 [trainer.py] => num_workers: 8
2024-08-02 12:33:36,647 [trainer.py] => T: 2
2024-08-02 12:33:39,198 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-02 12:33:39,320 [trainer.py] => All params: 0
2024-08-02 12:33:39,321 [trainer.py] => Trainable params: 0
2024-08-02 12:33:39,603 [foster.py] => Learning on 0-50
2024-08-02 12:33:39,605 [foster.py] => All params: 583774
2024-08-02 12:33:39,606 [foster.py] => Trainable params: 583774
2024-08-02 12:34:44,139 [foster.py] => Task 0, Epoch 1/200 => Loss 3.712, Train_accy 6.01, Test_accy 10.80
2024-08-02 12:34:53,082 [foster.py] => Task 0, Epoch 2/200 => Loss 3.430, Loss1 3.430,Train_accy 11.50
2024-08-02 12:35:02,118 [foster.py] => Task 0, Epoch 3/200 => Loss 3.281, Loss1 3.281,Train_accy 14.58
2024-08-02 12:35:11,006 [foster.py] => Task 0, Epoch 4/200 => Loss 3.147, Loss1 3.147,Train_accy 17.41
2024-08-02 12:35:20,131 [foster.py] => Task 0, Epoch 5/200 => Loss 3.001, Loss1 3.001,Train_accy 20.49
2024-08-02 12:35:29,952 [foster.py] => Task 0, Epoch 6/200 => Loss 2.853, Train_accy 23.28, Test_accy 28.50
2024-08-02 12:35:38,974 [foster.py] => Task 0, Epoch 7/200 => Loss 2.743, Loss1 2.743,Train_accy 25.45
2024-08-02 12:35:47,830 [foster.py] => Task 0, Epoch 8/200 => Loss 2.640, Loss1 2.640,Train_accy 28.15
2024-08-02 12:35:56,645 [foster.py] => Task 0, Epoch 9/200 => Loss 2.527, Loss1 2.527,Train_accy 30.56
2024-08-02 12:36:05,606 [foster.py] => Task 0, Epoch 10/200 => Loss 2.443, Loss1 2.443,Train_accy 32.60
2024-08-02 12:36:15,469 [foster.py] => Task 0, Epoch 11/200 => Loss 2.367, Train_accy 34.49, Test_accy 38.34
2024-08-02 12:36:24,609 [foster.py] => Task 0, Epoch 12/200 => Loss 2.289, Loss1 2.289,Train_accy 36.37
2024-08-02 12:36:33,649 [foster.py] => Task 0, Epoch 13/200 => Loss 2.238, Loss1 2.238,Train_accy 37.77
2024-08-02 12:36:42,591 [foster.py] => Task 0, Epoch 14/200 => Loss 2.183, Loss1 2.183,Train_accy 39.28
2024-08-02 12:36:51,467 [foster.py] => Task 0, Epoch 15/200 => Loss 2.128, Loss1 2.128,Train_accy 40.28
2024-08-02 12:37:01,203 [foster.py] => Task 0, Epoch 16/200 => Loss 2.084, Train_accy 41.38, Test_accy 47.88
2024-08-02 12:37:10,335 [foster.py] => Task 0, Epoch 17/200 => Loss 2.066, Loss1 2.066,Train_accy 42.03
2024-08-02 12:37:19,222 [foster.py] => Task 0, Epoch 18/200 => Loss 2.035, Loss1 2.035,Train_accy 42.83
2024-08-02 12:37:27,985 [foster.py] => Task 0, Epoch 19/200 => Loss 2.013, Loss1 2.013,Train_accy 43.56
2024-08-02 12:37:36,777 [foster.py] => Task 0, Epoch 20/200 => Loss 1.987, Loss1 1.987,Train_accy 44.22
2024-08-02 12:37:46,711 [foster.py] => Task 0, Epoch 21/200 => Loss 1.960, Train_accy 44.88, Test_accy 49.18
2024-08-02 12:37:55,699 [foster.py] => Task 0, Epoch 22/200 => Loss 1.931, Loss1 1.931,Train_accy 45.24
2024-08-02 12:38:04,755 [foster.py] => Task 0, Epoch 23/200 => Loss 1.922, Loss1 1.922,Train_accy 45.60
2024-08-02 12:38:13,794 [foster.py] => Task 0, Epoch 24/200 => Loss 1.894, Loss1 1.894,Train_accy 46.18
2024-08-02 12:38:22,702 [foster.py] => Task 0, Epoch 25/200 => Loss 1.886, Loss1 1.886,Train_accy 47.01
2024-08-02 12:38:32,490 [foster.py] => Task 0, Epoch 26/200 => Loss 1.864, Train_accy 47.30, Test_accy 55.06
2024-08-02 12:38:41,525 [foster.py] => Task 0, Epoch 27/200 => Loss 1.848, Loss1 1.848,Train_accy 47.74
2024-08-02 12:38:50,441 [foster.py] => Task 0, Epoch 28/200 => Loss 1.841, Loss1 1.841,Train_accy 48.00
2024-08-02 12:38:59,301 [foster.py] => Task 0, Epoch 29/200 => Loss 1.832, Loss1 1.832,Train_accy 48.12
2024-08-02 12:39:08,103 [foster.py] => Task 0, Epoch 30/200 => Loss 1.811, Loss1 1.811,Train_accy 49.00
2024-08-02 12:39:17,900 [foster.py] => Task 0, Epoch 31/200 => Loss 1.802, Train_accy 48.98, Test_accy 57.86
2024-08-02 12:39:26,633 [foster.py] => Task 0, Epoch 32/200 => Loss 1.799, Loss1 1.799,Train_accy 48.66
2024-08-02 12:39:35,487 [foster.py] => Task 0, Epoch 33/200 => Loss 1.798, Loss1 1.798,Train_accy 49.45
2024-08-02 12:39:44,254 [foster.py] => Task 0, Epoch 34/200 => Loss 1.770, Loss1 1.770,Train_accy 49.92
2024-08-02 12:39:53,419 [foster.py] => Task 0, Epoch 35/200 => Loss 1.770, Loss1 1.770,Train_accy 49.98
2024-08-02 12:40:03,199 [foster.py] => Task 0, Epoch 36/200 => Loss 1.758, Train_accy 49.85, Test_accy 54.30
2024-08-02 12:40:12,009 [foster.py] => Task 0, Epoch 37/200 => Loss 1.756, Loss1 1.756,Train_accy 50.08
2024-08-02 12:40:20,982 [foster.py] => Task 0, Epoch 38/200 => Loss 1.748, Loss1 1.748,Train_accy 50.47
2024-08-02 12:40:29,754 [foster.py] => Task 0, Epoch 39/200 => Loss 1.735, Loss1 1.735,Train_accy 50.69
2024-08-02 12:40:38,661 [foster.py] => Task 0, Epoch 40/200 => Loss 1.744, Loss1 1.744,Train_accy 50.80
2024-08-02 12:40:48,398 [foster.py] => Task 0, Epoch 41/200 => Loss 1.719, Train_accy 51.19, Test_accy 54.78
2024-08-02 12:40:57,391 [foster.py] => Task 0, Epoch 42/200 => Loss 1.719, Loss1 1.719,Train_accy 51.44
2024-08-02 12:41:06,267 [foster.py] => Task 0, Epoch 43/200 => Loss 1.704, Loss1 1.704,Train_accy 51.76
2024-08-02 12:41:15,272 [foster.py] => Task 0, Epoch 44/200 => Loss 1.707, Loss1 1.707,Train_accy 51.36
2024-08-02 12:41:24,522 [foster.py] => Task 0, Epoch 45/200 => Loss 1.704, Loss1 1.704,Train_accy 51.62
2024-08-02 12:41:34,348 [foster.py] => Task 0, Epoch 46/200 => Loss 1.670, Train_accy 52.21, Test_accy 57.96
2024-08-02 12:41:43,280 [foster.py] => Task 0, Epoch 47/200 => Loss 1.687, Loss1 1.687,Train_accy 51.77
2024-08-02 12:41:52,066 [foster.py] => Task 0, Epoch 48/200 => Loss 1.675, Loss1 1.675,Train_accy 52.53
2024-08-02 12:42:01,295 [foster.py] => Task 0, Epoch 49/200 => Loss 1.669, Loss1 1.669,Train_accy 52.32
2024-08-02 12:42:10,300 [foster.py] => Task 0, Epoch 50/200 => Loss 1.663, Loss1 1.663,Train_accy 52.70
2024-08-02 12:42:20,002 [foster.py] => Task 0, Epoch 51/200 => Loss 1.657, Train_accy 52.59, Test_accy 55.20
2024-08-02 12:42:29,011 [foster.py] => Task 0, Epoch 52/200 => Loss 1.655, Loss1 1.655,Train_accy 52.88
2024-08-02 12:42:37,909 [foster.py] => Task 0, Epoch 53/200 => Loss 1.645, Loss1 1.645,Train_accy 53.02
2024-08-02 12:42:46,815 [foster.py] => Task 0, Epoch 54/200 => Loss 1.637, Loss1 1.637,Train_accy 53.51
2024-08-02 12:42:55,802 [foster.py] => Task 0, Epoch 55/200 => Loss 1.633, Loss1 1.633,Train_accy 53.31
2024-08-02 12:43:05,621 [foster.py] => Task 0, Epoch 56/200 => Loss 1.641, Train_accy 53.24, Test_accy 60.44
2024-08-02 12:43:14,542 [foster.py] => Task 0, Epoch 57/200 => Loss 1.631, Loss1 1.631,Train_accy 53.63
2024-08-02 12:43:23,453 [foster.py] => Task 0, Epoch 58/200 => Loss 1.613, Loss1 1.613,Train_accy 53.87
2024-08-02 12:43:32,482 [foster.py] => Task 0, Epoch 59/200 => Loss 1.625, Loss1 1.625,Train_accy 53.89
2024-08-02 12:43:41,283 [foster.py] => Task 0, Epoch 60/200 => Loss 1.617, Loss1 1.617,Train_accy 54.04
2024-08-02 12:43:51,105 [foster.py] => Task 0, Epoch 61/200 => Loss 1.612, Train_accy 53.99, Test_accy 59.56
2024-08-02 12:44:00,051 [foster.py] => Task 0, Epoch 62/200 => Loss 1.603, Loss1 1.603,Train_accy 54.34
2024-08-02 12:44:09,119 [foster.py] => Task 0, Epoch 63/200 => Loss 1.603, Loss1 1.603,Train_accy 54.24
2024-08-02 12:44:17,969 [foster.py] => Task 0, Epoch 64/200 => Loss 1.591, Loss1 1.591,Train_accy 54.60
2024-08-02 12:44:26,804 [foster.py] => Task 0, Epoch 65/200 => Loss 1.582, Loss1 1.582,Train_accy 54.79
2024-08-02 12:44:36,626 [foster.py] => Task 0, Epoch 66/200 => Loss 1.583, Train_accy 54.93, Test_accy 59.24
2024-08-02 12:44:45,516 [foster.py] => Task 0, Epoch 67/200 => Loss 1.592, Loss1 1.592,Train_accy 54.70
2024-08-02 12:44:54,396 [foster.py] => Task 0, Epoch 68/200 => Loss 1.573, Loss1 1.573,Train_accy 55.06
2024-08-02 12:45:03,255 [foster.py] => Task 0, Epoch 69/200 => Loss 1.571, Loss1 1.571,Train_accy 54.77
2024-08-02 12:45:12,284 [foster.py] => Task 0, Epoch 70/200 => Loss 1.561, Loss1 1.561,Train_accy 55.47
2024-08-02 12:45:22,016 [foster.py] => Task 0, Epoch 71/200 => Loss 1.549, Train_accy 55.55, Test_accy 59.48
2024-08-02 12:45:30,866 [foster.py] => Task 0, Epoch 72/200 => Loss 1.555, Loss1 1.555,Train_accy 55.21
2024-08-02 12:45:39,703 [foster.py] => Task 0, Epoch 73/200 => Loss 1.561, Loss1 1.561,Train_accy 55.36
2024-08-02 12:45:48,756 [foster.py] => Task 0, Epoch 74/200 => Loss 1.524, Loss1 1.524,Train_accy 56.46
2024-08-02 12:45:57,672 [foster.py] => Task 0, Epoch 75/200 => Loss 1.530, Loss1 1.530,Train_accy 56.31
2024-08-02 12:46:07,417 [foster.py] => Task 0, Epoch 76/200 => Loss 1.512, Train_accy 56.85, Test_accy 64.46
2024-08-02 12:46:16,331 [foster.py] => Task 0, Epoch 77/200 => Loss 1.534, Loss1 1.534,Train_accy 56.00
2024-08-02 12:46:25,417 [foster.py] => Task 0, Epoch 78/200 => Loss 1.519, Loss1 1.519,Train_accy 56.76
2024-08-02 12:46:34,591 [foster.py] => Task 0, Epoch 79/200 => Loss 1.519, Loss1 1.519,Train_accy 56.52
2024-08-02 12:46:43,496 [foster.py] => Task 0, Epoch 80/200 => Loss 1.509, Loss1 1.509,Train_accy 56.49
2024-08-02 12:46:53,241 [foster.py] => Task 0, Epoch 81/200 => Loss 1.513, Train_accy 56.38, Test_accy 62.94
2024-08-02 12:47:02,187 [foster.py] => Task 0, Epoch 82/200 => Loss 1.481, Loss1 1.481,Train_accy 57.48
2024-08-02 12:47:11,030 [foster.py] => Task 0, Epoch 83/200 => Loss 1.495, Loss1 1.495,Train_accy 57.19
2024-08-02 12:47:19,921 [foster.py] => Task 0, Epoch 84/200 => Loss 1.484, Loss1 1.484,Train_accy 57.54
2024-08-02 12:47:29,083 [foster.py] => Task 0, Epoch 85/200 => Loss 1.497, Loss1 1.497,Train_accy 57.36
2024-08-02 12:47:38,874 [foster.py] => Task 0, Epoch 86/200 => Loss 1.489, Train_accy 57.41, Test_accy 60.28
2024-08-02 12:47:47,779 [foster.py] => Task 0, Epoch 87/200 => Loss 1.459, Loss1 1.459,Train_accy 58.19
2024-08-02 12:47:56,835 [foster.py] => Task 0, Epoch 88/200 => Loss 1.476, Loss1 1.476,Train_accy 57.80
2024-08-02 12:48:05,758 [foster.py] => Task 0, Epoch 89/200 => Loss 1.460, Loss1 1.460,Train_accy 57.92
2024-08-02 12:48:14,691 [foster.py] => Task 0, Epoch 90/200 => Loss 1.465, Loss1 1.465,Train_accy 58.00
2024-08-02 12:48:24,495 [foster.py] => Task 0, Epoch 91/200 => Loss 1.447, Train_accy 58.25, Test_accy 65.66
2024-08-02 12:48:33,312 [foster.py] => Task 0, Epoch 92/200 => Loss 1.446, Loss1 1.446,Train_accy 58.16
2024-08-02 12:48:42,178 [foster.py] => Task 0, Epoch 93/200 => Loss 1.449, Loss1 1.449,Train_accy 58.33
2024-08-02 12:48:50,967 [foster.py] => Task 0, Epoch 94/200 => Loss 1.435, Loss1 1.435,Train_accy 58.96
2024-08-02 12:48:59,772 [foster.py] => Task 0, Epoch 95/200 => Loss 1.430, Loss1 1.430,Train_accy 58.57
2024-08-02 12:49:09,506 [foster.py] => Task 0, Epoch 96/200 => Loss 1.422, Train_accy 58.78, Test_accy 63.98
2024-08-02 12:49:18,542 [foster.py] => Task 0, Epoch 97/200 => Loss 1.424, Loss1 1.424,Train_accy 59.35
2024-08-02 12:49:27,498 [foster.py] => Task 0, Epoch 98/200 => Loss 1.397, Loss1 1.397,Train_accy 59.49
2024-08-02 12:49:36,488 [foster.py] => Task 0, Epoch 99/200 => Loss 1.395, Loss1 1.395,Train_accy 59.90
2024-08-02 12:49:45,660 [foster.py] => Task 0, Epoch 100/200 => Loss 1.406, Loss1 1.406,Train_accy 59.40
2024-08-02 12:49:55,483 [foster.py] => Task 0, Epoch 101/200 => Loss 1.382, Train_accy 60.14, Test_accy 63.92
2024-08-02 12:50:04,325 [foster.py] => Task 0, Epoch 102/200 => Loss 1.370, Loss1 1.370,Train_accy 60.60
2024-08-02 12:50:13,191 [foster.py] => Task 0, Epoch 103/200 => Loss 1.357, Loss1 1.357,Train_accy 61.02
2024-08-02 12:50:22,206 [foster.py] => Task 0, Epoch 104/200 => Loss 1.360, Loss1 1.360,Train_accy 60.67
2024-08-02 12:50:31,031 [foster.py] => Task 0, Epoch 105/200 => Loss 1.371, Loss1 1.371,Train_accy 60.49
2024-08-02 12:50:40,735 [foster.py] => Task 0, Epoch 106/200 => Loss 1.370, Train_accy 60.28, Test_accy 67.78
2024-08-02 12:50:49,757 [foster.py] => Task 0, Epoch 107/200 => Loss 1.347, Loss1 1.347,Train_accy 61.02
2024-08-02 12:50:58,799 [foster.py] => Task 0, Epoch 108/200 => Loss 1.348, Loss1 1.348,Train_accy 61.25
2024-08-02 12:51:08,006 [foster.py] => Task 0, Epoch 109/200 => Loss 1.341, Loss1 1.341,Train_accy 61.16
2024-08-02 12:51:16,926 [foster.py] => Task 0, Epoch 110/200 => Loss 1.334, Loss1 1.334,Train_accy 61.42
2024-08-02 12:51:26,645 [foster.py] => Task 0, Epoch 111/200 => Loss 1.339, Train_accy 61.46, Test_accy 67.22
2024-08-02 12:51:35,557 [foster.py] => Task 0, Epoch 112/200 => Loss 1.336, Loss1 1.336,Train_accy 61.16
2024-08-02 12:51:44,680 [foster.py] => Task 0, Epoch 113/200 => Loss 1.325, Loss1 1.325,Train_accy 61.74
2024-08-02 12:51:53,742 [foster.py] => Task 0, Epoch 114/200 => Loss 1.295, Loss1 1.295,Train_accy 62.09
2024-08-02 12:52:02,656 [foster.py] => Task 0, Epoch 115/200 => Loss 1.311, Loss1 1.311,Train_accy 62.26
2024-08-02 12:52:12,470 [foster.py] => Task 0, Epoch 116/200 => Loss 1.303, Train_accy 62.14, Test_accy 67.14
2024-08-02 12:52:21,490 [foster.py] => Task 0, Epoch 117/200 => Loss 1.296, Loss1 1.296,Train_accy 62.05
2024-08-02 12:52:30,314 [foster.py] => Task 0, Epoch 118/200 => Loss 1.291, Loss1 1.291,Train_accy 62.59
2024-08-02 12:52:39,181 [foster.py] => Task 0, Epoch 119/200 => Loss 1.276, Loss1 1.276,Train_accy 63.09
2024-08-02 12:52:48,249 [foster.py] => Task 0, Epoch 120/200 => Loss 1.270, Loss1 1.270,Train_accy 63.31
2024-08-02 12:52:58,025 [foster.py] => Task 0, Epoch 121/200 => Loss 1.265, Train_accy 63.20, Test_accy 70.46
2024-08-02 12:53:06,981 [foster.py] => Task 0, Epoch 122/200 => Loss 1.268, Loss1 1.268,Train_accy 63.28
2024-08-02 12:53:15,854 [foster.py] => Task 0, Epoch 123/200 => Loss 1.254, Loss1 1.254,Train_accy 63.43
2024-08-02 12:53:24,837 [foster.py] => Task 0, Epoch 124/200 => Loss 1.254, Loss1 1.254,Train_accy 63.82
2024-08-02 12:53:33,707 [foster.py] => Task 0, Epoch 125/200 => Loss 1.240, Loss1 1.240,Train_accy 64.41
2024-08-02 12:53:43,746 [foster.py] => Task 0, Epoch 126/200 => Loss 1.227, Train_accy 64.56, Test_accy 66.84
2024-08-02 12:53:52,649 [foster.py] => Task 0, Epoch 127/200 => Loss 1.217, Loss1 1.217,Train_accy 64.56
2024-08-02 12:54:01,836 [foster.py] => Task 0, Epoch 128/200 => Loss 1.196, Loss1 1.196,Train_accy 64.81
2024-08-02 12:54:10,733 [foster.py] => Task 0, Epoch 129/200 => Loss 1.207, Loss1 1.207,Train_accy 64.71
2024-08-02 12:54:19,704 [foster.py] => Task 0, Epoch 130/200 => Loss 1.178, Loss1 1.178,Train_accy 65.70
2024-08-02 12:54:29,363 [foster.py] => Task 0, Epoch 131/200 => Loss 1.188, Train_accy 65.38, Test_accy 70.78
2024-08-02 12:54:38,268 [foster.py] => Task 0, Epoch 132/200 => Loss 1.195, Loss1 1.195,Train_accy 65.50
2024-08-02 12:54:47,206 [foster.py] => Task 0, Epoch 133/200 => Loss 1.180, Loss1 1.180,Train_accy 65.72
2024-08-02 12:54:56,084 [foster.py] => Task 0, Epoch 134/200 => Loss 1.168, Loss1 1.168,Train_accy 65.76
2024-08-02 12:55:05,129 [foster.py] => Task 0, Epoch 135/200 => Loss 1.150, Loss1 1.150,Train_accy 66.58
2024-08-02 12:55:14,792 [foster.py] => Task 0, Epoch 136/200 => Loss 1.149, Train_accy 66.54, Test_accy 71.98
2024-08-02 12:55:23,785 [foster.py] => Task 0, Epoch 137/200 => Loss 1.152, Loss1 1.152,Train_accy 66.32
2024-08-02 12:55:32,834 [foster.py] => Task 0, Epoch 138/200 => Loss 1.128, Loss1 1.128,Train_accy 66.98
2024-08-02 12:55:41,983 [foster.py] => Task 0, Epoch 139/200 => Loss 1.130, Loss1 1.130,Train_accy 67.07
2024-08-02 12:55:50,947 [foster.py] => Task 0, Epoch 140/200 => Loss 1.112, Loss1 1.112,Train_accy 67.36
2024-08-02 12:56:00,640 [foster.py] => Task 0, Epoch 141/200 => Loss 1.112, Train_accy 67.59, Test_accy 74.68
2024-08-02 12:56:10,000 [foster.py] => Task 0, Epoch 142/200 => Loss 1.087, Loss1 1.087,Train_accy 68.27
2024-08-02 12:56:18,862 [foster.py] => Task 0, Epoch 143/200 => Loss 1.093, Loss1 1.093,Train_accy 67.99
2024-08-02 12:56:27,872 [foster.py] => Task 0, Epoch 144/200 => Loss 1.065, Loss1 1.065,Train_accy 68.66
2024-08-02 12:56:36,885 [foster.py] => Task 0, Epoch 145/200 => Loss 1.063, Loss1 1.063,Train_accy 68.93
2024-08-02 12:56:46,541 [foster.py] => Task 0, Epoch 146/200 => Loss 1.049, Train_accy 69.30, Test_accy 69.30
2024-08-02 12:56:55,481 [foster.py] => Task 0, Epoch 147/200 => Loss 1.049, Loss1 1.049,Train_accy 69.31
2024-08-02 12:57:04,342 [foster.py] => Task 0, Epoch 148/200 => Loss 1.040, Loss1 1.040,Train_accy 69.52
2024-08-02 12:57:13,315 [foster.py] => Task 0, Epoch 149/200 => Loss 1.028, Loss1 1.028,Train_accy 70.00
2024-08-02 12:57:22,116 [foster.py] => Task 0, Epoch 150/200 => Loss 1.035, Loss1 1.035,Train_accy 69.44
2024-08-02 12:57:31,872 [foster.py] => Task 0, Epoch 151/200 => Loss 1.023, Train_accy 69.92, Test_accy 75.42
2024-08-02 12:57:40,693 [foster.py] => Task 0, Epoch 152/200 => Loss 1.011, Loss1 1.011,Train_accy 70.40
2024-08-02 12:57:49,585 [foster.py] => Task 0, Epoch 153/200 => Loss 1.004, Loss1 1.004,Train_accy 70.64
2024-08-02 12:57:58,477 [foster.py] => Task 0, Epoch 154/200 => Loss 1.000, Loss1 1.000,Train_accy 70.71
2024-08-02 12:58:07,344 [foster.py] => Task 0, Epoch 155/200 => Loss 0.973, Loss1 0.973,Train_accy 71.35
2024-08-02 12:58:17,221 [foster.py] => Task 0, Epoch 156/200 => Loss 0.972, Train_accy 71.60, Test_accy 76.28
2024-08-02 12:58:26,089 [foster.py] => Task 0, Epoch 157/200 => Loss 0.954, Loss1 0.954,Train_accy 72.21
2024-08-02 12:58:35,016 [foster.py] => Task 0, Epoch 158/200 => Loss 0.943, Loss1 0.943,Train_accy 72.51
2024-08-02 12:58:43,782 [foster.py] => Task 0, Epoch 159/200 => Loss 0.935, Loss1 0.935,Train_accy 72.42
2024-08-02 12:58:52,751 [foster.py] => Task 0, Epoch 160/200 => Loss 0.944, Loss1 0.944,Train_accy 72.50
2024-08-02 12:59:02,855 [foster.py] => Task 0, Epoch 161/200 => Loss 0.934, Train_accy 72.40, Test_accy 76.72
2024-08-02 12:59:11,888 [foster.py] => Task 0, Epoch 162/200 => Loss 0.910, Loss1 0.910,Train_accy 73.19
2024-08-02 12:59:20,776 [foster.py] => Task 0, Epoch 163/200 => Loss 0.917, Loss1 0.917,Train_accy 73.12
2024-08-02 12:59:29,750 [foster.py] => Task 0, Epoch 164/200 => Loss 0.885, Loss1 0.885,Train_accy 74.08
2024-08-02 12:59:38,788 [foster.py] => Task 0, Epoch 165/200 => Loss 0.883, Loss1 0.883,Train_accy 74.10
2024-08-02 12:59:48,574 [foster.py] => Task 0, Epoch 166/200 => Loss 0.881, Train_accy 74.03, Test_accy 78.54
2024-08-02 12:59:57,474 [foster.py] => Task 0, Epoch 167/200 => Loss 0.871, Loss1 0.871,Train_accy 74.69
2024-08-02 13:00:06,418 [foster.py] => Task 0, Epoch 168/200 => Loss 0.846, Loss1 0.846,Train_accy 75.22
2024-08-02 13:00:15,330 [foster.py] => Task 0, Epoch 169/200 => Loss 0.864, Loss1 0.864,Train_accy 74.86
2024-08-02 13:00:24,319 [foster.py] => Task 0, Epoch 170/200 => Loss 0.847, Loss1 0.847,Train_accy 75.31
2024-08-02 13:00:34,160 [foster.py] => Task 0, Epoch 171/200 => Loss 0.849, Train_accy 74.99, Test_accy 79.22
2024-08-02 13:00:43,290 [foster.py] => Task 0, Epoch 172/200 => Loss 0.822, Loss1 0.822,Train_accy 75.69
2024-08-02 13:00:52,175 [foster.py] => Task 0, Epoch 173/200 => Loss 0.813, Loss1 0.813,Train_accy 76.08
2024-08-02 13:01:01,088 [foster.py] => Task 0, Epoch 174/200 => Loss 0.812, Loss1 0.812,Train_accy 76.04
2024-08-02 13:01:10,001 [foster.py] => Task 0, Epoch 175/200 => Loss 0.795, Loss1 0.795,Train_accy 76.68
2024-08-02 13:01:19,779 [foster.py] => Task 0, Epoch 176/200 => Loss 0.785, Train_accy 77.04, Test_accy 80.16
2024-08-02 13:01:29,101 [foster.py] => Task 0, Epoch 177/200 => Loss 0.776, Loss1 0.776,Train_accy 76.89
2024-08-02 13:01:38,106 [foster.py] => Task 0, Epoch 178/200 => Loss 0.769, Loss1 0.769,Train_accy 77.22
2024-08-02 13:01:47,252 [foster.py] => Task 0, Epoch 179/200 => Loss 0.755, Loss1 0.755,Train_accy 77.73
2024-08-02 13:01:56,123 [foster.py] => Task 0, Epoch 180/200 => Loss 0.750, Loss1 0.750,Train_accy 77.82
2024-08-02 13:02:05,957 [foster.py] => Task 0, Epoch 181/200 => Loss 0.739, Train_accy 78.32, Test_accy 80.90
2024-08-02 13:02:14,899 [foster.py] => Task 0, Epoch 182/200 => Loss 0.737, Loss1 0.737,Train_accy 78.35
2024-08-02 13:02:23,832 [foster.py] => Task 0, Epoch 183/200 => Loss 0.725, Loss1 0.725,Train_accy 78.63
2024-08-02 13:02:32,693 [foster.py] => Task 0, Epoch 184/200 => Loss 0.714, Loss1 0.714,Train_accy 78.96
2024-08-02 13:02:41,555 [foster.py] => Task 0, Epoch 185/200 => Loss 0.714, Loss1 0.714,Train_accy 78.86
2024-08-02 13:02:51,341 [foster.py] => Task 0, Epoch 186/200 => Loss 0.718, Train_accy 78.61, Test_accy 81.14
2024-08-02 13:03:00,220 [foster.py] => Task 0, Epoch 187/200 => Loss 0.704, Loss1 0.704,Train_accy 79.36
2024-08-02 13:03:09,068 [foster.py] => Task 0, Epoch 188/200 => Loss 0.706, Loss1 0.706,Train_accy 79.37
2024-08-02 13:03:17,920 [foster.py] => Task 0, Epoch 189/200 => Loss 0.702, Loss1 0.702,Train_accy 79.07
2024-08-02 13:03:26,852 [foster.py] => Task 0, Epoch 190/200 => Loss 0.701, Loss1 0.701,Train_accy 79.54
2024-08-02 13:03:36,590 [foster.py] => Task 0, Epoch 191/200 => Loss 0.686, Train_accy 80.04, Test_accy 81.08
2024-08-02 13:03:45,478 [foster.py] => Task 0, Epoch 192/200 => Loss 0.694, Loss1 0.694,Train_accy 79.70
2024-08-02 13:03:54,442 [foster.py] => Task 0, Epoch 193/200 => Loss 0.681, Loss1 0.681,Train_accy 79.90
2024-08-02 13:04:03,290 [foster.py] => Task 0, Epoch 194/200 => Loss 0.683, Loss1 0.683,Train_accy 79.95
2024-08-02 13:04:12,192 [foster.py] => Task 0, Epoch 195/200 => Loss 0.683, Loss1 0.683,Train_accy 79.83
2024-08-02 13:04:22,049 [foster.py] => Task 0, Epoch 196/200 => Loss 0.685, Train_accy 79.74, Test_accy 81.48
2024-08-02 13:04:31,131 [foster.py] => Task 0, Epoch 197/200 => Loss 0.676, Loss1 0.676,Train_accy 80.07
2024-08-02 13:04:40,080 [foster.py] => Task 0, Epoch 198/200 => Loss 0.688, Loss1 0.688,Train_accy 79.74
2024-08-02 13:04:48,934 [foster.py] => Task 0, Epoch 199/200 => Loss 0.682, Loss1 0.682,Train_accy 80.12
2024-08-02 13:04:57,870 [foster.py] => Task 0, Epoch 200/200 => Loss 0.676, Loss1 0.676,Train_accy 79.95
2024-08-02 13:04:57,873 [foster.py] => training time: 1878.2090697288513
2024-08-02 13:04:57,875 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 13:05:27,498 [foster.py] => Exemplar size: 1000
2024-08-02 13:05:27,499 [trainer.py] => CNN: {'total': 81.66, '00-09': 86.2, '10-19': 78.1, '20-29': 83.2, '30-39': 78.2, '40-49': 82.6, 'old': 0, 'new': 81.66}
2024-08-02 13:05:27,502 [trainer.py] => NME: {'total': 80.72, '00-09': 83.4, '10-19': 76.9, '20-29': 83.2, '30-39': 78.4, '40-49': 81.7, 'old': 0, 'new': 80.72}
2024-08-02 13:05:27,502 [trainer.py] => CNN top1 curve: [81.66]
2024-08-02 13:05:27,502 [trainer.py] => CNN top5 curve: [97.02]
2024-08-02 13:05:27,502 [trainer.py] => NME top1 curve: [80.72]
2024-08-02 13:05:27,502 [trainer.py] => NME top5 curve: [96.8]

2024-08-02 13:05:27,502 [trainer.py] => CNN top1 平均值: 81.66
2024-08-02 13:05:27,504 [trainer.py] => All params: 583774
2024-08-02 13:05:27,505 [trainer.py] => Trainable params: 583774
2024-08-02 13:05:27,597 [foster.py] => Learning on 50-52
2024-08-02 13:05:27,600 [foster.py] => All params: 1167886
2024-08-02 13:05:27,602 [foster.py] => Trainable params: 587362
2024-08-02 13:05:27,639 [foster.py] => per cls weights : [1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728 1.01772728
 1.01772728 1.01772728 0.55681803 0.55681803]
2024-08-02 13:05:30,549 [foster.py] => Task 1, Epoch 1/170 => Loss 6.085, Loss_clf 1.534, Loss_fe 2.180, Loss_kd 2.278, Train_accy 60.50
2024-08-02 13:05:34,047 [foster.py] => Task 1, Epoch 2/170 => Loss 3.846, Loss_clf 0.695, Loss_fe 0.817, Loss_kd 2.242, Train_accy 65.30, Test_accy 79.10
2024-08-02 13:05:37,537 [foster.py] => Task 1, Epoch 3/170 => Loss 3.480, Loss_clf 0.519, Loss_fe 0.641, Loss_kd 2.229, Train_accy 62.35, Test_accy 79.71
2024-08-02 13:05:41,043 [foster.py] => Task 1, Epoch 4/170 => Loss 3.337, Loss_clf 0.500, Loss_fe 0.552, Loss_kd 2.195, Train_accy 61.30, Test_accy 79.37
2024-08-02 13:05:44,456 [foster.py] => Task 1, Epoch 5/170 => Loss 3.314, Loss_clf 0.504, Loss_fe 0.499, Loss_kd 2.221, Train_accy 63.10, Test_accy 79.63
2024-08-02 13:05:46,577 [foster.py] => Task 1, Epoch 6/170 => Loss 3.209, Loss_clf 0.476, Loss_fe 0.433, Loss_kd 2.210, Train_accy 63.30
2024-08-02 13:05:49,990 [foster.py] => Task 1, Epoch 7/170 => Loss 3.135, Loss_clf 0.446, Loss_fe 0.399, Loss_kd 2.201, Train_accy 65.60, Test_accy 79.54
2024-08-02 13:05:53,406 [foster.py] => Task 1, Epoch 8/170 => Loss 3.134, Loss_clf 0.469, Loss_fe 0.362, Loss_kd 2.213, Train_accy 64.60, Test_accy 79.62
2024-08-02 13:05:56,895 [foster.py] => Task 1, Epoch 9/170 => Loss 3.141, Loss_clf 0.483, Loss_fe 0.367, Loss_kd 2.201, Train_accy 64.95, Test_accy 79.90
2024-08-02 13:06:00,300 [foster.py] => Task 1, Epoch 10/170 => Loss 3.095, Loss_clf 0.454, Loss_fe 0.340, Loss_kd 2.211, Train_accy 67.50, Test_accy 79.62
2024-08-02 13:06:02,421 [foster.py] => Task 1, Epoch 11/170 => Loss 3.080, Loss_clf 0.454, Loss_fe 0.307, Loss_kd 2.229, Train_accy 67.55
2024-08-02 13:06:05,852 [foster.py] => Task 1, Epoch 12/170 => Loss 3.019, Loss_clf 0.434, Loss_fe 0.286, Loss_kd 2.209, Train_accy 67.30, Test_accy 79.98
2024-08-02 13:06:09,309 [foster.py] => Task 1, Epoch 13/170 => Loss 3.086, Loss_clf 0.465, Loss_fe 0.293, Loss_kd 2.238, Train_accy 67.85, Test_accy 80.06
2024-08-02 13:06:12,775 [foster.py] => Task 1, Epoch 14/170 => Loss 3.040, Loss_clf 0.438, Loss_fe 0.300, Loss_kd 2.212, Train_accy 67.85, Test_accy 80.00
2024-08-02 13:06:16,244 [foster.py] => Task 1, Epoch 15/170 => Loss 3.030, Loss_clf 0.444, Loss_fe 0.294, Loss_kd 2.203, Train_accy 67.15, Test_accy 79.67
2024-08-02 13:06:18,354 [foster.py] => Task 1, Epoch 16/170 => Loss 3.047, Loss_clf 0.443, Loss_fe 0.300, Loss_kd 2.214, Train_accy 71.05
2024-08-02 13:06:21,744 [foster.py] => Task 1, Epoch 17/170 => Loss 3.060, Loss_clf 0.453, Loss_fe 0.281, Loss_kd 2.234, Train_accy 67.95, Test_accy 80.56
2024-08-02 13:06:25,153 [foster.py] => Task 1, Epoch 18/170 => Loss 3.020, Loss_clf 0.440, Loss_fe 0.267, Loss_kd 2.224, Train_accy 69.30, Test_accy 80.40
2024-08-02 13:06:28,575 [foster.py] => Task 1, Epoch 19/170 => Loss 2.986, Loss_clf 0.403, Loss_fe 0.279, Loss_kd 2.214, Train_accy 70.05, Test_accy 80.48
2024-08-02 13:06:31,999 [foster.py] => Task 1, Epoch 20/170 => Loss 2.976, Loss_clf 0.432, Loss_fe 0.253, Loss_kd 2.201, Train_accy 69.65, Test_accy 80.02
2024-08-02 13:06:34,087 [foster.py] => Task 1, Epoch 21/170 => Loss 2.974, Loss_clf 0.418, Loss_fe 0.256, Loss_kd 2.209, Train_accy 71.75
2024-08-02 13:06:37,482 [foster.py] => Task 1, Epoch 22/170 => Loss 2.987, Loss_clf 0.420, Loss_fe 0.265, Loss_kd 2.212, Train_accy 73.20, Test_accy 80.13
2024-08-02 13:06:40,901 [foster.py] => Task 1, Epoch 23/170 => Loss 3.024, Loss_clf 0.436, Loss_fe 0.269, Loss_kd 2.229, Train_accy 71.15, Test_accy 80.33
2024-08-02 13:06:44,324 [foster.py] => Task 1, Epoch 24/170 => Loss 3.038, Loss_clf 0.434, Loss_fe 0.291, Loss_kd 2.222, Train_accy 70.05, Test_accy 79.73
2024-08-02 13:06:47,748 [foster.py] => Task 1, Epoch 25/170 => Loss 3.055, Loss_clf 0.443, Loss_fe 0.277, Loss_kd 2.245, Train_accy 69.25, Test_accy 80.27
2024-08-02 13:06:49,857 [foster.py] => Task 1, Epoch 26/170 => Loss 2.967, Loss_clf 0.415, Loss_fe 0.238, Loss_kd 2.224, Train_accy 71.25
2024-08-02 13:06:53,264 [foster.py] => Task 1, Epoch 27/170 => Loss 2.968, Loss_clf 0.414, Loss_fe 0.250, Loss_kd 2.215, Train_accy 71.75, Test_accy 80.33
2024-08-02 13:06:56,683 [foster.py] => Task 1, Epoch 28/170 => Loss 2.899, Loss_clf 0.379, Loss_fe 0.224, Loss_kd 2.206, Train_accy 73.65, Test_accy 80.02
2024-08-02 13:07:00,078 [foster.py] => Task 1, Epoch 29/170 => Loss 2.993, Loss_clf 0.432, Loss_fe 0.257, Loss_kd 2.214, Train_accy 71.90, Test_accy 80.29
2024-08-02 13:07:03,515 [foster.py] => Task 1, Epoch 30/170 => Loss 2.885, Loss_clf 0.387, Loss_fe 0.213, Loss_kd 2.196, Train_accy 72.55, Test_accy 80.21
2024-08-02 13:07:05,651 [foster.py] => Task 1, Epoch 31/170 => Loss 2.939, Loss_clf 0.417, Loss_fe 0.231, Loss_kd 2.201, Train_accy 72.75
2024-08-02 13:07:09,103 [foster.py] => Task 1, Epoch 32/170 => Loss 2.941, Loss_clf 0.421, Loss_fe 0.216, Loss_kd 2.214, Train_accy 70.80, Test_accy 80.71
2024-08-02 13:07:12,506 [foster.py] => Task 1, Epoch 33/170 => Loss 2.903, Loss_clf 0.359, Loss_fe 0.228, Loss_kd 2.226, Train_accy 76.55, Test_accy 80.21
2024-08-02 13:07:16,036 [foster.py] => Task 1, Epoch 34/170 => Loss 2.996, Loss_clf 0.429, Loss_fe 0.245, Loss_kd 2.231, Train_accy 73.80, Test_accy 80.69
2024-08-02 13:07:19,444 [foster.py] => Task 1, Epoch 35/170 => Loss 2.866, Loss_clf 0.371, Loss_fe 0.195, Loss_kd 2.210, Train_accy 74.15, Test_accy 80.25
2024-08-02 13:07:21,622 [foster.py] => Task 1, Epoch 36/170 => Loss 2.904, Loss_clf 0.379, Loss_fe 0.214, Loss_kd 2.221, Train_accy 74.00
2024-08-02 13:07:25,016 [foster.py] => Task 1, Epoch 37/170 => Loss 2.903, Loss_clf 0.392, Loss_fe 0.214, Loss_kd 2.207, Train_accy 73.85, Test_accy 80.25
2024-08-02 13:07:28,450 [foster.py] => Task 1, Epoch 38/170 => Loss 2.953, Loss_clf 0.401, Loss_fe 0.228, Loss_kd 2.234, Train_accy 74.25, Test_accy 79.98
2024-08-02 13:07:31,845 [foster.py] => Task 1, Epoch 39/170 => Loss 2.937, Loss_clf 0.398, Loss_fe 0.227, Loss_kd 2.222, Train_accy 74.15, Test_accy 80.31
2024-08-02 13:07:35,265 [foster.py] => Task 1, Epoch 40/170 => Loss 2.945, Loss_clf 0.435, Loss_fe 0.225, Loss_kd 2.197, Train_accy 73.55, Test_accy 80.71
2024-08-02 13:07:37,386 [foster.py] => Task 1, Epoch 41/170 => Loss 2.863, Loss_clf 0.367, Loss_fe 0.199, Loss_kd 2.207, Train_accy 75.35
2024-08-02 13:07:40,785 [foster.py] => Task 1, Epoch 42/170 => Loss 2.891, Loss_clf 0.378, Loss_fe 0.197, Loss_kd 2.225, Train_accy 75.15, Test_accy 80.44
2024-08-02 13:07:44,208 [foster.py] => Task 1, Epoch 43/170 => Loss 2.966, Loss_clf 0.425, Loss_fe 0.225, Loss_kd 2.225, Train_accy 72.45, Test_accy 80.87
2024-08-02 13:07:47,618 [foster.py] => Task 1, Epoch 44/170 => Loss 2.881, Loss_clf 0.382, Loss_fe 0.199, Loss_kd 2.210, Train_accy 76.60, Test_accy 80.58
2024-08-02 13:07:51,059 [foster.py] => Task 1, Epoch 45/170 => Loss 2.900, Loss_clf 0.391, Loss_fe 0.200, Loss_kd 2.220, Train_accy 72.15, Test_accy 80.12
2024-08-02 13:07:53,162 [foster.py] => Task 1, Epoch 46/170 => Loss 2.851, Loss_clf 0.372, Loss_fe 0.196, Loss_kd 2.194, Train_accy 75.80
2024-08-02 13:07:56,599 [foster.py] => Task 1, Epoch 47/170 => Loss 2.822, Loss_clf 0.356, Loss_fe 0.181, Loss_kd 2.197, Train_accy 75.30, Test_accy 80.44
2024-08-02 13:08:00,005 [foster.py] => Task 1, Epoch 48/170 => Loss 2.846, Loss_clf 0.374, Loss_fe 0.176, Loss_kd 2.206, Train_accy 76.15, Test_accy 80.60
2024-08-02 13:08:03,401 [foster.py] => Task 1, Epoch 49/170 => Loss 2.883, Loss_clf 0.367, Loss_fe 0.184, Loss_kd 2.241, Train_accy 75.80, Test_accy 80.81
2024-08-02 13:08:06,836 [foster.py] => Task 1, Epoch 50/170 => Loss 2.834, Loss_clf 0.371, Loss_fe 0.159, Loss_kd 2.215, Train_accy 75.20, Test_accy 80.60
2024-08-02 13:08:08,947 [foster.py] => Task 1, Epoch 51/170 => Loss 2.882, Loss_clf 0.382, Loss_fe 0.192, Loss_kd 2.217, Train_accy 77.20
2024-08-02 13:08:12,411 [foster.py] => Task 1, Epoch 52/170 => Loss 2.882, Loss_clf 0.383, Loss_fe 0.199, Loss_kd 2.211, Train_accy 77.70, Test_accy 80.65
2024-08-02 13:08:15,805 [foster.py] => Task 1, Epoch 53/170 => Loss 2.833, Loss_clf 0.363, Loss_fe 0.171, Loss_kd 2.210, Train_accy 75.00, Test_accy 80.33
2024-08-02 13:08:19,223 [foster.py] => Task 1, Epoch 54/170 => Loss 2.833, Loss_clf 0.360, Loss_fe 0.182, Loss_kd 2.202, Train_accy 76.75, Test_accy 80.60
2024-08-02 13:08:22,637 [foster.py] => Task 1, Epoch 55/170 => Loss 2.845, Loss_clf 0.361, Loss_fe 0.193, Loss_kd 2.202, Train_accy 78.25, Test_accy 80.37
2024-08-02 13:08:24,725 [foster.py] => Task 1, Epoch 56/170 => Loss 2.874, Loss_clf 0.374, Loss_fe 0.188, Loss_kd 2.222, Train_accy 77.60
2024-08-02 13:08:28,205 [foster.py] => Task 1, Epoch 57/170 => Loss 2.883, Loss_clf 0.385, Loss_fe 0.189, Loss_kd 2.219, Train_accy 74.35, Test_accy 80.38
2024-08-02 13:08:31,673 [foster.py] => Task 1, Epoch 58/170 => Loss 2.865, Loss_clf 0.372, Loss_fe 0.179, Loss_kd 2.225, Train_accy 75.85, Test_accy 80.40
2024-08-02 13:08:35,121 [foster.py] => Task 1, Epoch 59/170 => Loss 2.859, Loss_clf 0.377, Loss_fe 0.185, Loss_kd 2.207, Train_accy 74.50, Test_accy 80.06
2024-08-02 13:08:38,632 [foster.py] => Task 1, Epoch 60/170 => Loss 2.817, Loss_clf 0.352, Loss_fe 0.159, Loss_kd 2.216, Train_accy 77.05, Test_accy 80.62
2024-08-02 13:08:40,835 [foster.py] => Task 1, Epoch 61/170 => Loss 2.851, Loss_clf 0.373, Loss_fe 0.186, Loss_kd 2.202, Train_accy 76.20
2024-08-02 13:08:44,349 [foster.py] => Task 1, Epoch 62/170 => Loss 2.821, Loss_clf 0.364, Loss_fe 0.162, Loss_kd 2.205, Train_accy 76.95, Test_accy 81.02
2024-08-02 13:08:47,831 [foster.py] => Task 1, Epoch 63/170 => Loss 2.764, Loss_clf 0.331, Loss_fe 0.156, Loss_kd 2.189, Train_accy 77.50, Test_accy 80.83
2024-08-02 13:08:51,371 [foster.py] => Task 1, Epoch 64/170 => Loss 2.881, Loss_clf 0.389, Loss_fe 0.175, Loss_kd 2.226, Train_accy 77.30, Test_accy 80.77
2024-08-02 13:08:54,887 [foster.py] => Task 1, Epoch 65/170 => Loss 2.856, Loss_clf 0.373, Loss_fe 0.182, Loss_kd 2.211, Train_accy 77.60, Test_accy 80.69
2024-08-02 13:08:56,998 [foster.py] => Task 1, Epoch 66/170 => Loss 2.813, Loss_clf 0.362, Loss_fe 0.164, Loss_kd 2.198, Train_accy 78.60
2024-08-02 13:09:00,484 [foster.py] => Task 1, Epoch 67/170 => Loss 2.804, Loss_clf 0.353, Loss_fe 0.142, Loss_kd 2.219, Train_accy 76.40, Test_accy 80.35
2024-08-02 13:09:03,985 [foster.py] => Task 1, Epoch 68/170 => Loss 2.850, Loss_clf 0.353, Loss_fe 0.183, Loss_kd 2.223, Train_accy 77.80, Test_accy 80.88
2024-08-02 13:09:07,416 [foster.py] => Task 1, Epoch 69/170 => Loss 2.800, Loss_clf 0.339, Loss_fe 0.160, Loss_kd 2.211, Train_accy 79.55, Test_accy 80.42
2024-08-02 13:09:10,804 [foster.py] => Task 1, Epoch 70/170 => Loss 2.702, Loss_clf 0.283, Loss_fe 0.133, Loss_kd 2.196, Train_accy 80.10, Test_accy 80.50
2024-08-02 13:09:12,915 [foster.py] => Task 1, Epoch 71/170 => Loss 2.868, Loss_clf 0.379, Loss_fe 0.173, Loss_kd 2.226, Train_accy 77.35
2024-08-02 13:09:16,401 [foster.py] => Task 1, Epoch 72/170 => Loss 2.850, Loss_clf 0.380, Loss_fe 0.181, Loss_kd 2.200, Train_accy 76.40, Test_accy 80.54
2024-08-02 13:09:19,787 [foster.py] => Task 1, Epoch 73/170 => Loss 2.839, Loss_clf 0.375, Loss_fe 0.149, Loss_kd 2.225, Train_accy 76.45, Test_accy 80.58
2024-08-02 13:09:23,204 [foster.py] => Task 1, Epoch 74/170 => Loss 2.836, Loss_clf 0.349, Loss_fe 0.162, Loss_kd 2.235, Train_accy 77.95, Test_accy 80.42
2024-08-02 13:09:26,618 [foster.py] => Task 1, Epoch 75/170 => Loss 2.814, Loss_clf 0.362, Loss_fe 0.145, Loss_kd 2.217, Train_accy 77.05, Test_accy 80.62
2024-08-02 13:09:28,716 [foster.py] => Task 1, Epoch 76/170 => Loss 2.784, Loss_clf 0.330, Loss_fe 0.138, Loss_kd 2.226, Train_accy 78.70
2024-08-02 13:09:32,114 [foster.py] => Task 1, Epoch 77/170 => Loss 2.775, Loss_clf 0.332, Loss_fe 0.125, Loss_kd 2.227, Train_accy 78.35, Test_accy 80.83
2024-08-02 13:09:35,542 [foster.py] => Task 1, Epoch 78/170 => Loss 2.814, Loss_clf 0.359, Loss_fe 0.153, Loss_kd 2.212, Train_accy 79.10, Test_accy 80.65
2024-08-02 13:09:39,082 [foster.py] => Task 1, Epoch 79/170 => Loss 2.785, Loss_clf 0.351, Loss_fe 0.133, Loss_kd 2.210, Train_accy 77.75, Test_accy 80.73
2024-08-02 13:09:42,612 [foster.py] => Task 1, Epoch 80/170 => Loss 2.708, Loss_clf 0.313, Loss_fe 0.132, Loss_kd 2.175, Train_accy 80.10, Test_accy 80.77
2024-08-02 13:09:44,802 [foster.py] => Task 1, Epoch 81/170 => Loss 2.735, Loss_clf 0.324, Loss_fe 0.137, Loss_kd 2.185, Train_accy 79.75
2024-08-02 13:09:48,306 [foster.py] => Task 1, Epoch 82/170 => Loss 2.794, Loss_clf 0.340, Loss_fe 0.145, Loss_kd 2.219, Train_accy 80.10, Test_accy 80.83
2024-08-02 13:09:51,813 [foster.py] => Task 1, Epoch 83/170 => Loss 2.845, Loss_clf 0.372, Loss_fe 0.153, Loss_kd 2.230, Train_accy 78.15, Test_accy 80.48
2024-08-02 13:09:55,387 [foster.py] => Task 1, Epoch 84/170 => Loss 2.733, Loss_clf 0.318, Loss_fe 0.128, Loss_kd 2.197, Train_accy 80.55, Test_accy 80.40
2024-08-02 13:09:58,916 [foster.py] => Task 1, Epoch 85/170 => Loss 2.832, Loss_clf 0.374, Loss_fe 0.148, Loss_kd 2.220, Train_accy 78.50, Test_accy 80.77
2024-08-02 13:10:01,105 [foster.py] => Task 1, Epoch 86/170 => Loss 2.855, Loss_clf 0.389, Loss_fe 0.150, Loss_kd 2.226, Train_accy 77.50
2024-08-02 13:10:04,603 [foster.py] => Task 1, Epoch 87/170 => Loss 2.829, Loss_clf 0.372, Loss_fe 0.155, Loss_kd 2.212, Train_accy 78.95, Test_accy 80.52
2024-08-02 13:10:08,170 [foster.py] => Task 1, Epoch 88/170 => Loss 2.825, Loss_clf 0.370, Loss_fe 0.140, Loss_kd 2.224, Train_accy 79.30, Test_accy 80.62
2024-08-02 13:10:11,684 [foster.py] => Task 1, Epoch 89/170 => Loss 2.721, Loss_clf 0.313, Loss_fe 0.127, Loss_kd 2.192, Train_accy 78.65, Test_accy 80.29
2024-08-02 13:10:15,230 [foster.py] => Task 1, Epoch 90/170 => Loss 2.771, Loss_clf 0.335, Loss_fe 0.136, Loss_kd 2.210, Train_accy 80.40, Test_accy 80.62
2024-08-02 13:10:17,328 [foster.py] => Task 1, Epoch 91/170 => Loss 2.760, Loss_clf 0.327, Loss_fe 0.126, Loss_kd 2.217, Train_accy 78.70
2024-08-02 13:10:20,747 [foster.py] => Task 1, Epoch 92/170 => Loss 2.807, Loss_clf 0.351, Loss_fe 0.167, Loss_kd 2.200, Train_accy 78.75, Test_accy 80.60
2024-08-02 13:10:24,239 [foster.py] => Task 1, Epoch 93/170 => Loss 2.828, Loss_clf 0.361, Loss_fe 0.153, Loss_kd 2.223, Train_accy 77.70, Test_accy 80.81
2024-08-02 13:10:27,606 [foster.py] => Task 1, Epoch 94/170 => Loss 2.719, Loss_clf 0.312, Loss_fe 0.119, Loss_kd 2.199, Train_accy 77.85, Test_accy 80.29
2024-08-02 13:10:31,035 [foster.py] => Task 1, Epoch 95/170 => Loss 2.827, Loss_clf 0.358, Loss_fe 0.144, Loss_kd 2.234, Train_accy 80.05, Test_accy 80.67
2024-08-02 13:10:33,146 [foster.py] => Task 1, Epoch 96/170 => Loss 2.714, Loss_clf 0.316, Loss_fe 0.109, Loss_kd 2.199, Train_accy 79.75
2024-08-02 13:10:36,576 [foster.py] => Task 1, Epoch 97/170 => Loss 2.774, Loss_clf 0.341, Loss_fe 0.127, Loss_kd 2.216, Train_accy 79.55, Test_accy 80.69
2024-08-02 13:10:39,998 [foster.py] => Task 1, Epoch 98/170 => Loss 2.765, Loss_clf 0.321, Loss_fe 0.129, Loss_kd 2.224, Train_accy 81.70, Test_accy 80.63
2024-08-02 13:10:43,409 [foster.py] => Task 1, Epoch 99/170 => Loss 2.781, Loss_clf 0.352, Loss_fe 0.125, Loss_kd 2.214, Train_accy 79.40, Test_accy 80.65
2024-08-02 13:10:46,826 [foster.py] => Task 1, Epoch 100/170 => Loss 2.757, Loss_clf 0.335, Loss_fe 0.128, Loss_kd 2.204, Train_accy 80.65, Test_accy 80.63
2024-08-02 13:10:48,916 [foster.py] => Task 1, Epoch 101/170 => Loss 2.774, Loss_clf 0.340, Loss_fe 0.111, Loss_kd 2.233, Train_accy 79.40
2024-08-02 13:10:52,387 [foster.py] => Task 1, Epoch 102/170 => Loss 2.754, Loss_clf 0.333, Loss_fe 0.122, Loss_kd 2.209, Train_accy 79.30, Test_accy 80.67
2024-08-02 13:10:55,806 [foster.py] => Task 1, Epoch 103/170 => Loss 2.709, Loss_clf 0.315, Loss_fe 0.106, Loss_kd 2.198, Train_accy 80.50, Test_accy 80.60
2024-08-02 13:10:59,308 [foster.py] => Task 1, Epoch 104/170 => Loss 2.739, Loss_clf 0.340, Loss_fe 0.101, Loss_kd 2.208, Train_accy 80.60, Test_accy 80.87
2024-08-02 13:11:02,719 [foster.py] => Task 1, Epoch 105/170 => Loss 2.766, Loss_clf 0.338, Loss_fe 0.119, Loss_kd 2.218, Train_accy 81.55, Test_accy 80.71
2024-08-02 13:11:04,842 [foster.py] => Task 1, Epoch 106/170 => Loss 2.706, Loss_clf 0.305, Loss_fe 0.111, Loss_kd 2.201, Train_accy 81.85
2024-08-02 13:11:08,297 [foster.py] => Task 1, Epoch 107/170 => Loss 2.722, Loss_clf 0.336, Loss_fe 0.111, Loss_kd 2.186, Train_accy 81.70, Test_accy 80.50
2024-08-02 13:11:11,769 [foster.py] => Task 1, Epoch 108/170 => Loss 2.711, Loss_clf 0.308, Loss_fe 0.101, Loss_kd 2.211, Train_accy 83.20, Test_accy 80.56
2024-08-02 13:11:15,158 [foster.py] => Task 1, Epoch 109/170 => Loss 2.756, Loss_clf 0.331, Loss_fe 0.118, Loss_kd 2.216, Train_accy 81.80, Test_accy 80.81
2024-08-02 13:11:18,575 [foster.py] => Task 1, Epoch 110/170 => Loss 2.739, Loss_clf 0.330, Loss_fe 0.116, Loss_kd 2.204, Train_accy 81.50, Test_accy 81.06
2024-08-02 13:11:20,690 [foster.py] => Task 1, Epoch 111/170 => Loss 2.746, Loss_clf 0.329, Loss_fe 0.120, Loss_kd 2.208, Train_accy 81.15
2024-08-02 13:11:24,090 [foster.py] => Task 1, Epoch 112/170 => Loss 2.742, Loss_clf 0.324, Loss_fe 0.107, Loss_kd 2.221, Train_accy 81.70, Test_accy 80.54
2024-08-02 13:11:27,557 [foster.py] => Task 1, Epoch 113/170 => Loss 2.739, Loss_clf 0.318, Loss_fe 0.121, Loss_kd 2.210, Train_accy 79.80, Test_accy 80.77
2024-08-02 13:11:30,958 [foster.py] => Task 1, Epoch 114/170 => Loss 2.727, Loss_clf 0.323, Loss_fe 0.096, Loss_kd 2.218, Train_accy 79.80, Test_accy 80.81
2024-08-02 13:11:34,364 [foster.py] => Task 1, Epoch 115/170 => Loss 2.779, Loss_clf 0.340, Loss_fe 0.115, Loss_kd 2.233, Train_accy 82.00, Test_accy 80.73
2024-08-02 13:11:36,505 [foster.py] => Task 1, Epoch 116/170 => Loss 2.759, Loss_clf 0.328, Loss_fe 0.123, Loss_kd 2.219, Train_accy 82.35
2024-08-02 13:11:39,908 [foster.py] => Task 1, Epoch 117/170 => Loss 2.743, Loss_clf 0.320, Loss_fe 0.102, Loss_kd 2.231, Train_accy 80.15, Test_accy 80.65
2024-08-02 13:11:43,323 [foster.py] => Task 1, Epoch 118/170 => Loss 2.727, Loss_clf 0.324, Loss_fe 0.103, Loss_kd 2.210, Train_accy 81.25, Test_accy 80.73
2024-08-02 13:11:46,738 [foster.py] => Task 1, Epoch 119/170 => Loss 2.772, Loss_clf 0.331, Loss_fe 0.117, Loss_kd 2.233, Train_accy 81.95, Test_accy 80.54
2024-08-02 13:11:50,151 [foster.py] => Task 1, Epoch 120/170 => Loss 2.717, Loss_clf 0.310, Loss_fe 0.112, Loss_kd 2.206, Train_accy 82.10, Test_accy 80.67
2024-08-02 13:11:52,280 [foster.py] => Task 1, Epoch 121/170 => Loss 2.744, Loss_clf 0.337, Loss_fe 0.113, Loss_kd 2.204, Train_accy 80.40
2024-08-02 13:11:55,684 [foster.py] => Task 1, Epoch 122/170 => Loss 2.706, Loss_clf 0.295, Loss_fe 0.101, Loss_kd 2.220, Train_accy 81.45, Test_accy 80.58
2024-08-02 13:11:59,077 [foster.py] => Task 1, Epoch 123/170 => Loss 2.715, Loss_clf 0.309, Loss_fe 0.105, Loss_kd 2.212, Train_accy 82.20, Test_accy 80.69
2024-08-02 13:12:02,497 [foster.py] => Task 1, Epoch 124/170 => Loss 2.712, Loss_clf 0.315, Loss_fe 0.108, Loss_kd 2.200, Train_accy 80.65, Test_accy 80.73
2024-08-02 13:12:05,958 [foster.py] => Task 1, Epoch 125/170 => Loss 2.663, Loss_clf 0.286, Loss_fe 0.091, Loss_kd 2.197, Train_accy 82.60, Test_accy 80.73
2024-08-02 13:12:08,060 [foster.py] => Task 1, Epoch 126/170 => Loss 2.716, Loss_clf 0.316, Loss_fe 0.096, Loss_kd 2.214, Train_accy 81.85
2024-08-02 13:12:11,510 [foster.py] => Task 1, Epoch 127/170 => Loss 2.689, Loss_clf 0.293, Loss_fe 0.089, Loss_kd 2.217, Train_accy 83.70, Test_accy 80.90
2024-08-02 13:12:14,907 [foster.py] => Task 1, Epoch 128/170 => Loss 2.725, Loss_clf 0.307, Loss_fe 0.109, Loss_kd 2.219, Train_accy 82.60, Test_accy 80.87
2024-08-02 13:12:18,349 [foster.py] => Task 1, Epoch 129/170 => Loss 2.744, Loss_clf 0.331, Loss_fe 0.112, Loss_kd 2.211, Train_accy 82.35, Test_accy 80.92
2024-08-02 13:12:21,764 [foster.py] => Task 1, Epoch 130/170 => Loss 2.704, Loss_clf 0.313, Loss_fe 0.099, Loss_kd 2.202, Train_accy 81.85, Test_accy 80.87
2024-08-02 13:12:23,892 [foster.py] => Task 1, Epoch 131/170 => Loss 2.682, Loss_clf 0.301, Loss_fe 0.093, Loss_kd 2.198, Train_accy 82.30
2024-08-02 13:12:27,342 [foster.py] => Task 1, Epoch 132/170 => Loss 2.726, Loss_clf 0.333, Loss_fe 0.101, Loss_kd 2.202, Train_accy 81.15, Test_accy 80.79
2024-08-02 13:12:30,735 [foster.py] => Task 1, Epoch 133/170 => Loss 2.701, Loss_clf 0.308, Loss_fe 0.090, Loss_kd 2.213, Train_accy 82.45, Test_accy 80.77
2024-08-02 13:12:34,144 [foster.py] => Task 1, Epoch 134/170 => Loss 2.717, Loss_clf 0.325, Loss_fe 0.090, Loss_kd 2.213, Train_accy 81.80, Test_accy 80.65
2024-08-02 13:12:37,544 [foster.py] => Task 1, Epoch 135/170 => Loss 2.703, Loss_clf 0.305, Loss_fe 0.087, Loss_kd 2.221, Train_accy 82.30, Test_accy 80.67
2024-08-02 13:12:39,664 [foster.py] => Task 1, Epoch 136/170 => Loss 2.688, Loss_clf 0.312, Loss_fe 0.087, Loss_kd 2.200, Train_accy 83.50
2024-08-02 13:12:43,094 [foster.py] => Task 1, Epoch 137/170 => Loss 2.742, Loss_clf 0.339, Loss_fe 0.094, Loss_kd 2.220, Train_accy 81.00, Test_accy 80.67
2024-08-02 13:12:46,484 [foster.py] => Task 1, Epoch 138/170 => Loss 2.699, Loss_clf 0.312, Loss_fe 0.091, Loss_kd 2.205, Train_accy 82.95, Test_accy 80.87
2024-08-02 13:12:49,902 [foster.py] => Task 1, Epoch 139/170 => Loss 2.741, Loss_clf 0.330, Loss_fe 0.098, Loss_kd 2.223, Train_accy 82.35, Test_accy 80.81
2024-08-02 13:12:53,339 [foster.py] => Task 1, Epoch 140/170 => Loss 2.668, Loss_clf 0.285, Loss_fe 0.100, Loss_kd 2.194, Train_accy 82.70, Test_accy 80.90
2024-08-02 13:12:55,442 [foster.py] => Task 1, Epoch 141/170 => Loss 2.707, Loss_clf 0.309, Loss_fe 0.093, Loss_kd 2.215, Train_accy 82.85
2024-08-02 13:12:58,836 [foster.py] => Task 1, Epoch 142/170 => Loss 2.686, Loss_clf 0.303, Loss_fe 0.082, Loss_kd 2.212, Train_accy 82.55, Test_accy 80.79
2024-08-02 13:13:02,249 [foster.py] => Task 1, Epoch 143/170 => Loss 2.720, Loss_clf 0.319, Loss_fe 0.097, Loss_kd 2.214, Train_accy 82.45, Test_accy 80.75
2024-08-02 13:13:05,699 [foster.py] => Task 1, Epoch 144/170 => Loss 2.709, Loss_clf 0.307, Loss_fe 0.100, Loss_kd 2.212, Train_accy 82.70, Test_accy 80.79
2024-08-02 13:13:09,108 [foster.py] => Task 1, Epoch 145/170 => Loss 2.739, Loss_clf 0.314, Loss_fe 0.106, Loss_kd 2.229, Train_accy 83.90, Test_accy 80.71
2024-08-02 13:13:11,217 [foster.py] => Task 1, Epoch 146/170 => Loss 2.670, Loss_clf 0.304, Loss_fe 0.069, Loss_kd 2.207, Train_accy 82.90
2024-08-02 13:13:14,718 [foster.py] => Task 1, Epoch 147/170 => Loss 2.711, Loss_clf 0.330, Loss_fe 0.098, Loss_kd 2.194, Train_accy 82.45, Test_accy 80.75
2024-08-02 13:13:18,100 [foster.py] => Task 1, Epoch 148/170 => Loss 2.713, Loss_clf 0.320, Loss_fe 0.095, Loss_kd 2.208, Train_accy 81.65, Test_accy 80.81
2024-08-02 13:13:21,531 [foster.py] => Task 1, Epoch 149/170 => Loss 2.726, Loss_clf 0.336, Loss_fe 0.088, Loss_kd 2.212, Train_accy 81.70, Test_accy 80.69
2024-08-02 13:13:24,925 [foster.py] => Task 1, Epoch 150/170 => Loss 2.680, Loss_clf 0.295, Loss_fe 0.089, Loss_kd 2.207, Train_accy 82.50, Test_accy 80.69
2024-08-02 13:13:27,022 [foster.py] => Task 1, Epoch 151/170 => Loss 2.715, Loss_clf 0.335, Loss_fe 0.097, Loss_kd 2.195, Train_accy 82.45
2024-08-02 13:13:30,424 [foster.py] => Task 1, Epoch 152/170 => Loss 2.721, Loss_clf 0.317, Loss_fe 0.088, Loss_kd 2.226, Train_accy 82.70, Test_accy 80.73
2024-08-02 13:13:33,911 [foster.py] => Task 1, Epoch 153/170 => Loss 2.718, Loss_clf 0.313, Loss_fe 0.092, Loss_kd 2.223, Train_accy 83.35, Test_accy 80.69
2024-08-02 13:13:37,437 [foster.py] => Task 1, Epoch 154/170 => Loss 2.709, Loss_clf 0.313, Loss_fe 0.090, Loss_kd 2.216, Train_accy 82.80, Test_accy 80.67
2024-08-02 13:13:41,002 [foster.py] => Task 1, Epoch 155/170 => Loss 2.670, Loss_clf 0.287, Loss_fe 0.084, Loss_kd 2.209, Train_accy 83.95, Test_accy 80.81
2024-08-02 13:13:43,241 [foster.py] => Task 1, Epoch 156/170 => Loss 2.699, Loss_clf 0.318, Loss_fe 0.096, Loss_kd 2.196, Train_accy 82.10
2024-08-02 13:13:46,657 [foster.py] => Task 1, Epoch 157/170 => Loss 2.726, Loss_clf 0.334, Loss_fe 0.096, Loss_kd 2.206, Train_accy 80.60, Test_accy 80.69
2024-08-02 13:13:50,085 [foster.py] => Task 1, Epoch 158/170 => Loss 2.664, Loss_clf 0.280, Loss_fe 0.077, Loss_kd 2.217, Train_accy 82.60, Test_accy 80.75
2024-08-02 13:13:53,484 [foster.py] => Task 1, Epoch 159/170 => Loss 2.727, Loss_clf 0.313, Loss_fe 0.093, Loss_kd 2.231, Train_accy 82.05, Test_accy 80.75
2024-08-02 13:13:56,896 [foster.py] => Task 1, Epoch 160/170 => Loss 2.702, Loss_clf 0.317, Loss_fe 0.082, Loss_kd 2.214, Train_accy 82.00, Test_accy 80.81
2024-08-02 13:13:59,038 [foster.py] => Task 1, Epoch 161/170 => Loss 2.726, Loss_clf 0.314, Loss_fe 0.089, Loss_kd 2.233, Train_accy 81.85
2024-08-02 13:14:02,454 [foster.py] => Task 1, Epoch 162/170 => Loss 2.680, Loss_clf 0.284, Loss_fe 0.084, Loss_kd 2.222, Train_accy 83.50, Test_accy 80.77
2024-08-02 13:14:05,882 [foster.py] => Task 1, Epoch 163/170 => Loss 2.652, Loss_clf 0.289, Loss_fe 0.079, Loss_kd 2.195, Train_accy 83.60, Test_accy 80.71
2024-08-02 13:14:09,358 [foster.py] => Task 1, Epoch 164/170 => Loss 2.681, Loss_clf 0.289, Loss_fe 0.079, Loss_kd 2.222, Train_accy 82.95, Test_accy 80.75
2024-08-02 13:14:12,790 [foster.py] => Task 1, Epoch 165/170 => Loss 2.736, Loss_clf 0.325, Loss_fe 0.087, Loss_kd 2.233, Train_accy 83.30, Test_accy 80.83
2024-08-02 13:14:14,922 [foster.py] => Task 1, Epoch 166/170 => Loss 2.700, Loss_clf 0.311, Loss_fe 0.073, Loss_kd 2.225, Train_accy 81.40
2024-08-02 13:14:18,338 [foster.py] => Task 1, Epoch 167/170 => Loss 2.720, Loss_clf 0.317, Loss_fe 0.094, Loss_kd 2.219, Train_accy 82.00, Test_accy 80.73
2024-08-02 13:14:21,777 [foster.py] => Task 1, Epoch 168/170 => Loss 2.640, Loss_clf 0.286, Loss_fe 0.076, Loss_kd 2.190, Train_accy 82.00, Test_accy 80.65
2024-08-02 13:14:25,165 [foster.py] => Task 1, Epoch 169/170 => Loss 2.700, Loss_clf 0.310, Loss_fe 0.075, Loss_kd 2.225, Train_accy 82.55, Test_accy 80.71
2024-08-02 13:14:28,582 [foster.py] => Task 1, Epoch 170/170 => Loss 2.741, Loss_clf 0.334, Loss_fe 0.094, Loss_kd 2.222, Train_accy 80.60, Test_accy 80.75
2024-08-02 13:14:28,584 [foster.py] => do not weight align teacher!
2024-08-02 13:14:28,585 [foster.py] => per cls weights : [1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831 1.02107831
 1.02107831 1.02107831 0.47304214 0.47304214]
2024-08-02 13:14:33,233 [foster.py] => SNet: Task 1, Epoch 1/130 => Loss 27.142,  Loss1 0.679, Train_accy 40.45, Test_accy 76.69
2024-08-02 13:14:36,145 [foster.py] => SNet: Task 1, Epoch 2/130 => Loss 27.015,  Loss1 0.677, Train_accy 41.45
2024-08-02 13:14:39,032 [foster.py] => SNet: Task 1, Epoch 3/130 => Loss 26.918,  Loss1 0.676, Train_accy 49.20
2024-08-02 13:14:42,000 [foster.py] => SNet: Task 1, Epoch 4/130 => Loss 26.904,  Loss1 0.675, Train_accy 50.55
2024-08-02 13:14:44,877 [foster.py] => SNet: Task 1, Epoch 5/130 => Loss 26.910,  Loss1 0.674, Train_accy 50.90
2024-08-02 13:14:48,651 [foster.py] => SNet: Task 1, Epoch 6/130 => Loss 26.868,  Loss1 0.675, Train_accy 53.30, Test_accy 79.04
2024-08-02 13:14:51,542 [foster.py] => SNet: Task 1, Epoch 7/130 => Loss 26.834,  Loss1 0.675, Train_accy 54.05
2024-08-02 13:14:54,428 [foster.py] => SNet: Task 1, Epoch 8/130 => Loss 26.884,  Loss1 0.674, Train_accy 52.85
2024-08-02 13:14:57,314 [foster.py] => SNet: Task 1, Epoch 9/130 => Loss 26.926,  Loss1 0.675, Train_accy 56.80
2024-08-02 13:15:00,198 [foster.py] => SNet: Task 1, Epoch 10/130 => Loss 26.888,  Loss1 0.675, Train_accy 56.80
2024-08-02 13:15:03,993 [foster.py] => SNet: Task 1, Epoch 11/130 => Loss 26.937,  Loss1 0.675, Train_accy 57.45, Test_accy 79.13
2024-08-02 13:15:06,880 [foster.py] => SNet: Task 1, Epoch 12/130 => Loss 26.830,  Loss1 0.675, Train_accy 57.75
2024-08-02 13:15:09,790 [foster.py] => SNet: Task 1, Epoch 13/130 => Loss 26.919,  Loss1 0.676, Train_accy 57.35
2024-08-02 13:15:12,688 [foster.py] => SNet: Task 1, Epoch 14/130 => Loss 26.832,  Loss1 0.675, Train_accy 58.75
2024-08-02 13:15:15,585 [foster.py] => SNet: Task 1, Epoch 15/130 => Loss 26.889,  Loss1 0.674, Train_accy 58.45
2024-08-02 13:15:19,361 [foster.py] => SNet: Task 1, Epoch 16/130 => Loss 26.892,  Loss1 0.675, Train_accy 61.00, Test_accy 79.56
2024-08-02 13:15:22,246 [foster.py] => SNet: Task 1, Epoch 17/130 => Loss 26.887,  Loss1 0.675, Train_accy 60.45
2024-08-02 13:15:25,161 [foster.py] => SNet: Task 1, Epoch 18/130 => Loss 26.866,  Loss1 0.675, Train_accy 59.75
2024-08-02 13:15:28,079 [foster.py] => SNet: Task 1, Epoch 19/130 => Loss 26.860,  Loss1 0.675, Train_accy 59.40
2024-08-02 13:15:30,984 [foster.py] => SNet: Task 1, Epoch 20/130 => Loss 26.843,  Loss1 0.675, Train_accy 62.40
2024-08-02 13:15:34,757 [foster.py] => SNet: Task 1, Epoch 21/130 => Loss 26.830,  Loss1 0.675, Train_accy 62.25, Test_accy 79.44
2024-08-02 13:15:37,633 [foster.py] => SNet: Task 1, Epoch 22/130 => Loss 26.801,  Loss1 0.675, Train_accy 61.75
2024-08-02 13:15:40,511 [foster.py] => SNet: Task 1, Epoch 23/130 => Loss 26.874,  Loss1 0.676, Train_accy 61.95
2024-08-02 13:15:43,407 [foster.py] => SNet: Task 1, Epoch 24/130 => Loss 26.836,  Loss1 0.675, Train_accy 62.00
2024-08-02 13:15:46,357 [foster.py] => SNet: Task 1, Epoch 25/130 => Loss 26.848,  Loss1 0.675, Train_accy 63.50
2024-08-02 13:15:50,097 [foster.py] => SNet: Task 1, Epoch 26/130 => Loss 26.858,  Loss1 0.675, Train_accy 62.15, Test_accy 79.42
2024-08-02 13:15:53,003 [foster.py] => SNet: Task 1, Epoch 27/130 => Loss 26.832,  Loss1 0.675, Train_accy 62.00
2024-08-02 13:15:55,885 [foster.py] => SNet: Task 1, Epoch 28/130 => Loss 26.870,  Loss1 0.675, Train_accy 63.05
2024-08-02 13:15:58,770 [foster.py] => SNet: Task 1, Epoch 29/130 => Loss 26.828,  Loss1 0.675, Train_accy 63.60
2024-08-02 13:16:01,665 [foster.py] => SNet: Task 1, Epoch 30/130 => Loss 26.883,  Loss1 0.675, Train_accy 63.05
2024-08-02 13:16:05,435 [foster.py] => SNet: Task 1, Epoch 31/130 => Loss 26.842,  Loss1 0.675, Train_accy 61.85, Test_accy 79.65
2024-08-02 13:16:08,333 [foster.py] => SNet: Task 1, Epoch 32/130 => Loss 26.857,  Loss1 0.675, Train_accy 62.85
2024-08-02 13:16:11,228 [foster.py] => SNet: Task 1, Epoch 33/130 => Loss 26.866,  Loss1 0.675, Train_accy 63.45
2024-08-02 13:16:14,111 [foster.py] => SNet: Task 1, Epoch 34/130 => Loss 26.827,  Loss1 0.675, Train_accy 64.15
2024-08-02 13:16:17,029 [foster.py] => SNet: Task 1, Epoch 35/130 => Loss 26.855,  Loss1 0.675, Train_accy 63.70
2024-08-02 13:16:20,786 [foster.py] => SNet: Task 1, Epoch 36/130 => Loss 26.835,  Loss1 0.675, Train_accy 63.90, Test_accy 79.67
2024-08-02 13:16:23,672 [foster.py] => SNet: Task 1, Epoch 37/130 => Loss 26.881,  Loss1 0.675, Train_accy 65.05
2024-08-02 13:16:26,577 [foster.py] => SNet: Task 1, Epoch 38/130 => Loss 26.833,  Loss1 0.675, Train_accy 65.05
2024-08-02 13:16:29,485 [foster.py] => SNet: Task 1, Epoch 39/130 => Loss 26.824,  Loss1 0.675, Train_accy 64.40
2024-08-02 13:16:32,391 [foster.py] => SNet: Task 1, Epoch 40/130 => Loss 26.832,  Loss1 0.675, Train_accy 62.15
2024-08-02 13:16:36,142 [foster.py] => SNet: Task 1, Epoch 41/130 => Loss 26.861,  Loss1 0.675, Train_accy 63.00, Test_accy 79.96
2024-08-02 13:16:39,055 [foster.py] => SNet: Task 1, Epoch 42/130 => Loss 26.870,  Loss1 0.675, Train_accy 64.50
2024-08-02 13:16:41,988 [foster.py] => SNet: Task 1, Epoch 43/130 => Loss 26.813,  Loss1 0.675, Train_accy 65.00
2024-08-02 13:16:44,884 [foster.py] => SNet: Task 1, Epoch 44/130 => Loss 26.852,  Loss1 0.675, Train_accy 64.60
2024-08-02 13:16:47,777 [foster.py] => SNet: Task 1, Epoch 45/130 => Loss 26.910,  Loss1 0.675, Train_accy 64.10
2024-08-02 13:16:51,539 [foster.py] => SNet: Task 1, Epoch 46/130 => Loss 26.742,  Loss1 0.675, Train_accy 65.20, Test_accy 79.62
2024-08-02 13:16:54,510 [foster.py] => SNet: Task 1, Epoch 47/130 => Loss 26.918,  Loss1 0.675, Train_accy 63.65
2024-08-02 13:16:57,398 [foster.py] => SNet: Task 1, Epoch 48/130 => Loss 26.842,  Loss1 0.675, Train_accy 65.80
2024-08-02 13:17:00,294 [foster.py] => SNet: Task 1, Epoch 49/130 => Loss 26.846,  Loss1 0.675, Train_accy 64.40
2024-08-02 13:17:03,201 [foster.py] => SNet: Task 1, Epoch 50/130 => Loss 26.832,  Loss1 0.675, Train_accy 63.90
2024-08-02 13:17:06,947 [foster.py] => SNet: Task 1, Epoch 51/130 => Loss 26.819,  Loss1 0.675, Train_accy 64.70, Test_accy 80.04
2024-08-02 13:17:09,846 [foster.py] => SNet: Task 1, Epoch 52/130 => Loss 26.826,  Loss1 0.675, Train_accy 64.25
2024-08-02 13:17:12,749 [foster.py] => SNet: Task 1, Epoch 53/130 => Loss 26.811,  Loss1 0.675, Train_accy 65.75
2024-08-02 13:17:15,649 [foster.py] => SNet: Task 1, Epoch 54/130 => Loss 26.796,  Loss1 0.675, Train_accy 65.45
2024-08-02 13:17:18,551 [foster.py] => SNet: Task 1, Epoch 55/130 => Loss 26.909,  Loss1 0.675, Train_accy 65.90
2024-08-02 13:17:22,343 [foster.py] => SNet: Task 1, Epoch 56/130 => Loss 26.839,  Loss1 0.675, Train_accy 65.95, Test_accy 79.71
2024-08-02 13:17:25,244 [foster.py] => SNet: Task 1, Epoch 57/130 => Loss 26.820,  Loss1 0.675, Train_accy 65.20
2024-08-02 13:17:28,135 [foster.py] => SNet: Task 1, Epoch 58/130 => Loss 26.831,  Loss1 0.674, Train_accy 65.45
2024-08-02 13:17:31,038 [foster.py] => SNet: Task 1, Epoch 59/130 => Loss 26.825,  Loss1 0.675, Train_accy 63.95
2024-08-02 13:17:33,916 [foster.py] => SNet: Task 1, Epoch 60/130 => Loss 26.858,  Loss1 0.675, Train_accy 67.15
2024-08-02 13:17:37,679 [foster.py] => SNet: Task 1, Epoch 61/130 => Loss 26.866,  Loss1 0.675, Train_accy 64.65, Test_accy 79.81
2024-08-02 13:17:40,579 [foster.py] => SNet: Task 1, Epoch 62/130 => Loss 26.844,  Loss1 0.676, Train_accy 64.90
2024-08-02 13:17:43,464 [foster.py] => SNet: Task 1, Epoch 63/130 => Loss 26.869,  Loss1 0.675, Train_accy 64.80
2024-08-02 13:17:46,353 [foster.py] => SNet: Task 1, Epoch 64/130 => Loss 26.844,  Loss1 0.675, Train_accy 65.00
2024-08-02 13:17:49,236 [foster.py] => SNet: Task 1, Epoch 65/130 => Loss 26.864,  Loss1 0.675, Train_accy 65.70
2024-08-02 13:17:53,019 [foster.py] => SNet: Task 1, Epoch 66/130 => Loss 26.859,  Loss1 0.675, Train_accy 64.80, Test_accy 79.87
2024-08-02 13:17:55,892 [foster.py] => SNet: Task 1, Epoch 67/130 => Loss 26.865,  Loss1 0.675, Train_accy 65.95
2024-08-02 13:17:58,790 [foster.py] => SNet: Task 1, Epoch 68/130 => Loss 26.770,  Loss1 0.675, Train_accy 66.45
2024-08-02 13:18:01,743 [foster.py] => SNet: Task 1, Epoch 69/130 => Loss 26.837,  Loss1 0.675, Train_accy 66.20
2024-08-02 13:18:04,631 [foster.py] => SNet: Task 1, Epoch 70/130 => Loss 26.883,  Loss1 0.676, Train_accy 65.60
2024-08-02 13:18:08,420 [foster.py] => SNet: Task 1, Epoch 71/130 => Loss 26.771,  Loss1 0.676, Train_accy 65.55, Test_accy 79.94
2024-08-02 13:18:11,337 [foster.py] => SNet: Task 1, Epoch 72/130 => Loss 26.849,  Loss1 0.675, Train_accy 66.15
2024-08-02 13:18:14,235 [foster.py] => SNet: Task 1, Epoch 73/130 => Loss 26.873,  Loss1 0.675, Train_accy 66.20
2024-08-02 13:18:17,133 [foster.py] => SNet: Task 1, Epoch 74/130 => Loss 26.877,  Loss1 0.675, Train_accy 66.20
2024-08-02 13:18:20,016 [foster.py] => SNet: Task 1, Epoch 75/130 => Loss 26.838,  Loss1 0.674, Train_accy 64.55
2024-08-02 13:18:23,775 [foster.py] => SNet: Task 1, Epoch 76/130 => Loss 26.835,  Loss1 0.675, Train_accy 65.85, Test_accy 79.92
2024-08-02 13:18:26,676 [foster.py] => SNet: Task 1, Epoch 77/130 => Loss 26.871,  Loss1 0.675, Train_accy 65.80
2024-08-02 13:18:29,588 [foster.py] => SNet: Task 1, Epoch 78/130 => Loss 26.857,  Loss1 0.675, Train_accy 65.40
2024-08-02 13:18:32,481 [foster.py] => SNet: Task 1, Epoch 79/130 => Loss 26.878,  Loss1 0.675, Train_accy 64.75
2024-08-02 13:18:35,365 [foster.py] => SNet: Task 1, Epoch 80/130 => Loss 26.844,  Loss1 0.675, Train_accy 65.00
2024-08-02 13:18:39,125 [foster.py] => SNet: Task 1, Epoch 81/130 => Loss 26.888,  Loss1 0.675, Train_accy 64.80, Test_accy 79.73
2024-08-02 13:18:42,031 [foster.py] => SNet: Task 1, Epoch 82/130 => Loss 26.796,  Loss1 0.675, Train_accy 66.05
2024-08-02 13:18:44,924 [foster.py] => SNet: Task 1, Epoch 83/130 => Loss 26.851,  Loss1 0.675, Train_accy 64.65
2024-08-02 13:18:47,826 [foster.py] => SNet: Task 1, Epoch 84/130 => Loss 26.863,  Loss1 0.675, Train_accy 65.40
2024-08-02 13:18:50,734 [foster.py] => SNet: Task 1, Epoch 85/130 => Loss 26.849,  Loss1 0.675, Train_accy 65.05
2024-08-02 13:18:54,515 [foster.py] => SNet: Task 1, Epoch 86/130 => Loss 26.873,  Loss1 0.675, Train_accy 64.60, Test_accy 79.96
2024-08-02 13:18:57,406 [foster.py] => SNet: Task 1, Epoch 87/130 => Loss 26.853,  Loss1 0.675, Train_accy 66.75
2024-08-02 13:19:00,314 [foster.py] => SNet: Task 1, Epoch 88/130 => Loss 26.860,  Loss1 0.675, Train_accy 66.50
2024-08-02 13:19:03,204 [foster.py] => SNet: Task 1, Epoch 89/130 => Loss 26.860,  Loss1 0.675, Train_accy 66.40
2024-08-02 13:19:06,086 [foster.py] => SNet: Task 1, Epoch 90/130 => Loss 26.822,  Loss1 0.675, Train_accy 66.70
2024-08-02 13:19:09,890 [foster.py] => SNet: Task 1, Epoch 91/130 => Loss 26.833,  Loss1 0.675, Train_accy 66.45, Test_accy 79.94
2024-08-02 13:19:12,789 [foster.py] => SNet: Task 1, Epoch 92/130 => Loss 26.800,  Loss1 0.675, Train_accy 65.40
2024-08-02 13:19:15,711 [foster.py] => SNet: Task 1, Epoch 93/130 => Loss 26.830,  Loss1 0.675, Train_accy 65.60
2024-08-02 13:19:18,604 [foster.py] => SNet: Task 1, Epoch 94/130 => Loss 26.850,  Loss1 0.675, Train_accy 66.30
2024-08-02 13:19:21,509 [foster.py] => SNet: Task 1, Epoch 95/130 => Loss 26.855,  Loss1 0.675, Train_accy 65.35
2024-08-02 13:19:25,277 [foster.py] => SNet: Task 1, Epoch 96/130 => Loss 26.812,  Loss1 0.675, Train_accy 67.70, Test_accy 79.92
2024-08-02 13:19:28,170 [foster.py] => SNet: Task 1, Epoch 97/130 => Loss 26.888,  Loss1 0.675, Train_accy 66.05
2024-08-02 13:19:31,064 [foster.py] => SNet: Task 1, Epoch 98/130 => Loss 26.890,  Loss1 0.675, Train_accy 66.85
2024-08-02 13:19:33,968 [foster.py] => SNet: Task 1, Epoch 99/130 => Loss 26.834,  Loss1 0.675, Train_accy 65.85
2024-08-02 13:19:36,886 [foster.py] => SNet: Task 1, Epoch 100/130 => Loss 26.864,  Loss1 0.675, Train_accy 65.95
2024-08-02 13:19:40,667 [foster.py] => SNet: Task 1, Epoch 101/130 => Loss 26.860,  Loss1 0.675, Train_accy 66.65, Test_accy 79.65
2024-08-02 13:19:43,569 [foster.py] => SNet: Task 1, Epoch 102/130 => Loss 26.826,  Loss1 0.675, Train_accy 64.75
2024-08-02 13:19:46,457 [foster.py] => SNet: Task 1, Epoch 103/130 => Loss 26.846,  Loss1 0.675, Train_accy 65.90
2024-08-02 13:19:49,355 [foster.py] => SNet: Task 1, Epoch 104/130 => Loss 26.803,  Loss1 0.675, Train_accy 64.80
2024-08-02 13:19:52,276 [foster.py] => SNet: Task 1, Epoch 105/130 => Loss 26.814,  Loss1 0.675, Train_accy 65.05
2024-08-02 13:19:56,040 [foster.py] => SNet: Task 1, Epoch 106/130 => Loss 26.855,  Loss1 0.675, Train_accy 66.00, Test_accy 79.67
2024-08-02 13:19:58,925 [foster.py] => SNet: Task 1, Epoch 107/130 => Loss 26.804,  Loss1 0.674, Train_accy 66.70
2024-08-02 13:20:01,829 [foster.py] => SNet: Task 1, Epoch 108/130 => Loss 26.802,  Loss1 0.675, Train_accy 66.70
2024-08-02 13:20:04,737 [foster.py] => SNet: Task 1, Epoch 109/130 => Loss 26.871,  Loss1 0.675, Train_accy 67.15
2024-08-02 13:20:07,644 [foster.py] => SNet: Task 1, Epoch 110/130 => Loss 26.891,  Loss1 0.675, Train_accy 64.20
2024-08-02 13:20:11,410 [foster.py] => SNet: Task 1, Epoch 111/130 => Loss 26.859,  Loss1 0.675, Train_accy 66.55, Test_accy 79.88
2024-08-02 13:20:14,379 [foster.py] => SNet: Task 1, Epoch 112/130 => Loss 26.857,  Loss1 0.675, Train_accy 65.25
2024-08-02 13:20:17,298 [foster.py] => SNet: Task 1, Epoch 113/130 => Loss 26.846,  Loss1 0.675, Train_accy 65.65
2024-08-02 13:20:20,186 [foster.py] => SNet: Task 1, Epoch 114/130 => Loss 26.845,  Loss1 0.675, Train_accy 64.85
2024-08-02 13:20:23,088 [foster.py] => SNet: Task 1, Epoch 115/130 => Loss 26.852,  Loss1 0.675, Train_accy 65.40
2024-08-02 13:20:26,873 [foster.py] => SNet: Task 1, Epoch 116/130 => Loss 26.861,  Loss1 0.675, Train_accy 64.80, Test_accy 79.75
2024-08-02 13:20:29,748 [foster.py] => SNet: Task 1, Epoch 117/130 => Loss 26.858,  Loss1 0.675, Train_accy 64.75
2024-08-02 13:20:32,627 [foster.py] => SNet: Task 1, Epoch 118/130 => Loss 26.849,  Loss1 0.675, Train_accy 64.75
2024-08-02 13:20:35,501 [foster.py] => SNet: Task 1, Epoch 119/130 => Loss 26.835,  Loss1 0.675, Train_accy 65.80
2024-08-02 13:20:38,397 [foster.py] => SNet: Task 1, Epoch 120/130 => Loss 26.849,  Loss1 0.674, Train_accy 65.05
2024-08-02 13:20:42,182 [foster.py] => SNet: Task 1, Epoch 121/130 => Loss 26.814,  Loss1 0.675, Train_accy 64.45, Test_accy 79.96
2024-08-02 13:20:45,063 [foster.py] => SNet: Task 1, Epoch 122/130 => Loss 26.784,  Loss1 0.675, Train_accy 65.80
2024-08-02 13:20:47,965 [foster.py] => SNet: Task 1, Epoch 123/130 => Loss 26.810,  Loss1 0.675, Train_accy 63.70
2024-08-02 13:20:50,869 [foster.py] => SNet: Task 1, Epoch 124/130 => Loss 26.851,  Loss1 0.675, Train_accy 65.35
2024-08-02 13:20:53,759 [foster.py] => SNet: Task 1, Epoch 125/130 => Loss 26.819,  Loss1 0.675, Train_accy 65.50
2024-08-02 13:20:57,506 [foster.py] => SNet: Task 1, Epoch 126/130 => Loss 26.849,  Loss1 0.675, Train_accy 66.55, Test_accy 79.92
2024-08-02 13:21:00,428 [foster.py] => SNet: Task 1, Epoch 127/130 => Loss 26.846,  Loss1 0.675, Train_accy 66.05
2024-08-02 13:21:03,337 [foster.py] => SNet: Task 1, Epoch 128/130 => Loss 26.810,  Loss1 0.675, Train_accy 67.90
2024-08-02 13:21:06,247 [foster.py] => SNet: Task 1, Epoch 129/130 => Loss 26.877,  Loss1 0.675, Train_accy 65.70
2024-08-02 13:21:09,148 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 26.831,  Loss1 0.675, Train_accy 65.75
2024-08-02 13:21:09,149 [foster.py] => do not weight align student!
2024-08-02 13:21:10,046 [foster.py] => darknet eval: 
2024-08-02 13:21:10,046 [foster.py] => CNN top1 curve: 79.67
2024-08-02 13:21:10,047 [foster.py] => CNN top5 curve: 96.81
2024-08-02 13:21:10,047 [foster.py] => CNN top1 平均值: 79.67
2024-08-02 13:21:10,053 [foster.py] => timees : 942.4322564601898
2024-08-02 13:21:10,054 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 13:21:25,634 [foster.py] => Exemplar size: 1040
2024-08-02 13:21:25,635 [trainer.py] => CNN: {'total': 80.75, '00-09': 85.4, '10-19': 77.4, '20-29': 83.1, '30-39': 78.6, '40-49': 80.6, '50-59': 74.0, 'old': 81.02, 'new': 74.0}
2024-08-02 13:21:25,635 [trainer.py] => NME: {'total': 77.73, '00-09': 80.6, '10-19': 74.9, '20-29': 80.2, '30-39': 75.7, '40-49': 74.8, '50-59': 90.0, 'old': 77.24, 'new': 90.0}
2024-08-02 13:21:25,635 [trainer.py] => CNN top1 curve: [81.66, 80.75]
2024-08-02 13:21:25,636 [trainer.py] => CNN top5 curve: [97.02, 96.81]
2024-08-02 13:21:25,636 [trainer.py] => NME top1 curve: [80.72, 77.73]
2024-08-02 13:21:25,636 [trainer.py] => NME top5 curve: [96.8, 95.31]

2024-08-02 13:21:25,637 [trainer.py] => CNN top1 平均值: 81.20
2024-08-02 13:21:25,639 [trainer.py] => All params: 1167886
2024-08-02 13:21:25,642 [trainer.py] => Trainable params: 587362
2024-08-02 13:21:25,701 [foster.py] => Learning on 52-54
2024-08-02 13:21:25,705 [foster.py] => All params: 1168404
2024-08-02 13:21:25,707 [foster.py] => Trainable params: 587750
2024-08-02 13:21:25,744 [foster.py] => per cls weights : [1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951 1.01705951
 1.01705951 1.01705951 1.01705951 1.01705951 0.55645269 0.55645269]
2024-08-02 13:21:28,039 [foster.py] => Task 2, Epoch 1/170 => Loss 5.642, Loss_clf 1.504, Loss_fe 1.805, Loss_kd 2.246, Train_accy 65.25
2024-08-02 13:21:31,533 [foster.py] => Task 2, Epoch 2/170 => Loss 3.862, Loss_clf 0.743, Loss_fe 0.778, Loss_kd 2.252, Train_accy 63.43, Test_accy 78.31
2024-08-02 13:21:35,001 [foster.py] => Task 2, Epoch 3/170 => Loss 3.560, Loss_clf 0.565, Loss_fe 0.653, Loss_kd 2.255, Train_accy 66.47, Test_accy 77.72
2024-08-02 13:21:38,449 [foster.py] => Task 2, Epoch 4/170 => Loss 3.372, Loss_clf 0.490, Loss_fe 0.543, Loss_kd 2.250, Train_accy 63.77, Test_accy 78.15
2024-08-02 13:21:41,909 [foster.py] => Task 2, Epoch 5/170 => Loss 3.255, Loss_clf 0.474, Loss_fe 0.465, Loss_kd 2.229, Train_accy 62.65, Test_accy 77.81
2024-08-02 13:21:44,017 [foster.py] => Task 2, Epoch 6/170 => Loss 3.257, Loss_clf 0.484, Loss_fe 0.425, Loss_kd 2.260, Train_accy 64.26
2024-08-02 13:21:47,510 [foster.py] => Task 2, Epoch 7/170 => Loss 3.136, Loss_clf 0.442, Loss_fe 0.385, Loss_kd 2.222, Train_accy 64.02, Test_accy 78.24
2024-08-02 13:21:50,965 [foster.py] => Task 2, Epoch 8/170 => Loss 3.168, Loss_clf 0.460, Loss_fe 0.380, Loss_kd 2.240, Train_accy 65.20, Test_accy 78.70
2024-08-02 13:21:54,516 [foster.py] => Task 2, Epoch 9/170 => Loss 3.159, Loss_clf 0.466, Loss_fe 0.372, Loss_kd 2.234, Train_accy 64.26, Test_accy 78.15
2024-08-02 13:21:58,024 [foster.py] => Task 2, Epoch 10/170 => Loss 3.119, Loss_clf 0.436, Loss_fe 0.349, Loss_kd 2.246, Train_accy 63.68, Test_accy 77.52
2024-08-02 13:22:00,148 [foster.py] => Task 2, Epoch 11/170 => Loss 3.136, Loss_clf 0.457, Loss_fe 0.337, Loss_kd 2.254, Train_accy 65.49
2024-08-02 13:22:03,629 [foster.py] => Task 2, Epoch 12/170 => Loss 3.054, Loss_clf 0.411, Loss_fe 0.322, Loss_kd 2.234, Train_accy 68.28, Test_accy 78.67
2024-08-02 13:22:07,080 [foster.py] => Task 2, Epoch 13/170 => Loss 3.039, Loss_clf 0.397, Loss_fe 0.312, Loss_kd 2.242, Train_accy 68.53, Test_accy 78.72
2024-08-02 13:22:10,637 [foster.py] => Task 2, Epoch 14/170 => Loss 3.067, Loss_clf 0.413, Loss_fe 0.326, Loss_kd 2.240, Train_accy 66.08, Test_accy 79.02
2024-08-02 13:22:14,221 [foster.py] => Task 2, Epoch 15/170 => Loss 3.023, Loss_clf 0.428, Loss_fe 0.283, Loss_kd 2.225, Train_accy 68.58, Test_accy 78.80
2024-08-02 13:22:16,362 [foster.py] => Task 2, Epoch 16/170 => Loss 3.051, Loss_clf 0.423, Loss_fe 0.313, Loss_kd 2.228, Train_accy 67.25
2024-08-02 13:22:19,828 [foster.py] => Task 2, Epoch 17/170 => Loss 3.102, Loss_clf 0.440, Loss_fe 0.320, Loss_kd 2.253, Train_accy 68.24, Test_accy 78.07
2024-08-02 13:22:23,307 [foster.py] => Task 2, Epoch 18/170 => Loss 3.058, Loss_clf 0.438, Loss_fe 0.270, Loss_kd 2.261, Train_accy 68.24, Test_accy 79.00
2024-08-02 13:22:26,775 [foster.py] => Task 2, Epoch 19/170 => Loss 2.974, Loss_clf 0.402, Loss_fe 0.279, Loss_kd 2.207, Train_accy 69.07, Test_accy 79.15
2024-08-02 13:22:30,241 [foster.py] => Task 2, Epoch 20/170 => Loss 2.989, Loss_clf 0.392, Loss_fe 0.282, Loss_kd 2.228, Train_accy 68.48, Test_accy 78.19
2024-08-02 13:22:32,413 [foster.py] => Task 2, Epoch 21/170 => Loss 3.021, Loss_clf 0.405, Loss_fe 0.279, Loss_kd 2.248, Train_accy 70.10
2024-08-02 13:22:35,901 [foster.py] => Task 2, Epoch 22/170 => Loss 2.958, Loss_clf 0.390, Loss_fe 0.252, Loss_kd 2.229, Train_accy 68.97, Test_accy 78.94
2024-08-02 13:22:39,385 [foster.py] => Task 2, Epoch 23/170 => Loss 2.980, Loss_clf 0.395, Loss_fe 0.286, Loss_kd 2.213, Train_accy 68.82, Test_accy 78.85
2024-08-02 13:22:42,856 [foster.py] => Task 2, Epoch 24/170 => Loss 3.000, Loss_clf 0.401, Loss_fe 0.271, Loss_kd 2.240, Train_accy 69.56, Test_accy 79.07
2024-08-02 13:22:46,404 [foster.py] => Task 2, Epoch 25/170 => Loss 2.977, Loss_clf 0.398, Loss_fe 0.252, Loss_kd 2.239, Train_accy 68.24, Test_accy 78.72
2024-08-02 13:22:48,527 [foster.py] => Task 2, Epoch 26/170 => Loss 2.947, Loss_clf 0.389, Loss_fe 0.242, Loss_kd 2.228, Train_accy 69.75
2024-08-02 13:22:51,973 [foster.py] => Task 2, Epoch 27/170 => Loss 2.945, Loss_clf 0.361, Loss_fe 0.258, Loss_kd 2.238, Train_accy 73.14, Test_accy 78.81
2024-08-02 13:22:55,451 [foster.py] => Task 2, Epoch 28/170 => Loss 3.044, Loss_clf 0.417, Loss_fe 0.278, Loss_kd 2.261, Train_accy 70.00, Test_accy 78.70
2024-08-02 13:22:58,935 [foster.py] => Task 2, Epoch 29/170 => Loss 2.959, Loss_clf 0.407, Loss_fe 0.242, Loss_kd 2.224, Train_accy 71.67, Test_accy 78.83
2024-08-02 13:23:02,396 [foster.py] => Task 2, Epoch 30/170 => Loss 2.992, Loss_clf 0.400, Loss_fe 0.251, Loss_kd 2.252, Train_accy 70.83, Test_accy 78.85
2024-08-02 13:23:04,523 [foster.py] => Task 2, Epoch 31/170 => Loss 2.971, Loss_clf 0.387, Loss_fe 0.246, Loss_kd 2.250, Train_accy 72.94
2024-08-02 13:23:07,979 [foster.py] => Task 2, Epoch 32/170 => Loss 2.911, Loss_clf 0.369, Loss_fe 0.240, Loss_kd 2.216, Train_accy 72.25, Test_accy 78.78
2024-08-02 13:23:11,457 [foster.py] => Task 2, Epoch 33/170 => Loss 2.906, Loss_clf 0.373, Loss_fe 0.229, Loss_kd 2.218, Train_accy 70.59, Test_accy 78.89
2024-08-02 13:23:14,918 [foster.py] => Task 2, Epoch 34/170 => Loss 2.963, Loss_clf 0.389, Loss_fe 0.248, Loss_kd 2.239, Train_accy 72.06, Test_accy 78.94
2024-08-02 13:23:18,400 [foster.py] => Task 2, Epoch 35/170 => Loss 2.892, Loss_clf 0.362, Loss_fe 0.235, Loss_kd 2.209, Train_accy 72.50, Test_accy 79.15
2024-08-02 13:23:20,499 [foster.py] => Task 2, Epoch 36/170 => Loss 2.872, Loss_clf 0.360, Loss_fe 0.201, Loss_kd 2.224, Train_accy 70.49
2024-08-02 13:23:23,952 [foster.py] => Task 2, Epoch 37/170 => Loss 2.955, Loss_clf 0.392, Loss_fe 0.233, Loss_kd 2.243, Train_accy 72.55, Test_accy 79.00
2024-08-02 13:23:27,442 [foster.py] => Task 2, Epoch 38/170 => Loss 2.938, Loss_clf 0.386, Loss_fe 0.222, Loss_kd 2.243, Train_accy 71.52, Test_accy 79.06
2024-08-02 13:23:30,949 [foster.py] => Task 2, Epoch 39/170 => Loss 2.883, Loss_clf 0.357, Loss_fe 0.209, Loss_kd 2.230, Train_accy 72.50, Test_accy 79.37
2024-08-02 13:23:34,416 [foster.py] => Task 2, Epoch 40/170 => Loss 2.971, Loss_clf 0.392, Loss_fe 0.231, Loss_kd 2.260, Train_accy 72.30, Test_accy 79.37
2024-08-02 13:23:36,522 [foster.py] => Task 2, Epoch 41/170 => Loss 2.890, Loss_clf 0.370, Loss_fe 0.198, Loss_kd 2.235, Train_accy 73.14
2024-08-02 13:23:39,982 [foster.py] => Task 2, Epoch 42/170 => Loss 2.957, Loss_clf 0.391, Loss_fe 0.229, Loss_kd 2.249, Train_accy 72.06, Test_accy 78.76
2024-08-02 13:23:43,462 [foster.py] => Task 2, Epoch 43/170 => Loss 2.896, Loss_clf 0.373, Loss_fe 0.199, Loss_kd 2.236, Train_accy 72.89, Test_accy 79.46
2024-08-02 13:23:46,899 [foster.py] => Task 2, Epoch 44/170 => Loss 2.932, Loss_clf 0.392, Loss_fe 0.208, Loss_kd 2.244, Train_accy 71.47, Test_accy 78.61
2024-08-02 13:23:50,462 [foster.py] => Task 2, Epoch 45/170 => Loss 2.885, Loss_clf 0.346, Loss_fe 0.211, Loss_kd 2.240, Train_accy 73.14, Test_accy 79.19
2024-08-02 13:23:52,609 [foster.py] => Task 2, Epoch 46/170 => Loss 2.920, Loss_clf 0.389, Loss_fe 0.218, Loss_kd 2.227, Train_accy 71.91
2024-08-02 13:23:56,087 [foster.py] => Task 2, Epoch 47/170 => Loss 2.867, Loss_clf 0.343, Loss_fe 0.202, Loss_kd 2.234, Train_accy 75.05, Test_accy 79.17
2024-08-02 13:23:59,547 [foster.py] => Task 2, Epoch 48/170 => Loss 2.915, Loss_clf 0.370, Loss_fe 0.210, Loss_kd 2.248, Train_accy 72.50, Test_accy 78.72
2024-08-02 13:24:03,102 [foster.py] => Task 2, Epoch 49/170 => Loss 2.902, Loss_clf 0.363, Loss_fe 0.213, Loss_kd 2.239, Train_accy 74.46, Test_accy 79.13
2024-08-02 13:24:06,587 [foster.py] => Task 2, Epoch 50/170 => Loss 2.852, Loss_clf 0.364, Loss_fe 0.195, Loss_kd 2.207, Train_accy 73.24, Test_accy 79.11
2024-08-02 13:24:08,701 [foster.py] => Task 2, Epoch 51/170 => Loss 2.868, Loss_clf 0.359, Loss_fe 0.190, Loss_kd 2.232, Train_accy 75.25
2024-08-02 13:24:12,258 [foster.py] => Task 2, Epoch 52/170 => Loss 2.855, Loss_clf 0.349, Loss_fe 0.180, Loss_kd 2.239, Train_accy 73.87, Test_accy 79.41
2024-08-02 13:24:15,746 [foster.py] => Task 2, Epoch 53/170 => Loss 2.829, Loss_clf 0.333, Loss_fe 0.181, Loss_kd 2.229, Train_accy 78.43, Test_accy 79.15
2024-08-02 13:24:19,235 [foster.py] => Task 2, Epoch 54/170 => Loss 2.855, Loss_clf 0.357, Loss_fe 0.180, Loss_kd 2.231, Train_accy 73.48, Test_accy 79.07
2024-08-02 13:24:22,728 [foster.py] => Task 2, Epoch 55/170 => Loss 2.859, Loss_clf 0.351, Loss_fe 0.195, Loss_kd 2.225, Train_accy 75.88, Test_accy 79.20
2024-08-02 13:24:24,851 [foster.py] => Task 2, Epoch 56/170 => Loss 2.871, Loss_clf 0.358, Loss_fe 0.186, Loss_kd 2.239, Train_accy 75.15
2024-08-02 13:24:28,325 [foster.py] => Task 2, Epoch 57/170 => Loss 2.877, Loss_clf 0.362, Loss_fe 0.204, Loss_kd 2.224, Train_accy 75.83, Test_accy 79.02
2024-08-02 13:24:31,784 [foster.py] => Task 2, Epoch 58/170 => Loss 2.874, Loss_clf 0.361, Loss_fe 0.199, Loss_kd 2.227, Train_accy 75.69, Test_accy 79.17
2024-08-02 13:24:35,271 [foster.py] => Task 2, Epoch 59/170 => Loss 2.834, Loss_clf 0.341, Loss_fe 0.178, Loss_kd 2.228, Train_accy 76.03, Test_accy 79.00
2024-08-02 13:24:38,782 [foster.py] => Task 2, Epoch 60/170 => Loss 2.836, Loss_clf 0.340, Loss_fe 0.170, Loss_kd 2.238, Train_accy 76.32, Test_accy 79.13
2024-08-02 13:24:40,926 [foster.py] => Task 2, Epoch 61/170 => Loss 2.839, Loss_clf 0.353, Loss_fe 0.171, Loss_kd 2.229, Train_accy 75.59
2024-08-02 13:24:44,415 [foster.py] => Task 2, Epoch 62/170 => Loss 2.877, Loss_clf 0.357, Loss_fe 0.179, Loss_kd 2.253, Train_accy 74.36, Test_accy 78.85
2024-08-02 13:24:47,868 [foster.py] => Task 2, Epoch 63/170 => Loss 2.873, Loss_clf 0.362, Loss_fe 0.193, Loss_kd 2.232, Train_accy 77.25, Test_accy 79.41
2024-08-02 13:24:51,361 [foster.py] => Task 2, Epoch 64/170 => Loss 2.824, Loss_clf 0.341, Loss_fe 0.163, Loss_kd 2.233, Train_accy 75.25, Test_accy 79.09
2024-08-02 13:24:54,841 [foster.py] => Task 2, Epoch 65/170 => Loss 2.821, Loss_clf 0.340, Loss_fe 0.170, Loss_kd 2.224, Train_accy 78.87, Test_accy 78.89
2024-08-02 13:24:56,985 [foster.py] => Task 2, Epoch 66/170 => Loss 2.803, Loss_clf 0.339, Loss_fe 0.160, Loss_kd 2.217, Train_accy 77.30
2024-08-02 13:25:00,438 [foster.py] => Task 2, Epoch 67/170 => Loss 2.840, Loss_clf 0.340, Loss_fe 0.167, Loss_kd 2.245, Train_accy 75.54, Test_accy 79.28
2024-08-02 13:25:03,892 [foster.py] => Task 2, Epoch 68/170 => Loss 2.858, Loss_clf 0.360, Loss_fe 0.166, Loss_kd 2.245, Train_accy 76.76, Test_accy 79.17
2024-08-02 13:25:07,419 [foster.py] => Task 2, Epoch 69/170 => Loss 2.849, Loss_clf 0.339, Loss_fe 0.178, Loss_kd 2.245, Train_accy 77.40, Test_accy 79.15
2024-08-02 13:25:10,922 [foster.py] => Task 2, Epoch 70/170 => Loss 2.758, Loss_clf 0.303, Loss_fe 0.163, Loss_kd 2.205, Train_accy 77.75, Test_accy 78.93
2024-08-02 13:25:13,029 [foster.py] => Task 2, Epoch 71/170 => Loss 2.799, Loss_clf 0.328, Loss_fe 0.154, Loss_kd 2.230, Train_accy 77.35
2024-08-02 13:25:16,556 [foster.py] => Task 2, Epoch 72/170 => Loss 2.788, Loss_clf 0.329, Loss_fe 0.147, Loss_kd 2.225, Train_accy 78.48, Test_accy 78.81
2024-08-02 13:25:20,032 [foster.py] => Task 2, Epoch 73/170 => Loss 2.743, Loss_clf 0.295, Loss_fe 0.152, Loss_kd 2.209, Train_accy 80.59, Test_accy 79.39
2024-08-02 13:25:23,482 [foster.py] => Task 2, Epoch 74/170 => Loss 2.812, Loss_clf 0.340, Loss_fe 0.152, Loss_kd 2.232, Train_accy 78.87, Test_accy 79.13
2024-08-02 13:25:26,980 [foster.py] => Task 2, Epoch 75/170 => Loss 2.837, Loss_clf 0.354, Loss_fe 0.157, Loss_kd 2.238, Train_accy 75.88, Test_accy 78.89
2024-08-02 13:25:29,122 [foster.py] => Task 2, Epoch 76/170 => Loss 2.723, Loss_clf 0.286, Loss_fe 0.128, Loss_kd 2.222, Train_accy 79.46
2024-08-02 13:25:32,606 [foster.py] => Task 2, Epoch 77/170 => Loss 2.839, Loss_clf 0.333, Loss_fe 0.158, Loss_kd 2.259, Train_accy 78.53, Test_accy 79.24
2024-08-02 13:25:36,109 [foster.py] => Task 2, Epoch 78/170 => Loss 2.852, Loss_clf 0.347, Loss_fe 0.167, Loss_kd 2.250, Train_accy 75.83, Test_accy 79.24
2024-08-02 13:25:39,574 [foster.py] => Task 2, Epoch 79/170 => Loss 2.886, Loss_clf 0.379, Loss_fe 0.163, Loss_kd 2.257, Train_accy 75.15, Test_accy 79.13
2024-08-02 13:25:43,071 [foster.py] => Task 2, Epoch 80/170 => Loss 2.831, Loss_clf 0.337, Loss_fe 0.159, Loss_kd 2.247, Train_accy 76.08, Test_accy 79.07
2024-08-02 13:25:45,201 [foster.py] => Task 2, Epoch 81/170 => Loss 2.865, Loss_clf 0.350, Loss_fe 0.180, Loss_kd 2.246, Train_accy 76.42
2024-08-02 13:25:48,678 [foster.py] => Task 2, Epoch 82/170 => Loss 2.848, Loss_clf 0.355, Loss_fe 0.164, Loss_kd 2.242, Train_accy 76.57, Test_accy 78.89
2024-08-02 13:25:52,184 [foster.py] => Task 2, Epoch 83/170 => Loss 2.839, Loss_clf 0.345, Loss_fe 0.157, Loss_kd 2.249, Train_accy 76.91, Test_accy 79.00
2024-08-02 13:25:55,637 [foster.py] => Task 2, Epoch 84/170 => Loss 2.780, Loss_clf 0.319, Loss_fe 0.151, Loss_kd 2.224, Train_accy 77.94, Test_accy 79.11
2024-08-02 13:25:59,129 [foster.py] => Task 2, Epoch 85/170 => Loss 2.855, Loss_clf 0.360, Loss_fe 0.171, Loss_kd 2.236, Train_accy 78.24, Test_accy 79.46
2024-08-02 13:26:01,249 [foster.py] => Task 2, Epoch 86/170 => Loss 2.821, Loss_clf 0.334, Loss_fe 0.149, Loss_kd 2.249, Train_accy 78.92
2024-08-02 13:26:04,736 [foster.py] => Task 2, Epoch 87/170 => Loss 2.752, Loss_clf 0.316, Loss_fe 0.131, Loss_kd 2.219, Train_accy 78.73, Test_accy 79.24
2024-08-02 13:26:08,187 [foster.py] => Task 2, Epoch 88/170 => Loss 2.719, Loss_clf 0.294, Loss_fe 0.119, Loss_kd 2.219, Train_accy 77.75, Test_accy 79.26
2024-08-02 13:26:11,682 [foster.py] => Task 2, Epoch 89/170 => Loss 2.753, Loss_clf 0.312, Loss_fe 0.153, Loss_kd 2.201, Train_accy 80.15, Test_accy 79.00
2024-08-02 13:26:15,217 [foster.py] => Task 2, Epoch 90/170 => Loss 2.737, Loss_clf 0.301, Loss_fe 0.119, Loss_kd 2.229, Train_accy 79.41, Test_accy 79.26
2024-08-02 13:26:17,332 [foster.py] => Task 2, Epoch 91/170 => Loss 2.777, Loss_clf 0.332, Loss_fe 0.133, Loss_kd 2.224, Train_accy 77.89
2024-08-02 13:26:20,825 [foster.py] => Task 2, Epoch 92/170 => Loss 2.780, Loss_clf 0.337, Loss_fe 0.135, Loss_kd 2.221, Train_accy 78.48, Test_accy 79.22
2024-08-02 13:26:24,314 [foster.py] => Task 2, Epoch 93/170 => Loss 2.734, Loss_clf 0.296, Loss_fe 0.115, Loss_kd 2.236, Train_accy 78.63, Test_accy 79.11
2024-08-02 13:26:27,787 [foster.py] => Task 2, Epoch 94/170 => Loss 2.691, Loss_clf 0.296, Loss_fe 0.102, Loss_kd 2.206, Train_accy 80.98, Test_accy 79.17
2024-08-02 13:26:31,288 [foster.py] => Task 2, Epoch 95/170 => Loss 2.832, Loss_clf 0.351, Loss_fe 0.144, Loss_kd 2.249, Train_accy 78.33, Test_accy 78.98
2024-08-02 13:26:33,469 [foster.py] => Task 2, Epoch 96/170 => Loss 2.758, Loss_clf 0.309, Loss_fe 0.115, Loss_kd 2.246, Train_accy 79.36
2024-08-02 13:26:36,940 [foster.py] => Task 2, Epoch 97/170 => Loss 2.754, Loss_clf 0.303, Loss_fe 0.117, Loss_kd 2.245, Train_accy 81.86, Test_accy 78.85
2024-08-02 13:26:40,410 [foster.py] => Task 2, Epoch 98/170 => Loss 2.761, Loss_clf 0.329, Loss_fe 0.125, Loss_kd 2.221, Train_accy 79.07, Test_accy 78.93
2024-08-02 13:26:43,918 [foster.py] => Task 2, Epoch 99/170 => Loss 2.744, Loss_clf 0.316, Loss_fe 0.123, Loss_kd 2.218, Train_accy 79.56, Test_accy 79.26
2024-08-02 13:26:47,391 [foster.py] => Task 2, Epoch 100/170 => Loss 2.814, Loss_clf 0.346, Loss_fe 0.147, Loss_kd 2.234, Train_accy 78.28, Test_accy 79.30
2024-08-02 13:26:49,549 [foster.py] => Task 2, Epoch 101/170 => Loss 2.691, Loss_clf 0.278, Loss_fe 0.106, Loss_kd 2.221, Train_accy 81.23
2024-08-02 13:26:53,007 [foster.py] => Task 2, Epoch 102/170 => Loss 2.720, Loss_clf 0.298, Loss_fe 0.126, Loss_kd 2.209, Train_accy 81.27, Test_accy 79.41
2024-08-02 13:26:56,532 [foster.py] => Task 2, Epoch 103/170 => Loss 2.704, Loss_clf 0.289, Loss_fe 0.109, Loss_kd 2.220, Train_accy 81.91, Test_accy 79.65
2024-08-02 13:27:00,026 [foster.py] => Task 2, Epoch 104/170 => Loss 2.726, Loss_clf 0.296, Loss_fe 0.105, Loss_kd 2.237, Train_accy 81.42, Test_accy 79.54
2024-08-02 13:27:03,505 [foster.py] => Task 2, Epoch 105/170 => Loss 2.726, Loss_clf 0.293, Loss_fe 0.112, Loss_kd 2.233, Train_accy 80.83, Test_accy 79.31
2024-08-02 13:27:05,611 [foster.py] => Task 2, Epoch 106/170 => Loss 2.780, Loss_clf 0.319, Loss_fe 0.128, Loss_kd 2.244, Train_accy 81.52
2024-08-02 13:27:09,088 [foster.py] => Task 2, Epoch 107/170 => Loss 2.762, Loss_clf 0.306, Loss_fe 0.130, Loss_kd 2.238, Train_accy 80.64, Test_accy 79.48
2024-08-02 13:27:12,562 [foster.py] => Task 2, Epoch 108/170 => Loss 2.745, Loss_clf 0.314, Loss_fe 0.108, Loss_kd 2.236, Train_accy 80.74, Test_accy 79.37
2024-08-02 13:27:16,011 [foster.py] => Task 2, Epoch 109/170 => Loss 2.765, Loss_clf 0.308, Loss_fe 0.131, Loss_kd 2.239, Train_accy 82.11, Test_accy 79.19
2024-08-02 13:27:19,493 [foster.py] => Task 2, Epoch 110/170 => Loss 2.705, Loss_clf 0.288, Loss_fe 0.112, Loss_kd 2.218, Train_accy 82.40, Test_accy 79.54
2024-08-02 13:27:21,598 [foster.py] => Task 2, Epoch 111/170 => Loss 2.752, Loss_clf 0.313, Loss_fe 0.106, Loss_kd 2.245, Train_accy 79.80
2024-08-02 13:27:25,082 [foster.py] => Task 2, Epoch 112/170 => Loss 2.763, Loss_clf 0.311, Loss_fe 0.124, Loss_kd 2.241, Train_accy 81.42, Test_accy 79.33
2024-08-02 13:27:28,580 [foster.py] => Task 2, Epoch 113/170 => Loss 2.663, Loss_clf 0.260, Loss_fe 0.097, Loss_kd 2.219, Train_accy 82.55, Test_accy 79.39
2024-08-02 13:27:32,065 [foster.py] => Task 2, Epoch 114/170 => Loss 2.685, Loss_clf 0.273, Loss_fe 0.108, Loss_kd 2.217, Train_accy 80.69, Test_accy 79.43
2024-08-02 13:27:35,553 [foster.py] => Task 2, Epoch 115/170 => Loss 2.734, Loss_clf 0.310, Loss_fe 0.102, Loss_kd 2.235, Train_accy 81.76, Test_accy 79.19
2024-08-02 13:27:37,678 [foster.py] => Task 2, Epoch 116/170 => Loss 2.659, Loss_clf 0.275, Loss_fe 0.092, Loss_kd 2.206, Train_accy 82.35
2024-08-02 13:27:41,175 [foster.py] => Task 2, Epoch 117/170 => Loss 2.709, Loss_clf 0.285, Loss_fe 0.102, Loss_kd 2.235, Train_accy 81.91, Test_accy 79.52
2024-08-02 13:27:44,692 [foster.py] => Task 2, Epoch 118/170 => Loss 2.722, Loss_clf 0.298, Loss_fe 0.109, Loss_kd 2.229, Train_accy 82.01, Test_accy 79.48
2024-08-02 13:27:48,182 [foster.py] => Task 2, Epoch 119/170 => Loss 2.710, Loss_clf 0.293, Loss_fe 0.119, Loss_kd 2.212, Train_accy 81.37, Test_accy 79.31
2024-08-02 13:27:51,690 [foster.py] => Task 2, Epoch 120/170 => Loss 2.709, Loss_clf 0.282, Loss_fe 0.093, Loss_kd 2.246, Train_accy 82.50, Test_accy 79.43
2024-08-02 13:27:53,847 [foster.py] => Task 2, Epoch 121/170 => Loss 2.798, Loss_clf 0.333, Loss_fe 0.112, Loss_kd 2.264, Train_accy 81.81
2024-08-02 13:27:57,327 [foster.py] => Task 2, Epoch 122/170 => Loss 2.764, Loss_clf 0.321, Loss_fe 0.114, Loss_kd 2.241, Train_accy 80.20, Test_accy 79.31
2024-08-02 13:28:00,813 [foster.py] => Task 2, Epoch 123/170 => Loss 2.713, Loss_clf 0.290, Loss_fe 0.100, Loss_kd 2.235, Train_accy 80.44, Test_accy 79.50
2024-08-02 13:28:04,336 [foster.py] => Task 2, Epoch 124/170 => Loss 2.705, Loss_clf 0.299, Loss_fe 0.103, Loss_kd 2.216, Train_accy 82.06, Test_accy 79.39
2024-08-02 13:28:07,823 [foster.py] => Task 2, Epoch 125/170 => Loss 2.779, Loss_clf 0.318, Loss_fe 0.115, Loss_kd 2.257, Train_accy 81.08, Test_accy 79.50
2024-08-02 13:28:09,930 [foster.py] => Task 2, Epoch 126/170 => Loss 2.686, Loss_clf 0.276, Loss_fe 0.096, Loss_kd 2.227, Train_accy 82.11
2024-08-02 13:28:13,431 [foster.py] => Task 2, Epoch 127/170 => Loss 2.720, Loss_clf 0.294, Loss_fe 0.092, Loss_kd 2.247, Train_accy 81.62, Test_accy 79.44
2024-08-02 13:28:16,877 [foster.py] => Task 2, Epoch 128/170 => Loss 2.696, Loss_clf 0.281, Loss_fe 0.088, Loss_kd 2.239, Train_accy 82.21, Test_accy 79.41
2024-08-02 13:28:20,360 [foster.py] => Task 2, Epoch 129/170 => Loss 2.729, Loss_clf 0.309, Loss_fe 0.105, Loss_kd 2.228, Train_accy 81.57, Test_accy 79.43
2024-08-02 13:28:23,843 [foster.py] => Task 2, Epoch 130/170 => Loss 2.722, Loss_clf 0.299, Loss_fe 0.101, Loss_kd 2.235, Train_accy 80.64, Test_accy 79.50
2024-08-02 13:28:25,965 [foster.py] => Task 2, Epoch 131/170 => Loss 2.665, Loss_clf 0.274, Loss_fe 0.091, Loss_kd 2.214, Train_accy 82.16
2024-08-02 13:28:29,500 [foster.py] => Task 2, Epoch 132/170 => Loss 2.708, Loss_clf 0.287, Loss_fe 0.095, Loss_kd 2.238, Train_accy 82.94, Test_accy 79.46
2024-08-02 13:28:33,025 [foster.py] => Task 2, Epoch 133/170 => Loss 2.714, Loss_clf 0.299, Loss_fe 0.088, Loss_kd 2.239, Train_accy 81.32, Test_accy 79.46
2024-08-02 13:28:36,514 [foster.py] => Task 2, Epoch 134/170 => Loss 2.729, Loss_clf 0.305, Loss_fe 0.101, Loss_kd 2.236, Train_accy 80.83, Test_accy 79.56
2024-08-02 13:28:39,997 [foster.py] => Task 2, Epoch 135/170 => Loss 2.714, Loss_clf 0.289, Loss_fe 0.100, Loss_kd 2.238, Train_accy 80.98, Test_accy 79.44
2024-08-02 13:28:42,196 [foster.py] => Task 2, Epoch 136/170 => Loss 2.666, Loss_clf 0.285, Loss_fe 0.087, Loss_kd 2.208, Train_accy 82.50
2024-08-02 13:28:45,747 [foster.py] => Task 2, Epoch 137/170 => Loss 2.726, Loss_clf 0.304, Loss_fe 0.097, Loss_kd 2.237, Train_accy 82.79, Test_accy 79.33
2024-08-02 13:28:49,201 [foster.py] => Task 2, Epoch 138/170 => Loss 2.674, Loss_clf 0.270, Loss_fe 0.089, Loss_kd 2.229, Train_accy 83.14, Test_accy 79.37
2024-08-02 13:28:52,677 [foster.py] => Task 2, Epoch 139/170 => Loss 2.699, Loss_clf 0.288, Loss_fe 0.083, Loss_kd 2.240, Train_accy 82.30, Test_accy 79.43
2024-08-02 13:28:56,189 [foster.py] => Task 2, Epoch 140/170 => Loss 2.695, Loss_clf 0.292, Loss_fe 0.097, Loss_kd 2.220, Train_accy 82.30, Test_accy 79.37
2024-08-02 13:28:58,314 [foster.py] => Task 2, Epoch 141/170 => Loss 2.749, Loss_clf 0.315, Loss_fe 0.104, Loss_kd 2.242, Train_accy 81.86
2024-08-02 13:29:01,848 [foster.py] => Task 2, Epoch 142/170 => Loss 2.705, Loss_clf 0.296, Loss_fe 0.089, Loss_kd 2.233, Train_accy 81.91, Test_accy 79.35
2024-08-02 13:29:05,401 [foster.py] => Task 2, Epoch 143/170 => Loss 2.684, Loss_clf 0.270, Loss_fe 0.086, Loss_kd 2.241, Train_accy 83.43, Test_accy 79.31
2024-08-02 13:29:09,038 [foster.py] => Task 2, Epoch 144/170 => Loss 2.724, Loss_clf 0.296, Loss_fe 0.097, Loss_kd 2.243, Train_accy 82.84, Test_accy 79.37
2024-08-02 13:29:12,594 [foster.py] => Task 2, Epoch 145/170 => Loss 2.693, Loss_clf 0.277, Loss_fe 0.095, Loss_kd 2.234, Train_accy 82.50, Test_accy 79.39
2024-08-02 13:29:14,724 [foster.py] => Task 2, Epoch 146/170 => Loss 2.736, Loss_clf 0.302, Loss_fe 0.102, Loss_kd 2.244, Train_accy 83.33
2024-08-02 13:29:18,231 [foster.py] => Task 2, Epoch 147/170 => Loss 2.667, Loss_clf 0.270, Loss_fe 0.084, Loss_kd 2.226, Train_accy 84.02, Test_accy 79.35
2024-08-02 13:29:21,702 [foster.py] => Task 2, Epoch 148/170 => Loss 2.752, Loss_clf 0.310, Loss_fe 0.102, Loss_kd 2.252, Train_accy 81.96, Test_accy 79.33
2024-08-02 13:29:25,158 [foster.py] => Task 2, Epoch 149/170 => Loss 2.712, Loss_clf 0.293, Loss_fe 0.098, Loss_kd 2.234, Train_accy 83.28, Test_accy 79.35
2024-08-02 13:29:28,658 [foster.py] => Task 2, Epoch 150/170 => Loss 2.702, Loss_clf 0.295, Loss_fe 0.086, Loss_kd 2.234, Train_accy 82.55, Test_accy 79.30
2024-08-02 13:29:30,802 [foster.py] => Task 2, Epoch 151/170 => Loss 2.699, Loss_clf 0.285, Loss_fe 0.085, Loss_kd 2.241, Train_accy 83.53
2024-08-02 13:29:34,260 [foster.py] => Task 2, Epoch 152/170 => Loss 2.757, Loss_clf 0.311, Loss_fe 0.110, Loss_kd 2.249, Train_accy 82.21, Test_accy 79.41
2024-08-02 13:29:37,746 [foster.py] => Task 2, Epoch 153/170 => Loss 2.723, Loss_clf 0.309, Loss_fe 0.082, Loss_kd 2.245, Train_accy 81.37, Test_accy 79.43
2024-08-02 13:29:41,235 [foster.py] => Task 2, Epoch 154/170 => Loss 2.768, Loss_clf 0.316, Loss_fe 0.093, Loss_kd 2.270, Train_accy 81.47, Test_accy 79.41
2024-08-02 13:29:44,713 [foster.py] => Task 2, Epoch 155/170 => Loss 2.719, Loss_clf 0.301, Loss_fe 0.089, Loss_kd 2.242, Train_accy 82.60, Test_accy 79.37
2024-08-02 13:29:46,817 [foster.py] => Task 2, Epoch 156/170 => Loss 2.733, Loss_clf 0.291, Loss_fe 0.099, Loss_kd 2.254, Train_accy 83.87
2024-08-02 13:29:50,298 [foster.py] => Task 2, Epoch 157/170 => Loss 2.730, Loss_clf 0.307, Loss_fe 0.084, Loss_kd 2.251, Train_accy 81.86, Test_accy 79.41
2024-08-02 13:29:53,753 [foster.py] => Task 2, Epoch 158/170 => Loss 2.707, Loss_clf 0.295, Loss_fe 0.084, Loss_kd 2.241, Train_accy 83.28, Test_accy 79.39
2024-08-02 13:29:57,250 [foster.py] => Task 2, Epoch 159/170 => Loss 2.722, Loss_clf 0.297, Loss_fe 0.105, Loss_kd 2.233, Train_accy 82.35, Test_accy 79.39
2024-08-02 13:30:00,724 [foster.py] => Task 2, Epoch 160/170 => Loss 2.732, Loss_clf 0.311, Loss_fe 0.084, Loss_kd 2.249, Train_accy 80.15, Test_accy 79.30
2024-08-02 13:30:02,875 [foster.py] => Task 2, Epoch 161/170 => Loss 2.694, Loss_clf 0.292, Loss_fe 0.083, Loss_kd 2.232, Train_accy 81.27
2024-08-02 13:30:06,370 [foster.py] => Task 2, Epoch 162/170 => Loss 2.704, Loss_clf 0.297, Loss_fe 0.087, Loss_kd 2.233, Train_accy 82.16, Test_accy 79.35
2024-08-02 13:30:09,864 [foster.py] => Task 2, Epoch 163/170 => Loss 2.744, Loss_clf 0.301, Loss_fe 0.093, Loss_kd 2.261, Train_accy 81.96, Test_accy 79.35
2024-08-02 13:30:13,333 [foster.py] => Task 2, Epoch 164/170 => Loss 2.651, Loss_clf 0.270, Loss_fe 0.082, Loss_kd 2.213, Train_accy 82.65, Test_accy 79.33
2024-08-02 13:30:16,843 [foster.py] => Task 2, Epoch 165/170 => Loss 2.651, Loss_clf 0.266, Loss_fe 0.083, Loss_kd 2.216, Train_accy 83.33, Test_accy 79.33
2024-08-02 13:30:18,939 [foster.py] => Task 2, Epoch 166/170 => Loss 2.656, Loss_clf 0.279, Loss_fe 0.084, Loss_kd 2.206, Train_accy 81.91
2024-08-02 13:30:22,422 [foster.py] => Task 2, Epoch 167/170 => Loss 2.695, Loss_clf 0.286, Loss_fe 0.091, Loss_kd 2.232, Train_accy 81.47, Test_accy 79.35
2024-08-02 13:30:25,943 [foster.py] => Task 2, Epoch 168/170 => Loss 2.697, Loss_clf 0.286, Loss_fe 0.088, Loss_kd 2.236, Train_accy 81.91, Test_accy 79.26
2024-08-02 13:30:29,432 [foster.py] => Task 2, Epoch 169/170 => Loss 2.711, Loss_clf 0.301, Loss_fe 0.093, Loss_kd 2.230, Train_accy 81.62, Test_accy 79.33
2024-08-02 13:30:32,927 [foster.py] => Task 2, Epoch 170/170 => Loss 2.750, Loss_clf 0.314, Loss_fe 0.092, Loss_kd 2.257, Train_accy 82.35, Test_accy 79.35
2024-08-02 13:30:32,930 [foster.py] => do not weight align teacher!
2024-08-02 13:30:32,933 [foster.py] => per cls weights : [1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  1.0202818  1.0202818
 1.0202818  1.0202818  1.0202818  1.0202818  0.47267314 0.47267314]
2024-08-02 13:30:37,244 [foster.py] => SNet: Task 2, Epoch 1/130 => Loss 27.346,  Loss1 0.684, Train_accy 42.21, Test_accy 75.81
2024-08-02 13:30:40,156 [foster.py] => SNet: Task 2, Epoch 2/130 => Loss 27.203,  Loss1 0.683, Train_accy 48.14
2024-08-02 13:30:43,132 [foster.py] => SNet: Task 2, Epoch 3/130 => Loss 27.223,  Loss1 0.682, Train_accy 50.83
2024-08-02 13:30:46,047 [foster.py] => SNet: Task 2, Epoch 4/130 => Loss 27.141,  Loss1 0.681, Train_accy 48.33
2024-08-02 13:30:48,996 [foster.py] => SNet: Task 2, Epoch 5/130 => Loss 27.138,  Loss1 0.681, Train_accy 50.54
2024-08-02 13:30:52,807 [foster.py] => SNet: Task 2, Epoch 6/130 => Loss 27.100,  Loss1 0.681, Train_accy 50.78, Test_accy 77.00
2024-08-02 13:30:55,741 [foster.py] => SNet: Task 2, Epoch 7/130 => Loss 27.130,  Loss1 0.681, Train_accy 50.83
2024-08-02 13:30:58,643 [foster.py] => SNet: Task 2, Epoch 8/130 => Loss 27.100,  Loss1 0.681, Train_accy 51.76
2024-08-02 13:31:01,590 [foster.py] => SNet: Task 2, Epoch 9/130 => Loss 27.084,  Loss1 0.682, Train_accy 53.97
2024-08-02 13:31:04,527 [foster.py] => SNet: Task 2, Epoch 10/130 => Loss 27.084,  Loss1 0.681, Train_accy 51.72
2024-08-02 13:31:08,333 [foster.py] => SNet: Task 2, Epoch 11/130 => Loss 27.119,  Loss1 0.682, Train_accy 52.79, Test_accy 77.31
2024-08-02 13:31:11,266 [foster.py] => SNet: Task 2, Epoch 12/130 => Loss 27.167,  Loss1 0.682, Train_accy 55.64
2024-08-02 13:31:14,185 [foster.py] => SNet: Task 2, Epoch 13/130 => Loss 27.075,  Loss1 0.682, Train_accy 54.85
2024-08-02 13:31:17,102 [foster.py] => SNet: Task 2, Epoch 14/130 => Loss 27.118,  Loss1 0.681, Train_accy 54.02
2024-08-02 13:31:20,077 [foster.py] => SNet: Task 2, Epoch 15/130 => Loss 27.096,  Loss1 0.681, Train_accy 56.52
2024-08-02 13:31:23,909 [foster.py] => SNet: Task 2, Epoch 16/130 => Loss 27.089,  Loss1 0.682, Train_accy 54.85, Test_accy 77.65
2024-08-02 13:31:26,845 [foster.py] => SNet: Task 2, Epoch 17/130 => Loss 27.173,  Loss1 0.682, Train_accy 58.73
2024-08-02 13:31:29,796 [foster.py] => SNet: Task 2, Epoch 18/130 => Loss 27.080,  Loss1 0.682, Train_accy 57.25
2024-08-02 13:31:32,695 [foster.py] => SNet: Task 2, Epoch 19/130 => Loss 27.068,  Loss1 0.682, Train_accy 57.55
2024-08-02 13:31:35,605 [foster.py] => SNet: Task 2, Epoch 20/130 => Loss 27.114,  Loss1 0.682, Train_accy 56.52
2024-08-02 13:31:39,409 [foster.py] => SNet: Task 2, Epoch 21/130 => Loss 27.068,  Loss1 0.682, Train_accy 56.37, Test_accy 77.81
2024-08-02 13:31:42,339 [foster.py] => SNet: Task 2, Epoch 22/130 => Loss 27.059,  Loss1 0.682, Train_accy 57.16
2024-08-02 13:31:45,278 [foster.py] => SNet: Task 2, Epoch 23/130 => Loss 27.098,  Loss1 0.682, Train_accy 58.63
2024-08-02 13:31:48,212 [foster.py] => SNet: Task 2, Epoch 24/130 => Loss 27.100,  Loss1 0.682, Train_accy 59.56
2024-08-02 13:31:51,143 [foster.py] => SNet: Task 2, Epoch 25/130 => Loss 27.048,  Loss1 0.682, Train_accy 59.26
2024-08-02 13:31:54,956 [foster.py] => SNet: Task 2, Epoch 26/130 => Loss 27.104,  Loss1 0.682, Train_accy 59.07, Test_accy 77.46
2024-08-02 13:31:57,863 [foster.py] => SNet: Task 2, Epoch 27/130 => Loss 27.047,  Loss1 0.682, Train_accy 57.40
2024-08-02 13:32:00,763 [foster.py] => SNet: Task 2, Epoch 28/130 => Loss 27.109,  Loss1 0.682, Train_accy 59.41
2024-08-02 13:32:03,690 [foster.py] => SNet: Task 2, Epoch 29/130 => Loss 27.107,  Loss1 0.682, Train_accy 58.28
2024-08-02 13:32:06,616 [foster.py] => SNet: Task 2, Epoch 30/130 => Loss 27.131,  Loss1 0.681, Train_accy 58.87
2024-08-02 13:32:10,427 [foster.py] => SNet: Task 2, Epoch 31/130 => Loss 27.070,  Loss1 0.682, Train_accy 61.18, Test_accy 77.91
2024-08-02 13:32:13,354 [foster.py] => SNet: Task 2, Epoch 32/130 => Loss 27.053,  Loss1 0.682, Train_accy 59.95
2024-08-02 13:32:16,266 [foster.py] => SNet: Task 2, Epoch 33/130 => Loss 27.089,  Loss1 0.682, Train_accy 59.22
2024-08-02 13:32:19,175 [foster.py] => SNet: Task 2, Epoch 34/130 => Loss 27.204,  Loss1 0.682, Train_accy 59.07
2024-08-02 13:32:22,100 [foster.py] => SNet: Task 2, Epoch 35/130 => Loss 27.123,  Loss1 0.682, Train_accy 59.36
2024-08-02 13:32:25,997 [foster.py] => SNet: Task 2, Epoch 36/130 => Loss 27.057,  Loss1 0.682, Train_accy 60.49, Test_accy 77.98
2024-08-02 13:32:28,924 [foster.py] => SNet: Task 2, Epoch 37/130 => Loss 27.087,  Loss1 0.682, Train_accy 60.64
2024-08-02 13:32:31,836 [foster.py] => SNet: Task 2, Epoch 38/130 => Loss 27.032,  Loss1 0.682, Train_accy 61.13
2024-08-02 13:32:34,756 [foster.py] => SNet: Task 2, Epoch 39/130 => Loss 27.049,  Loss1 0.682, Train_accy 62.30
2024-08-02 13:32:37,657 [foster.py] => SNet: Task 2, Epoch 40/130 => Loss 27.094,  Loss1 0.682, Train_accy 60.05
2024-08-02 13:32:41,475 [foster.py] => SNet: Task 2, Epoch 41/130 => Loss 27.082,  Loss1 0.682, Train_accy 61.76, Test_accy 78.22
2024-08-02 13:32:44,394 [foster.py] => SNet: Task 2, Epoch 42/130 => Loss 27.102,  Loss1 0.682, Train_accy 61.52
2024-08-02 13:32:47,334 [foster.py] => SNet: Task 2, Epoch 43/130 => Loss 27.058,  Loss1 0.682, Train_accy 60.74
2024-08-02 13:32:50,279 [foster.py] => SNet: Task 2, Epoch 44/130 => Loss 27.089,  Loss1 0.682, Train_accy 61.96
2024-08-02 13:32:53,215 [foster.py] => SNet: Task 2, Epoch 45/130 => Loss 27.072,  Loss1 0.682, Train_accy 61.52
2024-08-02 13:32:57,049 [foster.py] => SNet: Task 2, Epoch 46/130 => Loss 27.120,  Loss1 0.682, Train_accy 62.06, Test_accy 78.02
2024-08-02 13:32:59,978 [foster.py] => SNet: Task 2, Epoch 47/130 => Loss 27.126,  Loss1 0.682, Train_accy 62.21
2024-08-02 13:33:02,886 [foster.py] => SNet: Task 2, Epoch 48/130 => Loss 27.056,  Loss1 0.682, Train_accy 61.72
2024-08-02 13:33:05,803 [foster.py] => SNet: Task 2, Epoch 49/130 => Loss 27.044,  Loss1 0.682, Train_accy 62.35
2024-08-02 13:33:08,739 [foster.py] => SNet: Task 2, Epoch 50/130 => Loss 27.082,  Loss1 0.682, Train_accy 61.86
2024-08-02 13:33:12,534 [foster.py] => SNet: Task 2, Epoch 51/130 => Loss 27.119,  Loss1 0.682, Train_accy 62.40, Test_accy 78.26
2024-08-02 13:33:15,453 [foster.py] => SNet: Task 2, Epoch 52/130 => Loss 27.093,  Loss1 0.682, Train_accy 61.32
2024-08-02 13:33:18,386 [foster.py] => SNet: Task 2, Epoch 53/130 => Loss 27.104,  Loss1 0.683, Train_accy 61.62
2024-08-02 13:33:21,298 [foster.py] => SNet: Task 2, Epoch 54/130 => Loss 27.086,  Loss1 0.682, Train_accy 62.89
2024-08-02 13:33:24,233 [foster.py] => SNet: Task 2, Epoch 55/130 => Loss 27.087,  Loss1 0.682, Train_accy 61.42
2024-08-02 13:33:28,055 [foster.py] => SNet: Task 2, Epoch 56/130 => Loss 27.162,  Loss1 0.682, Train_accy 61.86, Test_accy 78.41
2024-08-02 13:33:30,968 [foster.py] => SNet: Task 2, Epoch 57/130 => Loss 27.117,  Loss1 0.682, Train_accy 62.35
2024-08-02 13:33:33,971 [foster.py] => SNet: Task 2, Epoch 58/130 => Loss 27.131,  Loss1 0.682, Train_accy 61.96
2024-08-02 13:33:36,878 [foster.py] => SNet: Task 2, Epoch 59/130 => Loss 27.058,  Loss1 0.683, Train_accy 62.01
2024-08-02 13:33:39,774 [foster.py] => SNet: Task 2, Epoch 60/130 => Loss 27.079,  Loss1 0.682, Train_accy 63.43
2024-08-02 13:33:43,543 [foster.py] => SNet: Task 2, Epoch 61/130 => Loss 27.098,  Loss1 0.682, Train_accy 62.30, Test_accy 78.17
2024-08-02 13:33:46,465 [foster.py] => SNet: Task 2, Epoch 62/130 => Loss 27.088,  Loss1 0.682, Train_accy 65.05
2024-08-02 13:33:49,375 [foster.py] => SNet: Task 2, Epoch 63/130 => Loss 27.097,  Loss1 0.682, Train_accy 62.35
2024-08-02 13:33:52,325 [foster.py] => SNet: Task 2, Epoch 64/130 => Loss 27.063,  Loss1 0.682, Train_accy 63.24
2024-08-02 13:33:55,248 [foster.py] => SNet: Task 2, Epoch 65/130 => Loss 27.077,  Loss1 0.683, Train_accy 64.07
2024-08-02 13:33:59,052 [foster.py] => SNet: Task 2, Epoch 66/130 => Loss 27.160,  Loss1 0.682, Train_accy 62.60, Test_accy 78.52
2024-08-02 13:34:01,983 [foster.py] => SNet: Task 2, Epoch 67/130 => Loss 27.083,  Loss1 0.682, Train_accy 62.75
2024-08-02 13:34:04,913 [foster.py] => SNet: Task 2, Epoch 68/130 => Loss 27.113,  Loss1 0.682, Train_accy 62.70
2024-08-02 13:34:07,846 [foster.py] => SNet: Task 2, Epoch 69/130 => Loss 27.091,  Loss1 0.682, Train_accy 61.72
2024-08-02 13:34:10,752 [foster.py] => SNet: Task 2, Epoch 70/130 => Loss 27.111,  Loss1 0.682, Train_accy 62.55
2024-08-02 13:34:14,577 [foster.py] => SNet: Task 2, Epoch 71/130 => Loss 27.111,  Loss1 0.682, Train_accy 61.57, Test_accy 78.46
2024-08-02 13:34:17,494 [foster.py] => SNet: Task 2, Epoch 72/130 => Loss 27.100,  Loss1 0.682, Train_accy 62.79
2024-08-02 13:34:20,444 [foster.py] => SNet: Task 2, Epoch 73/130 => Loss 27.118,  Loss1 0.682, Train_accy 62.45
2024-08-02 13:34:23,358 [foster.py] => SNet: Task 2, Epoch 74/130 => Loss 27.054,  Loss1 0.682, Train_accy 64.36
2024-08-02 13:34:26,316 [foster.py] => SNet: Task 2, Epoch 75/130 => Loss 27.067,  Loss1 0.683, Train_accy 62.60
2024-08-02 13:34:30,161 [foster.py] => SNet: Task 2, Epoch 76/130 => Loss 27.096,  Loss1 0.682, Train_accy 64.26, Test_accy 78.28
2024-08-02 13:34:33,099 [foster.py] => SNet: Task 2, Epoch 77/130 => Loss 27.083,  Loss1 0.682, Train_accy 62.99
2024-08-02 13:34:36,021 [foster.py] => SNet: Task 2, Epoch 78/130 => Loss 27.061,  Loss1 0.682, Train_accy 64.26
2024-08-02 13:34:38,926 [foster.py] => SNet: Task 2, Epoch 79/130 => Loss 27.058,  Loss1 0.683, Train_accy 64.07
2024-08-02 13:34:41,920 [foster.py] => SNet: Task 2, Epoch 80/130 => Loss 27.065,  Loss1 0.682, Train_accy 64.36
2024-08-02 13:34:45,746 [foster.py] => SNet: Task 2, Epoch 81/130 => Loss 27.051,  Loss1 0.682, Train_accy 63.33, Test_accy 78.41
2024-08-02 13:34:48,657 [foster.py] => SNet: Task 2, Epoch 82/130 => Loss 27.082,  Loss1 0.682, Train_accy 62.94
2024-08-02 13:34:51,580 [foster.py] => SNet: Task 2, Epoch 83/130 => Loss 27.132,  Loss1 0.682, Train_accy 63.19
2024-08-02 13:34:54,490 [foster.py] => SNet: Task 2, Epoch 84/130 => Loss 27.065,  Loss1 0.682, Train_accy 63.53
2024-08-02 13:34:57,412 [foster.py] => SNet: Task 2, Epoch 85/130 => Loss 27.049,  Loss1 0.682, Train_accy 63.92
2024-08-02 13:35:01,225 [foster.py] => SNet: Task 2, Epoch 86/130 => Loss 27.083,  Loss1 0.682, Train_accy 63.38, Test_accy 78.85
2024-08-02 13:35:04,155 [foster.py] => SNet: Task 2, Epoch 87/130 => Loss 27.049,  Loss1 0.682, Train_accy 64.31
2024-08-02 13:35:07,065 [foster.py] => SNet: Task 2, Epoch 88/130 => Loss 27.068,  Loss1 0.682, Train_accy 62.30
2024-08-02 13:35:09,983 [foster.py] => SNet: Task 2, Epoch 89/130 => Loss 27.058,  Loss1 0.682, Train_accy 62.25
2024-08-02 13:35:12,923 [foster.py] => SNet: Task 2, Epoch 90/130 => Loss 27.060,  Loss1 0.682, Train_accy 63.48
2024-08-02 13:35:16,738 [foster.py] => SNet: Task 2, Epoch 91/130 => Loss 27.159,  Loss1 0.682, Train_accy 62.55, Test_accy 78.63
2024-08-02 13:35:19,642 [foster.py] => SNet: Task 2, Epoch 92/130 => Loss 27.107,  Loss1 0.682, Train_accy 63.24
2024-08-02 13:35:22,555 [foster.py] => SNet: Task 2, Epoch 93/130 => Loss 27.111,  Loss1 0.682, Train_accy 63.43
2024-08-02 13:35:25,463 [foster.py] => SNet: Task 2, Epoch 94/130 => Loss 27.075,  Loss1 0.682, Train_accy 63.73
2024-08-02 13:35:28,398 [foster.py] => SNet: Task 2, Epoch 95/130 => Loss 27.101,  Loss1 0.682, Train_accy 64.71
2024-08-02 13:35:32,225 [foster.py] => SNet: Task 2, Epoch 96/130 => Loss 27.095,  Loss1 0.682, Train_accy 62.65, Test_accy 78.61
2024-08-02 13:35:35,139 [foster.py] => SNet: Task 2, Epoch 97/130 => Loss 27.110,  Loss1 0.682, Train_accy 63.77
2024-08-02 13:35:38,041 [foster.py] => SNet: Task 2, Epoch 98/130 => Loss 27.089,  Loss1 0.682, Train_accy 61.23
2024-08-02 13:35:40,953 [foster.py] => SNet: Task 2, Epoch 99/130 => Loss 27.161,  Loss1 0.682, Train_accy 63.63
2024-08-02 13:35:43,866 [foster.py] => SNet: Task 2, Epoch 100/130 => Loss 27.045,  Loss1 0.682, Train_accy 64.36
2024-08-02 13:35:47,673 [foster.py] => SNet: Task 2, Epoch 101/130 => Loss 27.083,  Loss1 0.683, Train_accy 65.78, Test_accy 78.52
2024-08-02 13:35:50,674 [foster.py] => SNet: Task 2, Epoch 102/130 => Loss 27.093,  Loss1 0.682, Train_accy 64.61
2024-08-02 13:35:53,577 [foster.py] => SNet: Task 2, Epoch 103/130 => Loss 27.063,  Loss1 0.682, Train_accy 64.36
2024-08-02 13:35:56,504 [foster.py] => SNet: Task 2, Epoch 104/130 => Loss 27.118,  Loss1 0.682, Train_accy 64.85
2024-08-02 13:35:59,425 [foster.py] => SNet: Task 2, Epoch 105/130 => Loss 27.053,  Loss1 0.682, Train_accy 64.02
2024-08-02 13:36:03,235 [foster.py] => SNet: Task 2, Epoch 106/130 => Loss 27.058,  Loss1 0.683, Train_accy 63.28, Test_accy 78.54
2024-08-02 13:36:06,152 [foster.py] => SNet: Task 2, Epoch 107/130 => Loss 27.121,  Loss1 0.682, Train_accy 62.94
2024-08-02 13:36:09,069 [foster.py] => SNet: Task 2, Epoch 108/130 => Loss 27.116,  Loss1 0.683, Train_accy 62.94
2024-08-02 13:36:11,987 [foster.py] => SNet: Task 2, Epoch 109/130 => Loss 27.150,  Loss1 0.683, Train_accy 63.97
2024-08-02 13:36:14,912 [foster.py] => SNet: Task 2, Epoch 110/130 => Loss 27.138,  Loss1 0.683, Train_accy 63.82
2024-08-02 13:36:18,713 [foster.py] => SNet: Task 2, Epoch 111/130 => Loss 27.091,  Loss1 0.682, Train_accy 63.53, Test_accy 78.63
2024-08-02 13:36:21,630 [foster.py] => SNet: Task 2, Epoch 112/130 => Loss 27.083,  Loss1 0.683, Train_accy 64.61
2024-08-02 13:36:24,552 [foster.py] => SNet: Task 2, Epoch 113/130 => Loss 27.037,  Loss1 0.682, Train_accy 64.26
2024-08-02 13:36:27,458 [foster.py] => SNet: Task 2, Epoch 114/130 => Loss 27.143,  Loss1 0.682, Train_accy 63.92
2024-08-02 13:36:30,373 [foster.py] => SNet: Task 2, Epoch 115/130 => Loss 27.117,  Loss1 0.683, Train_accy 63.14
2024-08-02 13:36:34,180 [foster.py] => SNet: Task 2, Epoch 116/130 => Loss 27.093,  Loss1 0.683, Train_accy 64.17, Test_accy 78.50
2024-08-02 13:36:37,091 [foster.py] => SNet: Task 2, Epoch 117/130 => Loss 27.087,  Loss1 0.683, Train_accy 64.36
2024-08-02 13:36:40,010 [foster.py] => SNet: Task 2, Epoch 118/130 => Loss 27.095,  Loss1 0.682, Train_accy 63.33
2024-08-02 13:36:42,940 [foster.py] => SNet: Task 2, Epoch 119/130 => Loss 27.116,  Loss1 0.682, Train_accy 64.80
2024-08-02 13:36:45,847 [foster.py] => SNet: Task 2, Epoch 120/130 => Loss 27.119,  Loss1 0.682, Train_accy 64.90
2024-08-02 13:36:49,656 [foster.py] => SNet: Task 2, Epoch 121/130 => Loss 27.080,  Loss1 0.682, Train_accy 64.07, Test_accy 78.52
2024-08-02 13:36:52,580 [foster.py] => SNet: Task 2, Epoch 122/130 => Loss 27.059,  Loss1 0.682, Train_accy 64.61
2024-08-02 13:36:55,501 [foster.py] => SNet: Task 2, Epoch 123/130 => Loss 27.112,  Loss1 0.682, Train_accy 62.79
2024-08-02 13:36:58,494 [foster.py] => SNet: Task 2, Epoch 124/130 => Loss 27.098,  Loss1 0.682, Train_accy 63.14
2024-08-02 13:37:01,410 [foster.py] => SNet: Task 2, Epoch 125/130 => Loss 27.036,  Loss1 0.682, Train_accy 64.85
2024-08-02 13:37:05,239 [foster.py] => SNet: Task 2, Epoch 126/130 => Loss 27.070,  Loss1 0.682, Train_accy 63.53, Test_accy 78.67
2024-08-02 13:37:08,146 [foster.py] => SNet: Task 2, Epoch 127/130 => Loss 27.109,  Loss1 0.682, Train_accy 64.12
2024-08-02 13:37:11,044 [foster.py] => SNet: Task 2, Epoch 128/130 => Loss 27.090,  Loss1 0.682, Train_accy 63.38
2024-08-02 13:37:13,982 [foster.py] => SNet: Task 2, Epoch 129/130 => Loss 27.097,  Loss1 0.683, Train_accy 64.46
2024-08-02 13:37:16,925 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 27.066,  Loss1 0.682, Train_accy 62.55
2024-08-02 13:37:16,926 [foster.py] => do not weight align student!
2024-08-02 13:37:17,837 [foster.py] => darknet eval: 
2024-08-02 13:37:17,837 [foster.py] => CNN top1 curve: 78.48
2024-08-02 13:37:17,838 [foster.py] => CNN top5 curve: 96.35
2024-08-02 13:37:17,838 [foster.py] => CNN top1 平均值: 78.48
2024-08-02 13:37:17,840 [foster.py] => timees : 952.1150679588318
2024-08-02 13:37:17,841 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 13:37:34,241 [foster.py] => Exemplar size: 1080
2024-08-02 13:37:34,242 [trainer.py] => CNN: {'total': 79.35, '00-09': 83.9, '10-19': 76.0, '20-29': 82.8, '30-39': 78.0, '40-49': 81.0, '50-59': 67.0, 'old': 79.71, 'new': 70.0}
2024-08-02 13:37:34,242 [trainer.py] => NME: {'total': 76.3, '00-09': 79.3, '10-19': 72.7, '20-29': 81.5, '30-39': 74.2, '40-49': 72.8, '50-59': 78.75, 'old': 75.62, 'new': 94.0}
2024-08-02 13:37:34,242 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35]
2024-08-02 13:37:34,242 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65]
2024-08-02 13:37:34,242 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3]
2024-08-02 13:37:34,242 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65]

2024-08-02 13:37:34,242 [trainer.py] => CNN top1 平均值: 80.59
2024-08-02 13:37:34,244 [trainer.py] => All params: 1168404
2024-08-02 13:37:34,247 [trainer.py] => Trainable params: 587750
2024-08-02 13:37:34,306 [foster.py] => Learning on 54-56
2024-08-02 13:37:34,309 [foster.py] => All params: 1168922
2024-08-02 13:37:34,311 [foster.py] => Trainable params: 588138
2024-08-02 13:37:34,347 [foster.py] => per cls weights : [1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023 1.01644023
 0.55611386 0.55611386]
2024-08-02 13:37:36,688 [foster.py] => Task 3, Epoch 1/170 => Loss 5.671, Loss_clf 1.350, Loss_fe 1.906, Loss_kd 2.328, Train_accy 62.60
2024-08-02 13:37:40,370 [foster.py] => Task 3, Epoch 2/170 => Loss 3.711, Loss_clf 0.580, Loss_fe 0.731, Loss_kd 2.313, Train_accy 67.26, Test_accy 77.02
2024-08-02 13:37:43,966 [foster.py] => Task 3, Epoch 3/170 => Loss 3.453, Loss_clf 0.475, Loss_fe 0.641, Loss_kd 2.252, Train_accy 67.40, Test_accy 77.12
2024-08-02 13:37:47,601 [foster.py] => Task 3, Epoch 4/170 => Loss 3.407, Loss_clf 0.458, Loss_fe 0.582, Loss_kd 2.282, Train_accy 69.13, Test_accy 77.61
2024-08-02 13:37:51,184 [foster.py] => Task 3, Epoch 5/170 => Loss 3.435, Loss_clf 0.470, Loss_fe 0.574, Loss_kd 2.304, Train_accy 68.12, Test_accy 77.52
2024-08-02 13:37:53,446 [foster.py] => Task 3, Epoch 6/170 => Loss 3.371, Loss_clf 0.468, Loss_fe 0.518, Loss_kd 2.299, Train_accy 67.79
2024-08-02 13:37:57,075 [foster.py] => Task 3, Epoch 7/170 => Loss 3.329, Loss_clf 0.471, Loss_fe 0.472, Loss_kd 2.300, Train_accy 68.37, Test_accy 77.79
2024-08-02 13:38:00,694 [foster.py] => Task 3, Epoch 8/170 => Loss 3.304, Loss_clf 0.463, Loss_fe 0.457, Loss_kd 2.298, Train_accy 68.03, Test_accy 77.61
2024-08-02 13:38:04,320 [foster.py] => Task 3, Epoch 9/170 => Loss 3.194, Loss_clf 0.410, Loss_fe 0.410, Loss_kd 2.288, Train_accy 71.63, Test_accy 77.79
2024-08-02 13:38:07,933 [foster.py] => Task 3, Epoch 10/170 => Loss 3.252, Loss_clf 0.441, Loss_fe 0.411, Loss_kd 2.313, Train_accy 70.67, Test_accy 77.41
2024-08-02 13:38:10,151 [foster.py] => Task 3, Epoch 11/170 => Loss 3.261, Loss_clf 0.463, Loss_fe 0.397, Loss_kd 2.314, Train_accy 69.38
2024-08-02 13:38:13,796 [foster.py] => Task 3, Epoch 12/170 => Loss 3.200, Loss_clf 0.442, Loss_fe 0.366, Loss_kd 2.306, Train_accy 70.96, Test_accy 77.48
2024-08-02 13:38:17,457 [foster.py] => Task 3, Epoch 13/170 => Loss 3.160, Loss_clf 0.417, Loss_fe 0.386, Loss_kd 2.271, Train_accy 73.75, Test_accy 77.45
2024-08-02 13:38:21,095 [foster.py] => Task 3, Epoch 14/170 => Loss 3.149, Loss_clf 0.418, Loss_fe 0.371, Loss_kd 2.274, Train_accy 71.97, Test_accy 77.18
2024-08-02 13:38:24,686 [foster.py] => Task 3, Epoch 15/170 => Loss 3.259, Loss_clf 0.463, Loss_fe 0.380, Loss_kd 2.328, Train_accy 68.70, Test_accy 77.32
2024-08-02 13:38:26,910 [foster.py] => Task 3, Epoch 16/170 => Loss 3.091, Loss_clf 0.403, Loss_fe 0.338, Loss_kd 2.265, Train_accy 72.84
2024-08-02 13:38:30,526 [foster.py] => Task 3, Epoch 17/170 => Loss 3.189, Loss_clf 0.428, Loss_fe 0.368, Loss_kd 2.306, Train_accy 72.74, Test_accy 77.59
2024-08-02 13:38:34,119 [foster.py] => Task 3, Epoch 18/170 => Loss 3.125, Loss_clf 0.401, Loss_fe 0.336, Loss_kd 2.302, Train_accy 73.12, Test_accy 77.80
2024-08-02 13:38:37,791 [foster.py] => Task 3, Epoch 19/170 => Loss 3.098, Loss_clf 0.381, Loss_fe 0.330, Loss_kd 2.301, Train_accy 75.72, Test_accy 77.30
2024-08-02 13:38:41,372 [foster.py] => Task 3, Epoch 20/170 => Loss 3.161, Loss_clf 0.423, Loss_fe 0.355, Loss_kd 2.296, Train_accy 72.64, Test_accy 77.98
2024-08-02 13:38:43,632 [foster.py] => Task 3, Epoch 21/170 => Loss 3.179, Loss_clf 0.435, Loss_fe 0.346, Loss_kd 2.311, Train_accy 73.32
2024-08-02 13:38:47,238 [foster.py] => Task 3, Epoch 22/170 => Loss 3.076, Loss_clf 0.400, Loss_fe 0.323, Loss_kd 2.267, Train_accy 73.22, Test_accy 77.95
2024-08-02 13:38:50,925 [foster.py] => Task 3, Epoch 23/170 => Loss 3.171, Loss_clf 0.445, Loss_fe 0.326, Loss_kd 2.313, Train_accy 72.45, Test_accy 78.07
2024-08-02 13:38:54,516 [foster.py] => Task 3, Epoch 24/170 => Loss 3.162, Loss_clf 0.429, Loss_fe 0.334, Loss_kd 2.312, Train_accy 73.94, Test_accy 77.73
2024-08-02 13:38:58,126 [foster.py] => Task 3, Epoch 25/170 => Loss 3.075, Loss_clf 0.408, Loss_fe 0.304, Loss_kd 2.277, Train_accy 72.16, Test_accy 77.66
2024-08-02 13:39:00,342 [foster.py] => Task 3, Epoch 26/170 => Loss 3.067, Loss_clf 0.385, Loss_fe 0.315, Loss_kd 2.281, Train_accy 75.05
2024-08-02 13:39:03,947 [foster.py] => Task 3, Epoch 27/170 => Loss 3.013, Loss_clf 0.383, Loss_fe 0.288, Loss_kd 2.257, Train_accy 72.64, Test_accy 77.96
2024-08-02 13:39:07,518 [foster.py] => Task 3, Epoch 28/170 => Loss 3.020, Loss_clf 0.368, Loss_fe 0.302, Loss_kd 2.264, Train_accy 73.70, Test_accy 77.73
2024-08-02 13:39:11,127 [foster.py] => Task 3, Epoch 29/170 => Loss 3.035, Loss_clf 0.375, Loss_fe 0.285, Loss_kd 2.289, Train_accy 74.23, Test_accy 77.70
2024-08-02 13:39:14,711 [foster.py] => Task 3, Epoch 30/170 => Loss 3.033, Loss_clf 0.384, Loss_fe 0.272, Loss_kd 2.291, Train_accy 76.15, Test_accy 77.71
2024-08-02 13:39:16,953 [foster.py] => Task 3, Epoch 31/170 => Loss 2.934, Loss_clf 0.347, Loss_fe 0.258, Loss_kd 2.244, Train_accy 76.30
2024-08-02 13:39:20,550 [foster.py] => Task 3, Epoch 32/170 => Loss 3.024, Loss_clf 0.376, Loss_fe 0.267, Loss_kd 2.295, Train_accy 74.47, Test_accy 77.64
2024-08-02 13:39:24,155 [foster.py] => Task 3, Epoch 33/170 => Loss 3.046, Loss_clf 0.384, Loss_fe 0.293, Loss_kd 2.283, Train_accy 74.28, Test_accy 78.48
2024-08-02 13:39:27,785 [foster.py] => Task 3, Epoch 34/170 => Loss 3.103, Loss_clf 0.409, Loss_fe 0.309, Loss_kd 2.299, Train_accy 76.54, Test_accy 77.41
2024-08-02 13:39:31,420 [foster.py] => Task 3, Epoch 35/170 => Loss 3.054, Loss_clf 0.391, Loss_fe 0.298, Loss_kd 2.280, Train_accy 74.76, Test_accy 78.05
2024-08-02 13:39:33,750 [foster.py] => Task 3, Epoch 36/170 => Loss 3.030, Loss_clf 0.381, Loss_fe 0.287, Loss_kd 2.276, Train_accy 73.46
2024-08-02 13:39:37,356 [foster.py] => Task 3, Epoch 37/170 => Loss 3.019, Loss_clf 0.375, Loss_fe 0.274, Loss_kd 2.283, Train_accy 76.11, Test_accy 77.80
2024-08-02 13:39:40,991 [foster.py] => Task 3, Epoch 38/170 => Loss 3.061, Loss_clf 0.403, Loss_fe 0.279, Loss_kd 2.294, Train_accy 75.87, Test_accy 78.00
2024-08-02 13:39:44,609 [foster.py] => Task 3, Epoch 39/170 => Loss 2.972, Loss_clf 0.369, Loss_fe 0.245, Loss_kd 2.273, Train_accy 74.62, Test_accy 77.79
2024-08-02 13:39:48,252 [foster.py] => Task 3, Epoch 40/170 => Loss 3.032, Loss_clf 0.398, Loss_fe 0.256, Loss_kd 2.292, Train_accy 75.53, Test_accy 78.36
2024-08-02 13:39:50,490 [foster.py] => Task 3, Epoch 41/170 => Loss 3.007, Loss_clf 0.380, Loss_fe 0.240, Loss_kd 2.301, Train_accy 75.87
2024-08-02 13:39:54,117 [foster.py] => Task 3, Epoch 42/170 => Loss 2.985, Loss_clf 0.382, Loss_fe 0.245, Loss_kd 2.273, Train_accy 77.07, Test_accy 77.89
2024-08-02 13:39:57,747 [foster.py] => Task 3, Epoch 43/170 => Loss 3.020, Loss_clf 0.375, Loss_fe 0.272, Loss_kd 2.287, Train_accy 76.35, Test_accy 77.98
2024-08-02 13:40:01,364 [foster.py] => Task 3, Epoch 44/170 => Loss 2.923, Loss_clf 0.332, Loss_fe 0.244, Loss_kd 2.261, Train_accy 76.73, Test_accy 78.11
2024-08-02 13:40:04,981 [foster.py] => Task 3, Epoch 45/170 => Loss 2.983, Loss_clf 0.378, Loss_fe 0.249, Loss_kd 2.271, Train_accy 76.54, Test_accy 78.00
2024-08-02 13:40:07,211 [foster.py] => Task 3, Epoch 46/170 => Loss 2.976, Loss_clf 0.366, Loss_fe 0.240, Loss_kd 2.283, Train_accy 75.29
2024-08-02 13:40:10,784 [foster.py] => Task 3, Epoch 47/170 => Loss 3.008, Loss_clf 0.369, Loss_fe 0.270, Loss_kd 2.283, Train_accy 75.96, Test_accy 78.25
2024-08-02 13:40:14,401 [foster.py] => Task 3, Epoch 48/170 => Loss 2.967, Loss_clf 0.363, Loss_fe 0.245, Loss_kd 2.273, Train_accy 76.68, Test_accy 78.23
2024-08-02 13:40:18,032 [foster.py] => Task 3, Epoch 49/170 => Loss 2.974, Loss_clf 0.366, Loss_fe 0.244, Loss_kd 2.278, Train_accy 75.96, Test_accy 78.00
2024-08-02 13:40:21,639 [foster.py] => Task 3, Epoch 50/170 => Loss 2.955, Loss_clf 0.355, Loss_fe 0.228, Loss_kd 2.286, Train_accy 77.07, Test_accy 77.79
2024-08-02 13:40:23,858 [foster.py] => Task 3, Epoch 51/170 => Loss 2.983, Loss_clf 0.374, Loss_fe 0.228, Loss_kd 2.294, Train_accy 77.50
2024-08-02 13:40:27,430 [foster.py] => Task 3, Epoch 52/170 => Loss 3.007, Loss_clf 0.370, Loss_fe 0.224, Loss_kd 2.326, Train_accy 75.53, Test_accy 77.52
2024-08-02 13:40:31,010 [foster.py] => Task 3, Epoch 53/170 => Loss 2.947, Loss_clf 0.351, Loss_fe 0.217, Loss_kd 2.292, Train_accy 77.31, Test_accy 78.30
2024-08-02 13:40:34,659 [foster.py] => Task 3, Epoch 54/170 => Loss 2.952, Loss_clf 0.349, Loss_fe 0.219, Loss_kd 2.298, Train_accy 79.13, Test_accy 78.07
2024-08-02 13:40:38,271 [foster.py] => Task 3, Epoch 55/170 => Loss 2.938, Loss_clf 0.336, Loss_fe 0.225, Loss_kd 2.290, Train_accy 78.32, Test_accy 78.23
2024-08-02 13:40:40,515 [foster.py] => Task 3, Epoch 56/170 => Loss 3.048, Loss_clf 0.400, Loss_fe 0.247, Loss_kd 2.314, Train_accy 75.67
2024-08-02 13:40:44,153 [foster.py] => Task 3, Epoch 57/170 => Loss 2.974, Loss_clf 0.373, Loss_fe 0.224, Loss_kd 2.290, Train_accy 77.07, Test_accy 78.09
2024-08-02 13:40:47,787 [foster.py] => Task 3, Epoch 58/170 => Loss 2.916, Loss_clf 0.331, Loss_fe 0.208, Loss_kd 2.290, Train_accy 78.27, Test_accy 78.32
2024-08-02 13:40:51,562 [foster.py] => Task 3, Epoch 59/170 => Loss 2.984, Loss_clf 0.352, Loss_fe 0.228, Loss_kd 2.317, Train_accy 77.93, Test_accy 77.77
2024-08-02 13:40:55,159 [foster.py] => Task 3, Epoch 60/170 => Loss 2.928, Loss_clf 0.356, Loss_fe 0.213, Loss_kd 2.274, Train_accy 77.26, Test_accy 78.18
2024-08-02 13:40:57,404 [foster.py] => Task 3, Epoch 61/170 => Loss 2.952, Loss_clf 0.362, Loss_fe 0.221, Loss_kd 2.282, Train_accy 78.56
2024-08-02 13:41:01,018 [foster.py] => Task 3, Epoch 62/170 => Loss 2.971, Loss_clf 0.357, Loss_fe 0.217, Loss_kd 2.310, Train_accy 77.98, Test_accy 78.00
2024-08-02 13:41:04,607 [foster.py] => Task 3, Epoch 63/170 => Loss 2.930, Loss_clf 0.345, Loss_fe 0.224, Loss_kd 2.275, Train_accy 77.55, Test_accy 78.11
2024-08-02 13:41:08,189 [foster.py] => Task 3, Epoch 64/170 => Loss 2.967, Loss_clf 0.382, Loss_fe 0.209, Loss_kd 2.290, Train_accy 78.85, Test_accy 78.20
2024-08-02 13:41:11,876 [foster.py] => Task 3, Epoch 65/170 => Loss 2.921, Loss_clf 0.341, Loss_fe 0.210, Loss_kd 2.284, Train_accy 77.36, Test_accy 78.27
2024-08-02 13:41:14,126 [foster.py] => Task 3, Epoch 66/170 => Loss 2.870, Loss_clf 0.333, Loss_fe 0.174, Loss_kd 2.276, Train_accy 78.37
2024-08-02 13:41:17,753 [foster.py] => Task 3, Epoch 67/170 => Loss 2.837, Loss_clf 0.316, Loss_fe 0.169, Loss_kd 2.267, Train_accy 78.51, Test_accy 78.29
2024-08-02 13:41:21,347 [foster.py] => Task 3, Epoch 68/170 => Loss 2.924, Loss_clf 0.341, Loss_fe 0.182, Loss_kd 2.314, Train_accy 78.22, Test_accy 77.80
2024-08-02 13:41:24,932 [foster.py] => Task 3, Epoch 69/170 => Loss 2.889, Loss_clf 0.333, Loss_fe 0.197, Loss_kd 2.274, Train_accy 78.89, Test_accy 78.21
2024-08-02 13:41:28,563 [foster.py] => Task 3, Epoch 70/170 => Loss 2.921, Loss_clf 0.343, Loss_fe 0.182, Loss_kd 2.309, Train_accy 79.33, Test_accy 78.23
2024-08-02 13:41:30,803 [foster.py] => Task 3, Epoch 71/170 => Loss 2.953, Loss_clf 0.378, Loss_fe 0.201, Loss_kd 2.288, Train_accy 76.83
2024-08-02 13:41:34,405 [foster.py] => Task 3, Epoch 72/170 => Loss 2.946, Loss_clf 0.350, Loss_fe 0.224, Loss_kd 2.286, Train_accy 77.74, Test_accy 78.38
2024-08-02 13:41:38,080 [foster.py] => Task 3, Epoch 73/170 => Loss 2.940, Loss_clf 0.359, Loss_fe 0.208, Loss_kd 2.287, Train_accy 79.04, Test_accy 78.00
2024-08-02 13:41:41,667 [foster.py] => Task 3, Epoch 74/170 => Loss 2.911, Loss_clf 0.340, Loss_fe 0.204, Loss_kd 2.281, Train_accy 79.66, Test_accy 77.98
2024-08-02 13:41:45,292 [foster.py] => Task 3, Epoch 75/170 => Loss 2.939, Loss_clf 0.355, Loss_fe 0.195, Loss_kd 2.301, Train_accy 77.31, Test_accy 77.91
2024-08-02 13:41:47,506 [foster.py] => Task 3, Epoch 76/170 => Loss 2.904, Loss_clf 0.340, Loss_fe 0.183, Loss_kd 2.295, Train_accy 77.88
2024-08-02 13:41:51,105 [foster.py] => Task 3, Epoch 77/170 => Loss 2.871, Loss_clf 0.325, Loss_fe 0.184, Loss_kd 2.276, Train_accy 78.51, Test_accy 78.20
2024-08-02 13:41:54,753 [foster.py] => Task 3, Epoch 78/170 => Loss 2.924, Loss_clf 0.351, Loss_fe 0.206, Loss_kd 2.281, Train_accy 79.66, Test_accy 78.30
2024-08-02 13:41:58,369 [foster.py] => Task 3, Epoch 79/170 => Loss 2.923, Loss_clf 0.341, Loss_fe 0.195, Loss_kd 2.300, Train_accy 79.33, Test_accy 78.38
2024-08-02 13:42:02,002 [foster.py] => Task 3, Epoch 80/170 => Loss 2.878, Loss_clf 0.330, Loss_fe 0.162, Loss_kd 2.299, Train_accy 81.11, Test_accy 78.43
2024-08-02 13:42:04,217 [foster.py] => Task 3, Epoch 81/170 => Loss 2.874, Loss_clf 0.324, Loss_fe 0.170, Loss_kd 2.294, Train_accy 80.34
2024-08-02 13:42:07,938 [foster.py] => Task 3, Epoch 82/170 => Loss 2.874, Loss_clf 0.335, Loss_fe 0.163, Loss_kd 2.291, Train_accy 79.52, Test_accy 78.20
2024-08-02 13:42:11,524 [foster.py] => Task 3, Epoch 83/170 => Loss 2.829, Loss_clf 0.316, Loss_fe 0.169, Loss_kd 2.259, Train_accy 81.88, Test_accy 78.27
2024-08-02 13:42:15,144 [foster.py] => Task 3, Epoch 84/170 => Loss 2.855, Loss_clf 0.321, Loss_fe 0.173, Loss_kd 2.276, Train_accy 82.45, Test_accy 78.36
2024-08-02 13:42:18,755 [foster.py] => Task 3, Epoch 85/170 => Loss 2.899, Loss_clf 0.343, Loss_fe 0.173, Loss_kd 2.297, Train_accy 80.10, Test_accy 78.66
2024-08-02 13:42:20,975 [foster.py] => Task 3, Epoch 86/170 => Loss 2.888, Loss_clf 0.332, Loss_fe 0.163, Loss_kd 2.306, Train_accy 80.82
2024-08-02 13:42:24,718 [foster.py] => Task 3, Epoch 87/170 => Loss 2.872, Loss_clf 0.322, Loss_fe 0.172, Loss_kd 2.292, Train_accy 81.30, Test_accy 78.02
2024-08-02 13:42:28,410 [foster.py] => Task 3, Epoch 88/170 => Loss 2.910, Loss_clf 0.338, Loss_fe 0.189, Loss_kd 2.296, Train_accy 80.72, Test_accy 78.29
2024-08-02 13:42:32,140 [foster.py] => Task 3, Epoch 89/170 => Loss 2.799, Loss_clf 0.291, Loss_fe 0.157, Loss_kd 2.266, Train_accy 81.39, Test_accy 78.02
2024-08-02 13:42:35,824 [foster.py] => Task 3, Epoch 90/170 => Loss 2.864, Loss_clf 0.333, Loss_fe 0.159, Loss_kd 2.286, Train_accy 80.58, Test_accy 77.82
2024-08-02 13:42:38,045 [foster.py] => Task 3, Epoch 91/170 => Loss 2.854, Loss_clf 0.336, Loss_fe 0.159, Loss_kd 2.274, Train_accy 79.04
2024-08-02 13:42:41,669 [foster.py] => Task 3, Epoch 92/170 => Loss 2.895, Loss_clf 0.337, Loss_fe 0.179, Loss_kd 2.293, Train_accy 80.10, Test_accy 78.14
2024-08-02 13:42:45,282 [foster.py] => Task 3, Epoch 93/170 => Loss 2.868, Loss_clf 0.330, Loss_fe 0.161, Loss_kd 2.291, Train_accy 81.15, Test_accy 78.43
2024-08-02 13:42:48,885 [foster.py] => Task 3, Epoch 94/170 => Loss 2.771, Loss_clf 0.293, Loss_fe 0.136, Loss_kd 2.258, Train_accy 82.21, Test_accy 78.16
2024-08-02 13:42:52,488 [foster.py] => Task 3, Epoch 95/170 => Loss 2.873, Loss_clf 0.339, Loss_fe 0.141, Loss_kd 2.307, Train_accy 80.29, Test_accy 77.98
2024-08-02 13:42:54,705 [foster.py] => Task 3, Epoch 96/170 => Loss 2.853, Loss_clf 0.328, Loss_fe 0.138, Loss_kd 2.300, Train_accy 81.68
2024-08-02 13:42:58,287 [foster.py] => Task 3, Epoch 97/170 => Loss 2.765, Loss_clf 0.286, Loss_fe 0.143, Loss_kd 2.252, Train_accy 80.67, Test_accy 78.12
2024-08-02 13:43:01,893 [foster.py] => Task 3, Epoch 98/170 => Loss 2.867, Loss_clf 0.343, Loss_fe 0.154, Loss_kd 2.284, Train_accy 79.38, Test_accy 78.09
2024-08-02 13:43:05,541 [foster.py] => Task 3, Epoch 99/170 => Loss 2.893, Loss_clf 0.336, Loss_fe 0.165, Loss_kd 2.305, Train_accy 80.19, Test_accy 78.04
2024-08-02 13:43:09,138 [foster.py] => Task 3, Epoch 100/170 => Loss 2.890, Loss_clf 0.356, Loss_fe 0.148, Loss_kd 2.300, Train_accy 78.85, Test_accy 77.93
2024-08-02 13:43:11,360 [foster.py] => Task 3, Epoch 101/170 => Loss 2.841, Loss_clf 0.324, Loss_fe 0.156, Loss_kd 2.275, Train_accy 80.53
2024-08-02 13:43:14,968 [foster.py] => Task 3, Epoch 102/170 => Loss 2.858, Loss_clf 0.313, Loss_fe 0.156, Loss_kd 2.302, Train_accy 81.59, Test_accy 77.88
2024-08-02 13:43:18,583 [foster.py] => Task 3, Epoch 103/170 => Loss 2.823, Loss_clf 0.322, Loss_fe 0.133, Loss_kd 2.282, Train_accy 80.91, Test_accy 78.32
2024-08-02 13:43:22,209 [foster.py] => Task 3, Epoch 104/170 => Loss 2.802, Loss_clf 0.295, Loss_fe 0.146, Loss_kd 2.275, Train_accy 82.64, Test_accy 78.27
2024-08-02 13:43:25,855 [foster.py] => Task 3, Epoch 105/170 => Loss 2.782, Loss_clf 0.287, Loss_fe 0.131, Loss_kd 2.279, Train_accy 81.49, Test_accy 78.38
2024-08-02 13:43:28,071 [foster.py] => Task 3, Epoch 106/170 => Loss 2.865, Loss_clf 0.328, Loss_fe 0.143, Loss_kd 2.307, Train_accy 82.07
2024-08-02 13:43:31,665 [foster.py] => Task 3, Epoch 107/170 => Loss 2.821, Loss_clf 0.319, Loss_fe 0.138, Loss_kd 2.279, Train_accy 81.06, Test_accy 78.38
2024-08-02 13:43:35,292 [foster.py] => Task 3, Epoch 108/170 => Loss 2.820, Loss_clf 0.303, Loss_fe 0.134, Loss_kd 2.295, Train_accy 81.83, Test_accy 78.25
2024-08-02 13:43:38,902 [foster.py] => Task 3, Epoch 109/170 => Loss 2.815, Loss_clf 0.308, Loss_fe 0.140, Loss_kd 2.282, Train_accy 81.92, Test_accy 78.34
2024-08-02 13:43:42,517 [foster.py] => Task 3, Epoch 110/170 => Loss 2.792, Loss_clf 0.298, Loss_fe 0.133, Loss_kd 2.274, Train_accy 82.45, Test_accy 78.38
2024-08-02 13:43:44,756 [foster.py] => Task 3, Epoch 111/170 => Loss 2.861, Loss_clf 0.319, Loss_fe 0.160, Loss_kd 2.295, Train_accy 83.46
2024-08-02 13:43:48,391 [foster.py] => Task 3, Epoch 112/170 => Loss 2.830, Loss_clf 0.326, Loss_fe 0.130, Loss_kd 2.287, Train_accy 80.00, Test_accy 78.16
2024-08-02 13:43:52,061 [foster.py] => Task 3, Epoch 113/170 => Loss 2.804, Loss_clf 0.301, Loss_fe 0.125, Loss_kd 2.291, Train_accy 82.98, Test_accy 78.20
2024-08-02 13:43:55,680 [foster.py] => Task 3, Epoch 114/170 => Loss 2.756, Loss_clf 0.288, Loss_fe 0.123, Loss_kd 2.260, Train_accy 82.64, Test_accy 78.23
2024-08-02 13:43:59,299 [foster.py] => Task 3, Epoch 115/170 => Loss 2.846, Loss_clf 0.321, Loss_fe 0.152, Loss_kd 2.287, Train_accy 81.78, Test_accy 78.41
2024-08-02 13:44:01,534 [foster.py] => Task 3, Epoch 116/170 => Loss 2.870, Loss_clf 0.338, Loss_fe 0.154, Loss_kd 2.291, Train_accy 82.16
2024-08-02 13:44:05,188 [foster.py] => Task 3, Epoch 117/170 => Loss 2.717, Loss_clf 0.256, Loss_fe 0.127, Loss_kd 2.248, Train_accy 83.94, Test_accy 78.21
2024-08-02 13:44:08,786 [foster.py] => Task 3, Epoch 118/170 => Loss 2.827, Loss_clf 0.313, Loss_fe 0.138, Loss_kd 2.290, Train_accy 83.17, Test_accy 78.11
2024-08-02 13:44:12,386 [foster.py] => Task 3, Epoch 119/170 => Loss 2.807, Loss_clf 0.307, Loss_fe 0.132, Loss_kd 2.283, Train_accy 82.55, Test_accy 78.23
2024-08-02 13:44:16,012 [foster.py] => Task 3, Epoch 120/170 => Loss 2.796, Loss_clf 0.302, Loss_fe 0.122, Loss_kd 2.286, Train_accy 82.26, Test_accy 78.04
2024-08-02 13:44:18,226 [foster.py] => Task 3, Epoch 121/170 => Loss 2.813, Loss_clf 0.300, Loss_fe 0.131, Loss_kd 2.296, Train_accy 82.79
2024-08-02 13:44:21,972 [foster.py] => Task 3, Epoch 122/170 => Loss 2.779, Loss_clf 0.299, Loss_fe 0.119, Loss_kd 2.275, Train_accy 82.55, Test_accy 78.14
2024-08-02 13:44:25,581 [foster.py] => Task 3, Epoch 123/170 => Loss 2.800, Loss_clf 0.303, Loss_fe 0.127, Loss_kd 2.284, Train_accy 83.65, Test_accy 78.18
2024-08-02 13:44:29,201 [foster.py] => Task 3, Epoch 124/170 => Loss 2.797, Loss_clf 0.325, Loss_fe 0.116, Loss_kd 2.269, Train_accy 81.97, Test_accy 78.41
2024-08-02 13:44:32,816 [foster.py] => Task 3, Epoch 125/170 => Loss 2.753, Loss_clf 0.270, Loss_fe 0.119, Loss_kd 2.278, Train_accy 83.99, Test_accy 78.38
2024-08-02 13:44:35,039 [foster.py] => Task 3, Epoch 126/170 => Loss 2.792, Loss_clf 0.314, Loss_fe 0.111, Loss_kd 2.281, Train_accy 80.62
2024-08-02 13:44:38,669 [foster.py] => Task 3, Epoch 127/170 => Loss 2.798, Loss_clf 0.307, Loss_fe 0.117, Loss_kd 2.288, Train_accy 82.21, Test_accy 78.43
2024-08-02 13:44:42,361 [foster.py] => Task 3, Epoch 128/170 => Loss 2.788, Loss_clf 0.295, Loss_fe 0.115, Loss_kd 2.291, Train_accy 83.12, Test_accy 78.46
2024-08-02 13:44:45,981 [foster.py] => Task 3, Epoch 129/170 => Loss 2.818, Loss_clf 0.318, Loss_fe 0.116, Loss_kd 2.297, Train_accy 82.07, Test_accy 78.43
2024-08-02 13:44:49,605 [foster.py] => Task 3, Epoch 130/170 => Loss 2.850, Loss_clf 0.312, Loss_fe 0.131, Loss_kd 2.320, Train_accy 81.39, Test_accy 78.45
2024-08-02 13:44:51,848 [foster.py] => Task 3, Epoch 131/170 => Loss 2.854, Loss_clf 0.344, Loss_fe 0.136, Loss_kd 2.288, Train_accy 82.93
2024-08-02 13:44:55,451 [foster.py] => Task 3, Epoch 132/170 => Loss 2.804, Loss_clf 0.307, Loss_fe 0.118, Loss_kd 2.293, Train_accy 83.12, Test_accy 78.34
2024-08-02 13:44:59,034 [foster.py] => Task 3, Epoch 133/170 => Loss 2.816, Loss_clf 0.317, Loss_fe 0.110, Loss_kd 2.303, Train_accy 81.59, Test_accy 78.45
2024-08-02 13:45:02,630 [foster.py] => Task 3, Epoch 134/170 => Loss 2.810, Loss_clf 0.301, Loss_fe 0.130, Loss_kd 2.293, Train_accy 82.40, Test_accy 78.27
2024-08-02 13:45:06,229 [foster.py] => Task 3, Epoch 135/170 => Loss 2.801, Loss_clf 0.303, Loss_fe 0.120, Loss_kd 2.292, Train_accy 82.50, Test_accy 78.41
2024-08-02 13:45:08,439 [foster.py] => Task 3, Epoch 136/170 => Loss 2.794, Loss_clf 0.320, Loss_fe 0.104, Loss_kd 2.284, Train_accy 81.97
2024-08-02 13:45:12,050 [foster.py] => Task 3, Epoch 137/170 => Loss 2.772, Loss_clf 0.289, Loss_fe 0.113, Loss_kd 2.285, Train_accy 84.09, Test_accy 78.54
2024-08-02 13:45:15,653 [foster.py] => Task 3, Epoch 138/170 => Loss 2.808, Loss_clf 0.308, Loss_fe 0.110, Loss_kd 2.303, Train_accy 82.45, Test_accy 78.34
2024-08-02 13:45:19,261 [foster.py] => Task 3, Epoch 139/170 => Loss 2.726, Loss_clf 0.281, Loss_fe 0.105, Loss_kd 2.255, Train_accy 82.55, Test_accy 78.25
2024-08-02 13:45:22,867 [foster.py] => Task 3, Epoch 140/170 => Loss 2.734, Loss_clf 0.278, Loss_fe 0.098, Loss_kd 2.272, Train_accy 83.12, Test_accy 78.21
2024-08-02 13:45:25,094 [foster.py] => Task 3, Epoch 141/170 => Loss 2.706, Loss_clf 0.270, Loss_fe 0.089, Loss_kd 2.263, Train_accy 83.27
2024-08-02 13:45:28,690 [foster.py] => Task 3, Epoch 142/170 => Loss 2.742, Loss_clf 0.290, Loss_fe 0.110, Loss_kd 2.257, Train_accy 83.51, Test_accy 78.45
2024-08-02 13:45:32,327 [foster.py] => Task 3, Epoch 143/170 => Loss 2.742, Loss_clf 0.282, Loss_fe 0.114, Loss_kd 2.260, Train_accy 82.36, Test_accy 78.50
2024-08-02 13:45:35,946 [foster.py] => Task 3, Epoch 144/170 => Loss 2.746, Loss_clf 0.272, Loss_fe 0.105, Loss_kd 2.282, Train_accy 84.13, Test_accy 78.46
2024-08-02 13:45:39,562 [foster.py] => Task 3, Epoch 145/170 => Loss 2.781, Loss_clf 0.298, Loss_fe 0.101, Loss_kd 2.296, Train_accy 83.46, Test_accy 78.50
2024-08-02 13:45:41,789 [foster.py] => Task 3, Epoch 146/170 => Loss 2.790, Loss_clf 0.296, Loss_fe 0.112, Loss_kd 2.296, Train_accy 83.99
2024-08-02 13:45:45,438 [foster.py] => Task 3, Epoch 147/170 => Loss 2.756, Loss_clf 0.280, Loss_fe 0.113, Loss_kd 2.276, Train_accy 83.75, Test_accy 78.52
2024-08-02 13:45:49,035 [foster.py] => Task 3, Epoch 148/170 => Loss 2.763, Loss_clf 0.287, Loss_fe 0.102, Loss_kd 2.289, Train_accy 83.75, Test_accy 78.45
2024-08-02 13:45:52,652 [foster.py] => Task 3, Epoch 149/170 => Loss 2.772, Loss_clf 0.305, Loss_fe 0.098, Loss_kd 2.283, Train_accy 83.27, Test_accy 78.55
2024-08-02 13:45:56,269 [foster.py] => Task 3, Epoch 150/170 => Loss 2.714, Loss_clf 0.280, Loss_fe 0.098, Loss_kd 2.250, Train_accy 82.21, Test_accy 78.52
2024-08-02 13:45:58,554 [foster.py] => Task 3, Epoch 151/170 => Loss 2.745, Loss_clf 0.284, Loss_fe 0.092, Loss_kd 2.283, Train_accy 83.75
2024-08-02 13:46:02,159 [foster.py] => Task 3, Epoch 152/170 => Loss 2.741, Loss_clf 0.278, Loss_fe 0.101, Loss_kd 2.276, Train_accy 83.94, Test_accy 78.50
2024-08-02 13:46:05,770 [foster.py] => Task 3, Epoch 153/170 => Loss 2.779, Loss_clf 0.295, Loss_fe 0.108, Loss_kd 2.291, Train_accy 83.94, Test_accy 78.45
2024-08-02 13:46:09,368 [foster.py] => Task 3, Epoch 154/170 => Loss 2.752, Loss_clf 0.285, Loss_fe 0.100, Loss_kd 2.282, Train_accy 83.70, Test_accy 78.46
2024-08-02 13:46:12,960 [foster.py] => Task 3, Epoch 155/170 => Loss 2.804, Loss_clf 0.307, Loss_fe 0.114, Loss_kd 2.296, Train_accy 83.12, Test_accy 78.46
2024-08-02 13:46:15,192 [foster.py] => Task 3, Epoch 156/170 => Loss 2.783, Loss_clf 0.283, Loss_fe 0.119, Loss_kd 2.294, Train_accy 83.80
2024-08-02 13:46:18,821 [foster.py] => Task 3, Epoch 157/170 => Loss 2.695, Loss_clf 0.254, Loss_fe 0.085, Loss_kd 2.270, Train_accy 85.00, Test_accy 78.45
2024-08-02 13:46:22,429 [foster.py] => Task 3, Epoch 158/170 => Loss 2.799, Loss_clf 0.319, Loss_fe 0.103, Loss_kd 2.292, Train_accy 82.79, Test_accy 78.39
2024-08-02 13:46:26,046 [foster.py] => Task 3, Epoch 159/170 => Loss 2.752, Loss_clf 0.267, Loss_fe 0.109, Loss_kd 2.290, Train_accy 84.52, Test_accy 78.46
2024-08-02 13:46:29,670 [foster.py] => Task 3, Epoch 160/170 => Loss 2.754, Loss_clf 0.289, Loss_fe 0.108, Loss_kd 2.272, Train_accy 83.03, Test_accy 78.48
2024-08-02 13:46:31,901 [foster.py] => Task 3, Epoch 161/170 => Loss 2.808, Loss_clf 0.300, Loss_fe 0.123, Loss_kd 2.299, Train_accy 83.46
2024-08-02 13:46:35,513 [foster.py] => Task 3, Epoch 162/170 => Loss 2.787, Loss_clf 0.304, Loss_fe 0.105, Loss_kd 2.291, Train_accy 82.12, Test_accy 78.34
2024-08-02 13:46:39,157 [foster.py] => Task 3, Epoch 163/170 => Loss 2.769, Loss_clf 0.287, Loss_fe 0.117, Loss_kd 2.280, Train_accy 83.22, Test_accy 78.48
2024-08-02 13:46:42,785 [foster.py] => Task 3, Epoch 164/170 => Loss 2.819, Loss_clf 0.326, Loss_fe 0.116, Loss_kd 2.290, Train_accy 83.17, Test_accy 78.45
2024-08-02 13:46:46,380 [foster.py] => Task 3, Epoch 165/170 => Loss 2.745, Loss_clf 0.277, Loss_fe 0.096, Loss_kd 2.285, Train_accy 83.17, Test_accy 78.45
2024-08-02 13:46:48,696 [foster.py] => Task 3, Epoch 166/170 => Loss 2.769, Loss_clf 0.297, Loss_fe 0.098, Loss_kd 2.288, Train_accy 84.13
2024-08-02 13:46:52,429 [foster.py] => Task 3, Epoch 167/170 => Loss 2.721, Loss_clf 0.282, Loss_fe 0.103, Loss_kd 2.251, Train_accy 83.12, Test_accy 78.48
2024-08-02 13:46:56,106 [foster.py] => Task 3, Epoch 168/170 => Loss 2.810, Loss_clf 0.318, Loss_fe 0.103, Loss_kd 2.302, Train_accy 83.12, Test_accy 78.45
2024-08-02 13:46:59,800 [foster.py] => Task 3, Epoch 169/170 => Loss 2.713, Loss_clf 0.265, Loss_fe 0.086, Loss_kd 2.276, Train_accy 84.18, Test_accy 78.46
2024-08-02 13:47:03,487 [foster.py] => Task 3, Epoch 170/170 => Loss 2.764, Loss_clf 0.296, Loss_fe 0.110, Loss_kd 2.273, Train_accy 82.07, Test_accy 78.45
2024-08-02 13:47:03,489 [foster.py] => do not weight align teacher!
2024-08-02 13:47:03,491 [foster.py] => per cls weights : [1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433
 1.0195433 1.0195433 1.0195433 1.0195433 1.0195433 0.472331  0.472331 ]
2024-08-02 13:47:07,962 [foster.py] => SNet: Task 3, Epoch 1/130 => Loss 27.605,  Loss1 0.694, Train_accy 42.98, Test_accy 74.27
2024-08-02 13:47:11,012 [foster.py] => SNet: Task 3, Epoch 2/130 => Loss 27.409,  Loss1 0.690, Train_accy 52.55
2024-08-02 13:47:14,075 [foster.py] => SNet: Task 3, Epoch 3/130 => Loss 27.456,  Loss1 0.690, Train_accy 56.97
2024-08-02 13:47:17,120 [foster.py] => SNet: Task 3, Epoch 4/130 => Loss 27.436,  Loss1 0.689, Train_accy 55.43
2024-08-02 13:47:20,190 [foster.py] => SNet: Task 3, Epoch 5/130 => Loss 27.386,  Loss1 0.688, Train_accy 55.87
2024-08-02 13:47:24,153 [foster.py] => SNet: Task 3, Epoch 6/130 => Loss 27.393,  Loss1 0.688, Train_accy 57.31, Test_accy 76.77
2024-08-02 13:47:27,192 [foster.py] => SNet: Task 3, Epoch 7/130 => Loss 27.434,  Loss1 0.688, Train_accy 58.65
2024-08-02 13:47:30,254 [foster.py] => SNet: Task 3, Epoch 8/130 => Loss 27.371,  Loss1 0.688, Train_accy 59.62
2024-08-02 13:47:33,322 [foster.py] => SNet: Task 3, Epoch 9/130 => Loss 27.373,  Loss1 0.688, Train_accy 60.48
2024-08-02 13:47:36,357 [foster.py] => SNet: Task 3, Epoch 10/130 => Loss 27.382,  Loss1 0.689, Train_accy 61.39
2024-08-02 13:47:40,323 [foster.py] => SNet: Task 3, Epoch 11/130 => Loss 27.452,  Loss1 0.688, Train_accy 61.73, Test_accy 76.70
2024-08-02 13:47:43,373 [foster.py] => SNet: Task 3, Epoch 12/130 => Loss 27.349,  Loss1 0.688, Train_accy 62.12
2024-08-02 13:47:46,472 [foster.py] => SNet: Task 3, Epoch 13/130 => Loss 27.396,  Loss1 0.687, Train_accy 61.88
2024-08-02 13:47:49,545 [foster.py] => SNet: Task 3, Epoch 14/130 => Loss 27.363,  Loss1 0.688, Train_accy 60.91
2024-08-02 13:47:52,588 [foster.py] => SNet: Task 3, Epoch 15/130 => Loss 27.415,  Loss1 0.688, Train_accy 62.69
2024-08-02 13:47:56,546 [foster.py] => SNet: Task 3, Epoch 16/130 => Loss 27.353,  Loss1 0.687, Train_accy 62.79, Test_accy 77.52
2024-08-02 13:47:59,601 [foster.py] => SNet: Task 3, Epoch 17/130 => Loss 27.352,  Loss1 0.687, Train_accy 63.22
2024-08-02 13:48:02,662 [foster.py] => SNet: Task 3, Epoch 18/130 => Loss 27.349,  Loss1 0.687, Train_accy 63.89
2024-08-02 13:48:05,705 [foster.py] => SNet: Task 3, Epoch 19/130 => Loss 27.380,  Loss1 0.687, Train_accy 62.98
2024-08-02 13:48:08,760 [foster.py] => SNet: Task 3, Epoch 20/130 => Loss 27.414,  Loss1 0.687, Train_accy 64.81
2024-08-02 13:48:12,784 [foster.py] => SNet: Task 3, Epoch 21/130 => Loss 27.389,  Loss1 0.687, Train_accy 64.76, Test_accy 77.07
2024-08-02 13:48:15,844 [foster.py] => SNet: Task 3, Epoch 22/130 => Loss 27.404,  Loss1 0.687, Train_accy 65.77
2024-08-02 13:48:18,900 [foster.py] => SNet: Task 3, Epoch 23/130 => Loss 27.366,  Loss1 0.687, Train_accy 65.72
2024-08-02 13:48:21,954 [foster.py] => SNet: Task 3, Epoch 24/130 => Loss 27.364,  Loss1 0.687, Train_accy 66.11
2024-08-02 13:48:25,017 [foster.py] => SNet: Task 3, Epoch 25/130 => Loss 27.377,  Loss1 0.687, Train_accy 66.83
2024-08-02 13:48:29,014 [foster.py] => SNet: Task 3, Epoch 26/130 => Loss 27.395,  Loss1 0.688, Train_accy 66.44, Test_accy 77.29
2024-08-02 13:48:32,062 [foster.py] => SNet: Task 3, Epoch 27/130 => Loss 27.326,  Loss1 0.687, Train_accy 65.10
2024-08-02 13:48:35,113 [foster.py] => SNet: Task 3, Epoch 28/130 => Loss 27.409,  Loss1 0.688, Train_accy 66.30
2024-08-02 13:48:38,184 [foster.py] => SNet: Task 3, Epoch 29/130 => Loss 27.393,  Loss1 0.687, Train_accy 65.82
2024-08-02 13:48:41,276 [foster.py] => SNet: Task 3, Epoch 30/130 => Loss 27.369,  Loss1 0.687, Train_accy 66.15
2024-08-02 13:48:45,239 [foster.py] => SNet: Task 3, Epoch 31/130 => Loss 27.392,  Loss1 0.687, Train_accy 66.35, Test_accy 77.39
2024-08-02 13:48:48,279 [foster.py] => SNet: Task 3, Epoch 32/130 => Loss 27.407,  Loss1 0.687, Train_accy 67.21
2024-08-02 13:48:51,344 [foster.py] => SNet: Task 3, Epoch 33/130 => Loss 27.373,  Loss1 0.687, Train_accy 65.96
2024-08-02 13:48:54,380 [foster.py] => SNet: Task 3, Epoch 34/130 => Loss 27.393,  Loss1 0.687, Train_accy 66.88
2024-08-02 13:48:57,422 [foster.py] => SNet: Task 3, Epoch 35/130 => Loss 27.382,  Loss1 0.687, Train_accy 66.73
2024-08-02 13:49:01,390 [foster.py] => SNet: Task 3, Epoch 36/130 => Loss 27.404,  Loss1 0.687, Train_accy 67.93, Test_accy 77.50
2024-08-02 13:49:04,462 [foster.py] => SNet: Task 3, Epoch 37/130 => Loss 27.404,  Loss1 0.687, Train_accy 67.93
2024-08-02 13:49:07,527 [foster.py] => SNet: Task 3, Epoch 38/130 => Loss 27.351,  Loss1 0.687, Train_accy 66.92
2024-08-02 13:49:10,564 [foster.py] => SNet: Task 3, Epoch 39/130 => Loss 27.348,  Loss1 0.687, Train_accy 68.41
2024-08-02 13:49:13,617 [foster.py] => SNet: Task 3, Epoch 40/130 => Loss 27.369,  Loss1 0.687, Train_accy 68.22
2024-08-02 13:49:17,620 [foster.py] => SNet: Task 3, Epoch 41/130 => Loss 27.395,  Loss1 0.686, Train_accy 67.21, Test_accy 77.48
2024-08-02 13:49:20,678 [foster.py] => SNet: Task 3, Epoch 42/130 => Loss 27.357,  Loss1 0.687, Train_accy 67.79
2024-08-02 13:49:23,719 [foster.py] => SNet: Task 3, Epoch 43/130 => Loss 27.325,  Loss1 0.687, Train_accy 67.21
2024-08-02 13:49:26,783 [foster.py] => SNet: Task 3, Epoch 44/130 => Loss 27.397,  Loss1 0.688, Train_accy 67.40
2024-08-02 13:49:29,847 [foster.py] => SNet: Task 3, Epoch 45/130 => Loss 27.376,  Loss1 0.687, Train_accy 68.46
2024-08-02 13:49:33,848 [foster.py] => SNet: Task 3, Epoch 46/130 => Loss 27.351,  Loss1 0.687, Train_accy 68.17, Test_accy 77.43
2024-08-02 13:49:36,902 [foster.py] => SNet: Task 3, Epoch 47/130 => Loss 27.412,  Loss1 0.687, Train_accy 67.93
2024-08-02 13:49:39,964 [foster.py] => SNet: Task 3, Epoch 48/130 => Loss 27.382,  Loss1 0.686, Train_accy 68.37
2024-08-02 13:49:43,008 [foster.py] => SNet: Task 3, Epoch 49/130 => Loss 27.391,  Loss1 0.687, Train_accy 66.83
2024-08-02 13:49:46,058 [foster.py] => SNet: Task 3, Epoch 50/130 => Loss 27.349,  Loss1 0.687, Train_accy 68.75
2024-08-02 13:49:50,017 [foster.py] => SNet: Task 3, Epoch 51/130 => Loss 27.340,  Loss1 0.687, Train_accy 67.88, Test_accy 77.82
2024-08-02 13:49:53,077 [foster.py] => SNet: Task 3, Epoch 52/130 => Loss 27.388,  Loss1 0.687, Train_accy 67.98
2024-08-02 13:49:56,157 [foster.py] => SNet: Task 3, Epoch 53/130 => Loss 27.414,  Loss1 0.687, Train_accy 69.38
2024-08-02 13:49:59,193 [foster.py] => SNet: Task 3, Epoch 54/130 => Loss 27.343,  Loss1 0.687, Train_accy 68.70
2024-08-02 13:50:02,245 [foster.py] => SNet: Task 3, Epoch 55/130 => Loss 27.391,  Loss1 0.687, Train_accy 67.93
2024-08-02 13:50:06,224 [foster.py] => SNet: Task 3, Epoch 56/130 => Loss 27.389,  Loss1 0.687, Train_accy 68.89, Test_accy 77.54
2024-08-02 13:50:09,282 [foster.py] => SNet: Task 3, Epoch 57/130 => Loss 27.353,  Loss1 0.687, Train_accy 70.10
2024-08-02 13:50:12,348 [foster.py] => SNet: Task 3, Epoch 58/130 => Loss 27.295,  Loss1 0.687, Train_accy 67.50
2024-08-02 13:50:15,409 [foster.py] => SNet: Task 3, Epoch 59/130 => Loss 27.347,  Loss1 0.687, Train_accy 68.08
2024-08-02 13:50:18,464 [foster.py] => SNet: Task 3, Epoch 60/130 => Loss 27.382,  Loss1 0.687, Train_accy 69.52
2024-08-02 13:50:22,457 [foster.py] => SNet: Task 3, Epoch 61/130 => Loss 27.403,  Loss1 0.687, Train_accy 68.65, Test_accy 77.50
2024-08-02 13:50:25,551 [foster.py] => SNet: Task 3, Epoch 62/130 => Loss 27.406,  Loss1 0.687, Train_accy 67.64
2024-08-02 13:50:28,600 [foster.py] => SNet: Task 3, Epoch 63/130 => Loss 27.354,  Loss1 0.686, Train_accy 68.99
2024-08-02 13:50:31,679 [foster.py] => SNet: Task 3, Epoch 64/130 => Loss 27.352,  Loss1 0.687, Train_accy 68.41
2024-08-02 13:50:34,742 [foster.py] => SNet: Task 3, Epoch 65/130 => Loss 27.360,  Loss1 0.687, Train_accy 68.94
2024-08-02 13:50:38,695 [foster.py] => SNet: Task 3, Epoch 66/130 => Loss 27.341,  Loss1 0.687, Train_accy 69.42, Test_accy 77.21
2024-08-02 13:50:41,741 [foster.py] => SNet: Task 3, Epoch 67/130 => Loss 27.309,  Loss1 0.687, Train_accy 67.12
2024-08-02 13:50:44,776 [foster.py] => SNet: Task 3, Epoch 68/130 => Loss 27.327,  Loss1 0.687, Train_accy 68.41
2024-08-02 13:50:47,831 [foster.py] => SNet: Task 3, Epoch 69/130 => Loss 27.315,  Loss1 0.687, Train_accy 68.80
2024-08-02 13:50:50,933 [foster.py] => SNet: Task 3, Epoch 70/130 => Loss 27.398,  Loss1 0.687, Train_accy 69.13
2024-08-02 13:50:54,889 [foster.py] => SNet: Task 3, Epoch 71/130 => Loss 27.350,  Loss1 0.687, Train_accy 69.33, Test_accy 77.61
2024-08-02 13:50:57,943 [foster.py] => SNet: Task 3, Epoch 72/130 => Loss 27.346,  Loss1 0.687, Train_accy 69.86
2024-08-02 13:51:01,007 [foster.py] => SNet: Task 3, Epoch 73/130 => Loss 27.412,  Loss1 0.687, Train_accy 67.84
2024-08-02 13:51:04,057 [foster.py] => SNet: Task 3, Epoch 74/130 => Loss 27.364,  Loss1 0.686, Train_accy 70.00
2024-08-02 13:51:07,138 [foster.py] => SNet: Task 3, Epoch 75/130 => Loss 27.394,  Loss1 0.687, Train_accy 68.51
2024-08-02 13:51:11,101 [foster.py] => SNet: Task 3, Epoch 76/130 => Loss 27.391,  Loss1 0.686, Train_accy 70.10, Test_accy 77.59
2024-08-02 13:51:14,142 [foster.py] => SNet: Task 3, Epoch 77/130 => Loss 27.373,  Loss1 0.687, Train_accy 68.32
2024-08-02 13:51:17,195 [foster.py] => SNet: Task 3, Epoch 78/130 => Loss 27.371,  Loss1 0.687, Train_accy 70.29
2024-08-02 13:51:20,250 [foster.py] => SNet: Task 3, Epoch 79/130 => Loss 27.320,  Loss1 0.688, Train_accy 69.38
2024-08-02 13:51:23,307 [foster.py] => SNet: Task 3, Epoch 80/130 => Loss 27.374,  Loss1 0.687, Train_accy 68.08
2024-08-02 13:51:27,287 [foster.py] => SNet: Task 3, Epoch 81/130 => Loss 27.326,  Loss1 0.687, Train_accy 69.62, Test_accy 77.36
2024-08-02 13:51:30,383 [foster.py] => SNet: Task 3, Epoch 82/130 => Loss 27.309,  Loss1 0.687, Train_accy 69.86
2024-08-02 13:51:33,433 [foster.py] => SNet: Task 3, Epoch 83/130 => Loss 27.373,  Loss1 0.687, Train_accy 68.65
2024-08-02 13:51:36,502 [foster.py] => SNet: Task 3, Epoch 84/130 => Loss 27.416,  Loss1 0.687, Train_accy 69.42
2024-08-02 13:51:39,576 [foster.py] => SNet: Task 3, Epoch 85/130 => Loss 27.324,  Loss1 0.687, Train_accy 71.97
2024-08-02 13:51:43,557 [foster.py] => SNet: Task 3, Epoch 86/130 => Loss 27.361,  Loss1 0.687, Train_accy 69.23, Test_accy 77.75
2024-08-02 13:51:46,617 [foster.py] => SNet: Task 3, Epoch 87/130 => Loss 27.347,  Loss1 0.687, Train_accy 70.10
2024-08-02 13:51:49,664 [foster.py] => SNet: Task 3, Epoch 88/130 => Loss 27.338,  Loss1 0.687, Train_accy 69.90
2024-08-02 13:51:52,719 [foster.py] => SNet: Task 3, Epoch 89/130 => Loss 27.355,  Loss1 0.687, Train_accy 70.38
2024-08-02 13:51:55,784 [foster.py] => SNet: Task 3, Epoch 90/130 => Loss 27.366,  Loss1 0.687, Train_accy 68.17
2024-08-02 13:51:59,769 [foster.py] => SNet: Task 3, Epoch 91/130 => Loss 27.376,  Loss1 0.687, Train_accy 69.04, Test_accy 77.66
2024-08-02 13:52:02,847 [foster.py] => SNet: Task 3, Epoch 92/130 => Loss 27.380,  Loss1 0.687, Train_accy 68.89
2024-08-02 13:52:05,925 [foster.py] => SNet: Task 3, Epoch 93/130 => Loss 27.315,  Loss1 0.686, Train_accy 68.80
2024-08-02 13:52:08,974 [foster.py] => SNet: Task 3, Epoch 94/130 => Loss 27.398,  Loss1 0.686, Train_accy 68.22
2024-08-02 13:52:12,028 [foster.py] => SNet: Task 3, Epoch 95/130 => Loss 27.376,  Loss1 0.687, Train_accy 70.24
2024-08-02 13:52:16,029 [foster.py] => SNet: Task 3, Epoch 96/130 => Loss 27.389,  Loss1 0.686, Train_accy 67.79, Test_accy 77.54
2024-08-02 13:52:19,094 [foster.py] => SNet: Task 3, Epoch 97/130 => Loss 27.320,  Loss1 0.687, Train_accy 70.48
2024-08-02 13:52:22,162 [foster.py] => SNet: Task 3, Epoch 98/130 => Loss 27.345,  Loss1 0.687, Train_accy 69.33
2024-08-02 13:52:25,215 [foster.py] => SNet: Task 3, Epoch 99/130 => Loss 27.358,  Loss1 0.687, Train_accy 69.38
2024-08-02 13:52:28,295 [foster.py] => SNet: Task 3, Epoch 100/130 => Loss 27.333,  Loss1 0.687, Train_accy 69.42
2024-08-02 13:52:32,238 [foster.py] => SNet: Task 3, Epoch 101/130 => Loss 27.340,  Loss1 0.686, Train_accy 67.50, Test_accy 77.73
2024-08-02 13:52:35,299 [foster.py] => SNet: Task 3, Epoch 102/130 => Loss 27.368,  Loss1 0.687, Train_accy 68.94
2024-08-02 13:52:38,403 [foster.py] => SNet: Task 3, Epoch 103/130 => Loss 27.360,  Loss1 0.687, Train_accy 68.70
2024-08-02 13:52:41,478 [foster.py] => SNet: Task 3, Epoch 104/130 => Loss 27.342,  Loss1 0.687, Train_accy 69.52
2024-08-02 13:52:44,536 [foster.py] => SNet: Task 3, Epoch 105/130 => Loss 27.370,  Loss1 0.687, Train_accy 68.80
2024-08-02 13:52:48,550 [foster.py] => SNet: Task 3, Epoch 106/130 => Loss 27.359,  Loss1 0.687, Train_accy 69.76, Test_accy 77.77
2024-08-02 13:52:51,596 [foster.py] => SNet: Task 3, Epoch 107/130 => Loss 27.403,  Loss1 0.687, Train_accy 67.45
2024-08-02 13:52:54,646 [foster.py] => SNet: Task 3, Epoch 108/130 => Loss 27.378,  Loss1 0.687, Train_accy 69.76
2024-08-02 13:52:57,741 [foster.py] => SNet: Task 3, Epoch 109/130 => Loss 27.349,  Loss1 0.687, Train_accy 70.38
2024-08-02 13:53:00,783 [foster.py] => SNet: Task 3, Epoch 110/130 => Loss 27.347,  Loss1 0.686, Train_accy 69.52
2024-08-02 13:53:04,760 [foster.py] => SNet: Task 3, Epoch 111/130 => Loss 27.395,  Loss1 0.687, Train_accy 69.42, Test_accy 77.64
2024-08-02 13:53:07,816 [foster.py] => SNet: Task 3, Epoch 112/130 => Loss 27.345,  Loss1 0.687, Train_accy 71.15
2024-08-02 13:53:10,901 [foster.py] => SNet: Task 3, Epoch 113/130 => Loss 27.394,  Loss1 0.686, Train_accy 68.89
2024-08-02 13:53:13,956 [foster.py] => SNet: Task 3, Epoch 114/130 => Loss 27.362,  Loss1 0.687, Train_accy 68.99
2024-08-02 13:53:17,014 [foster.py] => SNet: Task 3, Epoch 115/130 => Loss 27.346,  Loss1 0.687, Train_accy 70.00
2024-08-02 13:53:21,001 [foster.py] => SNet: Task 3, Epoch 116/130 => Loss 27.376,  Loss1 0.686, Train_accy 68.32, Test_accy 77.75
2024-08-02 13:53:24,064 [foster.py] => SNet: Task 3, Epoch 117/130 => Loss 27.297,  Loss1 0.687, Train_accy 70.10
2024-08-02 13:53:27,123 [foster.py] => SNet: Task 3, Epoch 118/130 => Loss 27.295,  Loss1 0.687, Train_accy 67.98
2024-08-02 13:53:30,194 [foster.py] => SNet: Task 3, Epoch 119/130 => Loss 27.342,  Loss1 0.687, Train_accy 70.72
2024-08-02 13:53:33,241 [foster.py] => SNet: Task 3, Epoch 120/130 => Loss 27.346,  Loss1 0.687, Train_accy 69.09
2024-08-02 13:53:37,180 [foster.py] => SNet: Task 3, Epoch 121/130 => Loss 27.350,  Loss1 0.686, Train_accy 70.43, Test_accy 77.39
2024-08-02 13:53:40,214 [foster.py] => SNet: Task 3, Epoch 122/130 => Loss 27.391,  Loss1 0.687, Train_accy 69.13
2024-08-02 13:53:43,287 [foster.py] => SNet: Task 3, Epoch 123/130 => Loss 27.296,  Loss1 0.687, Train_accy 68.80
2024-08-02 13:53:46,388 [foster.py] => SNet: Task 3, Epoch 124/130 => Loss 27.406,  Loss1 0.687, Train_accy 70.14
2024-08-02 13:53:49,422 [foster.py] => SNet: Task 3, Epoch 125/130 => Loss 27.329,  Loss1 0.686, Train_accy 69.42
2024-08-02 13:53:53,371 [foster.py] => SNet: Task 3, Epoch 126/130 => Loss 27.289,  Loss1 0.687, Train_accy 69.95, Test_accy 77.50
2024-08-02 13:53:56,447 [foster.py] => SNet: Task 3, Epoch 127/130 => Loss 27.342,  Loss1 0.686, Train_accy 69.33
2024-08-02 13:53:59,481 [foster.py] => SNet: Task 3, Epoch 128/130 => Loss 27.360,  Loss1 0.687, Train_accy 69.38
2024-08-02 13:54:02,535 [foster.py] => SNet: Task 3, Epoch 129/130 => Loss 27.433,  Loss1 0.686, Train_accy 69.52
2024-08-02 13:54:05,596 [foster.py] => SNet: Task 3, Epoch 130/130 => Loss 27.327,  Loss1 0.687, Train_accy 70.19
2024-08-02 13:54:05,597 [foster.py] => do not weight align student!
2024-08-02 13:54:06,511 [foster.py] => darknet eval: 
2024-08-02 13:54:06,511 [foster.py] => CNN top1 curve: 77.8
2024-08-02 13:54:06,512 [foster.py] => CNN top5 curve: 96.21
2024-08-02 13:54:06,512 [foster.py] => CNN top1 平均值: 77.80
2024-08-02 13:54:06,516 [foster.py] => timees : 992.1883261203766
2024-08-02 13:54:06,518 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 13:54:23,574 [foster.py] => Exemplar size: 1120
2024-08-02 13:54:23,574 [trainer.py] => CNN: {'total': 78.45, '00-09': 83.5, '10-19': 75.2, '20-29': 82.3, '30-39': 76.2, '40-49': 80.6, '50-59': 69.17, 'old': 78.74, 'new': 70.5}
2024-08-02 13:54:23,574 [trainer.py] => NME: {'total': 74.91, '00-09': 77.6, '10-19': 70.9, '20-29': 79.5, '30-39': 71.8, '40-49': 74.5, '50-59': 75.33, 'old': 74.2, 'new': 94.0}
2024-08-02 13:54:23,574 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45]
2024-08-02 13:54:23,574 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46]
2024-08-02 13:54:23,574 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91]
2024-08-02 13:54:23,574 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54]

2024-08-02 13:54:23,574 [trainer.py] => CNN top1 平均值: 80.05
2024-08-02 13:54:23,577 [trainer.py] => All params: 1168922
2024-08-02 13:54:23,579 [trainer.py] => Trainable params: 588138
2024-08-02 13:54:23,639 [foster.py] => Learning on 56-58
2024-08-02 13:54:23,642 [foster.py] => All params: 1169440
2024-08-02 13:54:23,645 [foster.py] => Trainable params: 588526
2024-08-02 13:54:23,681 [foster.py] => per cls weights : [1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433 1.01586433
 1.01586433 1.01586433 0.55579878 0.55579878]
2024-08-02 13:54:26,040 [foster.py] => Task 4, Epoch 1/170 => Loss 5.673, Loss_clf 1.299, Loss_fe 1.821, Loss_kd 2.464, Train_accy 61.56
2024-08-02 13:54:29,675 [foster.py] => Task 4, Epoch 2/170 => Loss 4.072, Loss_clf 0.699, Loss_fe 0.866, Loss_kd 2.419, Train_accy 67.97, Test_accy 74.97
2024-08-02 13:54:33,383 [foster.py] => Task 4, Epoch 3/170 => Loss 3.834, Loss_clf 0.583, Loss_fe 0.743, Loss_kd 2.420, Train_accy 64.95, Test_accy 76.00
2024-08-02 13:54:37,027 [foster.py] => Task 4, Epoch 4/170 => Loss 3.666, Loss_clf 0.524, Loss_fe 0.633, Loss_kd 2.421, Train_accy 67.88, Test_accy 76.16
2024-08-02 13:54:40,694 [foster.py] => Task 4, Epoch 5/170 => Loss 3.656, Loss_clf 0.539, Loss_fe 0.597, Loss_kd 2.432, Train_accy 67.97, Test_accy 76.31
2024-08-02 13:54:43,011 [foster.py] => Task 4, Epoch 6/170 => Loss 3.532, Loss_clf 0.493, Loss_fe 0.545, Loss_kd 2.406, Train_accy 67.26
2024-08-02 13:54:46,693 [foster.py] => Task 4, Epoch 7/170 => Loss 3.534, Loss_clf 0.503, Loss_fe 0.525, Loss_kd 2.417, Train_accy 69.58, Test_accy 76.90
2024-08-02 13:54:50,428 [foster.py] => Task 4, Epoch 8/170 => Loss 3.535, Loss_clf 0.477, Loss_fe 0.527, Loss_kd 2.442, Train_accy 70.47, Test_accy 76.31
2024-08-02 13:54:54,091 [foster.py] => Task 4, Epoch 9/170 => Loss 3.492, Loss_clf 0.490, Loss_fe 0.488, Loss_kd 2.425, Train_accy 70.38, Test_accy 76.71
2024-08-02 13:54:57,734 [foster.py] => Task 4, Epoch 10/170 => Loss 3.433, Loss_clf 0.468, Loss_fe 0.464, Loss_kd 2.413, Train_accy 70.42, Test_accy 76.62
2024-08-02 13:54:59,980 [foster.py] => Task 4, Epoch 11/170 => Loss 3.411, Loss_clf 0.465, Loss_fe 0.443, Loss_kd 2.416, Train_accy 73.02
2024-08-02 13:55:03,636 [foster.py] => Task 4, Epoch 12/170 => Loss 3.404, Loss_clf 0.473, Loss_fe 0.419, Loss_kd 2.424, Train_accy 71.13, Test_accy 77.31
2024-08-02 13:55:07,380 [foster.py] => Task 4, Epoch 13/170 => Loss 3.423, Loss_clf 0.493, Loss_fe 0.418, Loss_kd 2.424, Train_accy 73.44, Test_accy 76.95
2024-08-02 13:55:11,036 [foster.py] => Task 4, Epoch 14/170 => Loss 3.348, Loss_clf 0.454, Loss_fe 0.411, Loss_kd 2.396, Train_accy 72.88, Test_accy 76.50
2024-08-02 13:55:14,695 [foster.py] => Task 4, Epoch 15/170 => Loss 3.357, Loss_clf 0.463, Loss_fe 0.396, Loss_kd 2.409, Train_accy 73.82, Test_accy 77.12
2024-08-02 13:55:16,908 [foster.py] => Task 4, Epoch 16/170 => Loss 3.355, Loss_clf 0.437, Loss_fe 0.407, Loss_kd 2.423, Train_accy 74.67
2024-08-02 13:55:20,565 [foster.py] => Task 4, Epoch 17/170 => Loss 3.371, Loss_clf 0.450, Loss_fe 0.406, Loss_kd 2.426, Train_accy 74.29, Test_accy 76.93
2024-08-02 13:55:24,216 [foster.py] => Task 4, Epoch 18/170 => Loss 3.390, Loss_clf 0.446, Loss_fe 0.425, Loss_kd 2.432, Train_accy 75.75, Test_accy 76.40
2024-08-02 13:55:27,839 [foster.py] => Task 4, Epoch 19/170 => Loss 3.296, Loss_clf 0.440, Loss_fe 0.359, Loss_kd 2.408, Train_accy 75.80, Test_accy 76.19
2024-08-02 13:55:31,493 [foster.py] => Task 4, Epoch 20/170 => Loss 3.336, Loss_clf 0.440, Loss_fe 0.381, Loss_kd 2.427, Train_accy 73.49, Test_accy 76.86
2024-08-02 13:55:33,773 [foster.py] => Task 4, Epoch 21/170 => Loss 3.345, Loss_clf 0.455, Loss_fe 0.363, Loss_kd 2.438, Train_accy 76.37
2024-08-02 13:55:37,475 [foster.py] => Task 4, Epoch 22/170 => Loss 3.261, Loss_clf 0.404, Loss_fe 0.373, Loss_kd 2.396, Train_accy 77.97, Test_accy 76.17
2024-08-02 13:55:41,197 [foster.py] => Task 4, Epoch 23/170 => Loss 3.314, Loss_clf 0.445, Loss_fe 0.353, Loss_kd 2.429, Train_accy 75.42, Test_accy 77.09
2024-08-02 13:55:44,886 [foster.py] => Task 4, Epoch 24/170 => Loss 3.252, Loss_clf 0.406, Loss_fe 0.356, Loss_kd 2.402, Train_accy 77.03, Test_accy 76.47
2024-08-02 13:55:48,529 [foster.py] => Task 4, Epoch 25/170 => Loss 3.214, Loss_clf 0.395, Loss_fe 0.336, Loss_kd 2.395, Train_accy 77.88, Test_accy 76.45
2024-08-02 13:55:50,772 [foster.py] => Task 4, Epoch 26/170 => Loss 3.239, Loss_clf 0.414, Loss_fe 0.339, Loss_kd 2.400, Train_accy 77.26
2024-08-02 13:55:54,412 [foster.py] => Task 4, Epoch 27/170 => Loss 3.236, Loss_clf 0.406, Loss_fe 0.334, Loss_kd 2.409, Train_accy 77.12, Test_accy 77.14
2024-08-02 13:55:58,133 [foster.py] => Task 4, Epoch 28/170 => Loss 3.238, Loss_clf 0.397, Loss_fe 0.341, Loss_kd 2.412, Train_accy 78.68, Test_accy 77.07
2024-08-02 13:56:01,802 [foster.py] => Task 4, Epoch 29/170 => Loss 3.284, Loss_clf 0.444, Loss_fe 0.324, Loss_kd 2.427, Train_accy 77.69, Test_accy 76.50
2024-08-02 13:56:05,464 [foster.py] => Task 4, Epoch 30/170 => Loss 3.250, Loss_clf 0.414, Loss_fe 0.335, Loss_kd 2.414, Train_accy 77.31, Test_accy 77.07
2024-08-02 13:56:07,684 [foster.py] => Task 4, Epoch 31/170 => Loss 3.187, Loss_clf 0.385, Loss_fe 0.311, Loss_kd 2.404, Train_accy 77.88
2024-08-02 13:56:11,323 [foster.py] => Task 4, Epoch 32/170 => Loss 3.261, Loss_clf 0.427, Loss_fe 0.294, Loss_kd 2.451, Train_accy 76.51, Test_accy 77.31
2024-08-02 13:56:15,022 [foster.py] => Task 4, Epoch 33/170 => Loss 3.228, Loss_clf 0.415, Loss_fe 0.314, Loss_kd 2.411, Train_accy 78.40, Test_accy 76.98
2024-08-02 13:56:18,690 [foster.py] => Task 4, Epoch 34/170 => Loss 3.241, Loss_clf 0.413, Loss_fe 0.308, Loss_kd 2.431, Train_accy 79.29, Test_accy 76.79
2024-08-02 13:56:22,428 [foster.py] => Task 4, Epoch 35/170 => Loss 3.284, Loss_clf 0.452, Loss_fe 0.317, Loss_kd 2.428, Train_accy 76.42, Test_accy 77.14
2024-08-02 13:56:24,728 [foster.py] => Task 4, Epoch 36/170 => Loss 3.233, Loss_clf 0.408, Loss_fe 0.301, Loss_kd 2.436, Train_accy 79.29
2024-08-02 13:56:28,393 [foster.py] => Task 4, Epoch 37/170 => Loss 3.179, Loss_clf 0.380, Loss_fe 0.296, Loss_kd 2.414, Train_accy 79.06, Test_accy 76.91
2024-08-02 13:56:32,079 [foster.py] => Task 4, Epoch 38/170 => Loss 3.162, Loss_clf 0.381, Loss_fe 0.287, Loss_kd 2.406, Train_accy 78.82, Test_accy 76.88
2024-08-02 13:56:35,717 [foster.py] => Task 4, Epoch 39/170 => Loss 3.223, Loss_clf 0.400, Loss_fe 0.319, Loss_kd 2.416, Train_accy 78.87, Test_accy 76.79
2024-08-02 13:56:39,545 [foster.py] => Task 4, Epoch 40/170 => Loss 3.205, Loss_clf 0.392, Loss_fe 0.278, Loss_kd 2.447, Train_accy 79.15, Test_accy 76.79
2024-08-02 13:56:41,927 [foster.py] => Task 4, Epoch 41/170 => Loss 3.220, Loss_clf 0.413, Loss_fe 0.299, Loss_kd 2.420, Train_accy 79.91
2024-08-02 13:56:45,660 [foster.py] => Task 4, Epoch 42/170 => Loss 3.197, Loss_clf 0.416, Loss_fe 0.285, Loss_kd 2.409, Train_accy 78.73, Test_accy 76.76
2024-08-02 13:56:49,313 [foster.py] => Task 4, Epoch 43/170 => Loss 3.215, Loss_clf 0.416, Loss_fe 0.281, Loss_kd 2.430, Train_accy 78.40, Test_accy 77.24
2024-08-02 13:56:52,963 [foster.py] => Task 4, Epoch 44/170 => Loss 3.159, Loss_clf 0.386, Loss_fe 0.258, Loss_kd 2.426, Train_accy 80.19, Test_accy 77.16
2024-08-02 13:56:56,609 [foster.py] => Task 4, Epoch 45/170 => Loss 3.125, Loss_clf 0.366, Loss_fe 0.270, Loss_kd 2.402, Train_accy 81.27, Test_accy 76.84
2024-08-02 13:56:58,860 [foster.py] => Task 4, Epoch 46/170 => Loss 3.186, Loss_clf 0.401, Loss_fe 0.254, Loss_kd 2.442, Train_accy 80.24
2024-08-02 13:57:02,501 [foster.py] => Task 4, Epoch 47/170 => Loss 3.199, Loss_clf 0.390, Loss_fe 0.285, Loss_kd 2.436, Train_accy 80.52, Test_accy 77.31
2024-08-02 13:57:06,225 [foster.py] => Task 4, Epoch 48/170 => Loss 3.177, Loss_clf 0.386, Loss_fe 0.284, Loss_kd 2.419, Train_accy 79.25, Test_accy 77.03
2024-08-02 13:57:09,911 [foster.py] => Task 4, Epoch 49/170 => Loss 3.202, Loss_clf 0.401, Loss_fe 0.309, Loss_kd 2.405, Train_accy 79.10, Test_accy 77.07
2024-08-02 13:57:13,645 [foster.py] => Task 4, Epoch 50/170 => Loss 3.205, Loss_clf 0.409, Loss_fe 0.293, Loss_kd 2.416, Train_accy 80.47, Test_accy 77.09
2024-08-02 13:57:15,865 [foster.py] => Task 4, Epoch 51/170 => Loss 3.225, Loss_clf 0.422, Loss_fe 0.275, Loss_kd 2.439, Train_accy 79.01
2024-08-02 13:57:19,560 [foster.py] => Task 4, Epoch 52/170 => Loss 3.085, Loss_clf 0.341, Loss_fe 0.237, Loss_kd 2.419, Train_accy 82.59, Test_accy 77.34
2024-08-02 13:57:23,204 [foster.py] => Task 4, Epoch 53/170 => Loss 3.124, Loss_clf 0.374, Loss_fe 0.257, Loss_kd 2.405, Train_accy 81.51, Test_accy 77.02
2024-08-02 13:57:26,869 [foster.py] => Task 4, Epoch 54/170 => Loss 3.162, Loss_clf 0.378, Loss_fe 0.282, Loss_kd 2.415, Train_accy 79.67, Test_accy 77.02
2024-08-02 13:57:30,540 [foster.py] => Task 4, Epoch 55/170 => Loss 3.137, Loss_clf 0.387, Loss_fe 0.239, Loss_kd 2.423, Train_accy 81.79, Test_accy 77.41
2024-08-02 13:57:32,772 [foster.py] => Task 4, Epoch 56/170 => Loss 3.128, Loss_clf 0.382, Loss_fe 0.255, Loss_kd 2.404, Train_accy 79.53
2024-08-02 13:57:36,422 [foster.py] => Task 4, Epoch 57/170 => Loss 3.118, Loss_clf 0.368, Loss_fe 0.246, Loss_kd 2.416, Train_accy 80.47, Test_accy 77.17
2024-08-02 13:57:40,077 [foster.py] => Task 4, Epoch 58/170 => Loss 3.132, Loss_clf 0.372, Loss_fe 0.243, Loss_kd 2.428, Train_accy 81.42, Test_accy 77.28
2024-08-02 13:57:43,731 [foster.py] => Task 4, Epoch 59/170 => Loss 3.158, Loss_clf 0.391, Loss_fe 0.244, Loss_kd 2.435, Train_accy 78.35, Test_accy 77.10
2024-08-02 13:57:47,449 [foster.py] => Task 4, Epoch 60/170 => Loss 3.087, Loss_clf 0.361, Loss_fe 0.227, Loss_kd 2.412, Train_accy 81.56, Test_accy 77.16
2024-08-02 13:57:49,671 [foster.py] => Task 4, Epoch 61/170 => Loss 3.043, Loss_clf 0.342, Loss_fe 0.214, Loss_kd 2.400, Train_accy 82.55
2024-08-02 13:57:53,374 [foster.py] => Task 4, Epoch 62/170 => Loss 3.088, Loss_clf 0.356, Loss_fe 0.222, Loss_kd 2.422, Train_accy 81.89, Test_accy 77.09
2024-08-02 13:57:57,013 [foster.py] => Task 4, Epoch 63/170 => Loss 3.050, Loss_clf 0.347, Loss_fe 0.218, Loss_kd 2.398, Train_accy 81.65, Test_accy 77.17
2024-08-02 13:58:00,730 [foster.py] => Task 4, Epoch 64/170 => Loss 3.060, Loss_clf 0.346, Loss_fe 0.227, Loss_kd 2.400, Train_accy 80.75, Test_accy 76.98
2024-08-02 13:58:04,395 [foster.py] => Task 4, Epoch 65/170 => Loss 3.092, Loss_clf 0.367, Loss_fe 0.227, Loss_kd 2.410, Train_accy 80.99, Test_accy 76.86
2024-08-02 13:58:06,616 [foster.py] => Task 4, Epoch 66/170 => Loss 3.083, Loss_clf 0.351, Loss_fe 0.224, Loss_kd 2.420, Train_accy 81.04
2024-08-02 13:58:10,301 [foster.py] => Task 4, Epoch 67/170 => Loss 3.178, Loss_clf 0.404, Loss_fe 0.242, Loss_kd 2.442, Train_accy 81.18, Test_accy 77.41
2024-08-02 13:58:13,922 [foster.py] => Task 4, Epoch 68/170 => Loss 3.073, Loss_clf 0.356, Loss_fe 0.230, Loss_kd 2.400, Train_accy 82.83, Test_accy 77.09
2024-08-02 13:58:17,603 [foster.py] => Task 4, Epoch 69/170 => Loss 3.059, Loss_clf 0.353, Loss_fe 0.202, Loss_kd 2.417, Train_accy 83.11, Test_accy 77.12
2024-08-02 13:58:21,263 [foster.py] => Task 4, Epoch 70/170 => Loss 3.049, Loss_clf 0.339, Loss_fe 0.215, Loss_kd 2.407, Train_accy 81.79, Test_accy 77.26
2024-08-02 13:58:23,490 [foster.py] => Task 4, Epoch 71/170 => Loss 3.000, Loss_clf 0.329, Loss_fe 0.204, Loss_kd 2.381, Train_accy 85.19
2024-08-02 13:58:27,148 [foster.py] => Task 4, Epoch 72/170 => Loss 3.026, Loss_clf 0.327, Loss_fe 0.200, Loss_kd 2.411, Train_accy 83.63, Test_accy 77.16
2024-08-02 13:58:30,834 [foster.py] => Task 4, Epoch 73/170 => Loss 3.083, Loss_clf 0.355, Loss_fe 0.197, Loss_kd 2.442, Train_accy 83.54, Test_accy 77.00
2024-08-02 13:58:34,490 [foster.py] => Task 4, Epoch 74/170 => Loss 3.073, Loss_clf 0.359, Loss_fe 0.204, Loss_kd 2.422, Train_accy 83.82, Test_accy 77.28
2024-08-02 13:58:38,127 [foster.py] => Task 4, Epoch 75/170 => Loss 3.006, Loss_clf 0.315, Loss_fe 0.181, Loss_kd 2.422, Train_accy 83.58, Test_accy 77.07
2024-08-02 13:58:40,360 [foster.py] => Task 4, Epoch 76/170 => Loss 3.072, Loss_clf 0.353, Loss_fe 0.196, Loss_kd 2.435, Train_accy 83.87
2024-08-02 13:58:44,047 [foster.py] => Task 4, Epoch 77/170 => Loss 3.093, Loss_clf 0.375, Loss_fe 0.199, Loss_kd 2.431, Train_accy 82.64, Test_accy 77.40
2024-08-02 13:58:47,746 [foster.py] => Task 4, Epoch 78/170 => Loss 3.062, Loss_clf 0.354, Loss_fe 0.203, Loss_kd 2.417, Train_accy 83.96, Test_accy 77.22
2024-08-02 13:58:51,395 [foster.py] => Task 4, Epoch 79/170 => Loss 3.085, Loss_clf 0.361, Loss_fe 0.207, Loss_kd 2.428, Train_accy 82.59, Test_accy 77.47
2024-08-02 13:58:55,051 [foster.py] => Task 4, Epoch 80/170 => Loss 3.087, Loss_clf 0.366, Loss_fe 0.210, Loss_kd 2.423, Train_accy 82.17, Test_accy 77.05
2024-08-02 13:58:57,286 [foster.py] => Task 4, Epoch 81/170 => Loss 3.006, Loss_clf 0.327, Loss_fe 0.176, Loss_kd 2.415, Train_accy 84.48
2024-08-02 13:59:00,953 [foster.py] => Task 4, Epoch 82/170 => Loss 3.030, Loss_clf 0.352, Loss_fe 0.193, Loss_kd 2.398, Train_accy 81.08, Test_accy 77.33
2024-08-02 13:59:04,668 [foster.py] => Task 4, Epoch 83/170 => Loss 2.971, Loss_clf 0.303, Loss_fe 0.170, Loss_kd 2.410, Train_accy 85.61, Test_accy 77.19
2024-08-02 13:59:08,314 [foster.py] => Task 4, Epoch 84/170 => Loss 3.139, Loss_clf 0.400, Loss_fe 0.206, Loss_kd 2.445, Train_accy 81.98, Test_accy 76.98
2024-08-02 13:59:12,019 [foster.py] => Task 4, Epoch 85/170 => Loss 3.005, Loss_clf 0.323, Loss_fe 0.186, Loss_kd 2.409, Train_accy 83.49, Test_accy 77.43
2024-08-02 13:59:14,247 [foster.py] => Task 4, Epoch 86/170 => Loss 2.937, Loss_clf 0.302, Loss_fe 0.172, Loss_kd 2.376, Train_accy 85.05
2024-08-02 13:59:17,939 [foster.py] => Task 4, Epoch 87/170 => Loss 2.979, Loss_clf 0.322, Loss_fe 0.171, Loss_kd 2.400, Train_accy 85.33, Test_accy 77.22
2024-08-02 13:59:21,652 [foster.py] => Task 4, Epoch 88/170 => Loss 3.003, Loss_clf 0.314, Loss_fe 0.181, Loss_kd 2.420, Train_accy 85.80, Test_accy 77.29
2024-08-02 13:59:25,316 [foster.py] => Task 4, Epoch 89/170 => Loss 3.019, Loss_clf 0.335, Loss_fe 0.159, Loss_kd 2.437, Train_accy 85.85, Test_accy 77.07
2024-08-02 13:59:28,964 [foster.py] => Task 4, Epoch 90/170 => Loss 3.034, Loss_clf 0.343, Loss_fe 0.185, Loss_kd 2.418, Train_accy 84.01, Test_accy 77.31
2024-08-02 13:59:31,185 [foster.py] => Task 4, Epoch 91/170 => Loss 3.083, Loss_clf 0.376, Loss_fe 0.190, Loss_kd 2.429, Train_accy 83.96
2024-08-02 13:59:34,884 [foster.py] => Task 4, Epoch 92/170 => Loss 3.042, Loss_clf 0.338, Loss_fe 0.187, Loss_kd 2.429, Train_accy 84.39, Test_accy 77.21
2024-08-02 13:59:38,535 [foster.py] => Task 4, Epoch 93/170 => Loss 2.971, Loss_clf 0.315, Loss_fe 0.163, Loss_kd 2.406, Train_accy 86.37, Test_accy 77.43
2024-08-02 13:59:42,176 [foster.py] => Task 4, Epoch 94/170 => Loss 3.039, Loss_clf 0.348, Loss_fe 0.187, Loss_kd 2.417, Train_accy 84.15, Test_accy 77.10
2024-08-02 13:59:45,850 [foster.py] => Task 4, Epoch 95/170 => Loss 3.071, Loss_clf 0.365, Loss_fe 0.176, Loss_kd 2.442, Train_accy 83.44, Test_accy 77.41
2024-08-02 13:59:48,076 [foster.py] => Task 4, Epoch 96/170 => Loss 2.951, Loss_clf 0.304, Loss_fe 0.161, Loss_kd 2.399, Train_accy 85.90
2024-08-02 13:59:51,731 [foster.py] => Task 4, Epoch 97/170 => Loss 2.984, Loss_clf 0.327, Loss_fe 0.169, Loss_kd 2.401, Train_accy 84.58, Test_accy 77.22
2024-08-02 13:59:55,388 [foster.py] => Task 4, Epoch 98/170 => Loss 2.968, Loss_clf 0.314, Loss_fe 0.155, Loss_kd 2.411, Train_accy 84.81, Test_accy 77.34
2024-08-02 13:59:59,067 [foster.py] => Task 4, Epoch 99/170 => Loss 2.977, Loss_clf 0.320, Loss_fe 0.162, Loss_kd 2.408, Train_accy 84.29, Test_accy 77.24
2024-08-02 14:00:02,728 [foster.py] => Task 4, Epoch 100/170 => Loss 2.968, Loss_clf 0.318, Loss_fe 0.170, Loss_kd 2.394, Train_accy 85.33, Test_accy 76.93
2024-08-02 14:00:04,938 [foster.py] => Task 4, Epoch 101/170 => Loss 3.019, Loss_clf 0.330, Loss_fe 0.179, Loss_kd 2.423, Train_accy 85.33
2024-08-02 14:00:08,611 [foster.py] => Task 4, Epoch 102/170 => Loss 3.029, Loss_clf 0.325, Loss_fe 0.172, Loss_kd 2.444, Train_accy 86.27, Test_accy 77.22
2024-08-02 14:00:12,256 [foster.py] => Task 4, Epoch 103/170 => Loss 2.981, Loss_clf 0.303, Loss_fe 0.162, Loss_kd 2.427, Train_accy 85.90, Test_accy 77.19
2024-08-02 14:00:15,904 [foster.py] => Task 4, Epoch 104/170 => Loss 3.001, Loss_clf 0.325, Loss_fe 0.168, Loss_kd 2.420, Train_accy 83.68, Test_accy 77.41
2024-08-02 14:00:19,572 [foster.py] => Task 4, Epoch 105/170 => Loss 2.930, Loss_clf 0.302, Loss_fe 0.137, Loss_kd 2.404, Train_accy 85.09, Test_accy 77.45
2024-08-02 14:00:21,843 [foster.py] => Task 4, Epoch 106/170 => Loss 2.984, Loss_clf 0.326, Loss_fe 0.153, Loss_kd 2.417, Train_accy 85.71
2024-08-02 14:00:25,488 [foster.py] => Task 4, Epoch 107/170 => Loss 2.982, Loss_clf 0.327, Loss_fe 0.162, Loss_kd 2.405, Train_accy 84.72, Test_accy 77.16
2024-08-02 14:00:29,190 [foster.py] => Task 4, Epoch 108/170 => Loss 3.043, Loss_clf 0.346, Loss_fe 0.173, Loss_kd 2.436, Train_accy 84.86, Test_accy 77.21
2024-08-02 14:00:32,853 [foster.py] => Task 4, Epoch 109/170 => Loss 2.908, Loss_clf 0.281, Loss_fe 0.142, Loss_kd 2.398, Train_accy 86.84, Test_accy 77.17
2024-08-02 14:00:36,536 [foster.py] => Task 4, Epoch 110/170 => Loss 2.915, Loss_clf 0.299, Loss_fe 0.121, Loss_kd 2.408, Train_accy 87.08, Test_accy 77.52
2024-08-02 14:00:38,788 [foster.py] => Task 4, Epoch 111/170 => Loss 2.942, Loss_clf 0.297, Loss_fe 0.138, Loss_kd 2.419, Train_accy 85.99
2024-08-02 14:00:42,473 [foster.py] => Task 4, Epoch 112/170 => Loss 2.974, Loss_clf 0.320, Loss_fe 0.149, Loss_kd 2.418, Train_accy 86.37, Test_accy 77.36
2024-08-02 14:00:46,139 [foster.py] => Task 4, Epoch 113/170 => Loss 2.966, Loss_clf 0.303, Loss_fe 0.168, Loss_kd 2.408, Train_accy 86.65, Test_accy 77.07
2024-08-02 14:00:49,827 [foster.py] => Task 4, Epoch 114/170 => Loss 2.891, Loss_clf 0.287, Loss_fe 0.127, Loss_kd 2.390, Train_accy 86.56, Test_accy 77.22
2024-08-02 14:00:53,471 [foster.py] => Task 4, Epoch 115/170 => Loss 3.038, Loss_clf 0.349, Loss_fe 0.153, Loss_kd 2.447, Train_accy 85.57, Test_accy 77.38
2024-08-02 14:00:55,700 [foster.py] => Task 4, Epoch 116/170 => Loss 2.982, Loss_clf 0.327, Loss_fe 0.133, Loss_kd 2.433, Train_accy 86.13
2024-08-02 14:00:59,419 [foster.py] => Task 4, Epoch 117/170 => Loss 2.964, Loss_clf 0.329, Loss_fe 0.131, Loss_kd 2.416, Train_accy 85.24, Test_accy 77.29
2024-08-02 14:01:03,185 [foster.py] => Task 4, Epoch 118/170 => Loss 2.907, Loss_clf 0.289, Loss_fe 0.131, Loss_kd 2.400, Train_accy 87.41, Test_accy 77.41
2024-08-02 14:01:06,840 [foster.py] => Task 4, Epoch 119/170 => Loss 2.918, Loss_clf 0.294, Loss_fe 0.144, Loss_kd 2.392, Train_accy 87.22, Test_accy 77.34
2024-08-02 14:01:10,480 [foster.py] => Task 4, Epoch 120/170 => Loss 2.917, Loss_clf 0.277, Loss_fe 0.130, Loss_kd 2.421, Train_accy 87.78, Test_accy 77.16
2024-08-02 14:01:12,731 [foster.py] => Task 4, Epoch 121/170 => Loss 2.987, Loss_clf 0.329, Loss_fe 0.151, Loss_kd 2.420, Train_accy 86.75
2024-08-02 14:01:16,401 [foster.py] => Task 4, Epoch 122/170 => Loss 2.972, Loss_clf 0.327, Loss_fe 0.148, Loss_kd 2.409, Train_accy 87.17, Test_accy 77.55
2024-08-02 14:01:20,056 [foster.py] => Task 4, Epoch 123/170 => Loss 2.955, Loss_clf 0.308, Loss_fe 0.135, Loss_kd 2.423, Train_accy 86.79, Test_accy 77.41
2024-08-02 14:01:23,717 [foster.py] => Task 4, Epoch 124/170 => Loss 2.955, Loss_clf 0.322, Loss_fe 0.124, Loss_kd 2.421, Train_accy 86.18, Test_accy 77.26
2024-08-02 14:01:27,404 [foster.py] => Task 4, Epoch 125/170 => Loss 2.880, Loss_clf 0.283, Loss_fe 0.124, Loss_kd 2.386, Train_accy 88.02, Test_accy 77.21
2024-08-02 14:01:29,654 [foster.py] => Task 4, Epoch 126/170 => Loss 2.867, Loss_clf 0.261, Loss_fe 0.112, Loss_kd 2.407, Train_accy 87.31
2024-08-02 14:01:33,329 [foster.py] => Task 4, Epoch 127/170 => Loss 2.959, Loss_clf 0.300, Loss_fe 0.139, Loss_kd 2.431, Train_accy 86.51, Test_accy 77.28
2024-08-02 14:01:36,964 [foster.py] => Task 4, Epoch 128/170 => Loss 2.980, Loss_clf 0.321, Loss_fe 0.134, Loss_kd 2.436, Train_accy 86.27, Test_accy 77.03
2024-08-02 14:01:40,672 [foster.py] => Task 4, Epoch 129/170 => Loss 2.929, Loss_clf 0.301, Loss_fe 0.122, Loss_kd 2.419, Train_accy 87.22, Test_accy 77.36
2024-08-02 14:01:44,314 [foster.py] => Task 4, Epoch 130/170 => Loss 2.892, Loss_clf 0.287, Loss_fe 0.131, Loss_kd 2.388, Train_accy 86.84, Test_accy 77.38
2024-08-02 14:01:46,539 [foster.py] => Task 4, Epoch 131/170 => Loss 2.945, Loss_clf 0.313, Loss_fe 0.126, Loss_kd 2.419, Train_accy 87.97
2024-08-02 14:01:50,186 [foster.py] => Task 4, Epoch 132/170 => Loss 2.967, Loss_clf 0.318, Loss_fe 0.129, Loss_kd 2.432, Train_accy 86.32, Test_accy 77.41
2024-08-02 14:01:53,844 [foster.py] => Task 4, Epoch 133/170 => Loss 2.892, Loss_clf 0.279, Loss_fe 0.115, Loss_kd 2.411, Train_accy 87.36, Test_accy 77.62
2024-08-02 14:01:57,482 [foster.py] => Task 4, Epoch 134/170 => Loss 2.987, Loss_clf 0.328, Loss_fe 0.130, Loss_kd 2.440, Train_accy 85.85, Test_accy 77.40
2024-08-02 14:02:01,141 [foster.py] => Task 4, Epoch 135/170 => Loss 2.937, Loss_clf 0.296, Loss_fe 0.120, Loss_kd 2.432, Train_accy 87.17, Test_accy 77.03
2024-08-02 14:02:03,391 [foster.py] => Task 4, Epoch 136/170 => Loss 2.895, Loss_clf 0.280, Loss_fe 0.118, Loss_kd 2.410, Train_accy 88.40
2024-08-02 14:02:07,067 [foster.py] => Task 4, Epoch 137/170 => Loss 2.931, Loss_clf 0.300, Loss_fe 0.133, Loss_kd 2.410, Train_accy 87.64, Test_accy 77.28
2024-08-02 14:02:10,723 [foster.py] => Task 4, Epoch 138/170 => Loss 2.940, Loss_clf 0.307, Loss_fe 0.118, Loss_kd 2.428, Train_accy 87.88, Test_accy 77.34
2024-08-02 14:02:14,392 [foster.py] => Task 4, Epoch 139/170 => Loss 2.997, Loss_clf 0.328, Loss_fe 0.142, Loss_kd 2.438, Train_accy 85.85, Test_accy 77.40
2024-08-02 14:02:18,083 [foster.py] => Task 4, Epoch 140/170 => Loss 2.934, Loss_clf 0.309, Loss_fe 0.112, Loss_kd 2.425, Train_accy 86.42, Test_accy 77.33
2024-08-02 14:02:20,329 [foster.py] => Task 4, Epoch 141/170 => Loss 2.922, Loss_clf 0.293, Loss_fe 0.118, Loss_kd 2.423, Train_accy 87.64
2024-08-02 14:02:24,024 [foster.py] => Task 4, Epoch 142/170 => Loss 2.878, Loss_clf 0.268, Loss_fe 0.100, Loss_kd 2.422, Train_accy 88.44, Test_accy 77.22
2024-08-02 14:02:27,727 [foster.py] => Task 4, Epoch 143/170 => Loss 2.879, Loss_clf 0.280, Loss_fe 0.105, Loss_kd 2.406, Train_accy 89.53, Test_accy 77.24
2024-08-02 14:02:31,394 [foster.py] => Task 4, Epoch 144/170 => Loss 2.909, Loss_clf 0.273, Loss_fe 0.113, Loss_kd 2.435, Train_accy 88.11, Test_accy 77.29
2024-08-02 14:02:35,116 [foster.py] => Task 4, Epoch 145/170 => Loss 2.878, Loss_clf 0.284, Loss_fe 0.098, Loss_kd 2.408, Train_accy 86.42, Test_accy 77.31
2024-08-02 14:02:37,348 [foster.py] => Task 4, Epoch 146/170 => Loss 2.861, Loss_clf 0.263, Loss_fe 0.103, Loss_kd 2.408, Train_accy 88.68
2024-08-02 14:02:41,018 [foster.py] => Task 4, Epoch 147/170 => Loss 2.967, Loss_clf 0.314, Loss_fe 0.117, Loss_kd 2.446, Train_accy 87.03, Test_accy 77.43
2024-08-02 14:02:44,684 [foster.py] => Task 4, Epoch 148/170 => Loss 2.876, Loss_clf 0.274, Loss_fe 0.097, Loss_kd 2.417, Train_accy 87.74, Test_accy 77.31
2024-08-02 14:02:48,337 [foster.py] => Task 4, Epoch 149/170 => Loss 2.910, Loss_clf 0.295, Loss_fe 0.124, Loss_kd 2.403, Train_accy 87.08, Test_accy 77.24
2024-08-02 14:02:52,007 [foster.py] => Task 4, Epoch 150/170 => Loss 2.906, Loss_clf 0.303, Loss_fe 0.113, Loss_kd 2.403, Train_accy 86.51, Test_accy 77.34
2024-08-02 14:02:54,218 [foster.py] => Task 4, Epoch 151/170 => Loss 2.926, Loss_clf 0.303, Loss_fe 0.109, Loss_kd 2.426, Train_accy 86.84
2024-08-02 14:02:57,952 [foster.py] => Task 4, Epoch 152/170 => Loss 2.856, Loss_clf 0.265, Loss_fe 0.096, Loss_kd 2.408, Train_accy 87.64, Test_accy 77.24
2024-08-02 14:03:01,599 [foster.py] => Task 4, Epoch 153/170 => Loss 2.887, Loss_clf 0.281, Loss_fe 0.120, Loss_kd 2.400, Train_accy 87.64, Test_accy 77.31
2024-08-02 14:03:05,327 [foster.py] => Task 4, Epoch 154/170 => Loss 2.881, Loss_clf 0.282, Loss_fe 0.109, Loss_kd 2.403, Train_accy 87.59, Test_accy 77.29
2024-08-02 14:03:09,122 [foster.py] => Task 4, Epoch 155/170 => Loss 2.885, Loss_clf 0.287, Loss_fe 0.099, Loss_kd 2.412, Train_accy 86.60, Test_accy 77.19
2024-08-02 14:03:11,426 [foster.py] => Task 4, Epoch 156/170 => Loss 2.910, Loss_clf 0.285, Loss_fe 0.110, Loss_kd 2.426, Train_accy 88.30
2024-08-02 14:03:15,114 [foster.py] => Task 4, Epoch 157/170 => Loss 2.934, Loss_clf 0.298, Loss_fe 0.112, Loss_kd 2.436, Train_accy 87.22, Test_accy 77.26
2024-08-02 14:03:18,782 [foster.py] => Task 4, Epoch 158/170 => Loss 2.941, Loss_clf 0.312, Loss_fe 0.124, Loss_kd 2.417, Train_accy 88.25, Test_accy 77.28
2024-08-02 14:03:22,461 [foster.py] => Task 4, Epoch 159/170 => Loss 2.932, Loss_clf 0.292, Loss_fe 0.129, Loss_kd 2.423, Train_accy 87.92, Test_accy 77.19
2024-08-02 14:03:26,132 [foster.py] => Task 4, Epoch 160/170 => Loss 2.918, Loss_clf 0.287, Loss_fe 0.116, Loss_kd 2.427, Train_accy 87.78, Test_accy 77.17
2024-08-02 14:03:28,375 [foster.py] => Task 4, Epoch 161/170 => Loss 2.890, Loss_clf 0.292, Loss_fe 0.105, Loss_kd 2.406, Train_accy 87.12
2024-08-02 14:03:32,031 [foster.py] => Task 4, Epoch 162/170 => Loss 2.892, Loss_clf 0.290, Loss_fe 0.109, Loss_kd 2.406, Train_accy 87.78, Test_accy 77.31
2024-08-02 14:03:35,717 [foster.py] => Task 4, Epoch 163/170 => Loss 2.882, Loss_clf 0.276, Loss_fe 0.111, Loss_kd 2.407, Train_accy 87.88, Test_accy 77.28
2024-08-02 14:03:39,402 [foster.py] => Task 4, Epoch 164/170 => Loss 2.912, Loss_clf 0.293, Loss_fe 0.101, Loss_kd 2.429, Train_accy 88.35, Test_accy 77.24
2024-08-02 14:03:43,085 [foster.py] => Task 4, Epoch 165/170 => Loss 2.897, Loss_clf 0.284, Loss_fe 0.109, Loss_kd 2.417, Train_accy 87.88, Test_accy 77.28
2024-08-02 14:03:45,328 [foster.py] => Task 4, Epoch 166/170 => Loss 2.943, Loss_clf 0.312, Loss_fe 0.124, Loss_kd 2.419, Train_accy 87.59
2024-08-02 14:03:49,021 [foster.py] => Task 4, Epoch 167/170 => Loss 2.876, Loss_clf 0.278, Loss_fe 0.098, Loss_kd 2.412, Train_accy 88.40, Test_accy 77.33
2024-08-02 14:03:52,702 [foster.py] => Task 4, Epoch 168/170 => Loss 2.879, Loss_clf 0.283, Loss_fe 0.101, Loss_kd 2.408, Train_accy 88.77, Test_accy 77.41
2024-08-02 14:03:56,411 [foster.py] => Task 4, Epoch 169/170 => Loss 2.889, Loss_clf 0.268, Loss_fe 0.100, Loss_kd 2.432, Train_accy 88.02, Test_accy 77.26
2024-08-02 14:04:00,091 [foster.py] => Task 4, Epoch 170/170 => Loss 2.875, Loss_clf 0.290, Loss_fe 0.094, Loss_kd 2.404, Train_accy 87.83, Test_accy 77.29
2024-08-02 14:04:00,094 [foster.py] => do not weight align teacher!
2024-08-02 14:04:00,096 [foster.py] => per cls weights : [1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668 1.01885668
 1.01885668 1.01885668 0.47201291 0.47201291]
2024-08-02 14:04:04,389 [foster.py] => SNet: Task 4, Epoch 1/130 => Loss 27.918,  Loss1 0.698, Train_accy 43.73, Test_accy 74.17
2024-08-02 14:04:07,464 [foster.py] => SNet: Task 4, Epoch 2/130 => Loss 27.837,  Loss1 0.698, Train_accy 51.27
2024-08-02 14:04:10,521 [foster.py] => SNet: Task 4, Epoch 3/130 => Loss 27.838,  Loss1 0.699, Train_accy 55.61
2024-08-02 14:04:13,585 [foster.py] => SNet: Task 4, Epoch 4/130 => Loss 27.764,  Loss1 0.698, Train_accy 55.75
2024-08-02 14:04:16,680 [foster.py] => SNet: Task 4, Epoch 5/130 => Loss 27.753,  Loss1 0.698, Train_accy 54.53
2024-08-02 14:04:20,696 [foster.py] => SNet: Task 4, Epoch 6/130 => Loss 27.802,  Loss1 0.698, Train_accy 55.00, Test_accy 75.33
2024-08-02 14:04:23,772 [foster.py] => SNet: Task 4, Epoch 7/130 => Loss 27.711,  Loss1 0.699, Train_accy 58.21
2024-08-02 14:04:26,825 [foster.py] => SNet: Task 4, Epoch 8/130 => Loss 27.728,  Loss1 0.698, Train_accy 59.34
2024-08-02 14:04:29,876 [foster.py] => SNet: Task 4, Epoch 9/130 => Loss 27.713,  Loss1 0.699, Train_accy 60.80
2024-08-02 14:04:32,967 [foster.py] => SNet: Task 4, Epoch 10/130 => Loss 27.766,  Loss1 0.699, Train_accy 61.79
2024-08-02 14:04:36,990 [foster.py] => SNet: Task 4, Epoch 11/130 => Loss 27.766,  Loss1 0.698, Train_accy 60.94, Test_accy 75.50
2024-08-02 14:04:40,056 [foster.py] => SNet: Task 4, Epoch 12/130 => Loss 27.779,  Loss1 0.698, Train_accy 61.42
2024-08-02 14:04:43,120 [foster.py] => SNet: Task 4, Epoch 13/130 => Loss 27.711,  Loss1 0.698, Train_accy 62.08
2024-08-02 14:04:46,192 [foster.py] => SNet: Task 4, Epoch 14/130 => Loss 27.769,  Loss1 0.698, Train_accy 63.54
2024-08-02 14:04:49,260 [foster.py] => SNet: Task 4, Epoch 15/130 => Loss 27.698,  Loss1 0.698, Train_accy 63.73
2024-08-02 14:04:53,291 [foster.py] => SNet: Task 4, Epoch 16/130 => Loss 27.726,  Loss1 0.698, Train_accy 65.90, Test_accy 75.88
2024-08-02 14:04:56,364 [foster.py] => SNet: Task 4, Epoch 17/130 => Loss 27.713,  Loss1 0.699, Train_accy 64.58
2024-08-02 14:04:59,438 [foster.py] => SNet: Task 4, Epoch 18/130 => Loss 27.717,  Loss1 0.699, Train_accy 67.26
2024-08-02 14:05:02,514 [foster.py] => SNet: Task 4, Epoch 19/130 => Loss 27.771,  Loss1 0.699, Train_accy 65.99
2024-08-02 14:05:05,572 [foster.py] => SNet: Task 4, Epoch 20/130 => Loss 27.707,  Loss1 0.698, Train_accy 65.05
2024-08-02 14:05:09,658 [foster.py] => SNet: Task 4, Epoch 21/130 => Loss 27.724,  Loss1 0.699, Train_accy 67.59, Test_accy 76.33
2024-08-02 14:05:12,722 [foster.py] => SNet: Task 4, Epoch 22/130 => Loss 27.607,  Loss1 0.699, Train_accy 67.41
2024-08-02 14:05:15,787 [foster.py] => SNet: Task 4, Epoch 23/130 => Loss 27.688,  Loss1 0.699, Train_accy 67.88
2024-08-02 14:05:18,853 [foster.py] => SNet: Task 4, Epoch 24/130 => Loss 27.709,  Loss1 0.699, Train_accy 65.57
2024-08-02 14:05:21,915 [foster.py] => SNet: Task 4, Epoch 25/130 => Loss 27.716,  Loss1 0.699, Train_accy 68.82
2024-08-02 14:05:25,923 [foster.py] => SNet: Task 4, Epoch 26/130 => Loss 27.772,  Loss1 0.699, Train_accy 66.56, Test_accy 76.28
2024-08-02 14:05:28,999 [foster.py] => SNet: Task 4, Epoch 27/130 => Loss 27.735,  Loss1 0.698, Train_accy 67.78
2024-08-02 14:05:32,059 [foster.py] => SNet: Task 4, Epoch 28/130 => Loss 27.771,  Loss1 0.698, Train_accy 68.40
2024-08-02 14:05:35,139 [foster.py] => SNet: Task 4, Epoch 29/130 => Loss 27.730,  Loss1 0.698, Train_accy 67.55
2024-08-02 14:05:38,229 [foster.py] => SNet: Task 4, Epoch 30/130 => Loss 27.696,  Loss1 0.698, Train_accy 66.75
2024-08-02 14:05:42,231 [foster.py] => SNet: Task 4, Epoch 31/130 => Loss 27.760,  Loss1 0.698, Train_accy 68.30, Test_accy 76.29
2024-08-02 14:05:45,300 [foster.py] => SNet: Task 4, Epoch 32/130 => Loss 27.709,  Loss1 0.698, Train_accy 67.83
2024-08-02 14:05:48,374 [foster.py] => SNet: Task 4, Epoch 33/130 => Loss 27.727,  Loss1 0.698, Train_accy 66.70
2024-08-02 14:05:51,442 [foster.py] => SNet: Task 4, Epoch 34/130 => Loss 27.735,  Loss1 0.698, Train_accy 68.92
2024-08-02 14:05:54,547 [foster.py] => SNet: Task 4, Epoch 35/130 => Loss 27.722,  Loss1 0.698, Train_accy 67.83
2024-08-02 14:05:58,561 [foster.py] => SNet: Task 4, Epoch 36/130 => Loss 27.719,  Loss1 0.699, Train_accy 69.86, Test_accy 76.28
2024-08-02 14:06:01,655 [foster.py] => SNet: Task 4, Epoch 37/130 => Loss 27.752,  Loss1 0.698, Train_accy 69.53
2024-08-02 14:06:04,729 [foster.py] => SNet: Task 4, Epoch 38/130 => Loss 27.729,  Loss1 0.699, Train_accy 69.81
2024-08-02 14:06:07,786 [foster.py] => SNet: Task 4, Epoch 39/130 => Loss 27.718,  Loss1 0.698, Train_accy 68.40
2024-08-02 14:06:10,845 [foster.py] => SNet: Task 4, Epoch 40/130 => Loss 27.765,  Loss1 0.698, Train_accy 68.63
2024-08-02 14:06:14,857 [foster.py] => SNet: Task 4, Epoch 41/130 => Loss 27.727,  Loss1 0.699, Train_accy 69.20, Test_accy 76.60
2024-08-02 14:06:17,978 [foster.py] => SNet: Task 4, Epoch 42/130 => Loss 27.711,  Loss1 0.698, Train_accy 69.86
2024-08-02 14:06:21,040 [foster.py] => SNet: Task 4, Epoch 43/130 => Loss 27.685,  Loss1 0.698, Train_accy 70.14
2024-08-02 14:06:24,106 [foster.py] => SNet: Task 4, Epoch 44/130 => Loss 27.675,  Loss1 0.699, Train_accy 69.43
2024-08-02 14:06:27,169 [foster.py] => SNet: Task 4, Epoch 45/130 => Loss 27.705,  Loss1 0.698, Train_accy 68.87
2024-08-02 14:06:31,179 [foster.py] => SNet: Task 4, Epoch 46/130 => Loss 27.768,  Loss1 0.698, Train_accy 70.24, Test_accy 76.52
2024-08-02 14:06:34,252 [foster.py] => SNet: Task 4, Epoch 47/130 => Loss 27.709,  Loss1 0.698, Train_accy 68.30
2024-08-02 14:06:37,326 [foster.py] => SNet: Task 4, Epoch 48/130 => Loss 27.726,  Loss1 0.699, Train_accy 70.61
2024-08-02 14:06:40,411 [foster.py] => SNet: Task 4, Epoch 49/130 => Loss 27.715,  Loss1 0.698, Train_accy 69.39
2024-08-02 14:06:43,466 [foster.py] => SNet: Task 4, Epoch 50/130 => Loss 27.706,  Loss1 0.698, Train_accy 70.52
2024-08-02 14:06:47,475 [foster.py] => SNet: Task 4, Epoch 51/130 => Loss 27.688,  Loss1 0.698, Train_accy 69.72, Test_accy 76.21
2024-08-02 14:06:50,523 [foster.py] => SNet: Task 4, Epoch 52/130 => Loss 27.691,  Loss1 0.698, Train_accy 71.32
2024-08-02 14:06:53,583 [foster.py] => SNet: Task 4, Epoch 53/130 => Loss 27.675,  Loss1 0.699, Train_accy 70.94
2024-08-02 14:06:56,654 [foster.py] => SNet: Task 4, Epoch 54/130 => Loss 27.739,  Loss1 0.699, Train_accy 70.75
2024-08-02 14:06:59,706 [foster.py] => SNet: Task 4, Epoch 55/130 => Loss 27.684,  Loss1 0.699, Train_accy 70.85
2024-08-02 14:07:03,713 [foster.py] => SNet: Task 4, Epoch 56/130 => Loss 27.692,  Loss1 0.699, Train_accy 68.77, Test_accy 76.52
2024-08-02 14:07:06,778 [foster.py] => SNet: Task 4, Epoch 57/130 => Loss 27.734,  Loss1 0.698, Train_accy 71.04
2024-08-02 14:07:09,827 [foster.py] => SNet: Task 4, Epoch 58/130 => Loss 27.679,  Loss1 0.699, Train_accy 69.62
2024-08-02 14:07:12,904 [foster.py] => SNet: Task 4, Epoch 59/130 => Loss 27.690,  Loss1 0.698, Train_accy 70.85
2024-08-02 14:07:15,973 [foster.py] => SNet: Task 4, Epoch 60/130 => Loss 27.687,  Loss1 0.699, Train_accy 69.39
2024-08-02 14:07:20,003 [foster.py] => SNet: Task 4, Epoch 61/130 => Loss 27.678,  Loss1 0.698, Train_accy 71.70, Test_accy 76.64
2024-08-02 14:07:23,073 [foster.py] => SNet: Task 4, Epoch 62/130 => Loss 27.722,  Loss1 0.698, Train_accy 70.57
2024-08-02 14:07:26,226 [foster.py] => SNet: Task 4, Epoch 63/130 => Loss 27.662,  Loss1 0.698, Train_accy 70.90
2024-08-02 14:07:29,288 [foster.py] => SNet: Task 4, Epoch 64/130 => Loss 27.677,  Loss1 0.699, Train_accy 71.79
2024-08-02 14:07:32,358 [foster.py] => SNet: Task 4, Epoch 65/130 => Loss 27.757,  Loss1 0.698, Train_accy 70.09
2024-08-02 14:07:36,396 [foster.py] => SNet: Task 4, Epoch 66/130 => Loss 27.683,  Loss1 0.698, Train_accy 70.85, Test_accy 76.74
2024-08-02 14:07:39,481 [foster.py] => SNet: Task 4, Epoch 67/130 => Loss 27.732,  Loss1 0.699, Train_accy 71.13
2024-08-02 14:07:42,550 [foster.py] => SNet: Task 4, Epoch 68/130 => Loss 27.742,  Loss1 0.699, Train_accy 71.51
2024-08-02 14:07:45,619 [foster.py] => SNet: Task 4, Epoch 69/130 => Loss 27.716,  Loss1 0.699, Train_accy 69.72
2024-08-02 14:07:48,699 [foster.py] => SNet: Task 4, Epoch 70/130 => Loss 27.711,  Loss1 0.698, Train_accy 70.47
2024-08-02 14:07:52,733 [foster.py] => SNet: Task 4, Epoch 71/130 => Loss 27.758,  Loss1 0.699, Train_accy 70.90, Test_accy 76.64
2024-08-02 14:07:55,784 [foster.py] => SNet: Task 4, Epoch 72/130 => Loss 27.662,  Loss1 0.698, Train_accy 71.51
2024-08-02 14:07:58,849 [foster.py] => SNet: Task 4, Epoch 73/130 => Loss 27.713,  Loss1 0.699, Train_accy 70.99
2024-08-02 14:08:01,913 [foster.py] => SNet: Task 4, Epoch 74/130 => Loss 27.685,  Loss1 0.699, Train_accy 71.51
2024-08-02 14:08:05,008 [foster.py] => SNet: Task 4, Epoch 75/130 => Loss 27.733,  Loss1 0.698, Train_accy 70.75
2024-08-02 14:08:09,017 [foster.py] => SNet: Task 4, Epoch 76/130 => Loss 27.725,  Loss1 0.699, Train_accy 70.66, Test_accy 76.53
2024-08-02 14:08:12,079 [foster.py] => SNet: Task 4, Epoch 77/130 => Loss 27.695,  Loss1 0.699, Train_accy 70.38
2024-08-02 14:08:15,144 [foster.py] => SNet: Task 4, Epoch 78/130 => Loss 27.702,  Loss1 0.699, Train_accy 72.78
2024-08-02 14:08:18,209 [foster.py] => SNet: Task 4, Epoch 79/130 => Loss 27.714,  Loss1 0.699, Train_accy 71.60
2024-08-02 14:08:21,267 [foster.py] => SNet: Task 4, Epoch 80/130 => Loss 27.747,  Loss1 0.698, Train_accy 70.38
2024-08-02 14:08:25,257 [foster.py] => SNet: Task 4, Epoch 81/130 => Loss 27.699,  Loss1 0.698, Train_accy 72.50, Test_accy 76.52
2024-08-02 14:08:28,314 [foster.py] => SNet: Task 4, Epoch 82/130 => Loss 27.729,  Loss1 0.698, Train_accy 69.34
2024-08-02 14:08:31,436 [foster.py] => SNet: Task 4, Epoch 83/130 => Loss 27.676,  Loss1 0.699, Train_accy 70.42
2024-08-02 14:08:34,510 [foster.py] => SNet: Task 4, Epoch 84/130 => Loss 27.765,  Loss1 0.699, Train_accy 71.46
2024-08-02 14:08:37,596 [foster.py] => SNet: Task 4, Epoch 85/130 => Loss 27.695,  Loss1 0.699, Train_accy 70.94
2024-08-02 14:08:41,588 [foster.py] => SNet: Task 4, Epoch 86/130 => Loss 27.693,  Loss1 0.699, Train_accy 71.56, Test_accy 76.28
2024-08-02 14:08:44,674 [foster.py] => SNet: Task 4, Epoch 87/130 => Loss 27.685,  Loss1 0.699, Train_accy 71.75
2024-08-02 14:08:47,716 [foster.py] => SNet: Task 4, Epoch 88/130 => Loss 27.770,  Loss1 0.698, Train_accy 71.23
2024-08-02 14:08:50,804 [foster.py] => SNet: Task 4, Epoch 89/130 => Loss 27.733,  Loss1 0.699, Train_accy 72.03
2024-08-02 14:08:53,862 [foster.py] => SNet: Task 4, Epoch 90/130 => Loss 27.667,  Loss1 0.698, Train_accy 70.90
2024-08-02 14:08:57,846 [foster.py] => SNet: Task 4, Epoch 91/130 => Loss 27.741,  Loss1 0.699, Train_accy 71.27, Test_accy 76.53
2024-08-02 14:09:00,927 [foster.py] => SNet: Task 4, Epoch 92/130 => Loss 27.717,  Loss1 0.698, Train_accy 72.78
2024-08-02 14:09:03,984 [foster.py] => SNet: Task 4, Epoch 93/130 => Loss 27.696,  Loss1 0.699, Train_accy 72.08
2024-08-02 14:09:07,065 [foster.py] => SNet: Task 4, Epoch 94/130 => Loss 27.693,  Loss1 0.699, Train_accy 71.75
2024-08-02 14:09:10,143 [foster.py] => SNet: Task 4, Epoch 95/130 => Loss 27.718,  Loss1 0.698, Train_accy 71.51
2024-08-02 14:09:14,123 [foster.py] => SNet: Task 4, Epoch 96/130 => Loss 27.692,  Loss1 0.699, Train_accy 70.94, Test_accy 76.83
2024-08-02 14:09:17,176 [foster.py] => SNet: Task 4, Epoch 97/130 => Loss 27.721,  Loss1 0.698, Train_accy 70.99
2024-08-02 14:09:20,279 [foster.py] => SNet: Task 4, Epoch 98/130 => Loss 27.728,  Loss1 0.699, Train_accy 72.59
2024-08-02 14:09:23,346 [foster.py] => SNet: Task 4, Epoch 99/130 => Loss 27.733,  Loss1 0.699, Train_accy 73.07
2024-08-02 14:09:26,392 [foster.py] => SNet: Task 4, Epoch 100/130 => Loss 27.678,  Loss1 0.698, Train_accy 71.32
2024-08-02 14:09:30,398 [foster.py] => SNet: Task 4, Epoch 101/130 => Loss 27.718,  Loss1 0.699, Train_accy 71.79, Test_accy 76.81
2024-08-02 14:09:33,470 [foster.py] => SNet: Task 4, Epoch 102/130 => Loss 27.673,  Loss1 0.699, Train_accy 70.57
2024-08-02 14:09:36,536 [foster.py] => SNet: Task 4, Epoch 103/130 => Loss 27.719,  Loss1 0.699, Train_accy 71.42
2024-08-02 14:09:39,649 [foster.py] => SNet: Task 4, Epoch 104/130 => Loss 27.715,  Loss1 0.698, Train_accy 70.90
2024-08-02 14:09:42,741 [foster.py] => SNet: Task 4, Epoch 105/130 => Loss 27.652,  Loss1 0.699, Train_accy 71.32
2024-08-02 14:09:46,758 [foster.py] => SNet: Task 4, Epoch 106/130 => Loss 27.698,  Loss1 0.699, Train_accy 72.41, Test_accy 76.81
2024-08-02 14:09:49,819 [foster.py] => SNet: Task 4, Epoch 107/130 => Loss 27.708,  Loss1 0.698, Train_accy 71.42
2024-08-02 14:09:52,886 [foster.py] => SNet: Task 4, Epoch 108/130 => Loss 27.710,  Loss1 0.699, Train_accy 73.11
2024-08-02 14:09:55,946 [foster.py] => SNet: Task 4, Epoch 109/130 => Loss 27.739,  Loss1 0.699, Train_accy 71.51
2024-08-02 14:09:59,025 [foster.py] => SNet: Task 4, Epoch 110/130 => Loss 27.724,  Loss1 0.699, Train_accy 71.27
2024-08-02 14:10:03,049 [foster.py] => SNet: Task 4, Epoch 111/130 => Loss 27.693,  Loss1 0.698, Train_accy 72.36, Test_accy 76.81
2024-08-02 14:10:06,110 [foster.py] => SNet: Task 4, Epoch 112/130 => Loss 27.686,  Loss1 0.698, Train_accy 70.94
2024-08-02 14:10:09,171 [foster.py] => SNet: Task 4, Epoch 113/130 => Loss 27.696,  Loss1 0.698, Train_accy 72.12
2024-08-02 14:10:12,240 [foster.py] => SNet: Task 4, Epoch 114/130 => Loss 27.724,  Loss1 0.698, Train_accy 71.32
2024-08-02 14:10:15,308 [foster.py] => SNet: Task 4, Epoch 115/130 => Loss 27.738,  Loss1 0.698, Train_accy 70.71
2024-08-02 14:10:19,328 [foster.py] => SNet: Task 4, Epoch 116/130 => Loss 27.770,  Loss1 0.699, Train_accy 71.75, Test_accy 76.74
2024-08-02 14:10:22,397 [foster.py] => SNet: Task 4, Epoch 117/130 => Loss 27.698,  Loss1 0.698, Train_accy 70.38
2024-08-02 14:10:25,447 [foster.py] => SNet: Task 4, Epoch 118/130 => Loss 27.714,  Loss1 0.699, Train_accy 71.18
2024-08-02 14:10:28,537 [foster.py] => SNet: Task 4, Epoch 119/130 => Loss 27.764,  Loss1 0.699, Train_accy 71.27
2024-08-02 14:10:31,621 [foster.py] => SNet: Task 4, Epoch 120/130 => Loss 27.738,  Loss1 0.698, Train_accy 71.51
2024-08-02 14:10:35,630 [foster.py] => SNet: Task 4, Epoch 121/130 => Loss 27.674,  Loss1 0.699, Train_accy 70.66, Test_accy 76.91
2024-08-02 14:10:38,692 [foster.py] => SNet: Task 4, Epoch 122/130 => Loss 27.730,  Loss1 0.698, Train_accy 72.74
2024-08-02 14:10:41,752 [foster.py] => SNet: Task 4, Epoch 123/130 => Loss 27.718,  Loss1 0.699, Train_accy 70.66
2024-08-02 14:10:44,853 [foster.py] => SNet: Task 4, Epoch 124/130 => Loss 27.706,  Loss1 0.699, Train_accy 72.50
2024-08-02 14:10:47,982 [foster.py] => SNet: Task 4, Epoch 125/130 => Loss 27.708,  Loss1 0.698, Train_accy 70.85
2024-08-02 14:10:51,999 [foster.py] => SNet: Task 4, Epoch 126/130 => Loss 27.746,  Loss1 0.698, Train_accy 70.61, Test_accy 76.69
2024-08-02 14:10:55,058 [foster.py] => SNet: Task 4, Epoch 127/130 => Loss 27.713,  Loss1 0.698, Train_accy 71.75
2024-08-02 14:10:58,124 [foster.py] => SNet: Task 4, Epoch 128/130 => Loss 27.688,  Loss1 0.698, Train_accy 71.84
2024-08-02 14:11:01,178 [foster.py] => SNet: Task 4, Epoch 129/130 => Loss 27.766,  Loss1 0.698, Train_accy 71.56
2024-08-02 14:11:04,246 [foster.py] => SNet: Task 4, Epoch 130/130 => Loss 27.744,  Loss1 0.699, Train_accy 71.37
2024-08-02 14:11:04,248 [foster.py] => do not weight align student!
2024-08-02 14:11:05,203 [foster.py] => darknet eval: 
2024-08-02 14:11:05,203 [foster.py] => CNN top1 curve: 76.74
2024-08-02 14:11:05,204 [foster.py] => CNN top5 curve: 95.74
2024-08-02 14:11:05,204 [foster.py] => CNN top1 平均值: 76.74
2024-08-02 14:11:05,207 [foster.py] => timees : 1001.54576587677
2024-08-02 14:11:05,208 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 14:11:22,923 [foster.py] => Exemplar size: 1160
2024-08-02 14:11:22,923 [trainer.py] => CNN: {'total': 77.29, '00-09': 82.9, '10-19': 73.4, '20-29': 81.7, '30-39': 75.8, '40-49': 80.1, '50-59': 68.0, 'old': 77.27, 'new': 78.0}
2024-08-02 14:11:22,923 [trainer.py] => NME: {'total': 74.0, '00-09': 77.1, '10-19': 68.3, '20-29': 78.8, '30-39': 74.0, '40-49': 76.9, '50-59': 67.62, 'old': 73.39, 'new': 91.0}
2024-08-02 14:11:22,924 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29]
2024-08-02 14:11:22,924 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79]
2024-08-02 14:11:22,927 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0]
2024-08-02 14:11:22,927 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83]

2024-08-02 14:11:22,927 [trainer.py] => CNN top1 平均值: 79.50
2024-08-02 14:11:22,930 [trainer.py] => All params: 1169440
2024-08-02 14:11:22,933 [trainer.py] => Trainable params: 588526
2024-08-02 14:11:22,993 [foster.py] => Learning on 58-60
2024-08-02 14:11:22,997 [foster.py] => All params: 1169958
2024-08-02 14:11:22,999 [foster.py] => Trainable params: 588914
2024-08-02 14:11:23,035 [foster.py] => per cls weights : [1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741 1.01532741
 1.01532741 1.01532741 1.01532741 1.01532741 0.55550502 0.55550502]
2024-08-02 14:11:25,393 [foster.py] => Task 5, Epoch 1/170 => Loss 6.176, Loss_clf 1.541, Loss_fe 2.113, Loss_kd 2.437, Train_accy 56.20
2024-08-02 14:11:29,072 [foster.py] => Task 5, Epoch 2/170 => Loss 4.242, Loss_clf 0.793, Loss_fe 0.948, Loss_kd 2.416, Train_accy 64.17, Test_accy 73.95
2024-08-02 14:11:32,797 [foster.py] => Task 5, Epoch 3/170 => Loss 3.970, Loss_clf 0.676, Loss_fe 0.814, Loss_kd 2.395, Train_accy 63.94, Test_accy 74.38
2024-08-02 14:11:36,475 [foster.py] => Task 5, Epoch 4/170 => Loss 3.784, Loss_clf 0.605, Loss_fe 0.714, Loss_kd 2.380, Train_accy 65.74, Test_accy 75.05
2024-08-02 14:11:40,155 [foster.py] => Task 5, Epoch 5/170 => Loss 3.770, Loss_clf 0.638, Loss_fe 0.655, Loss_kd 2.393, Train_accy 65.32, Test_accy 75.35
2024-08-02 14:11:42,381 [foster.py] => Task 5, Epoch 6/170 => Loss 3.712, Loss_clf 0.603, Loss_fe 0.619, Loss_kd 2.405, Train_accy 66.71
2024-08-02 14:11:46,095 [foster.py] => Task 5, Epoch 7/170 => Loss 3.637, Loss_clf 0.592, Loss_fe 0.595, Loss_kd 2.367, Train_accy 68.06, Test_accy 75.15
2024-08-02 14:11:49,819 [foster.py] => Task 5, Epoch 8/170 => Loss 3.675, Loss_clf 0.606, Loss_fe 0.570, Loss_kd 2.414, Train_accy 67.45, Test_accy 75.32
2024-08-02 14:11:53,549 [foster.py] => Task 5, Epoch 9/170 => Loss 3.580, Loss_clf 0.554, Loss_fe 0.550, Loss_kd 2.392, Train_accy 70.32, Test_accy 75.13
2024-08-02 14:11:57,221 [foster.py] => Task 5, Epoch 10/170 => Loss 3.566, Loss_clf 0.552, Loss_fe 0.538, Loss_kd 2.392, Train_accy 70.05, Test_accy 75.18
2024-08-02 14:11:59,453 [foster.py] => Task 5, Epoch 11/170 => Loss 3.574, Loss_clf 0.574, Loss_fe 0.528, Loss_kd 2.388, Train_accy 69.26
2024-08-02 14:12:03,123 [foster.py] => Task 5, Epoch 12/170 => Loss 3.610, Loss_clf 0.582, Loss_fe 0.549, Loss_kd 2.396, Train_accy 70.56, Test_accy 75.73
2024-08-02 14:12:06,817 [foster.py] => Task 5, Epoch 13/170 => Loss 3.570, Loss_clf 0.570, Loss_fe 0.518, Loss_kd 2.397, Train_accy 68.70, Test_accy 75.18
2024-08-02 14:12:10,537 [foster.py] => Task 5, Epoch 14/170 => Loss 3.533, Loss_clf 0.556, Loss_fe 0.509, Loss_kd 2.384, Train_accy 73.06, Test_accy 75.57
2024-08-02 14:12:14,253 [foster.py] => Task 5, Epoch 15/170 => Loss 3.560, Loss_clf 0.566, Loss_fe 0.496, Loss_kd 2.414, Train_accy 70.37, Test_accy 75.63
2024-08-02 14:12:16,493 [foster.py] => Task 5, Epoch 16/170 => Loss 3.454, Loss_clf 0.518, Loss_fe 0.483, Loss_kd 2.370, Train_accy 72.22
2024-08-02 14:12:20,170 [foster.py] => Task 5, Epoch 17/170 => Loss 3.463, Loss_clf 0.523, Loss_fe 0.483, Loss_kd 2.373, Train_accy 71.85, Test_accy 75.05
2024-08-02 14:12:23,871 [foster.py] => Task 5, Epoch 18/170 => Loss 3.539, Loss_clf 0.571, Loss_fe 0.477, Loss_kd 2.406, Train_accy 71.62, Test_accy 75.72
2024-08-02 14:12:27,590 [foster.py] => Task 5, Epoch 19/170 => Loss 3.470, Loss_clf 0.531, Loss_fe 0.448, Loss_kd 2.406, Train_accy 71.71, Test_accy 75.42
2024-08-02 14:12:31,267 [foster.py] => Task 5, Epoch 20/170 => Loss 3.416, Loss_clf 0.513, Loss_fe 0.445, Loss_kd 2.375, Train_accy 72.18, Test_accy 75.63
2024-08-02 14:12:33,501 [foster.py] => Task 5, Epoch 21/170 => Loss 3.395, Loss_clf 0.494, Loss_fe 0.436, Loss_kd 2.381, Train_accy 72.82
2024-08-02 14:12:37,228 [foster.py] => Task 5, Epoch 22/170 => Loss 3.440, Loss_clf 0.527, Loss_fe 0.437, Loss_kd 2.392, Train_accy 72.08, Test_accy 76.03
2024-08-02 14:12:40,935 [foster.py] => Task 5, Epoch 23/170 => Loss 3.423, Loss_clf 0.521, Loss_fe 0.416, Loss_kd 2.402, Train_accy 74.26, Test_accy 75.87
2024-08-02 14:12:44,629 [foster.py] => Task 5, Epoch 24/170 => Loss 3.452, Loss_clf 0.530, Loss_fe 0.416, Loss_kd 2.421, Train_accy 73.43, Test_accy 75.48
2024-08-02 14:12:48,316 [foster.py] => Task 5, Epoch 25/170 => Loss 3.395, Loss_clf 0.490, Loss_fe 0.424, Loss_kd 2.397, Train_accy 74.44, Test_accy 75.75
2024-08-02 14:12:50,533 [foster.py] => Task 5, Epoch 26/170 => Loss 3.289, Loss_clf 0.461, Loss_fe 0.379, Loss_kd 2.365, Train_accy 75.65
2024-08-02 14:12:54,208 [foster.py] => Task 5, Epoch 27/170 => Loss 3.400, Loss_clf 0.505, Loss_fe 0.413, Loss_kd 2.397, Train_accy 73.98, Test_accy 75.87
2024-08-02 14:12:57,866 [foster.py] => Task 5, Epoch 28/170 => Loss 3.356, Loss_clf 0.503, Loss_fe 0.397, Loss_kd 2.373, Train_accy 74.07, Test_accy 75.92
2024-08-02 14:13:01,553 [foster.py] => Task 5, Epoch 29/170 => Loss 3.377, Loss_clf 0.500, Loss_fe 0.414, Loss_kd 2.380, Train_accy 74.54, Test_accy 73.88
2024-08-02 14:13:05,251 [foster.py] => Task 5, Epoch 30/170 => Loss 3.277, Loss_clf 0.445, Loss_fe 0.363, Loss_kd 2.385, Train_accy 74.68, Test_accy 75.88
2024-08-02 14:13:07,487 [foster.py] => Task 5, Epoch 31/170 => Loss 3.357, Loss_clf 0.497, Loss_fe 0.378, Loss_kd 2.398, Train_accy 76.76
2024-08-02 14:13:11,168 [foster.py] => Task 5, Epoch 32/170 => Loss 3.319, Loss_clf 0.473, Loss_fe 0.386, Loss_kd 2.377, Train_accy 76.25, Test_accy 75.53
2024-08-02 14:13:14,850 [foster.py] => Task 5, Epoch 33/170 => Loss 3.349, Loss_clf 0.486, Loss_fe 0.392, Loss_kd 2.386, Train_accy 74.49, Test_accy 75.88
2024-08-02 14:13:18,554 [foster.py] => Task 5, Epoch 34/170 => Loss 3.309, Loss_clf 0.489, Loss_fe 0.369, Loss_kd 2.367, Train_accy 76.81, Test_accy 75.37
2024-08-02 14:13:22,231 [foster.py] => Task 5, Epoch 35/170 => Loss 3.322, Loss_clf 0.490, Loss_fe 0.382, Loss_kd 2.367, Train_accy 74.68, Test_accy 75.25
2024-08-02 14:13:24,478 [foster.py] => Task 5, Epoch 36/170 => Loss 3.356, Loss_clf 0.491, Loss_fe 0.392, Loss_kd 2.389, Train_accy 75.09
2024-08-02 14:13:28,235 [foster.py] => Task 5, Epoch 37/170 => Loss 3.328, Loss_clf 0.469, Loss_fe 0.379, Loss_kd 2.395, Train_accy 77.50, Test_accy 75.72
2024-08-02 14:13:31,928 [foster.py] => Task 5, Epoch 38/170 => Loss 3.217, Loss_clf 0.435, Loss_fe 0.344, Loss_kd 2.355, Train_accy 76.81, Test_accy 75.68
2024-08-02 14:13:35,594 [foster.py] => Task 5, Epoch 39/170 => Loss 3.284, Loss_clf 0.465, Loss_fe 0.348, Loss_kd 2.388, Train_accy 76.71, Test_accy 76.08
2024-08-02 14:13:39,284 [foster.py] => Task 5, Epoch 40/170 => Loss 3.235, Loss_clf 0.432, Loss_fe 0.348, Loss_kd 2.372, Train_accy 77.82, Test_accy 76.00
2024-08-02 14:13:41,518 [foster.py] => Task 5, Epoch 41/170 => Loss 3.250, Loss_clf 0.453, Loss_fe 0.316, Loss_kd 2.397, Train_accy 77.45
2024-08-02 14:13:45,228 [foster.py] => Task 5, Epoch 42/170 => Loss 3.374, Loss_clf 0.502, Loss_fe 0.377, Loss_kd 2.410, Train_accy 76.62, Test_accy 75.85
2024-08-02 14:13:48,946 [foster.py] => Task 5, Epoch 43/170 => Loss 3.290, Loss_clf 0.462, Loss_fe 0.331, Loss_kd 2.413, Train_accy 76.90, Test_accy 75.73
2024-08-02 14:13:52,714 [foster.py] => Task 5, Epoch 44/170 => Loss 3.241, Loss_clf 0.444, Loss_fe 0.334, Loss_kd 2.379, Train_accy 77.04, Test_accy 75.95
2024-08-02 14:13:56,369 [foster.py] => Task 5, Epoch 45/170 => Loss 3.292, Loss_clf 0.464, Loss_fe 0.339, Loss_kd 2.405, Train_accy 76.90, Test_accy 76.13
2024-08-02 14:13:58,652 [foster.py] => Task 5, Epoch 46/170 => Loss 3.245, Loss_clf 0.442, Loss_fe 0.340, Loss_kd 2.379, Train_accy 77.04
2024-08-02 14:14:02,358 [foster.py] => Task 5, Epoch 47/170 => Loss 3.246, Loss_clf 0.439, Loss_fe 0.332, Loss_kd 2.391, Train_accy 78.24, Test_accy 76.48
2024-08-02 14:14:06,049 [foster.py] => Task 5, Epoch 48/170 => Loss 3.270, Loss_clf 0.452, Loss_fe 0.339, Loss_kd 2.395, Train_accy 77.64, Test_accy 75.27
2024-08-02 14:14:09,767 [foster.py] => Task 5, Epoch 49/170 => Loss 3.274, Loss_clf 0.449, Loss_fe 0.333, Loss_kd 2.408, Train_accy 76.30, Test_accy 76.35
2024-08-02 14:14:13,462 [foster.py] => Task 5, Epoch 50/170 => Loss 3.268, Loss_clf 0.457, Loss_fe 0.334, Loss_kd 2.392, Train_accy 77.41, Test_accy 75.27
2024-08-02 14:14:15,705 [foster.py] => Task 5, Epoch 51/170 => Loss 3.264, Loss_clf 0.452, Loss_fe 0.327, Loss_kd 2.400, Train_accy 77.45
2024-08-02 14:14:19,390 [foster.py] => Task 5, Epoch 52/170 => Loss 3.209, Loss_clf 0.428, Loss_fe 0.316, Loss_kd 2.382, Train_accy 77.27, Test_accy 76.00
2024-08-02 14:14:23,080 [foster.py] => Task 5, Epoch 53/170 => Loss 3.122, Loss_clf 0.387, Loss_fe 0.300, Loss_kd 2.353, Train_accy 79.21, Test_accy 75.82
2024-08-02 14:14:26,791 [foster.py] => Task 5, Epoch 54/170 => Loss 3.175, Loss_clf 0.416, Loss_fe 0.282, Loss_kd 2.392, Train_accy 79.95, Test_accy 76.43
2024-08-02 14:14:30,503 [foster.py] => Task 5, Epoch 55/170 => Loss 3.210, Loss_clf 0.430, Loss_fe 0.305, Loss_kd 2.391, Train_accy 79.54, Test_accy 76.18
2024-08-02 14:14:32,743 [foster.py] => Task 5, Epoch 56/170 => Loss 3.159, Loss_clf 0.403, Loss_fe 0.296, Loss_kd 2.376, Train_accy 78.19
2024-08-02 14:14:36,456 [foster.py] => Task 5, Epoch 57/170 => Loss 3.218, Loss_clf 0.439, Loss_fe 0.326, Loss_kd 2.370, Train_accy 77.69, Test_accy 76.03
2024-08-02 14:14:40,127 [foster.py] => Task 5, Epoch 58/170 => Loss 3.166, Loss_clf 0.422, Loss_fe 0.284, Loss_kd 2.376, Train_accy 78.29, Test_accy 76.07
2024-08-02 14:14:43,844 [foster.py] => Task 5, Epoch 59/170 => Loss 3.203, Loss_clf 0.446, Loss_fe 0.298, Loss_kd 2.375, Train_accy 78.33, Test_accy 75.73
2024-08-02 14:14:47,593 [foster.py] => Task 5, Epoch 60/170 => Loss 3.124, Loss_clf 0.392, Loss_fe 0.281, Loss_kd 2.368, Train_accy 80.00, Test_accy 75.92
2024-08-02 14:14:49,819 [foster.py] => Task 5, Epoch 61/170 => Loss 3.167, Loss_clf 0.414, Loss_fe 0.279, Loss_kd 2.391, Train_accy 81.11
2024-08-02 14:14:53,540 [foster.py] => Task 5, Epoch 62/170 => Loss 3.136, Loss_clf 0.407, Loss_fe 0.274, Loss_kd 2.371, Train_accy 79.86, Test_accy 75.82
2024-08-02 14:14:57,251 [foster.py] => Task 5, Epoch 63/170 => Loss 3.113, Loss_clf 0.409, Loss_fe 0.261, Loss_kd 2.360, Train_accy 79.26, Test_accy 76.02
2024-08-02 14:15:00,922 [foster.py] => Task 5, Epoch 64/170 => Loss 3.085, Loss_clf 0.383, Loss_fe 0.251, Loss_kd 2.368, Train_accy 78.47, Test_accy 76.27
2024-08-02 14:15:04,609 [foster.py] => Task 5, Epoch 65/170 => Loss 3.180, Loss_clf 0.423, Loss_fe 0.283, Loss_kd 2.390, Train_accy 79.91, Test_accy 76.60
2024-08-02 14:15:06,875 [foster.py] => Task 5, Epoch 66/170 => Loss 3.090, Loss_clf 0.372, Loss_fe 0.269, Loss_kd 2.365, Train_accy 79.77
2024-08-02 14:15:10,599 [foster.py] => Task 5, Epoch 67/170 => Loss 3.189, Loss_clf 0.433, Loss_fe 0.283, Loss_kd 2.390, Train_accy 79.21, Test_accy 75.78
2024-08-02 14:15:14,329 [foster.py] => Task 5, Epoch 68/170 => Loss 3.133, Loss_clf 0.395, Loss_fe 0.276, Loss_kd 2.379, Train_accy 80.60, Test_accy 75.83
2024-08-02 14:15:18,021 [foster.py] => Task 5, Epoch 69/170 => Loss 3.074, Loss_clf 0.370, Loss_fe 0.247, Loss_kd 2.373, Train_accy 82.13, Test_accy 76.07
2024-08-02 14:15:21,718 [foster.py] => Task 5, Epoch 70/170 => Loss 3.132, Loss_clf 0.413, Loss_fe 0.238, Loss_kd 2.396, Train_accy 80.28, Test_accy 75.57
2024-08-02 14:15:23,984 [foster.py] => Task 5, Epoch 71/170 => Loss 3.206, Loss_clf 0.431, Loss_fe 0.294, Loss_kd 2.396, Train_accy 79.35
2024-08-02 14:15:27,660 [foster.py] => Task 5, Epoch 72/170 => Loss 3.127, Loss_clf 0.386, Loss_fe 0.246, Loss_kd 2.410, Train_accy 81.25, Test_accy 75.97
2024-08-02 14:15:31,376 [foster.py] => Task 5, Epoch 73/170 => Loss 3.179, Loss_clf 0.418, Loss_fe 0.273, Loss_kd 2.404, Train_accy 79.86, Test_accy 75.72
2024-08-02 14:15:35,064 [foster.py] => Task 5, Epoch 74/170 => Loss 3.133, Loss_clf 0.394, Loss_fe 0.252, Loss_kd 2.402, Train_accy 81.06, Test_accy 76.12
2024-08-02 14:15:38,741 [foster.py] => Task 5, Epoch 75/170 => Loss 3.157, Loss_clf 0.414, Loss_fe 0.272, Loss_kd 2.387, Train_accy 79.95, Test_accy 76.22
2024-08-02 14:15:40,979 [foster.py] => Task 5, Epoch 76/170 => Loss 3.122, Loss_clf 0.409, Loss_fe 0.252, Loss_kd 2.377, Train_accy 79.54
2024-08-02 14:15:44,704 [foster.py] => Task 5, Epoch 77/170 => Loss 3.072, Loss_clf 0.383, Loss_fe 0.226, Loss_kd 2.380, Train_accy 80.97, Test_accy 76.17
2024-08-02 14:15:48,391 [foster.py] => Task 5, Epoch 78/170 => Loss 3.138, Loss_clf 0.403, Loss_fe 0.268, Loss_kd 2.384, Train_accy 80.05, Test_accy 76.18
2024-08-02 14:15:52,069 [foster.py] => Task 5, Epoch 79/170 => Loss 3.120, Loss_clf 0.398, Loss_fe 0.256, Loss_kd 2.382, Train_accy 81.39, Test_accy 75.87
2024-08-02 14:15:55,745 [foster.py] => Task 5, Epoch 80/170 => Loss 3.054, Loss_clf 0.369, Loss_fe 0.222, Loss_kd 2.380, Train_accy 81.11, Test_accy 76.43
2024-08-02 14:15:57,974 [foster.py] => Task 5, Epoch 81/170 => Loss 3.077, Loss_clf 0.368, Loss_fe 0.229, Loss_kd 2.396, Train_accy 81.57
2024-08-02 14:16:01,696 [foster.py] => Task 5, Epoch 82/170 => Loss 3.072, Loss_clf 0.376, Loss_fe 0.228, Loss_kd 2.384, Train_accy 82.36, Test_accy 75.82
2024-08-02 14:16:05,471 [foster.py] => Task 5, Epoch 83/170 => Loss 3.095, Loss_clf 0.381, Loss_fe 0.242, Loss_kd 2.388, Train_accy 81.94, Test_accy 76.58
2024-08-02 14:16:09,158 [foster.py] => Task 5, Epoch 84/170 => Loss 3.091, Loss_clf 0.392, Loss_fe 0.228, Loss_kd 2.387, Train_accy 82.78, Test_accy 76.02
2024-08-02 14:16:12,847 [foster.py] => Task 5, Epoch 85/170 => Loss 3.140, Loss_clf 0.415, Loss_fe 0.236, Loss_kd 2.404, Train_accy 81.48, Test_accy 76.22
2024-08-02 14:16:15,093 [foster.py] => Task 5, Epoch 86/170 => Loss 3.080, Loss_clf 0.377, Loss_fe 0.229, Loss_kd 2.390, Train_accy 81.20
2024-08-02 14:16:18,760 [foster.py] => Task 5, Epoch 87/170 => Loss 3.076, Loss_clf 0.379, Loss_fe 0.212, Loss_kd 2.402, Train_accy 81.81, Test_accy 76.22
2024-08-02 14:16:22,553 [foster.py] => Task 5, Epoch 88/170 => Loss 3.034, Loss_clf 0.361, Loss_fe 0.212, Loss_kd 2.377, Train_accy 82.13, Test_accy 76.15
2024-08-02 14:16:26,322 [foster.py] => Task 5, Epoch 89/170 => Loss 3.071, Loss_clf 0.379, Loss_fe 0.218, Loss_kd 2.390, Train_accy 84.31, Test_accy 76.20
2024-08-02 14:16:30,116 [foster.py] => Task 5, Epoch 90/170 => Loss 3.088, Loss_clf 0.392, Loss_fe 0.229, Loss_kd 2.384, Train_accy 81.25, Test_accy 76.22
2024-08-02 14:16:32,370 [foster.py] => Task 5, Epoch 91/170 => Loss 3.091, Loss_clf 0.398, Loss_fe 0.214, Loss_kd 2.394, Train_accy 82.64
2024-08-02 14:16:36,090 [foster.py] => Task 5, Epoch 92/170 => Loss 3.030, Loss_clf 0.345, Loss_fe 0.209, Loss_kd 2.392, Train_accy 83.84, Test_accy 76.37
2024-08-02 14:16:39,778 [foster.py] => Task 5, Epoch 93/170 => Loss 3.064, Loss_clf 0.370, Loss_fe 0.219, Loss_kd 2.391, Train_accy 81.62, Test_accy 76.75
2024-08-02 14:16:43,479 [foster.py] => Task 5, Epoch 94/170 => Loss 3.028, Loss_clf 0.360, Loss_fe 0.196, Loss_kd 2.389, Train_accy 83.47, Test_accy 76.25
2024-08-02 14:16:47,177 [foster.py] => Task 5, Epoch 95/170 => Loss 3.079, Loss_clf 0.384, Loss_fe 0.207, Loss_kd 2.403, Train_accy 82.36, Test_accy 76.27
2024-08-02 14:16:49,407 [foster.py] => Task 5, Epoch 96/170 => Loss 2.992, Loss_clf 0.342, Loss_fe 0.181, Loss_kd 2.385, Train_accy 83.80
2024-08-02 14:16:53,082 [foster.py] => Task 5, Epoch 97/170 => Loss 3.034, Loss_clf 0.362, Loss_fe 0.191, Loss_kd 2.397, Train_accy 82.22, Test_accy 76.08
2024-08-02 14:16:56,758 [foster.py] => Task 5, Epoch 98/170 => Loss 3.070, Loss_clf 0.384, Loss_fe 0.199, Loss_kd 2.402, Train_accy 82.96, Test_accy 75.90
2024-08-02 14:17:00,429 [foster.py] => Task 5, Epoch 99/170 => Loss 3.106, Loss_clf 0.390, Loss_fe 0.229, Loss_kd 2.402, Train_accy 81.85, Test_accy 76.23
2024-08-02 14:17:04,155 [foster.py] => Task 5, Epoch 100/170 => Loss 3.048, Loss_clf 0.370, Loss_fe 0.203, Loss_kd 2.392, Train_accy 81.94, Test_accy 75.97
2024-08-02 14:17:06,416 [foster.py] => Task 5, Epoch 101/170 => Loss 3.056, Loss_clf 0.376, Loss_fe 0.204, Loss_kd 2.392, Train_accy 82.59
2024-08-02 14:17:10,099 [foster.py] => Task 5, Epoch 102/170 => Loss 2.993, Loss_clf 0.348, Loss_fe 0.194, Loss_kd 2.368, Train_accy 83.29, Test_accy 75.93
2024-08-02 14:17:13,829 [foster.py] => Task 5, Epoch 103/170 => Loss 3.029, Loss_clf 0.355, Loss_fe 0.189, Loss_kd 2.401, Train_accy 83.43, Test_accy 76.05
2024-08-02 14:17:17,590 [foster.py] => Task 5, Epoch 104/170 => Loss 3.067, Loss_clf 0.368, Loss_fe 0.220, Loss_kd 2.395, Train_accy 83.61, Test_accy 76.30
2024-08-02 14:17:21,380 [foster.py] => Task 5, Epoch 105/170 => Loss 3.000, Loss_clf 0.349, Loss_fe 0.182, Loss_kd 2.385, Train_accy 82.96, Test_accy 76.22
2024-08-02 14:17:23,751 [foster.py] => Task 5, Epoch 106/170 => Loss 2.962, Loss_clf 0.337, Loss_fe 0.181, Loss_kd 2.362, Train_accy 83.56
2024-08-02 14:17:27,528 [foster.py] => Task 5, Epoch 107/170 => Loss 3.039, Loss_clf 0.357, Loss_fe 0.205, Loss_kd 2.393, Train_accy 83.98, Test_accy 76.67
2024-08-02 14:17:31,325 [foster.py] => Task 5, Epoch 108/170 => Loss 2.948, Loss_clf 0.323, Loss_fe 0.167, Loss_kd 2.375, Train_accy 84.72, Test_accy 76.25
2024-08-02 14:17:35,014 [foster.py] => Task 5, Epoch 109/170 => Loss 3.030, Loss_clf 0.362, Loss_fe 0.180, Loss_kd 2.403, Train_accy 84.58, Test_accy 76.60
2024-08-02 14:17:38,712 [foster.py] => Task 5, Epoch 110/170 => Loss 3.067, Loss_clf 0.378, Loss_fe 0.191, Loss_kd 2.413, Train_accy 83.56, Test_accy 76.27
2024-08-02 14:17:40,963 [foster.py] => Task 5, Epoch 111/170 => Loss 2.988, Loss_clf 0.343, Loss_fe 0.166, Loss_kd 2.395, Train_accy 85.09
2024-08-02 14:17:44,658 [foster.py] => Task 5, Epoch 112/170 => Loss 3.029, Loss_clf 0.347, Loss_fe 0.185, Loss_kd 2.412, Train_accy 83.52, Test_accy 76.38
2024-08-02 14:17:48,371 [foster.py] => Task 5, Epoch 113/170 => Loss 2.976, Loss_clf 0.324, Loss_fe 0.171, Loss_kd 2.397, Train_accy 83.89, Test_accy 76.37
2024-08-02 14:17:52,098 [foster.py] => Task 5, Epoch 114/170 => Loss 2.977, Loss_clf 0.336, Loss_fe 0.165, Loss_kd 2.392, Train_accy 85.28, Test_accy 76.40
2024-08-02 14:17:55,827 [foster.py] => Task 5, Epoch 115/170 => Loss 2.889, Loss_clf 0.294, Loss_fe 0.149, Loss_kd 2.363, Train_accy 85.88, Test_accy 76.30
2024-08-02 14:17:58,095 [foster.py] => Task 5, Epoch 116/170 => Loss 2.916, Loss_clf 0.324, Loss_fe 0.168, Loss_kd 2.342, Train_accy 84.95
2024-08-02 14:18:01,807 [foster.py] => Task 5, Epoch 117/170 => Loss 2.946, Loss_clf 0.324, Loss_fe 0.166, Loss_kd 2.373, Train_accy 85.05, Test_accy 76.08
2024-08-02 14:18:05,529 [foster.py] => Task 5, Epoch 118/170 => Loss 2.975, Loss_clf 0.344, Loss_fe 0.170, Loss_kd 2.377, Train_accy 83.66, Test_accy 75.95
2024-08-02 14:18:09,225 [foster.py] => Task 5, Epoch 119/170 => Loss 3.016, Loss_clf 0.362, Loss_fe 0.175, Loss_kd 2.395, Train_accy 84.12, Test_accy 76.23
2024-08-02 14:18:12,954 [foster.py] => Task 5, Epoch 120/170 => Loss 2.997, Loss_clf 0.347, Loss_fe 0.179, Loss_kd 2.387, Train_accy 84.26, Test_accy 76.10
2024-08-02 14:18:15,198 [foster.py] => Task 5, Epoch 121/170 => Loss 2.934, Loss_clf 0.322, Loss_fe 0.167, Loss_kd 2.362, Train_accy 85.51
2024-08-02 14:18:18,886 [foster.py] => Task 5, Epoch 122/170 => Loss 2.965, Loss_clf 0.335, Loss_fe 0.166, Loss_kd 2.381, Train_accy 85.65, Test_accy 76.12
2024-08-02 14:18:22,602 [foster.py] => Task 5, Epoch 123/170 => Loss 2.986, Loss_clf 0.341, Loss_fe 0.160, Loss_kd 2.401, Train_accy 84.86, Test_accy 76.37
2024-08-02 14:18:26,285 [foster.py] => Task 5, Epoch 124/170 => Loss 2.955, Loss_clf 0.324, Loss_fe 0.166, Loss_kd 2.382, Train_accy 85.51, Test_accy 76.38
2024-08-02 14:18:29,968 [foster.py] => Task 5, Epoch 125/170 => Loss 2.933, Loss_clf 0.308, Loss_fe 0.164, Loss_kd 2.377, Train_accy 86.67, Test_accy 76.33
2024-08-02 14:18:32,178 [foster.py] => Task 5, Epoch 126/170 => Loss 2.944, Loss_clf 0.314, Loss_fe 0.164, Loss_kd 2.383, Train_accy 85.37
2024-08-02 14:18:35,868 [foster.py] => Task 5, Epoch 127/170 => Loss 2.908, Loss_clf 0.303, Loss_fe 0.144, Loss_kd 2.378, Train_accy 85.32, Test_accy 76.15
2024-08-02 14:18:39,565 [foster.py] => Task 5, Epoch 128/170 => Loss 2.915, Loss_clf 0.313, Loss_fe 0.142, Loss_kd 2.377, Train_accy 85.79, Test_accy 76.05
2024-08-02 14:18:43,306 [foster.py] => Task 5, Epoch 129/170 => Loss 2.984, Loss_clf 0.339, Loss_fe 0.157, Loss_kd 2.404, Train_accy 84.86, Test_accy 76.05
2024-08-02 14:18:47,012 [foster.py] => Task 5, Epoch 130/170 => Loss 2.977, Loss_clf 0.340, Loss_fe 0.164, Loss_kd 2.389, Train_accy 84.95, Test_accy 76.07
2024-08-02 14:18:49,248 [foster.py] => Task 5, Epoch 131/170 => Loss 2.964, Loss_clf 0.339, Loss_fe 0.163, Loss_kd 2.379, Train_accy 85.00
2024-08-02 14:18:52,980 [foster.py] => Task 5, Epoch 132/170 => Loss 2.947, Loss_clf 0.333, Loss_fe 0.154, Loss_kd 2.376, Train_accy 85.51, Test_accy 76.10
2024-08-02 14:18:56,669 [foster.py] => Task 5, Epoch 133/170 => Loss 2.925, Loss_clf 0.315, Loss_fe 0.145, Loss_kd 2.382, Train_accy 84.44, Test_accy 76.15
2024-08-02 14:19:00,372 [foster.py] => Task 5, Epoch 134/170 => Loss 3.020, Loss_clf 0.359, Loss_fe 0.161, Loss_kd 2.415, Train_accy 84.81, Test_accy 75.95
2024-08-02 14:19:04,089 [foster.py] => Task 5, Epoch 135/170 => Loss 2.990, Loss_clf 0.342, Loss_fe 0.162, Loss_kd 2.402, Train_accy 85.51, Test_accy 75.92
2024-08-02 14:19:06,306 [foster.py] => Task 5, Epoch 136/170 => Loss 2.948, Loss_clf 0.326, Loss_fe 0.156, Loss_kd 2.383, Train_accy 86.20
2024-08-02 14:19:09,993 [foster.py] => Task 5, Epoch 137/170 => Loss 2.940, Loss_clf 0.338, Loss_fe 0.151, Loss_kd 2.368, Train_accy 84.12, Test_accy 76.07
2024-08-02 14:19:13,711 [foster.py] => Task 5, Epoch 138/170 => Loss 2.907, Loss_clf 0.314, Loss_fe 0.143, Loss_kd 2.368, Train_accy 85.09, Test_accy 76.03
2024-08-02 14:19:17,517 [foster.py] => Task 5, Epoch 139/170 => Loss 3.001, Loss_clf 0.345, Loss_fe 0.160, Loss_kd 2.412, Train_accy 85.09, Test_accy 75.83
2024-08-02 14:19:21,214 [foster.py] => Task 5, Epoch 140/170 => Loss 2.921, Loss_clf 0.312, Loss_fe 0.147, Loss_kd 2.379, Train_accy 86.02, Test_accy 76.05
2024-08-02 14:19:23,453 [foster.py] => Task 5, Epoch 141/170 => Loss 2.951, Loss_clf 0.336, Loss_fe 0.141, Loss_kd 2.390, Train_accy 86.02
2024-08-02 14:19:27,120 [foster.py] => Task 5, Epoch 142/170 => Loss 2.970, Loss_clf 0.316, Loss_fe 0.156, Loss_kd 2.414, Train_accy 85.60, Test_accy 76.15
2024-08-02 14:19:30,837 [foster.py] => Task 5, Epoch 143/170 => Loss 2.954, Loss_clf 0.336, Loss_fe 0.144, Loss_kd 2.390, Train_accy 84.44, Test_accy 76.15
2024-08-02 14:19:34,522 [foster.py] => Task 5, Epoch 144/170 => Loss 2.897, Loss_clf 0.309, Loss_fe 0.126, Loss_kd 2.378, Train_accy 84.86, Test_accy 76.05
2024-08-02 14:19:38,247 [foster.py] => Task 5, Epoch 145/170 => Loss 2.897, Loss_clf 0.295, Loss_fe 0.129, Loss_kd 2.389, Train_accy 87.22, Test_accy 76.07
2024-08-02 14:19:40,488 [foster.py] => Task 5, Epoch 146/170 => Loss 2.962, Loss_clf 0.329, Loss_fe 0.159, Loss_kd 2.390, Train_accy 85.60
2024-08-02 14:19:44,202 [foster.py] => Task 5, Epoch 147/170 => Loss 2.934, Loss_clf 0.320, Loss_fe 0.139, Loss_kd 2.391, Train_accy 85.88, Test_accy 76.00
2024-08-02 14:19:47,906 [foster.py] => Task 5, Epoch 148/170 => Loss 2.879, Loss_clf 0.289, Loss_fe 0.121, Loss_kd 2.384, Train_accy 86.67, Test_accy 76.10
2024-08-02 14:19:51,591 [foster.py] => Task 5, Epoch 149/170 => Loss 2.968, Loss_clf 0.344, Loss_fe 0.154, Loss_kd 2.387, Train_accy 85.14, Test_accy 76.08
2024-08-02 14:19:55,268 [foster.py] => Task 5, Epoch 150/170 => Loss 2.934, Loss_clf 0.316, Loss_fe 0.141, Loss_kd 2.393, Train_accy 85.83, Test_accy 76.25
2024-08-02 14:19:57,534 [foster.py] => Task 5, Epoch 151/170 => Loss 2.970, Loss_clf 0.346, Loss_fe 0.153, Loss_kd 2.388, Train_accy 85.65
2024-08-02 14:20:01,313 [foster.py] => Task 5, Epoch 152/170 => Loss 2.904, Loss_clf 0.310, Loss_fe 0.135, Loss_kd 2.375, Train_accy 86.81, Test_accy 76.18
2024-08-02 14:20:05,039 [foster.py] => Task 5, Epoch 153/170 => Loss 2.914, Loss_clf 0.323, Loss_fe 0.133, Loss_kd 2.375, Train_accy 86.11, Test_accy 76.17
2024-08-02 14:20:08,738 [foster.py] => Task 5, Epoch 154/170 => Loss 2.940, Loss_clf 0.321, Loss_fe 0.139, Loss_kd 2.396, Train_accy 85.93, Test_accy 76.12
2024-08-02 14:20:12,441 [foster.py] => Task 5, Epoch 155/170 => Loss 2.972, Loss_clf 0.348, Loss_fe 0.139, Loss_kd 2.401, Train_accy 85.42, Test_accy 76.08
2024-08-02 14:20:14,689 [foster.py] => Task 5, Epoch 156/170 => Loss 2.895, Loss_clf 0.301, Loss_fe 0.137, Loss_kd 2.373, Train_accy 86.76
2024-08-02 14:20:18,404 [foster.py] => Task 5, Epoch 157/170 => Loss 2.832, Loss_clf 0.264, Loss_fe 0.123, Loss_kd 2.362, Train_accy 87.69, Test_accy 76.23
2024-08-02 14:20:22,086 [foster.py] => Task 5, Epoch 158/170 => Loss 2.912, Loss_clf 0.301, Loss_fe 0.135, Loss_kd 2.392, Train_accy 85.60, Test_accy 76.12
2024-08-02 14:20:25,855 [foster.py] => Task 5, Epoch 159/170 => Loss 2.940, Loss_clf 0.321, Loss_fe 0.141, Loss_kd 2.394, Train_accy 85.05, Test_accy 76.23
2024-08-02 14:20:29,537 [foster.py] => Task 5, Epoch 160/170 => Loss 2.965, Loss_clf 0.328, Loss_fe 0.161, Loss_kd 2.393, Train_accy 86.85, Test_accy 76.10
2024-08-02 14:20:31,794 [foster.py] => Task 5, Epoch 161/170 => Loss 2.964, Loss_clf 0.339, Loss_fe 0.149, Loss_kd 2.393, Train_accy 84.77
2024-08-02 14:20:35,535 [foster.py] => Task 5, Epoch 162/170 => Loss 2.894, Loss_clf 0.296, Loss_fe 0.134, Loss_kd 2.381, Train_accy 87.31, Test_accy 76.18
2024-08-02 14:20:39,207 [foster.py] => Task 5, Epoch 163/170 => Loss 2.921, Loss_clf 0.306, Loss_fe 0.144, Loss_kd 2.387, Train_accy 85.74, Test_accy 76.07
2024-08-02 14:20:42,913 [foster.py] => Task 5, Epoch 164/170 => Loss 2.946, Loss_clf 0.320, Loss_fe 0.149, Loss_kd 2.393, Train_accy 85.74, Test_accy 76.15
2024-08-02 14:20:46,597 [foster.py] => Task 5, Epoch 165/170 => Loss 2.915, Loss_clf 0.317, Loss_fe 0.141, Loss_kd 2.374, Train_accy 86.71, Test_accy 76.22
2024-08-02 14:20:48,892 [foster.py] => Task 5, Epoch 166/170 => Loss 2.918, Loss_clf 0.298, Loss_fe 0.133, Loss_kd 2.402, Train_accy 87.55
2024-08-02 14:20:52,607 [foster.py] => Task 5, Epoch 167/170 => Loss 2.948, Loss_clf 0.333, Loss_fe 0.130, Loss_kd 2.401, Train_accy 85.46, Test_accy 76.20
2024-08-02 14:20:56,369 [foster.py] => Task 5, Epoch 168/170 => Loss 2.946, Loss_clf 0.330, Loss_fe 0.133, Loss_kd 2.399, Train_accy 85.42, Test_accy 76.18
2024-08-02 14:21:00,144 [foster.py] => Task 5, Epoch 169/170 => Loss 2.932, Loss_clf 0.307, Loss_fe 0.142, Loss_kd 2.399, Train_accy 86.94, Test_accy 76.22
2024-08-02 14:21:03,867 [foster.py] => Task 5, Epoch 170/170 => Loss 2.914, Loss_clf 0.312, Loss_fe 0.128, Loss_kd 2.391, Train_accy 86.53, Test_accy 76.17
2024-08-02 14:21:03,871 [foster.py] => do not weight align teacher!
2024-08-02 14:21:03,874 [foster.py] => per cls weights : [1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668 1.01821668
 1.01821668 1.01821668 1.01821668 1.01821668 0.47171641 0.47171641]
2024-08-02 14:21:08,167 [foster.py] => SNet: Task 5, Epoch 1/130 => Loss 27.980,  Loss1 0.701, Train_accy 46.62, Test_accy 74.20
2024-08-02 14:21:11,265 [foster.py] => SNet: Task 5, Epoch 2/130 => Loss 27.955,  Loss1 0.700, Train_accy 51.39
2024-08-02 14:21:14,361 [foster.py] => SNet: Task 5, Epoch 3/130 => Loss 27.960,  Loss1 0.700, Train_accy 52.55
2024-08-02 14:21:17,459 [foster.py] => SNet: Task 5, Epoch 4/130 => Loss 27.940,  Loss1 0.700, Train_accy 52.13
2024-08-02 14:21:20,546 [foster.py] => SNet: Task 5, Epoch 5/130 => Loss 27.999,  Loss1 0.700, Train_accy 50.60
2024-08-02 14:21:24,587 [foster.py] => SNet: Task 5, Epoch 6/130 => Loss 27.955,  Loss1 0.699, Train_accy 53.29, Test_accy 74.25
2024-08-02 14:21:27,667 [foster.py] => SNet: Task 5, Epoch 7/130 => Loss 27.930,  Loss1 0.700, Train_accy 55.28
2024-08-02 14:21:30,741 [foster.py] => SNet: Task 5, Epoch 8/130 => Loss 27.918,  Loss1 0.700, Train_accy 55.32
2024-08-02 14:21:33,837 [foster.py] => SNet: Task 5, Epoch 9/130 => Loss 27.937,  Loss1 0.700, Train_accy 55.69
2024-08-02 14:21:36,930 [foster.py] => SNet: Task 5, Epoch 10/130 => Loss 27.948,  Loss1 0.699, Train_accy 56.53
2024-08-02 14:21:40,984 [foster.py] => SNet: Task 5, Epoch 11/130 => Loss 27.870,  Loss1 0.699, Train_accy 56.85, Test_accy 74.72
2024-08-02 14:21:44,067 [foster.py] => SNet: Task 5, Epoch 12/130 => Loss 27.946,  Loss1 0.699, Train_accy 56.11
2024-08-02 14:21:47,162 [foster.py] => SNet: Task 5, Epoch 13/130 => Loss 27.946,  Loss1 0.700, Train_accy 58.43
2024-08-02 14:21:50,235 [foster.py] => SNet: Task 5, Epoch 14/130 => Loss 27.907,  Loss1 0.699, Train_accy 57.31
2024-08-02 14:21:53,317 [foster.py] => SNet: Task 5, Epoch 15/130 => Loss 27.927,  Loss1 0.699, Train_accy 56.81
2024-08-02 14:21:57,385 [foster.py] => SNet: Task 5, Epoch 16/130 => Loss 27.834,  Loss1 0.699, Train_accy 58.10, Test_accy 74.40
2024-08-02 14:22:00,457 [foster.py] => SNet: Task 5, Epoch 17/130 => Loss 27.944,  Loss1 0.699, Train_accy 61.02
2024-08-02 14:22:03,563 [foster.py] => SNet: Task 5, Epoch 18/130 => Loss 27.954,  Loss1 0.699, Train_accy 58.61
2024-08-02 14:22:06,646 [foster.py] => SNet: Task 5, Epoch 19/130 => Loss 27.922,  Loss1 0.699, Train_accy 59.86
2024-08-02 14:22:09,730 [foster.py] => SNet: Task 5, Epoch 20/130 => Loss 27.921,  Loss1 0.699, Train_accy 59.95
2024-08-02 14:22:13,738 [foster.py] => SNet: Task 5, Epoch 21/130 => Loss 27.862,  Loss1 0.699, Train_accy 60.79, Test_accy 74.93
2024-08-02 14:22:16,894 [foster.py] => SNet: Task 5, Epoch 22/130 => Loss 27.912,  Loss1 0.699, Train_accy 59.58
2024-08-02 14:22:19,970 [foster.py] => SNet: Task 5, Epoch 23/130 => Loss 27.925,  Loss1 0.700, Train_accy 61.25
2024-08-02 14:22:23,075 [foster.py] => SNet: Task 5, Epoch 24/130 => Loss 27.946,  Loss1 0.700, Train_accy 60.93
2024-08-02 14:22:26,155 [foster.py] => SNet: Task 5, Epoch 25/130 => Loss 27.873,  Loss1 0.699, Train_accy 60.79
2024-08-02 14:22:30,198 [foster.py] => SNet: Task 5, Epoch 26/130 => Loss 27.887,  Loss1 0.700, Train_accy 61.53, Test_accy 74.97
2024-08-02 14:22:33,281 [foster.py] => SNet: Task 5, Epoch 27/130 => Loss 27.933,  Loss1 0.699, Train_accy 62.22
2024-08-02 14:22:36,352 [foster.py] => SNet: Task 5, Epoch 28/130 => Loss 27.925,  Loss1 0.699, Train_accy 61.67
2024-08-02 14:22:39,423 [foster.py] => SNet: Task 5, Epoch 29/130 => Loss 27.907,  Loss1 0.699, Train_accy 62.13
2024-08-02 14:22:42,493 [foster.py] => SNet: Task 5, Epoch 30/130 => Loss 27.925,  Loss1 0.699, Train_accy 62.22
2024-08-02 14:22:46,552 [foster.py] => SNet: Task 5, Epoch 31/130 => Loss 27.903,  Loss1 0.699, Train_accy 64.21, Test_accy 74.98
2024-08-02 14:22:49,661 [foster.py] => SNet: Task 5, Epoch 32/130 => Loss 27.910,  Loss1 0.699, Train_accy 63.47
2024-08-02 14:22:52,746 [foster.py] => SNet: Task 5, Epoch 33/130 => Loss 27.904,  Loss1 0.699, Train_accy 62.59
2024-08-02 14:22:55,830 [foster.py] => SNet: Task 5, Epoch 34/130 => Loss 27.892,  Loss1 0.699, Train_accy 62.82
2024-08-02 14:22:58,907 [foster.py] => SNet: Task 5, Epoch 35/130 => Loss 27.883,  Loss1 0.699, Train_accy 64.03
2024-08-02 14:23:02,954 [foster.py] => SNet: Task 5, Epoch 36/130 => Loss 27.896,  Loss1 0.699, Train_accy 63.29, Test_accy 75.20
2024-08-02 14:23:06,048 [foster.py] => SNet: Task 5, Epoch 37/130 => Loss 27.919,  Loss1 0.699, Train_accy 64.17
2024-08-02 14:23:09,121 [foster.py] => SNet: Task 5, Epoch 38/130 => Loss 27.922,  Loss1 0.699, Train_accy 64.44
2024-08-02 14:23:12,199 [foster.py] => SNet: Task 5, Epoch 39/130 => Loss 27.906,  Loss1 0.699, Train_accy 62.82
2024-08-02 14:23:15,292 [foster.py] => SNet: Task 5, Epoch 40/130 => Loss 27.902,  Loss1 0.699, Train_accy 63.56
2024-08-02 14:23:19,325 [foster.py] => SNet: Task 5, Epoch 41/130 => Loss 27.866,  Loss1 0.699, Train_accy 61.71, Test_accy 74.98
2024-08-02 14:23:22,393 [foster.py] => SNet: Task 5, Epoch 42/130 => Loss 27.922,  Loss1 0.699, Train_accy 64.31
2024-08-02 14:23:25,538 [foster.py] => SNet: Task 5, Epoch 43/130 => Loss 27.970,  Loss1 0.699, Train_accy 63.43
2024-08-02 14:23:28,665 [foster.py] => SNet: Task 5, Epoch 44/130 => Loss 27.891,  Loss1 0.699, Train_accy 63.89
2024-08-02 14:23:31,738 [foster.py] => SNet: Task 5, Epoch 45/130 => Loss 27.883,  Loss1 0.699, Train_accy 65.32
2024-08-02 14:23:35,814 [foster.py] => SNet: Task 5, Epoch 46/130 => Loss 27.901,  Loss1 0.699, Train_accy 64.31, Test_accy 75.52
2024-08-02 14:23:38,887 [foster.py] => SNet: Task 5, Epoch 47/130 => Loss 27.945,  Loss1 0.699, Train_accy 65.51
2024-08-02 14:23:41,952 [foster.py] => SNet: Task 5, Epoch 48/130 => Loss 27.920,  Loss1 0.699, Train_accy 64.72
2024-08-02 14:23:45,021 [foster.py] => SNet: Task 5, Epoch 49/130 => Loss 27.860,  Loss1 0.699, Train_accy 66.48
2024-08-02 14:23:48,121 [foster.py] => SNet: Task 5, Epoch 50/130 => Loss 27.956,  Loss1 0.699, Train_accy 64.95
2024-08-02 14:23:52,190 [foster.py] => SNet: Task 5, Epoch 51/130 => Loss 27.913,  Loss1 0.699, Train_accy 66.30, Test_accy 75.23
2024-08-02 14:23:55,278 [foster.py] => SNet: Task 5, Epoch 52/130 => Loss 27.933,  Loss1 0.698, Train_accy 64.68
2024-08-02 14:23:58,374 [foster.py] => SNet: Task 5, Epoch 53/130 => Loss 27.916,  Loss1 0.699, Train_accy 63.89
2024-08-02 14:24:01,474 [foster.py] => SNet: Task 5, Epoch 54/130 => Loss 27.902,  Loss1 0.699, Train_accy 64.95
2024-08-02 14:24:04,567 [foster.py] => SNet: Task 5, Epoch 55/130 => Loss 27.904,  Loss1 0.699, Train_accy 65.14
2024-08-02 14:24:08,599 [foster.py] => SNet: Task 5, Epoch 56/130 => Loss 27.955,  Loss1 0.699, Train_accy 64.40, Test_accy 75.22
2024-08-02 14:24:11,710 [foster.py] => SNet: Task 5, Epoch 57/130 => Loss 27.944,  Loss1 0.699, Train_accy 65.46
2024-08-02 14:24:14,803 [foster.py] => SNet: Task 5, Epoch 58/130 => Loss 27.874,  Loss1 0.699, Train_accy 64.54
2024-08-02 14:24:17,889 [foster.py] => SNet: Task 5, Epoch 59/130 => Loss 27.927,  Loss1 0.699, Train_accy 64.95
2024-08-02 14:24:21,009 [foster.py] => SNet: Task 5, Epoch 60/130 => Loss 27.885,  Loss1 0.699, Train_accy 67.27
2024-08-02 14:24:25,060 [foster.py] => SNet: Task 5, Epoch 61/130 => Loss 27.917,  Loss1 0.699, Train_accy 66.02, Test_accy 75.17
2024-08-02 14:24:28,130 [foster.py] => SNet: Task 5, Epoch 62/130 => Loss 27.912,  Loss1 0.699, Train_accy 65.23
2024-08-02 14:24:31,219 [foster.py] => SNet: Task 5, Epoch 63/130 => Loss 27.897,  Loss1 0.699, Train_accy 65.23
2024-08-02 14:24:34,358 [foster.py] => SNet: Task 5, Epoch 64/130 => Loss 27.876,  Loss1 0.699, Train_accy 66.67
2024-08-02 14:24:37,460 [foster.py] => SNet: Task 5, Epoch 65/130 => Loss 27.918,  Loss1 0.699, Train_accy 66.34
2024-08-02 14:24:41,490 [foster.py] => SNet: Task 5, Epoch 66/130 => Loss 27.926,  Loss1 0.699, Train_accy 65.56, Test_accy 75.13
2024-08-02 14:24:44,564 [foster.py] => SNet: Task 5, Epoch 67/130 => Loss 27.907,  Loss1 0.699, Train_accy 66.99
2024-08-02 14:24:47,657 [foster.py] => SNet: Task 5, Epoch 68/130 => Loss 27.892,  Loss1 0.699, Train_accy 67.04
2024-08-02 14:24:50,763 [foster.py] => SNet: Task 5, Epoch 69/130 => Loss 27.882,  Loss1 0.699, Train_accy 66.16
2024-08-02 14:24:53,856 [foster.py] => SNet: Task 5, Epoch 70/130 => Loss 27.887,  Loss1 0.699, Train_accy 66.06
2024-08-02 14:24:57,898 [foster.py] => SNet: Task 5, Epoch 71/130 => Loss 27.891,  Loss1 0.699, Train_accy 67.96, Test_accy 75.40
2024-08-02 14:25:00,992 [foster.py] => SNet: Task 5, Epoch 72/130 => Loss 27.896,  Loss1 0.698, Train_accy 66.16
2024-08-02 14:25:04,101 [foster.py] => SNet: Task 5, Epoch 73/130 => Loss 27.907,  Loss1 0.698, Train_accy 67.41
2024-08-02 14:25:07,195 [foster.py] => SNet: Task 5, Epoch 74/130 => Loss 27.910,  Loss1 0.699, Train_accy 66.16
2024-08-02 14:25:10,281 [foster.py] => SNet: Task 5, Epoch 75/130 => Loss 27.929,  Loss1 0.699, Train_accy 66.34
2024-08-02 14:25:14,318 [foster.py] => SNet: Task 5, Epoch 76/130 => Loss 27.892,  Loss1 0.699, Train_accy 68.66, Test_accy 75.35
2024-08-02 14:25:17,411 [foster.py] => SNet: Task 5, Epoch 77/130 => Loss 27.885,  Loss1 0.699, Train_accy 67.59
2024-08-02 14:25:20,487 [foster.py] => SNet: Task 5, Epoch 78/130 => Loss 27.927,  Loss1 0.699, Train_accy 66.85
2024-08-02 14:25:23,604 [foster.py] => SNet: Task 5, Epoch 79/130 => Loss 27.908,  Loss1 0.699, Train_accy 65.28
2024-08-02 14:25:26,676 [foster.py] => SNet: Task 5, Epoch 80/130 => Loss 27.892,  Loss1 0.699, Train_accy 66.71
2024-08-02 14:25:30,739 [foster.py] => SNet: Task 5, Epoch 81/130 => Loss 27.893,  Loss1 0.699, Train_accy 66.81, Test_accy 75.27
2024-08-02 14:25:33,815 [foster.py] => SNet: Task 5, Epoch 82/130 => Loss 27.885,  Loss1 0.699, Train_accy 66.90
2024-08-02 14:25:36,925 [foster.py] => SNet: Task 5, Epoch 83/130 => Loss 27.901,  Loss1 0.699, Train_accy 66.90
2024-08-02 14:25:40,053 [foster.py] => SNet: Task 5, Epoch 84/130 => Loss 27.900,  Loss1 0.699, Train_accy 68.43
2024-08-02 14:25:43,143 [foster.py] => SNet: Task 5, Epoch 85/130 => Loss 27.940,  Loss1 0.699, Train_accy 67.08
2024-08-02 14:25:47,199 [foster.py] => SNet: Task 5, Epoch 86/130 => Loss 27.890,  Loss1 0.699, Train_accy 66.25, Test_accy 75.12
2024-08-02 14:25:50,306 [foster.py] => SNet: Task 5, Epoch 87/130 => Loss 27.914,  Loss1 0.699, Train_accy 66.71
2024-08-02 14:25:53,389 [foster.py] => SNet: Task 5, Epoch 88/130 => Loss 27.957,  Loss1 0.699, Train_accy 65.65
2024-08-02 14:25:56,474 [foster.py] => SNet: Task 5, Epoch 89/130 => Loss 27.897,  Loss1 0.699, Train_accy 65.60
2024-08-02 14:25:59,554 [foster.py] => SNet: Task 5, Epoch 90/130 => Loss 27.893,  Loss1 0.699, Train_accy 67.18
2024-08-02 14:26:03,596 [foster.py] => SNet: Task 5, Epoch 91/130 => Loss 27.905,  Loss1 0.699, Train_accy 64.40, Test_accy 75.15
2024-08-02 14:26:06,674 [foster.py] => SNet: Task 5, Epoch 92/130 => Loss 27.937,  Loss1 0.699, Train_accy 66.90
2024-08-02 14:26:09,743 [foster.py] => SNet: Task 5, Epoch 93/130 => Loss 27.986,  Loss1 0.699, Train_accy 67.55
2024-08-02 14:26:12,845 [foster.py] => SNet: Task 5, Epoch 94/130 => Loss 27.882,  Loss1 0.699, Train_accy 68.06
2024-08-02 14:26:15,928 [foster.py] => SNet: Task 5, Epoch 95/130 => Loss 27.923,  Loss1 0.699, Train_accy 68.10
2024-08-02 14:26:19,937 [foster.py] => SNet: Task 5, Epoch 96/130 => Loss 27.873,  Loss1 0.699, Train_accy 68.56, Test_accy 75.38
2024-08-02 14:26:23,013 [foster.py] => SNet: Task 5, Epoch 97/130 => Loss 27.905,  Loss1 0.699, Train_accy 67.27
2024-08-02 14:26:26,103 [foster.py] => SNet: Task 5, Epoch 98/130 => Loss 27.934,  Loss1 0.699, Train_accy 65.83
2024-08-02 14:26:29,168 [foster.py] => SNet: Task 5, Epoch 99/130 => Loss 27.910,  Loss1 0.699, Train_accy 67.69
2024-08-02 14:26:32,249 [foster.py] => SNet: Task 5, Epoch 100/130 => Loss 27.853,  Loss1 0.699, Train_accy 65.28
2024-08-02 14:26:36,267 [foster.py] => SNet: Task 5, Epoch 101/130 => Loss 27.920,  Loss1 0.699, Train_accy 68.15, Test_accy 75.40
2024-08-02 14:26:39,333 [foster.py] => SNet: Task 5, Epoch 102/130 => Loss 27.880,  Loss1 0.699, Train_accy 67.69
2024-08-02 14:26:42,436 [foster.py] => SNet: Task 5, Epoch 103/130 => Loss 27.908,  Loss1 0.698, Train_accy 66.71
2024-08-02 14:26:45,517 [foster.py] => SNet: Task 5, Epoch 104/130 => Loss 27.938,  Loss1 0.699, Train_accy 67.50
2024-08-02 14:26:48,699 [foster.py] => SNet: Task 5, Epoch 105/130 => Loss 27.909,  Loss1 0.699, Train_accy 66.67
2024-08-02 14:26:52,726 [foster.py] => SNet: Task 5, Epoch 106/130 => Loss 27.912,  Loss1 0.699, Train_accy 68.43, Test_accy 75.30
2024-08-02 14:26:55,824 [foster.py] => SNet: Task 5, Epoch 107/130 => Loss 27.888,  Loss1 0.699, Train_accy 67.69
2024-08-02 14:26:58,888 [foster.py] => SNet: Task 5, Epoch 108/130 => Loss 27.902,  Loss1 0.699, Train_accy 67.50
2024-08-02 14:27:01,967 [foster.py] => SNet: Task 5, Epoch 109/130 => Loss 27.926,  Loss1 0.699, Train_accy 66.11
2024-08-02 14:27:05,059 [foster.py] => SNet: Task 5, Epoch 110/130 => Loss 27.883,  Loss1 0.698, Train_accy 68.43
2024-08-02 14:27:09,103 [foster.py] => SNet: Task 5, Epoch 111/130 => Loss 27.919,  Loss1 0.699, Train_accy 68.33, Test_accy 74.88
2024-08-02 14:27:12,197 [foster.py] => SNet: Task 5, Epoch 112/130 => Loss 27.924,  Loss1 0.699, Train_accy 68.10
2024-08-02 14:27:15,285 [foster.py] => SNet: Task 5, Epoch 113/130 => Loss 27.877,  Loss1 0.699, Train_accy 68.15
2024-08-02 14:27:18,376 [foster.py] => SNet: Task 5, Epoch 114/130 => Loss 27.915,  Loss1 0.699, Train_accy 67.87
2024-08-02 14:27:21,463 [foster.py] => SNet: Task 5, Epoch 115/130 => Loss 27.893,  Loss1 0.699, Train_accy 67.50
2024-08-02 14:27:25,479 [foster.py] => SNet: Task 5, Epoch 116/130 => Loss 27.917,  Loss1 0.699, Train_accy 67.73, Test_accy 75.20
2024-08-02 14:27:28,563 [foster.py] => SNet: Task 5, Epoch 117/130 => Loss 27.914,  Loss1 0.699, Train_accy 68.43
2024-08-02 14:27:31,662 [foster.py] => SNet: Task 5, Epoch 118/130 => Loss 27.884,  Loss1 0.699, Train_accy 66.94
2024-08-02 14:27:34,743 [foster.py] => SNet: Task 5, Epoch 119/130 => Loss 27.909,  Loss1 0.699, Train_accy 66.67
2024-08-02 14:27:37,815 [foster.py] => SNet: Task 5, Epoch 120/130 => Loss 27.878,  Loss1 0.698, Train_accy 66.94
2024-08-02 14:27:41,859 [foster.py] => SNet: Task 5, Epoch 121/130 => Loss 27.926,  Loss1 0.699, Train_accy 67.04, Test_accy 75.30
2024-08-02 14:27:44,932 [foster.py] => SNet: Task 5, Epoch 122/130 => Loss 27.885,  Loss1 0.699, Train_accy 68.01
2024-08-02 14:27:48,000 [foster.py] => SNet: Task 5, Epoch 123/130 => Loss 27.888,  Loss1 0.698, Train_accy 67.27
2024-08-02 14:27:51,098 [foster.py] => SNet: Task 5, Epoch 124/130 => Loss 27.893,  Loss1 0.699, Train_accy 67.59
2024-08-02 14:27:54,257 [foster.py] => SNet: Task 5, Epoch 125/130 => Loss 27.892,  Loss1 0.699, Train_accy 66.94
2024-08-02 14:27:58,299 [foster.py] => SNet: Task 5, Epoch 126/130 => Loss 27.865,  Loss1 0.699, Train_accy 67.69, Test_accy 75.32
2024-08-02 14:28:01,422 [foster.py] => SNet: Task 5, Epoch 127/130 => Loss 27.886,  Loss1 0.699, Train_accy 66.76
2024-08-02 14:28:04,554 [foster.py] => SNet: Task 5, Epoch 128/130 => Loss 27.875,  Loss1 0.699, Train_accy 68.47
2024-08-02 14:28:07,651 [foster.py] => SNet: Task 5, Epoch 129/130 => Loss 27.905,  Loss1 0.699, Train_accy 67.87
2024-08-02 14:28:10,737 [foster.py] => SNet: Task 5, Epoch 130/130 => Loss 27.936,  Loss1 0.699, Train_accy 68.84
2024-08-02 14:28:10,737 [foster.py] => do not weight align student!
2024-08-02 14:28:11,688 [foster.py] => darknet eval: 
2024-08-02 14:28:11,688 [foster.py] => CNN top1 curve: 75.38
2024-08-02 14:28:11,688 [foster.py] => CNN top5 curve: 94.63
2024-08-02 14:28:11,688 [foster.py] => CNN top1 平均值: 75.38
2024-08-02 14:28:11,691 [foster.py] => timees : 1008.675136089325
2024-08-02 14:28:11,692 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 14:28:29,994 [foster.py] => Exemplar size: 1200
2024-08-02 14:28:29,995 [trainer.py] => CNN: {'total': 76.17, '00-09': 82.1, '10-19': 71.7, '20-29': 81.0, '30-39': 76.0, '40-49': 80.3, '50-59': 65.9, 'old': 76.28, 'new': 73.0}
2024-08-02 14:28:29,995 [trainer.py] => NME: {'total': 72.02, '00-09': 75.2, '10-19': 66.3, '20-29': 76.9, '30-39': 71.8, '40-49': 76.4, '50-59': 65.5, 'old': 71.66, 'new': 82.5}
2024-08-02 14:28:29,995 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17]
2024-08-02 14:28:29,995 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27]
2024-08-02 14:28:29,995 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02]
2024-08-02 14:28:29,995 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9]

2024-08-02 14:28:29,995 [trainer.py] => CNN top1 平均值: 78.95
2024-08-02 14:28:29,997 [trainer.py] => All params: 1169958
2024-08-02 14:28:30,000 [trainer.py] => Trainable params: 588914
2024-08-02 14:28:30,060 [foster.py] => Learning on 60-62
2024-08-02 14:28:30,063 [foster.py] => All params: 1170476
2024-08-02 14:28:30,065 [foster.py] => Trainable params: 589302
2024-08-02 14:28:30,103 [foster.py] => per cls weights : [1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565 1.01482565
 0.5552305  0.5552305 ]
2024-08-02 14:28:32,517 [foster.py] => Task 6, Epoch 1/170 => Loss 5.499, Loss_clf 1.236, Loss_fe 1.746, Loss_kd 2.435, Train_accy 61.64
2024-08-02 14:28:36,393 [foster.py] => Task 6, Epoch 2/170 => Loss 3.849, Loss_clf 0.595, Loss_fe 0.728, Loss_kd 2.443, Train_accy 74.36, Test_accy 74.58
2024-08-02 14:28:40,216 [foster.py] => Task 6, Epoch 3/170 => Loss 3.648, Loss_clf 0.531, Loss_fe 0.621, Loss_kd 2.414, Train_accy 71.73, Test_accy 74.24
2024-08-02 14:28:44,073 [foster.py] => Task 6, Epoch 4/170 => Loss 3.603, Loss_clf 0.513, Loss_fe 0.594, Loss_kd 2.413, Train_accy 71.18, Test_accy 74.58
2024-08-02 14:28:47,948 [foster.py] => Task 6, Epoch 5/170 => Loss 3.530, Loss_clf 0.497, Loss_fe 0.534, Loss_kd 2.417, Train_accy 71.91, Test_accy 74.34
2024-08-02 14:28:50,283 [foster.py] => Task 6, Epoch 6/170 => Loss 3.528, Loss_clf 0.494, Loss_fe 0.531, Loss_kd 2.421, Train_accy 74.00
2024-08-02 14:28:54,119 [foster.py] => Task 6, Epoch 7/170 => Loss 3.538, Loss_clf 0.507, Loss_fe 0.495, Loss_kd 2.453, Train_accy 73.45, Test_accy 74.42
2024-08-02 14:28:57,943 [foster.py] => Task 6, Epoch 8/170 => Loss 3.495, Loss_clf 0.472, Loss_fe 0.497, Loss_kd 2.443, Train_accy 73.09, Test_accy 74.27
2024-08-02 14:29:01,774 [foster.py] => Task 6, Epoch 9/170 => Loss 3.482, Loss_clf 0.489, Loss_fe 0.476, Loss_kd 2.434, Train_accy 74.05, Test_accy 74.16
2024-08-02 14:29:05,688 [foster.py] => Task 6, Epoch 10/170 => Loss 3.407, Loss_clf 0.452, Loss_fe 0.444, Loss_kd 2.428, Train_accy 75.05, Test_accy 73.90
2024-08-02 14:29:08,111 [foster.py] => Task 6, Epoch 11/170 => Loss 3.423, Loss_clf 0.443, Loss_fe 0.459, Loss_kd 2.439, Train_accy 73.05
2024-08-02 14:29:11,984 [foster.py] => Task 6, Epoch 12/170 => Loss 3.399, Loss_clf 0.461, Loss_fe 0.428, Loss_kd 2.428, Train_accy 74.95, Test_accy 74.37
2024-08-02 14:29:15,977 [foster.py] => Task 6, Epoch 13/170 => Loss 3.436, Loss_clf 0.480, Loss_fe 0.416, Loss_kd 2.457, Train_accy 75.32, Test_accy 74.31
2024-08-02 14:29:19,846 [foster.py] => Task 6, Epoch 14/170 => Loss 3.405, Loss_clf 0.455, Loss_fe 0.422, Loss_kd 2.444, Train_accy 74.73, Test_accy 74.69
2024-08-02 14:29:23,682 [foster.py] => Task 6, Epoch 15/170 => Loss 3.314, Loss_clf 0.410, Loss_fe 0.399, Loss_kd 2.422, Train_accy 76.64, Test_accy 74.58
2024-08-02 14:29:26,018 [foster.py] => Task 6, Epoch 16/170 => Loss 3.382, Loss_clf 0.458, Loss_fe 0.395, Loss_kd 2.447, Train_accy 76.45
2024-08-02 14:29:29,909 [foster.py] => Task 6, Epoch 17/170 => Loss 3.402, Loss_clf 0.480, Loss_fe 0.404, Loss_kd 2.435, Train_accy 74.59, Test_accy 74.52
2024-08-02 14:29:33,753 [foster.py] => Task 6, Epoch 18/170 => Loss 3.331, Loss_clf 0.437, Loss_fe 0.386, Loss_kd 2.425, Train_accy 75.41, Test_accy 74.05
2024-08-02 14:29:37,635 [foster.py] => Task 6, Epoch 19/170 => Loss 3.301, Loss_clf 0.426, Loss_fe 0.385, Loss_kd 2.408, Train_accy 76.64, Test_accy 74.02
2024-08-02 14:29:41,516 [foster.py] => Task 6, Epoch 20/170 => Loss 3.277, Loss_clf 0.420, Loss_fe 0.369, Loss_kd 2.406, Train_accy 77.14, Test_accy 74.47
2024-08-02 14:29:43,887 [foster.py] => Task 6, Epoch 21/170 => Loss 3.255, Loss_clf 0.423, Loss_fe 0.351, Loss_kd 2.400, Train_accy 78.05
2024-08-02 14:29:47,746 [foster.py] => Task 6, Epoch 22/170 => Loss 3.206, Loss_clf 0.398, Loss_fe 0.339, Loss_kd 2.387, Train_accy 77.59, Test_accy 74.92
2024-08-02 14:29:51,746 [foster.py] => Task 6, Epoch 23/170 => Loss 3.306, Loss_clf 0.442, Loss_fe 0.344, Loss_kd 2.438, Train_accy 77.59, Test_accy 74.92
2024-08-02 14:29:55,596 [foster.py] => Task 6, Epoch 24/170 => Loss 3.303, Loss_clf 0.431, Loss_fe 0.353, Loss_kd 2.437, Train_accy 76.77, Test_accy 74.44
2024-08-02 14:29:59,474 [foster.py] => Task 6, Epoch 25/170 => Loss 3.262, Loss_clf 0.423, Loss_fe 0.338, Loss_kd 2.419, Train_accy 78.50, Test_accy 74.13
2024-08-02 14:30:01,841 [foster.py] => Task 6, Epoch 26/170 => Loss 3.295, Loss_clf 0.417, Loss_fe 0.376, Loss_kd 2.420, Train_accy 79.77
2024-08-02 14:30:05,759 [foster.py] => Task 6, Epoch 27/170 => Loss 3.234, Loss_clf 0.411, Loss_fe 0.327, Loss_kd 2.415, Train_accy 77.68, Test_accy 74.68
2024-08-02 14:30:09,590 [foster.py] => Task 6, Epoch 28/170 => Loss 3.251, Loss_clf 0.425, Loss_fe 0.349, Loss_kd 2.396, Train_accy 79.68, Test_accy 75.05
2024-08-02 14:30:13,451 [foster.py] => Task 6, Epoch 29/170 => Loss 3.250, Loss_clf 0.404, Loss_fe 0.300, Loss_kd 2.462, Train_accy 78.91, Test_accy 75.08
2024-08-02 14:30:17,318 [foster.py] => Task 6, Epoch 30/170 => Loss 3.157, Loss_clf 0.356, Loss_fe 0.300, Loss_kd 2.420, Train_accy 81.27, Test_accy 74.77
2024-08-02 14:30:19,665 [foster.py] => Task 6, Epoch 31/170 => Loss 3.246, Loss_clf 0.413, Loss_fe 0.336, Loss_kd 2.414, Train_accy 81.55
2024-08-02 14:30:23,531 [foster.py] => Task 6, Epoch 32/170 => Loss 3.157, Loss_clf 0.379, Loss_fe 0.301, Loss_kd 2.395, Train_accy 78.86, Test_accy 75.00
2024-08-02 14:30:27,450 [foster.py] => Task 6, Epoch 33/170 => Loss 3.258, Loss_clf 0.423, Loss_fe 0.321, Loss_kd 2.432, Train_accy 79.32, Test_accy 74.81
2024-08-02 14:30:31,305 [foster.py] => Task 6, Epoch 34/170 => Loss 3.236, Loss_clf 0.408, Loss_fe 0.329, Loss_kd 2.416, Train_accy 80.14, Test_accy 74.52
2024-08-02 14:30:35,250 [foster.py] => Task 6, Epoch 35/170 => Loss 3.228, Loss_clf 0.404, Loss_fe 0.314, Loss_kd 2.429, Train_accy 78.36, Test_accy 74.84
2024-08-02 14:30:37,592 [foster.py] => Task 6, Epoch 36/170 => Loss 3.190, Loss_clf 0.373, Loss_fe 0.294, Loss_kd 2.440, Train_accy 81.23
2024-08-02 14:30:41,422 [foster.py] => Task 6, Epoch 37/170 => Loss 3.172, Loss_clf 0.402, Loss_fe 0.283, Loss_kd 2.405, Train_accy 80.59, Test_accy 74.69
2024-08-02 14:30:45,357 [foster.py] => Task 6, Epoch 38/170 => Loss 3.262, Loss_clf 0.432, Loss_fe 0.329, Loss_kd 2.419, Train_accy 79.45, Test_accy 74.68
2024-08-02 14:30:49,197 [foster.py] => Task 6, Epoch 39/170 => Loss 3.145, Loss_clf 0.358, Loss_fe 0.286, Loss_kd 2.419, Train_accy 80.23, Test_accy 74.23
2024-08-02 14:30:53,043 [foster.py] => Task 6, Epoch 40/170 => Loss 3.245, Loss_clf 0.425, Loss_fe 0.304, Loss_kd 2.434, Train_accy 76.41, Test_accy 74.24
2024-08-02 14:30:55,398 [foster.py] => Task 6, Epoch 41/170 => Loss 3.196, Loss_clf 0.405, Loss_fe 0.301, Loss_kd 2.408, Train_accy 80.68
2024-08-02 14:30:59,272 [foster.py] => Task 6, Epoch 42/170 => Loss 3.204, Loss_clf 0.378, Loss_fe 0.306, Loss_kd 2.437, Train_accy 78.77, Test_accy 74.81
2024-08-02 14:31:03,124 [foster.py] => Task 6, Epoch 43/170 => Loss 3.216, Loss_clf 0.390, Loss_fe 0.301, Loss_kd 2.442, Train_accy 79.14, Test_accy 75.15
2024-08-02 14:31:07,002 [foster.py] => Task 6, Epoch 44/170 => Loss 3.191, Loss_clf 0.398, Loss_fe 0.285, Loss_kd 2.425, Train_accy 81.14, Test_accy 75.05
2024-08-02 14:31:10,860 [foster.py] => Task 6, Epoch 45/170 => Loss 3.157, Loss_clf 0.375, Loss_fe 0.266, Loss_kd 2.433, Train_accy 81.05, Test_accy 75.31
2024-08-02 14:31:13,254 [foster.py] => Task 6, Epoch 46/170 => Loss 3.183, Loss_clf 0.370, Loss_fe 0.267, Loss_kd 2.463, Train_accy 81.36
2024-08-02 14:31:17,103 [foster.py] => Task 6, Epoch 47/170 => Loss 3.138, Loss_clf 0.381, Loss_fe 0.238, Loss_kd 2.437, Train_accy 80.55, Test_accy 74.76
2024-08-02 14:31:20,922 [foster.py] => Task 6, Epoch 48/170 => Loss 3.118, Loss_clf 0.368, Loss_fe 0.246, Loss_kd 2.423, Train_accy 81.91, Test_accy 74.61
2024-08-02 14:31:24,787 [foster.py] => Task 6, Epoch 49/170 => Loss 3.158, Loss_clf 0.382, Loss_fe 0.253, Loss_kd 2.440, Train_accy 80.86, Test_accy 74.85
2024-08-02 14:31:28,630 [foster.py] => Task 6, Epoch 50/170 => Loss 3.145, Loss_clf 0.383, Loss_fe 0.270, Loss_kd 2.410, Train_accy 80.27, Test_accy 74.63
2024-08-02 14:31:30,964 [foster.py] => Task 6, Epoch 51/170 => Loss 3.180, Loss_clf 0.378, Loss_fe 0.263, Loss_kd 2.456, Train_accy 83.36
2024-08-02 14:31:34,827 [foster.py] => Task 6, Epoch 52/170 => Loss 3.145, Loss_clf 0.364, Loss_fe 0.268, Loss_kd 2.430, Train_accy 81.05, Test_accy 75.03
2024-08-02 14:31:38,665 [foster.py] => Task 6, Epoch 53/170 => Loss 3.112, Loss_clf 0.348, Loss_fe 0.258, Loss_kd 2.425, Train_accy 83.32, Test_accy 75.10
2024-08-02 14:31:42,533 [foster.py] => Task 6, Epoch 54/170 => Loss 3.180, Loss_clf 0.390, Loss_fe 0.266, Loss_kd 2.442, Train_accy 81.55, Test_accy 74.85
2024-08-02 14:31:46,415 [foster.py] => Task 6, Epoch 55/170 => Loss 3.132, Loss_clf 0.368, Loss_fe 0.279, Loss_kd 2.403, Train_accy 83.09, Test_accy 75.03
2024-08-02 14:31:48,772 [foster.py] => Task 6, Epoch 56/170 => Loss 3.137, Loss_clf 0.369, Loss_fe 0.280, Loss_kd 2.406, Train_accy 81.36
2024-08-02 14:31:52,706 [foster.py] => Task 6, Epoch 57/170 => Loss 3.262, Loss_clf 0.431, Loss_fe 0.285, Loss_kd 2.463, Train_accy 80.41, Test_accy 74.66
2024-08-02 14:31:56,592 [foster.py] => Task 6, Epoch 58/170 => Loss 3.107, Loss_clf 0.359, Loss_fe 0.242, Loss_kd 2.424, Train_accy 81.73, Test_accy 74.94
2024-08-02 14:32:00,433 [foster.py] => Task 6, Epoch 59/170 => Loss 3.112, Loss_clf 0.362, Loss_fe 0.233, Loss_kd 2.434, Train_accy 82.18, Test_accy 74.85
2024-08-02 14:32:04,312 [foster.py] => Task 6, Epoch 60/170 => Loss 3.006, Loss_clf 0.317, Loss_fe 0.199, Loss_kd 2.408, Train_accy 83.27, Test_accy 75.42
2024-08-02 14:32:06,660 [foster.py] => Task 6, Epoch 61/170 => Loss 3.080, Loss_clf 0.343, Loss_fe 0.222, Loss_kd 2.432, Train_accy 83.95
2024-08-02 14:32:10,566 [foster.py] => Task 6, Epoch 62/170 => Loss 3.098, Loss_clf 0.360, Loss_fe 0.235, Loss_kd 2.422, Train_accy 81.00, Test_accy 74.58
2024-08-02 14:32:14,458 [foster.py] => Task 6, Epoch 63/170 => Loss 3.116, Loss_clf 0.381, Loss_fe 0.238, Loss_kd 2.415, Train_accy 83.05, Test_accy 75.18
2024-08-02 14:32:18,352 [foster.py] => Task 6, Epoch 64/170 => Loss 3.092, Loss_clf 0.375, Loss_fe 0.212, Loss_kd 2.422, Train_accy 82.86, Test_accy 75.19
2024-08-02 14:32:22,198 [foster.py] => Task 6, Epoch 65/170 => Loss 3.099, Loss_clf 0.350, Loss_fe 0.232, Loss_kd 2.435, Train_accy 82.68, Test_accy 75.23
2024-08-02 14:32:24,561 [foster.py] => Task 6, Epoch 66/170 => Loss 3.044, Loss_clf 0.332, Loss_fe 0.226, Loss_kd 2.404, Train_accy 83.82
2024-08-02 14:32:28,385 [foster.py] => Task 6, Epoch 67/170 => Loss 3.130, Loss_clf 0.373, Loss_fe 0.231, Loss_kd 2.443, Train_accy 81.77, Test_accy 74.92
2024-08-02 14:32:32,222 [foster.py] => Task 6, Epoch 68/170 => Loss 3.033, Loss_clf 0.325, Loss_fe 0.206, Loss_kd 2.420, Train_accy 83.68, Test_accy 75.29
2024-08-02 14:32:36,071 [foster.py] => Task 6, Epoch 69/170 => Loss 3.014, Loss_clf 0.309, Loss_fe 0.201, Loss_kd 2.422, Train_accy 82.73, Test_accy 75.35
2024-08-02 14:32:39,915 [foster.py] => Task 6, Epoch 70/170 => Loss 3.017, Loss_clf 0.326, Loss_fe 0.204, Loss_kd 2.405, Train_accy 85.86, Test_accy 75.16
2024-08-02 14:32:42,264 [foster.py] => Task 6, Epoch 71/170 => Loss 3.099, Loss_clf 0.364, Loss_fe 0.198, Loss_kd 2.454, Train_accy 81.09
2024-08-02 14:32:46,124 [foster.py] => Task 6, Epoch 72/170 => Loss 3.044, Loss_clf 0.325, Loss_fe 0.199, Loss_kd 2.438, Train_accy 83.95, Test_accy 75.11
2024-08-02 14:32:49,973 [foster.py] => Task 6, Epoch 73/170 => Loss 3.088, Loss_clf 0.364, Loss_fe 0.225, Loss_kd 2.417, Train_accy 84.18, Test_accy 75.24
2024-08-02 14:32:53,885 [foster.py] => Task 6, Epoch 74/170 => Loss 3.051, Loss_clf 0.333, Loss_fe 0.211, Loss_kd 2.424, Train_accy 83.50, Test_accy 74.95
2024-08-02 14:32:57,736 [foster.py] => Task 6, Epoch 75/170 => Loss 3.156, Loss_clf 0.372, Loss_fe 0.243, Loss_kd 2.459, Train_accy 83.91, Test_accy 75.37
2024-08-02 14:33:00,143 [foster.py] => Task 6, Epoch 76/170 => Loss 3.132, Loss_clf 0.346, Loss_fe 0.243, Loss_kd 2.459, Train_accy 84.05
2024-08-02 14:33:04,025 [foster.py] => Task 6, Epoch 77/170 => Loss 3.114, Loss_clf 0.354, Loss_fe 0.217, Loss_kd 2.459, Train_accy 83.41, Test_accy 75.47
2024-08-02 14:33:07,864 [foster.py] => Task 6, Epoch 78/170 => Loss 3.085, Loss_clf 0.348, Loss_fe 0.212, Loss_kd 2.441, Train_accy 82.36, Test_accy 75.35
2024-08-02 14:33:11,831 [foster.py] => Task 6, Epoch 79/170 => Loss 2.989, Loss_clf 0.307, Loss_fe 0.182, Loss_kd 2.417, Train_accy 84.64, Test_accy 75.21
2024-08-02 14:33:15,680 [foster.py] => Task 6, Epoch 80/170 => Loss 3.005, Loss_clf 0.321, Loss_fe 0.179, Loss_kd 2.424, Train_accy 83.41, Test_accy 75.47
2024-08-02 14:33:18,040 [foster.py] => Task 6, Epoch 81/170 => Loss 3.069, Loss_clf 0.370, Loss_fe 0.182, Loss_kd 2.435, Train_accy 83.18
2024-08-02 14:33:21,938 [foster.py] => Task 6, Epoch 82/170 => Loss 3.047, Loss_clf 0.344, Loss_fe 0.179, Loss_kd 2.442, Train_accy 84.73, Test_accy 75.55
2024-08-02 14:33:25,782 [foster.py] => Task 6, Epoch 83/170 => Loss 3.001, Loss_clf 0.313, Loss_fe 0.174, Loss_kd 2.431, Train_accy 84.68, Test_accy 75.45
2024-08-02 14:33:29,683 [foster.py] => Task 6, Epoch 84/170 => Loss 2.982, Loss_clf 0.316, Loss_fe 0.166, Loss_kd 2.418, Train_accy 86.18, Test_accy 75.03
2024-08-02 14:33:33,498 [foster.py] => Task 6, Epoch 85/170 => Loss 3.015, Loss_clf 0.337, Loss_fe 0.169, Loss_kd 2.427, Train_accy 85.55, Test_accy 75.47
2024-08-02 14:33:35,847 [foster.py] => Task 6, Epoch 86/170 => Loss 3.009, Loss_clf 0.337, Loss_fe 0.189, Loss_kd 2.402, Train_accy 84.23
2024-08-02 14:33:39,808 [foster.py] => Task 6, Epoch 87/170 => Loss 3.025, Loss_clf 0.332, Loss_fe 0.192, Loss_kd 2.419, Train_accy 84.09, Test_accy 74.68
2024-08-02 14:33:43,806 [foster.py] => Task 6, Epoch 88/170 => Loss 3.122, Loss_clf 0.360, Loss_fe 0.214, Loss_kd 2.464, Train_accy 84.41, Test_accy 75.13
2024-08-02 14:33:47,702 [foster.py] => Task 6, Epoch 89/170 => Loss 3.071, Loss_clf 0.348, Loss_fe 0.215, Loss_kd 2.425, Train_accy 79.59, Test_accy 74.69
2024-08-02 14:33:51,667 [foster.py] => Task 6, Epoch 90/170 => Loss 3.118, Loss_clf 0.369, Loss_fe 0.213, Loss_kd 2.453, Train_accy 84.55, Test_accy 75.53
2024-08-02 14:33:53,999 [foster.py] => Task 6, Epoch 91/170 => Loss 3.133, Loss_clf 0.371, Loss_fe 0.220, Loss_kd 2.459, Train_accy 83.64
2024-08-02 14:33:57,895 [foster.py] => Task 6, Epoch 92/170 => Loss 3.042, Loss_clf 0.365, Loss_fe 0.177, Loss_kd 2.418, Train_accy 83.27, Test_accy 75.39
2024-08-02 14:34:01,737 [foster.py] => Task 6, Epoch 93/170 => Loss 3.059, Loss_clf 0.349, Loss_fe 0.175, Loss_kd 2.452, Train_accy 82.82, Test_accy 74.53
2024-08-02 14:34:05,610 [foster.py] => Task 6, Epoch 94/170 => Loss 2.998, Loss_clf 0.303, Loss_fe 0.175, Loss_kd 2.437, Train_accy 85.73, Test_accy 75.35
2024-08-02 14:34:09,469 [foster.py] => Task 6, Epoch 95/170 => Loss 3.017, Loss_clf 0.340, Loss_fe 0.194, Loss_kd 2.402, Train_accy 85.36, Test_accy 75.44
2024-08-02 14:34:11,832 [foster.py] => Task 6, Epoch 96/170 => Loss 3.013, Loss_clf 0.319, Loss_fe 0.173, Loss_kd 2.439, Train_accy 84.18
2024-08-02 14:34:15,723 [foster.py] => Task 6, Epoch 97/170 => Loss 3.009, Loss_clf 0.323, Loss_fe 0.169, Loss_kd 2.435, Train_accy 85.45, Test_accy 75.19
2024-08-02 14:34:19,612 [foster.py] => Task 6, Epoch 98/170 => Loss 3.039, Loss_clf 0.347, Loss_fe 0.176, Loss_kd 2.433, Train_accy 83.77, Test_accy 75.37
2024-08-02 14:34:23,488 [foster.py] => Task 6, Epoch 99/170 => Loss 3.020, Loss_clf 0.350, Loss_fe 0.166, Loss_kd 2.422, Train_accy 84.09, Test_accy 75.37
2024-08-02 14:34:27,343 [foster.py] => Task 6, Epoch 100/170 => Loss 2.994, Loss_clf 0.324, Loss_fe 0.159, Loss_kd 2.429, Train_accy 83.14, Test_accy 75.55
2024-08-02 14:34:29,762 [foster.py] => Task 6, Epoch 101/170 => Loss 3.005, Loss_clf 0.335, Loss_fe 0.159, Loss_kd 2.429, Train_accy 83.50
2024-08-02 14:34:33,682 [foster.py] => Task 6, Epoch 102/170 => Loss 3.121, Loss_clf 0.370, Loss_fe 0.209, Loss_kd 2.458, Train_accy 83.77, Test_accy 75.24
2024-08-02 14:34:37,551 [foster.py] => Task 6, Epoch 103/170 => Loss 2.893, Loss_clf 0.266, Loss_fe 0.149, Loss_kd 2.397, Train_accy 86.45, Test_accy 75.29
2024-08-02 14:34:41,397 [foster.py] => Task 6, Epoch 104/170 => Loss 3.043, Loss_clf 0.332, Loss_fe 0.174, Loss_kd 2.454, Train_accy 85.64, Test_accy 75.45
2024-08-02 14:34:45,247 [foster.py] => Task 6, Epoch 105/170 => Loss 3.083, Loss_clf 0.350, Loss_fe 0.188, Loss_kd 2.461, Train_accy 84.18, Test_accy 75.35
2024-08-02 14:34:47,578 [foster.py] => Task 6, Epoch 106/170 => Loss 3.035, Loss_clf 0.329, Loss_fe 0.186, Loss_kd 2.437, Train_accy 84.18
2024-08-02 14:34:51,450 [foster.py] => Task 6, Epoch 107/170 => Loss 3.006, Loss_clf 0.320, Loss_fe 0.170, Loss_kd 2.432, Train_accy 85.82, Test_accy 75.55
2024-08-02 14:34:55,350 [foster.py] => Task 6, Epoch 108/170 => Loss 2.929, Loss_clf 0.295, Loss_fe 0.150, Loss_kd 2.403, Train_accy 85.05, Test_accy 75.66
2024-08-02 14:34:59,226 [foster.py] => Task 6, Epoch 109/170 => Loss 2.983, Loss_clf 0.330, Loss_fe 0.145, Loss_kd 2.425, Train_accy 84.32, Test_accy 75.39
2024-08-02 14:35:03,093 [foster.py] => Task 6, Epoch 110/170 => Loss 2.985, Loss_clf 0.314, Loss_fe 0.152, Loss_kd 2.436, Train_accy 86.09, Test_accy 75.45
2024-08-02 14:35:05,435 [foster.py] => Task 6, Epoch 111/170 => Loss 2.942, Loss_clf 0.297, Loss_fe 0.141, Loss_kd 2.422, Train_accy 86.23
2024-08-02 14:35:09,299 [foster.py] => Task 6, Epoch 112/170 => Loss 2.982, Loss_clf 0.320, Loss_fe 0.153, Loss_kd 2.428, Train_accy 86.00, Test_accy 75.32
2024-08-02 14:35:13,153 [foster.py] => Task 6, Epoch 113/170 => Loss 2.959, Loss_clf 0.303, Loss_fe 0.131, Loss_kd 2.441, Train_accy 86.09, Test_accy 75.37
2024-08-02 14:35:17,019 [foster.py] => Task 6, Epoch 114/170 => Loss 2.989, Loss_clf 0.315, Loss_fe 0.142, Loss_kd 2.449, Train_accy 85.86, Test_accy 75.31
2024-08-02 14:35:20,868 [foster.py] => Task 6, Epoch 115/170 => Loss 2.981, Loss_clf 0.317, Loss_fe 0.147, Loss_kd 2.434, Train_accy 86.05, Test_accy 75.45
2024-08-02 14:35:23,231 [foster.py] => Task 6, Epoch 116/170 => Loss 2.972, Loss_clf 0.323, Loss_fe 0.135, Loss_kd 2.431, Train_accy 88.00
2024-08-02 14:35:27,130 [foster.py] => Task 6, Epoch 117/170 => Loss 2.936, Loss_clf 0.307, Loss_fe 0.121, Loss_kd 2.425, Train_accy 87.09, Test_accy 75.11
2024-08-02 14:35:30,986 [foster.py] => Task 6, Epoch 118/170 => Loss 2.899, Loss_clf 0.269, Loss_fe 0.118, Loss_kd 2.429, Train_accy 88.05, Test_accy 75.00
2024-08-02 14:35:34,824 [foster.py] => Task 6, Epoch 119/170 => Loss 3.016, Loss_clf 0.329, Loss_fe 0.150, Loss_kd 2.453, Train_accy 85.68, Test_accy 75.37
2024-08-02 14:35:38,684 [foster.py] => Task 6, Epoch 120/170 => Loss 2.909, Loss_clf 0.287, Loss_fe 0.110, Loss_kd 2.429, Train_accy 86.77, Test_accy 75.48
2024-08-02 14:35:41,032 [foster.py] => Task 6, Epoch 121/170 => Loss 2.917, Loss_clf 0.287, Loss_fe 0.135, Loss_kd 2.413, Train_accy 87.50
2024-08-02 14:35:44,891 [foster.py] => Task 6, Epoch 122/170 => Loss 2.929, Loss_clf 0.296, Loss_fe 0.120, Loss_kd 2.431, Train_accy 87.95, Test_accy 75.47
2024-08-02 14:35:48,871 [foster.py] => Task 6, Epoch 123/170 => Loss 2.973, Loss_clf 0.314, Loss_fe 0.128, Loss_kd 2.447, Train_accy 86.59, Test_accy 75.45
2024-08-02 14:35:52,730 [foster.py] => Task 6, Epoch 124/170 => Loss 2.956, Loss_clf 0.300, Loss_fe 0.132, Loss_kd 2.441, Train_accy 87.59, Test_accy 75.53
2024-08-02 14:35:56,566 [foster.py] => Task 6, Epoch 125/170 => Loss 2.927, Loss_clf 0.286, Loss_fe 0.115, Loss_kd 2.443, Train_accy 87.50, Test_accy 75.56
2024-08-02 14:35:58,882 [foster.py] => Task 6, Epoch 126/170 => Loss 3.006, Loss_clf 0.321, Loss_fe 0.137, Loss_kd 2.464, Train_accy 86.95
2024-08-02 14:36:02,762 [foster.py] => Task 6, Epoch 127/170 => Loss 2.930, Loss_clf 0.298, Loss_fe 0.126, Loss_kd 2.424, Train_accy 87.14, Test_accy 75.40
2024-08-02 14:36:06,660 [foster.py] => Task 6, Epoch 128/170 => Loss 2.962, Loss_clf 0.297, Loss_fe 0.125, Loss_kd 2.457, Train_accy 87.05, Test_accy 75.35
2024-08-02 14:36:10,541 [foster.py] => Task 6, Epoch 129/170 => Loss 2.941, Loss_clf 0.314, Loss_fe 0.114, Loss_kd 2.429, Train_accy 86.64, Test_accy 75.50
2024-08-02 14:36:14,433 [foster.py] => Task 6, Epoch 130/170 => Loss 2.949, Loss_clf 0.310, Loss_fe 0.120, Loss_kd 2.436, Train_accy 87.23, Test_accy 75.61
2024-08-02 14:36:16,858 [foster.py] => Task 6, Epoch 131/170 => Loss 2.866, Loss_clf 0.272, Loss_fe 0.108, Loss_kd 2.405, Train_accy 87.68
2024-08-02 14:36:20,703 [foster.py] => Task 6, Epoch 132/170 => Loss 2.932, Loss_clf 0.302, Loss_fe 0.123, Loss_kd 2.424, Train_accy 87.23, Test_accy 75.45
2024-08-02 14:36:24,591 [foster.py] => Task 6, Epoch 133/170 => Loss 2.990, Loss_clf 0.328, Loss_fe 0.141, Loss_kd 2.439, Train_accy 86.77, Test_accy 75.18
2024-08-02 14:36:28,475 [foster.py] => Task 6, Epoch 134/170 => Loss 2.913, Loss_clf 0.287, Loss_fe 0.096, Loss_kd 2.447, Train_accy 87.77, Test_accy 75.26
2024-08-02 14:36:32,347 [foster.py] => Task 6, Epoch 135/170 => Loss 2.900, Loss_clf 0.294, Loss_fe 0.109, Loss_kd 2.416, Train_accy 87.05, Test_accy 75.32
2024-08-02 14:36:34,675 [foster.py] => Task 6, Epoch 136/170 => Loss 3.009, Loss_clf 0.324, Loss_fe 0.139, Loss_kd 2.463, Train_accy 86.82
2024-08-02 14:36:38,530 [foster.py] => Task 6, Epoch 137/170 => Loss 2.941, Loss_clf 0.300, Loss_fe 0.114, Loss_kd 2.444, Train_accy 86.36, Test_accy 75.48
2024-08-02 14:36:42,379 [foster.py] => Task 6, Epoch 138/170 => Loss 2.896, Loss_clf 0.279, Loss_fe 0.120, Loss_kd 2.415, Train_accy 87.45, Test_accy 75.40
2024-08-02 14:36:46,233 [foster.py] => Task 6, Epoch 139/170 => Loss 2.946, Loss_clf 0.306, Loss_fe 0.108, Loss_kd 2.449, Train_accy 87.00, Test_accy 75.34
2024-08-02 14:36:50,075 [foster.py] => Task 6, Epoch 140/170 => Loss 2.866, Loss_clf 0.268, Loss_fe 0.099, Loss_kd 2.416, Train_accy 88.09, Test_accy 75.50
2024-08-02 14:36:52,438 [foster.py] => Task 6, Epoch 141/170 => Loss 2.864, Loss_clf 0.270, Loss_fe 0.103, Loss_kd 2.410, Train_accy 87.27
2024-08-02 14:36:56,306 [foster.py] => Task 6, Epoch 142/170 => Loss 2.956, Loss_clf 0.304, Loss_fe 0.117, Loss_kd 2.452, Train_accy 86.91, Test_accy 75.35
2024-08-02 14:37:00,145 [foster.py] => Task 6, Epoch 143/170 => Loss 3.019, Loss_clf 0.321, Loss_fe 0.151, Loss_kd 2.464, Train_accy 87.23, Test_accy 75.52
2024-08-02 14:37:03,998 [foster.py] => Task 6, Epoch 144/170 => Loss 2.937, Loss_clf 0.292, Loss_fe 0.109, Loss_kd 2.454, Train_accy 86.36, Test_accy 75.60
2024-08-02 14:37:07,903 [foster.py] => Task 6, Epoch 145/170 => Loss 2.895, Loss_clf 0.287, Loss_fe 0.122, Loss_kd 2.404, Train_accy 88.27, Test_accy 75.55
2024-08-02 14:37:10,237 [foster.py] => Task 6, Epoch 146/170 => Loss 2.912, Loss_clf 0.290, Loss_fe 0.110, Loss_kd 2.430, Train_accy 88.14
2024-08-02 14:37:14,121 [foster.py] => Task 6, Epoch 147/170 => Loss 2.922, Loss_clf 0.304, Loss_fe 0.122, Loss_kd 2.413, Train_accy 86.73, Test_accy 75.42
2024-08-02 14:37:17,989 [foster.py] => Task 6, Epoch 148/170 => Loss 2.976, Loss_clf 0.319, Loss_fe 0.153, Loss_kd 2.422, Train_accy 86.45, Test_accy 75.52
2024-08-02 14:37:21,862 [foster.py] => Task 6, Epoch 149/170 => Loss 2.965, Loss_clf 0.315, Loss_fe 0.138, Loss_kd 2.430, Train_accy 87.32, Test_accy 75.44
2024-08-02 14:37:25,723 [foster.py] => Task 6, Epoch 150/170 => Loss 2.875, Loss_clf 0.275, Loss_fe 0.104, Loss_kd 2.414, Train_accy 86.68, Test_accy 75.50
2024-08-02 14:37:28,065 [foster.py] => Task 6, Epoch 151/170 => Loss 2.914, Loss_clf 0.271, Loss_fe 0.120, Loss_kd 2.439, Train_accy 88.59
2024-08-02 14:37:32,042 [foster.py] => Task 6, Epoch 152/170 => Loss 2.888, Loss_clf 0.272, Loss_fe 0.098, Loss_kd 2.436, Train_accy 87.73, Test_accy 75.68
2024-08-02 14:37:36,032 [foster.py] => Task 6, Epoch 153/170 => Loss 2.875, Loss_clf 0.269, Loss_fe 0.100, Loss_kd 2.424, Train_accy 88.18, Test_accy 75.53
2024-08-02 14:37:39,933 [foster.py] => Task 6, Epoch 154/170 => Loss 2.902, Loss_clf 0.277, Loss_fe 0.106, Loss_kd 2.436, Train_accy 87.86, Test_accy 75.45
2024-08-02 14:37:43,842 [foster.py] => Task 6, Epoch 155/170 => Loss 2.868, Loss_clf 0.262, Loss_fe 0.102, Loss_kd 2.421, Train_accy 87.77, Test_accy 75.48
2024-08-02 14:37:46,205 [foster.py] => Task 6, Epoch 156/170 => Loss 2.856, Loss_clf 0.261, Loss_fe 0.099, Loss_kd 2.413, Train_accy 87.73
2024-08-02 14:37:50,109 [foster.py] => Task 6, Epoch 157/170 => Loss 2.919, Loss_clf 0.301, Loss_fe 0.112, Loss_kd 2.423, Train_accy 87.36, Test_accy 75.56
2024-08-02 14:37:53,974 [foster.py] => Task 6, Epoch 158/170 => Loss 2.884, Loss_clf 0.263, Loss_fe 0.107, Loss_kd 2.432, Train_accy 89.36, Test_accy 75.50
2024-08-02 14:37:57,845 [foster.py] => Task 6, Epoch 159/170 => Loss 2.910, Loss_clf 0.278, Loss_fe 0.105, Loss_kd 2.444, Train_accy 87.59, Test_accy 75.44
2024-08-02 14:38:01,735 [foster.py] => Task 6, Epoch 160/170 => Loss 2.888, Loss_clf 0.291, Loss_fe 0.098, Loss_kd 2.416, Train_accy 87.50, Test_accy 75.58
2024-08-02 14:38:04,175 [foster.py] => Task 6, Epoch 161/170 => Loss 2.901, Loss_clf 0.287, Loss_fe 0.099, Loss_kd 2.433, Train_accy 87.82
2024-08-02 14:38:08,073 [foster.py] => Task 6, Epoch 162/170 => Loss 2.854, Loss_clf 0.265, Loss_fe 0.092, Loss_kd 2.415, Train_accy 88.68, Test_accy 75.50
2024-08-02 14:38:11,991 [foster.py] => Task 6, Epoch 163/170 => Loss 2.879, Loss_clf 0.277, Loss_fe 0.099, Loss_kd 2.421, Train_accy 87.41, Test_accy 75.55
2024-08-02 14:38:15,864 [foster.py] => Task 6, Epoch 164/170 => Loss 2.940, Loss_clf 0.311, Loss_fe 0.126, Loss_kd 2.421, Train_accy 87.23, Test_accy 75.56
2024-08-02 14:38:19,700 [foster.py] => Task 6, Epoch 165/170 => Loss 2.935, Loss_clf 0.285, Loss_fe 0.122, Loss_kd 2.445, Train_accy 87.73, Test_accy 75.60
2024-08-02 14:38:22,076 [foster.py] => Task 6, Epoch 166/170 => Loss 2.933, Loss_clf 0.309, Loss_fe 0.099, Loss_kd 2.443, Train_accy 86.23
2024-08-02 14:38:25,971 [foster.py] => Task 6, Epoch 167/170 => Loss 2.942, Loss_clf 0.319, Loss_fe 0.119, Loss_kd 2.422, Train_accy 86.50, Test_accy 75.52
2024-08-02 14:38:29,812 [foster.py] => Task 6, Epoch 168/170 => Loss 2.867, Loss_clf 0.276, Loss_fe 0.102, Loss_kd 2.407, Train_accy 86.82, Test_accy 75.53
2024-08-02 14:38:33,689 [foster.py] => Task 6, Epoch 169/170 => Loss 2.904, Loss_clf 0.278, Loss_fe 0.109, Loss_kd 2.435, Train_accy 88.27, Test_accy 75.50
2024-08-02 14:38:37,597 [foster.py] => Task 6, Epoch 170/170 => Loss 2.880, Loss_clf 0.273, Loss_fe 0.095, Loss_kd 2.430, Train_accy 88.14, Test_accy 75.56
2024-08-02 14:38:37,600 [foster.py] => do not weight align teacher!
2024-08-02 14:38:37,603 [foster.py] => per cls weights : [1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869 1.01761869
 0.47143938 0.47143938]
2024-08-02 14:38:42,051 [foster.py] => SNet: Task 6, Epoch 1/130 => Loss 28.267,  Loss1 0.709, Train_accy 47.68, Test_accy 71.94
2024-08-02 14:38:45,282 [foster.py] => SNet: Task 6, Epoch 2/130 => Loss 28.190,  Loss1 0.708, Train_accy 58.77
2024-08-02 14:38:48,484 [foster.py] => SNet: Task 6, Epoch 3/130 => Loss 28.191,  Loss1 0.708, Train_accy 59.00
2024-08-02 14:38:51,722 [foster.py] => SNet: Task 6, Epoch 4/130 => Loss 28.143,  Loss1 0.708, Train_accy 58.68
2024-08-02 14:38:54,947 [foster.py] => SNet: Task 6, Epoch 5/130 => Loss 28.169,  Loss1 0.707, Train_accy 60.41
2024-08-02 14:38:59,155 [foster.py] => SNet: Task 6, Epoch 6/130 => Loss 28.146,  Loss1 0.708, Train_accy 64.23, Test_accy 73.45
2024-08-02 14:39:02,391 [foster.py] => SNet: Task 6, Epoch 7/130 => Loss 28.136,  Loss1 0.708, Train_accy 64.82
2024-08-02 14:39:05,634 [foster.py] => SNet: Task 6, Epoch 8/130 => Loss 28.147,  Loss1 0.707, Train_accy 65.73
2024-08-02 14:39:08,883 [foster.py] => SNet: Task 6, Epoch 9/130 => Loss 28.178,  Loss1 0.708, Train_accy 65.00
2024-08-02 14:39:12,117 [foster.py] => SNet: Task 6, Epoch 10/130 => Loss 28.157,  Loss1 0.708, Train_accy 67.50
2024-08-02 14:39:16,359 [foster.py] => SNet: Task 6, Epoch 11/130 => Loss 28.172,  Loss1 0.708, Train_accy 65.82, Test_accy 73.71
2024-08-02 14:39:19,611 [foster.py] => SNet: Task 6, Epoch 12/130 => Loss 28.192,  Loss1 0.708, Train_accy 68.05
2024-08-02 14:39:22,900 [foster.py] => SNet: Task 6, Epoch 13/130 => Loss 28.139,  Loss1 0.708, Train_accy 67.23
2024-08-02 14:39:26,141 [foster.py] => SNet: Task 6, Epoch 14/130 => Loss 28.117,  Loss1 0.707, Train_accy 68.32
2024-08-02 14:39:29,350 [foster.py] => SNet: Task 6, Epoch 15/130 => Loss 28.152,  Loss1 0.707, Train_accy 68.91
2024-08-02 14:39:33,547 [foster.py] => SNet: Task 6, Epoch 16/130 => Loss 28.160,  Loss1 0.707, Train_accy 68.36, Test_accy 73.90
2024-08-02 14:39:36,773 [foster.py] => SNet: Task 6, Epoch 17/130 => Loss 28.163,  Loss1 0.707, Train_accy 69.86
2024-08-02 14:39:39,983 [foster.py] => SNet: Task 6, Epoch 18/130 => Loss 28.091,  Loss1 0.707, Train_accy 69.23
2024-08-02 14:39:43,211 [foster.py] => SNet: Task 6, Epoch 19/130 => Loss 28.116,  Loss1 0.708, Train_accy 68.14
2024-08-02 14:39:46,425 [foster.py] => SNet: Task 6, Epoch 20/130 => Loss 28.121,  Loss1 0.707, Train_accy 69.18
2024-08-02 14:39:50,635 [foster.py] => SNet: Task 6, Epoch 21/130 => Loss 28.120,  Loss1 0.708, Train_accy 70.18, Test_accy 73.71
2024-08-02 14:39:53,885 [foster.py] => SNet: Task 6, Epoch 22/130 => Loss 28.169,  Loss1 0.708, Train_accy 70.05
2024-08-02 14:39:57,098 [foster.py] => SNet: Task 6, Epoch 23/130 => Loss 28.165,  Loss1 0.707, Train_accy 68.14
2024-08-02 14:40:00,322 [foster.py] => SNet: Task 6, Epoch 24/130 => Loss 28.140,  Loss1 0.708, Train_accy 70.27
2024-08-02 14:40:03,553 [foster.py] => SNet: Task 6, Epoch 25/130 => Loss 28.122,  Loss1 0.707, Train_accy 71.00
2024-08-02 14:40:07,752 [foster.py] => SNet: Task 6, Epoch 26/130 => Loss 28.174,  Loss1 0.707, Train_accy 69.68, Test_accy 74.00
2024-08-02 14:40:10,970 [foster.py] => SNet: Task 6, Epoch 27/130 => Loss 28.133,  Loss1 0.707, Train_accy 70.77
2024-08-02 14:40:14,182 [foster.py] => SNet: Task 6, Epoch 28/130 => Loss 28.135,  Loss1 0.708, Train_accy 70.77
2024-08-02 14:40:17,422 [foster.py] => SNet: Task 6, Epoch 29/130 => Loss 28.108,  Loss1 0.708, Train_accy 70.95
2024-08-02 14:40:20,629 [foster.py] => SNet: Task 6, Epoch 30/130 => Loss 28.158,  Loss1 0.707, Train_accy 71.18
2024-08-02 14:40:24,815 [foster.py] => SNet: Task 6, Epoch 31/130 => Loss 28.087,  Loss1 0.707, Train_accy 70.64, Test_accy 73.74
2024-08-02 14:40:28,028 [foster.py] => SNet: Task 6, Epoch 32/130 => Loss 28.105,  Loss1 0.708, Train_accy 69.64
2024-08-02 14:40:31,304 [foster.py] => SNet: Task 6, Epoch 33/130 => Loss 28.076,  Loss1 0.708, Train_accy 70.50
2024-08-02 14:40:34,520 [foster.py] => SNet: Task 6, Epoch 34/130 => Loss 28.107,  Loss1 0.708, Train_accy 71.00
2024-08-02 14:40:37,736 [foster.py] => SNet: Task 6, Epoch 35/130 => Loss 28.133,  Loss1 0.707, Train_accy 71.73
2024-08-02 14:40:41,931 [foster.py] => SNet: Task 6, Epoch 36/130 => Loss 28.128,  Loss1 0.708, Train_accy 70.59, Test_accy 74.21
2024-08-02 14:40:45,159 [foster.py] => SNet: Task 6, Epoch 37/130 => Loss 28.171,  Loss1 0.707, Train_accy 70.73
2024-08-02 14:40:48,368 [foster.py] => SNet: Task 6, Epoch 38/130 => Loss 28.162,  Loss1 0.707, Train_accy 71.05
2024-08-02 14:40:51,569 [foster.py] => SNet: Task 6, Epoch 39/130 => Loss 28.168,  Loss1 0.707, Train_accy 71.68
2024-08-02 14:40:54,777 [foster.py] => SNet: Task 6, Epoch 40/130 => Loss 28.110,  Loss1 0.708, Train_accy 72.00
2024-08-02 14:40:58,983 [foster.py] => SNet: Task 6, Epoch 41/130 => Loss 28.173,  Loss1 0.708, Train_accy 69.73, Test_accy 74.03
2024-08-02 14:41:02,200 [foster.py] => SNet: Task 6, Epoch 42/130 => Loss 28.158,  Loss1 0.707, Train_accy 69.27
2024-08-02 14:41:05,450 [foster.py] => SNet: Task 6, Epoch 43/130 => Loss 28.145,  Loss1 0.707, Train_accy 70.95
2024-08-02 14:41:08,677 [foster.py] => SNet: Task 6, Epoch 44/130 => Loss 28.127,  Loss1 0.708, Train_accy 70.18
2024-08-02 14:41:11,900 [foster.py] => SNet: Task 6, Epoch 45/130 => Loss 28.109,  Loss1 0.708, Train_accy 72.82
2024-08-02 14:41:16,083 [foster.py] => SNet: Task 6, Epoch 46/130 => Loss 28.174,  Loss1 0.708, Train_accy 69.91, Test_accy 74.27
2024-08-02 14:41:19,297 [foster.py] => SNet: Task 6, Epoch 47/130 => Loss 28.130,  Loss1 0.708, Train_accy 72.18
2024-08-02 14:41:22,520 [foster.py] => SNet: Task 6, Epoch 48/130 => Loss 28.122,  Loss1 0.707, Train_accy 72.18
2024-08-02 14:41:25,740 [foster.py] => SNet: Task 6, Epoch 49/130 => Loss 28.145,  Loss1 0.708, Train_accy 71.64
2024-08-02 14:41:28,946 [foster.py] => SNet: Task 6, Epoch 50/130 => Loss 28.129,  Loss1 0.708, Train_accy 73.68
2024-08-02 14:41:33,173 [foster.py] => SNet: Task 6, Epoch 51/130 => Loss 28.121,  Loss1 0.707, Train_accy 72.00, Test_accy 74.19
2024-08-02 14:41:36,386 [foster.py] => SNet: Task 6, Epoch 52/130 => Loss 28.113,  Loss1 0.707, Train_accy 71.68
2024-08-02 14:41:39,672 [foster.py] => SNet: Task 6, Epoch 53/130 => Loss 28.064,  Loss1 0.707, Train_accy 72.27
2024-08-02 14:41:42,897 [foster.py] => SNet: Task 6, Epoch 54/130 => Loss 28.062,  Loss1 0.707, Train_accy 72.59
2024-08-02 14:41:46,109 [foster.py] => SNet: Task 6, Epoch 55/130 => Loss 28.109,  Loss1 0.707, Train_accy 71.41
2024-08-02 14:41:50,318 [foster.py] => SNet: Task 6, Epoch 56/130 => Loss 28.107,  Loss1 0.708, Train_accy 72.64, Test_accy 74.35
2024-08-02 14:41:53,552 [foster.py] => SNet: Task 6, Epoch 57/130 => Loss 28.168,  Loss1 0.707, Train_accy 71.77
2024-08-02 14:41:56,763 [foster.py] => SNet: Task 6, Epoch 58/130 => Loss 28.152,  Loss1 0.707, Train_accy 72.50
2024-08-02 14:41:59,966 [foster.py] => SNet: Task 6, Epoch 59/130 => Loss 28.153,  Loss1 0.707, Train_accy 73.91
2024-08-02 14:42:03,183 [foster.py] => SNet: Task 6, Epoch 60/130 => Loss 28.116,  Loss1 0.707, Train_accy 72.27
2024-08-02 14:42:07,401 [foster.py] => SNet: Task 6, Epoch 61/130 => Loss 28.136,  Loss1 0.707, Train_accy 73.27, Test_accy 74.39
2024-08-02 14:42:10,630 [foster.py] => SNet: Task 6, Epoch 62/130 => Loss 28.118,  Loss1 0.707, Train_accy 72.86
2024-08-02 14:42:13,859 [foster.py] => SNet: Task 6, Epoch 63/130 => Loss 28.141,  Loss1 0.708, Train_accy 71.32
2024-08-02 14:42:17,101 [foster.py] => SNet: Task 6, Epoch 64/130 => Loss 28.113,  Loss1 0.707, Train_accy 71.82
2024-08-02 14:42:20,311 [foster.py] => SNet: Task 6, Epoch 65/130 => Loss 28.150,  Loss1 0.707, Train_accy 72.27
2024-08-02 14:42:24,538 [foster.py] => SNet: Task 6, Epoch 66/130 => Loss 28.149,  Loss1 0.708, Train_accy 72.86, Test_accy 73.92
2024-08-02 14:42:27,740 [foster.py] => SNet: Task 6, Epoch 67/130 => Loss 28.134,  Loss1 0.707, Train_accy 73.00
2024-08-02 14:42:30,969 [foster.py] => SNet: Task 6, Epoch 68/130 => Loss 28.115,  Loss1 0.707, Train_accy 72.23
2024-08-02 14:42:34,190 [foster.py] => SNet: Task 6, Epoch 69/130 => Loss 28.077,  Loss1 0.708, Train_accy 72.45
2024-08-02 14:42:37,399 [foster.py] => SNet: Task 6, Epoch 70/130 => Loss 28.134,  Loss1 0.708, Train_accy 73.05
2024-08-02 14:42:41,617 [foster.py] => SNet: Task 6, Epoch 71/130 => Loss 28.117,  Loss1 0.707, Train_accy 72.64, Test_accy 74.71
2024-08-02 14:42:44,827 [foster.py] => SNet: Task 6, Epoch 72/130 => Loss 28.121,  Loss1 0.708, Train_accy 73.45
2024-08-02 14:42:48,113 [foster.py] => SNet: Task 6, Epoch 73/130 => Loss 28.142,  Loss1 0.708, Train_accy 72.55
2024-08-02 14:42:51,339 [foster.py] => SNet: Task 6, Epoch 74/130 => Loss 28.098,  Loss1 0.708, Train_accy 73.59
2024-08-02 14:42:54,555 [foster.py] => SNet: Task 6, Epoch 75/130 => Loss 28.116,  Loss1 0.707, Train_accy 73.32
2024-08-02 14:42:58,753 [foster.py] => SNet: Task 6, Epoch 76/130 => Loss 28.109,  Loss1 0.708, Train_accy 73.27, Test_accy 74.05
2024-08-02 14:43:01,989 [foster.py] => SNet: Task 6, Epoch 77/130 => Loss 28.150,  Loss1 0.707, Train_accy 73.82
2024-08-02 14:43:05,205 [foster.py] => SNet: Task 6, Epoch 78/130 => Loss 28.128,  Loss1 0.708, Train_accy 72.36
2024-08-02 14:43:08,423 [foster.py] => SNet: Task 6, Epoch 79/130 => Loss 28.114,  Loss1 0.708, Train_accy 74.45
2024-08-02 14:43:11,648 [foster.py] => SNet: Task 6, Epoch 80/130 => Loss 28.152,  Loss1 0.708, Train_accy 72.86
2024-08-02 14:43:15,838 [foster.py] => SNet: Task 6, Epoch 81/130 => Loss 28.151,  Loss1 0.708, Train_accy 72.77, Test_accy 74.34
2024-08-02 14:43:19,053 [foster.py] => SNet: Task 6, Epoch 82/130 => Loss 28.167,  Loss1 0.707, Train_accy 73.23
2024-08-02 14:43:22,278 [foster.py] => SNet: Task 6, Epoch 83/130 => Loss 28.081,  Loss1 0.707, Train_accy 73.14
2024-08-02 14:43:25,519 [foster.py] => SNet: Task 6, Epoch 84/130 => Loss 28.089,  Loss1 0.707, Train_accy 73.77
2024-08-02 14:43:28,743 [foster.py] => SNet: Task 6, Epoch 85/130 => Loss 28.105,  Loss1 0.707, Train_accy 72.18
2024-08-02 14:43:32,957 [foster.py] => SNet: Task 6, Epoch 86/130 => Loss 28.111,  Loss1 0.707, Train_accy 71.45, Test_accy 74.53
2024-08-02 14:43:36,196 [foster.py] => SNet: Task 6, Epoch 87/130 => Loss 28.162,  Loss1 0.707, Train_accy 73.05
2024-08-02 14:43:39,396 [foster.py] => SNet: Task 6, Epoch 88/130 => Loss 28.146,  Loss1 0.707, Train_accy 73.77
2024-08-02 14:43:42,606 [foster.py] => SNet: Task 6, Epoch 89/130 => Loss 28.165,  Loss1 0.707, Train_accy 73.82
2024-08-02 14:43:45,799 [foster.py] => SNet: Task 6, Epoch 90/130 => Loss 28.147,  Loss1 0.707, Train_accy 73.50
2024-08-02 14:43:50,071 [foster.py] => SNet: Task 6, Epoch 91/130 => Loss 28.149,  Loss1 0.707, Train_accy 73.73, Test_accy 74.18
2024-08-02 14:43:53,266 [foster.py] => SNet: Task 6, Epoch 92/130 => Loss 28.095,  Loss1 0.708, Train_accy 74.45
2024-08-02 14:43:56,566 [foster.py] => SNet: Task 6, Epoch 93/130 => Loss 28.103,  Loss1 0.707, Train_accy 73.05
2024-08-02 14:43:59,828 [foster.py] => SNet: Task 6, Epoch 94/130 => Loss 28.169,  Loss1 0.707, Train_accy 72.41
2024-08-02 14:44:03,079 [foster.py] => SNet: Task 6, Epoch 95/130 => Loss 28.139,  Loss1 0.708, Train_accy 72.45
2024-08-02 14:44:07,271 [foster.py] => SNet: Task 6, Epoch 96/130 => Loss 28.099,  Loss1 0.707, Train_accy 73.73, Test_accy 74.11
2024-08-02 14:44:10,484 [foster.py] => SNet: Task 6, Epoch 97/130 => Loss 28.175,  Loss1 0.708, Train_accy 73.59
2024-08-02 14:44:13,706 [foster.py] => SNet: Task 6, Epoch 98/130 => Loss 28.131,  Loss1 0.708, Train_accy 74.45
2024-08-02 14:44:16,918 [foster.py] => SNet: Task 6, Epoch 99/130 => Loss 28.145,  Loss1 0.707, Train_accy 72.91
2024-08-02 14:44:20,169 [foster.py] => SNet: Task 6, Epoch 100/130 => Loss 28.141,  Loss1 0.707, Train_accy 73.73
2024-08-02 14:44:24,345 [foster.py] => SNet: Task 6, Epoch 101/130 => Loss 28.139,  Loss1 0.707, Train_accy 72.59, Test_accy 74.37
2024-08-02 14:44:27,557 [foster.py] => SNet: Task 6, Epoch 102/130 => Loss 28.128,  Loss1 0.707, Train_accy 73.64
2024-08-02 14:44:30,787 [foster.py] => SNet: Task 6, Epoch 103/130 => Loss 28.143,  Loss1 0.707, Train_accy 74.27
2024-08-02 14:44:33,999 [foster.py] => SNet: Task 6, Epoch 104/130 => Loss 28.066,  Loss1 0.708, Train_accy 72.77
2024-08-02 14:44:37,229 [foster.py] => SNet: Task 6, Epoch 105/130 => Loss 28.136,  Loss1 0.707, Train_accy 73.82
2024-08-02 14:44:41,404 [foster.py] => SNet: Task 6, Epoch 106/130 => Loss 28.096,  Loss1 0.708, Train_accy 72.82, Test_accy 74.32
2024-08-02 14:44:44,631 [foster.py] => SNet: Task 6, Epoch 107/130 => Loss 28.114,  Loss1 0.708, Train_accy 72.45
2024-08-02 14:44:47,860 [foster.py] => SNet: Task 6, Epoch 108/130 => Loss 28.145,  Loss1 0.708, Train_accy 72.50
2024-08-02 14:44:51,091 [foster.py] => SNet: Task 6, Epoch 109/130 => Loss 28.121,  Loss1 0.708, Train_accy 73.50
2024-08-02 14:44:54,348 [foster.py] => SNet: Task 6, Epoch 110/130 => Loss 28.108,  Loss1 0.707, Train_accy 74.27
2024-08-02 14:44:58,548 [foster.py] => SNet: Task 6, Epoch 111/130 => Loss 28.106,  Loss1 0.708, Train_accy 73.09, Test_accy 74.63
2024-08-02 14:45:01,780 [foster.py] => SNet: Task 6, Epoch 112/130 => Loss 28.122,  Loss1 0.707, Train_accy 73.41
2024-08-02 14:45:05,069 [foster.py] => SNet: Task 6, Epoch 113/130 => Loss 28.134,  Loss1 0.707, Train_accy 73.00
2024-08-02 14:45:08,290 [foster.py] => SNet: Task 6, Epoch 114/130 => Loss 28.152,  Loss1 0.708, Train_accy 73.95
2024-08-02 14:45:11,543 [foster.py] => SNet: Task 6, Epoch 115/130 => Loss 28.128,  Loss1 0.707, Train_accy 73.05
2024-08-02 14:45:15,722 [foster.py] => SNet: Task 6, Epoch 116/130 => Loss 28.117,  Loss1 0.707, Train_accy 73.59, Test_accy 74.45
2024-08-02 14:45:18,939 [foster.py] => SNet: Task 6, Epoch 117/130 => Loss 28.137,  Loss1 0.707, Train_accy 73.41
2024-08-02 14:45:22,164 [foster.py] => SNet: Task 6, Epoch 118/130 => Loss 28.140,  Loss1 0.707, Train_accy 73.77
2024-08-02 14:45:25,395 [foster.py] => SNet: Task 6, Epoch 119/130 => Loss 28.121,  Loss1 0.707, Train_accy 74.14
2024-08-02 14:45:28,625 [foster.py] => SNet: Task 6, Epoch 120/130 => Loss 28.116,  Loss1 0.707, Train_accy 73.36
2024-08-02 14:45:32,830 [foster.py] => SNet: Task 6, Epoch 121/130 => Loss 28.151,  Loss1 0.707, Train_accy 73.32, Test_accy 74.56
2024-08-02 14:45:36,059 [foster.py] => SNet: Task 6, Epoch 122/130 => Loss 28.160,  Loss1 0.707, Train_accy 74.00
2024-08-02 14:45:39,267 [foster.py] => SNet: Task 6, Epoch 123/130 => Loss 28.073,  Loss1 0.707, Train_accy 73.50
2024-08-02 14:45:42,485 [foster.py] => SNet: Task 6, Epoch 124/130 => Loss 28.168,  Loss1 0.708, Train_accy 73.55
2024-08-02 14:45:45,670 [foster.py] => SNet: Task 6, Epoch 125/130 => Loss 28.099,  Loss1 0.708, Train_accy 73.41
2024-08-02 14:45:49,878 [foster.py] => SNet: Task 6, Epoch 126/130 => Loss 28.096,  Loss1 0.708, Train_accy 73.05, Test_accy 74.53
2024-08-02 14:45:53,083 [foster.py] => SNet: Task 6, Epoch 127/130 => Loss 28.079,  Loss1 0.708, Train_accy 73.05
2024-08-02 14:45:56,315 [foster.py] => SNet: Task 6, Epoch 128/130 => Loss 28.108,  Loss1 0.708, Train_accy 73.32
2024-08-02 14:45:59,539 [foster.py] => SNet: Task 6, Epoch 129/130 => Loss 28.123,  Loss1 0.708, Train_accy 74.05
2024-08-02 14:46:02,773 [foster.py] => SNet: Task 6, Epoch 130/130 => Loss 28.116,  Loss1 0.708, Train_accy 75.00
2024-08-02 14:46:02,774 [foster.py] => do not weight align student!
2024-08-02 14:46:03,761 [foster.py] => darknet eval: 
2024-08-02 14:46:03,762 [foster.py] => CNN top1 curve: 74.5
2024-08-02 14:46:03,762 [foster.py] => CNN top5 curve: 94.03
2024-08-02 14:46:03,762 [foster.py] => CNN top1 平均值: 74.50
2024-08-02 14:46:03,768 [foster.py] => timees : 1053.6839716434479
2024-08-02 14:46:03,769 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 14:46:22,915 [foster.py] => Exemplar size: 1240
2024-08-02 14:46:22,916 [trainer.py] => CNN: {'total': 75.56, '00-09': 80.9, '10-19': 71.5, '20-29': 80.4, '30-39': 75.5, '40-49': 79.8, '50-59': 64.0, '60-69': 82.0, 'old': 75.35, 'new': 82.0}
2024-08-02 14:46:22,916 [trainer.py] => NME: {'total': 71.27, '00-09': 75.5, '10-19': 66.0, '20-29': 77.3, '30-39': 71.7, '40-49': 74.3, '50-59': 59.1, '60-69': 90.0, 'old': 70.65, 'new': 90.0}
2024-08-02 14:46:22,916 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56]
2024-08-02 14:46:22,916 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52]
2024-08-02 14:46:22,916 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27]
2024-08-02 14:46:22,916 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56]

2024-08-02 14:46:22,916 [trainer.py] => CNN top1 平均值: 78.46
2024-08-02 14:46:22,919 [trainer.py] => All params: 1170476
2024-08-02 14:46:22,921 [trainer.py] => Trainable params: 589302
2024-08-02 14:46:22,981 [foster.py] => Learning on 62-64
2024-08-02 14:46:22,984 [foster.py] => All params: 1170994
2024-08-02 14:46:22,986 [foster.py] => Trainable params: 589690
2024-08-02 14:46:23,023 [foster.py] => per cls weights : [1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  1.0143557  1.0143557  1.0143557  1.0143557
 1.0143557  1.0143557  0.55497338 0.55497338]
2024-08-02 14:46:25,497 [foster.py] => Task 7, Epoch 1/170 => Loss 5.388, Loss_clf 1.100, Loss_fe 1.779, Loss_kd 2.430, Train_accy 66.21
2024-08-02 14:46:29,449 [foster.py] => Task 7, Epoch 2/170 => Loss 3.824, Loss_clf 0.556, Loss_fe 0.771, Loss_kd 2.418, Train_accy 70.94, Test_accy 71.77
2024-08-02 14:46:33,328 [foster.py] => Task 7, Epoch 3/170 => Loss 3.691, Loss_clf 0.522, Loss_fe 0.653, Loss_kd 2.436, Train_accy 69.06, Test_accy 72.31
2024-08-02 14:46:37,211 [foster.py] => Task 7, Epoch 4/170 => Loss 3.546, Loss_clf 0.494, Loss_fe 0.558, Loss_kd 2.414, Train_accy 72.10, Test_accy 72.81
2024-08-02 14:46:41,105 [foster.py] => Task 7, Epoch 5/170 => Loss 3.512, Loss_clf 0.488, Loss_fe 0.512, Loss_kd 2.432, Train_accy 70.22, Test_accy 72.50
2024-08-02 14:46:43,455 [foster.py] => Task 7, Epoch 6/170 => Loss 3.516, Loss_clf 0.480, Loss_fe 0.502, Loss_kd 2.453, Train_accy 70.36
2024-08-02 14:46:47,315 [foster.py] => Task 7, Epoch 7/170 => Loss 3.471, Loss_clf 0.487, Loss_fe 0.456, Loss_kd 2.448, Train_accy 69.11, Test_accy 72.78
2024-08-02 14:46:51,207 [foster.py] => Task 7, Epoch 8/170 => Loss 3.467, Loss_clf 0.490, Loss_fe 0.442, Loss_kd 2.455, Train_accy 71.47, Test_accy 72.98
2024-08-02 14:46:55,076 [foster.py] => Task 7, Epoch 9/170 => Loss 3.393, Loss_clf 0.457, Loss_fe 0.437, Loss_kd 2.419, Train_accy 72.46, Test_accy 72.53
2024-08-02 14:46:58,996 [foster.py] => Task 7, Epoch 10/170 => Loss 3.364, Loss_clf 0.448, Loss_fe 0.404, Loss_kd 2.432, Train_accy 71.96, Test_accy 72.97
2024-08-02 14:47:01,368 [foster.py] => Task 7, Epoch 11/170 => Loss 3.397, Loss_clf 0.462, Loss_fe 0.413, Loss_kd 2.442, Train_accy 71.88
2024-08-02 14:47:05,289 [foster.py] => Task 7, Epoch 12/170 => Loss 3.310, Loss_clf 0.420, Loss_fe 0.400, Loss_kd 2.411, Train_accy 74.20, Test_accy 72.80
2024-08-02 14:47:09,178 [foster.py] => Task 7, Epoch 13/170 => Loss 3.399, Loss_clf 0.473, Loss_fe 0.394, Loss_kd 2.451, Train_accy 74.78, Test_accy 72.83
2024-08-02 14:47:13,080 [foster.py] => Task 7, Epoch 14/170 => Loss 3.336, Loss_clf 0.447, Loss_fe 0.385, Loss_kd 2.424, Train_accy 73.71, Test_accy 72.91
2024-08-02 14:47:16,999 [foster.py] => Task 7, Epoch 15/170 => Loss 3.356, Loss_clf 0.443, Loss_fe 0.395, Loss_kd 2.438, Train_accy 74.24, Test_accy 72.95
2024-08-02 14:47:19,321 [foster.py] => Task 7, Epoch 16/170 => Loss 3.236, Loss_clf 0.399, Loss_fe 0.347, Loss_kd 2.410, Train_accy 72.99
2024-08-02 14:47:23,195 [foster.py] => Task 7, Epoch 17/170 => Loss 3.311, Loss_clf 0.450, Loss_fe 0.336, Loss_kd 2.444, Train_accy 73.17, Test_accy 73.20
2024-08-02 14:47:27,111 [foster.py] => Task 7, Epoch 18/170 => Loss 3.312, Loss_clf 0.432, Loss_fe 0.356, Loss_kd 2.444, Train_accy 77.28, Test_accy 73.25
2024-08-02 14:47:31,065 [foster.py] => Task 7, Epoch 19/170 => Loss 3.308, Loss_clf 0.446, Loss_fe 0.365, Loss_kd 2.418, Train_accy 75.67, Test_accy 72.86
2024-08-02 14:47:34,970 [foster.py] => Task 7, Epoch 20/170 => Loss 3.279, Loss_clf 0.406, Loss_fe 0.360, Loss_kd 2.434, Train_accy 75.98, Test_accy 72.95
2024-08-02 14:47:37,321 [foster.py] => Task 7, Epoch 21/170 => Loss 3.350, Loss_clf 0.460, Loss_fe 0.364, Loss_kd 2.445, Train_accy 75.27
2024-08-02 14:47:41,199 [foster.py] => Task 7, Epoch 22/170 => Loss 3.276, Loss_clf 0.423, Loss_fe 0.342, Loss_kd 2.430, Train_accy 77.41, Test_accy 72.39
2024-08-02 14:47:45,121 [foster.py] => Task 7, Epoch 23/170 => Loss 3.283, Loss_clf 0.445, Loss_fe 0.330, Loss_kd 2.428, Train_accy 75.27, Test_accy 72.91
2024-08-02 14:47:49,047 [foster.py] => Task 7, Epoch 24/170 => Loss 3.192, Loss_clf 0.404, Loss_fe 0.280, Loss_kd 2.428, Train_accy 76.52, Test_accy 72.98
2024-08-02 14:47:52,900 [foster.py] => Task 7, Epoch 25/170 => Loss 3.184, Loss_clf 0.380, Loss_fe 0.297, Loss_kd 2.427, Train_accy 79.60, Test_accy 72.80
2024-08-02 14:47:55,265 [foster.py] => Task 7, Epoch 26/170 => Loss 3.192, Loss_clf 0.380, Loss_fe 0.314, Loss_kd 2.418, Train_accy 79.02
2024-08-02 14:47:59,179 [foster.py] => Task 7, Epoch 27/170 => Loss 3.237, Loss_clf 0.389, Loss_fe 0.308, Loss_kd 2.459, Train_accy 79.51, Test_accy 73.03
2024-08-02 14:48:03,067 [foster.py] => Task 7, Epoch 28/170 => Loss 3.259, Loss_clf 0.422, Loss_fe 0.327, Loss_kd 2.430, Train_accy 78.93, Test_accy 72.94
2024-08-02 14:48:06,974 [foster.py] => Task 7, Epoch 29/170 => Loss 3.215, Loss_clf 0.396, Loss_fe 0.307, Loss_kd 2.433, Train_accy 77.05, Test_accy 73.31
2024-08-02 14:48:10,851 [foster.py] => Task 7, Epoch 30/170 => Loss 3.217, Loss_clf 0.393, Loss_fe 0.298, Loss_kd 2.445, Train_accy 78.21, Test_accy 72.70
2024-08-02 14:48:13,209 [foster.py] => Task 7, Epoch 31/170 => Loss 3.197, Loss_clf 0.389, Loss_fe 0.285, Loss_kd 2.443, Train_accy 76.61
2024-08-02 14:48:17,111 [foster.py] => Task 7, Epoch 32/170 => Loss 3.187, Loss_clf 0.395, Loss_fe 0.281, Loss_kd 2.431, Train_accy 78.71, Test_accy 73.34
2024-08-02 14:48:20,993 [foster.py] => Task 7, Epoch 33/170 => Loss 3.166, Loss_clf 0.373, Loss_fe 0.290, Loss_kd 2.422, Train_accy 80.45, Test_accy 73.34
2024-08-02 14:48:24,853 [foster.py] => Task 7, Epoch 34/170 => Loss 3.151, Loss_clf 0.378, Loss_fe 0.265, Loss_kd 2.427, Train_accy 78.08, Test_accy 73.38
2024-08-02 14:48:28,738 [foster.py] => Task 7, Epoch 35/170 => Loss 3.186, Loss_clf 0.399, Loss_fe 0.269, Loss_kd 2.439, Train_accy 79.24, Test_accy 72.92
2024-08-02 14:48:31,106 [foster.py] => Task 7, Epoch 36/170 => Loss 3.195, Loss_clf 0.387, Loss_fe 0.288, Loss_kd 2.439, Train_accy 79.64
2024-08-02 14:48:34,969 [foster.py] => Task 7, Epoch 37/170 => Loss 3.194, Loss_clf 0.401, Loss_fe 0.274, Loss_kd 2.439, Train_accy 77.19, Test_accy 73.11
2024-08-02 14:48:38,866 [foster.py] => Task 7, Epoch 38/170 => Loss 3.167, Loss_clf 0.394, Loss_fe 0.265, Loss_kd 2.428, Train_accy 78.48, Test_accy 73.28
2024-08-02 14:48:42,753 [foster.py] => Task 7, Epoch 39/170 => Loss 3.093, Loss_clf 0.352, Loss_fe 0.257, Loss_kd 2.405, Train_accy 81.25, Test_accy 73.19
2024-08-02 14:48:46,645 [foster.py] => Task 7, Epoch 40/170 => Loss 3.122, Loss_clf 0.369, Loss_fe 0.260, Loss_kd 2.413, Train_accy 80.36, Test_accy 73.23
2024-08-02 14:48:49,022 [foster.py] => Task 7, Epoch 41/170 => Loss 3.152, Loss_clf 0.366, Loss_fe 0.282, Loss_kd 2.424, Train_accy 80.94
2024-08-02 14:48:52,897 [foster.py] => Task 7, Epoch 42/170 => Loss 3.155, Loss_clf 0.381, Loss_fe 0.256, Loss_kd 2.438, Train_accy 80.45, Test_accy 73.44
2024-08-02 14:48:56,752 [foster.py] => Task 7, Epoch 43/170 => Loss 3.167, Loss_clf 0.377, Loss_fe 0.268, Loss_kd 2.441, Train_accy 80.13, Test_accy 73.66
2024-08-02 14:49:00,633 [foster.py] => Task 7, Epoch 44/170 => Loss 3.128, Loss_clf 0.364, Loss_fe 0.259, Loss_kd 2.424, Train_accy 80.98, Test_accy 73.14
2024-08-02 14:49:04,507 [foster.py] => Task 7, Epoch 45/170 => Loss 3.169, Loss_clf 0.389, Loss_fe 0.273, Loss_kd 2.426, Train_accy 79.64, Test_accy 73.50
2024-08-02 14:49:06,939 [foster.py] => Task 7, Epoch 46/170 => Loss 3.086, Loss_clf 0.349, Loss_fe 0.251, Loss_kd 2.407, Train_accy 79.29
2024-08-02 14:49:10,880 [foster.py] => Task 7, Epoch 47/170 => Loss 3.247, Loss_clf 0.420, Loss_fe 0.286, Loss_kd 2.460, Train_accy 80.58, Test_accy 73.25
2024-08-02 14:49:14,760 [foster.py] => Task 7, Epoch 48/170 => Loss 3.115, Loss_clf 0.360, Loss_fe 0.251, Loss_kd 2.424, Train_accy 80.98, Test_accy 73.47
2024-08-02 14:49:18,632 [foster.py] => Task 7, Epoch 49/170 => Loss 3.130, Loss_clf 0.370, Loss_fe 0.248, Loss_kd 2.432, Train_accy 80.04, Test_accy 73.28
2024-08-02 14:49:22,512 [foster.py] => Task 7, Epoch 50/170 => Loss 3.153, Loss_clf 0.378, Loss_fe 0.252, Loss_kd 2.443, Train_accy 81.34, Test_accy 72.86
2024-08-02 14:49:24,851 [foster.py] => Task 7, Epoch 51/170 => Loss 3.153, Loss_clf 0.365, Loss_fe 0.254, Loss_kd 2.453, Train_accy 81.83
2024-08-02 14:49:28,720 [foster.py] => Task 7, Epoch 52/170 => Loss 3.047, Loss_clf 0.340, Loss_fe 0.210, Loss_kd 2.418, Train_accy 81.38, Test_accy 73.23
2024-08-02 14:49:32,626 [foster.py] => Task 7, Epoch 53/170 => Loss 3.060, Loss_clf 0.348, Loss_fe 0.224, Loss_kd 2.409, Train_accy 81.88, Test_accy 73.31
2024-08-02 14:49:36,516 [foster.py] => Task 7, Epoch 54/170 => Loss 3.143, Loss_clf 0.380, Loss_fe 0.218, Loss_kd 2.465, Train_accy 82.19, Test_accy 73.05
2024-08-02 14:49:40,394 [foster.py] => Task 7, Epoch 55/170 => Loss 3.137, Loss_clf 0.373, Loss_fe 0.262, Loss_kd 2.423, Train_accy 81.34, Test_accy 73.44
2024-08-02 14:49:42,755 [foster.py] => Task 7, Epoch 56/170 => Loss 3.124, Loss_clf 0.387, Loss_fe 0.217, Loss_kd 2.440, Train_accy 81.43
2024-08-02 14:49:46,626 [foster.py] => Task 7, Epoch 57/170 => Loss 3.117, Loss_clf 0.374, Loss_fe 0.227, Loss_kd 2.436, Train_accy 82.37, Test_accy 73.12
2024-08-02 14:49:50,532 [foster.py] => Task 7, Epoch 58/170 => Loss 3.058, Loss_clf 0.351, Loss_fe 0.210, Loss_kd 2.417, Train_accy 82.59, Test_accy 73.50
2024-08-02 14:49:54,458 [foster.py] => Task 7, Epoch 59/170 => Loss 3.150, Loss_clf 0.385, Loss_fe 0.218, Loss_kd 2.465, Train_accy 83.62, Test_accy 73.77
2024-08-02 14:49:58,341 [foster.py] => Task 7, Epoch 60/170 => Loss 3.051, Loss_clf 0.338, Loss_fe 0.200, Loss_kd 2.432, Train_accy 82.68, Test_accy 73.39
2024-08-02 14:50:00,739 [foster.py] => Task 7, Epoch 61/170 => Loss 3.022, Loss_clf 0.312, Loss_fe 0.198, Loss_kd 2.432, Train_accy 83.04
2024-08-02 14:50:04,682 [foster.py] => Task 7, Epoch 62/170 => Loss 3.045, Loss_clf 0.345, Loss_fe 0.197, Loss_kd 2.424, Train_accy 83.88, Test_accy 73.38
2024-08-02 14:50:08,572 [foster.py] => Task 7, Epoch 63/170 => Loss 3.071, Loss_clf 0.347, Loss_fe 0.217, Loss_kd 2.428, Train_accy 82.10, Test_accy 73.50
2024-08-02 14:50:12,463 [foster.py] => Task 7, Epoch 64/170 => Loss 3.124, Loss_clf 0.374, Loss_fe 0.230, Loss_kd 2.440, Train_accy 84.87, Test_accy 73.50
2024-08-02 14:50:16,374 [foster.py] => Task 7, Epoch 65/170 => Loss 3.038, Loss_clf 0.337, Loss_fe 0.199, Loss_kd 2.423, Train_accy 82.41, Test_accy 73.81
2024-08-02 14:50:18,730 [foster.py] => Task 7, Epoch 66/170 => Loss 3.034, Loss_clf 0.330, Loss_fe 0.199, Loss_kd 2.425, Train_accy 83.04
2024-08-02 14:50:22,593 [foster.py] => Task 7, Epoch 67/170 => Loss 3.090, Loss_clf 0.366, Loss_fe 0.202, Loss_kd 2.441, Train_accy 84.60, Test_accy 73.48
2024-08-02 14:50:26,575 [foster.py] => Task 7, Epoch 68/170 => Loss 3.081, Loss_clf 0.354, Loss_fe 0.197, Loss_kd 2.450, Train_accy 81.56, Test_accy 73.53
2024-08-02 14:50:30,515 [foster.py] => Task 7, Epoch 69/170 => Loss 3.032, Loss_clf 0.353, Loss_fe 0.193, Loss_kd 2.407, Train_accy 83.48, Test_accy 73.20
2024-08-02 14:50:34,394 [foster.py] => Task 7, Epoch 70/170 => Loss 3.032, Loss_clf 0.336, Loss_fe 0.181, Loss_kd 2.434, Train_accy 83.48, Test_accy 73.30
2024-08-02 14:50:36,768 [foster.py] => Task 7, Epoch 71/170 => Loss 3.078, Loss_clf 0.351, Loss_fe 0.214, Loss_kd 2.433, Train_accy 82.95
2024-08-02 14:50:40,634 [foster.py] => Task 7, Epoch 72/170 => Loss 3.023, Loss_clf 0.332, Loss_fe 0.187, Loss_kd 2.424, Train_accy 84.42, Test_accy 73.47
2024-08-02 14:50:44,518 [foster.py] => Task 7, Epoch 73/170 => Loss 2.990, Loss_clf 0.318, Loss_fe 0.187, Loss_kd 2.406, Train_accy 83.79, Test_accy 73.41
2024-08-02 14:50:48,379 [foster.py] => Task 7, Epoch 74/170 => Loss 3.016, Loss_clf 0.326, Loss_fe 0.175, Loss_kd 2.435, Train_accy 83.62, Test_accy 72.91
2024-08-02 14:50:52,277 [foster.py] => Task 7, Epoch 75/170 => Loss 3.028, Loss_clf 0.337, Loss_fe 0.183, Loss_kd 2.429, Train_accy 84.64, Test_accy 73.38
2024-08-02 14:50:54,631 [foster.py] => Task 7, Epoch 76/170 => Loss 3.045, Loss_clf 0.342, Loss_fe 0.184, Loss_kd 2.438, Train_accy 84.51
2024-08-02 14:50:58,512 [foster.py] => Task 7, Epoch 77/170 => Loss 3.028, Loss_clf 0.335, Loss_fe 0.176, Loss_kd 2.438, Train_accy 84.38, Test_accy 73.47
2024-08-02 14:51:02,383 [foster.py] => Task 7, Epoch 78/170 => Loss 3.041, Loss_clf 0.340, Loss_fe 0.195, Loss_kd 2.426, Train_accy 83.17, Test_accy 73.73
2024-08-02 14:51:06,252 [foster.py] => Task 7, Epoch 79/170 => Loss 2.997, Loss_clf 0.328, Loss_fe 0.173, Loss_kd 2.417, Train_accy 82.46, Test_accy 73.64
2024-08-02 14:51:10,120 [foster.py] => Task 7, Epoch 80/170 => Loss 3.009, Loss_clf 0.329, Loss_fe 0.161, Loss_kd 2.438, Train_accy 84.64, Test_accy 73.09
2024-08-02 14:51:12,483 [foster.py] => Task 7, Epoch 81/170 => Loss 3.031, Loss_clf 0.347, Loss_fe 0.193, Loss_kd 2.411, Train_accy 83.48
2024-08-02 14:51:16,366 [foster.py] => Task 7, Epoch 82/170 => Loss 3.040, Loss_clf 0.335, Loss_fe 0.169, Loss_kd 2.455, Train_accy 84.51, Test_accy 73.31
2024-08-02 14:51:20,283 [foster.py] => Task 7, Epoch 83/170 => Loss 2.993, Loss_clf 0.320, Loss_fe 0.150, Loss_kd 2.443, Train_accy 85.89, Test_accy 73.23
2024-08-02 14:51:24,136 [foster.py] => Task 7, Epoch 84/170 => Loss 3.000, Loss_clf 0.323, Loss_fe 0.170, Loss_kd 2.427, Train_accy 84.33, Test_accy 73.30
2024-08-02 14:51:28,023 [foster.py] => Task 7, Epoch 85/170 => Loss 2.972, Loss_clf 0.312, Loss_fe 0.163, Loss_kd 2.418, Train_accy 83.79, Test_accy 73.70
2024-08-02 14:51:30,376 [foster.py] => Task 7, Epoch 86/170 => Loss 2.977, Loss_clf 0.322, Loss_fe 0.160, Loss_kd 2.416, Train_accy 85.13
2024-08-02 14:51:34,315 [foster.py] => Task 7, Epoch 87/170 => Loss 3.034, Loss_clf 0.326, Loss_fe 0.171, Loss_kd 2.456, Train_accy 84.29, Test_accy 73.73
2024-08-02 14:51:38,217 [foster.py] => Task 7, Epoch 88/170 => Loss 3.045, Loss_clf 0.347, Loss_fe 0.164, Loss_kd 2.453, Train_accy 84.20, Test_accy 73.61
2024-08-02 14:51:42,125 [foster.py] => Task 7, Epoch 89/170 => Loss 3.022, Loss_clf 0.329, Loss_fe 0.177, Loss_kd 2.435, Train_accy 86.12, Test_accy 73.78
2024-08-02 14:51:46,124 [foster.py] => Task 7, Epoch 90/170 => Loss 2.971, Loss_clf 0.305, Loss_fe 0.167, Loss_kd 2.419, Train_accy 85.62, Test_accy 73.80
2024-08-02 14:51:48,466 [foster.py] => Task 7, Epoch 91/170 => Loss 2.954, Loss_clf 0.320, Loss_fe 0.142, Loss_kd 2.413, Train_accy 86.25
2024-08-02 14:51:52,333 [foster.py] => Task 7, Epoch 92/170 => Loss 2.917, Loss_clf 0.280, Loss_fe 0.150, Loss_kd 2.408, Train_accy 85.40, Test_accy 73.80
2024-08-02 14:51:56,212 [foster.py] => Task 7, Epoch 93/170 => Loss 3.001, Loss_clf 0.346, Loss_fe 0.158, Loss_kd 2.418, Train_accy 85.45, Test_accy 73.70
2024-08-02 14:52:00,063 [foster.py] => Task 7, Epoch 94/170 => Loss 3.027, Loss_clf 0.335, Loss_fe 0.166, Loss_kd 2.447, Train_accy 85.89, Test_accy 73.61
2024-08-02 14:52:03,950 [foster.py] => Task 7, Epoch 95/170 => Loss 3.009, Loss_clf 0.325, Loss_fe 0.158, Loss_kd 2.446, Train_accy 84.02, Test_accy 73.88
2024-08-02 14:52:06,286 [foster.py] => Task 7, Epoch 96/170 => Loss 2.993, Loss_clf 0.331, Loss_fe 0.134, Loss_kd 2.447, Train_accy 85.71
2024-08-02 14:52:10,187 [foster.py] => Task 7, Epoch 97/170 => Loss 2.979, Loss_clf 0.309, Loss_fe 0.155, Loss_kd 2.434, Train_accy 86.38, Test_accy 73.45
2024-08-02 14:52:14,079 [foster.py] => Task 7, Epoch 98/170 => Loss 3.010, Loss_clf 0.343, Loss_fe 0.148, Loss_kd 2.439, Train_accy 84.87, Test_accy 73.39
2024-08-02 14:52:18,004 [foster.py] => Task 7, Epoch 99/170 => Loss 2.904, Loss_clf 0.274, Loss_fe 0.137, Loss_kd 2.414, Train_accy 87.81, Test_accy 73.73
2024-08-02 14:52:21,872 [foster.py] => Task 7, Epoch 100/170 => Loss 2.956, Loss_clf 0.296, Loss_fe 0.131, Loss_kd 2.449, Train_accy 88.39, Test_accy 73.56
2024-08-02 14:52:24,215 [foster.py] => Task 7, Epoch 101/170 => Loss 3.000, Loss_clf 0.319, Loss_fe 0.137, Loss_kd 2.463, Train_accy 87.19
2024-08-02 14:52:28,080 [foster.py] => Task 7, Epoch 102/170 => Loss 2.993, Loss_clf 0.325, Loss_fe 0.146, Loss_kd 2.441, Train_accy 85.62, Test_accy 73.62
2024-08-02 14:52:31,947 [foster.py] => Task 7, Epoch 103/170 => Loss 2.943, Loss_clf 0.304, Loss_fe 0.130, Loss_kd 2.429, Train_accy 87.14, Test_accy 73.56
2024-08-02 14:52:35,821 [foster.py] => Task 7, Epoch 104/170 => Loss 2.911, Loss_clf 0.289, Loss_fe 0.134, Loss_kd 2.408, Train_accy 88.04, Test_accy 73.53
2024-08-02 14:52:39,735 [foster.py] => Task 7, Epoch 105/170 => Loss 2.981, Loss_clf 0.322, Loss_fe 0.145, Loss_kd 2.434, Train_accy 86.12, Test_accy 73.50
2024-08-02 14:52:42,151 [foster.py] => Task 7, Epoch 106/170 => Loss 2.987, Loss_clf 0.318, Loss_fe 0.133, Loss_kd 2.455, Train_accy 87.01
2024-08-02 14:52:46,047 [foster.py] => Task 7, Epoch 107/170 => Loss 2.905, Loss_clf 0.280, Loss_fe 0.109, Loss_kd 2.436, Train_accy 87.01, Test_accy 73.50
2024-08-02 14:52:49,920 [foster.py] => Task 7, Epoch 108/170 => Loss 2.960, Loss_clf 0.312, Loss_fe 0.121, Loss_kd 2.446, Train_accy 87.10, Test_accy 73.70
2024-08-02 14:52:53,814 [foster.py] => Task 7, Epoch 109/170 => Loss 2.942, Loss_clf 0.298, Loss_fe 0.133, Loss_kd 2.431, Train_accy 88.39, Test_accy 73.53
2024-08-02 14:52:57,693 [foster.py] => Task 7, Epoch 110/170 => Loss 2.936, Loss_clf 0.291, Loss_fe 0.131, Loss_kd 2.434, Train_accy 86.43, Test_accy 73.78
2024-08-02 14:53:00,055 [foster.py] => Task 7, Epoch 111/170 => Loss 3.001, Loss_clf 0.344, Loss_fe 0.142, Loss_kd 2.435, Train_accy 84.06
2024-08-02 14:53:04,000 [foster.py] => Task 7, Epoch 112/170 => Loss 2.961, Loss_clf 0.314, Loss_fe 0.134, Loss_kd 2.433, Train_accy 87.68, Test_accy 73.78
2024-08-02 14:53:07,876 [foster.py] => Task 7, Epoch 113/170 => Loss 2.905, Loss_clf 0.282, Loss_fe 0.119, Loss_kd 2.425, Train_accy 87.54, Test_accy 73.61
2024-08-02 14:53:11,766 [foster.py] => Task 7, Epoch 114/170 => Loss 2.940, Loss_clf 0.295, Loss_fe 0.135, Loss_kd 2.431, Train_accy 87.63, Test_accy 73.45
2024-08-02 14:53:15,693 [foster.py] => Task 7, Epoch 115/170 => Loss 2.937, Loss_clf 0.297, Loss_fe 0.122, Loss_kd 2.438, Train_accy 87.28, Test_accy 73.62
2024-08-02 14:53:18,057 [foster.py] => Task 7, Epoch 116/170 => Loss 2.827, Loss_clf 0.246, Loss_fe 0.105, Loss_kd 2.398, Train_accy 88.48
2024-08-02 14:53:21,944 [foster.py] => Task 7, Epoch 117/170 => Loss 2.923, Loss_clf 0.284, Loss_fe 0.115, Loss_kd 2.444, Train_accy 87.19, Test_accy 73.64
2024-08-02 14:53:25,798 [foster.py] => Task 7, Epoch 118/170 => Loss 2.919, Loss_clf 0.291, Loss_fe 0.118, Loss_kd 2.430, Train_accy 86.88, Test_accy 73.70
2024-08-02 14:53:29,660 [foster.py] => Task 7, Epoch 119/170 => Loss 2.952, Loss_clf 0.307, Loss_fe 0.127, Loss_kd 2.437, Train_accy 87.54, Test_accy 73.55
2024-08-02 14:53:33,626 [foster.py] => Task 7, Epoch 120/170 => Loss 2.919, Loss_clf 0.290, Loss_fe 0.108, Loss_kd 2.442, Train_accy 87.37, Test_accy 73.58
2024-08-02 14:53:36,006 [foster.py] => Task 7, Epoch 121/170 => Loss 2.914, Loss_clf 0.296, Loss_fe 0.114, Loss_kd 2.424, Train_accy 87.05
2024-08-02 14:53:39,900 [foster.py] => Task 7, Epoch 122/170 => Loss 2.956, Loss_clf 0.317, Loss_fe 0.119, Loss_kd 2.440, Train_accy 86.65, Test_accy 73.45
2024-08-02 14:53:43,758 [foster.py] => Task 7, Epoch 123/170 => Loss 2.892, Loss_clf 0.289, Loss_fe 0.113, Loss_kd 2.411, Train_accy 88.57, Test_accy 73.56
2024-08-02 14:53:47,627 [foster.py] => Task 7, Epoch 124/170 => Loss 2.897, Loss_clf 0.288, Loss_fe 0.103, Loss_kd 2.426, Train_accy 88.62, Test_accy 73.50
2024-08-02 14:53:51,504 [foster.py] => Task 7, Epoch 125/170 => Loss 2.906, Loss_clf 0.285, Loss_fe 0.116, Loss_kd 2.425, Train_accy 88.12, Test_accy 73.62
2024-08-02 14:53:53,848 [foster.py] => Task 7, Epoch 126/170 => Loss 2.892, Loss_clf 0.289, Loss_fe 0.108, Loss_kd 2.415, Train_accy 87.86
2024-08-02 14:53:57,718 [foster.py] => Task 7, Epoch 127/170 => Loss 2.878, Loss_clf 0.269, Loss_fe 0.104, Loss_kd 2.426, Train_accy 88.75, Test_accy 73.58
2024-08-02 14:54:01,562 [foster.py] => Task 7, Epoch 128/170 => Loss 2.886, Loss_clf 0.277, Loss_fe 0.123, Loss_kd 2.408, Train_accy 88.75, Test_accy 73.61
2024-08-02 14:54:05,446 [foster.py] => Task 7, Epoch 129/170 => Loss 2.922, Loss_clf 0.294, Loss_fe 0.117, Loss_kd 2.430, Train_accy 88.12, Test_accy 73.72
2024-08-02 14:54:09,347 [foster.py] => Task 7, Epoch 130/170 => Loss 2.893, Loss_clf 0.280, Loss_fe 0.102, Loss_kd 2.432, Train_accy 89.02, Test_accy 73.72
2024-08-02 14:54:11,716 [foster.py] => Task 7, Epoch 131/170 => Loss 2.876, Loss_clf 0.272, Loss_fe 0.101, Loss_kd 2.423, Train_accy 87.68
2024-08-02 14:54:15,624 [foster.py] => Task 7, Epoch 132/170 => Loss 2.948, Loss_clf 0.308, Loss_fe 0.105, Loss_kd 2.455, Train_accy 86.56, Test_accy 73.70
2024-08-02 14:54:19,507 [foster.py] => Task 7, Epoch 133/170 => Loss 2.912, Loss_clf 0.285, Loss_fe 0.118, Loss_kd 2.429, Train_accy 88.35, Test_accy 73.75
2024-08-02 14:54:23,461 [foster.py] => Task 7, Epoch 134/170 => Loss 2.956, Loss_clf 0.299, Loss_fe 0.118, Loss_kd 2.458, Train_accy 87.05, Test_accy 73.88
2024-08-02 14:54:27,342 [foster.py] => Task 7, Epoch 135/170 => Loss 2.916, Loss_clf 0.293, Loss_fe 0.102, Loss_kd 2.440, Train_accy 87.37, Test_accy 73.70
2024-08-02 14:54:29,689 [foster.py] => Task 7, Epoch 136/170 => Loss 2.922, Loss_clf 0.294, Loss_fe 0.109, Loss_kd 2.440, Train_accy 87.81
2024-08-02 14:54:33,578 [foster.py] => Task 7, Epoch 137/170 => Loss 2.943, Loss_clf 0.300, Loss_fe 0.124, Loss_kd 2.438, Train_accy 87.10, Test_accy 73.83
2024-08-02 14:54:37,475 [foster.py] => Task 7, Epoch 138/170 => Loss 2.928, Loss_clf 0.309, Loss_fe 0.096, Loss_kd 2.443, Train_accy 87.14, Test_accy 73.64
2024-08-02 14:54:41,355 [foster.py] => Task 7, Epoch 139/170 => Loss 2.876, Loss_clf 0.271, Loss_fe 0.109, Loss_kd 2.416, Train_accy 88.93, Test_accy 73.59
2024-08-02 14:54:45,227 [foster.py] => Task 7, Epoch 140/170 => Loss 2.883, Loss_clf 0.284, Loss_fe 0.094, Loss_kd 2.426, Train_accy 88.35, Test_accy 73.62
2024-08-02 14:54:47,584 [foster.py] => Task 7, Epoch 141/170 => Loss 2.884, Loss_clf 0.270, Loss_fe 0.100, Loss_kd 2.434, Train_accy 88.53
2024-08-02 14:54:51,442 [foster.py] => Task 7, Epoch 142/170 => Loss 2.859, Loss_clf 0.262, Loss_fe 0.082, Loss_kd 2.435, Train_accy 89.15, Test_accy 73.56
2024-08-02 14:54:55,346 [foster.py] => Task 7, Epoch 143/170 => Loss 2.909, Loss_clf 0.296, Loss_fe 0.105, Loss_kd 2.429, Train_accy 88.35, Test_accy 73.62
2024-08-02 14:54:59,222 [foster.py] => Task 7, Epoch 144/170 => Loss 2.891, Loss_clf 0.284, Loss_fe 0.101, Loss_kd 2.427, Train_accy 88.39, Test_accy 73.70
2024-08-02 14:55:03,143 [foster.py] => Task 7, Epoch 145/170 => Loss 2.912, Loss_clf 0.289, Loss_fe 0.097, Loss_kd 2.446, Train_accy 88.21, Test_accy 73.73
2024-08-02 14:55:05,524 [foster.py] => Task 7, Epoch 146/170 => Loss 2.937, Loss_clf 0.307, Loss_fe 0.101, Loss_kd 2.448, Train_accy 87.50
2024-08-02 14:55:09,422 [foster.py] => Task 7, Epoch 147/170 => Loss 2.919, Loss_clf 0.287, Loss_fe 0.106, Loss_kd 2.446, Train_accy 87.86, Test_accy 73.69
2024-08-02 14:55:13,323 [foster.py] => Task 7, Epoch 148/170 => Loss 2.930, Loss_clf 0.306, Loss_fe 0.114, Loss_kd 2.430, Train_accy 87.72, Test_accy 73.69
2024-08-02 14:55:17,193 [foster.py] => Task 7, Epoch 149/170 => Loss 2.899, Loss_clf 0.283, Loss_fe 0.100, Loss_kd 2.437, Train_accy 88.57, Test_accy 73.69
2024-08-02 14:55:21,082 [foster.py] => Task 7, Epoch 150/170 => Loss 2.973, Loss_clf 0.322, Loss_fe 0.112, Loss_kd 2.458, Train_accy 87.77, Test_accy 73.72
2024-08-02 14:55:23,434 [foster.py] => Task 7, Epoch 151/170 => Loss 2.853, Loss_clf 0.277, Loss_fe 0.098, Loss_kd 2.400, Train_accy 87.37
2024-08-02 14:55:27,315 [foster.py] => Task 7, Epoch 152/170 => Loss 2.903, Loss_clf 0.301, Loss_fe 0.098, Loss_kd 2.424, Train_accy 88.04, Test_accy 73.77
2024-08-02 14:55:31,190 [foster.py] => Task 7, Epoch 153/170 => Loss 2.899, Loss_clf 0.292, Loss_fe 0.089, Loss_kd 2.438, Train_accy 87.46, Test_accy 73.73
2024-08-02 14:55:35,076 [foster.py] => Task 7, Epoch 154/170 => Loss 2.871, Loss_clf 0.266, Loss_fe 0.106, Loss_kd 2.420, Train_accy 88.79, Test_accy 73.77
2024-08-02 14:55:38,969 [foster.py] => Task 7, Epoch 155/170 => Loss 2.880, Loss_clf 0.292, Loss_fe 0.089, Loss_kd 2.420, Train_accy 87.63, Test_accy 73.75
2024-08-02 14:55:41,379 [foster.py] => Task 7, Epoch 156/170 => Loss 2.929, Loss_clf 0.293, Loss_fe 0.097, Loss_kd 2.459, Train_accy 88.62
2024-08-02 14:55:45,273 [foster.py] => Task 7, Epoch 157/170 => Loss 2.890, Loss_clf 0.291, Loss_fe 0.092, Loss_kd 2.428, Train_accy 87.37, Test_accy 73.70
2024-08-02 14:55:49,153 [foster.py] => Task 7, Epoch 158/170 => Loss 2.886, Loss_clf 0.282, Loss_fe 0.114, Loss_kd 2.412, Train_accy 88.88, Test_accy 73.81
2024-08-02 14:55:53,010 [foster.py] => Task 7, Epoch 159/170 => Loss 2.887, Loss_clf 0.276, Loss_fe 0.107, Loss_kd 2.424, Train_accy 88.21, Test_accy 73.69
2024-08-02 14:55:56,898 [foster.py] => Task 7, Epoch 160/170 => Loss 2.936, Loss_clf 0.305, Loss_fe 0.111, Loss_kd 2.439, Train_accy 88.48, Test_accy 73.72
2024-08-02 14:55:59,268 [foster.py] => Task 7, Epoch 161/170 => Loss 2.924, Loss_clf 0.290, Loss_fe 0.106, Loss_kd 2.448, Train_accy 88.53
2024-08-02 14:56:03,148 [foster.py] => Task 7, Epoch 162/170 => Loss 2.876, Loss_clf 0.265, Loss_fe 0.094, Loss_kd 2.437, Train_accy 88.79, Test_accy 73.69
2024-08-02 14:56:07,036 [foster.py] => Task 7, Epoch 163/170 => Loss 2.931, Loss_clf 0.296, Loss_fe 0.109, Loss_kd 2.447, Train_accy 88.04, Test_accy 73.75
2024-08-02 14:56:11,014 [foster.py] => Task 7, Epoch 164/170 => Loss 2.882, Loss_clf 0.274, Loss_fe 0.093, Loss_kd 2.435, Train_accy 88.88, Test_accy 73.64
2024-08-02 14:56:14,869 [foster.py] => Task 7, Epoch 165/170 => Loss 2.956, Loss_clf 0.317, Loss_fe 0.109, Loss_kd 2.449, Train_accy 87.14, Test_accy 73.70
2024-08-02 14:56:17,285 [foster.py] => Task 7, Epoch 166/170 => Loss 2.886, Loss_clf 0.272, Loss_fe 0.105, Loss_kd 2.429, Train_accy 89.38
2024-08-02 14:56:21,178 [foster.py] => Task 7, Epoch 167/170 => Loss 2.889, Loss_clf 0.278, Loss_fe 0.100, Loss_kd 2.431, Train_accy 87.72, Test_accy 73.55
2024-08-02 14:56:25,052 [foster.py] => Task 7, Epoch 168/170 => Loss 2.859, Loss_clf 0.262, Loss_fe 0.098, Loss_kd 2.419, Train_accy 89.46, Test_accy 73.69
2024-08-02 14:56:28,957 [foster.py] => Task 7, Epoch 169/170 => Loss 2.869, Loss_clf 0.269, Loss_fe 0.084, Loss_kd 2.436, Train_accy 88.04, Test_accy 73.64
2024-08-02 14:56:32,820 [foster.py] => Task 7, Epoch 170/170 => Loss 2.926, Loss_clf 0.299, Loss_fe 0.108, Loss_kd 2.439, Train_accy 88.35, Test_accy 73.67
2024-08-02 14:56:32,824 [foster.py] => do not weight align teacher!
2024-08-02 14:56:32,827 [foster.py] => per cls weights : [1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871 1.01705871
 1.01705871 1.01705871 0.47117995 0.47117995]
2024-08-02 14:56:37,238 [foster.py] => SNet: Task 7, Epoch 1/130 => Loss 28.464,  Loss1 0.716, Train_accy 47.68, Test_accy 70.69
2024-08-02 14:56:40,460 [foster.py] => SNet: Task 7, Epoch 2/130 => Loss 28.351,  Loss1 0.716, Train_accy 56.65
2024-08-02 14:56:43,740 [foster.py] => SNet: Task 7, Epoch 3/130 => Loss 28.396,  Loss1 0.716, Train_accy 57.81
2024-08-02 14:56:46,974 [foster.py] => SNet: Task 7, Epoch 4/130 => Loss 28.373,  Loss1 0.715, Train_accy 58.57
2024-08-02 14:56:50,214 [foster.py] => SNet: Task 7, Epoch 5/130 => Loss 28.335,  Loss1 0.715, Train_accy 60.62
2024-08-02 14:56:54,486 [foster.py] => SNet: Task 7, Epoch 6/130 => Loss 28.358,  Loss1 0.714, Train_accy 60.98, Test_accy 72.23
2024-08-02 14:56:57,703 [foster.py] => SNet: Task 7, Epoch 7/130 => Loss 28.387,  Loss1 0.715, Train_accy 61.92
2024-08-02 14:57:00,917 [foster.py] => SNet: Task 7, Epoch 8/130 => Loss 28.382,  Loss1 0.714, Train_accy 62.05
2024-08-02 14:57:04,164 [foster.py] => SNet: Task 7, Epoch 9/130 => Loss 28.344,  Loss1 0.715, Train_accy 62.77
2024-08-02 14:57:07,405 [foster.py] => SNet: Task 7, Epoch 10/130 => Loss 28.310,  Loss1 0.714, Train_accy 64.06
2024-08-02 14:57:11,634 [foster.py] => SNet: Task 7, Epoch 11/130 => Loss 28.310,  Loss1 0.715, Train_accy 64.51, Test_accy 72.45
2024-08-02 14:57:14,867 [foster.py] => SNet: Task 7, Epoch 12/130 => Loss 28.339,  Loss1 0.715, Train_accy 65.98
2024-08-02 14:57:18,119 [foster.py] => SNet: Task 7, Epoch 13/130 => Loss 28.289,  Loss1 0.714, Train_accy 65.58
2024-08-02 14:57:21,359 [foster.py] => SNet: Task 7, Epoch 14/130 => Loss 28.364,  Loss1 0.714, Train_accy 64.60
2024-08-02 14:57:24,618 [foster.py] => SNet: Task 7, Epoch 15/130 => Loss 28.330,  Loss1 0.714, Train_accy 65.27
2024-08-02 14:57:28,846 [foster.py] => SNet: Task 7, Epoch 16/130 => Loss 28.340,  Loss1 0.714, Train_accy 64.24, Test_accy 72.89
2024-08-02 14:57:32,057 [foster.py] => SNet: Task 7, Epoch 17/130 => Loss 28.333,  Loss1 0.713, Train_accy 66.83
2024-08-02 14:57:35,289 [foster.py] => SNet: Task 7, Epoch 18/130 => Loss 28.323,  Loss1 0.714, Train_accy 65.67
2024-08-02 14:57:38,514 [foster.py] => SNet: Task 7, Epoch 19/130 => Loss 28.317,  Loss1 0.715, Train_accy 64.82
2024-08-02 14:57:41,752 [foster.py] => SNet: Task 7, Epoch 20/130 => Loss 28.307,  Loss1 0.714, Train_accy 66.25
2024-08-02 14:57:45,972 [foster.py] => SNet: Task 7, Epoch 21/130 => Loss 28.329,  Loss1 0.713, Train_accy 65.94, Test_accy 72.69
2024-08-02 14:57:49,185 [foster.py] => SNet: Task 7, Epoch 22/130 => Loss 28.284,  Loss1 0.714, Train_accy 67.72
2024-08-02 14:57:52,479 [foster.py] => SNet: Task 7, Epoch 23/130 => Loss 28.350,  Loss1 0.714, Train_accy 67.32
2024-08-02 14:57:55,710 [foster.py] => SNet: Task 7, Epoch 24/130 => Loss 28.332,  Loss1 0.713, Train_accy 67.54
2024-08-02 14:57:58,955 [foster.py] => SNet: Task 7, Epoch 25/130 => Loss 28.270,  Loss1 0.714, Train_accy 68.12
2024-08-02 14:58:03,173 [foster.py] => SNet: Task 7, Epoch 26/130 => Loss 28.386,  Loss1 0.714, Train_accy 69.15, Test_accy 72.98
2024-08-02 14:58:06,410 [foster.py] => SNet: Task 7, Epoch 27/130 => Loss 28.383,  Loss1 0.713, Train_accy 68.35
2024-08-02 14:58:09,682 [foster.py] => SNet: Task 7, Epoch 28/130 => Loss 28.335,  Loss1 0.714, Train_accy 66.79
2024-08-02 14:58:12,919 [foster.py] => SNet: Task 7, Epoch 29/130 => Loss 28.363,  Loss1 0.713, Train_accy 69.42
2024-08-02 14:58:16,160 [foster.py] => SNet: Task 7, Epoch 30/130 => Loss 28.356,  Loss1 0.714, Train_accy 68.04
2024-08-02 14:58:20,398 [foster.py] => SNet: Task 7, Epoch 31/130 => Loss 28.333,  Loss1 0.714, Train_accy 69.60, Test_accy 72.88
2024-08-02 14:58:23,691 [foster.py] => SNet: Task 7, Epoch 32/130 => Loss 28.315,  Loss1 0.713, Train_accy 69.15
2024-08-02 14:58:26,913 [foster.py] => SNet: Task 7, Epoch 33/130 => Loss 28.304,  Loss1 0.714, Train_accy 71.34
2024-08-02 14:58:30,156 [foster.py] => SNet: Task 7, Epoch 34/130 => Loss 28.270,  Loss1 0.714, Train_accy 69.91
2024-08-02 14:58:33,383 [foster.py] => SNet: Task 7, Epoch 35/130 => Loss 28.348,  Loss1 0.714, Train_accy 69.91
2024-08-02 14:58:37,591 [foster.py] => SNet: Task 7, Epoch 36/130 => Loss 28.282,  Loss1 0.714, Train_accy 69.42, Test_accy 73.03
2024-08-02 14:58:40,834 [foster.py] => SNet: Task 7, Epoch 37/130 => Loss 28.314,  Loss1 0.714, Train_accy 70.09
2024-08-02 14:58:44,058 [foster.py] => SNet: Task 7, Epoch 38/130 => Loss 28.277,  Loss1 0.714, Train_accy 70.22
2024-08-02 14:58:47,275 [foster.py] => SNet: Task 7, Epoch 39/130 => Loss 28.309,  Loss1 0.714, Train_accy 70.31
2024-08-02 14:58:50,538 [foster.py] => SNet: Task 7, Epoch 40/130 => Loss 28.354,  Loss1 0.714, Train_accy 70.36
2024-08-02 14:58:54,783 [foster.py] => SNet: Task 7, Epoch 41/130 => Loss 28.316,  Loss1 0.714, Train_accy 69.06, Test_accy 72.89
2024-08-02 14:58:57,995 [foster.py] => SNet: Task 7, Epoch 42/130 => Loss 28.290,  Loss1 0.713, Train_accy 70.18
2024-08-02 14:59:01,303 [foster.py] => SNet: Task 7, Epoch 43/130 => Loss 28.333,  Loss1 0.713, Train_accy 68.71
2024-08-02 14:59:04,551 [foster.py] => SNet: Task 7, Epoch 44/130 => Loss 28.330,  Loss1 0.714, Train_accy 70.45
2024-08-02 14:59:07,777 [foster.py] => SNet: Task 7, Epoch 45/130 => Loss 28.340,  Loss1 0.713, Train_accy 69.91
2024-08-02 14:59:12,006 [foster.py] => SNet: Task 7, Epoch 46/130 => Loss 28.324,  Loss1 0.713, Train_accy 70.58, Test_accy 73.09
2024-08-02 14:59:15,229 [foster.py] => SNet: Task 7, Epoch 47/130 => Loss 28.312,  Loss1 0.714, Train_accy 70.40
2024-08-02 14:59:18,459 [foster.py] => SNet: Task 7, Epoch 48/130 => Loss 28.328,  Loss1 0.714, Train_accy 70.71
2024-08-02 14:59:21,692 [foster.py] => SNet: Task 7, Epoch 49/130 => Loss 28.317,  Loss1 0.713, Train_accy 68.93
2024-08-02 14:59:24,970 [foster.py] => SNet: Task 7, Epoch 50/130 => Loss 28.287,  Loss1 0.714, Train_accy 70.62
2024-08-02 14:59:29,201 [foster.py] => SNet: Task 7, Epoch 51/130 => Loss 28.323,  Loss1 0.714, Train_accy 71.43, Test_accy 72.84
2024-08-02 14:59:32,443 [foster.py] => SNet: Task 7, Epoch 52/130 => Loss 28.313,  Loss1 0.714, Train_accy 71.43
2024-08-02 14:59:35,682 [foster.py] => SNet: Task 7, Epoch 53/130 => Loss 28.277,  Loss1 0.713, Train_accy 69.91
2024-08-02 14:59:38,896 [foster.py] => SNet: Task 7, Epoch 54/130 => Loss 28.293,  Loss1 0.713, Train_accy 72.63
2024-08-02 14:59:42,123 [foster.py] => SNet: Task 7, Epoch 55/130 => Loss 28.306,  Loss1 0.714, Train_accy 71.29
2024-08-02 14:59:46,356 [foster.py] => SNet: Task 7, Epoch 56/130 => Loss 28.278,  Loss1 0.714, Train_accy 71.21, Test_accy 72.98
2024-08-02 14:59:49,593 [foster.py] => SNet: Task 7, Epoch 57/130 => Loss 28.308,  Loss1 0.713, Train_accy 71.12
2024-08-02 14:59:52,825 [foster.py] => SNet: Task 7, Epoch 58/130 => Loss 28.321,  Loss1 0.713, Train_accy 70.98
2024-08-02 14:59:56,061 [foster.py] => SNet: Task 7, Epoch 59/130 => Loss 28.323,  Loss1 0.714, Train_accy 70.31
2024-08-02 14:59:59,331 [foster.py] => SNet: Task 7, Epoch 60/130 => Loss 28.319,  Loss1 0.714, Train_accy 71.88
2024-08-02 15:00:03,562 [foster.py] => SNet: Task 7, Epoch 61/130 => Loss 28.316,  Loss1 0.714, Train_accy 72.95, Test_accy 73.02
2024-08-02 15:00:06,772 [foster.py] => SNet: Task 7, Epoch 62/130 => Loss 28.338,  Loss1 0.714, Train_accy 71.61
2024-08-02 15:00:10,079 [foster.py] => SNet: Task 7, Epoch 63/130 => Loss 28.346,  Loss1 0.714, Train_accy 71.83
2024-08-02 15:00:13,324 [foster.py] => SNet: Task 7, Epoch 64/130 => Loss 28.268,  Loss1 0.714, Train_accy 70.45
2024-08-02 15:00:16,557 [foster.py] => SNet: Task 7, Epoch 65/130 => Loss 28.340,  Loss1 0.714, Train_accy 71.34
2024-08-02 15:00:20,797 [foster.py] => SNet: Task 7, Epoch 66/130 => Loss 28.349,  Loss1 0.714, Train_accy 71.52, Test_accy 73.08
2024-08-02 15:00:24,039 [foster.py] => SNet: Task 7, Epoch 67/130 => Loss 28.311,  Loss1 0.713, Train_accy 72.95
2024-08-02 15:00:27,270 [foster.py] => SNet: Task 7, Epoch 68/130 => Loss 28.282,  Loss1 0.714, Train_accy 72.81
2024-08-02 15:00:30,502 [foster.py] => SNet: Task 7, Epoch 69/130 => Loss 28.260,  Loss1 0.714, Train_accy 70.31
2024-08-02 15:00:33,720 [foster.py] => SNet: Task 7, Epoch 70/130 => Loss 28.340,  Loss1 0.714, Train_accy 71.07
2024-08-02 15:00:37,942 [foster.py] => SNet: Task 7, Epoch 71/130 => Loss 28.285,  Loss1 0.714, Train_accy 71.96, Test_accy 73.20
2024-08-02 15:00:41,165 [foster.py] => SNet: Task 7, Epoch 72/130 => Loss 28.358,  Loss1 0.713, Train_accy 72.10
2024-08-02 15:00:44,393 [foster.py] => SNet: Task 7, Epoch 73/130 => Loss 28.283,  Loss1 0.713, Train_accy 72.59
2024-08-02 15:00:47,630 [foster.py] => SNet: Task 7, Epoch 74/130 => Loss 28.369,  Loss1 0.714, Train_accy 71.56
2024-08-02 15:00:50,856 [foster.py] => SNet: Task 7, Epoch 75/130 => Loss 28.305,  Loss1 0.713, Train_accy 70.40
2024-08-02 15:00:55,071 [foster.py] => SNet: Task 7, Epoch 76/130 => Loss 28.295,  Loss1 0.714, Train_accy 71.61, Test_accy 73.16
2024-08-02 15:00:58,338 [foster.py] => SNet: Task 7, Epoch 77/130 => Loss 28.338,  Loss1 0.714, Train_accy 71.03
2024-08-02 15:01:01,567 [foster.py] => SNet: Task 7, Epoch 78/130 => Loss 28.362,  Loss1 0.714, Train_accy 71.96
2024-08-02 15:01:04,806 [foster.py] => SNet: Task 7, Epoch 79/130 => Loss 28.299,  Loss1 0.713, Train_accy 72.99
2024-08-02 15:01:08,028 [foster.py] => SNet: Task 7, Epoch 80/130 => Loss 28.322,  Loss1 0.714, Train_accy 72.28
2024-08-02 15:01:12,285 [foster.py] => SNet: Task 7, Epoch 81/130 => Loss 28.286,  Loss1 0.714, Train_accy 72.14, Test_accy 73.22
2024-08-02 15:01:15,578 [foster.py] => SNet: Task 7, Epoch 82/130 => Loss 28.326,  Loss1 0.713, Train_accy 71.29
2024-08-02 15:01:18,806 [foster.py] => SNet: Task 7, Epoch 83/130 => Loss 28.353,  Loss1 0.713, Train_accy 71.38
2024-08-02 15:01:22,068 [foster.py] => SNet: Task 7, Epoch 84/130 => Loss 28.317,  Loss1 0.713, Train_accy 74.06
2024-08-02 15:01:25,338 [foster.py] => SNet: Task 7, Epoch 85/130 => Loss 28.235,  Loss1 0.713, Train_accy 73.66
2024-08-02 15:01:29,556 [foster.py] => SNet: Task 7, Epoch 86/130 => Loss 28.313,  Loss1 0.713, Train_accy 71.25, Test_accy 73.27
2024-08-02 15:01:32,776 [foster.py] => SNet: Task 7, Epoch 87/130 => Loss 28.332,  Loss1 0.714, Train_accy 71.88
2024-08-02 15:01:36,025 [foster.py] => SNet: Task 7, Epoch 88/130 => Loss 28.263,  Loss1 0.714, Train_accy 71.12
2024-08-02 15:01:39,271 [foster.py] => SNet: Task 7, Epoch 89/130 => Loss 28.283,  Loss1 0.714, Train_accy 72.90
2024-08-02 15:01:42,528 [foster.py] => SNet: Task 7, Epoch 90/130 => Loss 28.270,  Loss1 0.714, Train_accy 72.19
2024-08-02 15:01:46,730 [foster.py] => SNet: Task 7, Epoch 91/130 => Loss 28.321,  Loss1 0.713, Train_accy 72.59, Test_accy 73.08
2024-08-02 15:01:49,956 [foster.py] => SNet: Task 7, Epoch 92/130 => Loss 28.320,  Loss1 0.714, Train_accy 71.74
2024-08-02 15:01:53,149 [foster.py] => SNet: Task 7, Epoch 93/130 => Loss 28.351,  Loss1 0.713, Train_accy 71.07
2024-08-02 15:01:56,375 [foster.py] => SNet: Task 7, Epoch 94/130 => Loss 28.329,  Loss1 0.714, Train_accy 70.76
2024-08-02 15:01:59,611 [foster.py] => SNet: Task 7, Epoch 95/130 => Loss 28.254,  Loss1 0.714, Train_accy 73.48
2024-08-02 15:02:03,853 [foster.py] => SNet: Task 7, Epoch 96/130 => Loss 28.350,  Loss1 0.713, Train_accy 72.28, Test_accy 73.02
2024-08-02 15:02:07,091 [foster.py] => SNet: Task 7, Epoch 97/130 => Loss 28.305,  Loss1 0.714, Train_accy 72.50
2024-08-02 15:02:10,344 [foster.py] => SNet: Task 7, Epoch 98/130 => Loss 28.261,  Loss1 0.714, Train_accy 72.68
2024-08-02 15:02:13,593 [foster.py] => SNet: Task 7, Epoch 99/130 => Loss 28.312,  Loss1 0.713, Train_accy 73.62
2024-08-02 15:02:16,807 [foster.py] => SNet: Task 7, Epoch 100/130 => Loss 28.317,  Loss1 0.713, Train_accy 72.50
2024-08-02 15:02:21,041 [foster.py] => SNet: Task 7, Epoch 101/130 => Loss 28.340,  Loss1 0.713, Train_accy 71.07, Test_accy 72.97
2024-08-02 15:02:24,372 [foster.py] => SNet: Task 7, Epoch 102/130 => Loss 28.292,  Loss1 0.713, Train_accy 72.28
2024-08-02 15:02:27,605 [foster.py] => SNet: Task 7, Epoch 103/130 => Loss 28.295,  Loss1 0.713, Train_accy 73.44
2024-08-02 15:02:30,842 [foster.py] => SNet: Task 7, Epoch 104/130 => Loss 28.344,  Loss1 0.713, Train_accy 71.79
2024-08-02 15:02:34,065 [foster.py] => SNet: Task 7, Epoch 105/130 => Loss 28.276,  Loss1 0.714, Train_accy 73.57
2024-08-02 15:02:38,316 [foster.py] => SNet: Task 7, Epoch 106/130 => Loss 28.314,  Loss1 0.713, Train_accy 72.68, Test_accy 73.25
2024-08-02 15:02:41,522 [foster.py] => SNet: Task 7, Epoch 107/130 => Loss 28.282,  Loss1 0.713, Train_accy 72.19
2024-08-02 15:02:44,735 [foster.py] => SNet: Task 7, Epoch 108/130 => Loss 28.272,  Loss1 0.714, Train_accy 72.59
2024-08-02 15:02:47,995 [foster.py] => SNet: Task 7, Epoch 109/130 => Loss 28.286,  Loss1 0.714, Train_accy 72.37
2024-08-02 15:02:51,233 [foster.py] => SNet: Task 7, Epoch 110/130 => Loss 28.356,  Loss1 0.713, Train_accy 71.79
2024-08-02 15:02:55,459 [foster.py] => SNet: Task 7, Epoch 111/130 => Loss 28.320,  Loss1 0.714, Train_accy 72.23, Test_accy 73.48
2024-08-02 15:02:58,718 [foster.py] => SNet: Task 7, Epoch 112/130 => Loss 28.256,  Loss1 0.713, Train_accy 73.30
2024-08-02 15:03:01,971 [foster.py] => SNet: Task 7, Epoch 113/130 => Loss 28.303,  Loss1 0.714, Train_accy 71.92
2024-08-02 15:03:05,194 [foster.py] => SNet: Task 7, Epoch 114/130 => Loss 28.307,  Loss1 0.713, Train_accy 73.04
2024-08-02 15:03:08,403 [foster.py] => SNet: Task 7, Epoch 115/130 => Loss 28.329,  Loss1 0.713, Train_accy 72.72
2024-08-02 15:03:12,612 [foster.py] => SNet: Task 7, Epoch 116/130 => Loss 28.319,  Loss1 0.714, Train_accy 73.84, Test_accy 73.20
2024-08-02 15:03:15,853 [foster.py] => SNet: Task 7, Epoch 117/130 => Loss 28.314,  Loss1 0.714, Train_accy 72.32
2024-08-02 15:03:19,080 [foster.py] => SNet: Task 7, Epoch 118/130 => Loss 28.372,  Loss1 0.714, Train_accy 71.52
2024-08-02 15:03:22,294 [foster.py] => SNet: Task 7, Epoch 119/130 => Loss 28.314,  Loss1 0.714, Train_accy 73.66
2024-08-02 15:03:25,519 [foster.py] => SNet: Task 7, Epoch 120/130 => Loss 28.304,  Loss1 0.714, Train_accy 72.99
2024-08-02 15:03:29,762 [foster.py] => SNet: Task 7, Epoch 121/130 => Loss 28.308,  Loss1 0.714, Train_accy 71.43, Test_accy 73.14
2024-08-02 15:03:33,075 [foster.py] => SNet: Task 7, Epoch 122/130 => Loss 28.311,  Loss1 0.713, Train_accy 73.30
2024-08-02 15:03:36,291 [foster.py] => SNet: Task 7, Epoch 123/130 => Loss 28.318,  Loss1 0.713, Train_accy 73.39
2024-08-02 15:03:39,519 [foster.py] => SNet: Task 7, Epoch 124/130 => Loss 28.326,  Loss1 0.714, Train_accy 71.83
2024-08-02 15:03:42,767 [foster.py] => SNet: Task 7, Epoch 125/130 => Loss 28.254,  Loss1 0.714, Train_accy 71.21
2024-08-02 15:03:47,032 [foster.py] => SNet: Task 7, Epoch 126/130 => Loss 28.342,  Loss1 0.714, Train_accy 72.01, Test_accy 73.25
2024-08-02 15:03:50,256 [foster.py] => SNet: Task 7, Epoch 127/130 => Loss 28.289,  Loss1 0.713, Train_accy 73.08
2024-08-02 15:03:53,528 [foster.py] => SNet: Task 7, Epoch 128/130 => Loss 28.303,  Loss1 0.713, Train_accy 73.21
2024-08-02 15:03:56,743 [foster.py] => SNet: Task 7, Epoch 129/130 => Loss 28.319,  Loss1 0.713, Train_accy 72.81
2024-08-02 15:03:59,975 [foster.py] => SNet: Task 7, Epoch 130/130 => Loss 28.313,  Loss1 0.713, Train_accy 72.77
2024-08-02 15:03:59,976 [foster.py] => do not weight align student!
2024-08-02 15:04:00,963 [foster.py] => darknet eval: 
2024-08-02 15:04:00,963 [foster.py] => CNN top1 curve: 73.2
2024-08-02 15:04:00,964 [foster.py] => CNN top5 curve: 93.62
2024-08-02 15:04:00,964 [foster.py] => CNN top1 平均值: 73.20
2024-08-02 15:04:00,970 [foster.py] => timees : 1057.965898990631
2024-08-02 15:04:00,972 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 15:04:20,641 [foster.py] => Exemplar size: 1280
2024-08-02 15:04:20,641 [trainer.py] => CNN: {'total': 73.67, '00-09': 81.4, '10-19': 69.4, '20-29': 80.8, '30-39': 73.9, '40-49': 79.4, '50-59': 59.4, '60-69': 68.0, 'old': 73.71, 'new': 72.5}
2024-08-02 15:04:20,642 [trainer.py] => NME: {'total': 69.28, '00-09': 74.1, '10-19': 65.4, '20-29': 76.1, '30-39': 68.7, '40-49': 74.1, '50-59': 55.9, '60-69': 72.75, 'old': 68.58, 'new': 91.0}
2024-08-02 15:04:20,642 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67]
2024-08-02 15:04:20,642 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83]
2024-08-02 15:04:20,643 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28]
2024-08-02 15:04:20,643 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67]

2024-08-02 15:04:20,643 [trainer.py] => CNN top1 平均值: 77.86
2024-08-02 15:04:20,646 [trainer.py] => All params: 1170994
2024-08-02 15:04:20,649 [trainer.py] => Trainable params: 589690
2024-08-02 15:04:20,709 [foster.py] => Learning on 64-66
2024-08-02 15:04:20,713 [foster.py] => All params: 1171512
2024-08-02 15:04:20,716 [foster.py] => Trainable params: 590078
2024-08-02 15:04:20,754 [foster.py] => per cls weights : [1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462 1.01391462
 1.01391462 1.01391462 1.01391462 1.01391462 0.55473206 0.55473206]
2024-08-02 15:04:23,202 [foster.py] => Task 8, Epoch 1/170 => Loss 5.673, Loss_clf 1.164, Loss_fe 1.940, Loss_kd 2.490, Train_accy 63.29
2024-08-02 15:04:27,127 [foster.py] => Task 8, Epoch 2/170 => Loss 3.847, Loss_clf 0.563, Loss_fe 0.764, Loss_kd 2.442, Train_accy 75.61, Test_accy 71.92
2024-08-02 15:04:31,062 [foster.py] => Task 8, Epoch 3/170 => Loss 3.677, Loss_clf 0.492, Loss_fe 0.654, Loss_kd 2.453, Train_accy 75.88, Test_accy 72.38
2024-08-02 15:04:34,964 [foster.py] => Task 8, Epoch 4/170 => Loss 3.659, Loss_clf 0.496, Loss_fe 0.607, Loss_kd 2.477, Train_accy 72.59, Test_accy 72.24
2024-08-02 15:04:38,904 [foster.py] => Task 8, Epoch 5/170 => Loss 3.585, Loss_clf 0.480, Loss_fe 0.584, Loss_kd 2.443, Train_accy 74.96, Test_accy 72.21
2024-08-02 15:04:41,247 [foster.py] => Task 8, Epoch 6/170 => Loss 3.557, Loss_clf 0.482, Loss_fe 0.538, Loss_kd 2.458, Train_accy 74.12
2024-08-02 15:04:45,192 [foster.py] => Task 8, Epoch 7/170 => Loss 3.521, Loss_clf 0.479, Loss_fe 0.503, Loss_kd 2.461, Train_accy 74.25, Test_accy 72.47
2024-08-02 15:04:49,115 [foster.py] => Task 8, Epoch 8/170 => Loss 3.453, Loss_clf 0.461, Loss_fe 0.463, Loss_kd 2.450, Train_accy 75.79, Test_accy 72.58
2024-08-02 15:04:53,008 [foster.py] => Task 8, Epoch 9/170 => Loss 3.519, Loss_clf 0.481, Loss_fe 0.465, Loss_kd 2.494, Train_accy 76.45, Test_accy 72.35
2024-08-02 15:04:57,018 [foster.py] => Task 8, Epoch 10/170 => Loss 3.407, Loss_clf 0.434, Loss_fe 0.444, Loss_kd 2.451, Train_accy 76.75, Test_accy 72.41
2024-08-02 15:04:59,356 [foster.py] => Task 8, Epoch 11/170 => Loss 3.342, Loss_clf 0.412, Loss_fe 0.415, Loss_kd 2.437, Train_accy 78.51
2024-08-02 15:05:03,290 [foster.py] => Task 8, Epoch 12/170 => Loss 3.363, Loss_clf 0.439, Loss_fe 0.392, Loss_kd 2.454, Train_accy 77.89, Test_accy 72.32
2024-08-02 15:05:07,199 [foster.py] => Task 8, Epoch 13/170 => Loss 3.339, Loss_clf 0.409, Loss_fe 0.412, Loss_kd 2.441, Train_accy 78.68, Test_accy 72.42
2024-08-02 15:05:11,111 [foster.py] => Task 8, Epoch 14/170 => Loss 3.389, Loss_clf 0.438, Loss_fe 0.393, Loss_kd 2.479, Train_accy 76.93, Test_accy 72.38
2024-08-02 15:05:15,060 [foster.py] => Task 8, Epoch 15/170 => Loss 3.325, Loss_clf 0.410, Loss_fe 0.385, Loss_kd 2.452, Train_accy 79.47, Test_accy 72.12
2024-08-02 15:05:17,418 [foster.py] => Task 8, Epoch 16/170 => Loss 3.291, Loss_clf 0.406, Loss_fe 0.376, Loss_kd 2.431, Train_accy 77.94
2024-08-02 15:05:21,342 [foster.py] => Task 8, Epoch 17/170 => Loss 3.358, Loss_clf 0.434, Loss_fe 0.376, Loss_kd 2.469, Train_accy 77.85, Test_accy 72.47
2024-08-02 15:05:25,268 [foster.py] => Task 8, Epoch 18/170 => Loss 3.307, Loss_clf 0.414, Loss_fe 0.362, Loss_kd 2.452, Train_accy 78.68, Test_accy 72.08
2024-08-02 15:05:29,210 [foster.py] => Task 8, Epoch 19/170 => Loss 3.267, Loss_clf 0.408, Loss_fe 0.330, Loss_kd 2.451, Train_accy 78.64, Test_accy 72.70
2024-08-02 15:05:33,212 [foster.py] => Task 8, Epoch 20/170 => Loss 3.220, Loss_clf 0.385, Loss_fe 0.328, Loss_kd 2.430, Train_accy 80.39, Test_accy 72.67
2024-08-02 15:05:35,549 [foster.py] => Task 8, Epoch 21/170 => Loss 3.302, Loss_clf 0.415, Loss_fe 0.353, Loss_kd 2.456, Train_accy 80.53
2024-08-02 15:05:39,497 [foster.py] => Task 8, Epoch 22/170 => Loss 3.217, Loss_clf 0.365, Loss_fe 0.335, Loss_kd 2.439, Train_accy 81.75, Test_accy 72.45
2024-08-02 15:05:43,469 [foster.py] => Task 8, Epoch 23/170 => Loss 3.258, Loss_clf 0.399, Loss_fe 0.340, Loss_kd 2.442, Train_accy 79.17, Test_accy 72.30
2024-08-02 15:05:47,461 [foster.py] => Task 8, Epoch 24/170 => Loss 3.263, Loss_clf 0.406, Loss_fe 0.323, Loss_kd 2.456, Train_accy 77.98, Test_accy 72.65
2024-08-02 15:05:51,387 [foster.py] => Task 8, Epoch 25/170 => Loss 3.222, Loss_clf 0.383, Loss_fe 0.318, Loss_kd 2.443, Train_accy 80.09, Test_accy 71.89
2024-08-02 15:05:53,725 [foster.py] => Task 8, Epoch 26/170 => Loss 3.259, Loss_clf 0.401, Loss_fe 0.327, Loss_kd 2.453, Train_accy 80.35
2024-08-02 15:05:57,665 [foster.py] => Task 8, Epoch 27/170 => Loss 3.226, Loss_clf 0.397, Loss_fe 0.300, Loss_kd 2.451, Train_accy 80.70, Test_accy 72.48
2024-08-02 15:06:01,620 [foster.py] => Task 8, Epoch 28/170 => Loss 3.201, Loss_clf 0.376, Loss_fe 0.295, Loss_kd 2.451, Train_accy 80.83, Test_accy 72.11
2024-08-02 15:06:05,536 [foster.py] => Task 8, Epoch 29/170 => Loss 3.220, Loss_clf 0.400, Loss_fe 0.310, Loss_kd 2.432, Train_accy 81.14, Test_accy 72.42
2024-08-02 15:06:09,482 [foster.py] => Task 8, Epoch 30/170 => Loss 3.213, Loss_clf 0.382, Loss_fe 0.297, Loss_kd 2.455, Train_accy 80.53, Test_accy 72.45
2024-08-02 15:06:11,840 [foster.py] => Task 8, Epoch 31/170 => Loss 3.210, Loss_clf 0.388, Loss_fe 0.281, Loss_kd 2.463, Train_accy 81.01
2024-08-02 15:06:15,822 [foster.py] => Task 8, Epoch 32/170 => Loss 3.186, Loss_clf 0.384, Loss_fe 0.276, Loss_kd 2.448, Train_accy 81.01, Test_accy 72.53
2024-08-02 15:06:19,783 [foster.py] => Task 8, Epoch 33/170 => Loss 3.167, Loss_clf 0.366, Loss_fe 0.282, Loss_kd 2.441, Train_accy 82.32, Test_accy 72.33
2024-08-02 15:06:23,703 [foster.py] => Task 8, Epoch 34/170 => Loss 3.166, Loss_clf 0.377, Loss_fe 0.242, Loss_kd 2.469, Train_accy 82.63, Test_accy 72.91
2024-08-02 15:06:27,650 [foster.py] => Task 8, Epoch 35/170 => Loss 3.196, Loss_clf 0.379, Loss_fe 0.280, Loss_kd 2.458, Train_accy 81.05, Test_accy 72.48
2024-08-02 15:06:30,008 [foster.py] => Task 8, Epoch 36/170 => Loss 3.254, Loss_clf 0.405, Loss_fe 0.304, Loss_kd 2.466, Train_accy 82.41
2024-08-02 15:06:33,932 [foster.py] => Task 8, Epoch 37/170 => Loss 3.173, Loss_clf 0.374, Loss_fe 0.294, Loss_kd 2.428, Train_accy 81.97, Test_accy 72.12
2024-08-02 15:06:37,836 [foster.py] => Task 8, Epoch 38/170 => Loss 3.161, Loss_clf 0.371, Loss_fe 0.279, Loss_kd 2.433, Train_accy 82.54, Test_accy 72.68
2024-08-02 15:06:41,785 [foster.py] => Task 8, Epoch 39/170 => Loss 3.228, Loss_clf 0.402, Loss_fe 0.287, Loss_kd 2.460, Train_accy 81.36, Test_accy 72.86
2024-08-02 15:06:45,728 [foster.py] => Task 8, Epoch 40/170 => Loss 3.143, Loss_clf 0.351, Loss_fe 0.254, Loss_kd 2.460, Train_accy 82.54, Test_accy 72.82
2024-08-02 15:06:48,109 [foster.py] => Task 8, Epoch 41/170 => Loss 3.163, Loss_clf 0.373, Loss_fe 0.249, Loss_kd 2.463, Train_accy 82.02
2024-08-02 15:06:52,051 [foster.py] => Task 8, Epoch 42/170 => Loss 3.142, Loss_clf 0.371, Loss_fe 0.250, Loss_kd 2.443, Train_accy 82.63, Test_accy 72.95
2024-08-02 15:06:55,997 [foster.py] => Task 8, Epoch 43/170 => Loss 3.173, Loss_clf 0.372, Loss_fe 0.252, Loss_kd 2.471, Train_accy 81.45, Test_accy 72.45
2024-08-02 15:06:59,918 [foster.py] => Task 8, Epoch 44/170 => Loss 3.152, Loss_clf 0.370, Loss_fe 0.247, Loss_kd 2.457, Train_accy 83.33, Test_accy 72.71
2024-08-02 15:07:03,849 [foster.py] => Task 8, Epoch 45/170 => Loss 3.178, Loss_clf 0.386, Loss_fe 0.263, Loss_kd 2.452, Train_accy 82.59, Test_accy 72.68
2024-08-02 15:07:06,215 [foster.py] => Task 8, Epoch 46/170 => Loss 3.098, Loss_clf 0.331, Loss_fe 0.231, Loss_kd 2.457, Train_accy 83.68
2024-08-02 15:07:10,153 [foster.py] => Task 8, Epoch 47/170 => Loss 3.163, Loss_clf 0.375, Loss_fe 0.240, Loss_kd 2.469, Train_accy 82.59, Test_accy 72.88
2024-08-02 15:07:14,071 [foster.py] => Task 8, Epoch 48/170 => Loss 3.199, Loss_clf 0.386, Loss_fe 0.258, Loss_kd 2.476, Train_accy 83.20, Test_accy 72.64
2024-08-02 15:07:18,021 [foster.py] => Task 8, Epoch 49/170 => Loss 3.176, Loss_clf 0.393, Loss_fe 0.246, Loss_kd 2.459, Train_accy 83.11, Test_accy 72.42
2024-08-02 15:07:21,915 [foster.py] => Task 8, Epoch 50/170 => Loss 3.103, Loss_clf 0.345, Loss_fe 0.221, Loss_kd 2.459, Train_accy 84.17, Test_accy 72.98
2024-08-02 15:07:24,263 [foster.py] => Task 8, Epoch 51/170 => Loss 3.128, Loss_clf 0.366, Loss_fe 0.217, Loss_kd 2.466, Train_accy 81.97
2024-08-02 15:07:28,224 [foster.py] => Task 8, Epoch 52/170 => Loss 3.191, Loss_clf 0.386, Loss_fe 0.247, Loss_kd 2.479, Train_accy 83.60, Test_accy 72.77
2024-08-02 15:07:32,152 [foster.py] => Task 8, Epoch 53/170 => Loss 3.141, Loss_clf 0.363, Loss_fe 0.240, Loss_kd 2.460, Train_accy 82.54, Test_accy 72.80
2024-08-02 15:07:36,131 [foster.py] => Task 8, Epoch 54/170 => Loss 3.149, Loss_clf 0.364, Loss_fe 0.222, Loss_kd 2.483, Train_accy 82.32, Test_accy 72.36
2024-08-02 15:07:40,088 [foster.py] => Task 8, Epoch 55/170 => Loss 3.155, Loss_clf 0.367, Loss_fe 0.241, Loss_kd 2.468, Train_accy 82.81, Test_accy 72.79
2024-08-02 15:07:42,432 [foster.py] => Task 8, Epoch 56/170 => Loss 3.113, Loss_clf 0.347, Loss_fe 0.219, Loss_kd 2.468, Train_accy 85.04
2024-08-02 15:07:46,438 [foster.py] => Task 8, Epoch 57/170 => Loss 3.090, Loss_clf 0.327, Loss_fe 0.229, Loss_kd 2.456, Train_accy 83.51, Test_accy 72.88
2024-08-02 15:07:50,428 [foster.py] => Task 8, Epoch 58/170 => Loss 3.087, Loss_clf 0.350, Loss_fe 0.219, Loss_kd 2.441, Train_accy 83.42, Test_accy 73.06
2024-08-02 15:07:54,403 [foster.py] => Task 8, Epoch 59/170 => Loss 3.043, Loss_clf 0.327, Loss_fe 0.194, Loss_kd 2.444, Train_accy 83.90, Test_accy 72.95
2024-08-02 15:07:58,331 [foster.py] => Task 8, Epoch 60/170 => Loss 3.057, Loss_clf 0.339, Loss_fe 0.195, Loss_kd 2.446, Train_accy 85.48, Test_accy 73.24
2024-08-02 15:08:00,682 [foster.py] => Task 8, Epoch 61/170 => Loss 3.050, Loss_clf 0.337, Loss_fe 0.212, Loss_kd 2.423, Train_accy 84.91
2024-08-02 15:08:04,607 [foster.py] => Task 8, Epoch 62/170 => Loss 3.067, Loss_clf 0.333, Loss_fe 0.208, Loss_kd 2.449, Train_accy 84.47, Test_accy 72.98
2024-08-02 15:08:08,557 [foster.py] => Task 8, Epoch 63/170 => Loss 3.053, Loss_clf 0.326, Loss_fe 0.201, Loss_kd 2.448, Train_accy 85.61, Test_accy 72.62
2024-08-02 15:08:12,503 [foster.py] => Task 8, Epoch 64/170 => Loss 3.106, Loss_clf 0.358, Loss_fe 0.203, Loss_kd 2.466, Train_accy 84.74, Test_accy 73.11
2024-08-02 15:08:16,441 [foster.py] => Task 8, Epoch 65/170 => Loss 3.099, Loss_clf 0.355, Loss_fe 0.193, Loss_kd 2.472, Train_accy 84.25, Test_accy 72.83
2024-08-02 15:08:18,804 [foster.py] => Task 8, Epoch 66/170 => Loss 3.049, Loss_clf 0.317, Loss_fe 0.192, Loss_kd 2.462, Train_accy 85.35
2024-08-02 15:08:22,736 [foster.py] => Task 8, Epoch 67/170 => Loss 3.060, Loss_clf 0.337, Loss_fe 0.197, Loss_kd 2.447, Train_accy 84.82, Test_accy 72.98
2024-08-02 15:08:26,675 [foster.py] => Task 8, Epoch 68/170 => Loss 3.062, Loss_clf 0.340, Loss_fe 0.191, Loss_kd 2.453, Train_accy 85.13, Test_accy 72.95
2024-08-02 15:08:30,611 [foster.py] => Task 8, Epoch 69/170 => Loss 3.097, Loss_clf 0.352, Loss_fe 0.196, Loss_kd 2.471, Train_accy 83.46, Test_accy 73.18
2024-08-02 15:08:34,549 [foster.py] => Task 8, Epoch 70/170 => Loss 3.099, Loss_clf 0.354, Loss_fe 0.193, Loss_kd 2.474, Train_accy 85.35, Test_accy 72.98
2024-08-02 15:08:36,938 [foster.py] => Task 8, Epoch 71/170 => Loss 3.070, Loss_clf 0.334, Loss_fe 0.186, Loss_kd 2.471, Train_accy 85.88
2024-08-02 15:08:40,884 [foster.py] => Task 8, Epoch 72/170 => Loss 3.046, Loss_clf 0.331, Loss_fe 0.179, Loss_kd 2.458, Train_accy 85.18, Test_accy 73.09
2024-08-02 15:08:44,871 [foster.py] => Task 8, Epoch 73/170 => Loss 3.029, Loss_clf 0.333, Loss_fe 0.176, Loss_kd 2.443, Train_accy 84.78, Test_accy 72.94
2024-08-02 15:08:48,799 [foster.py] => Task 8, Epoch 74/170 => Loss 3.050, Loss_clf 0.337, Loss_fe 0.182, Loss_kd 2.453, Train_accy 84.87, Test_accy 72.76
2024-08-02 15:08:52,711 [foster.py] => Task 8, Epoch 75/170 => Loss 2.964, Loss_clf 0.294, Loss_fe 0.169, Loss_kd 2.423, Train_accy 86.49, Test_accy 72.77
2024-08-02 15:08:55,262 [foster.py] => Task 8, Epoch 76/170 => Loss 3.006, Loss_clf 0.312, Loss_fe 0.172, Loss_kd 2.445, Train_accy 86.62
2024-08-02 15:08:59,181 [foster.py] => Task 8, Epoch 77/170 => Loss 3.045, Loss_clf 0.321, Loss_fe 0.186, Loss_kd 2.460, Train_accy 85.70, Test_accy 72.94
2024-08-02 15:09:03,120 [foster.py] => Task 8, Epoch 78/170 => Loss 3.018, Loss_clf 0.328, Loss_fe 0.168, Loss_kd 2.444, Train_accy 85.88, Test_accy 73.11
2024-08-02 15:09:07,084 [foster.py] => Task 8, Epoch 79/170 => Loss 3.103, Loss_clf 0.359, Loss_fe 0.180, Loss_kd 2.484, Train_accy 85.18, Test_accy 73.26
2024-08-02 15:09:11,023 [foster.py] => Task 8, Epoch 80/170 => Loss 3.010, Loss_clf 0.308, Loss_fe 0.154, Loss_kd 2.470, Train_accy 87.54, Test_accy 73.17
2024-08-02 15:09:13,370 [foster.py] => Task 8, Epoch 81/170 => Loss 3.080, Loss_clf 0.358, Loss_fe 0.182, Loss_kd 2.463, Train_accy 84.87
2024-08-02 15:09:17,261 [foster.py] => Task 8, Epoch 82/170 => Loss 3.040, Loss_clf 0.331, Loss_fe 0.163, Loss_kd 2.468, Train_accy 85.44, Test_accy 73.05
2024-08-02 15:09:21,244 [foster.py] => Task 8, Epoch 83/170 => Loss 2.981, Loss_clf 0.313, Loss_fe 0.160, Loss_kd 2.431, Train_accy 86.49, Test_accy 73.20
2024-08-02 15:09:25,183 [foster.py] => Task 8, Epoch 84/170 => Loss 2.994, Loss_clf 0.311, Loss_fe 0.158, Loss_kd 2.447, Train_accy 85.57, Test_accy 72.70
2024-08-02 15:09:29,095 [foster.py] => Task 8, Epoch 85/170 => Loss 3.062, Loss_clf 0.345, Loss_fe 0.175, Loss_kd 2.464, Train_accy 87.15, Test_accy 73.20
2024-08-02 15:09:31,450 [foster.py] => Task 8, Epoch 86/170 => Loss 3.075, Loss_clf 0.364, Loss_fe 0.178, Loss_kd 2.454, Train_accy 84.21
2024-08-02 15:09:35,392 [foster.py] => Task 8, Epoch 87/170 => Loss 3.036, Loss_clf 0.330, Loss_fe 0.164, Loss_kd 2.463, Train_accy 86.01, Test_accy 72.71
2024-08-02 15:09:39,315 [foster.py] => Task 8, Epoch 88/170 => Loss 3.086, Loss_clf 0.355, Loss_fe 0.183, Loss_kd 2.470, Train_accy 84.52, Test_accy 72.98
2024-08-02 15:09:43,239 [foster.py] => Task 8, Epoch 89/170 => Loss 3.039, Loss_clf 0.332, Loss_fe 0.166, Loss_kd 2.463, Train_accy 84.82, Test_accy 72.88
2024-08-02 15:09:47,223 [foster.py] => Task 8, Epoch 90/170 => Loss 3.041, Loss_clf 0.338, Loss_fe 0.163, Loss_kd 2.461, Train_accy 85.57, Test_accy 73.06
2024-08-02 15:09:49,601 [foster.py] => Task 8, Epoch 91/170 => Loss 3.018, Loss_clf 0.323, Loss_fe 0.160, Loss_kd 2.457, Train_accy 85.79
2024-08-02 15:09:53,541 [foster.py] => Task 8, Epoch 92/170 => Loss 3.013, Loss_clf 0.309, Loss_fe 0.172, Loss_kd 2.454, Train_accy 87.15, Test_accy 73.17
2024-08-02 15:09:57,481 [foster.py] => Task 8, Epoch 93/170 => Loss 3.018, Loss_clf 0.326, Loss_fe 0.151, Loss_kd 2.463, Train_accy 85.70, Test_accy 72.94
2024-08-02 15:10:01,383 [foster.py] => Task 8, Epoch 94/170 => Loss 2.980, Loss_clf 0.314, Loss_fe 0.155, Loss_kd 2.433, Train_accy 87.85, Test_accy 73.09
2024-08-02 15:10:05,324 [foster.py] => Task 8, Epoch 95/170 => Loss 3.088, Loss_clf 0.347, Loss_fe 0.172, Loss_kd 2.490, Train_accy 86.10, Test_accy 73.03
2024-08-02 15:10:07,683 [foster.py] => Task 8, Epoch 96/170 => Loss 3.060, Loss_clf 0.324, Loss_fe 0.177, Loss_kd 2.479, Train_accy 87.19
2024-08-02 15:10:11,630 [foster.py] => Task 8, Epoch 97/170 => Loss 3.003, Loss_clf 0.319, Loss_fe 0.143, Loss_kd 2.463, Train_accy 86.14, Test_accy 73.02
2024-08-02 15:10:15,634 [foster.py] => Task 8, Epoch 98/170 => Loss 3.002, Loss_clf 0.324, Loss_fe 0.153, Loss_kd 2.447, Train_accy 85.88, Test_accy 72.95
2024-08-02 15:10:19,541 [foster.py] => Task 8, Epoch 99/170 => Loss 2.964, Loss_clf 0.301, Loss_fe 0.151, Loss_kd 2.434, Train_accy 87.59, Test_accy 73.03
2024-08-02 15:10:23,518 [foster.py] => Task 8, Epoch 100/170 => Loss 2.965, Loss_clf 0.289, Loss_fe 0.147, Loss_kd 2.451, Train_accy 87.50, Test_accy 72.98
2024-08-02 15:10:25,870 [foster.py] => Task 8, Epoch 101/170 => Loss 3.019, Loss_clf 0.332, Loss_fe 0.133, Loss_kd 2.475, Train_accy 87.06
2024-08-02 15:10:29,811 [foster.py] => Task 8, Epoch 102/170 => Loss 3.000, Loss_clf 0.320, Loss_fe 0.142, Loss_kd 2.459, Train_accy 85.57, Test_accy 73.08
2024-08-02 15:10:33,727 [foster.py] => Task 8, Epoch 103/170 => Loss 3.022, Loss_clf 0.338, Loss_fe 0.148, Loss_kd 2.458, Train_accy 85.31, Test_accy 73.14
2024-08-02 15:10:37,665 [foster.py] => Task 8, Epoch 104/170 => Loss 3.000, Loss_clf 0.320, Loss_fe 0.123, Loss_kd 2.478, Train_accy 86.84, Test_accy 72.92
2024-08-02 15:10:41,586 [foster.py] => Task 8, Epoch 105/170 => Loss 2.953, Loss_clf 0.309, Loss_fe 0.138, Loss_kd 2.429, Train_accy 86.62, Test_accy 73.17
2024-08-02 15:10:43,972 [foster.py] => Task 8, Epoch 106/170 => Loss 3.013, Loss_clf 0.321, Loss_fe 0.141, Loss_kd 2.474, Train_accy 86.54
2024-08-02 15:10:47,904 [foster.py] => Task 8, Epoch 107/170 => Loss 3.028, Loss_clf 0.324, Loss_fe 0.150, Loss_kd 2.476, Train_accy 86.54, Test_accy 72.98
2024-08-02 15:10:51,839 [foster.py] => Task 8, Epoch 108/170 => Loss 3.013, Loss_clf 0.334, Loss_fe 0.143, Loss_kd 2.457, Train_accy 86.40, Test_accy 73.08
2024-08-02 15:10:55,747 [foster.py] => Task 8, Epoch 109/170 => Loss 2.993, Loss_clf 0.325, Loss_fe 0.132, Loss_kd 2.457, Train_accy 86.23, Test_accy 73.21
2024-08-02 15:10:59,671 [foster.py] => Task 8, Epoch 110/170 => Loss 2.987, Loss_clf 0.319, Loss_fe 0.136, Loss_kd 2.454, Train_accy 86.67, Test_accy 73.15
2024-08-02 15:11:02,005 [foster.py] => Task 8, Epoch 111/170 => Loss 2.999, Loss_clf 0.319, Loss_fe 0.129, Loss_kd 2.473, Train_accy 87.37
2024-08-02 15:11:05,936 [foster.py] => Task 8, Epoch 112/170 => Loss 2.934, Loss_clf 0.286, Loss_fe 0.128, Loss_kd 2.442, Train_accy 88.20, Test_accy 73.14
2024-08-02 15:11:09,866 [foster.py] => Task 8, Epoch 113/170 => Loss 2.996, Loss_clf 0.320, Loss_fe 0.135, Loss_kd 2.463, Train_accy 86.93, Test_accy 73.17
2024-08-02 15:11:13,803 [foster.py] => Task 8, Epoch 114/170 => Loss 2.959, Loss_clf 0.301, Loss_fe 0.122, Loss_kd 2.457, Train_accy 87.85, Test_accy 73.18
2024-08-02 15:11:17,724 [foster.py] => Task 8, Epoch 115/170 => Loss 2.964, Loss_clf 0.303, Loss_fe 0.140, Loss_kd 2.443, Train_accy 87.94, Test_accy 73.02
2024-08-02 15:11:20,076 [foster.py] => Task 8, Epoch 116/170 => Loss 2.959, Loss_clf 0.301, Loss_fe 0.123, Loss_kd 2.457, Train_accy 86.62
2024-08-02 15:11:24,051 [foster.py] => Task 8, Epoch 117/170 => Loss 2.939, Loss_clf 0.285, Loss_fe 0.107, Loss_kd 2.469, Train_accy 88.11, Test_accy 73.12
2024-08-02 15:11:27,982 [foster.py] => Task 8, Epoch 118/170 => Loss 2.963, Loss_clf 0.295, Loss_fe 0.122, Loss_kd 2.468, Train_accy 88.51, Test_accy 73.15
2024-08-02 15:11:31,912 [foster.py] => Task 8, Epoch 119/170 => Loss 2.882, Loss_clf 0.257, Loss_fe 0.114, Loss_kd 2.434, Train_accy 88.60, Test_accy 73.17
2024-08-02 15:11:35,937 [foster.py] => Task 8, Epoch 120/170 => Loss 2.977, Loss_clf 0.296, Loss_fe 0.125, Loss_kd 2.477, Train_accy 87.63, Test_accy 73.36
2024-08-02 15:11:38,324 [foster.py] => Task 8, Epoch 121/170 => Loss 2.982, Loss_clf 0.300, Loss_fe 0.126, Loss_kd 2.477, Train_accy 87.81
2024-08-02 15:11:42,269 [foster.py] => Task 8, Epoch 122/170 => Loss 2.915, Loss_clf 0.283, Loss_fe 0.109, Loss_kd 2.445, Train_accy 88.38, Test_accy 73.23
2024-08-02 15:11:46,274 [foster.py] => Task 8, Epoch 123/170 => Loss 2.967, Loss_clf 0.310, Loss_fe 0.122, Loss_kd 2.456, Train_accy 87.32, Test_accy 73.18
2024-08-02 15:11:50,181 [foster.py] => Task 8, Epoch 124/170 => Loss 2.956, Loss_clf 0.302, Loss_fe 0.104, Loss_kd 2.472, Train_accy 88.16, Test_accy 73.05
2024-08-02 15:11:54,136 [foster.py] => Task 8, Epoch 125/170 => Loss 2.986, Loss_clf 0.322, Loss_fe 0.124, Loss_kd 2.462, Train_accy 86.45, Test_accy 73.09
2024-08-02 15:11:56,508 [foster.py] => Task 8, Epoch 126/170 => Loss 2.921, Loss_clf 0.292, Loss_fe 0.098, Loss_kd 2.452, Train_accy 87.68
2024-08-02 15:12:00,492 [foster.py] => Task 8, Epoch 127/170 => Loss 2.923, Loss_clf 0.273, Loss_fe 0.102, Loss_kd 2.469, Train_accy 88.29, Test_accy 73.24
2024-08-02 15:12:04,434 [foster.py] => Task 8, Epoch 128/170 => Loss 2.897, Loss_clf 0.270, Loss_fe 0.107, Loss_kd 2.442, Train_accy 88.51, Test_accy 73.29
2024-08-02 15:12:08,355 [foster.py] => Task 8, Epoch 129/170 => Loss 2.964, Loss_clf 0.299, Loss_fe 0.117, Loss_kd 2.469, Train_accy 88.07, Test_accy 73.18
2024-08-02 15:12:12,320 [foster.py] => Task 8, Epoch 130/170 => Loss 2.981, Loss_clf 0.295, Loss_fe 0.128, Loss_kd 2.479, Train_accy 87.76, Test_accy 73.44
2024-08-02 15:12:14,651 [foster.py] => Task 8, Epoch 131/170 => Loss 2.903, Loss_clf 0.285, Loss_fe 0.104, Loss_kd 2.436, Train_accy 88.16
2024-08-02 15:12:18,568 [foster.py] => Task 8, Epoch 132/170 => Loss 2.985, Loss_clf 0.304, Loss_fe 0.115, Loss_kd 2.487, Train_accy 87.59, Test_accy 73.11
2024-08-02 15:12:22,493 [foster.py] => Task 8, Epoch 133/170 => Loss 2.953, Loss_clf 0.301, Loss_fe 0.106, Loss_kd 2.467, Train_accy 87.72, Test_accy 73.00
2024-08-02 15:12:26,402 [foster.py] => Task 8, Epoch 134/170 => Loss 2.860, Loss_clf 0.259, Loss_fe 0.090, Loss_kd 2.433, Train_accy 88.68, Test_accy 73.23
2024-08-02 15:12:30,331 [foster.py] => Task 8, Epoch 135/170 => Loss 2.953, Loss_clf 0.294, Loss_fe 0.118, Loss_kd 2.462, Train_accy 88.29, Test_accy 73.29
2024-08-02 15:12:32,700 [foster.py] => Task 8, Epoch 136/170 => Loss 2.977, Loss_clf 0.312, Loss_fe 0.109, Loss_kd 2.478, Train_accy 87.50
2024-08-02 15:12:36,607 [foster.py] => Task 8, Epoch 137/170 => Loss 2.926, Loss_clf 0.280, Loss_fe 0.096, Loss_kd 2.471, Train_accy 88.82, Test_accy 73.09
2024-08-02 15:12:40,603 [foster.py] => Task 8, Epoch 138/170 => Loss 2.906, Loss_clf 0.276, Loss_fe 0.109, Loss_kd 2.443, Train_accy 89.65, Test_accy 73.17
2024-08-02 15:12:44,533 [foster.py] => Task 8, Epoch 139/170 => Loss 2.923, Loss_clf 0.297, Loss_fe 0.104, Loss_kd 2.444, Train_accy 87.81, Test_accy 73.17
2024-08-02 15:12:48,482 [foster.py] => Task 8, Epoch 140/170 => Loss 2.895, Loss_clf 0.268, Loss_fe 0.099, Loss_kd 2.450, Train_accy 89.12, Test_accy 73.24
2024-08-02 15:12:50,839 [foster.py] => Task 8, Epoch 141/170 => Loss 2.939, Loss_clf 0.300, Loss_fe 0.101, Loss_kd 2.460, Train_accy 87.94
2024-08-02 15:12:54,829 [foster.py] => Task 8, Epoch 142/170 => Loss 2.925, Loss_clf 0.294, Loss_fe 0.093, Loss_kd 2.459, Train_accy 88.33, Test_accy 73.12
2024-08-02 15:12:58,802 [foster.py] => Task 8, Epoch 143/170 => Loss 2.933, Loss_clf 0.289, Loss_fe 0.108, Loss_kd 2.458, Train_accy 88.29, Test_accy 73.06
2024-08-02 15:13:02,735 [foster.py] => Task 8, Epoch 144/170 => Loss 2.938, Loss_clf 0.298, Loss_fe 0.107, Loss_kd 2.455, Train_accy 87.89, Test_accy 73.15
2024-08-02 15:13:06,681 [foster.py] => Task 8, Epoch 145/170 => Loss 2.868, Loss_clf 0.268, Loss_fe 0.104, Loss_kd 2.420, Train_accy 88.77, Test_accy 73.12
2024-08-02 15:13:09,038 [foster.py] => Task 8, Epoch 146/170 => Loss 2.904, Loss_clf 0.267, Loss_fe 0.090, Loss_kd 2.468, Train_accy 88.82
2024-08-02 15:13:12,964 [foster.py] => Task 8, Epoch 147/170 => Loss 2.946, Loss_clf 0.298, Loss_fe 0.103, Loss_kd 2.466, Train_accy 88.07, Test_accy 73.08
2024-08-02 15:13:16,896 [foster.py] => Task 8, Epoch 148/170 => Loss 2.884, Loss_clf 0.263, Loss_fe 0.100, Loss_kd 2.444, Train_accy 88.60, Test_accy 73.09
2024-08-02 15:13:20,820 [foster.py] => Task 8, Epoch 149/170 => Loss 2.962, Loss_clf 0.309, Loss_fe 0.101, Loss_kd 2.472, Train_accy 88.29, Test_accy 73.17
2024-08-02 15:13:24,772 [foster.py] => Task 8, Epoch 150/170 => Loss 2.877, Loss_clf 0.264, Loss_fe 0.094, Loss_kd 2.441, Train_accy 88.99, Test_accy 73.09
2024-08-02 15:13:27,107 [foster.py] => Task 8, Epoch 151/170 => Loss 2.879, Loss_clf 0.273, Loss_fe 0.094, Loss_kd 2.435, Train_accy 88.33
2024-08-02 15:13:31,056 [foster.py] => Task 8, Epoch 152/170 => Loss 2.935, Loss_clf 0.285, Loss_fe 0.111, Loss_kd 2.461, Train_accy 88.55, Test_accy 73.11
2024-08-02 15:13:34,988 [foster.py] => Task 8, Epoch 153/170 => Loss 2.946, Loss_clf 0.301, Loss_fe 0.113, Loss_kd 2.454, Train_accy 87.32, Test_accy 73.11
2024-08-02 15:13:39,004 [foster.py] => Task 8, Epoch 154/170 => Loss 2.943, Loss_clf 0.292, Loss_fe 0.109, Loss_kd 2.464, Train_accy 87.81, Test_accy 72.97
2024-08-02 15:13:42,935 [foster.py] => Task 8, Epoch 155/170 => Loss 2.899, Loss_clf 0.273, Loss_fe 0.103, Loss_kd 2.445, Train_accy 89.12, Test_accy 72.98
2024-08-02 15:13:45,274 [foster.py] => Task 8, Epoch 156/170 => Loss 2.958, Loss_clf 0.312, Loss_fe 0.100, Loss_kd 2.467, Train_accy 87.54
2024-08-02 15:13:49,215 [foster.py] => Task 8, Epoch 157/170 => Loss 2.924, Loss_clf 0.284, Loss_fe 0.109, Loss_kd 2.452, Train_accy 88.64, Test_accy 73.05
2024-08-02 15:13:53,141 [foster.py] => Task 8, Epoch 158/170 => Loss 2.903, Loss_clf 0.268, Loss_fe 0.087, Loss_kd 2.469, Train_accy 89.12, Test_accy 73.09
2024-08-02 15:13:57,103 [foster.py] => Task 8, Epoch 159/170 => Loss 2.960, Loss_clf 0.305, Loss_fe 0.113, Loss_kd 2.464, Train_accy 87.59, Test_accy 73.06
2024-08-02 15:14:01,012 [foster.py] => Task 8, Epoch 160/170 => Loss 2.937, Loss_clf 0.292, Loss_fe 0.099, Loss_kd 2.468, Train_accy 87.94, Test_accy 73.11
2024-08-02 15:14:03,370 [foster.py] => Task 8, Epoch 161/170 => Loss 2.916, Loss_clf 0.285, Loss_fe 0.104, Loss_kd 2.449, Train_accy 88.25
2024-08-02 15:14:07,346 [foster.py] => Task 8, Epoch 162/170 => Loss 2.882, Loss_clf 0.270, Loss_fe 0.079, Loss_kd 2.454, Train_accy 88.99, Test_accy 73.08
2024-08-02 15:14:11,296 [foster.py] => Task 8, Epoch 163/170 => Loss 2.930, Loss_clf 0.290, Loss_fe 0.107, Loss_kd 2.456, Train_accy 88.86, Test_accy 73.11
2024-08-02 15:14:15,281 [foster.py] => Task 8, Epoch 164/170 => Loss 2.918, Loss_clf 0.290, Loss_fe 0.105, Loss_kd 2.445, Train_accy 88.82, Test_accy 73.14
2024-08-02 15:14:19,209 [foster.py] => Task 8, Epoch 165/170 => Loss 2.922, Loss_clf 0.287, Loss_fe 0.089, Loss_kd 2.467, Train_accy 88.86, Test_accy 73.08
2024-08-02 15:14:21,561 [foster.py] => Task 8, Epoch 166/170 => Loss 2.970, Loss_clf 0.303, Loss_fe 0.095, Loss_kd 2.492, Train_accy 87.28
2024-08-02 15:14:25,603 [foster.py] => Task 8, Epoch 167/170 => Loss 2.906, Loss_clf 0.296, Loss_fe 0.092, Loss_kd 2.441, Train_accy 87.28, Test_accy 73.06
2024-08-02 15:14:29,631 [foster.py] => Task 8, Epoch 168/170 => Loss 2.900, Loss_clf 0.274, Loss_fe 0.095, Loss_kd 2.452, Train_accy 88.64, Test_accy 73.15
2024-08-02 15:14:33,612 [foster.py] => Task 8, Epoch 169/170 => Loss 2.921, Loss_clf 0.287, Loss_fe 0.109, Loss_kd 2.447, Train_accy 88.38, Test_accy 73.11
2024-08-02 15:14:37,565 [foster.py] => Task 8, Epoch 170/170 => Loss 2.896, Loss_clf 0.285, Loss_fe 0.103, Loss_kd 2.432, Train_accy 87.37, Test_accy 73.08
2024-08-02 15:14:37,568 [foster.py] => do not weight align teacher!
2024-08-02 15:14:37,570 [foster.py] => per cls weights : [1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323 1.01653323
 1.01653323 1.01653323 1.01653323 1.01653323 0.47093651 0.47093651]
2024-08-02 15:14:42,019 [foster.py] => SNet: Task 8, Epoch 1/130 => Loss 28.742,  Loss1 0.721, Train_accy 47.59, Test_accy 69.47
2024-08-02 15:14:45,268 [foster.py] => SNet: Task 8, Epoch 2/130 => Loss 28.617,  Loss1 0.721, Train_accy 57.85
2024-08-02 15:14:48,500 [foster.py] => SNet: Task 8, Epoch 3/130 => Loss 28.611,  Loss1 0.721, Train_accy 60.53
2024-08-02 15:14:51,741 [foster.py] => SNet: Task 8, Epoch 4/130 => Loss 28.563,  Loss1 0.721, Train_accy 60.57
2024-08-02 15:14:54,975 [foster.py] => SNet: Task 8, Epoch 5/130 => Loss 28.575,  Loss1 0.720, Train_accy 61.36
2024-08-02 15:14:59,274 [foster.py] => SNet: Task 8, Epoch 6/130 => Loss 28.532,  Loss1 0.721, Train_accy 65.66, Test_accy 71.24
2024-08-02 15:15:02,547 [foster.py] => SNet: Task 8, Epoch 7/130 => Loss 28.582,  Loss1 0.720, Train_accy 64.52
2024-08-02 15:15:05,789 [foster.py] => SNet: Task 8, Epoch 8/130 => Loss 28.585,  Loss1 0.721, Train_accy 65.79
2024-08-02 15:15:09,056 [foster.py] => SNet: Task 8, Epoch 9/130 => Loss 28.498,  Loss1 0.721, Train_accy 66.10
2024-08-02 15:15:12,353 [foster.py] => SNet: Task 8, Epoch 10/130 => Loss 28.560,  Loss1 0.720, Train_accy 68.07
2024-08-02 15:15:16,652 [foster.py] => SNet: Task 8, Epoch 11/130 => Loss 28.547,  Loss1 0.720, Train_accy 69.56, Test_accy 71.92
2024-08-02 15:15:19,890 [foster.py] => SNet: Task 8, Epoch 12/130 => Loss 28.585,  Loss1 0.721, Train_accy 67.19
2024-08-02 15:15:23,136 [foster.py] => SNet: Task 8, Epoch 13/130 => Loss 28.560,  Loss1 0.720, Train_accy 68.95
2024-08-02 15:15:26,383 [foster.py] => SNet: Task 8, Epoch 14/130 => Loss 28.536,  Loss1 0.721, Train_accy 70.44
2024-08-02 15:15:29,656 [foster.py] => SNet: Task 8, Epoch 15/130 => Loss 28.560,  Loss1 0.721, Train_accy 70.22
2024-08-02 15:15:33,922 [foster.py] => SNet: Task 8, Epoch 16/130 => Loss 28.535,  Loss1 0.720, Train_accy 70.09, Test_accy 71.73
2024-08-02 15:15:37,155 [foster.py] => SNet: Task 8, Epoch 17/130 => Loss 28.540,  Loss1 0.721, Train_accy 71.32
2024-08-02 15:15:40,395 [foster.py] => SNet: Task 8, Epoch 18/130 => Loss 28.564,  Loss1 0.721, Train_accy 71.71
2024-08-02 15:15:43,653 [foster.py] => SNet: Task 8, Epoch 19/130 => Loss 28.545,  Loss1 0.721, Train_accy 70.79
2024-08-02 15:15:46,899 [foster.py] => SNet: Task 8, Epoch 20/130 => Loss 28.559,  Loss1 0.720, Train_accy 70.92
2024-08-02 15:15:51,191 [foster.py] => SNet: Task 8, Epoch 21/130 => Loss 28.525,  Loss1 0.720, Train_accy 72.06, Test_accy 72.27
2024-08-02 15:15:54,451 [foster.py] => SNet: Task 8, Epoch 22/130 => Loss 28.530,  Loss1 0.721, Train_accy 71.84
2024-08-02 15:15:57,687 [foster.py] => SNet: Task 8, Epoch 23/130 => Loss 28.571,  Loss1 0.721, Train_accy 73.51
2024-08-02 15:16:00,957 [foster.py] => SNet: Task 8, Epoch 24/130 => Loss 28.507,  Loss1 0.721, Train_accy 72.06
2024-08-02 15:16:04,206 [foster.py] => SNet: Task 8, Epoch 25/130 => Loss 28.573,  Loss1 0.721, Train_accy 71.84
2024-08-02 15:16:08,472 [foster.py] => SNet: Task 8, Epoch 26/130 => Loss 28.573,  Loss1 0.720, Train_accy 73.33, Test_accy 72.09
2024-08-02 15:16:11,738 [foster.py] => SNet: Task 8, Epoch 27/130 => Loss 28.548,  Loss1 0.721, Train_accy 72.63
2024-08-02 15:16:14,981 [foster.py] => SNet: Task 8, Epoch 28/130 => Loss 28.602,  Loss1 0.721, Train_accy 72.81
2024-08-02 15:16:18,252 [foster.py] => SNet: Task 8, Epoch 29/130 => Loss 28.490,  Loss1 0.720, Train_accy 73.16
2024-08-02 15:16:21,559 [foster.py] => SNet: Task 8, Epoch 30/130 => Loss 28.602,  Loss1 0.720, Train_accy 73.68
2024-08-02 15:16:25,828 [foster.py] => SNet: Task 8, Epoch 31/130 => Loss 28.537,  Loss1 0.721, Train_accy 73.95, Test_accy 72.20
2024-08-02 15:16:29,087 [foster.py] => SNet: Task 8, Epoch 32/130 => Loss 28.521,  Loss1 0.721, Train_accy 73.77
2024-08-02 15:16:32,346 [foster.py] => SNet: Task 8, Epoch 33/130 => Loss 28.536,  Loss1 0.721, Train_accy 73.11
2024-08-02 15:16:35,604 [foster.py] => SNet: Task 8, Epoch 34/130 => Loss 28.528,  Loss1 0.721, Train_accy 73.90
2024-08-02 15:16:38,847 [foster.py] => SNet: Task 8, Epoch 35/130 => Loss 28.543,  Loss1 0.720, Train_accy 73.95
2024-08-02 15:16:43,132 [foster.py] => SNet: Task 8, Epoch 36/130 => Loss 28.538,  Loss1 0.721, Train_accy 74.25, Test_accy 72.12
2024-08-02 15:16:46,376 [foster.py] => SNet: Task 8, Epoch 37/130 => Loss 28.526,  Loss1 0.721, Train_accy 74.34
2024-08-02 15:16:49,627 [foster.py] => SNet: Task 8, Epoch 38/130 => Loss 28.525,  Loss1 0.721, Train_accy 74.82
2024-08-02 15:16:52,878 [foster.py] => SNet: Task 8, Epoch 39/130 => Loss 28.535,  Loss1 0.721, Train_accy 75.35
2024-08-02 15:16:56,126 [foster.py] => SNet: Task 8, Epoch 40/130 => Loss 28.551,  Loss1 0.720, Train_accy 73.99
2024-08-02 15:17:00,440 [foster.py] => SNet: Task 8, Epoch 41/130 => Loss 28.538,  Loss1 0.720, Train_accy 73.99, Test_accy 71.94
2024-08-02 15:17:03,720 [foster.py] => SNet: Task 8, Epoch 42/130 => Loss 28.527,  Loss1 0.720, Train_accy 74.52
2024-08-02 15:17:06,967 [foster.py] => SNet: Task 8, Epoch 43/130 => Loss 28.559,  Loss1 0.721, Train_accy 74.56
2024-08-02 15:17:10,229 [foster.py] => SNet: Task 8, Epoch 44/130 => Loss 28.602,  Loss1 0.720, Train_accy 73.64
2024-08-02 15:17:13,453 [foster.py] => SNet: Task 8, Epoch 45/130 => Loss 28.554,  Loss1 0.720, Train_accy 74.52
2024-08-02 15:17:17,722 [foster.py] => SNet: Task 8, Epoch 46/130 => Loss 28.565,  Loss1 0.721, Train_accy 75.22, Test_accy 72.36
2024-08-02 15:17:20,974 [foster.py] => SNet: Task 8, Epoch 47/130 => Loss 28.542,  Loss1 0.721, Train_accy 75.09
2024-08-02 15:17:24,228 [foster.py] => SNet: Task 8, Epoch 48/130 => Loss 28.510,  Loss1 0.720, Train_accy 75.13
2024-08-02 15:17:27,532 [foster.py] => SNet: Task 8, Epoch 49/130 => Loss 28.511,  Loss1 0.720, Train_accy 75.18
2024-08-02 15:17:30,796 [foster.py] => SNet: Task 8, Epoch 50/130 => Loss 28.536,  Loss1 0.721, Train_accy 73.60
2024-08-02 15:17:35,067 [foster.py] => SNet: Task 8, Epoch 51/130 => Loss 28.460,  Loss1 0.720, Train_accy 75.04, Test_accy 72.24
2024-08-02 15:17:38,304 [foster.py] => SNet: Task 8, Epoch 52/130 => Loss 28.515,  Loss1 0.720, Train_accy 75.22
2024-08-02 15:17:41,559 [foster.py] => SNet: Task 8, Epoch 53/130 => Loss 28.542,  Loss1 0.721, Train_accy 76.75
2024-08-02 15:17:44,814 [foster.py] => SNet: Task 8, Epoch 54/130 => Loss 28.521,  Loss1 0.720, Train_accy 75.04
2024-08-02 15:17:48,063 [foster.py] => SNet: Task 8, Epoch 55/130 => Loss 28.504,  Loss1 0.721, Train_accy 76.89
2024-08-02 15:17:52,347 [foster.py] => SNet: Task 8, Epoch 56/130 => Loss 28.568,  Loss1 0.721, Train_accy 74.74, Test_accy 72.26
2024-08-02 15:17:55,619 [foster.py] => SNet: Task 8, Epoch 57/130 => Loss 28.512,  Loss1 0.721, Train_accy 74.87
2024-08-02 15:17:58,842 [foster.py] => SNet: Task 8, Epoch 58/130 => Loss 28.525,  Loss1 0.721, Train_accy 75.44
2024-08-02 15:18:02,123 [foster.py] => SNet: Task 8, Epoch 59/130 => Loss 28.533,  Loss1 0.721, Train_accy 74.65
2024-08-02 15:18:05,376 [foster.py] => SNet: Task 8, Epoch 60/130 => Loss 28.544,  Loss1 0.720, Train_accy 74.96
2024-08-02 15:18:09,679 [foster.py] => SNet: Task 8, Epoch 61/130 => Loss 28.566,  Loss1 0.720, Train_accy 75.57, Test_accy 72.08
2024-08-02 15:18:12,953 [foster.py] => SNet: Task 8, Epoch 62/130 => Loss 28.493,  Loss1 0.721, Train_accy 75.44
2024-08-02 15:18:16,193 [foster.py] => SNet: Task 8, Epoch 63/130 => Loss 28.525,  Loss1 0.720, Train_accy 76.75
2024-08-02 15:18:19,414 [foster.py] => SNet: Task 8, Epoch 64/130 => Loss 28.540,  Loss1 0.721, Train_accy 76.58
2024-08-02 15:18:22,660 [foster.py] => SNet: Task 8, Epoch 65/130 => Loss 28.563,  Loss1 0.721, Train_accy 75.13
2024-08-02 15:18:26,917 [foster.py] => SNet: Task 8, Epoch 66/130 => Loss 28.498,  Loss1 0.720, Train_accy 75.39, Test_accy 72.14
2024-08-02 15:18:30,205 [foster.py] => SNet: Task 8, Epoch 67/130 => Loss 28.518,  Loss1 0.720, Train_accy 76.23
2024-08-02 15:18:33,435 [foster.py] => SNet: Task 8, Epoch 68/130 => Loss 28.520,  Loss1 0.720, Train_accy 75.09
2024-08-02 15:18:36,746 [foster.py] => SNet: Task 8, Epoch 69/130 => Loss 28.559,  Loss1 0.721, Train_accy 75.18
2024-08-02 15:18:39,995 [foster.py] => SNet: Task 8, Epoch 70/130 => Loss 28.539,  Loss1 0.721, Train_accy 75.00
2024-08-02 15:18:44,291 [foster.py] => SNet: Task 8, Epoch 71/130 => Loss 28.505,  Loss1 0.721, Train_accy 76.45, Test_accy 72.20
2024-08-02 15:18:47,535 [foster.py] => SNet: Task 8, Epoch 72/130 => Loss 28.531,  Loss1 0.720, Train_accy 74.34
2024-08-02 15:18:50,769 [foster.py] => SNet: Task 8, Epoch 73/130 => Loss 28.572,  Loss1 0.720, Train_accy 74.43
2024-08-02 15:18:54,022 [foster.py] => SNet: Task 8, Epoch 74/130 => Loss 28.531,  Loss1 0.721, Train_accy 75.48
2024-08-02 15:18:57,239 [foster.py] => SNet: Task 8, Epoch 75/130 => Loss 28.596,  Loss1 0.720, Train_accy 75.92
2024-08-02 15:19:01,526 [foster.py] => SNet: Task 8, Epoch 76/130 => Loss 28.540,  Loss1 0.720, Train_accy 75.88, Test_accy 72.42
2024-08-02 15:19:04,808 [foster.py] => SNet: Task 8, Epoch 77/130 => Loss 28.521,  Loss1 0.721, Train_accy 76.45
2024-08-02 15:19:08,040 [foster.py] => SNet: Task 8, Epoch 78/130 => Loss 28.536,  Loss1 0.721, Train_accy 77.32
2024-08-02 15:19:11,289 [foster.py] => SNet: Task 8, Epoch 79/130 => Loss 28.498,  Loss1 0.721, Train_accy 76.67
2024-08-02 15:19:14,513 [foster.py] => SNet: Task 8, Epoch 80/130 => Loss 28.548,  Loss1 0.721, Train_accy 76.10
2024-08-02 15:19:18,837 [foster.py] => SNet: Task 8, Epoch 81/130 => Loss 28.524,  Loss1 0.721, Train_accy 75.70, Test_accy 72.09
2024-08-02 15:19:22,066 [foster.py] => SNet: Task 8, Epoch 82/130 => Loss 28.545,  Loss1 0.720, Train_accy 76.93
2024-08-02 15:19:25,299 [foster.py] => SNet: Task 8, Epoch 83/130 => Loss 28.520,  Loss1 0.721, Train_accy 76.71
2024-08-02 15:19:28,551 [foster.py] => SNet: Task 8, Epoch 84/130 => Loss 28.532,  Loss1 0.721, Train_accy 75.53
2024-08-02 15:19:31,794 [foster.py] => SNet: Task 8, Epoch 85/130 => Loss 28.550,  Loss1 0.720, Train_accy 76.71
2024-08-02 15:19:36,074 [foster.py] => SNet: Task 8, Epoch 86/130 => Loss 28.585,  Loss1 0.720, Train_accy 76.23, Test_accy 72.20
2024-08-02 15:19:39,324 [foster.py] => SNet: Task 8, Epoch 87/130 => Loss 28.520,  Loss1 0.721, Train_accy 75.39
2024-08-02 15:19:42,578 [foster.py] => SNet: Task 8, Epoch 88/130 => Loss 28.538,  Loss1 0.720, Train_accy 76.23
2024-08-02 15:19:45,876 [foster.py] => SNet: Task 8, Epoch 89/130 => Loss 28.534,  Loss1 0.721, Train_accy 76.32
2024-08-02 15:19:49,115 [foster.py] => SNet: Task 8, Epoch 90/130 => Loss 28.544,  Loss1 0.720, Train_accy 76.80
2024-08-02 15:19:53,383 [foster.py] => SNet: Task 8, Epoch 91/130 => Loss 28.572,  Loss1 0.721, Train_accy 76.40, Test_accy 72.32
2024-08-02 15:19:56,617 [foster.py] => SNet: Task 8, Epoch 92/130 => Loss 28.540,  Loss1 0.721, Train_accy 75.04
2024-08-02 15:19:59,867 [foster.py] => SNet: Task 8, Epoch 93/130 => Loss 28.524,  Loss1 0.720, Train_accy 76.89
2024-08-02 15:20:03,119 [foster.py] => SNet: Task 8, Epoch 94/130 => Loss 28.536,  Loss1 0.721, Train_accy 76.14
2024-08-02 15:20:06,386 [foster.py] => SNet: Task 8, Epoch 95/130 => Loss 28.505,  Loss1 0.720, Train_accy 75.48
2024-08-02 15:20:10,672 [foster.py] => SNet: Task 8, Epoch 96/130 => Loss 28.536,  Loss1 0.721, Train_accy 75.88, Test_accy 72.32
2024-08-02 15:20:13,940 [foster.py] => SNet: Task 8, Epoch 97/130 => Loss 28.512,  Loss1 0.720, Train_accy 75.75
2024-08-02 15:20:17,175 [foster.py] => SNet: Task 8, Epoch 98/130 => Loss 28.530,  Loss1 0.720, Train_accy 75.75
2024-08-02 15:20:20,438 [foster.py] => SNet: Task 8, Epoch 99/130 => Loss 28.547,  Loss1 0.720, Train_accy 76.14
2024-08-02 15:20:23,670 [foster.py] => SNet: Task 8, Epoch 100/130 => Loss 28.506,  Loss1 0.721, Train_accy 77.19
2024-08-02 15:20:27,944 [foster.py] => SNet: Task 8, Epoch 101/130 => Loss 28.536,  Loss1 0.720, Train_accy 76.67, Test_accy 72.02
2024-08-02 15:20:31,209 [foster.py] => SNet: Task 8, Epoch 102/130 => Loss 28.473,  Loss1 0.720, Train_accy 77.89
2024-08-02 15:20:34,488 [foster.py] => SNet: Task 8, Epoch 103/130 => Loss 28.543,  Loss1 0.721, Train_accy 76.71
2024-08-02 15:20:37,716 [foster.py] => SNet: Task 8, Epoch 104/130 => Loss 28.538,  Loss1 0.720, Train_accy 78.11
2024-08-02 15:20:40,953 [foster.py] => SNet: Task 8, Epoch 105/130 => Loss 28.541,  Loss1 0.721, Train_accy 75.92
2024-08-02 15:20:45,224 [foster.py] => SNet: Task 8, Epoch 106/130 => Loss 28.511,  Loss1 0.721, Train_accy 76.45, Test_accy 72.14
2024-08-02 15:20:48,505 [foster.py] => SNet: Task 8, Epoch 107/130 => Loss 28.526,  Loss1 0.721, Train_accy 75.83
2024-08-02 15:20:51,754 [foster.py] => SNet: Task 8, Epoch 108/130 => Loss 28.532,  Loss1 0.721, Train_accy 75.61
2024-08-02 15:20:55,101 [foster.py] => SNet: Task 8, Epoch 109/130 => Loss 28.548,  Loss1 0.721, Train_accy 76.14
2024-08-02 15:20:58,350 [foster.py] => SNet: Task 8, Epoch 110/130 => Loss 28.548,  Loss1 0.720, Train_accy 76.23
2024-08-02 15:21:02,597 [foster.py] => SNet: Task 8, Epoch 111/130 => Loss 28.558,  Loss1 0.721, Train_accy 76.32, Test_accy 72.18
2024-08-02 15:21:05,842 [foster.py] => SNet: Task 8, Epoch 112/130 => Loss 28.515,  Loss1 0.720, Train_accy 75.88
2024-08-02 15:21:09,097 [foster.py] => SNet: Task 8, Epoch 113/130 => Loss 28.528,  Loss1 0.721, Train_accy 76.45
2024-08-02 15:21:12,352 [foster.py] => SNet: Task 8, Epoch 114/130 => Loss 28.524,  Loss1 0.721, Train_accy 76.58
2024-08-02 15:21:15,581 [foster.py] => SNet: Task 8, Epoch 115/130 => Loss 28.553,  Loss1 0.721, Train_accy 76.14
2024-08-02 15:21:19,836 [foster.py] => SNet: Task 8, Epoch 116/130 => Loss 28.491,  Loss1 0.721, Train_accy 77.46, Test_accy 72.17
2024-08-02 15:21:23,105 [foster.py] => SNet: Task 8, Epoch 117/130 => Loss 28.466,  Loss1 0.721, Train_accy 77.46
2024-08-02 15:21:26,343 [foster.py] => SNet: Task 8, Epoch 118/130 => Loss 28.493,  Loss1 0.720, Train_accy 77.19
2024-08-02 15:21:29,583 [foster.py] => SNet: Task 8, Epoch 119/130 => Loss 28.552,  Loss1 0.721, Train_accy 75.75
2024-08-02 15:21:32,828 [foster.py] => SNet: Task 8, Epoch 120/130 => Loss 28.517,  Loss1 0.721, Train_accy 76.27
2024-08-02 15:21:37,078 [foster.py] => SNet: Task 8, Epoch 121/130 => Loss 28.556,  Loss1 0.721, Train_accy 76.23, Test_accy 72.35
2024-08-02 15:21:40,347 [foster.py] => SNet: Task 8, Epoch 122/130 => Loss 28.537,  Loss1 0.721, Train_accy 76.58
2024-08-02 15:21:43,601 [foster.py] => SNet: Task 8, Epoch 123/130 => Loss 28.534,  Loss1 0.720, Train_accy 75.96
2024-08-02 15:21:46,843 [foster.py] => SNet: Task 8, Epoch 124/130 => Loss 28.501,  Loss1 0.721, Train_accy 75.57
2024-08-02 15:21:50,080 [foster.py] => SNet: Task 8, Epoch 125/130 => Loss 28.533,  Loss1 0.721, Train_accy 77.50
2024-08-02 15:21:54,344 [foster.py] => SNet: Task 8, Epoch 126/130 => Loss 28.509,  Loss1 0.721, Train_accy 75.39, Test_accy 72.20
2024-08-02 15:21:57,598 [foster.py] => SNet: Task 8, Epoch 127/130 => Loss 28.524,  Loss1 0.721, Train_accy 76.93
2024-08-02 15:22:00,840 [foster.py] => SNet: Task 8, Epoch 128/130 => Loss 28.546,  Loss1 0.721, Train_accy 75.13
2024-08-02 15:22:04,144 [foster.py] => SNet: Task 8, Epoch 129/130 => Loss 28.524,  Loss1 0.720, Train_accy 74.96
2024-08-02 15:22:07,374 [foster.py] => SNet: Task 8, Epoch 130/130 => Loss 28.536,  Loss1 0.721, Train_accy 76.27
2024-08-02 15:22:07,376 [foster.py] => do not weight align student!
2024-08-02 15:22:08,426 [foster.py] => darknet eval: 
2024-08-02 15:22:08,427 [foster.py] => CNN top1 curve: 72.26
2024-08-02 15:22:08,430 [foster.py] => CNN top5 curve: 92.85
2024-08-02 15:22:08,430 [foster.py] => CNN top1 平均值: 72.26
2024-08-02 15:22:08,434 [foster.py] => timees : 1067.7000670433044
2024-08-02 15:22:08,436 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 15:22:28,635 [foster.py] => Exemplar size: 1320
2024-08-02 15:22:28,635 [trainer.py] => CNN: {'total': 73.08, '00-09': 79.5, '10-19': 67.8, '20-29': 78.6, '30-39': 73.8, '40-49': 78.8, '50-59': 63.2, '60-69': 67.67, 'old': 72.86, 'new': 80.0}
2024-08-02 15:22:28,635 [trainer.py] => NME: {'total': 69.15, '00-09': 73.6, '10-19': 59.1, '20-29': 75.3, '30-39': 68.3, '40-49': 72.8, '50-59': 68.3, '60-69': 65.0, 'old': 68.45, 'new': 91.5}
2024-08-02 15:22:28,636 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08]
2024-08-02 15:22:28,636 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38]
2024-08-02 15:22:28,636 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15]
2024-08-02 15:22:28,636 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65]

2024-08-02 15:22:28,636 [trainer.py] => CNN top1 平均值: 77.33
2024-08-02 15:22:28,638 [trainer.py] => All params: 1171512
2024-08-02 15:22:28,641 [trainer.py] => Trainable params: 590078
2024-08-02 15:22:28,701 [foster.py] => Learning on 66-68
2024-08-02 15:22:28,705 [foster.py] => All params: 1172030
2024-08-02 15:22:28,707 [foster.py] => Trainable params: 590466
2024-08-02 15:22:28,745 [foster.py] => per cls weights : [1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984 1.01349984
 0.55450512 0.55450512]
2024-08-02 15:22:31,334 [foster.py] => Task 9, Epoch 1/170 => Loss 5.244, Loss_clf 1.068, Loss_fe 1.653, Loss_kd 2.447, Train_accy 66.08
2024-08-02 15:22:35,418 [foster.py] => Task 9, Epoch 2/170 => Loss 3.912, Loss_clf 0.560, Loss_fe 0.806, Loss_kd 2.469, Train_accy 77.54, Test_accy 70.82
2024-08-02 15:22:39,500 [foster.py] => Task 9, Epoch 3/170 => Loss 3.683, Loss_clf 0.517, Loss_fe 0.614, Loss_kd 2.475, Train_accy 73.58, Test_accy 71.40
2024-08-02 15:22:43,628 [foster.py] => Task 9, Epoch 4/170 => Loss 3.504, Loss_clf 0.453, Loss_fe 0.544, Loss_kd 2.431, Train_accy 76.94, Test_accy 71.46
2024-08-02 15:22:47,677 [foster.py] => Task 9, Epoch 5/170 => Loss 3.466, Loss_clf 0.454, Loss_fe 0.491, Loss_kd 2.445, Train_accy 76.03, Test_accy 71.44
2024-08-02 15:22:50,139 [foster.py] => Task 9, Epoch 6/170 => Loss 3.420, Loss_clf 0.444, Loss_fe 0.460, Loss_kd 2.441, Train_accy 77.24
2024-08-02 15:22:54,225 [foster.py] => Task 9, Epoch 7/170 => Loss 3.382, Loss_clf 0.425, Loss_fe 0.439, Loss_kd 2.442, Train_accy 78.36, Test_accy 71.76
2024-08-02 15:22:58,345 [foster.py] => Task 9, Epoch 8/170 => Loss 3.381, Loss_clf 0.430, Loss_fe 0.424, Loss_kd 2.450, Train_accy 78.49, Test_accy 71.47
2024-08-02 15:23:02,466 [foster.py] => Task 9, Epoch 9/170 => Loss 3.437, Loss_clf 0.450, Loss_fe 0.456, Loss_kd 2.455, Train_accy 77.37, Test_accy 71.90
2024-08-02 15:23:06,551 [foster.py] => Task 9, Epoch 10/170 => Loss 3.374, Loss_clf 0.426, Loss_fe 0.448, Loss_kd 2.426, Train_accy 76.90, Test_accy 71.97
2024-08-02 15:23:09,009 [foster.py] => Task 9, Epoch 11/170 => Loss 3.380, Loss_clf 0.440, Loss_fe 0.416, Loss_kd 2.448, Train_accy 78.32
2024-08-02 15:23:13,097 [foster.py] => Task 9, Epoch 12/170 => Loss 3.419, Loss_clf 0.445, Loss_fe 0.434, Loss_kd 2.464, Train_accy 79.66, Test_accy 71.63
2024-08-02 15:23:17,205 [foster.py] => Task 9, Epoch 13/170 => Loss 3.315, Loss_clf 0.390, Loss_fe 0.405, Loss_kd 2.445, Train_accy 80.69, Test_accy 71.68
2024-08-02 15:23:21,412 [foster.py] => Task 9, Epoch 14/170 => Loss 3.381, Loss_clf 0.423, Loss_fe 0.433, Loss_kd 2.450, Train_accy 79.40, Test_accy 71.62
2024-08-02 15:23:25,596 [foster.py] => Task 9, Epoch 15/170 => Loss 3.340, Loss_clf 0.406, Loss_fe 0.386, Loss_kd 2.471, Train_accy 80.04, Test_accy 71.72
2024-08-02 15:23:28,098 [foster.py] => Task 9, Epoch 16/170 => Loss 3.296, Loss_clf 0.389, Loss_fe 0.389, Loss_kd 2.443, Train_accy 81.16
2024-08-02 15:23:32,231 [foster.py] => Task 9, Epoch 17/170 => Loss 3.276, Loss_clf 0.406, Loss_fe 0.375, Loss_kd 2.420, Train_accy 80.34, Test_accy 71.37
2024-08-02 15:23:36,315 [foster.py] => Task 9, Epoch 18/170 => Loss 3.316, Loss_clf 0.424, Loss_fe 0.369, Loss_kd 2.448, Train_accy 78.71, Test_accy 72.00
2024-08-02 15:23:40,378 [foster.py] => Task 9, Epoch 19/170 => Loss 3.216, Loss_clf 0.385, Loss_fe 0.332, Loss_kd 2.424, Train_accy 81.77, Test_accy 71.79
2024-08-02 15:23:44,460 [foster.py] => Task 9, Epoch 20/170 => Loss 3.304, Loss_clf 0.398, Loss_fe 0.360, Loss_kd 2.470, Train_accy 80.60, Test_accy 71.97
2024-08-02 15:23:46,895 [foster.py] => Task 9, Epoch 21/170 => Loss 3.316, Loss_clf 0.393, Loss_fe 0.374, Loss_kd 2.472, Train_accy 82.07
2024-08-02 15:23:50,981 [foster.py] => Task 9, Epoch 22/170 => Loss 3.398, Loss_clf 0.457, Loss_fe 0.388, Loss_kd 2.477, Train_accy 82.03, Test_accy 71.62
2024-08-02 15:23:55,046 [foster.py] => Task 9, Epoch 23/170 => Loss 3.355, Loss_clf 0.431, Loss_fe 0.427, Loss_kd 2.421, Train_accy 78.62, Test_accy 71.69
2024-08-02 15:23:59,155 [foster.py] => Task 9, Epoch 24/170 => Loss 3.379, Loss_clf 0.435, Loss_fe 0.361, Loss_kd 2.506, Train_accy 80.04, Test_accy 72.32
2024-08-02 15:24:03,267 [foster.py] => Task 9, Epoch 25/170 => Loss 3.254, Loss_clf 0.397, Loss_fe 0.353, Loss_kd 2.428, Train_accy 82.03, Test_accy 72.04
2024-08-02 15:24:05,747 [foster.py] => Task 9, Epoch 26/170 => Loss 3.337, Loss_clf 0.433, Loss_fe 0.345, Loss_kd 2.482, Train_accy 80.99
2024-08-02 15:24:09,866 [foster.py] => Task 9, Epoch 27/170 => Loss 3.284, Loss_clf 0.406, Loss_fe 0.339, Loss_kd 2.463, Train_accy 80.26, Test_accy 72.00
2024-08-02 15:24:13,981 [foster.py] => Task 9, Epoch 28/170 => Loss 3.232, Loss_clf 0.389, Loss_fe 0.311, Loss_kd 2.456, Train_accy 82.16, Test_accy 71.91
2024-08-02 15:24:18,081 [foster.py] => Task 9, Epoch 29/170 => Loss 3.164, Loss_clf 0.385, Loss_fe 0.286, Loss_kd 2.419, Train_accy 81.55, Test_accy 72.00
2024-08-02 15:24:22,171 [foster.py] => Task 9, Epoch 30/170 => Loss 3.239, Loss_clf 0.376, Loss_fe 0.315, Loss_kd 2.471, Train_accy 82.07, Test_accy 72.04
2024-08-02 15:24:24,620 [foster.py] => Task 9, Epoch 31/170 => Loss 3.180, Loss_clf 0.374, Loss_fe 0.313, Loss_kd 2.419, Train_accy 81.90
2024-08-02 15:24:28,704 [foster.py] => Task 9, Epoch 32/170 => Loss 3.184, Loss_clf 0.360, Loss_fe 0.266, Loss_kd 2.481, Train_accy 84.66, Test_accy 72.25
2024-08-02 15:24:32,789 [foster.py] => Task 9, Epoch 33/170 => Loss 3.268, Loss_clf 0.419, Loss_fe 0.296, Loss_kd 2.476, Train_accy 82.07, Test_accy 71.88
2024-08-02 15:24:36,886 [foster.py] => Task 9, Epoch 34/170 => Loss 3.244, Loss_clf 0.393, Loss_fe 0.324, Loss_kd 2.452, Train_accy 81.64, Test_accy 71.66
2024-08-02 15:24:40,957 [foster.py] => Task 9, Epoch 35/170 => Loss 3.220, Loss_clf 0.373, Loss_fe 0.324, Loss_kd 2.447, Train_accy 81.29, Test_accy 71.76
2024-08-02 15:24:43,518 [foster.py] => Task 9, Epoch 36/170 => Loss 3.292, Loss_clf 0.423, Loss_fe 0.316, Loss_kd 2.477, Train_accy 80.60
2024-08-02 15:24:47,633 [foster.py] => Task 9, Epoch 37/170 => Loss 3.283, Loss_clf 0.429, Loss_fe 0.310, Loss_kd 2.468, Train_accy 81.34, Test_accy 72.03
2024-08-02 15:24:51,782 [foster.py] => Task 9, Epoch 38/170 => Loss 3.190, Loss_clf 0.379, Loss_fe 0.298, Loss_kd 2.439, Train_accy 83.19, Test_accy 72.19
2024-08-02 15:24:55,858 [foster.py] => Task 9, Epoch 39/170 => Loss 3.185, Loss_clf 0.359, Loss_fe 0.287, Loss_kd 2.462, Train_accy 80.30, Test_accy 71.87
2024-08-02 15:25:00,004 [foster.py] => Task 9, Epoch 40/170 => Loss 3.103, Loss_clf 0.350, Loss_fe 0.268, Loss_kd 2.411, Train_accy 82.41, Test_accy 71.84
2024-08-02 15:25:02,475 [foster.py] => Task 9, Epoch 41/170 => Loss 3.081, Loss_clf 0.348, Loss_fe 0.225, Loss_kd 2.432, Train_accy 81.90
2024-08-02 15:25:06,584 [foster.py] => Task 9, Epoch 42/170 => Loss 3.147, Loss_clf 0.377, Loss_fe 0.257, Loss_kd 2.437, Train_accy 82.72, Test_accy 72.35
2024-08-02 15:25:10,660 [foster.py] => Task 9, Epoch 43/170 => Loss 3.149, Loss_clf 0.373, Loss_fe 0.267, Loss_kd 2.434, Train_accy 83.62, Test_accy 71.90
2024-08-02 15:25:14,838 [foster.py] => Task 9, Epoch 44/170 => Loss 3.125, Loss_clf 0.353, Loss_fe 0.243, Loss_kd 2.452, Train_accy 81.72, Test_accy 71.54
2024-08-02 15:25:18,907 [foster.py] => Task 9, Epoch 45/170 => Loss 3.142, Loss_clf 0.354, Loss_fe 0.234, Loss_kd 2.477, Train_accy 84.44, Test_accy 72.49
2024-08-02 15:25:21,363 [foster.py] => Task 9, Epoch 46/170 => Loss 3.084, Loss_clf 0.334, Loss_fe 0.248, Loss_kd 2.427, Train_accy 85.00
2024-08-02 15:25:25,514 [foster.py] => Task 9, Epoch 47/170 => Loss 3.142, Loss_clf 0.379, Loss_fe 0.259, Loss_kd 2.429, Train_accy 82.76, Test_accy 72.18
2024-08-02 15:25:29,599 [foster.py] => Task 9, Epoch 48/170 => Loss 3.076, Loss_clf 0.333, Loss_fe 0.229, Loss_kd 2.439, Train_accy 85.82, Test_accy 72.19
2024-08-02 15:25:33,755 [foster.py] => Task 9, Epoch 49/170 => Loss 3.171, Loss_clf 0.384, Loss_fe 0.250, Loss_kd 2.461, Train_accy 83.28, Test_accy 72.15
2024-08-02 15:25:37,874 [foster.py] => Task 9, Epoch 50/170 => Loss 3.037, Loss_clf 0.332, Loss_fe 0.207, Loss_kd 2.423, Train_accy 84.78, Test_accy 72.32
2024-08-02 15:25:40,329 [foster.py] => Task 9, Epoch 51/170 => Loss 3.059, Loss_clf 0.339, Loss_fe 0.215, Loss_kd 2.430, Train_accy 85.60
2024-08-02 15:25:44,486 [foster.py] => Task 9, Epoch 52/170 => Loss 3.063, Loss_clf 0.330, Loss_fe 0.228, Loss_kd 2.430, Train_accy 84.35, Test_accy 71.84
2024-08-02 15:25:48,557 [foster.py] => Task 9, Epoch 53/170 => Loss 3.104, Loss_clf 0.349, Loss_fe 0.237, Loss_kd 2.441, Train_accy 85.65, Test_accy 72.32
2024-08-02 15:25:52,629 [foster.py] => Task 9, Epoch 54/170 => Loss 3.065, Loss_clf 0.330, Loss_fe 0.230, Loss_kd 2.429, Train_accy 85.52, Test_accy 71.75
2024-08-02 15:25:56,760 [foster.py] => Task 9, Epoch 55/170 => Loss 3.212, Loss_clf 0.381, Loss_fe 0.277, Loss_kd 2.477, Train_accy 83.92, Test_accy 71.97
2024-08-02 15:25:59,275 [foster.py] => Task 9, Epoch 56/170 => Loss 3.212, Loss_clf 0.395, Loss_fe 0.281, Loss_kd 2.460, Train_accy 80.69
2024-08-02 15:26:03,394 [foster.py] => Task 9, Epoch 57/170 => Loss 3.249, Loss_clf 0.395, Loss_fe 0.328, Loss_kd 2.450, Train_accy 84.31, Test_accy 71.97
2024-08-02 15:26:07,465 [foster.py] => Task 9, Epoch 58/170 => Loss 3.189, Loss_clf 0.359, Loss_fe 0.286, Loss_kd 2.469, Train_accy 81.94, Test_accy 72.00
2024-08-02 15:26:11,593 [foster.py] => Task 9, Epoch 59/170 => Loss 3.169, Loss_clf 0.390, Loss_fe 0.253, Loss_kd 2.450, Train_accy 82.67, Test_accy 72.15
2024-08-02 15:26:15,708 [foster.py] => Task 9, Epoch 60/170 => Loss 3.130, Loss_clf 0.343, Loss_fe 0.243, Loss_kd 2.468, Train_accy 84.57, Test_accy 72.25
2024-08-02 15:26:18,186 [foster.py] => Task 9, Epoch 61/170 => Loss 3.067, Loss_clf 0.332, Loss_fe 0.217, Loss_kd 2.443, Train_accy 84.57
2024-08-02 15:26:22,292 [foster.py] => Task 9, Epoch 62/170 => Loss 3.086, Loss_clf 0.338, Loss_fe 0.226, Loss_kd 2.446, Train_accy 85.13, Test_accy 72.15
2024-08-02 15:26:26,394 [foster.py] => Task 9, Epoch 63/170 => Loss 3.042, Loss_clf 0.321, Loss_fe 0.210, Loss_kd 2.436, Train_accy 84.48, Test_accy 72.04
2024-08-02 15:26:30,517 [foster.py] => Task 9, Epoch 64/170 => Loss 3.125, Loss_clf 0.358, Loss_fe 0.230, Loss_kd 2.461, Train_accy 84.44, Test_accy 72.26
2024-08-02 15:26:34,633 [foster.py] => Task 9, Epoch 65/170 => Loss 3.070, Loss_clf 0.339, Loss_fe 0.211, Loss_kd 2.444, Train_accy 84.87, Test_accy 72.16
2024-08-02 15:26:37,201 [foster.py] => Task 9, Epoch 66/170 => Loss 3.102, Loss_clf 0.360, Loss_fe 0.225, Loss_kd 2.442, Train_accy 85.39
2024-08-02 15:26:41,405 [foster.py] => Task 9, Epoch 67/170 => Loss 3.065, Loss_clf 0.339, Loss_fe 0.196, Loss_kd 2.455, Train_accy 83.41, Test_accy 72.03
2024-08-02 15:26:45,697 [foster.py] => Task 9, Epoch 68/170 => Loss 3.028, Loss_clf 0.316, Loss_fe 0.192, Loss_kd 2.444, Train_accy 85.13, Test_accy 72.37
2024-08-02 15:26:49,932 [foster.py] => Task 9, Epoch 69/170 => Loss 3.130, Loss_clf 0.361, Loss_fe 0.211, Loss_kd 2.482, Train_accy 84.74, Test_accy 72.35
2024-08-02 15:26:54,027 [foster.py] => Task 9, Epoch 70/170 => Loss 3.023, Loss_clf 0.311, Loss_fe 0.195, Loss_kd 2.441, Train_accy 86.21, Test_accy 72.54
2024-08-02 15:26:56,496 [foster.py] => Task 9, Epoch 71/170 => Loss 3.058, Loss_clf 0.340, Loss_fe 0.204, Loss_kd 2.440, Train_accy 85.43
2024-08-02 15:27:00,623 [foster.py] => Task 9, Epoch 72/170 => Loss 2.974, Loss_clf 0.301, Loss_fe 0.177, Loss_kd 2.422, Train_accy 85.69, Test_accy 72.32
2024-08-02 15:27:04,680 [foster.py] => Task 9, Epoch 73/170 => Loss 3.098, Loss_clf 0.353, Loss_fe 0.187, Loss_kd 2.482, Train_accy 86.51, Test_accy 72.49
2024-08-02 15:27:08,771 [foster.py] => Task 9, Epoch 74/170 => Loss 2.977, Loss_clf 0.307, Loss_fe 0.170, Loss_kd 2.425, Train_accy 85.78, Test_accy 72.35
2024-08-02 15:27:12,847 [foster.py] => Task 9, Epoch 75/170 => Loss 3.003, Loss_clf 0.314, Loss_fe 0.184, Loss_kd 2.430, Train_accy 86.77, Test_accy 72.21
2024-08-02 15:27:15,305 [foster.py] => Task 9, Epoch 76/170 => Loss 3.028, Loss_clf 0.334, Loss_fe 0.169, Loss_kd 2.450, Train_accy 86.21
2024-08-02 15:27:19,423 [foster.py] => Task 9, Epoch 77/170 => Loss 3.010, Loss_clf 0.312, Loss_fe 0.178, Loss_kd 2.444, Train_accy 85.52, Test_accy 72.21
2024-08-02 15:27:23,512 [foster.py] => Task 9, Epoch 78/170 => Loss 2.997, Loss_clf 0.302, Loss_fe 0.169, Loss_kd 2.451, Train_accy 88.19, Test_accy 72.16
2024-08-02 15:27:27,598 [foster.py] => Task 9, Epoch 79/170 => Loss 3.062, Loss_clf 0.347, Loss_fe 0.162, Loss_kd 2.476, Train_accy 85.30, Test_accy 72.40
2024-08-02 15:27:31,709 [foster.py] => Task 9, Epoch 80/170 => Loss 3.061, Loss_clf 0.344, Loss_fe 0.195, Loss_kd 2.446, Train_accy 84.66, Test_accy 72.07
2024-08-02 15:27:34,292 [foster.py] => Task 9, Epoch 81/170 => Loss 3.146, Loss_clf 0.370, Loss_fe 0.222, Loss_kd 2.478, Train_accy 85.30
2024-08-02 15:27:38,379 [foster.py] => Task 9, Epoch 82/170 => Loss 3.072, Loss_clf 0.338, Loss_fe 0.207, Loss_kd 2.451, Train_accy 86.21, Test_accy 72.21
2024-08-02 15:27:42,465 [foster.py] => Task 9, Epoch 83/170 => Loss 3.019, Loss_clf 0.307, Loss_fe 0.187, Loss_kd 2.450, Train_accy 86.34, Test_accy 72.31
2024-08-02 15:27:46,602 [foster.py] => Task 9, Epoch 84/170 => Loss 2.962, Loss_clf 0.293, Loss_fe 0.172, Loss_kd 2.422, Train_accy 86.55, Test_accy 71.90
2024-08-02 15:27:50,724 [foster.py] => Task 9, Epoch 85/170 => Loss 3.000, Loss_clf 0.329, Loss_fe 0.168, Loss_kd 2.427, Train_accy 85.86, Test_accy 72.35
2024-08-02 15:27:53,184 [foster.py] => Task 9, Epoch 86/170 => Loss 3.002, Loss_clf 0.314, Loss_fe 0.163, Loss_kd 2.450, Train_accy 86.77
2024-08-02 15:27:57,281 [foster.py] => Task 9, Epoch 87/170 => Loss 3.060, Loss_clf 0.356, Loss_fe 0.170, Loss_kd 2.458, Train_accy 86.25, Test_accy 72.43
2024-08-02 15:28:01,377 [foster.py] => Task 9, Epoch 88/170 => Loss 3.067, Loss_clf 0.348, Loss_fe 0.179, Loss_kd 2.464, Train_accy 85.69, Test_accy 72.57
2024-08-02 15:28:05,460 [foster.py] => Task 9, Epoch 89/170 => Loss 2.978, Loss_clf 0.307, Loss_fe 0.147, Loss_kd 2.448, Train_accy 89.31, Test_accy 72.43
2024-08-02 15:28:09,549 [foster.py] => Task 9, Epoch 90/170 => Loss 3.098, Loss_clf 0.363, Loss_fe 0.184, Loss_kd 2.474, Train_accy 84.96, Test_accy 72.26
2024-08-02 15:28:12,018 [foster.py] => Task 9, Epoch 91/170 => Loss 3.030, Loss_clf 0.315, Loss_fe 0.187, Loss_kd 2.451, Train_accy 85.09
2024-08-02 15:28:16,130 [foster.py] => Task 9, Epoch 92/170 => Loss 3.029, Loss_clf 0.323, Loss_fe 0.182, Loss_kd 2.449, Train_accy 85.17, Test_accy 72.28
2024-08-02 15:28:20,209 [foster.py] => Task 9, Epoch 93/170 => Loss 3.019, Loss_clf 0.319, Loss_fe 0.172, Loss_kd 2.453, Train_accy 87.41, Test_accy 72.32
2024-08-02 15:28:24,318 [foster.py] => Task 9, Epoch 94/170 => Loss 3.072, Loss_clf 0.339, Loss_fe 0.202, Loss_kd 2.456, Train_accy 86.38, Test_accy 72.32
2024-08-02 15:28:28,429 [foster.py] => Task 9, Epoch 95/170 => Loss 2.979, Loss_clf 0.318, Loss_fe 0.186, Loss_kd 2.401, Train_accy 84.57, Test_accy 72.21
2024-08-02 15:28:30,881 [foster.py] => Task 9, Epoch 96/170 => Loss 3.025, Loss_clf 0.333, Loss_fe 0.184, Loss_kd 2.433, Train_accy 85.26
2024-08-02 15:28:34,972 [foster.py] => Task 9, Epoch 97/170 => Loss 2.963, Loss_clf 0.311, Loss_fe 0.151, Loss_kd 2.427, Train_accy 87.50, Test_accy 72.44
2024-08-02 15:28:39,045 [foster.py] => Task 9, Epoch 98/170 => Loss 2.943, Loss_clf 0.301, Loss_fe 0.147, Loss_kd 2.420, Train_accy 86.12, Test_accy 72.44
2024-08-02 15:28:43,169 [foster.py] => Task 9, Epoch 99/170 => Loss 2.982, Loss_clf 0.312, Loss_fe 0.149, Loss_kd 2.445, Train_accy 85.86, Test_accy 72.38
2024-08-02 15:28:47,257 [foster.py] => Task 9, Epoch 100/170 => Loss 2.882, Loss_clf 0.270, Loss_fe 0.112, Loss_kd 2.425, Train_accy 87.41, Test_accy 72.51
2024-08-02 15:28:49,714 [foster.py] => Task 9, Epoch 101/170 => Loss 2.955, Loss_clf 0.316, Loss_fe 0.124, Loss_kd 2.439, Train_accy 86.85
2024-08-02 15:28:53,828 [foster.py] => Task 9, Epoch 102/170 => Loss 2.981, Loss_clf 0.304, Loss_fe 0.145, Loss_kd 2.456, Train_accy 86.98, Test_accy 72.53
2024-08-02 15:28:57,960 [foster.py] => Task 9, Epoch 103/170 => Loss 2.912, Loss_clf 0.283, Loss_fe 0.131, Loss_kd 2.423, Train_accy 87.97, Test_accy 72.56
2024-08-02 15:29:02,032 [foster.py] => Task 9, Epoch 104/170 => Loss 2.972, Loss_clf 0.305, Loss_fe 0.139, Loss_kd 2.453, Train_accy 89.05, Test_accy 72.28
2024-08-02 15:29:06,134 [foster.py] => Task 9, Epoch 105/170 => Loss 3.002, Loss_clf 0.330, Loss_fe 0.156, Loss_kd 2.441, Train_accy 88.15, Test_accy 72.32
2024-08-02 15:29:08,637 [foster.py] => Task 9, Epoch 106/170 => Loss 2.944, Loss_clf 0.303, Loss_fe 0.141, Loss_kd 2.425, Train_accy 86.21
2024-08-02 15:29:12,741 [foster.py] => Task 9, Epoch 107/170 => Loss 2.948, Loss_clf 0.302, Loss_fe 0.124, Loss_kd 2.447, Train_accy 87.67, Test_accy 72.54
2024-08-02 15:29:16,843 [foster.py] => Task 9, Epoch 108/170 => Loss 2.949, Loss_clf 0.298, Loss_fe 0.135, Loss_kd 2.440, Train_accy 87.72, Test_accy 72.47
2024-08-02 15:29:20,936 [foster.py] => Task 9, Epoch 109/170 => Loss 2.971, Loss_clf 0.314, Loss_fe 0.137, Loss_kd 2.445, Train_accy 87.97, Test_accy 72.47
2024-08-02 15:29:25,083 [foster.py] => Task 9, Epoch 110/170 => Loss 3.019, Loss_clf 0.341, Loss_fe 0.142, Loss_kd 2.460, Train_accy 88.58, Test_accy 72.44
2024-08-02 15:29:27,557 [foster.py] => Task 9, Epoch 111/170 => Loss 3.006, Loss_clf 0.314, Loss_fe 0.141, Loss_kd 2.475, Train_accy 87.41
2024-08-02 15:29:31,675 [foster.py] => Task 9, Epoch 112/170 => Loss 2.972, Loss_clf 0.309, Loss_fe 0.128, Loss_kd 2.459, Train_accy 87.41, Test_accy 72.63
2024-08-02 15:29:35,739 [foster.py] => Task 9, Epoch 113/170 => Loss 2.924, Loss_clf 0.298, Loss_fe 0.133, Loss_kd 2.418, Train_accy 87.63, Test_accy 72.65
2024-08-02 15:29:39,835 [foster.py] => Task 9, Epoch 114/170 => Loss 2.981, Loss_clf 0.333, Loss_fe 0.114, Loss_kd 2.457, Train_accy 87.72, Test_accy 72.47
2024-08-02 15:29:43,953 [foster.py] => Task 9, Epoch 115/170 => Loss 3.005, Loss_clf 0.310, Loss_fe 0.154, Loss_kd 2.465, Train_accy 87.80, Test_accy 72.37
2024-08-02 15:29:46,402 [foster.py] => Task 9, Epoch 116/170 => Loss 3.001, Loss_clf 0.326, Loss_fe 0.136, Loss_kd 2.463, Train_accy 87.89
2024-08-02 15:29:50,578 [foster.py] => Task 9, Epoch 117/170 => Loss 2.979, Loss_clf 0.319, Loss_fe 0.128, Loss_kd 2.455, Train_accy 86.81, Test_accy 72.37
2024-08-02 15:29:54,676 [foster.py] => Task 9, Epoch 118/170 => Loss 2.914, Loss_clf 0.282, Loss_fe 0.126, Loss_kd 2.431, Train_accy 88.28, Test_accy 72.15
2024-08-02 15:29:58,785 [foster.py] => Task 9, Epoch 119/170 => Loss 3.009, Loss_clf 0.341, Loss_fe 0.142, Loss_kd 2.450, Train_accy 87.89, Test_accy 72.35
2024-08-02 15:30:03,003 [foster.py] => Task 9, Epoch 120/170 => Loss 2.977, Loss_clf 0.321, Loss_fe 0.137, Loss_kd 2.444, Train_accy 87.63, Test_accy 72.41
2024-08-02 15:30:05,469 [foster.py] => Task 9, Epoch 121/170 => Loss 2.917, Loss_clf 0.271, Loss_fe 0.115, Loss_kd 2.455, Train_accy 87.93
2024-08-02 15:30:09,560 [foster.py] => Task 9, Epoch 122/170 => Loss 2.972, Loss_clf 0.303, Loss_fe 0.126, Loss_kd 2.467, Train_accy 88.75, Test_accy 72.57
2024-08-02 15:30:13,613 [foster.py] => Task 9, Epoch 123/170 => Loss 2.914, Loss_clf 0.284, Loss_fe 0.127, Loss_kd 2.429, Train_accy 88.84, Test_accy 72.50
2024-08-02 15:30:17,738 [foster.py] => Task 9, Epoch 124/170 => Loss 2.947, Loss_clf 0.298, Loss_fe 0.117, Loss_kd 2.455, Train_accy 88.15, Test_accy 72.47
2024-08-02 15:30:21,907 [foster.py] => Task 9, Epoch 125/170 => Loss 2.883, Loss_clf 0.263, Loss_fe 0.109, Loss_kd 2.435, Train_accy 89.27, Test_accy 72.38
2024-08-02 15:30:24,449 [foster.py] => Task 9, Epoch 126/170 => Loss 2.911, Loss_clf 0.286, Loss_fe 0.111, Loss_kd 2.439, Train_accy 88.58
2024-08-02 15:30:28,522 [foster.py] => Task 9, Epoch 127/170 => Loss 2.991, Loss_clf 0.311, Loss_fe 0.118, Loss_kd 2.485, Train_accy 87.24, Test_accy 72.65
2024-08-02 15:30:32,624 [foster.py] => Task 9, Epoch 128/170 => Loss 2.947, Loss_clf 0.296, Loss_fe 0.128, Loss_kd 2.447, Train_accy 88.84, Test_accy 72.46
2024-08-02 15:30:36,706 [foster.py] => Task 9, Epoch 129/170 => Loss 2.926, Loss_clf 0.297, Loss_fe 0.118, Loss_kd 2.435, Train_accy 88.71, Test_accy 72.47
2024-08-02 15:30:40,816 [foster.py] => Task 9, Epoch 130/170 => Loss 2.892, Loss_clf 0.272, Loss_fe 0.107, Loss_kd 2.439, Train_accy 89.57, Test_accy 72.54
2024-08-02 15:30:43,261 [foster.py] => Task 9, Epoch 131/170 => Loss 2.944, Loss_clf 0.320, Loss_fe 0.108, Loss_kd 2.441, Train_accy 86.68
2024-08-02 15:30:47,349 [foster.py] => Task 9, Epoch 132/170 => Loss 2.954, Loss_clf 0.306, Loss_fe 0.103, Loss_kd 2.469, Train_accy 88.41, Test_accy 72.68
2024-08-02 15:30:51,434 [foster.py] => Task 9, Epoch 133/170 => Loss 2.974, Loss_clf 0.328, Loss_fe 0.111, Loss_kd 2.459, Train_accy 88.19, Test_accy 72.68
2024-08-02 15:30:55,564 [foster.py] => Task 9, Epoch 134/170 => Loss 2.966, Loss_clf 0.317, Loss_fe 0.110, Loss_kd 2.464, Train_accy 87.80, Test_accy 72.72
2024-08-02 15:30:59,702 [foster.py] => Task 9, Epoch 135/170 => Loss 2.939, Loss_clf 0.293, Loss_fe 0.114, Loss_kd 2.456, Train_accy 88.10, Test_accy 72.78
2024-08-02 15:31:02,154 [foster.py] => Task 9, Epoch 136/170 => Loss 2.913, Loss_clf 0.296, Loss_fe 0.112, Loss_kd 2.430, Train_accy 87.93
2024-08-02 15:31:06,225 [foster.py] => Task 9, Epoch 137/170 => Loss 2.890, Loss_clf 0.293, Loss_fe 0.093, Loss_kd 2.429, Train_accy 88.88, Test_accy 72.72
2024-08-02 15:31:10,333 [foster.py] => Task 9, Epoch 138/170 => Loss 2.905, Loss_clf 0.284, Loss_fe 0.116, Loss_kd 2.430, Train_accy 88.97, Test_accy 72.72
2024-08-02 15:31:14,390 [foster.py] => Task 9, Epoch 139/170 => Loss 2.920, Loss_clf 0.304, Loss_fe 0.108, Loss_kd 2.433, Train_accy 88.15, Test_accy 72.69
2024-08-02 15:31:18,506 [foster.py] => Task 9, Epoch 140/170 => Loss 2.915, Loss_clf 0.288, Loss_fe 0.118, Loss_kd 2.434, Train_accy 89.01, Test_accy 72.74
2024-08-02 15:31:20,941 [foster.py] => Task 9, Epoch 141/170 => Loss 2.957, Loss_clf 0.322, Loss_fe 0.100, Loss_kd 2.459, Train_accy 88.62
2024-08-02 15:31:25,045 [foster.py] => Task 9, Epoch 142/170 => Loss 2.982, Loss_clf 0.322, Loss_fe 0.118, Loss_kd 2.466, Train_accy 88.23, Test_accy 72.57
2024-08-02 15:31:29,137 [foster.py] => Task 9, Epoch 143/170 => Loss 2.946, Loss_clf 0.288, Loss_fe 0.110, Loss_kd 2.472, Train_accy 89.31, Test_accy 72.65
2024-08-02 15:31:33,260 [foster.py] => Task 9, Epoch 144/170 => Loss 2.884, Loss_clf 0.275, Loss_fe 0.094, Loss_kd 2.441, Train_accy 88.97, Test_accy 72.60
2024-08-02 15:31:37,347 [foster.py] => Task 9, Epoch 145/170 => Loss 2.985, Loss_clf 0.306, Loss_fe 0.121, Loss_kd 2.480, Train_accy 88.45, Test_accy 72.65
2024-08-02 15:31:39,859 [foster.py] => Task 9, Epoch 146/170 => Loss 2.877, Loss_clf 0.265, Loss_fe 0.119, Loss_kd 2.419, Train_accy 89.48
2024-08-02 15:31:43,971 [foster.py] => Task 9, Epoch 147/170 => Loss 2.950, Loss_clf 0.302, Loss_fe 0.113, Loss_kd 2.459, Train_accy 89.18, Test_accy 72.69
2024-08-02 15:31:48,183 [foster.py] => Task 9, Epoch 148/170 => Loss 2.969, Loss_clf 0.319, Loss_fe 0.127, Loss_kd 2.448, Train_accy 89.35, Test_accy 72.78
2024-08-02 15:31:52,322 [foster.py] => Task 9, Epoch 149/170 => Loss 2.901, Loss_clf 0.264, Loss_fe 0.103, Loss_kd 2.459, Train_accy 89.22, Test_accy 72.68
2024-08-02 15:31:56,436 [foster.py] => Task 9, Epoch 150/170 => Loss 2.865, Loss_clf 0.266, Loss_fe 0.101, Loss_kd 2.424, Train_accy 89.40, Test_accy 72.74
2024-08-02 15:31:58,940 [foster.py] => Task 9, Epoch 151/170 => Loss 2.909, Loss_clf 0.283, Loss_fe 0.118, Loss_kd 2.433, Train_accy 89.09
2024-08-02 15:32:03,026 [foster.py] => Task 9, Epoch 152/170 => Loss 2.960, Loss_clf 0.306, Loss_fe 0.122, Loss_kd 2.457, Train_accy 89.78, Test_accy 72.72
2024-08-02 15:32:07,138 [foster.py] => Task 9, Epoch 153/170 => Loss 3.012, Loss_clf 0.330, Loss_fe 0.141, Loss_kd 2.465, Train_accy 88.88, Test_accy 72.75
2024-08-02 15:32:11,209 [foster.py] => Task 9, Epoch 154/170 => Loss 2.948, Loss_clf 0.296, Loss_fe 0.093, Loss_kd 2.482, Train_accy 89.27, Test_accy 72.75
2024-08-02 15:32:15,273 [foster.py] => Task 9, Epoch 155/170 => Loss 2.924, Loss_clf 0.289, Loss_fe 0.101, Loss_kd 2.457, Train_accy 89.22, Test_accy 72.75
2024-08-02 15:32:17,742 [foster.py] => Task 9, Epoch 156/170 => Loss 2.961, Loss_clf 0.305, Loss_fe 0.121, Loss_kd 2.458, Train_accy 87.63
2024-08-02 15:32:21,822 [foster.py] => Task 9, Epoch 157/170 => Loss 2.970, Loss_clf 0.309, Loss_fe 0.111, Loss_kd 2.474, Train_accy 87.59, Test_accy 72.74
2024-08-02 15:32:25,936 [foster.py] => Task 9, Epoch 158/170 => Loss 2.899, Loss_clf 0.267, Loss_fe 0.094, Loss_kd 2.462, Train_accy 89.05, Test_accy 72.78
2024-08-02 15:32:30,011 [foster.py] => Task 9, Epoch 159/170 => Loss 2.868, Loss_clf 0.264, Loss_fe 0.108, Loss_kd 2.420, Train_accy 88.53, Test_accy 72.79
2024-08-02 15:32:34,107 [foster.py] => Task 9, Epoch 160/170 => Loss 2.919, Loss_clf 0.288, Loss_fe 0.105, Loss_kd 2.450, Train_accy 88.58, Test_accy 72.74
2024-08-02 15:32:36,573 [foster.py] => Task 9, Epoch 161/170 => Loss 2.891, Loss_clf 0.279, Loss_fe 0.094, Loss_kd 2.442, Train_accy 89.14
2024-08-02 15:32:40,692 [foster.py] => Task 9, Epoch 162/170 => Loss 2.975, Loss_clf 0.305, Loss_fe 0.144, Loss_kd 2.450, Train_accy 89.78, Test_accy 72.71
2024-08-02 15:32:44,790 [foster.py] => Task 9, Epoch 163/170 => Loss 2.939, Loss_clf 0.289, Loss_fe 0.108, Loss_kd 2.466, Train_accy 88.06, Test_accy 72.75
2024-08-02 15:32:48,896 [foster.py] => Task 9, Epoch 164/170 => Loss 2.941, Loss_clf 0.293, Loss_fe 0.114, Loss_kd 2.459, Train_accy 88.28, Test_accy 72.81
2024-08-02 15:32:52,990 [foster.py] => Task 9, Epoch 165/170 => Loss 2.923, Loss_clf 0.272, Loss_fe 0.103, Loss_kd 2.472, Train_accy 88.97, Test_accy 72.69
2024-08-02 15:32:55,466 [foster.py] => Task 9, Epoch 166/170 => Loss 2.866, Loss_clf 0.264, Loss_fe 0.092, Loss_kd 2.436, Train_accy 89.74
2024-08-02 15:32:59,567 [foster.py] => Task 9, Epoch 167/170 => Loss 2.888, Loss_clf 0.279, Loss_fe 0.093, Loss_kd 2.441, Train_accy 90.22, Test_accy 72.78
2024-08-02 15:33:03,699 [foster.py] => Task 9, Epoch 168/170 => Loss 2.890, Loss_clf 0.270, Loss_fe 0.094, Loss_kd 2.450, Train_accy 88.84, Test_accy 72.78
2024-08-02 15:33:07,770 [foster.py] => Task 9, Epoch 169/170 => Loss 2.913, Loss_clf 0.284, Loss_fe 0.089, Loss_kd 2.463, Train_accy 88.58, Test_accy 72.74
2024-08-02 15:33:11,833 [foster.py] => Task 9, Epoch 170/170 => Loss 2.886, Loss_clf 0.271, Loss_fe 0.086, Loss_kd 2.453, Train_accy 88.97, Test_accy 72.79
2024-08-02 15:33:11,837 [foster.py] => do not weight align teacher!
2024-08-02 15:33:11,840 [foster.py] => per cls weights : [1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916 1.01603916
 0.47070762 0.47070762]
2024-08-02 15:33:16,508 [foster.py] => SNet: Task 9, Epoch 1/130 => Loss 28.854,  Loss1 0.722, Train_accy 50.86, Test_accy 69.15
2024-08-02 15:33:19,885 [foster.py] => SNet: Task 9, Epoch 2/130 => Loss 28.804,  Loss1 0.722, Train_accy 62.89
2024-08-02 15:33:23,273 [foster.py] => SNet: Task 9, Epoch 3/130 => Loss 28.748,  Loss1 0.721, Train_accy 63.45
2024-08-02 15:33:26,673 [foster.py] => SNet: Task 9, Epoch 4/130 => Loss 28.759,  Loss1 0.722, Train_accy 65.26
2024-08-02 15:33:30,075 [foster.py] => SNet: Task 9, Epoch 5/130 => Loss 28.782,  Loss1 0.721, Train_accy 66.85
2024-08-02 15:33:34,488 [foster.py] => SNet: Task 9, Epoch 6/130 => Loss 28.799,  Loss1 0.722, Train_accy 69.87, Test_accy 70.04
2024-08-02 15:33:37,866 [foster.py] => SNet: Task 9, Epoch 7/130 => Loss 28.723,  Loss1 0.722, Train_accy 69.70
2024-08-02 15:33:41,265 [foster.py] => SNet: Task 9, Epoch 8/130 => Loss 28.710,  Loss1 0.722, Train_accy 71.08
2024-08-02 15:33:44,639 [foster.py] => SNet: Task 9, Epoch 9/130 => Loss 28.682,  Loss1 0.722, Train_accy 71.59
2024-08-02 15:33:48,007 [foster.py] => SNet: Task 9, Epoch 10/130 => Loss 28.746,  Loss1 0.721, Train_accy 72.89
2024-08-02 15:33:52,455 [foster.py] => SNet: Task 9, Epoch 11/130 => Loss 28.683,  Loss1 0.722, Train_accy 73.23, Test_accy 70.54
2024-08-02 15:33:55,834 [foster.py] => SNet: Task 9, Epoch 12/130 => Loss 28.749,  Loss1 0.722, Train_accy 72.84
2024-08-02 15:33:59,253 [foster.py] => SNet: Task 9, Epoch 13/130 => Loss 28.690,  Loss1 0.721, Train_accy 73.49
2024-08-02 15:34:02,634 [foster.py] => SNet: Task 9, Epoch 14/130 => Loss 28.745,  Loss1 0.722, Train_accy 72.24
2024-08-02 15:34:06,022 [foster.py] => SNet: Task 9, Epoch 15/130 => Loss 28.654,  Loss1 0.721, Train_accy 73.79
2024-08-02 15:34:10,451 [foster.py] => SNet: Task 9, Epoch 16/130 => Loss 28.715,  Loss1 0.722, Train_accy 73.75, Test_accy 70.79
2024-08-02 15:34:13,864 [foster.py] => SNet: Task 9, Epoch 17/130 => Loss 28.759,  Loss1 0.721, Train_accy 72.97
2024-08-02 15:34:17,243 [foster.py] => SNet: Task 9, Epoch 18/130 => Loss 28.748,  Loss1 0.720, Train_accy 73.49
2024-08-02 15:34:20,612 [foster.py] => SNet: Task 9, Epoch 19/130 => Loss 28.740,  Loss1 0.721, Train_accy 74.14
2024-08-02 15:34:24,009 [foster.py] => SNet: Task 9, Epoch 20/130 => Loss 28.757,  Loss1 0.721, Train_accy 76.34
2024-08-02 15:34:28,442 [foster.py] => SNet: Task 9, Epoch 21/130 => Loss 28.737,  Loss1 0.721, Train_accy 72.37, Test_accy 70.37
2024-08-02 15:34:31,802 [foster.py] => SNet: Task 9, Epoch 22/130 => Loss 28.707,  Loss1 0.721, Train_accy 73.23
2024-08-02 15:34:35,189 [foster.py] => SNet: Task 9, Epoch 23/130 => Loss 28.753,  Loss1 0.722, Train_accy 74.27
2024-08-02 15:34:38,583 [foster.py] => SNet: Task 9, Epoch 24/130 => Loss 28.750,  Loss1 0.722, Train_accy 74.57
2024-08-02 15:34:42,009 [foster.py] => SNet: Task 9, Epoch 25/130 => Loss 28.765,  Loss1 0.721, Train_accy 73.71
2024-08-02 15:34:46,478 [foster.py] => SNet: Task 9, Epoch 26/130 => Loss 28.669,  Loss1 0.721, Train_accy 73.88, Test_accy 70.75
2024-08-02 15:34:49,838 [foster.py] => SNet: Task 9, Epoch 27/130 => Loss 28.738,  Loss1 0.721, Train_accy 76.08
2024-08-02 15:34:53,236 [foster.py] => SNet: Task 9, Epoch 28/130 => Loss 28.711,  Loss1 0.722, Train_accy 72.03
2024-08-02 15:34:56,623 [foster.py] => SNet: Task 9, Epoch 29/130 => Loss 28.649,  Loss1 0.722, Train_accy 75.00
2024-08-02 15:35:00,014 [foster.py] => SNet: Task 9, Epoch 30/130 => Loss 28.743,  Loss1 0.721, Train_accy 75.47
2024-08-02 15:35:04,455 [foster.py] => SNet: Task 9, Epoch 31/130 => Loss 28.697,  Loss1 0.721, Train_accy 75.52, Test_accy 71.06
2024-08-02 15:35:07,895 [foster.py] => SNet: Task 9, Epoch 32/130 => Loss 28.758,  Loss1 0.721, Train_accy 75.52
2024-08-02 15:35:11,266 [foster.py] => SNet: Task 9, Epoch 33/130 => Loss 28.693,  Loss1 0.721, Train_accy 75.69
2024-08-02 15:35:14,661 [foster.py] => SNet: Task 9, Epoch 34/130 => Loss 28.691,  Loss1 0.721, Train_accy 75.43
2024-08-02 15:35:18,025 [foster.py] => SNet: Task 9, Epoch 35/130 => Loss 28.739,  Loss1 0.721, Train_accy 73.71
2024-08-02 15:35:22,430 [foster.py] => SNet: Task 9, Epoch 36/130 => Loss 28.656,  Loss1 0.721, Train_accy 76.59, Test_accy 71.24
2024-08-02 15:35:25,831 [foster.py] => SNet: Task 9, Epoch 37/130 => Loss 28.690,  Loss1 0.721, Train_accy 75.91
2024-08-02 15:35:29,187 [foster.py] => SNet: Task 9, Epoch 38/130 => Loss 28.759,  Loss1 0.721, Train_accy 76.47
2024-08-02 15:35:32,587 [foster.py] => SNet: Task 9, Epoch 39/130 => Loss 28.699,  Loss1 0.721, Train_accy 75.39
2024-08-02 15:35:35,951 [foster.py] => SNet: Task 9, Epoch 40/130 => Loss 28.731,  Loss1 0.722, Train_accy 75.86
2024-08-02 15:35:40,376 [foster.py] => SNet: Task 9, Epoch 41/130 => Loss 28.750,  Loss1 0.722, Train_accy 75.60, Test_accy 71.04
2024-08-02 15:35:43,748 [foster.py] => SNet: Task 9, Epoch 42/130 => Loss 28.718,  Loss1 0.721, Train_accy 75.82
2024-08-02 15:35:47,126 [foster.py] => SNet: Task 9, Epoch 43/130 => Loss 28.742,  Loss1 0.722, Train_accy 75.26
2024-08-02 15:35:50,532 [foster.py] => SNet: Task 9, Epoch 44/130 => Loss 28.737,  Loss1 0.721, Train_accy 75.82
2024-08-02 15:35:53,896 [foster.py] => SNet: Task 9, Epoch 45/130 => Loss 28.718,  Loss1 0.721, Train_accy 75.95
2024-08-02 15:35:58,321 [foster.py] => SNet: Task 9, Epoch 46/130 => Loss 28.754,  Loss1 0.722, Train_accy 76.81, Test_accy 70.96
2024-08-02 15:36:01,719 [foster.py] => SNet: Task 9, Epoch 47/130 => Loss 28.689,  Loss1 0.721, Train_accy 75.78
2024-08-02 15:36:05,079 [foster.py] => SNet: Task 9, Epoch 48/130 => Loss 28.698,  Loss1 0.721, Train_accy 75.13
2024-08-02 15:36:08,455 [foster.py] => SNet: Task 9, Epoch 49/130 => Loss 28.699,  Loss1 0.721, Train_accy 77.80
2024-08-02 15:36:11,849 [foster.py] => SNet: Task 9, Epoch 50/130 => Loss 28.702,  Loss1 0.721, Train_accy 77.33
2024-08-02 15:36:16,318 [foster.py] => SNet: Task 9, Epoch 51/130 => Loss 28.724,  Loss1 0.721, Train_accy 75.86, Test_accy 70.94
2024-08-02 15:36:19,676 [foster.py] => SNet: Task 9, Epoch 52/130 => Loss 28.723,  Loss1 0.721, Train_accy 76.34
2024-08-02 15:36:23,041 [foster.py] => SNet: Task 9, Epoch 53/130 => Loss 28.743,  Loss1 0.721, Train_accy 77.20
2024-08-02 15:36:26,460 [foster.py] => SNet: Task 9, Epoch 54/130 => Loss 28.738,  Loss1 0.721, Train_accy 77.50
2024-08-02 15:36:29,838 [foster.py] => SNet: Task 9, Epoch 55/130 => Loss 28.640,  Loss1 0.722, Train_accy 77.46
2024-08-02 15:36:34,266 [foster.py] => SNet: Task 9, Epoch 56/130 => Loss 28.730,  Loss1 0.722, Train_accy 76.94, Test_accy 71.12
2024-08-02 15:36:37,640 [foster.py] => SNet: Task 9, Epoch 57/130 => Loss 28.682,  Loss1 0.723, Train_accy 77.16
2024-08-02 15:36:41,024 [foster.py] => SNet: Task 9, Epoch 58/130 => Loss 28.692,  Loss1 0.722, Train_accy 77.16
2024-08-02 15:36:44,399 [foster.py] => SNet: Task 9, Epoch 59/130 => Loss 28.674,  Loss1 0.722, Train_accy 76.85
2024-08-02 15:36:47,772 [foster.py] => SNet: Task 9, Epoch 60/130 => Loss 28.720,  Loss1 0.722, Train_accy 76.64
2024-08-02 15:36:52,236 [foster.py] => SNet: Task 9, Epoch 61/130 => Loss 28.700,  Loss1 0.721, Train_accy 76.42, Test_accy 71.26
2024-08-02 15:36:55,644 [foster.py] => SNet: Task 9, Epoch 62/130 => Loss 28.673,  Loss1 0.722, Train_accy 75.95
2024-08-02 15:36:59,000 [foster.py] => SNet: Task 9, Epoch 63/130 => Loss 28.723,  Loss1 0.721, Train_accy 77.03
2024-08-02 15:37:02,382 [foster.py] => SNet: Task 9, Epoch 64/130 => Loss 28.658,  Loss1 0.721, Train_accy 77.54
2024-08-02 15:37:05,752 [foster.py] => SNet: Task 9, Epoch 65/130 => Loss 28.694,  Loss1 0.722, Train_accy 76.03
2024-08-02 15:37:10,203 [foster.py] => SNet: Task 9, Epoch 66/130 => Loss 28.740,  Loss1 0.721, Train_accy 76.72, Test_accy 71.15
2024-08-02 15:37:13,596 [foster.py] => SNet: Task 9, Epoch 67/130 => Loss 28.745,  Loss1 0.721, Train_accy 76.25
2024-08-02 15:37:16,971 [foster.py] => SNet: Task 9, Epoch 68/130 => Loss 28.703,  Loss1 0.722, Train_accy 76.51
2024-08-02 15:37:20,377 [foster.py] => SNet: Task 9, Epoch 69/130 => Loss 28.678,  Loss1 0.722, Train_accy 77.16
2024-08-02 15:37:23,805 [foster.py] => SNet: Task 9, Epoch 70/130 => Loss 28.728,  Loss1 0.721, Train_accy 76.25
2024-08-02 15:37:28,224 [foster.py] => SNet: Task 9, Epoch 71/130 => Loss 28.691,  Loss1 0.721, Train_accy 76.16, Test_accy 71.15
2024-08-02 15:37:31,588 [foster.py] => SNet: Task 9, Epoch 72/130 => Loss 28.675,  Loss1 0.722, Train_accy 77.28
2024-08-02 15:37:34,970 [foster.py] => SNet: Task 9, Epoch 73/130 => Loss 28.647,  Loss1 0.721, Train_accy 77.20
2024-08-02 15:37:38,398 [foster.py] => SNet: Task 9, Epoch 74/130 => Loss 28.756,  Loss1 0.721, Train_accy 77.24
2024-08-02 15:37:41,776 [foster.py] => SNet: Task 9, Epoch 75/130 => Loss 28.739,  Loss1 0.721, Train_accy 77.33
2024-08-02 15:37:46,204 [foster.py] => SNet: Task 9, Epoch 76/130 => Loss 28.676,  Loss1 0.722, Train_accy 76.42, Test_accy 71.26
2024-08-02 15:37:49,572 [foster.py] => SNet: Task 9, Epoch 77/130 => Loss 28.745,  Loss1 0.721, Train_accy 75.43
2024-08-02 15:37:52,959 [foster.py] => SNet: Task 9, Epoch 78/130 => Loss 28.742,  Loss1 0.722, Train_accy 76.64
2024-08-02 15:37:56,325 [foster.py] => SNet: Task 9, Epoch 79/130 => Loss 28.695,  Loss1 0.721, Train_accy 77.28
2024-08-02 15:37:59,705 [foster.py] => SNet: Task 9, Epoch 80/130 => Loss 28.746,  Loss1 0.721, Train_accy 76.85
2024-08-02 15:38:04,141 [foster.py] => SNet: Task 9, Epoch 81/130 => Loss 28.690,  Loss1 0.722, Train_accy 76.47, Test_accy 70.82
2024-08-02 15:38:07,502 [foster.py] => SNet: Task 9, Epoch 82/130 => Loss 28.725,  Loss1 0.722, Train_accy 77.97
2024-08-02 15:38:10,900 [foster.py] => SNet: Task 9, Epoch 83/130 => Loss 28.722,  Loss1 0.722, Train_accy 76.64
2024-08-02 15:38:14,317 [foster.py] => SNet: Task 9, Epoch 84/130 => Loss 28.690,  Loss1 0.722, Train_accy 76.34
2024-08-02 15:38:17,689 [foster.py] => SNet: Task 9, Epoch 85/130 => Loss 28.690,  Loss1 0.722, Train_accy 78.58
2024-08-02 15:38:22,110 [foster.py] => SNet: Task 9, Epoch 86/130 => Loss 28.686,  Loss1 0.722, Train_accy 77.93, Test_accy 71.16
2024-08-02 15:38:25,474 [foster.py] => SNet: Task 9, Epoch 87/130 => Loss 28.673,  Loss1 0.722, Train_accy 77.11
2024-08-02 15:38:28,854 [foster.py] => SNet: Task 9, Epoch 88/130 => Loss 28.737,  Loss1 0.721, Train_accy 77.16
2024-08-02 15:38:32,297 [foster.py] => SNet: Task 9, Epoch 89/130 => Loss 28.727,  Loss1 0.721, Train_accy 77.28
2024-08-02 15:38:35,677 [foster.py] => SNet: Task 9, Epoch 90/130 => Loss 28.678,  Loss1 0.721, Train_accy 78.10
2024-08-02 15:38:40,095 [foster.py] => SNet: Task 9, Epoch 91/130 => Loss 28.613,  Loss1 0.721, Train_accy 77.76, Test_accy 71.60
2024-08-02 15:38:43,472 [foster.py] => SNet: Task 9, Epoch 92/130 => Loss 28.728,  Loss1 0.721, Train_accy 76.21
2024-08-02 15:38:46,830 [foster.py] => SNet: Task 9, Epoch 93/130 => Loss 28.706,  Loss1 0.721, Train_accy 77.63
2024-08-02 15:38:50,214 [foster.py] => SNet: Task 9, Epoch 94/130 => Loss 28.722,  Loss1 0.721, Train_accy 77.46
2024-08-02 15:38:53,589 [foster.py] => SNet: Task 9, Epoch 95/130 => Loss 28.740,  Loss1 0.721, Train_accy 75.78
2024-08-02 15:38:58,045 [foster.py] => SNet: Task 9, Epoch 96/130 => Loss 28.671,  Loss1 0.721, Train_accy 78.97, Test_accy 71.18
2024-08-02 15:39:01,417 [foster.py] => SNet: Task 9, Epoch 97/130 => Loss 28.691,  Loss1 0.722, Train_accy 77.76
2024-08-02 15:39:04,782 [foster.py] => SNet: Task 9, Epoch 98/130 => Loss 28.703,  Loss1 0.722, Train_accy 76.85
2024-08-02 15:39:08,171 [foster.py] => SNet: Task 9, Epoch 99/130 => Loss 28.678,  Loss1 0.721, Train_accy 77.20
2024-08-02 15:39:11,555 [foster.py] => SNet: Task 9, Epoch 100/130 => Loss 28.721,  Loss1 0.722, Train_accy 77.11
2024-08-02 15:39:15,983 [foster.py] => SNet: Task 9, Epoch 101/130 => Loss 28.710,  Loss1 0.721, Train_accy 77.28, Test_accy 71.31
2024-08-02 15:39:19,350 [foster.py] => SNet: Task 9, Epoch 102/130 => Loss 28.735,  Loss1 0.722, Train_accy 76.90
2024-08-02 15:39:22,731 [foster.py] => SNet: Task 9, Epoch 103/130 => Loss 28.701,  Loss1 0.722, Train_accy 76.68
2024-08-02 15:39:26,131 [foster.py] => SNet: Task 9, Epoch 104/130 => Loss 28.740,  Loss1 0.721, Train_accy 76.47
2024-08-02 15:39:29,495 [foster.py] => SNet: Task 9, Epoch 105/130 => Loss 28.713,  Loss1 0.721, Train_accy 76.21
2024-08-02 15:39:33,911 [foster.py] => SNet: Task 9, Epoch 106/130 => Loss 28.724,  Loss1 0.721, Train_accy 78.58, Test_accy 71.22
2024-08-02 15:39:37,299 [foster.py] => SNet: Task 9, Epoch 107/130 => Loss 28.676,  Loss1 0.721, Train_accy 77.28
2024-08-02 15:39:40,734 [foster.py] => SNet: Task 9, Epoch 108/130 => Loss 28.641,  Loss1 0.722, Train_accy 77.50
2024-08-02 15:39:44,097 [foster.py] => SNet: Task 9, Epoch 109/130 => Loss 28.765,  Loss1 0.721, Train_accy 77.46
2024-08-02 15:39:47,464 [foster.py] => SNet: Task 9, Epoch 110/130 => Loss 28.713,  Loss1 0.722, Train_accy 78.32
2024-08-02 15:39:51,909 [foster.py] => SNet: Task 9, Epoch 111/130 => Loss 28.697,  Loss1 0.721, Train_accy 77.80, Test_accy 71.47
2024-08-02 15:39:55,296 [foster.py] => SNet: Task 9, Epoch 112/130 => Loss 28.699,  Loss1 0.721, Train_accy 78.32
2024-08-02 15:39:58,662 [foster.py] => SNet: Task 9, Epoch 113/130 => Loss 28.710,  Loss1 0.722, Train_accy 78.45
2024-08-02 15:40:02,062 [foster.py] => SNet: Task 9, Epoch 114/130 => Loss 28.733,  Loss1 0.721, Train_accy 77.97
2024-08-02 15:40:05,439 [foster.py] => SNet: Task 9, Epoch 115/130 => Loss 28.723,  Loss1 0.722, Train_accy 77.54
2024-08-02 15:40:09,880 [foster.py] => SNet: Task 9, Epoch 116/130 => Loss 28.739,  Loss1 0.722, Train_accy 77.67, Test_accy 71.57
2024-08-02 15:40:13,251 [foster.py] => SNet: Task 9, Epoch 117/130 => Loss 28.707,  Loss1 0.722, Train_accy 77.93
2024-08-02 15:40:16,625 [foster.py] => SNet: Task 9, Epoch 118/130 => Loss 28.682,  Loss1 0.722, Train_accy 79.14
2024-08-02 15:40:19,995 [foster.py] => SNet: Task 9, Epoch 119/130 => Loss 28.669,  Loss1 0.722, Train_accy 76.77
2024-08-02 15:40:23,369 [foster.py] => SNet: Task 9, Epoch 120/130 => Loss 28.703,  Loss1 0.722, Train_accy 78.49
2024-08-02 15:40:27,830 [foster.py] => SNet: Task 9, Epoch 121/130 => Loss 28.727,  Loss1 0.721, Train_accy 76.81, Test_accy 71.50
2024-08-02 15:40:31,224 [foster.py] => SNet: Task 9, Epoch 122/130 => Loss 28.672,  Loss1 0.721, Train_accy 76.94
2024-08-02 15:40:34,580 [foster.py] => SNet: Task 9, Epoch 123/130 => Loss 28.693,  Loss1 0.721, Train_accy 77.33
2024-08-02 15:40:37,988 [foster.py] => SNet: Task 9, Epoch 124/130 => Loss 28.701,  Loss1 0.721, Train_accy 78.41
2024-08-02 15:40:41,383 [foster.py] => SNet: Task 9, Epoch 125/130 => Loss 28.679,  Loss1 0.721, Train_accy 78.36
2024-08-02 15:40:45,812 [foster.py] => SNet: Task 9, Epoch 126/130 => Loss 28.678,  Loss1 0.722, Train_accy 77.50, Test_accy 71.47
2024-08-02 15:40:49,254 [foster.py] => SNet: Task 9, Epoch 127/130 => Loss 28.712,  Loss1 0.721, Train_accy 76.42
2024-08-02 15:40:52,641 [foster.py] => SNet: Task 9, Epoch 128/130 => Loss 28.722,  Loss1 0.721, Train_accy 77.46
2024-08-02 15:40:56,005 [foster.py] => SNet: Task 9, Epoch 129/130 => Loss 28.724,  Loss1 0.721, Train_accy 77.97
2024-08-02 15:40:59,398 [foster.py] => SNet: Task 9, Epoch 130/130 => Loss 28.696,  Loss1 0.722, Train_accy 76.59
2024-08-02 15:40:59,399 [foster.py] => do not weight align student!
2024-08-02 15:41:00,438 [foster.py] => darknet eval: 
2024-08-02 15:41:00,438 [foster.py] => CNN top1 curve: 71.4
2024-08-02 15:41:00,438 [foster.py] => CNN top5 curve: 92.22
2024-08-02 15:41:00,439 [foster.py] => CNN top1 平均值: 71.40
2024-08-02 15:41:00,441 [foster.py] => timees : 1111.71577501297
2024-08-02 15:41:00,442 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 15:41:21,261 [foster.py] => Exemplar size: 1360
2024-08-02 15:41:21,262 [trainer.py] => CNN: {'total': 72.79, '00-09': 79.5, '10-19': 65.9, '20-29': 78.7, '30-39': 72.5, '40-49': 78.6, '50-59': 63.8, '60-69': 70.0, 'old': 72.35, 'new': 87.5}
2024-08-02 15:41:21,262 [trainer.py] => NME: {'total': 68.26, '00-09': 72.4, '10-19': 58.5, '20-29': 74.2, '30-39': 65.4, '40-49': 73.6, '50-59': 67.5, '60-69': 65.75, 'old': 67.45, 'new': 95.0}
2024-08-02 15:41:21,262 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79]
2024-08-02 15:41:21,262 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9]
2024-08-02 15:41:21,262 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26]
2024-08-02 15:41:21,262 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69]

2024-08-02 15:41:21,262 [trainer.py] => CNN top1 平均值: 76.88
2024-08-02 15:41:21,265 [trainer.py] => All params: 1172030
2024-08-02 15:41:21,267 [trainer.py] => Trainable params: 590466
2024-08-02 15:41:21,327 [foster.py] => Learning on 68-70
2024-08-02 15:41:21,330 [foster.py] => All params: 1172548
2024-08-02 15:41:21,332 [foster.py] => Trainable params: 590854
2024-08-02 15:41:21,371 [foster.py] => per cls weights : [1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908 1.01310908
 1.01310908 1.01310908 0.55429133 0.55429133]
2024-08-02 15:41:23,942 [foster.py] => Task 10, Epoch 1/170 => Loss 5.590, Loss_clf 1.221, Loss_fe 1.926, Loss_kd 2.371, Train_accy 63.98
2024-08-02 15:41:28,123 [foster.py] => Task 10, Epoch 2/170 => Loss 3.538, Loss_clf 0.481, Loss_fe 0.690, Loss_kd 2.298, Train_accy 72.63, Test_accy 70.26
2024-08-02 15:41:32,247 [foster.py] => Task 10, Epoch 3/170 => Loss 3.459, Loss_clf 0.473, Loss_fe 0.582, Loss_kd 2.334, Train_accy 68.90, Test_accy 70.09
2024-08-02 15:41:36,379 [foster.py] => Task 10, Epoch 4/170 => Loss 3.265, Loss_clf 0.411, Loss_fe 0.484, Loss_kd 2.300, Train_accy 72.84, Test_accy 70.40
2024-08-02 15:41:40,481 [foster.py] => Task 10, Epoch 5/170 => Loss 3.292, Loss_clf 0.442, Loss_fe 0.446, Loss_kd 2.334, Train_accy 75.04, Test_accy 70.84
2024-08-02 15:41:43,063 [foster.py] => Task 10, Epoch 6/170 => Loss 3.286, Loss_clf 0.455, Loss_fe 0.441, Loss_kd 2.320, Train_accy 72.50
2024-08-02 15:41:47,199 [foster.py] => Task 10, Epoch 7/170 => Loss 3.181, Loss_clf 0.399, Loss_fe 0.405, Loss_kd 2.308, Train_accy 74.03, Test_accy 70.60
2024-08-02 15:41:51,305 [foster.py] => Task 10, Epoch 8/170 => Loss 3.177, Loss_clf 0.417, Loss_fe 0.375, Loss_kd 2.315, Train_accy 74.07, Test_accy 70.27
2024-08-02 15:41:55,406 [foster.py] => Task 10, Epoch 9/170 => Loss 3.119, Loss_clf 0.398, Loss_fe 0.375, Loss_kd 2.277, Train_accy 74.96, Test_accy 70.17
2024-08-02 15:41:59,544 [foster.py] => Task 10, Epoch 10/170 => Loss 3.165, Loss_clf 0.401, Loss_fe 0.373, Loss_kd 2.321, Train_accy 73.73, Test_accy 70.53
2024-08-02 15:42:02,073 [foster.py] => Task 10, Epoch 11/170 => Loss 3.096, Loss_clf 0.392, Loss_fe 0.336, Loss_kd 2.299, Train_accy 73.01
2024-08-02 15:42:06,202 [foster.py] => Task 10, Epoch 12/170 => Loss 3.091, Loss_clf 0.389, Loss_fe 0.317, Loss_kd 2.316, Train_accy 75.00, Test_accy 70.51
2024-08-02 15:42:10,320 [foster.py] => Task 10, Epoch 13/170 => Loss 3.109, Loss_clf 0.399, Loss_fe 0.318, Loss_kd 2.322, Train_accy 76.10, Test_accy 70.20
2024-08-02 15:42:14,459 [foster.py] => Task 10, Epoch 14/170 => Loss 3.093, Loss_clf 0.400, Loss_fe 0.318, Loss_kd 2.306, Train_accy 75.38, Test_accy 70.64
2024-08-02 15:42:18,661 [foster.py] => Task 10, Epoch 15/170 => Loss 2.986, Loss_clf 0.351, Loss_fe 0.294, Loss_kd 2.273, Train_accy 77.54, Test_accy 70.53
2024-08-02 15:42:21,130 [foster.py] => Task 10, Epoch 16/170 => Loss 3.048, Loss_clf 0.389, Loss_fe 0.285, Loss_kd 2.305, Train_accy 75.89
2024-08-02 15:42:25,237 [foster.py] => Task 10, Epoch 17/170 => Loss 2.953, Loss_clf 0.353, Loss_fe 0.262, Loss_kd 2.269, Train_accy 78.39, Test_accy 70.53
2024-08-02 15:42:29,328 [foster.py] => Task 10, Epoch 18/170 => Loss 3.030, Loss_clf 0.377, Loss_fe 0.287, Loss_kd 2.298, Train_accy 77.54, Test_accy 70.86
2024-08-02 15:42:33,467 [foster.py] => Task 10, Epoch 19/170 => Loss 3.145, Loss_clf 0.438, Loss_fe 0.306, Loss_kd 2.331, Train_accy 76.44, Test_accy 70.91
2024-08-02 15:42:37,607 [foster.py] => Task 10, Epoch 20/170 => Loss 3.043, Loss_clf 0.379, Loss_fe 0.289, Loss_kd 2.305, Train_accy 76.69, Test_accy 70.53
2024-08-02 15:42:40,073 [foster.py] => Task 10, Epoch 21/170 => Loss 3.068, Loss_clf 0.401, Loss_fe 0.305, Loss_kd 2.293, Train_accy 76.53
2024-08-02 15:42:44,211 [foster.py] => Task 10, Epoch 22/170 => Loss 3.046, Loss_clf 0.378, Loss_fe 0.271, Loss_kd 2.327, Train_accy 77.75, Test_accy 70.67
2024-08-02 15:42:48,365 [foster.py] => Task 10, Epoch 23/170 => Loss 3.010, Loss_clf 0.367, Loss_fe 0.254, Loss_kd 2.320, Train_accy 77.16, Test_accy 70.44
2024-08-02 15:42:52,485 [foster.py] => Task 10, Epoch 24/170 => Loss 2.956, Loss_clf 0.351, Loss_fe 0.251, Loss_kd 2.285, Train_accy 77.80, Test_accy 70.96
2024-08-02 15:42:56,586 [foster.py] => Task 10, Epoch 25/170 => Loss 2.983, Loss_clf 0.348, Loss_fe 0.254, Loss_kd 2.312, Train_accy 78.47, Test_accy 70.16
2024-08-02 15:42:59,034 [foster.py] => Task 10, Epoch 26/170 => Loss 3.007, Loss_clf 0.363, Loss_fe 0.256, Loss_kd 2.318, Train_accy 77.29
2024-08-02 15:43:03,201 [foster.py] => Task 10, Epoch 27/170 => Loss 3.051, Loss_clf 0.379, Loss_fe 0.264, Loss_kd 2.338, Train_accy 78.69, Test_accy 70.76
2024-08-02 15:43:07,368 [foster.py] => Task 10, Epoch 28/170 => Loss 2.965, Loss_clf 0.370, Loss_fe 0.249, Loss_kd 2.277, Train_accy 78.39, Test_accy 70.27
2024-08-02 15:43:11,527 [foster.py] => Task 10, Epoch 29/170 => Loss 2.913, Loss_clf 0.337, Loss_fe 0.217, Loss_kd 2.290, Train_accy 78.43, Test_accy 70.87
2024-08-02 15:43:15,669 [foster.py] => Task 10, Epoch 30/170 => Loss 2.926, Loss_clf 0.341, Loss_fe 0.221, Loss_kd 2.294, Train_accy 78.90, Test_accy 71.09
2024-08-02 15:43:18,154 [foster.py] => Task 10, Epoch 31/170 => Loss 2.966, Loss_clf 0.364, Loss_fe 0.218, Loss_kd 2.315, Train_accy 80.30
2024-08-02 15:43:22,281 [foster.py] => Task 10, Epoch 32/170 => Loss 3.006, Loss_clf 0.370, Loss_fe 0.245, Loss_kd 2.321, Train_accy 80.38, Test_accy 70.83
2024-08-02 15:43:26,422 [foster.py] => Task 10, Epoch 33/170 => Loss 2.988, Loss_clf 0.351, Loss_fe 0.230, Loss_kd 2.337, Train_accy 77.92, Test_accy 71.07
2024-08-02 15:43:30,550 [foster.py] => Task 10, Epoch 34/170 => Loss 2.950, Loss_clf 0.352, Loss_fe 0.211, Loss_kd 2.318, Train_accy 80.93, Test_accy 70.44
2024-08-02 15:43:34,655 [foster.py] => Task 10, Epoch 35/170 => Loss 2.911, Loss_clf 0.320, Loss_fe 0.223, Loss_kd 2.299, Train_accy 80.17, Test_accy 70.66
2024-08-02 15:43:37,103 [foster.py] => Task 10, Epoch 36/170 => Loss 2.975, Loss_clf 0.354, Loss_fe 0.225, Loss_kd 2.326, Train_accy 80.00
2024-08-02 15:43:41,339 [foster.py] => Task 10, Epoch 37/170 => Loss 2.889, Loss_clf 0.324, Loss_fe 0.211, Loss_kd 2.285, Train_accy 82.92, Test_accy 70.49
2024-08-02 15:43:45,451 [foster.py] => Task 10, Epoch 38/170 => Loss 2.977, Loss_clf 0.367, Loss_fe 0.223, Loss_kd 2.316, Train_accy 76.91, Test_accy 70.57
2024-08-02 15:43:49,551 [foster.py] => Task 10, Epoch 39/170 => Loss 2.863, Loss_clf 0.316, Loss_fe 0.182, Loss_kd 2.296, Train_accy 80.81, Test_accy 71.06
2024-08-02 15:43:53,667 [foster.py] => Task 10, Epoch 40/170 => Loss 2.927, Loss_clf 0.336, Loss_fe 0.203, Loss_kd 2.318, Train_accy 81.82, Test_accy 70.79
2024-08-02 15:43:56,135 [foster.py] => Task 10, Epoch 41/170 => Loss 2.885, Loss_clf 0.337, Loss_fe 0.194, Loss_kd 2.285, Train_accy 81.48
2024-08-02 15:44:00,257 [foster.py] => Task 10, Epoch 42/170 => Loss 2.868, Loss_clf 0.313, Loss_fe 0.175, Loss_kd 2.311, Train_accy 81.02, Test_accy 70.71
2024-08-02 15:44:04,494 [foster.py] => Task 10, Epoch 43/170 => Loss 2.916, Loss_clf 0.334, Loss_fe 0.204, Loss_kd 2.308, Train_accy 81.27, Test_accy 70.63
2024-08-02 15:44:08,599 [foster.py] => Task 10, Epoch 44/170 => Loss 2.916, Loss_clf 0.350, Loss_fe 0.202, Loss_kd 2.294, Train_accy 80.00, Test_accy 71.09
2024-08-02 15:44:12,717 [foster.py] => Task 10, Epoch 45/170 => Loss 2.932, Loss_clf 0.363, Loss_fe 0.192, Loss_kd 2.308, Train_accy 81.27, Test_accy 70.56
2024-08-02 15:44:15,183 [foster.py] => Task 10, Epoch 46/170 => Loss 2.950, Loss_clf 0.355, Loss_fe 0.198, Loss_kd 2.327, Train_accy 79.96
2024-08-02 15:44:19,309 [foster.py] => Task 10, Epoch 47/170 => Loss 2.896, Loss_clf 0.331, Loss_fe 0.191, Loss_kd 2.306, Train_accy 80.68, Test_accy 71.24
2024-08-02 15:44:23,425 [foster.py] => Task 10, Epoch 48/170 => Loss 2.918, Loss_clf 0.340, Loss_fe 0.192, Loss_kd 2.316, Train_accy 81.14, Test_accy 70.97
2024-08-02 15:44:27,553 [foster.py] => Task 10, Epoch 49/170 => Loss 2.918, Loss_clf 0.345, Loss_fe 0.196, Loss_kd 2.308, Train_accy 81.27, Test_accy 70.66
2024-08-02 15:44:31,693 [foster.py] => Task 10, Epoch 50/170 => Loss 2.977, Loss_clf 0.360, Loss_fe 0.205, Loss_kd 2.342, Train_accy 79.53, Test_accy 71.43
2024-08-02 15:44:34,165 [foster.py] => Task 10, Epoch 51/170 => Loss 2.934, Loss_clf 0.345, Loss_fe 0.209, Loss_kd 2.311, Train_accy 79.87
2024-08-02 15:44:38,308 [foster.py] => Task 10, Epoch 52/170 => Loss 2.877, Loss_clf 0.320, Loss_fe 0.193, Loss_kd 2.295, Train_accy 80.38, Test_accy 71.07
2024-08-02 15:44:42,383 [foster.py] => Task 10, Epoch 53/170 => Loss 2.843, Loss_clf 0.311, Loss_fe 0.179, Loss_kd 2.284, Train_accy 82.33, Test_accy 71.03
2024-08-02 15:44:46,498 [foster.py] => Task 10, Epoch 54/170 => Loss 2.822, Loss_clf 0.290, Loss_fe 0.171, Loss_kd 2.292, Train_accy 80.72, Test_accy 71.29
2024-08-02 15:44:50,621 [foster.py] => Task 10, Epoch 55/170 => Loss 2.853, Loss_clf 0.316, Loss_fe 0.175, Loss_kd 2.292, Train_accy 82.25, Test_accy 71.06
2024-08-02 15:44:53,106 [foster.py] => Task 10, Epoch 56/170 => Loss 2.881, Loss_clf 0.337, Loss_fe 0.159, Loss_kd 2.315, Train_accy 81.65
2024-08-02 15:44:57,237 [foster.py] => Task 10, Epoch 57/170 => Loss 2.862, Loss_clf 0.324, Loss_fe 0.165, Loss_kd 2.304, Train_accy 81.57, Test_accy 71.11
2024-08-02 15:45:01,409 [foster.py] => Task 10, Epoch 58/170 => Loss 2.925, Loss_clf 0.362, Loss_fe 0.183, Loss_kd 2.310, Train_accy 81.36, Test_accy 71.30
2024-08-02 15:45:05,566 [foster.py] => Task 10, Epoch 59/170 => Loss 2.931, Loss_clf 0.352, Loss_fe 0.179, Loss_kd 2.329, Train_accy 81.48, Test_accy 71.56
2024-08-02 15:45:09,692 [foster.py] => Task 10, Epoch 60/170 => Loss 2.866, Loss_clf 0.326, Loss_fe 0.161, Loss_kd 2.309, Train_accy 82.37, Test_accy 70.99
2024-08-02 15:45:12,151 [foster.py] => Task 10, Epoch 61/170 => Loss 2.831, Loss_clf 0.312, Loss_fe 0.157, Loss_kd 2.294, Train_accy 82.75
2024-08-02 15:45:16,273 [foster.py] => Task 10, Epoch 62/170 => Loss 2.823, Loss_clf 0.309, Loss_fe 0.168, Loss_kd 2.278, Train_accy 81.53, Test_accy 71.00
2024-08-02 15:45:20,357 [foster.py] => Task 10, Epoch 63/170 => Loss 2.847, Loss_clf 0.314, Loss_fe 0.166, Loss_kd 2.298, Train_accy 81.36, Test_accy 70.76
2024-08-02 15:45:24,595 [foster.py] => Task 10, Epoch 64/170 => Loss 2.841, Loss_clf 0.311, Loss_fe 0.167, Loss_kd 2.293, Train_accy 82.29, Test_accy 71.13
2024-08-02 15:45:28,833 [foster.py] => Task 10, Epoch 65/170 => Loss 2.860, Loss_clf 0.313, Loss_fe 0.160, Loss_kd 2.318, Train_accy 83.05, Test_accy 71.16
2024-08-02 15:45:31,304 [foster.py] => Task 10, Epoch 66/170 => Loss 2.863, Loss_clf 0.330, Loss_fe 0.162, Loss_kd 2.302, Train_accy 80.97
2024-08-02 15:45:35,453 [foster.py] => Task 10, Epoch 67/170 => Loss 2.905, Loss_clf 0.344, Loss_fe 0.170, Loss_kd 2.321, Train_accy 81.78, Test_accy 71.17
2024-08-02 15:45:39,577 [foster.py] => Task 10, Epoch 68/170 => Loss 2.869, Loss_clf 0.321, Loss_fe 0.173, Loss_kd 2.305, Train_accy 81.82, Test_accy 71.26
2024-08-02 15:45:43,689 [foster.py] => Task 10, Epoch 69/170 => Loss 2.908, Loss_clf 0.349, Loss_fe 0.175, Loss_kd 2.315, Train_accy 81.44, Test_accy 70.61
2024-08-02 15:45:47,799 [foster.py] => Task 10, Epoch 70/170 => Loss 2.796, Loss_clf 0.292, Loss_fe 0.132, Loss_kd 2.303, Train_accy 81.27, Test_accy 71.34
2024-08-02 15:45:50,289 [foster.py] => Task 10, Epoch 71/170 => Loss 2.794, Loss_clf 0.290, Loss_fe 0.144, Loss_kd 2.291, Train_accy 83.69
2024-08-02 15:45:54,410 [foster.py] => Task 10, Epoch 72/170 => Loss 2.838, Loss_clf 0.312, Loss_fe 0.143, Loss_kd 2.313, Train_accy 83.81, Test_accy 71.06
2024-08-02 15:45:58,511 [foster.py] => Task 10, Epoch 73/170 => Loss 2.872, Loss_clf 0.334, Loss_fe 0.152, Loss_kd 2.316, Train_accy 82.29, Test_accy 71.40
2024-08-02 15:46:02,631 [foster.py] => Task 10, Epoch 74/170 => Loss 2.905, Loss_clf 0.348, Loss_fe 0.159, Loss_kd 2.329, Train_accy 81.61, Test_accy 71.29
2024-08-02 15:46:06,732 [foster.py] => Task 10, Epoch 75/170 => Loss 2.820, Loss_clf 0.305, Loss_fe 0.141, Loss_kd 2.304, Train_accy 83.14, Test_accy 71.40
2024-08-02 15:46:09,198 [foster.py] => Task 10, Epoch 76/170 => Loss 2.853, Loss_clf 0.332, Loss_fe 0.148, Loss_kd 2.303, Train_accy 83.81
2024-08-02 15:46:13,324 [foster.py] => Task 10, Epoch 77/170 => Loss 2.823, Loss_clf 0.312, Loss_fe 0.138, Loss_kd 2.305, Train_accy 83.09, Test_accy 71.31
2024-08-02 15:46:17,431 [foster.py] => Task 10, Epoch 78/170 => Loss 2.824, Loss_clf 0.304, Loss_fe 0.137, Loss_kd 2.313, Train_accy 84.15, Test_accy 71.09
2024-08-02 15:46:21,619 [foster.py] => Task 10, Epoch 79/170 => Loss 2.799, Loss_clf 0.295, Loss_fe 0.139, Loss_kd 2.296, Train_accy 84.03, Test_accy 71.37
2024-08-02 15:46:25,778 [foster.py] => Task 10, Epoch 80/170 => Loss 2.812, Loss_clf 0.307, Loss_fe 0.126, Loss_kd 2.309, Train_accy 83.86, Test_accy 71.59
2024-08-02 15:46:28,255 [foster.py] => Task 10, Epoch 81/170 => Loss 2.836, Loss_clf 0.320, Loss_fe 0.141, Loss_kd 2.306, Train_accy 82.67
2024-08-02 15:46:32,363 [foster.py] => Task 10, Epoch 82/170 => Loss 2.830, Loss_clf 0.308, Loss_fe 0.139, Loss_kd 2.313, Train_accy 84.15, Test_accy 71.39
2024-08-02 15:46:36,446 [foster.py] => Task 10, Epoch 83/170 => Loss 2.841, Loss_clf 0.314, Loss_fe 0.140, Loss_kd 2.317, Train_accy 84.45, Test_accy 71.11
2024-08-02 15:46:40,549 [foster.py] => Task 10, Epoch 84/170 => Loss 2.848, Loss_clf 0.316, Loss_fe 0.128, Loss_kd 2.335, Train_accy 83.56, Test_accy 71.07
2024-08-02 15:46:44,773 [foster.py] => Task 10, Epoch 85/170 => Loss 2.857, Loss_clf 0.322, Loss_fe 0.143, Loss_kd 2.322, Train_accy 83.09, Test_accy 71.23
2024-08-02 15:46:47,228 [foster.py] => Task 10, Epoch 86/170 => Loss 2.808, Loss_clf 0.306, Loss_fe 0.122, Loss_kd 2.311, Train_accy 85.76
2024-08-02 15:46:51,355 [foster.py] => Task 10, Epoch 87/170 => Loss 2.858, Loss_clf 0.314, Loss_fe 0.142, Loss_kd 2.332, Train_accy 82.71, Test_accy 71.29
2024-08-02 15:46:55,473 [foster.py] => Task 10, Epoch 88/170 => Loss 2.790, Loss_clf 0.290, Loss_fe 0.120, Loss_kd 2.311, Train_accy 84.62, Test_accy 71.29
2024-08-02 15:46:59,593 [foster.py] => Task 10, Epoch 89/170 => Loss 2.798, Loss_clf 0.289, Loss_fe 0.124, Loss_kd 2.315, Train_accy 83.60, Test_accy 71.60
2024-08-02 15:47:03,707 [foster.py] => Task 10, Epoch 90/170 => Loss 2.824, Loss_clf 0.323, Loss_fe 0.134, Loss_kd 2.298, Train_accy 83.43, Test_accy 71.47
2024-08-02 15:47:06,165 [foster.py] => Task 10, Epoch 91/170 => Loss 2.753, Loss_clf 0.280, Loss_fe 0.104, Loss_kd 2.300, Train_accy 85.38
2024-08-02 15:47:10,266 [foster.py] => Task 10, Epoch 92/170 => Loss 2.783, Loss_clf 0.304, Loss_fe 0.117, Loss_kd 2.292, Train_accy 83.69, Test_accy 71.40
2024-08-02 15:47:14,378 [foster.py] => Task 10, Epoch 93/170 => Loss 2.813, Loss_clf 0.311, Loss_fe 0.116, Loss_kd 2.316, Train_accy 83.39, Test_accy 71.19
2024-08-02 15:47:18,491 [foster.py] => Task 10, Epoch 94/170 => Loss 2.786, Loss_clf 0.289, Loss_fe 0.115, Loss_kd 2.313, Train_accy 85.30, Test_accy 71.30
2024-08-02 15:47:22,601 [foster.py] => Task 10, Epoch 95/170 => Loss 2.791, Loss_clf 0.300, Loss_fe 0.102, Loss_kd 2.319, Train_accy 84.41, Test_accy 71.47
2024-08-02 15:47:25,081 [foster.py] => Task 10, Epoch 96/170 => Loss 2.789, Loss_clf 0.315, Loss_fe 0.106, Loss_kd 2.299, Train_accy 84.03
2024-08-02 15:47:29,193 [foster.py] => Task 10, Epoch 97/170 => Loss 2.768, Loss_clf 0.292, Loss_fe 0.097, Loss_kd 2.310, Train_accy 84.36, Test_accy 71.54
2024-08-02 15:47:33,332 [foster.py] => Task 10, Epoch 98/170 => Loss 2.779, Loss_clf 0.295, Loss_fe 0.118, Loss_kd 2.297, Train_accy 84.66, Test_accy 71.51
2024-08-02 15:47:37,481 [foster.py] => Task 10, Epoch 99/170 => Loss 2.784, Loss_clf 0.298, Loss_fe 0.100, Loss_kd 2.317, Train_accy 85.42, Test_accy 71.57
2024-08-02 15:47:41,636 [foster.py] => Task 10, Epoch 100/170 => Loss 2.852, Loss_clf 0.327, Loss_fe 0.112, Loss_kd 2.343, Train_accy 83.86, Test_accy 71.44
2024-08-02 15:47:44,172 [foster.py] => Task 10, Epoch 101/170 => Loss 2.810, Loss_clf 0.304, Loss_fe 0.115, Loss_kd 2.322, Train_accy 85.42
2024-08-02 15:47:48,309 [foster.py] => Task 10, Epoch 102/170 => Loss 2.851, Loss_clf 0.332, Loss_fe 0.119, Loss_kd 2.330, Train_accy 85.04, Test_accy 71.21
2024-08-02 15:47:52,417 [foster.py] => Task 10, Epoch 103/170 => Loss 2.790, Loss_clf 0.310, Loss_fe 0.106, Loss_kd 2.305, Train_accy 83.60, Test_accy 71.34
2024-08-02 15:47:56,562 [foster.py] => Task 10, Epoch 104/170 => Loss 2.795, Loss_clf 0.288, Loss_fe 0.120, Loss_kd 2.317, Train_accy 85.68, Test_accy 71.17
2024-08-02 15:48:00,670 [foster.py] => Task 10, Epoch 105/170 => Loss 2.803, Loss_clf 0.306, Loss_fe 0.106, Loss_kd 2.321, Train_accy 84.70, Test_accy 71.29
2024-08-02 15:48:03,116 [foster.py] => Task 10, Epoch 106/170 => Loss 2.761, Loss_clf 0.290, Loss_fe 0.101, Loss_kd 2.300, Train_accy 85.59
2024-08-02 15:48:07,213 [foster.py] => Task 10, Epoch 107/170 => Loss 2.821, Loss_clf 0.312, Loss_fe 0.112, Loss_kd 2.326, Train_accy 85.30, Test_accy 71.31
2024-08-02 15:48:11,317 [foster.py] => Task 10, Epoch 108/170 => Loss 2.728, Loss_clf 0.276, Loss_fe 0.097, Loss_kd 2.286, Train_accy 86.02, Test_accy 71.30
2024-08-02 15:48:15,418 [foster.py] => Task 10, Epoch 109/170 => Loss 2.771, Loss_clf 0.280, Loss_fe 0.104, Loss_kd 2.318, Train_accy 85.13, Test_accy 71.27
2024-08-02 15:48:19,519 [foster.py] => Task 10, Epoch 110/170 => Loss 2.789, Loss_clf 0.292, Loss_fe 0.122, Loss_kd 2.306, Train_accy 86.44, Test_accy 70.99
2024-08-02 15:48:21,981 [foster.py] => Task 10, Epoch 111/170 => Loss 2.776, Loss_clf 0.284, Loss_fe 0.112, Loss_kd 2.311, Train_accy 85.17
2024-08-02 15:48:26,149 [foster.py] => Task 10, Epoch 112/170 => Loss 2.815, Loss_clf 0.311, Loss_fe 0.109, Loss_kd 2.324, Train_accy 83.98, Test_accy 71.44
2024-08-02 15:48:30,263 [foster.py] => Task 10, Epoch 113/170 => Loss 2.819, Loss_clf 0.319, Loss_fe 0.118, Loss_kd 2.312, Train_accy 84.87, Test_accy 71.26
2024-08-02 15:48:34,409 [foster.py] => Task 10, Epoch 114/170 => Loss 2.803, Loss_clf 0.288, Loss_fe 0.111, Loss_kd 2.334, Train_accy 85.85, Test_accy 71.34
2024-08-02 15:48:38,541 [foster.py] => Task 10, Epoch 115/170 => Loss 2.774, Loss_clf 0.281, Loss_fe 0.106, Loss_kd 2.317, Train_accy 86.14, Test_accy 71.63
2024-08-02 15:48:41,038 [foster.py] => Task 10, Epoch 116/170 => Loss 2.706, Loss_clf 0.264, Loss_fe 0.087, Loss_kd 2.287, Train_accy 87.12
2024-08-02 15:48:45,136 [foster.py] => Task 10, Epoch 117/170 => Loss 2.795, Loss_clf 0.302, Loss_fe 0.111, Loss_kd 2.312, Train_accy 85.38, Test_accy 71.30
2024-08-02 15:48:49,304 [foster.py] => Task 10, Epoch 118/170 => Loss 2.755, Loss_clf 0.290, Loss_fe 0.105, Loss_kd 2.291, Train_accy 85.59, Test_accy 71.63
2024-08-02 15:48:53,419 [foster.py] => Task 10, Epoch 119/170 => Loss 2.791, Loss_clf 0.305, Loss_fe 0.103, Loss_kd 2.312, Train_accy 84.49, Test_accy 71.60
2024-08-02 15:48:57,506 [foster.py] => Task 10, Epoch 120/170 => Loss 2.714, Loss_clf 0.257, Loss_fe 0.083, Loss_kd 2.305, Train_accy 86.31, Test_accy 71.57
2024-08-02 15:48:59,972 [foster.py] => Task 10, Epoch 121/170 => Loss 2.737, Loss_clf 0.274, Loss_fe 0.092, Loss_kd 2.302, Train_accy 86.10
2024-08-02 15:49:04,209 [foster.py] => Task 10, Epoch 122/170 => Loss 2.781, Loss_clf 0.291, Loss_fe 0.095, Loss_kd 2.325, Train_accy 85.55, Test_accy 71.37
2024-08-02 15:49:08,464 [foster.py] => Task 10, Epoch 123/170 => Loss 2.747, Loss_clf 0.287, Loss_fe 0.075, Loss_kd 2.316, Train_accy 85.25, Test_accy 71.50
2024-08-02 15:49:12,579 [foster.py] => Task 10, Epoch 124/170 => Loss 2.733, Loss_clf 0.275, Loss_fe 0.096, Loss_kd 2.292, Train_accy 86.74, Test_accy 71.41
2024-08-02 15:49:16,664 [foster.py] => Task 10, Epoch 125/170 => Loss 2.740, Loss_clf 0.279, Loss_fe 0.085, Loss_kd 2.307, Train_accy 84.79, Test_accy 71.44
2024-08-02 15:49:19,112 [foster.py] => Task 10, Epoch 126/170 => Loss 2.762, Loss_clf 0.294, Loss_fe 0.088, Loss_kd 2.311, Train_accy 85.81
2024-08-02 15:49:23,229 [foster.py] => Task 10, Epoch 127/170 => Loss 2.732, Loss_clf 0.285, Loss_fe 0.089, Loss_kd 2.289, Train_accy 84.45, Test_accy 71.36
2024-08-02 15:49:27,343 [foster.py] => Task 10, Epoch 128/170 => Loss 2.823, Loss_clf 0.310, Loss_fe 0.099, Loss_kd 2.344, Train_accy 85.55, Test_accy 71.39
2024-08-02 15:49:31,462 [foster.py] => Task 10, Epoch 129/170 => Loss 2.745, Loss_clf 0.287, Loss_fe 0.097, Loss_kd 2.292, Train_accy 85.00, Test_accy 71.39
2024-08-02 15:49:35,572 [foster.py] => Task 10, Epoch 130/170 => Loss 2.745, Loss_clf 0.282, Loss_fe 0.093, Loss_kd 2.301, Train_accy 85.81, Test_accy 71.36
2024-08-02 15:49:38,015 [foster.py] => Task 10, Epoch 131/170 => Loss 2.725, Loss_clf 0.272, Loss_fe 0.085, Loss_kd 2.300, Train_accy 85.85
2024-08-02 15:49:42,103 [foster.py] => Task 10, Epoch 132/170 => Loss 2.783, Loss_clf 0.294, Loss_fe 0.081, Loss_kd 2.337, Train_accy 85.38, Test_accy 71.49
2024-08-02 15:49:46,187 [foster.py] => Task 10, Epoch 133/170 => Loss 2.766, Loss_clf 0.284, Loss_fe 0.093, Loss_kd 2.319, Train_accy 86.44, Test_accy 71.43
2024-08-02 15:49:50,327 [foster.py] => Task 10, Epoch 134/170 => Loss 2.708, Loss_clf 0.263, Loss_fe 0.078, Loss_kd 2.299, Train_accy 85.97, Test_accy 71.49
2024-08-02 15:49:54,489 [foster.py] => Task 10, Epoch 135/170 => Loss 2.762, Loss_clf 0.284, Loss_fe 0.083, Loss_kd 2.326, Train_accy 85.59, Test_accy 71.46
2024-08-02 15:49:56,944 [foster.py] => Task 10, Epoch 136/170 => Loss 2.785, Loss_clf 0.299, Loss_fe 0.101, Loss_kd 2.315, Train_accy 86.82
2024-08-02 15:50:01,054 [foster.py] => Task 10, Epoch 137/170 => Loss 2.742, Loss_clf 0.273, Loss_fe 0.089, Loss_kd 2.311, Train_accy 85.97, Test_accy 71.34
2024-08-02 15:50:05,181 [foster.py] => Task 10, Epoch 138/170 => Loss 2.759, Loss_clf 0.278, Loss_fe 0.082, Loss_kd 2.328, Train_accy 85.89, Test_accy 71.19
2024-08-02 15:50:09,312 [foster.py] => Task 10, Epoch 139/170 => Loss 2.759, Loss_clf 0.290, Loss_fe 0.082, Loss_kd 2.317, Train_accy 85.85, Test_accy 71.20
2024-08-02 15:50:13,454 [foster.py] => Task 10, Epoch 140/170 => Loss 2.790, Loss_clf 0.299, Loss_fe 0.094, Loss_kd 2.327, Train_accy 85.89, Test_accy 71.17
2024-08-02 15:50:15,922 [foster.py] => Task 10, Epoch 141/170 => Loss 2.695, Loss_clf 0.261, Loss_fe 0.084, Loss_kd 2.282, Train_accy 85.97
2024-08-02 15:50:20,113 [foster.py] => Task 10, Epoch 142/170 => Loss 2.731, Loss_clf 0.278, Loss_fe 0.078, Loss_kd 2.306, Train_accy 86.61, Test_accy 71.26
2024-08-02 15:50:24,213 [foster.py] => Task 10, Epoch 143/170 => Loss 2.768, Loss_clf 0.287, Loss_fe 0.090, Loss_kd 2.321, Train_accy 86.19, Test_accy 71.20
2024-08-02 15:50:28,399 [foster.py] => Task 10, Epoch 144/170 => Loss 2.774, Loss_clf 0.303, Loss_fe 0.085, Loss_kd 2.316, Train_accy 85.04, Test_accy 71.27
2024-08-02 15:50:32,526 [foster.py] => Task 10, Epoch 145/170 => Loss 2.731, Loss_clf 0.276, Loss_fe 0.074, Loss_kd 2.312, Train_accy 86.31, Test_accy 71.29
2024-08-02 15:50:34,983 [foster.py] => Task 10, Epoch 146/170 => Loss 2.757, Loss_clf 0.281, Loss_fe 0.090, Loss_kd 2.316, Train_accy 85.64
2024-08-02 15:50:39,091 [foster.py] => Task 10, Epoch 147/170 => Loss 2.712, Loss_clf 0.273, Loss_fe 0.078, Loss_kd 2.292, Train_accy 86.10, Test_accy 71.21
2024-08-02 15:50:43,189 [foster.py] => Task 10, Epoch 148/170 => Loss 2.716, Loss_clf 0.266, Loss_fe 0.078, Loss_kd 2.303, Train_accy 86.91, Test_accy 71.27
2024-08-02 15:50:47,339 [foster.py] => Task 10, Epoch 149/170 => Loss 2.730, Loss_clf 0.276, Loss_fe 0.084, Loss_kd 2.301, Train_accy 85.17, Test_accy 71.29
2024-08-02 15:50:51,473 [foster.py] => Task 10, Epoch 150/170 => Loss 2.745, Loss_clf 0.289, Loss_fe 0.078, Loss_kd 2.309, Train_accy 87.08, Test_accy 71.30
2024-08-02 15:50:53,942 [foster.py] => Task 10, Epoch 151/170 => Loss 2.754, Loss_clf 0.296, Loss_fe 0.079, Loss_kd 2.310, Train_accy 86.02
2024-08-02 15:50:58,065 [foster.py] => Task 10, Epoch 152/170 => Loss 2.735, Loss_clf 0.272, Loss_fe 0.078, Loss_kd 2.315, Train_accy 86.40, Test_accy 71.33
2024-08-02 15:51:02,190 [foster.py] => Task 10, Epoch 153/170 => Loss 2.680, Loss_clf 0.263, Loss_fe 0.072, Loss_kd 2.276, Train_accy 86.10, Test_accy 71.30
2024-08-02 15:51:06,313 [foster.py] => Task 10, Epoch 154/170 => Loss 2.774, Loss_clf 0.293, Loss_fe 0.083, Loss_kd 2.328, Train_accy 86.74, Test_accy 71.30
2024-08-02 15:51:10,446 [foster.py] => Task 10, Epoch 155/170 => Loss 2.725, Loss_clf 0.288, Loss_fe 0.091, Loss_kd 2.278, Train_accy 85.72, Test_accy 71.30
2024-08-02 15:51:12,924 [foster.py] => Task 10, Epoch 156/170 => Loss 2.789, Loss_clf 0.298, Loss_fe 0.088, Loss_kd 2.333, Train_accy 86.61
2024-08-02 15:51:17,080 [foster.py] => Task 10, Epoch 157/170 => Loss 2.729, Loss_clf 0.257, Loss_fe 0.088, Loss_kd 2.314, Train_accy 86.78, Test_accy 71.27
2024-08-02 15:51:21,189 [foster.py] => Task 10, Epoch 158/170 => Loss 2.722, Loss_clf 0.272, Loss_fe 0.081, Loss_kd 2.299, Train_accy 86.10, Test_accy 71.37
2024-08-02 15:51:25,296 [foster.py] => Task 10, Epoch 159/170 => Loss 2.718, Loss_clf 0.274, Loss_fe 0.066, Loss_kd 2.309, Train_accy 86.10, Test_accy 71.33
2024-08-02 15:51:29,426 [foster.py] => Task 10, Epoch 160/170 => Loss 2.697, Loss_clf 0.260, Loss_fe 0.067, Loss_kd 2.301, Train_accy 86.95, Test_accy 71.33
2024-08-02 15:51:31,890 [foster.py] => Task 10, Epoch 161/170 => Loss 2.749, Loss_clf 0.278, Loss_fe 0.083, Loss_kd 2.318, Train_accy 86.99
2024-08-02 15:51:35,992 [foster.py] => Task 10, Epoch 162/170 => Loss 2.709, Loss_clf 0.268, Loss_fe 0.078, Loss_kd 2.295, Train_accy 87.20, Test_accy 71.30
2024-08-02 15:51:40,120 [foster.py] => Task 10, Epoch 163/170 => Loss 2.730, Loss_clf 0.279, Loss_fe 0.065, Loss_kd 2.316, Train_accy 86.36, Test_accy 71.36
2024-08-02 15:51:44,239 [foster.py] => Task 10, Epoch 164/170 => Loss 2.747, Loss_clf 0.292, Loss_fe 0.078, Loss_kd 2.307, Train_accy 86.10, Test_accy 71.29
2024-08-02 15:51:48,427 [foster.py] => Task 10, Epoch 165/170 => Loss 2.746, Loss_clf 0.280, Loss_fe 0.073, Loss_kd 2.323, Train_accy 86.74, Test_accy 71.31
2024-08-02 15:51:50,902 [foster.py] => Task 10, Epoch 166/170 => Loss 2.771, Loss_clf 0.288, Loss_fe 0.074, Loss_kd 2.339, Train_accy 86.78
2024-08-02 15:51:55,025 [foster.py] => Task 10, Epoch 167/170 => Loss 2.695, Loss_clf 0.260, Loss_fe 0.077, Loss_kd 2.289, Train_accy 87.20, Test_accy 71.34
2024-08-02 15:51:59,155 [foster.py] => Task 10, Epoch 168/170 => Loss 2.755, Loss_clf 0.303, Loss_fe 0.078, Loss_kd 2.304, Train_accy 85.76, Test_accy 71.33
2024-08-02 15:52:03,264 [foster.py] => Task 10, Epoch 169/170 => Loss 2.735, Loss_clf 0.269, Loss_fe 0.070, Loss_kd 2.326, Train_accy 86.36, Test_accy 71.34
2024-08-02 15:52:07,403 [foster.py] => Task 10, Epoch 170/170 => Loss 2.694, Loss_clf 0.245, Loss_fe 0.069, Loss_kd 2.310, Train_accy 87.46, Test_accy 71.43
2024-08-02 15:52:07,405 [foster.py] => do not weight align teacher!
2024-08-02 15:52:07,407 [foster.py] => per cls weights : [1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376 1.01557376
 1.01557376 1.01557376 0.47049201 0.47049201]
2024-08-02 15:52:12,075 [foster.py] => SNet: Task 10, Epoch 1/130 => Loss 29.006,  Loss1 0.728, Train_accy 51.27, Test_accy 67.59
2024-08-02 15:52:15,478 [foster.py] => SNet: Task 10, Epoch 2/130 => Loss 28.822,  Loss1 0.726, Train_accy 57.97
2024-08-02 15:52:18,897 [foster.py] => SNet: Task 10, Epoch 3/130 => Loss 28.832,  Loss1 0.726, Train_accy 60.89
2024-08-02 15:52:22,305 [foster.py] => SNet: Task 10, Epoch 4/130 => Loss 28.774,  Loss1 0.725, Train_accy 62.37
2024-08-02 15:52:25,716 [foster.py] => SNet: Task 10, Epoch 5/130 => Loss 28.774,  Loss1 0.725, Train_accy 64.28
2024-08-02 15:52:30,169 [foster.py] => SNet: Task 10, Epoch 6/130 => Loss 28.746,  Loss1 0.725, Train_accy 65.30, Test_accy 69.74
2024-08-02 15:52:33,555 [foster.py] => SNet: Task 10, Epoch 7/130 => Loss 28.786,  Loss1 0.725, Train_accy 66.14
2024-08-02 15:52:36,940 [foster.py] => SNet: Task 10, Epoch 8/130 => Loss 28.753,  Loss1 0.726, Train_accy 66.31
2024-08-02 15:52:40,350 [foster.py] => SNet: Task 10, Epoch 9/130 => Loss 28.782,  Loss1 0.725, Train_accy 67.37
2024-08-02 15:52:43,796 [foster.py] => SNet: Task 10, Epoch 10/130 => Loss 28.722,  Loss1 0.725, Train_accy 67.63
2024-08-02 15:52:48,255 [foster.py] => SNet: Task 10, Epoch 11/130 => Loss 28.713,  Loss1 0.726, Train_accy 68.18, Test_accy 70.19
2024-08-02 15:52:51,654 [foster.py] => SNet: Task 10, Epoch 12/130 => Loss 28.763,  Loss1 0.725, Train_accy 68.01
2024-08-02 15:52:55,043 [foster.py] => SNet: Task 10, Epoch 13/130 => Loss 28.755,  Loss1 0.726, Train_accy 68.09
2024-08-02 15:52:58,465 [foster.py] => SNet: Task 10, Epoch 14/130 => Loss 28.756,  Loss1 0.725, Train_accy 68.47
2024-08-02 15:53:01,860 [foster.py] => SNet: Task 10, Epoch 15/130 => Loss 28.765,  Loss1 0.725, Train_accy 69.07
2024-08-02 15:53:06,351 [foster.py] => SNet: Task 10, Epoch 16/130 => Loss 28.756,  Loss1 0.726, Train_accy 68.56, Test_accy 70.50
2024-08-02 15:53:09,725 [foster.py] => SNet: Task 10, Epoch 17/130 => Loss 28.767,  Loss1 0.725, Train_accy 69.92
2024-08-02 15:53:13,125 [foster.py] => SNet: Task 10, Epoch 18/130 => Loss 28.756,  Loss1 0.726, Train_accy 70.04
2024-08-02 15:53:16,509 [foster.py] => SNet: Task 10, Epoch 19/130 => Loss 28.792,  Loss1 0.725, Train_accy 69.28
2024-08-02 15:53:19,915 [foster.py] => SNet: Task 10, Epoch 20/130 => Loss 28.761,  Loss1 0.725, Train_accy 69.11
2024-08-02 15:53:24,377 [foster.py] => SNet: Task 10, Epoch 21/130 => Loss 28.783,  Loss1 0.725, Train_accy 71.23, Test_accy 70.26
2024-08-02 15:53:27,758 [foster.py] => SNet: Task 10, Epoch 22/130 => Loss 28.767,  Loss1 0.726, Train_accy 69.28
2024-08-02 15:53:31,152 [foster.py] => SNet: Task 10, Epoch 23/130 => Loss 28.749,  Loss1 0.725, Train_accy 70.59
2024-08-02 15:53:34,589 [foster.py] => SNet: Task 10, Epoch 24/130 => Loss 28.709,  Loss1 0.725, Train_accy 70.51
2024-08-02 15:53:37,962 [foster.py] => SNet: Task 10, Epoch 25/130 => Loss 28.744,  Loss1 0.725, Train_accy 69.58
2024-08-02 15:53:42,431 [foster.py] => SNet: Task 10, Epoch 26/130 => Loss 28.693,  Loss1 0.725, Train_accy 70.51, Test_accy 70.21
2024-08-02 15:53:45,844 [foster.py] => SNet: Task 10, Epoch 27/130 => Loss 28.725,  Loss1 0.725, Train_accy 71.61
2024-08-02 15:53:49,230 [foster.py] => SNet: Task 10, Epoch 28/130 => Loss 28.760,  Loss1 0.726, Train_accy 70.04
2024-08-02 15:53:52,689 [foster.py] => SNet: Task 10, Epoch 29/130 => Loss 28.789,  Loss1 0.726, Train_accy 70.64
2024-08-02 15:53:56,074 [foster.py] => SNet: Task 10, Epoch 30/130 => Loss 28.753,  Loss1 0.726, Train_accy 70.30
2024-08-02 15:54:00,562 [foster.py] => SNet: Task 10, Epoch 31/130 => Loss 28.684,  Loss1 0.725, Train_accy 71.61, Test_accy 70.46
2024-08-02 15:54:03,974 [foster.py] => SNet: Task 10, Epoch 32/130 => Loss 28.744,  Loss1 0.726, Train_accy 71.40
2024-08-02 15:54:07,377 [foster.py] => SNet: Task 10, Epoch 33/130 => Loss 28.750,  Loss1 0.725, Train_accy 72.63
2024-08-02 15:54:10,772 [foster.py] => SNet: Task 10, Epoch 34/130 => Loss 28.753,  Loss1 0.725, Train_accy 72.29
2024-08-02 15:54:14,193 [foster.py] => SNet: Task 10, Epoch 35/130 => Loss 28.754,  Loss1 0.726, Train_accy 70.51
2024-08-02 15:54:18,639 [foster.py] => SNet: Task 10, Epoch 36/130 => Loss 28.752,  Loss1 0.725, Train_accy 70.93, Test_accy 70.56
2024-08-02 15:54:22,055 [foster.py] => SNet: Task 10, Epoch 37/130 => Loss 28.749,  Loss1 0.725, Train_accy 73.05
2024-08-02 15:54:25,485 [foster.py] => SNet: Task 10, Epoch 38/130 => Loss 28.720,  Loss1 0.725, Train_accy 71.19
2024-08-02 15:54:28,911 [foster.py] => SNet: Task 10, Epoch 39/130 => Loss 28.729,  Loss1 0.725, Train_accy 72.37
2024-08-02 15:54:32,287 [foster.py] => SNet: Task 10, Epoch 40/130 => Loss 28.714,  Loss1 0.726, Train_accy 72.03
2024-08-02 15:54:36,781 [foster.py] => SNet: Task 10, Epoch 41/130 => Loss 28.778,  Loss1 0.726, Train_accy 71.61, Test_accy 70.61
2024-08-02 15:54:40,155 [foster.py] => SNet: Task 10, Epoch 42/130 => Loss 28.745,  Loss1 0.726, Train_accy 72.71
2024-08-02 15:54:43,537 [foster.py] => SNet: Task 10, Epoch 43/130 => Loss 28.756,  Loss1 0.726, Train_accy 73.22
2024-08-02 15:54:46,957 [foster.py] => SNet: Task 10, Epoch 44/130 => Loss 28.732,  Loss1 0.726, Train_accy 73.05
2024-08-02 15:54:50,359 [foster.py] => SNet: Task 10, Epoch 45/130 => Loss 28.762,  Loss1 0.725, Train_accy 71.99
2024-08-02 15:54:54,823 [foster.py] => SNet: Task 10, Epoch 46/130 => Loss 28.728,  Loss1 0.725, Train_accy 72.50, Test_accy 70.60
2024-08-02 15:54:58,229 [foster.py] => SNet: Task 10, Epoch 47/130 => Loss 28.732,  Loss1 0.725, Train_accy 70.59
2024-08-02 15:55:01,666 [foster.py] => SNet: Task 10, Epoch 48/130 => Loss 28.745,  Loss1 0.726, Train_accy 72.20
2024-08-02 15:55:05,075 [foster.py] => SNet: Task 10, Epoch 49/130 => Loss 28.779,  Loss1 0.726, Train_accy 73.81
2024-08-02 15:55:08,461 [foster.py] => SNet: Task 10, Epoch 50/130 => Loss 28.755,  Loss1 0.725, Train_accy 73.86
2024-08-02 15:55:12,918 [foster.py] => SNet: Task 10, Epoch 51/130 => Loss 28.746,  Loss1 0.725, Train_accy 72.71, Test_accy 70.40
2024-08-02 15:55:16,303 [foster.py] => SNet: Task 10, Epoch 52/130 => Loss 28.742,  Loss1 0.726, Train_accy 72.58
2024-08-02 15:55:19,703 [foster.py] => SNet: Task 10, Epoch 53/130 => Loss 28.754,  Loss1 0.726, Train_accy 72.25
2024-08-02 15:55:23,118 [foster.py] => SNet: Task 10, Epoch 54/130 => Loss 28.729,  Loss1 0.725, Train_accy 72.75
2024-08-02 15:55:26,501 [foster.py] => SNet: Task 10, Epoch 55/130 => Loss 28.754,  Loss1 0.726, Train_accy 72.08
2024-08-02 15:55:30,971 [foster.py] => SNet: Task 10, Epoch 56/130 => Loss 28.767,  Loss1 0.725, Train_accy 72.16, Test_accy 70.49
2024-08-02 15:55:34,383 [foster.py] => SNet: Task 10, Epoch 57/130 => Loss 28.767,  Loss1 0.725, Train_accy 72.12
2024-08-02 15:55:37,777 [foster.py] => SNet: Task 10, Epoch 58/130 => Loss 28.719,  Loss1 0.726, Train_accy 72.58
2024-08-02 15:55:41,190 [foster.py] => SNet: Task 10, Epoch 59/130 => Loss 28.764,  Loss1 0.725, Train_accy 71.61
2024-08-02 15:55:44,627 [foster.py] => SNet: Task 10, Epoch 60/130 => Loss 28.717,  Loss1 0.725, Train_accy 73.22
2024-08-02 15:55:49,074 [foster.py] => SNet: Task 10, Epoch 61/130 => Loss 28.709,  Loss1 0.726, Train_accy 72.71, Test_accy 70.60
2024-08-02 15:55:52,459 [foster.py] => SNet: Task 10, Epoch 62/130 => Loss 28.758,  Loss1 0.725, Train_accy 72.92
2024-08-02 15:55:55,850 [foster.py] => SNet: Task 10, Epoch 63/130 => Loss 28.751,  Loss1 0.725, Train_accy 73.05
2024-08-02 15:55:59,242 [foster.py] => SNet: Task 10, Epoch 64/130 => Loss 28.749,  Loss1 0.726, Train_accy 71.69
2024-08-02 15:56:02,645 [foster.py] => SNet: Task 10, Epoch 65/130 => Loss 28.726,  Loss1 0.726, Train_accy 72.67
2024-08-02 15:56:07,129 [foster.py] => SNet: Task 10, Epoch 66/130 => Loss 28.689,  Loss1 0.726, Train_accy 74.28, Test_accy 70.51
2024-08-02 15:56:10,600 [foster.py] => SNet: Task 10, Epoch 67/130 => Loss 28.696,  Loss1 0.725, Train_accy 73.69
2024-08-02 15:56:13,994 [foster.py] => SNet: Task 10, Epoch 68/130 => Loss 28.707,  Loss1 0.725, Train_accy 73.60
2024-08-02 15:56:17,379 [foster.py] => SNet: Task 10, Epoch 69/130 => Loss 28.755,  Loss1 0.726, Train_accy 73.01
2024-08-02 15:56:20,751 [foster.py] => SNet: Task 10, Epoch 70/130 => Loss 28.688,  Loss1 0.726, Train_accy 74.24
2024-08-02 15:56:25,208 [foster.py] => SNet: Task 10, Epoch 71/130 => Loss 28.777,  Loss1 0.725, Train_accy 72.58, Test_accy 70.31
2024-08-02 15:56:28,592 [foster.py] => SNet: Task 10, Epoch 72/130 => Loss 28.769,  Loss1 0.725, Train_accy 72.33
2024-08-02 15:56:31,984 [foster.py] => SNet: Task 10, Epoch 73/130 => Loss 28.757,  Loss1 0.726, Train_accy 73.26
2024-08-02 15:56:35,388 [foster.py] => SNet: Task 10, Epoch 74/130 => Loss 28.739,  Loss1 0.725, Train_accy 73.09
2024-08-02 15:56:38,771 [foster.py] => SNet: Task 10, Epoch 75/130 => Loss 28.743,  Loss1 0.726, Train_accy 73.18
2024-08-02 15:56:43,252 [foster.py] => SNet: Task 10, Epoch 76/130 => Loss 28.756,  Loss1 0.725, Train_accy 73.14, Test_accy 70.73
2024-08-02 15:56:46,668 [foster.py] => SNet: Task 10, Epoch 77/130 => Loss 28.747,  Loss1 0.725, Train_accy 74.07
2024-08-02 15:56:50,055 [foster.py] => SNet: Task 10, Epoch 78/130 => Loss 28.719,  Loss1 0.726, Train_accy 73.94
2024-08-02 15:56:53,457 [foster.py] => SNet: Task 10, Epoch 79/130 => Loss 28.693,  Loss1 0.725, Train_accy 73.69
2024-08-02 15:56:56,853 [foster.py] => SNet: Task 10, Epoch 80/130 => Loss 28.732,  Loss1 0.725, Train_accy 73.73
2024-08-02 15:57:01,276 [foster.py] => SNet: Task 10, Epoch 81/130 => Loss 28.782,  Loss1 0.726, Train_accy 72.88, Test_accy 70.69
2024-08-02 15:57:04,698 [foster.py] => SNet: Task 10, Epoch 82/130 => Loss 28.739,  Loss1 0.726, Train_accy 74.15
2024-08-02 15:57:08,107 [foster.py] => SNet: Task 10, Epoch 83/130 => Loss 28.777,  Loss1 0.726, Train_accy 74.32
2024-08-02 15:57:11,528 [foster.py] => SNet: Task 10, Epoch 84/130 => Loss 28.746,  Loss1 0.725, Train_accy 74.03
2024-08-02 15:57:14,948 [foster.py] => SNet: Task 10, Epoch 85/130 => Loss 28.671,  Loss1 0.726, Train_accy 72.84
2024-08-02 15:57:19,472 [foster.py] => SNet: Task 10, Epoch 86/130 => Loss 28.689,  Loss1 0.726, Train_accy 73.73, Test_accy 70.63
2024-08-02 15:57:22,887 [foster.py] => SNet: Task 10, Epoch 87/130 => Loss 28.725,  Loss1 0.725, Train_accy 73.94
2024-08-02 15:57:26,272 [foster.py] => SNet: Task 10, Epoch 88/130 => Loss 28.730,  Loss1 0.725, Train_accy 73.01
2024-08-02 15:57:29,643 [foster.py] => SNet: Task 10, Epoch 89/130 => Loss 28.721,  Loss1 0.725, Train_accy 71.78
2024-08-02 15:57:33,015 [foster.py] => SNet: Task 10, Epoch 90/130 => Loss 28.736,  Loss1 0.725, Train_accy 73.05
2024-08-02 15:57:37,464 [foster.py] => SNet: Task 10, Epoch 91/130 => Loss 28.715,  Loss1 0.726, Train_accy 73.31, Test_accy 70.80
2024-08-02 15:57:40,844 [foster.py] => SNet: Task 10, Epoch 92/130 => Loss 28.732,  Loss1 0.725, Train_accy 73.98
2024-08-02 15:57:44,256 [foster.py] => SNet: Task 10, Epoch 93/130 => Loss 28.767,  Loss1 0.725, Train_accy 73.26
2024-08-02 15:57:47,661 [foster.py] => SNet: Task 10, Epoch 94/130 => Loss 28.760,  Loss1 0.725, Train_accy 73.73
2024-08-02 15:57:51,080 [foster.py] => SNet: Task 10, Epoch 95/130 => Loss 28.732,  Loss1 0.726, Train_accy 73.52
2024-08-02 15:57:55,555 [foster.py] => SNet: Task 10, Epoch 96/130 => Loss 28.803,  Loss1 0.725, Train_accy 71.99, Test_accy 70.51
2024-08-02 15:57:58,943 [foster.py] => SNet: Task 10, Epoch 97/130 => Loss 28.771,  Loss1 0.725, Train_accy 72.71
2024-08-02 15:58:02,394 [foster.py] => SNet: Task 10, Epoch 98/130 => Loss 28.764,  Loss1 0.726, Train_accy 72.97
2024-08-02 15:58:05,805 [foster.py] => SNet: Task 10, Epoch 99/130 => Loss 28.734,  Loss1 0.725, Train_accy 73.98
2024-08-02 15:58:09,183 [foster.py] => SNet: Task 10, Epoch 100/130 => Loss 28.732,  Loss1 0.726, Train_accy 72.67
2024-08-02 15:58:13,657 [foster.py] => SNet: Task 10, Epoch 101/130 => Loss 28.751,  Loss1 0.726, Train_accy 75.81, Test_accy 70.77
2024-08-02 15:58:17,057 [foster.py] => SNet: Task 10, Epoch 102/130 => Loss 28.748,  Loss1 0.726, Train_accy 73.14
2024-08-02 15:58:20,431 [foster.py] => SNet: Task 10, Epoch 103/130 => Loss 28.726,  Loss1 0.726, Train_accy 73.39
2024-08-02 15:58:23,827 [foster.py] => SNet: Task 10, Epoch 104/130 => Loss 28.768,  Loss1 0.726, Train_accy 73.18
2024-08-02 15:58:27,294 [foster.py] => SNet: Task 10, Epoch 105/130 => Loss 28.740,  Loss1 0.726, Train_accy 73.31
2024-08-02 15:58:31,773 [foster.py] => SNet: Task 10, Epoch 106/130 => Loss 28.767,  Loss1 0.726, Train_accy 73.69, Test_accy 70.30
2024-08-02 15:58:35,192 [foster.py] => SNet: Task 10, Epoch 107/130 => Loss 28.726,  Loss1 0.725, Train_accy 73.18
2024-08-02 15:58:38,558 [foster.py] => SNet: Task 10, Epoch 108/130 => Loss 28.769,  Loss1 0.726, Train_accy 72.25
2024-08-02 15:58:41,961 [foster.py] => SNet: Task 10, Epoch 109/130 => Loss 28.776,  Loss1 0.725, Train_accy 73.56
2024-08-02 15:58:45,351 [foster.py] => SNet: Task 10, Epoch 110/130 => Loss 28.766,  Loss1 0.726, Train_accy 74.58
2024-08-02 15:58:49,809 [foster.py] => SNet: Task 10, Epoch 111/130 => Loss 28.766,  Loss1 0.726, Train_accy 74.58, Test_accy 70.57
2024-08-02 15:58:53,228 [foster.py] => SNet: Task 10, Epoch 112/130 => Loss 28.754,  Loss1 0.726, Train_accy 73.86
2024-08-02 15:58:56,601 [foster.py] => SNet: Task 10, Epoch 113/130 => Loss 28.740,  Loss1 0.725, Train_accy 72.71
2024-08-02 15:58:59,996 [foster.py] => SNet: Task 10, Epoch 114/130 => Loss 28.754,  Loss1 0.726, Train_accy 73.18
2024-08-02 15:59:03,365 [foster.py] => SNet: Task 10, Epoch 115/130 => Loss 28.736,  Loss1 0.725, Train_accy 74.49
2024-08-02 15:59:07,853 [foster.py] => SNet: Task 10, Epoch 116/130 => Loss 28.736,  Loss1 0.726, Train_accy 73.22, Test_accy 70.39
2024-08-02 15:59:11,248 [foster.py] => SNet: Task 10, Epoch 117/130 => Loss 28.743,  Loss1 0.725, Train_accy 73.90
2024-08-02 15:59:14,666 [foster.py] => SNet: Task 10, Epoch 118/130 => Loss 28.733,  Loss1 0.725, Train_accy 73.31
2024-08-02 15:59:18,059 [foster.py] => SNet: Task 10, Epoch 119/130 => Loss 28.709,  Loss1 0.726, Train_accy 73.73
2024-08-02 15:59:21,461 [foster.py] => SNet: Task 10, Epoch 120/130 => Loss 28.753,  Loss1 0.725, Train_accy 73.64
2024-08-02 15:59:25,885 [foster.py] => SNet: Task 10, Epoch 121/130 => Loss 28.778,  Loss1 0.725, Train_accy 73.77, Test_accy 70.46
2024-08-02 15:59:29,260 [foster.py] => SNet: Task 10, Epoch 122/130 => Loss 28.767,  Loss1 0.726, Train_accy 72.97
2024-08-02 15:59:32,629 [foster.py] => SNet: Task 10, Epoch 123/130 => Loss 28.759,  Loss1 0.725, Train_accy 73.64
2024-08-02 15:59:36,117 [foster.py] => SNet: Task 10, Epoch 124/130 => Loss 28.700,  Loss1 0.726, Train_accy 73.73
2024-08-02 15:59:39,517 [foster.py] => SNet: Task 10, Epoch 125/130 => Loss 28.758,  Loss1 0.725, Train_accy 73.98
2024-08-02 15:59:44,012 [foster.py] => SNet: Task 10, Epoch 126/130 => Loss 28.745,  Loss1 0.725, Train_accy 73.64, Test_accy 70.56
2024-08-02 15:59:47,395 [foster.py] => SNet: Task 10, Epoch 127/130 => Loss 28.778,  Loss1 0.726, Train_accy 72.97
2024-08-02 15:59:50,786 [foster.py] => SNet: Task 10, Epoch 128/130 => Loss 28.696,  Loss1 0.725, Train_accy 74.11
2024-08-02 15:59:54,212 [foster.py] => SNet: Task 10, Epoch 129/130 => Loss 28.747,  Loss1 0.725, Train_accy 74.53
2024-08-02 15:59:57,601 [foster.py] => SNet: Task 10, Epoch 130/130 => Loss 28.812,  Loss1 0.725, Train_accy 73.43
2024-08-02 15:59:57,603 [foster.py] => do not weight align student!
2024-08-02 15:59:58,674 [foster.py] => darknet eval: 
2024-08-02 15:59:58,675 [foster.py] => CNN top1 curve: 70.61
2024-08-02 15:59:58,676 [foster.py] => CNN top5 curve: 91.99
2024-08-02 15:59:58,676 [foster.py] => CNN top1 平均值: 70.61
2024-08-02 15:59:58,681 [foster.py] => timees : 1117.3294327259064
2024-08-02 15:59:58,683 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 16:00:20,023 [foster.py] => Exemplar size: 1400
2024-08-02 16:00:20,024 [trainer.py] => CNN: {'total': 71.43, '00-09': 77.5, '10-19': 64.5, '20-29': 78.3, '30-39': 70.7, '40-49': 76.8, '50-59': 62.4, '60-69': 69.8, 'old': 71.41, 'new': 72.0}
2024-08-02 16:00:20,024 [trainer.py] => NME: {'total': 67.61, '00-09': 70.0, '10-19': 59.4, '20-29': 71.8, '30-39': 64.8, '40-49': 71.0, '50-59': 65.7, '60-69': 70.6, 'old': 66.87, 'new': 93.0}
2024-08-02 16:00:20,024 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43]
2024-08-02 16:00:20,027 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31]
2024-08-02 16:00:20,027 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61]
2024-08-02 16:00:20,027 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91]

2024-08-02 16:00:20,028 [trainer.py] => CNN top1 平均值: 76.38
2024-08-02 16:00:20,030 [trainer.py] => All params: 1172548
2024-08-02 16:00:20,033 [trainer.py] => Trainable params: 590854
2024-08-02 16:00:20,095 [foster.py] => Learning on 70-72
2024-08-02 16:00:20,098 [foster.py] => All params: 1173066
2024-08-02 16:00:20,100 [foster.py] => Trainable params: 591242
2024-08-02 16:00:20,138 [foster.py] => per cls weights : [1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  1.0127403  1.0127403
 1.0127403  1.0127403  1.0127403  1.0127403  0.55408956 0.55408956]
2024-08-02 16:00:22,743 [foster.py] => Task 11, Epoch 1/170 => Loss 5.350, Loss_clf 0.885, Loss_fe 1.895, Loss_kd 2.497, Train_accy 67.96
2024-08-02 16:00:26,931 [foster.py] => Task 11, Epoch 2/170 => Loss 3.901, Loss_clf 0.573, Loss_fe 0.787, Loss_kd 2.468, Train_accy 75.08, Test_accy 68.43
2024-08-02 16:00:31,212 [foster.py] => Task 11, Epoch 3/170 => Loss 3.681, Loss_clf 0.494, Loss_fe 0.664, Loss_kd 2.451, Train_accy 74.50, Test_accy 69.86
2024-08-02 16:00:35,404 [foster.py] => Task 11, Epoch 4/170 => Loss 3.635, Loss_clf 0.513, Loss_fe 0.585, Loss_kd 2.466, Train_accy 76.04, Test_accy 69.79
2024-08-02 16:00:39,567 [foster.py] => Task 11, Epoch 5/170 => Loss 3.556, Loss_clf 0.492, Loss_fe 0.518, Loss_kd 2.474, Train_accy 77.04, Test_accy 69.38
2024-08-02 16:00:42,044 [foster.py] => Task 11, Epoch 6/170 => Loss 3.529, Loss_clf 0.491, Loss_fe 0.495, Loss_kd 2.471, Train_accy 77.62
2024-08-02 16:00:46,233 [foster.py] => Task 11, Epoch 7/170 => Loss 3.501, Loss_clf 0.489, Loss_fe 0.484, Loss_kd 2.456, Train_accy 77.29, Test_accy 69.92
2024-08-02 16:00:50,419 [foster.py] => Task 11, Epoch 8/170 => Loss 3.451, Loss_clf 0.468, Loss_fe 0.463, Loss_kd 2.448, Train_accy 77.08, Test_accy 69.81
2024-08-02 16:00:54,595 [foster.py] => Task 11, Epoch 9/170 => Loss 3.434, Loss_clf 0.451, Loss_fe 0.450, Loss_kd 2.461, Train_accy 78.92, Test_accy 70.11
2024-08-02 16:00:58,816 [foster.py] => Task 11, Epoch 10/170 => Loss 3.437, Loss_clf 0.463, Loss_fe 0.423, Loss_kd 2.478, Train_accy 79.00, Test_accy 70.10
2024-08-02 16:01:01,280 [foster.py] => Task 11, Epoch 11/170 => Loss 3.331, Loss_clf 0.424, Loss_fe 0.393, Loss_kd 2.443, Train_accy 79.79
2024-08-02 16:01:05,457 [foster.py] => Task 11, Epoch 12/170 => Loss 3.337, Loss_clf 0.416, Loss_fe 0.390, Loss_kd 2.460, Train_accy 80.83, Test_accy 69.51
2024-08-02 16:01:09,619 [foster.py] => Task 11, Epoch 13/170 => Loss 3.348, Loss_clf 0.440, Loss_fe 0.387, Loss_kd 2.449, Train_accy 79.67, Test_accy 69.39
2024-08-02 16:01:13,806 [foster.py] => Task 11, Epoch 14/170 => Loss 3.383, Loss_clf 0.458, Loss_fe 0.376, Loss_kd 2.476, Train_accy 78.04, Test_accy 68.96
2024-08-02 16:01:17,961 [foster.py] => Task 11, Epoch 15/170 => Loss 3.332, Loss_clf 0.423, Loss_fe 0.389, Loss_kd 2.448, Train_accy 80.67, Test_accy 69.62
2024-08-02 16:01:20,450 [foster.py] => Task 11, Epoch 16/170 => Loss 3.339, Loss_clf 0.436, Loss_fe 0.385, Loss_kd 2.446, Train_accy 79.17
2024-08-02 16:01:24,631 [foster.py] => Task 11, Epoch 17/170 => Loss 3.335, Loss_clf 0.450, Loss_fe 0.370, Loss_kd 2.444, Train_accy 79.21, Test_accy 69.69
2024-08-02 16:01:28,794 [foster.py] => Task 11, Epoch 18/170 => Loss 3.302, Loss_clf 0.432, Loss_fe 0.342, Loss_kd 2.456, Train_accy 79.75, Test_accy 69.89
2024-08-02 16:01:32,949 [foster.py] => Task 11, Epoch 19/170 => Loss 3.273, Loss_clf 0.417, Loss_fe 0.329, Loss_kd 2.455, Train_accy 82.12, Test_accy 69.11
2024-08-02 16:01:37,161 [foster.py] => Task 11, Epoch 20/170 => Loss 3.272, Loss_clf 0.418, Loss_fe 0.328, Loss_kd 2.454, Train_accy 80.71, Test_accy 70.25
2024-08-02 16:01:39,628 [foster.py] => Task 11, Epoch 21/170 => Loss 3.262, Loss_clf 0.412, Loss_fe 0.326, Loss_kd 2.452, Train_accy 81.04
2024-08-02 16:01:43,801 [foster.py] => Task 11, Epoch 22/170 => Loss 3.273, Loss_clf 0.406, Loss_fe 0.351, Loss_kd 2.444, Train_accy 81.67, Test_accy 69.58
2024-08-02 16:01:47,972 [foster.py] => Task 11, Epoch 23/170 => Loss 3.293, Loss_clf 0.428, Loss_fe 0.321, Loss_kd 2.471, Train_accy 79.83, Test_accy 69.68
2024-08-02 16:01:52,153 [foster.py] => Task 11, Epoch 24/170 => Loss 3.226, Loss_clf 0.415, Loss_fe 0.294, Loss_kd 2.445, Train_accy 79.08, Test_accy 69.96
2024-08-02 16:01:56,326 [foster.py] => Task 11, Epoch 25/170 => Loss 3.295, Loss_clf 0.427, Loss_fe 0.335, Loss_kd 2.461, Train_accy 80.62, Test_accy 70.15
2024-08-02 16:01:58,790 [foster.py] => Task 11, Epoch 26/170 => Loss 3.302, Loss_clf 0.411, Loss_fe 0.343, Loss_kd 2.476, Train_accy 81.00
2024-08-02 16:02:02,959 [foster.py] => Task 11, Epoch 27/170 => Loss 3.209, Loss_clf 0.399, Loss_fe 0.308, Loss_kd 2.431, Train_accy 81.50, Test_accy 70.06
2024-08-02 16:02:07,143 [foster.py] => Task 11, Epoch 28/170 => Loss 3.268, Loss_clf 0.399, Loss_fe 0.305, Loss_kd 2.491, Train_accy 82.62, Test_accy 69.92
2024-08-02 16:02:11,360 [foster.py] => Task 11, Epoch 29/170 => Loss 3.218, Loss_clf 0.385, Loss_fe 0.307, Loss_kd 2.455, Train_accy 82.71, Test_accy 69.96
2024-08-02 16:02:15,540 [foster.py] => Task 11, Epoch 30/170 => Loss 3.227, Loss_clf 0.405, Loss_fe 0.298, Loss_kd 2.453, Train_accy 80.50, Test_accy 70.08
2024-08-02 16:02:18,049 [foster.py] => Task 11, Epoch 31/170 => Loss 3.222, Loss_clf 0.391, Loss_fe 0.297, Loss_kd 2.462, Train_accy 82.00
2024-08-02 16:02:22,243 [foster.py] => Task 11, Epoch 32/170 => Loss 3.200, Loss_clf 0.383, Loss_fe 0.290, Loss_kd 2.456, Train_accy 82.25, Test_accy 69.64
2024-08-02 16:02:26,403 [foster.py] => Task 11, Epoch 33/170 => Loss 3.133, Loss_clf 0.362, Loss_fe 0.277, Loss_kd 2.423, Train_accy 82.38, Test_accy 69.29
2024-08-02 16:02:30,581 [foster.py] => Task 11, Epoch 34/170 => Loss 3.114, Loss_clf 0.358, Loss_fe 0.266, Loss_kd 2.419, Train_accy 82.33, Test_accy 70.46
2024-08-02 16:02:34,766 [foster.py] => Task 11, Epoch 35/170 => Loss 3.235, Loss_clf 0.401, Loss_fe 0.297, Loss_kd 2.465, Train_accy 82.71, Test_accy 69.35
2024-08-02 16:02:37,217 [foster.py] => Task 11, Epoch 36/170 => Loss 3.233, Loss_clf 0.390, Loss_fe 0.297, Loss_kd 2.474, Train_accy 83.04
2024-08-02 16:02:41,368 [foster.py] => Task 11, Epoch 37/170 => Loss 3.244, Loss_clf 0.410, Loss_fe 0.290, Loss_kd 2.472, Train_accy 82.62, Test_accy 70.18
2024-08-02 16:02:45,523 [foster.py] => Task 11, Epoch 38/170 => Loss 3.155, Loss_clf 0.375, Loss_fe 0.270, Loss_kd 2.438, Train_accy 82.67, Test_accy 70.17
2024-08-02 16:02:49,714 [foster.py] => Task 11, Epoch 39/170 => Loss 3.188, Loss_clf 0.384, Loss_fe 0.276, Loss_kd 2.457, Train_accy 83.75, Test_accy 69.19
2024-08-02 16:02:53,912 [foster.py] => Task 11, Epoch 40/170 => Loss 3.171, Loss_clf 0.382, Loss_fe 0.257, Loss_kd 2.459, Train_accy 82.75, Test_accy 70.31
2024-08-02 16:02:56,371 [foster.py] => Task 11, Epoch 41/170 => Loss 3.131, Loss_clf 0.373, Loss_fe 0.262, Loss_kd 2.425, Train_accy 82.50
2024-08-02 16:03:00,538 [foster.py] => Task 11, Epoch 42/170 => Loss 3.207, Loss_clf 0.393, Loss_fe 0.293, Loss_kd 2.450, Train_accy 83.42, Test_accy 70.33
2024-08-02 16:03:04,694 [foster.py] => Task 11, Epoch 43/170 => Loss 3.209, Loss_clf 0.402, Loss_fe 0.268, Loss_kd 2.467, Train_accy 82.88, Test_accy 69.61
2024-08-02 16:03:08,882 [foster.py] => Task 11, Epoch 44/170 => Loss 3.168, Loss_clf 0.390, Loss_fe 0.270, Loss_kd 2.436, Train_accy 83.54, Test_accy 69.90
2024-08-02 16:03:13,042 [foster.py] => Task 11, Epoch 45/170 => Loss 3.104, Loss_clf 0.359, Loss_fe 0.246, Loss_kd 2.428, Train_accy 84.04, Test_accy 70.28
2024-08-02 16:03:15,485 [foster.py] => Task 11, Epoch 46/170 => Loss 3.186, Loss_clf 0.398, Loss_fe 0.279, Loss_kd 2.437, Train_accy 82.04
2024-08-02 16:03:19,699 [foster.py] => Task 11, Epoch 47/170 => Loss 3.163, Loss_clf 0.372, Loss_fe 0.244, Loss_kd 2.475, Train_accy 84.54, Test_accy 70.06
2024-08-02 16:03:23,873 [foster.py] => Task 11, Epoch 48/170 => Loss 3.141, Loss_clf 0.368, Loss_fe 0.265, Loss_kd 2.437, Train_accy 83.75, Test_accy 70.60
2024-08-02 16:03:28,031 [foster.py] => Task 11, Epoch 49/170 => Loss 3.196, Loss_clf 0.402, Loss_fe 0.260, Loss_kd 2.463, Train_accy 83.17, Test_accy 70.29
2024-08-02 16:03:32,205 [foster.py] => Task 11, Epoch 50/170 => Loss 3.104, Loss_clf 0.353, Loss_fe 0.237, Loss_kd 2.443, Train_accy 84.62, Test_accy 70.39
2024-08-02 16:03:34,645 [foster.py] => Task 11, Epoch 51/170 => Loss 3.164, Loss_clf 0.389, Loss_fe 0.249, Loss_kd 2.454, Train_accy 84.08
2024-08-02 16:03:38,854 [foster.py] => Task 11, Epoch 52/170 => Loss 3.165, Loss_clf 0.383, Loss_fe 0.246, Loss_kd 2.465, Train_accy 84.17, Test_accy 70.33
2024-08-02 16:03:43,042 [foster.py] => Task 11, Epoch 53/170 => Loss 3.140, Loss_clf 0.363, Loss_fe 0.241, Loss_kd 2.464, Train_accy 84.46, Test_accy 70.17
2024-08-02 16:03:47,197 [foster.py] => Task 11, Epoch 54/170 => Loss 3.156, Loss_clf 0.374, Loss_fe 0.230, Loss_kd 2.479, Train_accy 83.92, Test_accy 70.36
2024-08-02 16:03:51,469 [foster.py] => Task 11, Epoch 55/170 => Loss 3.082, Loss_clf 0.345, Loss_fe 0.228, Loss_kd 2.437, Train_accy 86.00, Test_accy 70.64
2024-08-02 16:03:54,056 [foster.py] => Task 11, Epoch 56/170 => Loss 3.130, Loss_clf 0.368, Loss_fe 0.236, Loss_kd 2.454, Train_accy 83.75
2024-08-02 16:03:58,242 [foster.py] => Task 11, Epoch 57/170 => Loss 3.222, Loss_clf 0.405, Loss_fe 0.259, Loss_kd 2.485, Train_accy 83.04, Test_accy 70.06
2024-08-02 16:04:02,399 [foster.py] => Task 11, Epoch 58/170 => Loss 3.114, Loss_clf 0.360, Loss_fe 0.212, Loss_kd 2.469, Train_accy 84.96, Test_accy 70.44
2024-08-02 16:04:06,594 [foster.py] => Task 11, Epoch 59/170 => Loss 3.105, Loss_clf 0.369, Loss_fe 0.223, Loss_kd 2.442, Train_accy 83.75, Test_accy 70.08
2024-08-02 16:04:10,752 [foster.py] => Task 11, Epoch 60/170 => Loss 3.145, Loss_clf 0.375, Loss_fe 0.230, Loss_kd 2.468, Train_accy 84.25, Test_accy 70.46
2024-08-02 16:04:13,222 [foster.py] => Task 11, Epoch 61/170 => Loss 3.053, Loss_clf 0.343, Loss_fe 0.206, Loss_kd 2.433, Train_accy 87.29
2024-08-02 16:04:17,364 [foster.py] => Task 11, Epoch 62/170 => Loss 3.135, Loss_clf 0.373, Loss_fe 0.223, Loss_kd 2.466, Train_accy 84.17, Test_accy 70.18
2024-08-02 16:04:21,559 [foster.py] => Task 11, Epoch 63/170 => Loss 3.090, Loss_clf 0.355, Loss_fe 0.225, Loss_kd 2.439, Train_accy 85.17, Test_accy 69.79
2024-08-02 16:04:25,726 [foster.py] => Task 11, Epoch 64/170 => Loss 3.146, Loss_clf 0.374, Loss_fe 0.209, Loss_kd 2.491, Train_accy 85.00, Test_accy 70.39
2024-08-02 16:04:29,945 [foster.py] => Task 11, Epoch 65/170 => Loss 3.068, Loss_clf 0.337, Loss_fe 0.204, Loss_kd 2.455, Train_accy 85.38, Test_accy 70.24
2024-08-02 16:04:32,491 [foster.py] => Task 11, Epoch 66/170 => Loss 3.058, Loss_clf 0.335, Loss_fe 0.210, Loss_kd 2.441, Train_accy 86.21
2024-08-02 16:04:36,656 [foster.py] => Task 11, Epoch 67/170 => Loss 3.152, Loss_clf 0.375, Loss_fe 0.228, Loss_kd 2.477, Train_accy 85.08, Test_accy 69.99
2024-08-02 16:04:40,848 [foster.py] => Task 11, Epoch 68/170 => Loss 3.091, Loss_clf 0.368, Loss_fe 0.208, Loss_kd 2.443, Train_accy 84.58, Test_accy 70.71
2024-08-02 16:04:44,997 [foster.py] => Task 11, Epoch 69/170 => Loss 3.055, Loss_clf 0.334, Loss_fe 0.203, Loss_kd 2.448, Train_accy 85.88, Test_accy 70.58
2024-08-02 16:04:49,171 [foster.py] => Task 11, Epoch 70/170 => Loss 3.128, Loss_clf 0.359, Loss_fe 0.212, Loss_kd 2.485, Train_accy 85.42, Test_accy 69.99
2024-08-02 16:04:51,629 [foster.py] => Task 11, Epoch 71/170 => Loss 3.045, Loss_clf 0.330, Loss_fe 0.197, Loss_kd 2.446, Train_accy 85.58
2024-08-02 16:04:55,772 [foster.py] => Task 11, Epoch 72/170 => Loss 3.076, Loss_clf 0.360, Loss_fe 0.183, Loss_kd 2.461, Train_accy 84.96, Test_accy 70.35
2024-08-02 16:05:00,002 [foster.py] => Task 11, Epoch 73/170 => Loss 3.078, Loss_clf 0.359, Loss_fe 0.215, Loss_kd 2.433, Train_accy 85.96, Test_accy 70.38
2024-08-02 16:05:04,234 [foster.py] => Task 11, Epoch 74/170 => Loss 3.062, Loss_clf 0.327, Loss_fe 0.204, Loss_kd 2.459, Train_accy 85.67, Test_accy 70.54
2024-08-02 16:05:08,416 [foster.py] => Task 11, Epoch 75/170 => Loss 3.012, Loss_clf 0.322, Loss_fe 0.198, Loss_kd 2.421, Train_accy 86.29, Test_accy 70.18
2024-08-02 16:05:10,889 [foster.py] => Task 11, Epoch 76/170 => Loss 3.061, Loss_clf 0.340, Loss_fe 0.180, Loss_kd 2.469, Train_accy 86.62
2024-08-02 16:05:15,058 [foster.py] => Task 11, Epoch 77/170 => Loss 3.033, Loss_clf 0.338, Loss_fe 0.181, Loss_kd 2.443, Train_accy 86.67, Test_accy 70.29
2024-08-02 16:05:19,238 [foster.py] => Task 11, Epoch 78/170 => Loss 3.072, Loss_clf 0.346, Loss_fe 0.186, Loss_kd 2.469, Train_accy 85.50, Test_accy 70.39
2024-08-02 16:05:23,420 [foster.py] => Task 11, Epoch 79/170 => Loss 3.031, Loss_clf 0.334, Loss_fe 0.180, Loss_kd 2.446, Train_accy 85.96, Test_accy 70.33
2024-08-02 16:05:27,602 [foster.py] => Task 11, Epoch 80/170 => Loss 3.029, Loss_clf 0.333, Loss_fe 0.173, Loss_kd 2.452, Train_accy 86.46, Test_accy 70.82
2024-08-02 16:05:30,067 [foster.py] => Task 11, Epoch 81/170 => Loss 3.062, Loss_clf 0.351, Loss_fe 0.184, Loss_kd 2.454, Train_accy 85.54
2024-08-02 16:05:34,266 [foster.py] => Task 11, Epoch 82/170 => Loss 3.074, Loss_clf 0.361, Loss_fe 0.178, Loss_kd 2.463, Train_accy 85.67, Test_accy 70.60
2024-08-02 16:05:38,411 [foster.py] => Task 11, Epoch 83/170 => Loss 3.065, Loss_clf 0.356, Loss_fe 0.176, Loss_kd 2.461, Train_accy 86.04, Test_accy 70.15
2024-08-02 16:05:42,569 [foster.py] => Task 11, Epoch 84/170 => Loss 3.073, Loss_clf 0.355, Loss_fe 0.191, Loss_kd 2.455, Train_accy 85.00, Test_accy 70.01
2024-08-02 16:05:46,748 [foster.py] => Task 11, Epoch 85/170 => Loss 3.008, Loss_clf 0.329, Loss_fe 0.180, Loss_kd 2.427, Train_accy 86.33, Test_accy 70.15
2024-08-02 16:05:49,252 [foster.py] => Task 11, Epoch 86/170 => Loss 3.093, Loss_clf 0.365, Loss_fe 0.194, Loss_kd 2.463, Train_accy 86.12
2024-08-02 16:05:53,415 [foster.py] => Task 11, Epoch 87/170 => Loss 3.045, Loss_clf 0.343, Loss_fe 0.181, Loss_kd 2.450, Train_accy 86.33, Test_accy 70.26
2024-08-02 16:05:57,618 [foster.py] => Task 11, Epoch 88/170 => Loss 3.014, Loss_clf 0.314, Loss_fe 0.170, Loss_kd 2.459, Train_accy 87.54, Test_accy 70.50
2024-08-02 16:06:01,823 [foster.py] => Task 11, Epoch 89/170 => Loss 3.030, Loss_clf 0.325, Loss_fe 0.152, Loss_kd 2.480, Train_accy 86.96, Test_accy 70.65
2024-08-02 16:06:06,042 [foster.py] => Task 11, Epoch 90/170 => Loss 3.063, Loss_clf 0.351, Loss_fe 0.159, Loss_kd 2.481, Train_accy 87.21, Test_accy 70.28
2024-08-02 16:06:08,538 [foster.py] => Task 11, Epoch 91/170 => Loss 2.983, Loss_clf 0.321, Loss_fe 0.162, Loss_kd 2.429, Train_accy 87.29
2024-08-02 16:06:12,729 [foster.py] => Task 11, Epoch 92/170 => Loss 2.999, Loss_clf 0.323, Loss_fe 0.170, Loss_kd 2.435, Train_accy 87.12, Test_accy 70.42
2024-08-02 16:06:16,941 [foster.py] => Task 11, Epoch 93/170 => Loss 3.021, Loss_clf 0.339, Loss_fe 0.157, Loss_kd 2.453, Train_accy 87.21, Test_accy 70.21
2024-08-02 16:06:21,161 [foster.py] => Task 11, Epoch 94/170 => Loss 3.001, Loss_clf 0.322, Loss_fe 0.155, Loss_kd 2.453, Train_accy 87.29, Test_accy 70.29
2024-08-02 16:06:25,313 [foster.py] => Task 11, Epoch 95/170 => Loss 3.024, Loss_clf 0.333, Loss_fe 0.162, Loss_kd 2.458, Train_accy 86.75, Test_accy 69.82
2024-08-02 16:06:27,777 [foster.py] => Task 11, Epoch 96/170 => Loss 2.992, Loss_clf 0.323, Loss_fe 0.150, Loss_kd 2.448, Train_accy 87.21
2024-08-02 16:06:31,978 [foster.py] => Task 11, Epoch 97/170 => Loss 2.982, Loss_clf 0.326, Loss_fe 0.156, Loss_kd 2.429, Train_accy 87.29, Test_accy 70.53
2024-08-02 16:06:36,143 [foster.py] => Task 11, Epoch 98/170 => Loss 2.982, Loss_clf 0.326, Loss_fe 0.145, Loss_kd 2.439, Train_accy 87.17, Test_accy 70.14
2024-08-02 16:06:40,279 [foster.py] => Task 11, Epoch 99/170 => Loss 2.980, Loss_clf 0.321, Loss_fe 0.147, Loss_kd 2.440, Train_accy 86.33, Test_accy 70.39
2024-08-02 16:06:44,446 [foster.py] => Task 11, Epoch 100/170 => Loss 2.990, Loss_clf 0.332, Loss_fe 0.138, Loss_kd 2.449, Train_accy 86.96, Test_accy 70.42
2024-08-02 16:06:47,010 [foster.py] => Task 11, Epoch 101/170 => Loss 3.104, Loss_clf 0.373, Loss_fe 0.178, Loss_kd 2.480, Train_accy 85.88
2024-08-02 16:06:51,227 [foster.py] => Task 11, Epoch 102/170 => Loss 2.970, Loss_clf 0.312, Loss_fe 0.143, Loss_kd 2.444, Train_accy 87.08, Test_accy 70.61
2024-08-02 16:06:55,407 [foster.py] => Task 11, Epoch 103/170 => Loss 3.000, Loss_clf 0.332, Loss_fe 0.142, Loss_kd 2.455, Train_accy 87.50, Test_accy 70.46
2024-08-02 16:06:59,584 [foster.py] => Task 11, Epoch 104/170 => Loss 2.965, Loss_clf 0.307, Loss_fe 0.151, Loss_kd 2.437, Train_accy 87.00, Test_accy 70.75
2024-08-02 16:07:03,776 [foster.py] => Task 11, Epoch 105/170 => Loss 3.015, Loss_clf 0.323, Loss_fe 0.150, Loss_kd 2.470, Train_accy 87.08, Test_accy 70.40
2024-08-02 16:07:06,263 [foster.py] => Task 11, Epoch 106/170 => Loss 3.006, Loss_clf 0.330, Loss_fe 0.146, Loss_kd 2.457, Train_accy 87.62
2024-08-02 16:07:10,475 [foster.py] => Task 11, Epoch 107/170 => Loss 2.934, Loss_clf 0.293, Loss_fe 0.122, Loss_kd 2.447, Train_accy 88.79, Test_accy 70.11
2024-08-02 16:07:14,645 [foster.py] => Task 11, Epoch 108/170 => Loss 2.952, Loss_clf 0.300, Loss_fe 0.145, Loss_kd 2.435, Train_accy 88.71, Test_accy 70.43
2024-08-02 16:07:18,877 [foster.py] => Task 11, Epoch 109/170 => Loss 2.987, Loss_clf 0.319, Loss_fe 0.135, Loss_kd 2.461, Train_accy 87.92, Test_accy 70.56
2024-08-02 16:07:23,033 [foster.py] => Task 11, Epoch 110/170 => Loss 2.932, Loss_clf 0.295, Loss_fe 0.133, Loss_kd 2.432, Train_accy 88.79, Test_accy 70.44
2024-08-02 16:07:25,480 [foster.py] => Task 11, Epoch 111/170 => Loss 3.030, Loss_clf 0.340, Loss_fe 0.157, Loss_kd 2.461, Train_accy 87.08
2024-08-02 16:07:29,668 [foster.py] => Task 11, Epoch 112/170 => Loss 2.914, Loss_clf 0.283, Loss_fe 0.125, Loss_kd 2.435, Train_accy 88.75, Test_accy 70.29
2024-08-02 16:07:33,832 [foster.py] => Task 11, Epoch 113/170 => Loss 2.933, Loss_clf 0.298, Loss_fe 0.130, Loss_kd 2.433, Train_accy 88.17, Test_accy 70.21
2024-08-02 16:07:37,999 [foster.py] => Task 11, Epoch 114/170 => Loss 2.964, Loss_clf 0.302, Loss_fe 0.129, Loss_kd 2.461, Train_accy 88.75, Test_accy 70.32
2024-08-02 16:07:42,207 [foster.py] => Task 11, Epoch 115/170 => Loss 2.954, Loss_clf 0.308, Loss_fe 0.128, Loss_kd 2.446, Train_accy 87.96, Test_accy 70.28
2024-08-02 16:07:44,791 [foster.py] => Task 11, Epoch 116/170 => Loss 3.039, Loss_clf 0.353, Loss_fe 0.136, Loss_kd 2.477, Train_accy 87.29
2024-08-02 16:07:48,987 [foster.py] => Task 11, Epoch 117/170 => Loss 2.934, Loss_clf 0.293, Loss_fe 0.130, Loss_kd 2.439, Train_accy 88.29, Test_accy 70.58
2024-08-02 16:07:53,154 [foster.py] => Task 11, Epoch 118/170 => Loss 2.929, Loss_clf 0.295, Loss_fe 0.107, Loss_kd 2.455, Train_accy 88.54, Test_accy 70.60
2024-08-02 16:07:57,329 [foster.py] => Task 11, Epoch 119/170 => Loss 2.949, Loss_clf 0.298, Loss_fe 0.131, Loss_kd 2.450, Train_accy 89.04, Test_accy 70.53
2024-08-02 16:08:01,525 [foster.py] => Task 11, Epoch 120/170 => Loss 2.966, Loss_clf 0.317, Loss_fe 0.129, Loss_kd 2.449, Train_accy 88.38, Test_accy 70.67
2024-08-02 16:08:03,977 [foster.py] => Task 11, Epoch 121/170 => Loss 3.034, Loss_clf 0.331, Loss_fe 0.149, Loss_kd 2.483, Train_accy 88.00
2024-08-02 16:08:08,163 [foster.py] => Task 11, Epoch 122/170 => Loss 2.913, Loss_clf 0.289, Loss_fe 0.118, Loss_kd 2.435, Train_accy 88.83, Test_accy 70.47
2024-08-02 16:08:12,352 [foster.py] => Task 11, Epoch 123/170 => Loss 2.897, Loss_clf 0.280, Loss_fe 0.105, Loss_kd 2.441, Train_accy 89.50, Test_accy 70.72
2024-08-02 16:08:16,567 [foster.py] => Task 11, Epoch 124/170 => Loss 2.920, Loss_clf 0.292, Loss_fe 0.116, Loss_kd 2.441, Train_accy 88.38, Test_accy 70.46
2024-08-02 16:08:20,729 [foster.py] => Task 11, Epoch 125/170 => Loss 2.987, Loss_clf 0.316, Loss_fe 0.122, Loss_kd 2.476, Train_accy 87.92, Test_accy 70.60
2024-08-02 16:08:23,225 [foster.py] => Task 11, Epoch 126/170 => Loss 2.963, Loss_clf 0.312, Loss_fe 0.125, Loss_kd 2.454, Train_accy 88.04
2024-08-02 16:08:27,389 [foster.py] => Task 11, Epoch 127/170 => Loss 2.964, Loss_clf 0.316, Loss_fe 0.119, Loss_kd 2.456, Train_accy 86.96, Test_accy 70.44
2024-08-02 16:08:31,578 [foster.py] => Task 11, Epoch 128/170 => Loss 2.936, Loss_clf 0.299, Loss_fe 0.114, Loss_kd 2.452, Train_accy 88.58, Test_accy 70.47
2024-08-02 16:08:35,717 [foster.py] => Task 11, Epoch 129/170 => Loss 2.916, Loss_clf 0.298, Loss_fe 0.112, Loss_kd 2.435, Train_accy 88.71, Test_accy 70.62
2024-08-02 16:08:39,924 [foster.py] => Task 11, Epoch 130/170 => Loss 2.929, Loss_clf 0.298, Loss_fe 0.112, Loss_kd 2.447, Train_accy 88.38, Test_accy 70.56
2024-08-02 16:08:42,369 [foster.py] => Task 11, Epoch 131/170 => Loss 2.962, Loss_clf 0.308, Loss_fe 0.108, Loss_kd 2.474, Train_accy 88.50
2024-08-02 16:08:46,521 [foster.py] => Task 11, Epoch 132/170 => Loss 2.903, Loss_clf 0.300, Loss_fe 0.102, Loss_kd 2.431, Train_accy 88.38, Test_accy 70.67
2024-08-02 16:08:50,788 [foster.py] => Task 11, Epoch 133/170 => Loss 2.967, Loss_clf 0.306, Loss_fe 0.117, Loss_kd 2.472, Train_accy 88.92, Test_accy 70.62
2024-08-02 16:08:54,960 [foster.py] => Task 11, Epoch 134/170 => Loss 2.912, Loss_clf 0.291, Loss_fe 0.093, Loss_kd 2.456, Train_accy 90.04, Test_accy 70.49
2024-08-02 16:08:59,184 [foster.py] => Task 11, Epoch 135/170 => Loss 2.927, Loss_clf 0.297, Loss_fe 0.103, Loss_kd 2.456, Train_accy 89.33, Test_accy 70.40
2024-08-02 16:09:01,720 [foster.py] => Task 11, Epoch 136/170 => Loss 2.984, Loss_clf 0.327, Loss_fe 0.124, Loss_kd 2.462, Train_accy 88.00
2024-08-02 16:09:05,852 [foster.py] => Task 11, Epoch 137/170 => Loss 2.951, Loss_clf 0.302, Loss_fe 0.131, Loss_kd 2.447, Train_accy 88.79, Test_accy 70.33
2024-08-02 16:09:10,018 [foster.py] => Task 11, Epoch 138/170 => Loss 2.939, Loss_clf 0.303, Loss_fe 0.103, Loss_kd 2.462, Train_accy 89.21, Test_accy 70.46
2024-08-02 16:09:14,198 [foster.py] => Task 11, Epoch 139/170 => Loss 2.955, Loss_clf 0.304, Loss_fe 0.118, Loss_kd 2.462, Train_accy 88.12, Test_accy 70.60
2024-08-02 16:09:18,349 [foster.py] => Task 11, Epoch 140/170 => Loss 2.984, Loss_clf 0.328, Loss_fe 0.118, Loss_kd 2.467, Train_accy 88.38, Test_accy 70.49
2024-08-02 16:09:20,830 [foster.py] => Task 11, Epoch 141/170 => Loss 2.975, Loss_clf 0.319, Loss_fe 0.118, Loss_kd 2.466, Train_accy 88.25
2024-08-02 16:09:25,009 [foster.py] => Task 11, Epoch 142/170 => Loss 2.920, Loss_clf 0.288, Loss_fe 0.112, Loss_kd 2.448, Train_accy 89.96, Test_accy 70.56
2024-08-02 16:09:29,192 [foster.py] => Task 11, Epoch 143/170 => Loss 2.912, Loss_clf 0.300, Loss_fe 0.094, Loss_kd 2.446, Train_accy 87.83, Test_accy 70.56
2024-08-02 16:09:33,401 [foster.py] => Task 11, Epoch 144/170 => Loss 3.014, Loss_clf 0.343, Loss_fe 0.127, Loss_kd 2.473, Train_accy 88.25, Test_accy 70.46
2024-08-02 16:09:37,580 [foster.py] => Task 11, Epoch 145/170 => Loss 2.969, Loss_clf 0.324, Loss_fe 0.102, Loss_kd 2.472, Train_accy 88.33, Test_accy 70.49
2024-08-02 16:09:40,042 [foster.py] => Task 11, Epoch 146/170 => Loss 2.947, Loss_clf 0.299, Loss_fe 0.095, Loss_kd 2.482, Train_accy 89.38
2024-08-02 16:09:44,233 [foster.py] => Task 11, Epoch 147/170 => Loss 2.935, Loss_clf 0.299, Loss_fe 0.106, Loss_kd 2.459, Train_accy 89.54, Test_accy 70.61
2024-08-02 16:09:48,458 [foster.py] => Task 11, Epoch 148/170 => Loss 2.903, Loss_clf 0.293, Loss_fe 0.095, Loss_kd 2.443, Train_accy 89.33, Test_accy 70.58
2024-08-02 16:09:52,619 [foster.py] => Task 11, Epoch 149/170 => Loss 2.954, Loss_clf 0.304, Loss_fe 0.106, Loss_kd 2.472, Train_accy 89.58, Test_accy 70.57
2024-08-02 16:09:56,795 [foster.py] => Task 11, Epoch 150/170 => Loss 2.969, Loss_clf 0.312, Loss_fe 0.115, Loss_kd 2.469, Train_accy 89.25, Test_accy 70.51
2024-08-02 16:09:59,336 [foster.py] => Task 11, Epoch 151/170 => Loss 2.970, Loss_clf 0.318, Loss_fe 0.112, Loss_kd 2.467, Train_accy 88.67
2024-08-02 16:10:03,553 [foster.py] => Task 11, Epoch 152/170 => Loss 2.958, Loss_clf 0.302, Loss_fe 0.111, Loss_kd 2.473, Train_accy 89.17, Test_accy 70.58
2024-08-02 16:10:07,719 [foster.py] => Task 11, Epoch 153/170 => Loss 2.883, Loss_clf 0.265, Loss_fe 0.104, Loss_kd 2.444, Train_accy 89.67, Test_accy 70.47
2024-08-02 16:10:11,909 [foster.py] => Task 11, Epoch 154/170 => Loss 2.939, Loss_clf 0.309, Loss_fe 0.102, Loss_kd 2.456, Train_accy 87.79, Test_accy 70.50
2024-08-02 16:10:16,049 [foster.py] => Task 11, Epoch 155/170 => Loss 2.956, Loss_clf 0.320, Loss_fe 0.101, Loss_kd 2.463, Train_accy 88.00, Test_accy 70.50
2024-08-02 16:10:18,548 [foster.py] => Task 11, Epoch 156/170 => Loss 2.941, Loss_clf 0.301, Loss_fe 0.113, Loss_kd 2.455, Train_accy 88.83
2024-08-02 16:10:22,743 [foster.py] => Task 11, Epoch 157/170 => Loss 2.929, Loss_clf 0.291, Loss_fe 0.100, Loss_kd 2.467, Train_accy 89.46, Test_accy 70.54
2024-08-02 16:10:26,937 [foster.py] => Task 11, Epoch 158/170 => Loss 2.971, Loss_clf 0.310, Loss_fe 0.119, Loss_kd 2.470, Train_accy 88.62, Test_accy 70.58
2024-08-02 16:10:31,119 [foster.py] => Task 11, Epoch 159/170 => Loss 2.916, Loss_clf 0.300, Loss_fe 0.099, Loss_kd 2.446, Train_accy 88.21, Test_accy 70.53
2024-08-02 16:10:35,341 [foster.py] => Task 11, Epoch 160/170 => Loss 2.853, Loss_clf 0.266, Loss_fe 0.090, Loss_kd 2.425, Train_accy 90.46, Test_accy 70.53
2024-08-02 16:10:37,816 [foster.py] => Task 11, Epoch 161/170 => Loss 2.949, Loss_clf 0.302, Loss_fe 0.110, Loss_kd 2.466, Train_accy 89.08
2024-08-02 16:10:41,994 [foster.py] => Task 11, Epoch 162/170 => Loss 2.908, Loss_clf 0.288, Loss_fe 0.102, Loss_kd 2.446, Train_accy 89.08, Test_accy 70.53
2024-08-02 16:10:46,180 [foster.py] => Task 11, Epoch 163/170 => Loss 2.969, Loss_clf 0.307, Loss_fe 0.124, Loss_kd 2.466, Train_accy 89.33, Test_accy 70.54
2024-08-02 16:10:50,362 [foster.py] => Task 11, Epoch 164/170 => Loss 2.902, Loss_clf 0.290, Loss_fe 0.103, Loss_kd 2.438, Train_accy 89.17, Test_accy 70.47
2024-08-02 16:10:54,606 [foster.py] => Task 11, Epoch 165/170 => Loss 2.893, Loss_clf 0.283, Loss_fe 0.101, Loss_kd 2.438, Train_accy 89.92, Test_accy 70.54
2024-08-02 16:10:57,183 [foster.py] => Task 11, Epoch 166/170 => Loss 2.932, Loss_clf 0.286, Loss_fe 0.103, Loss_kd 2.471, Train_accy 89.96
2024-08-02 16:11:01,353 [foster.py] => Task 11, Epoch 167/170 => Loss 2.929, Loss_clf 0.291, Loss_fe 0.102, Loss_kd 2.464, Train_accy 89.25, Test_accy 70.53
2024-08-02 16:11:05,536 [foster.py] => Task 11, Epoch 168/170 => Loss 2.910, Loss_clf 0.297, Loss_fe 0.102, Loss_kd 2.439, Train_accy 89.33, Test_accy 70.49
2024-08-02 16:11:09,714 [foster.py] => Task 11, Epoch 169/170 => Loss 2.941, Loss_clf 0.305, Loss_fe 0.107, Loss_kd 2.457, Train_accy 88.83, Test_accy 70.57
2024-08-02 16:11:13,891 [foster.py] => Task 11, Epoch 170/170 => Loss 2.934, Loss_clf 0.314, Loss_fe 0.091, Loss_kd 2.457, Train_accy 89.04, Test_accy 70.56
2024-08-02 16:11:13,895 [foster.py] => do not weight align teacher!
2024-08-02 16:11:13,899 [foster.py] => per cls weights : [1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461 1.01513461
 1.01513461 1.01513461 1.01513461 1.01513461 0.47028856 0.47028856]
2024-08-02 16:11:18,587 [foster.py] => SNet: Task 11, Epoch 1/130 => Loss 29.299,  Loss1 0.740, Train_accy 52.79, Test_accy 66.29
2024-08-02 16:11:21,990 [foster.py] => SNet: Task 11, Epoch 2/130 => Loss 29.150,  Loss1 0.740, Train_accy 64.62
2024-08-02 16:11:25,463 [foster.py] => SNet: Task 11, Epoch 3/130 => Loss 29.099,  Loss1 0.739, Train_accy 64.71
2024-08-02 16:11:28,882 [foster.py] => SNet: Task 11, Epoch 4/130 => Loss 29.101,  Loss1 0.740, Train_accy 66.21
2024-08-02 16:11:32,310 [foster.py] => SNet: Task 11, Epoch 5/130 => Loss 29.070,  Loss1 0.740, Train_accy 68.29
2024-08-02 16:11:36,821 [foster.py] => SNet: Task 11, Epoch 6/130 => Loss 29.112,  Loss1 0.740, Train_accy 69.08, Test_accy 69.40
2024-08-02 16:11:40,249 [foster.py] => SNet: Task 11, Epoch 7/130 => Loss 29.086,  Loss1 0.740, Train_accy 68.08
2024-08-02 16:11:43,652 [foster.py] => SNet: Task 11, Epoch 8/130 => Loss 29.083,  Loss1 0.740, Train_accy 70.96
2024-08-02 16:11:47,079 [foster.py] => SNet: Task 11, Epoch 9/130 => Loss 29.089,  Loss1 0.740, Train_accy 72.21
2024-08-02 16:11:50,531 [foster.py] => SNet: Task 11, Epoch 10/130 => Loss 29.124,  Loss1 0.739, Train_accy 71.17
2024-08-02 16:11:55,017 [foster.py] => SNet: Task 11, Epoch 11/130 => Loss 29.066,  Loss1 0.740, Train_accy 72.00, Test_accy 69.17
2024-08-02 16:11:58,423 [foster.py] => SNet: Task 11, Epoch 12/130 => Loss 29.067,  Loss1 0.740, Train_accy 72.25
2024-08-02 16:12:01,816 [foster.py] => SNet: Task 11, Epoch 13/130 => Loss 29.075,  Loss1 0.739, Train_accy 72.75
2024-08-02 16:12:05,214 [foster.py] => SNet: Task 11, Epoch 14/130 => Loss 29.103,  Loss1 0.740, Train_accy 74.29
2024-08-02 16:12:08,614 [foster.py] => SNet: Task 11, Epoch 15/130 => Loss 29.058,  Loss1 0.740, Train_accy 73.33
2024-08-02 16:12:13,174 [foster.py] => SNet: Task 11, Epoch 16/130 => Loss 29.078,  Loss1 0.740, Train_accy 73.71, Test_accy 69.67
2024-08-02 16:12:16,609 [foster.py] => SNet: Task 11, Epoch 17/130 => Loss 29.081,  Loss1 0.739, Train_accy 73.00
2024-08-02 16:12:20,036 [foster.py] => SNet: Task 11, Epoch 18/130 => Loss 29.097,  Loss1 0.739, Train_accy 73.67
2024-08-02 16:12:23,475 [foster.py] => SNet: Task 11, Epoch 19/130 => Loss 29.083,  Loss1 0.740, Train_accy 74.58
2024-08-02 16:12:26,897 [foster.py] => SNet: Task 11, Epoch 20/130 => Loss 29.073,  Loss1 0.739, Train_accy 72.29
2024-08-02 16:12:31,384 [foster.py] => SNet: Task 11, Epoch 21/130 => Loss 29.072,  Loss1 0.740, Train_accy 74.54, Test_accy 69.60
2024-08-02 16:12:34,847 [foster.py] => SNet: Task 11, Epoch 22/130 => Loss 29.096,  Loss1 0.739, Train_accy 72.92
2024-08-02 16:12:38,253 [foster.py] => SNet: Task 11, Epoch 23/130 => Loss 29.098,  Loss1 0.740, Train_accy 74.62
2024-08-02 16:12:41,664 [foster.py] => SNet: Task 11, Epoch 24/130 => Loss 29.070,  Loss1 0.739, Train_accy 73.88
2024-08-02 16:12:45,076 [foster.py] => SNet: Task 11, Epoch 25/130 => Loss 29.096,  Loss1 0.741, Train_accy 73.67
2024-08-02 16:12:49,579 [foster.py] => SNet: Task 11, Epoch 26/130 => Loss 29.034,  Loss1 0.740, Train_accy 75.96, Test_accy 69.49
2024-08-02 16:12:52,990 [foster.py] => SNet: Task 11, Epoch 27/130 => Loss 29.044,  Loss1 0.740, Train_accy 74.17
2024-08-02 16:12:56,384 [foster.py] => SNet: Task 11, Epoch 28/130 => Loss 29.077,  Loss1 0.739, Train_accy 74.96
2024-08-02 16:12:59,828 [foster.py] => SNet: Task 11, Epoch 29/130 => Loss 29.082,  Loss1 0.740, Train_accy 75.58
2024-08-02 16:13:03,242 [foster.py] => SNet: Task 11, Epoch 30/130 => Loss 29.012,  Loss1 0.740, Train_accy 75.50
2024-08-02 16:13:07,729 [foster.py] => SNet: Task 11, Epoch 31/130 => Loss 29.067,  Loss1 0.740, Train_accy 74.46, Test_accy 69.42
2024-08-02 16:13:11,132 [foster.py] => SNet: Task 11, Epoch 32/130 => Loss 29.077,  Loss1 0.740, Train_accy 76.33
2024-08-02 16:13:14,550 [foster.py] => SNet: Task 11, Epoch 33/130 => Loss 29.064,  Loss1 0.739, Train_accy 75.58
2024-08-02 16:13:17,969 [foster.py] => SNet: Task 11, Epoch 34/130 => Loss 29.015,  Loss1 0.740, Train_accy 74.96
2024-08-02 16:13:21,387 [foster.py] => SNet: Task 11, Epoch 35/130 => Loss 29.072,  Loss1 0.739, Train_accy 74.96
2024-08-02 16:13:25,916 [foster.py] => SNet: Task 11, Epoch 36/130 => Loss 29.081,  Loss1 0.739, Train_accy 75.17, Test_accy 69.75
2024-08-02 16:13:29,356 [foster.py] => SNet: Task 11, Epoch 37/130 => Loss 29.084,  Loss1 0.740, Train_accy 75.00
2024-08-02 16:13:32,776 [foster.py] => SNet: Task 11, Epoch 38/130 => Loss 29.077,  Loss1 0.740, Train_accy 74.96
2024-08-02 16:13:36,171 [foster.py] => SNet: Task 11, Epoch 39/130 => Loss 29.126,  Loss1 0.739, Train_accy 74.33
2024-08-02 16:13:39,588 [foster.py] => SNet: Task 11, Epoch 40/130 => Loss 29.035,  Loss1 0.740, Train_accy 77.17
2024-08-02 16:13:44,131 [foster.py] => SNet: Task 11, Epoch 41/130 => Loss 29.097,  Loss1 0.740, Train_accy 76.00, Test_accy 69.74
2024-08-02 16:13:47,534 [foster.py] => SNet: Task 11, Epoch 42/130 => Loss 29.037,  Loss1 0.740, Train_accy 77.67
2024-08-02 16:13:50,941 [foster.py] => SNet: Task 11, Epoch 43/130 => Loss 29.023,  Loss1 0.740, Train_accy 76.46
2024-08-02 16:13:54,352 [foster.py] => SNet: Task 11, Epoch 44/130 => Loss 29.051,  Loss1 0.740, Train_accy 76.75
2024-08-02 16:13:57,791 [foster.py] => SNet: Task 11, Epoch 45/130 => Loss 29.084,  Loss1 0.740, Train_accy 75.00
2024-08-02 16:14:02,320 [foster.py] => SNet: Task 11, Epoch 46/130 => Loss 29.061,  Loss1 0.740, Train_accy 76.25, Test_accy 69.81
2024-08-02 16:14:05,756 [foster.py] => SNet: Task 11, Epoch 47/130 => Loss 29.073,  Loss1 0.740, Train_accy 76.21
2024-08-02 16:14:09,144 [foster.py] => SNet: Task 11, Epoch 48/130 => Loss 29.086,  Loss1 0.740, Train_accy 75.21
2024-08-02 16:14:12,578 [foster.py] => SNet: Task 11, Epoch 49/130 => Loss 29.069,  Loss1 0.740, Train_accy 75.96
2024-08-02 16:14:15,973 [foster.py] => SNet: Task 11, Epoch 50/130 => Loss 29.067,  Loss1 0.740, Train_accy 76.83
2024-08-02 16:14:20,499 [foster.py] => SNet: Task 11, Epoch 51/130 => Loss 29.051,  Loss1 0.740, Train_accy 76.62, Test_accy 69.85
2024-08-02 16:14:23,926 [foster.py] => SNet: Task 11, Epoch 52/130 => Loss 29.060,  Loss1 0.740, Train_accy 76.79
2024-08-02 16:14:27,313 [foster.py] => SNet: Task 11, Epoch 53/130 => Loss 29.075,  Loss1 0.739, Train_accy 76.50
2024-08-02 16:14:30,717 [foster.py] => SNet: Task 11, Epoch 54/130 => Loss 29.063,  Loss1 0.740, Train_accy 76.21
2024-08-02 16:14:34,130 [foster.py] => SNet: Task 11, Epoch 55/130 => Loss 29.022,  Loss1 0.740, Train_accy 76.46
2024-08-02 16:14:38,620 [foster.py] => SNet: Task 11, Epoch 56/130 => Loss 29.075,  Loss1 0.740, Train_accy 78.12, Test_accy 69.72
2024-08-02 16:14:42,016 [foster.py] => SNet: Task 11, Epoch 57/130 => Loss 29.109,  Loss1 0.740, Train_accy 75.33
2024-08-02 16:14:45,442 [foster.py] => SNet: Task 11, Epoch 58/130 => Loss 29.074,  Loss1 0.740, Train_accy 76.29
2024-08-02 16:14:48,838 [foster.py] => SNet: Task 11, Epoch 59/130 => Loss 29.074,  Loss1 0.740, Train_accy 76.21
2024-08-02 16:14:52,304 [foster.py] => SNet: Task 11, Epoch 60/130 => Loss 29.075,  Loss1 0.740, Train_accy 76.83
2024-08-02 16:14:56,809 [foster.py] => SNet: Task 11, Epoch 61/130 => Loss 29.081,  Loss1 0.740, Train_accy 76.33, Test_accy 69.50
2024-08-02 16:15:00,217 [foster.py] => SNet: Task 11, Epoch 62/130 => Loss 29.026,  Loss1 0.740, Train_accy 75.71
2024-08-02 16:15:03,630 [foster.py] => SNet: Task 11, Epoch 63/130 => Loss 29.040,  Loss1 0.740, Train_accy 76.62
2024-08-02 16:15:07,044 [foster.py] => SNet: Task 11, Epoch 64/130 => Loss 29.058,  Loss1 0.740, Train_accy 77.62
2024-08-02 16:15:10,447 [foster.py] => SNet: Task 11, Epoch 65/130 => Loss 29.078,  Loss1 0.739, Train_accy 76.54
2024-08-02 16:15:14,951 [foster.py] => SNet: Task 11, Epoch 66/130 => Loss 29.013,  Loss1 0.740, Train_accy 76.79, Test_accy 69.75
2024-08-02 16:15:18,358 [foster.py] => SNet: Task 11, Epoch 67/130 => Loss 29.046,  Loss1 0.740, Train_accy 78.12
2024-08-02 16:15:21,746 [foster.py] => SNet: Task 11, Epoch 68/130 => Loss 29.068,  Loss1 0.740, Train_accy 77.00
2024-08-02 16:15:25,162 [foster.py] => SNet: Task 11, Epoch 69/130 => Loss 29.069,  Loss1 0.740, Train_accy 76.08
2024-08-02 16:15:28,580 [foster.py] => SNet: Task 11, Epoch 70/130 => Loss 29.030,  Loss1 0.740, Train_accy 77.42
2024-08-02 16:15:33,058 [foster.py] => SNet: Task 11, Epoch 71/130 => Loss 29.087,  Loss1 0.741, Train_accy 77.12, Test_accy 69.71
2024-08-02 16:15:36,455 [foster.py] => SNet: Task 11, Epoch 72/130 => Loss 29.075,  Loss1 0.740, Train_accy 76.62
2024-08-02 16:15:39,866 [foster.py] => SNet: Task 11, Epoch 73/130 => Loss 29.050,  Loss1 0.740, Train_accy 76.58
2024-08-02 16:15:43,289 [foster.py] => SNet: Task 11, Epoch 74/130 => Loss 29.121,  Loss1 0.740, Train_accy 75.54
2024-08-02 16:15:46,687 [foster.py] => SNet: Task 11, Epoch 75/130 => Loss 29.088,  Loss1 0.740, Train_accy 77.12
2024-08-02 16:15:51,162 [foster.py] => SNet: Task 11, Epoch 76/130 => Loss 29.047,  Loss1 0.740, Train_accy 77.58, Test_accy 69.68
2024-08-02 16:15:54,585 [foster.py] => SNet: Task 11, Epoch 77/130 => Loss 29.078,  Loss1 0.740, Train_accy 77.79
2024-08-02 16:15:57,989 [foster.py] => SNet: Task 11, Epoch 78/130 => Loss 29.070,  Loss1 0.739, Train_accy 76.50
2024-08-02 16:16:01,443 [foster.py] => SNet: Task 11, Epoch 79/130 => Loss 29.046,  Loss1 0.740, Train_accy 77.25
2024-08-02 16:16:04,859 [foster.py] => SNet: Task 11, Epoch 80/130 => Loss 29.065,  Loss1 0.740, Train_accy 76.96
2024-08-02 16:16:09,343 [foster.py] => SNet: Task 11, Epoch 81/130 => Loss 29.092,  Loss1 0.740, Train_accy 76.71, Test_accy 69.54
2024-08-02 16:16:12,738 [foster.py] => SNet: Task 11, Epoch 82/130 => Loss 29.074,  Loss1 0.740, Train_accy 78.42
2024-08-02 16:16:16,150 [foster.py] => SNet: Task 11, Epoch 83/130 => Loss 29.105,  Loss1 0.740, Train_accy 76.75
2024-08-02 16:16:19,544 [foster.py] => SNet: Task 11, Epoch 84/130 => Loss 29.091,  Loss1 0.740, Train_accy 76.50
2024-08-02 16:16:22,959 [foster.py] => SNet: Task 11, Epoch 85/130 => Loss 29.043,  Loss1 0.740, Train_accy 75.92
2024-08-02 16:16:27,457 [foster.py] => SNet: Task 11, Epoch 86/130 => Loss 29.054,  Loss1 0.740, Train_accy 77.71, Test_accy 69.69
2024-08-02 16:16:30,857 [foster.py] => SNet: Task 11, Epoch 87/130 => Loss 29.084,  Loss1 0.740, Train_accy 77.17
2024-08-02 16:16:34,291 [foster.py] => SNet: Task 11, Epoch 88/130 => Loss 29.043,  Loss1 0.739, Train_accy 76.17
2024-08-02 16:16:37,728 [foster.py] => SNet: Task 11, Epoch 89/130 => Loss 29.045,  Loss1 0.740, Train_accy 77.46
2024-08-02 16:16:41,125 [foster.py] => SNet: Task 11, Epoch 90/130 => Loss 29.037,  Loss1 0.740, Train_accy 77.58
2024-08-02 16:16:45,615 [foster.py] => SNet: Task 11, Epoch 91/130 => Loss 29.056,  Loss1 0.740, Train_accy 76.54, Test_accy 69.76
2024-08-02 16:16:49,024 [foster.py] => SNet: Task 11, Epoch 92/130 => Loss 29.045,  Loss1 0.740, Train_accy 78.12
2024-08-02 16:16:52,465 [foster.py] => SNet: Task 11, Epoch 93/130 => Loss 29.035,  Loss1 0.740, Train_accy 77.83
2024-08-02 16:16:55,871 [foster.py] => SNet: Task 11, Epoch 94/130 => Loss 29.081,  Loss1 0.740, Train_accy 77.38
2024-08-02 16:16:59,292 [foster.py] => SNet: Task 11, Epoch 95/130 => Loss 29.084,  Loss1 0.740, Train_accy 78.96
2024-08-02 16:17:03,823 [foster.py] => SNet: Task 11, Epoch 96/130 => Loss 29.044,  Loss1 0.740, Train_accy 77.54, Test_accy 69.32
2024-08-02 16:17:07,241 [foster.py] => SNet: Task 11, Epoch 97/130 => Loss 29.065,  Loss1 0.740, Train_accy 77.29
2024-08-02 16:17:10,715 [foster.py] => SNet: Task 11, Epoch 98/130 => Loss 29.031,  Loss1 0.740, Train_accy 77.38
2024-08-02 16:17:14,119 [foster.py] => SNet: Task 11, Epoch 99/130 => Loss 29.119,  Loss1 0.740, Train_accy 77.50
2024-08-02 16:17:17,510 [foster.py] => SNet: Task 11, Epoch 100/130 => Loss 29.085,  Loss1 0.740, Train_accy 77.04
2024-08-02 16:17:21,996 [foster.py] => SNet: Task 11, Epoch 101/130 => Loss 29.054,  Loss1 0.740, Train_accy 77.08, Test_accy 69.90
2024-08-02 16:17:25,417 [foster.py] => SNet: Task 11, Epoch 102/130 => Loss 29.093,  Loss1 0.740, Train_accy 76.67
2024-08-02 16:17:28,847 [foster.py] => SNet: Task 11, Epoch 103/130 => Loss 29.030,  Loss1 0.739, Train_accy 77.50
2024-08-02 16:17:32,251 [foster.py] => SNet: Task 11, Epoch 104/130 => Loss 29.031,  Loss1 0.740, Train_accy 78.12
2024-08-02 16:17:35,635 [foster.py] => SNet: Task 11, Epoch 105/130 => Loss 29.016,  Loss1 0.740, Train_accy 77.50
2024-08-02 16:17:40,127 [foster.py] => SNet: Task 11, Epoch 106/130 => Loss 29.077,  Loss1 0.740, Train_accy 76.08, Test_accy 69.68
2024-08-02 16:17:43,541 [foster.py] => SNet: Task 11, Epoch 107/130 => Loss 29.066,  Loss1 0.740, Train_accy 77.08
2024-08-02 16:17:46,962 [foster.py] => SNet: Task 11, Epoch 108/130 => Loss 29.071,  Loss1 0.740, Train_accy 77.04
2024-08-02 16:17:50,375 [foster.py] => SNet: Task 11, Epoch 109/130 => Loss 29.052,  Loss1 0.739, Train_accy 77.12
2024-08-02 16:17:53,802 [foster.py] => SNet: Task 11, Epoch 110/130 => Loss 29.018,  Loss1 0.740, Train_accy 77.54
2024-08-02 16:17:58,299 [foster.py] => SNet: Task 11, Epoch 111/130 => Loss 29.071,  Loss1 0.740, Train_accy 77.54, Test_accy 69.75
2024-08-02 16:18:01,725 [foster.py] => SNet: Task 11, Epoch 112/130 => Loss 29.086,  Loss1 0.740, Train_accy 77.92
2024-08-02 16:18:05,119 [foster.py] => SNet: Task 11, Epoch 113/130 => Loss 29.053,  Loss1 0.740, Train_accy 77.54
2024-08-02 16:18:08,527 [foster.py] => SNet: Task 11, Epoch 114/130 => Loss 29.058,  Loss1 0.740, Train_accy 76.62
2024-08-02 16:18:11,944 [foster.py] => SNet: Task 11, Epoch 115/130 => Loss 29.066,  Loss1 0.739, Train_accy 75.92
2024-08-02 16:18:16,445 [foster.py] => SNet: Task 11, Epoch 116/130 => Loss 29.102,  Loss1 0.739, Train_accy 75.83, Test_accy 69.68
2024-08-02 16:18:19,907 [foster.py] => SNet: Task 11, Epoch 117/130 => Loss 29.032,  Loss1 0.740, Train_accy 76.88
2024-08-02 16:18:23,299 [foster.py] => SNet: Task 11, Epoch 118/130 => Loss 29.070,  Loss1 0.740, Train_accy 76.88
2024-08-02 16:18:26,710 [foster.py] => SNet: Task 11, Epoch 119/130 => Loss 29.098,  Loss1 0.740, Train_accy 76.92
2024-08-02 16:18:30,127 [foster.py] => SNet: Task 11, Epoch 120/130 => Loss 29.091,  Loss1 0.740, Train_accy 77.00
2024-08-02 16:18:34,606 [foster.py] => SNet: Task 11, Epoch 121/130 => Loss 29.051,  Loss1 0.739, Train_accy 77.92, Test_accy 69.65
2024-08-02 16:18:38,013 [foster.py] => SNet: Task 11, Epoch 122/130 => Loss 29.075,  Loss1 0.740, Train_accy 75.58
2024-08-02 16:18:41,437 [foster.py] => SNet: Task 11, Epoch 123/130 => Loss 29.073,  Loss1 0.740, Train_accy 77.04
2024-08-02 16:18:44,842 [foster.py] => SNet: Task 11, Epoch 124/130 => Loss 29.025,  Loss1 0.740, Train_accy 77.33
2024-08-02 16:18:48,242 [foster.py] => SNet: Task 11, Epoch 125/130 => Loss 29.048,  Loss1 0.740, Train_accy 76.96
2024-08-02 16:18:52,753 [foster.py] => SNet: Task 11, Epoch 126/130 => Loss 29.085,  Loss1 0.740, Train_accy 77.88, Test_accy 69.93
2024-08-02 16:18:56,164 [foster.py] => SNet: Task 11, Epoch 127/130 => Loss 29.087,  Loss1 0.740, Train_accy 76.88
2024-08-02 16:18:59,594 [foster.py] => SNet: Task 11, Epoch 128/130 => Loss 29.088,  Loss1 0.740, Train_accy 77.71
2024-08-02 16:19:03,009 [foster.py] => SNet: Task 11, Epoch 129/130 => Loss 29.083,  Loss1 0.740, Train_accy 76.25
2024-08-02 16:19:06,416 [foster.py] => SNet: Task 11, Epoch 130/130 => Loss 29.082,  Loss1 0.740, Train_accy 75.92
2024-08-02 16:19:06,417 [foster.py] => do not weight align student!
2024-08-02 16:19:07,507 [foster.py] => darknet eval: 
2024-08-02 16:19:07,507 [foster.py] => CNN top1 curve: 69.58
2024-08-02 16:19:07,508 [foster.py] => CNN top5 curve: 91.17
2024-08-02 16:19:07,508 [foster.py] => CNN top1 平均值: 69.58
2024-08-02 16:19:07,514 [foster.py] => timees : 1127.395453453064
2024-08-02 16:19:07,515 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 16:19:29,581 [foster.py] => Exemplar size: 1440
2024-08-02 16:19:29,581 [trainer.py] => CNN: {'total': 70.56, '00-09': 77.7, '10-19': 63.3, '20-29': 77.0, '30-39': 69.0, '40-49': 74.8, '50-59': 61.7, '60-69': 69.7, '70-79': 74.0, 'old': 70.46, 'new': 74.0}
2024-08-02 16:19:29,581 [trainer.py] => NME: {'total': 66.04, '00-09': 71.3, '10-19': 55.6, '20-29': 70.9, '30-39': 62.7, '40-49': 68.6, '50-59': 63.8, '60-69': 64.9, '70-79': 88.5, 'old': 65.4, 'new': 88.5}
2024-08-02 16:19:29,581 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56]
2024-08-02 16:19:29,581 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96]
2024-08-02 16:19:29,581 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04]
2024-08-02 16:19:29,581 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31]

2024-08-02 16:19:29,581 [trainer.py] => CNN top1 平均值: 75.90
2024-08-02 16:19:29,584 [trainer.py] => All params: 1173066
2024-08-02 16:19:29,586 [trainer.py] => Trainable params: 591242
2024-08-02 16:19:29,647 [foster.py] => Learning on 72-74
2024-08-02 16:19:29,650 [foster.py] => All params: 1173584
2024-08-02 16:19:29,652 [foster.py] => Trainable params: 591630
2024-08-02 16:19:29,690 [foster.py] => per cls weights : [1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 1.0123917  1.0123917  1.0123917  1.0123917  1.0123917  1.0123917
 0.55389884 0.55389884]
2024-08-02 16:19:32,454 [foster.py] => Task 12, Epoch 1/170 => Loss 5.080, Loss_clf 0.921, Loss_fe 1.660, Loss_kd 2.430, Train_accy 69.22
2024-08-02 16:19:36,744 [foster.py] => Task 12, Epoch 2/170 => Loss 3.668, Loss_clf 0.484, Loss_fe 0.648, Loss_kd 2.466, Train_accy 78.36, Test_accy 68.74
2024-08-02 16:19:41,096 [foster.py] => Task 12, Epoch 3/170 => Loss 3.445, Loss_clf 0.436, Loss_fe 0.547, Loss_kd 2.393, Train_accy 75.90, Test_accy 68.82
2024-08-02 16:19:45,419 [foster.py] => Task 12, Epoch 4/170 => Loss 3.405, Loss_clf 0.419, Loss_fe 0.522, Loss_kd 2.396, Train_accy 77.79, Test_accy 69.19
2024-08-02 16:19:49,762 [foster.py] => Task 12, Epoch 5/170 => Loss 3.394, Loss_clf 0.418, Loss_fe 0.496, Loss_kd 2.412, Train_accy 77.91, Test_accy 69.27
2024-08-02 16:19:52,342 [foster.py] => Task 12, Epoch 6/170 => Loss 3.369, Loss_clf 0.428, Loss_fe 0.477, Loss_kd 2.396, Train_accy 77.91
2024-08-02 16:19:56,648 [foster.py] => Task 12, Epoch 7/170 => Loss 3.448, Loss_clf 0.448, Loss_fe 0.486, Loss_kd 2.445, Train_accy 77.13, Test_accy 67.99
2024-08-02 16:20:00,962 [foster.py] => Task 12, Epoch 8/170 => Loss 3.329, Loss_clf 0.408, Loss_fe 0.440, Loss_kd 2.412, Train_accy 77.58, Test_accy 69.34
2024-08-02 16:20:05,282 [foster.py] => Task 12, Epoch 9/170 => Loss 3.365, Loss_clf 0.421, Loss_fe 0.436, Loss_kd 2.439, Train_accy 78.32, Test_accy 69.14
2024-08-02 16:20:09,571 [foster.py] => Task 12, Epoch 10/170 => Loss 3.525, Loss_clf 0.454, Loss_fe 0.556, Loss_kd 2.445, Train_accy 78.24, Test_accy 67.53
2024-08-02 16:20:12,183 [foster.py] => Task 12, Epoch 11/170 => Loss 3.479, Loss_clf 0.435, Loss_fe 0.553, Loss_kd 2.422, Train_accy 76.19
2024-08-02 16:20:16,502 [foster.py] => Task 12, Epoch 12/170 => Loss 3.361, Loss_clf 0.402, Loss_fe 0.442, Loss_kd 2.448, Train_accy 76.89, Test_accy 68.96
2024-08-02 16:20:20,845 [foster.py] => Task 12, Epoch 13/170 => Loss 3.262, Loss_clf 0.392, Loss_fe 0.390, Loss_kd 2.410, Train_accy 78.69, Test_accy 69.05
2024-08-02 16:20:25,144 [foster.py] => Task 12, Epoch 14/170 => Loss 3.274, Loss_clf 0.398, Loss_fe 0.384, Loss_kd 2.423, Train_accy 79.43, Test_accy 68.77
2024-08-02 16:20:29,496 [foster.py] => Task 12, Epoch 15/170 => Loss 3.252, Loss_clf 0.404, Loss_fe 0.392, Loss_kd 2.388, Train_accy 79.80, Test_accy 68.81
2024-08-02 16:20:32,088 [foster.py] => Task 12, Epoch 16/170 => Loss 3.359, Loss_clf 0.417, Loss_fe 0.434, Loss_kd 2.438, Train_accy 77.09
2024-08-02 16:20:36,389 [foster.py] => Task 12, Epoch 17/170 => Loss 3.333, Loss_clf 0.422, Loss_fe 0.389, Loss_kd 2.452, Train_accy 78.36, Test_accy 68.34
2024-08-02 16:20:40,685 [foster.py] => Task 12, Epoch 18/170 => Loss 3.261, Loss_clf 0.404, Loss_fe 0.390, Loss_kd 2.400, Train_accy 79.34, Test_accy 67.92
2024-08-02 16:20:45,005 [foster.py] => Task 12, Epoch 19/170 => Loss 3.259, Loss_clf 0.406, Loss_fe 0.373, Loss_kd 2.411, Train_accy 79.34, Test_accy 67.95
2024-08-02 16:20:49,408 [foster.py] => Task 12, Epoch 20/170 => Loss 3.246, Loss_clf 0.382, Loss_fe 0.399, Loss_kd 2.396, Train_accy 78.36, Test_accy 69.15
2024-08-02 16:20:52,007 [foster.py] => Task 12, Epoch 21/170 => Loss 3.254, Loss_clf 0.384, Loss_fe 0.340, Loss_kd 2.460, Train_accy 78.52
2024-08-02 16:20:56,317 [foster.py] => Task 12, Epoch 22/170 => Loss 3.204, Loss_clf 0.390, Loss_fe 0.321, Loss_kd 2.424, Train_accy 81.02, Test_accy 68.27
2024-08-02 16:21:00,600 [foster.py] => Task 12, Epoch 23/170 => Loss 3.407, Loss_clf 0.454, Loss_fe 0.459, Loss_kd 2.425, Train_accy 78.98, Test_accy 69.43
2024-08-02 16:21:04,928 [foster.py] => Task 12, Epoch 24/170 => Loss 3.385, Loss_clf 0.437, Loss_fe 0.460, Loss_kd 2.419, Train_accy 77.70, Test_accy 68.77
2024-08-02 16:21:09,260 [foster.py] => Task 12, Epoch 25/170 => Loss 3.377, Loss_clf 0.422, Loss_fe 0.428, Loss_kd 2.457, Train_accy 78.36, Test_accy 68.86
2024-08-02 16:21:11,855 [foster.py] => Task 12, Epoch 26/170 => Loss 3.453, Loss_clf 0.470, Loss_fe 0.461, Loss_kd 2.453, Train_accy 78.28
2024-08-02 16:21:16,146 [foster.py] => Task 12, Epoch 27/170 => Loss 3.284, Loss_clf 0.426, Loss_fe 0.374, Loss_kd 2.415, Train_accy 75.94, Test_accy 68.92
2024-08-02 16:21:20,418 [foster.py] => Task 12, Epoch 28/170 => Loss 3.288, Loss_clf 0.425, Loss_fe 0.379, Loss_kd 2.415, Train_accy 78.28, Test_accy 69.15
2024-08-02 16:21:24,703 [foster.py] => Task 12, Epoch 29/170 => Loss 3.271, Loss_clf 0.399, Loss_fe 0.372, Loss_kd 2.431, Train_accy 78.61, Test_accy 69.01
2024-08-02 16:21:28,977 [foster.py] => Task 12, Epoch 30/170 => Loss 3.332, Loss_clf 0.438, Loss_fe 0.358, Loss_kd 2.466, Train_accy 78.93, Test_accy 69.57
2024-08-02 16:21:31,535 [foster.py] => Task 12, Epoch 31/170 => Loss 3.255, Loss_clf 0.375, Loss_fe 0.405, Loss_kd 2.406, Train_accy 79.96
2024-08-02 16:21:35,829 [foster.py] => Task 12, Epoch 32/170 => Loss 3.327, Loss_clf 0.405, Loss_fe 0.400, Loss_kd 2.453, Train_accy 78.44, Test_accy 69.14
2024-08-02 16:21:40,113 [foster.py] => Task 12, Epoch 33/170 => Loss 3.313, Loss_clf 0.414, Loss_fe 0.393, Loss_kd 2.436, Train_accy 78.81, Test_accy 69.45
2024-08-02 16:21:44,378 [foster.py] => Task 12, Epoch 34/170 => Loss 3.271, Loss_clf 0.403, Loss_fe 0.357, Loss_kd 2.441, Train_accy 80.53, Test_accy 69.05
2024-08-02 16:21:48,670 [foster.py] => Task 12, Epoch 35/170 => Loss 3.195, Loss_clf 0.381, Loss_fe 0.325, Loss_kd 2.420, Train_accy 79.63, Test_accy 68.82
2024-08-02 16:21:51,249 [foster.py] => Task 12, Epoch 36/170 => Loss 3.199, Loss_clf 0.388, Loss_fe 0.322, Loss_kd 2.420, Train_accy 79.75
2024-08-02 16:21:55,611 [foster.py] => Task 12, Epoch 37/170 => Loss 3.136, Loss_clf 0.354, Loss_fe 0.335, Loss_kd 2.379, Train_accy 80.20, Test_accy 69.38
2024-08-02 16:21:59,924 [foster.py] => Task 12, Epoch 38/170 => Loss 3.179, Loss_clf 0.386, Loss_fe 0.309, Loss_kd 2.415, Train_accy 79.71, Test_accy 69.64
2024-08-02 16:22:04,219 [foster.py] => Task 12, Epoch 39/170 => Loss 3.185, Loss_clf 0.372, Loss_fe 0.319, Loss_kd 2.426, Train_accy 79.18, Test_accy 69.76
2024-08-02 16:22:08,560 [foster.py] => Task 12, Epoch 40/170 => Loss 3.268, Loss_clf 0.417, Loss_fe 0.377, Loss_kd 2.405, Train_accy 79.92, Test_accy 68.35
2024-08-02 16:22:11,143 [foster.py] => Task 12, Epoch 41/170 => Loss 3.231, Loss_clf 0.416, Loss_fe 0.307, Loss_kd 2.439, Train_accy 77.99
2024-08-02 16:22:15,473 [foster.py] => Task 12, Epoch 42/170 => Loss 3.117, Loss_clf 0.354, Loss_fe 0.288, Loss_kd 2.406, Train_accy 81.93, Test_accy 69.23
2024-08-02 16:22:19,761 [foster.py] => Task 12, Epoch 43/170 => Loss 3.164, Loss_clf 0.387, Loss_fe 0.293, Loss_kd 2.415, Train_accy 79.51, Test_accy 68.45
2024-08-02 16:22:24,067 [foster.py] => Task 12, Epoch 44/170 => Loss 3.190, Loss_clf 0.366, Loss_fe 0.366, Loss_kd 2.390, Train_accy 79.34, Test_accy 69.46
2024-08-02 16:22:28,460 [foster.py] => Task 12, Epoch 45/170 => Loss 3.310, Loss_clf 0.406, Loss_fe 0.374, Loss_kd 2.460, Train_accy 79.06, Test_accy 69.78
2024-08-02 16:22:31,175 [foster.py] => Task 12, Epoch 46/170 => Loss 3.356, Loss_clf 0.416, Loss_fe 0.393, Loss_kd 2.476, Train_accy 79.30
2024-08-02 16:22:35,567 [foster.py] => Task 12, Epoch 47/170 => Loss 3.186, Loss_clf 0.359, Loss_fe 0.347, Loss_kd 2.412, Train_accy 80.74, Test_accy 69.62
2024-08-02 16:22:39,844 [foster.py] => Task 12, Epoch 48/170 => Loss 3.175, Loss_clf 0.388, Loss_fe 0.302, Loss_kd 2.417, Train_accy 79.47, Test_accy 69.54
2024-08-02 16:22:44,142 [foster.py] => Task 12, Epoch 49/170 => Loss 3.158, Loss_clf 0.380, Loss_fe 0.307, Loss_kd 2.402, Train_accy 80.98, Test_accy 69.51
2024-08-02 16:22:48,423 [foster.py] => Task 12, Epoch 50/170 => Loss 3.158, Loss_clf 0.379, Loss_fe 0.282, Loss_kd 2.429, Train_accy 79.30, Test_accy 69.69
2024-08-02 16:22:50,995 [foster.py] => Task 12, Epoch 51/170 => Loss 3.197, Loss_clf 0.401, Loss_fe 0.289, Loss_kd 2.437, Train_accy 81.23
2024-08-02 16:22:55,416 [foster.py] => Task 12, Epoch 52/170 => Loss 3.139, Loss_clf 0.379, Loss_fe 0.281, Loss_kd 2.410, Train_accy 79.39, Test_accy 69.81
2024-08-02 16:22:59,736 [foster.py] => Task 12, Epoch 53/170 => Loss 3.124, Loss_clf 0.363, Loss_fe 0.259, Loss_kd 2.433, Train_accy 81.97, Test_accy 69.68
2024-08-02 16:23:04,084 [foster.py] => Task 12, Epoch 54/170 => Loss 3.134, Loss_clf 0.391, Loss_fe 0.261, Loss_kd 2.414, Train_accy 79.80, Test_accy 69.53
2024-08-02 16:23:08,385 [foster.py] => Task 12, Epoch 55/170 => Loss 3.184, Loss_clf 0.383, Loss_fe 0.304, Loss_kd 2.428, Train_accy 81.43, Test_accy 69.18
2024-08-02 16:23:10,996 [foster.py] => Task 12, Epoch 56/170 => Loss 3.175, Loss_clf 0.393, Loss_fe 0.276, Loss_kd 2.437, Train_accy 79.18
2024-08-02 16:23:15,288 [foster.py] => Task 12, Epoch 57/170 => Loss 3.212, Loss_clf 0.378, Loss_fe 0.317, Loss_kd 2.447, Train_accy 80.16, Test_accy 68.09
2024-08-02 16:23:19,567 [foster.py] => Task 12, Epoch 58/170 => Loss 3.110, Loss_clf 0.371, Loss_fe 0.266, Loss_kd 2.405, Train_accy 81.07, Test_accy 69.20
2024-08-02 16:23:23,853 [foster.py] => Task 12, Epoch 59/170 => Loss 3.210, Loss_clf 0.377, Loss_fe 0.291, Loss_kd 2.471, Train_accy 81.89, Test_accy 68.64
2024-08-02 16:23:28,136 [foster.py] => Task 12, Epoch 60/170 => Loss 3.190, Loss_clf 0.388, Loss_fe 0.295, Loss_kd 2.438, Train_accy 81.80, Test_accy 69.51
2024-08-02 16:23:30,680 [foster.py] => Task 12, Epoch 61/170 => Loss 3.129, Loss_clf 0.353, Loss_fe 0.298, Loss_kd 2.410, Train_accy 82.70
2024-08-02 16:23:34,942 [foster.py] => Task 12, Epoch 62/170 => Loss 3.162, Loss_clf 0.368, Loss_fe 0.283, Loss_kd 2.442, Train_accy 81.80, Test_accy 69.11
2024-08-02 16:23:39,251 [foster.py] => Task 12, Epoch 63/170 => Loss 3.113, Loss_clf 0.355, Loss_fe 0.258, Loss_kd 2.430, Train_accy 82.83, Test_accy 69.59
2024-08-02 16:23:43,520 [foster.py] => Task 12, Epoch 64/170 => Loss 3.193, Loss_clf 0.377, Loss_fe 0.332, Loss_kd 2.414, Train_accy 83.89, Test_accy 68.51
2024-08-02 16:23:47,834 [foster.py] => Task 12, Epoch 65/170 => Loss 3.228, Loss_clf 0.418, Loss_fe 0.292, Loss_kd 2.448, Train_accy 78.48, Test_accy 69.39
2024-08-02 16:23:50,397 [foster.py] => Task 12, Epoch 66/170 => Loss 3.125, Loss_clf 0.360, Loss_fe 0.262, Loss_kd 2.434, Train_accy 83.36
2024-08-02 16:23:54,717 [foster.py] => Task 12, Epoch 67/170 => Loss 3.073, Loss_clf 0.366, Loss_fe 0.244, Loss_kd 2.394, Train_accy 80.66, Test_accy 69.23
2024-08-02 16:23:59,059 [foster.py] => Task 12, Epoch 68/170 => Loss 3.046, Loss_clf 0.329, Loss_fe 0.207, Loss_kd 2.440, Train_accy 83.11, Test_accy 69.45
2024-08-02 16:24:03,372 [foster.py] => Task 12, Epoch 69/170 => Loss 3.011, Loss_clf 0.353, Loss_fe 0.196, Loss_kd 2.394, Train_accy 81.93, Test_accy 69.42
2024-08-02 16:24:07,697 [foster.py] => Task 12, Epoch 70/170 => Loss 3.090, Loss_clf 0.345, Loss_fe 0.247, Loss_kd 2.429, Train_accy 82.13, Test_accy 69.91
2024-08-02 16:24:10,364 [foster.py] => Task 12, Epoch 71/170 => Loss 3.114, Loss_clf 0.354, Loss_fe 0.228, Loss_kd 2.462, Train_accy 81.68
2024-08-02 16:24:14,768 [foster.py] => Task 12, Epoch 72/170 => Loss 3.052, Loss_clf 0.337, Loss_fe 0.244, Loss_kd 2.402, Train_accy 84.02, Test_accy 69.47
2024-08-02 16:24:19,153 [foster.py] => Task 12, Epoch 73/170 => Loss 3.022, Loss_clf 0.338, Loss_fe 0.219, Loss_kd 2.398, Train_accy 81.72, Test_accy 69.41
2024-08-02 16:24:23,494 [foster.py] => Task 12, Epoch 74/170 => Loss 3.002, Loss_clf 0.308, Loss_fe 0.197, Loss_kd 2.428, Train_accy 84.02, Test_accy 69.23
2024-08-02 16:24:27,780 [foster.py] => Task 12, Epoch 75/170 => Loss 2.988, Loss_clf 0.340, Loss_fe 0.187, Loss_kd 2.394, Train_accy 83.81, Test_accy 69.50
2024-08-02 16:24:30,338 [foster.py] => Task 12, Epoch 76/170 => Loss 3.041, Loss_clf 0.339, Loss_fe 0.215, Loss_kd 2.419, Train_accy 83.98
2024-08-02 16:24:34,641 [foster.py] => Task 12, Epoch 77/170 => Loss 3.034, Loss_clf 0.345, Loss_fe 0.208, Loss_kd 2.413, Train_accy 83.11, Test_accy 69.35
2024-08-02 16:24:38,986 [foster.py] => Task 12, Epoch 78/170 => Loss 3.030, Loss_clf 0.335, Loss_fe 0.192, Loss_kd 2.434, Train_accy 82.54, Test_accy 69.36
2024-08-02 16:24:43,307 [foster.py] => Task 12, Epoch 79/170 => Loss 3.090, Loss_clf 0.367, Loss_fe 0.200, Loss_kd 2.453, Train_accy 84.39, Test_accy 69.62
2024-08-02 16:24:47,591 [foster.py] => Task 12, Epoch 80/170 => Loss 3.156, Loss_clf 0.368, Loss_fe 0.268, Loss_kd 2.451, Train_accy 81.97, Test_accy 69.46
2024-08-02 16:24:50,185 [foster.py] => Task 12, Epoch 81/170 => Loss 3.178, Loss_clf 0.384, Loss_fe 0.305, Loss_kd 2.420, Train_accy 84.67
2024-08-02 16:24:54,548 [foster.py] => Task 12, Epoch 82/170 => Loss 3.195, Loss_clf 0.368, Loss_fe 0.294, Loss_kd 2.463, Train_accy 81.02, Test_accy 69.14
2024-08-02 16:24:58,840 [foster.py] => Task 12, Epoch 83/170 => Loss 3.003, Loss_clf 0.321, Loss_fe 0.220, Loss_kd 2.394, Train_accy 83.57, Test_accy 69.31
2024-08-02 16:25:03,137 [foster.py] => Task 12, Epoch 84/170 => Loss 3.026, Loss_clf 0.338, Loss_fe 0.221, Loss_kd 2.398, Train_accy 82.42, Test_accy 69.35
2024-08-02 16:25:07,421 [foster.py] => Task 12, Epoch 85/170 => Loss 2.997, Loss_clf 0.320, Loss_fe 0.214, Loss_kd 2.395, Train_accy 82.09, Test_accy 69.54
2024-08-02 16:25:09,989 [foster.py] => Task 12, Epoch 86/170 => Loss 3.044, Loss_clf 0.336, Loss_fe 0.198, Loss_kd 2.441, Train_accy 82.66
2024-08-02 16:25:14,252 [foster.py] => Task 12, Epoch 87/170 => Loss 3.051, Loss_clf 0.344, Loss_fe 0.189, Loss_kd 2.448, Train_accy 85.49, Test_accy 69.57
2024-08-02 16:25:18,614 [foster.py] => Task 12, Epoch 88/170 => Loss 3.121, Loss_clf 0.401, Loss_fe 0.202, Loss_kd 2.449, Train_accy 80.41, Test_accy 69.24
2024-08-02 16:25:22,922 [foster.py] => Task 12, Epoch 89/170 => Loss 3.004, Loss_clf 0.331, Loss_fe 0.187, Loss_kd 2.416, Train_accy 85.25, Test_accy 69.70
2024-08-02 16:25:27,189 [foster.py] => Task 12, Epoch 90/170 => Loss 2.949, Loss_clf 0.312, Loss_fe 0.158, Loss_kd 2.411, Train_accy 85.20, Test_accy 69.66
2024-08-02 16:25:29,788 [foster.py] => Task 12, Epoch 91/170 => Loss 2.964, Loss_clf 0.319, Loss_fe 0.157, Loss_kd 2.419, Train_accy 84.63
2024-08-02 16:25:34,088 [foster.py] => Task 12, Epoch 92/170 => Loss 3.012, Loss_clf 0.341, Loss_fe 0.176, Loss_kd 2.427, Train_accy 86.02, Test_accy 69.47
2024-08-02 16:25:38,388 [foster.py] => Task 12, Epoch 93/170 => Loss 2.966, Loss_clf 0.306, Loss_fe 0.172, Loss_kd 2.419, Train_accy 86.43, Test_accy 69.86
2024-08-02 16:25:42,704 [foster.py] => Task 12, Epoch 94/170 => Loss 2.998, Loss_clf 0.328, Loss_fe 0.196, Loss_kd 2.406, Train_accy 85.04, Test_accy 69.76
2024-08-02 16:25:47,010 [foster.py] => Task 12, Epoch 95/170 => Loss 3.091, Loss_clf 0.344, Loss_fe 0.229, Loss_kd 2.448, Train_accy 83.11, Test_accy 69.82
2024-08-02 16:25:49,560 [foster.py] => Task 12, Epoch 96/170 => Loss 3.093, Loss_clf 0.354, Loss_fe 0.215, Loss_kd 2.454, Train_accy 85.33
2024-08-02 16:25:53,839 [foster.py] => Task 12, Epoch 97/170 => Loss 3.116, Loss_clf 0.380, Loss_fe 0.217, Loss_kd 2.449, Train_accy 84.51, Test_accy 69.09
2024-08-02 16:25:58,117 [foster.py] => Task 12, Epoch 98/170 => Loss 3.004, Loss_clf 0.327, Loss_fe 0.209, Loss_kd 2.400, Train_accy 82.66, Test_accy 69.36
2024-08-02 16:26:02,445 [foster.py] => Task 12, Epoch 99/170 => Loss 2.996, Loss_clf 0.302, Loss_fe 0.198, Loss_kd 2.427, Train_accy 84.14, Test_accy 69.59
2024-08-02 16:26:06,762 [foster.py] => Task 12, Epoch 100/170 => Loss 3.024, Loss_clf 0.322, Loss_fe 0.190, Loss_kd 2.443, Train_accy 85.25, Test_accy 69.70
2024-08-02 16:26:09,346 [foster.py] => Task 12, Epoch 101/170 => Loss 2.964, Loss_clf 0.321, Loss_fe 0.177, Loss_kd 2.397, Train_accy 83.44
2024-08-02 16:26:13,731 [foster.py] => Task 12, Epoch 102/170 => Loss 3.009, Loss_clf 0.331, Loss_fe 0.179, Loss_kd 2.430, Train_accy 85.00, Test_accy 69.80
2024-08-02 16:26:18,071 [foster.py] => Task 12, Epoch 103/170 => Loss 2.929, Loss_clf 0.300, Loss_fe 0.156, Loss_kd 2.405, Train_accy 82.70, Test_accy 69.53
2024-08-02 16:26:22,361 [foster.py] => Task 12, Epoch 104/170 => Loss 2.973, Loss_clf 0.335, Loss_fe 0.148, Loss_kd 2.422, Train_accy 84.06, Test_accy 69.82
2024-08-02 16:26:26,681 [foster.py] => Task 12, Epoch 105/170 => Loss 3.069, Loss_clf 0.353, Loss_fe 0.157, Loss_kd 2.488, Train_accy 83.57, Test_accy 69.89
2024-08-02 16:26:29,234 [foster.py] => Task 12, Epoch 106/170 => Loss 3.021, Loss_clf 0.320, Loss_fe 0.201, Loss_kd 2.431, Train_accy 84.80
2024-08-02 16:26:33,535 [foster.py] => Task 12, Epoch 107/170 => Loss 3.004, Loss_clf 0.332, Loss_fe 0.186, Loss_kd 2.417, Train_accy 87.09, Test_accy 69.88
2024-08-02 16:26:37,860 [foster.py] => Task 12, Epoch 108/170 => Loss 3.008, Loss_clf 0.323, Loss_fe 0.186, Loss_kd 2.430, Train_accy 83.36, Test_accy 69.59
2024-08-02 16:26:42,154 [foster.py] => Task 12, Epoch 109/170 => Loss 2.982, Loss_clf 0.321, Loss_fe 0.172, Loss_kd 2.419, Train_accy 85.98, Test_accy 69.76
2024-08-02 16:26:46,500 [foster.py] => Task 12, Epoch 110/170 => Loss 2.987, Loss_clf 0.319, Loss_fe 0.160, Loss_kd 2.438, Train_accy 84.84, Test_accy 69.61
2024-08-02 16:26:49,049 [foster.py] => Task 12, Epoch 111/170 => Loss 2.912, Loss_clf 0.292, Loss_fe 0.151, Loss_kd 2.401, Train_accy 84.63
2024-08-02 16:26:53,348 [foster.py] => Task 12, Epoch 112/170 => Loss 3.052, Loss_clf 0.313, Loss_fe 0.217, Loss_kd 2.453, Train_accy 86.07, Test_accy 69.49
2024-08-02 16:26:57,656 [foster.py] => Task 12, Epoch 113/170 => Loss 3.022, Loss_clf 0.335, Loss_fe 0.171, Loss_kd 2.446, Train_accy 82.66, Test_accy 69.54
2024-08-02 16:27:02,028 [foster.py] => Task 12, Epoch 114/170 => Loss 2.955, Loss_clf 0.304, Loss_fe 0.172, Loss_kd 2.411, Train_accy 86.27, Test_accy 69.74
2024-08-02 16:27:06,464 [foster.py] => Task 12, Epoch 115/170 => Loss 2.962, Loss_clf 0.314, Loss_fe 0.151, Loss_kd 2.428, Train_accy 84.18, Test_accy 69.57
2024-08-02 16:27:09,126 [foster.py] => Task 12, Epoch 116/170 => Loss 2.908, Loss_clf 0.285, Loss_fe 0.145, Loss_kd 2.409, Train_accy 86.31
2024-08-02 16:27:13,537 [foster.py] => Task 12, Epoch 117/170 => Loss 2.946, Loss_clf 0.292, Loss_fe 0.153, Loss_kd 2.432, Train_accy 87.01, Test_accy 69.54
2024-08-02 16:27:17,819 [foster.py] => Task 12, Epoch 118/170 => Loss 3.152, Loss_clf 0.372, Loss_fe 0.222, Loss_kd 2.487, Train_accy 86.19, Test_accy 69.55
2024-08-02 16:27:22,076 [foster.py] => Task 12, Epoch 119/170 => Loss 3.030, Loss_clf 0.342, Loss_fe 0.190, Loss_kd 2.429, Train_accy 84.22, Test_accy 69.59
2024-08-02 16:27:26,398 [foster.py] => Task 12, Epoch 120/170 => Loss 2.942, Loss_clf 0.297, Loss_fe 0.172, Loss_kd 2.404, Train_accy 84.10, Test_accy 69.57
2024-08-02 16:27:28,972 [foster.py] => Task 12, Epoch 121/170 => Loss 3.047, Loss_clf 0.349, Loss_fe 0.154, Loss_kd 2.474, Train_accy 85.49
2024-08-02 16:27:33,265 [foster.py] => Task 12, Epoch 122/170 => Loss 2.894, Loss_clf 0.286, Loss_fe 0.149, Loss_kd 2.391, Train_accy 85.29, Test_accy 69.77
2024-08-02 16:27:37,557 [foster.py] => Task 12, Epoch 123/170 => Loss 2.942, Loss_clf 0.301, Loss_fe 0.150, Loss_kd 2.422, Train_accy 85.86, Test_accy 69.80
2024-08-02 16:27:41,855 [foster.py] => Task 12, Epoch 124/170 => Loss 3.033, Loss_clf 0.315, Loss_fe 0.193, Loss_kd 2.455, Train_accy 85.86, Test_accy 69.76
2024-08-02 16:27:46,162 [foster.py] => Task 12, Epoch 125/170 => Loss 2.935, Loss_clf 0.302, Loss_fe 0.149, Loss_kd 2.414, Train_accy 86.48, Test_accy 69.54
2024-08-02 16:27:48,735 [foster.py] => Task 12, Epoch 126/170 => Loss 2.982, Loss_clf 0.305, Loss_fe 0.158, Loss_kd 2.449, Train_accy 85.29
2024-08-02 16:27:53,032 [foster.py] => Task 12, Epoch 127/170 => Loss 2.956, Loss_clf 0.299, Loss_fe 0.157, Loss_kd 2.431, Train_accy 86.02, Test_accy 69.91
2024-08-02 16:27:57,309 [foster.py] => Task 12, Epoch 128/170 => Loss 2.946, Loss_clf 0.316, Loss_fe 0.137, Loss_kd 2.424, Train_accy 86.64, Test_accy 69.76
2024-08-02 16:28:01,604 [foster.py] => Task 12, Epoch 129/170 => Loss 2.917, Loss_clf 0.292, Loss_fe 0.136, Loss_kd 2.421, Train_accy 85.94, Test_accy 69.70
2024-08-02 16:28:05,907 [foster.py] => Task 12, Epoch 130/170 => Loss 2.912, Loss_clf 0.305, Loss_fe 0.132, Loss_kd 2.406, Train_accy 85.49, Test_accy 69.53
2024-08-02 16:28:08,499 [foster.py] => Task 12, Epoch 131/170 => Loss 3.006, Loss_clf 0.334, Loss_fe 0.153, Loss_kd 2.450, Train_accy 86.39
2024-08-02 16:28:12,760 [foster.py] => Task 12, Epoch 132/170 => Loss 2.971, Loss_clf 0.315, Loss_fe 0.146, Loss_kd 2.441, Train_accy 86.76, Test_accy 69.64
2024-08-02 16:28:17,064 [foster.py] => Task 12, Epoch 133/170 => Loss 2.941, Loss_clf 0.317, Loss_fe 0.129, Loss_kd 2.426, Train_accy 85.61, Test_accy 69.64
2024-08-02 16:28:21,386 [foster.py] => Task 12, Epoch 134/170 => Loss 2.965, Loss_clf 0.331, Loss_fe 0.161, Loss_kd 2.405, Train_accy 86.60, Test_accy 69.65
2024-08-02 16:28:25,690 [foster.py] => Task 12, Epoch 135/170 => Loss 2.907, Loss_clf 0.302, Loss_fe 0.129, Loss_kd 2.408, Train_accy 85.33, Test_accy 69.86
2024-08-02 16:28:28,256 [foster.py] => Task 12, Epoch 136/170 => Loss 2.941, Loss_clf 0.306, Loss_fe 0.140, Loss_kd 2.426, Train_accy 86.56
2024-08-02 16:28:32,591 [foster.py] => Task 12, Epoch 137/170 => Loss 3.053, Loss_clf 0.345, Loss_fe 0.179, Loss_kd 2.460, Train_accy 85.78, Test_accy 69.55
2024-08-02 16:28:36,866 [foster.py] => Task 12, Epoch 138/170 => Loss 2.873, Loss_clf 0.271, Loss_fe 0.144, Loss_kd 2.391, Train_accy 86.80, Test_accy 69.70
2024-08-02 16:28:41,168 [foster.py] => Task 12, Epoch 139/170 => Loss 2.917, Loss_clf 0.298, Loss_fe 0.122, Loss_kd 2.428, Train_accy 84.92, Test_accy 69.70
2024-08-02 16:28:45,478 [foster.py] => Task 12, Epoch 140/170 => Loss 2.853, Loss_clf 0.274, Loss_fe 0.109, Loss_kd 2.401, Train_accy 86.11, Test_accy 69.81
2024-08-02 16:28:48,082 [foster.py] => Task 12, Epoch 141/170 => Loss 2.837, Loss_clf 0.276, Loss_fe 0.111, Loss_kd 2.383, Train_accy 86.31
2024-08-02 16:28:52,387 [foster.py] => Task 12, Epoch 142/170 => Loss 2.900, Loss_clf 0.286, Loss_fe 0.114, Loss_kd 2.431, Train_accy 86.97, Test_accy 69.80
2024-08-02 16:28:56,658 [foster.py] => Task 12, Epoch 143/170 => Loss 2.911, Loss_clf 0.283, Loss_fe 0.161, Loss_kd 2.398, Train_accy 87.30, Test_accy 69.82
2024-08-02 16:29:00,956 [foster.py] => Task 12, Epoch 144/170 => Loss 2.984, Loss_clf 0.332, Loss_fe 0.120, Loss_kd 2.463, Train_accy 87.99, Test_accy 69.57
2024-08-02 16:29:05,253 [foster.py] => Task 12, Epoch 145/170 => Loss 2.884, Loss_clf 0.286, Loss_fe 0.135, Loss_kd 2.395, Train_accy 87.01, Test_accy 69.76
2024-08-02 16:29:07,872 [foster.py] => Task 12, Epoch 146/170 => Loss 2.913, Loss_clf 0.287, Loss_fe 0.130, Loss_kd 2.428, Train_accy 87.09
2024-08-02 16:29:12,200 [foster.py] => Task 12, Epoch 147/170 => Loss 2.921, Loss_clf 0.283, Loss_fe 0.121, Loss_kd 2.448, Train_accy 87.17, Test_accy 69.77
2024-08-02 16:29:16,584 [foster.py] => Task 12, Epoch 148/170 => Loss 3.002, Loss_clf 0.334, Loss_fe 0.167, Loss_kd 2.432, Train_accy 87.25, Test_accy 69.92
2024-08-02 16:29:21,068 [foster.py] => Task 12, Epoch 149/170 => Loss 2.962, Loss_clf 0.340, Loss_fe 0.117, Loss_kd 2.436, Train_accy 85.08, Test_accy 69.85
2024-08-02 16:29:25,475 [foster.py] => Task 12, Epoch 150/170 => Loss 2.931, Loss_clf 0.324, Loss_fe 0.114, Loss_kd 2.424, Train_accy 86.76, Test_accy 69.81
2024-08-02 16:29:28,041 [foster.py] => Task 12, Epoch 151/170 => Loss 2.916, Loss_clf 0.293, Loss_fe 0.111, Loss_kd 2.442, Train_accy 86.19
2024-08-02 16:29:32,372 [foster.py] => Task 12, Epoch 152/170 => Loss 2.937, Loss_clf 0.329, Loss_fe 0.125, Loss_kd 2.415, Train_accy 84.80, Test_accy 69.92
2024-08-02 16:29:36,742 [foster.py] => Task 12, Epoch 153/170 => Loss 2.865, Loss_clf 0.282, Loss_fe 0.110, Loss_kd 2.404, Train_accy 86.80, Test_accy 69.97
2024-08-02 16:29:41,137 [foster.py] => Task 12, Epoch 154/170 => Loss 2.931, Loss_clf 0.303, Loss_fe 0.125, Loss_kd 2.434, Train_accy 86.11, Test_accy 69.88
2024-08-02 16:29:45,526 [foster.py] => Task 12, Epoch 155/170 => Loss 2.939, Loss_clf 0.287, Loss_fe 0.170, Loss_kd 2.413, Train_accy 86.84, Test_accy 69.84
2024-08-02 16:29:48,097 [foster.py] => Task 12, Epoch 156/170 => Loss 2.958, Loss_clf 0.319, Loss_fe 0.117, Loss_kd 2.452, Train_accy 85.53
2024-08-02 16:29:52,436 [foster.py] => Task 12, Epoch 157/170 => Loss 2.941, Loss_clf 0.295, Loss_fe 0.164, Loss_kd 2.414, Train_accy 86.60, Test_accy 69.97
2024-08-02 16:29:56,768 [foster.py] => Task 12, Epoch 158/170 => Loss 2.947, Loss_clf 0.321, Loss_fe 0.119, Loss_kd 2.437, Train_accy 85.33, Test_accy 69.85
2024-08-02 16:30:01,096 [foster.py] => Task 12, Epoch 159/170 => Loss 2.832, Loss_clf 0.269, Loss_fe 0.105, Loss_kd 2.390, Train_accy 86.48, Test_accy 69.89
2024-08-02 16:30:05,449 [foster.py] => Task 12, Epoch 160/170 => Loss 2.915, Loss_clf 0.294, Loss_fe 0.117, Loss_kd 2.434, Train_accy 86.19, Test_accy 69.86
2024-08-02 16:30:08,101 [foster.py] => Task 12, Epoch 161/170 => Loss 2.927, Loss_clf 0.296, Loss_fe 0.133, Loss_kd 2.429, Train_accy 84.67
2024-08-02 16:30:12,572 [foster.py] => Task 12, Epoch 162/170 => Loss 2.902, Loss_clf 0.261, Loss_fe 0.141, Loss_kd 2.430, Train_accy 87.09, Test_accy 69.82
2024-08-02 16:30:16,979 [foster.py] => Task 12, Epoch 163/170 => Loss 2.889, Loss_clf 0.288, Loss_fe 0.115, Loss_kd 2.417, Train_accy 85.53, Test_accy 69.88
2024-08-02 16:30:21,268 [foster.py] => Task 12, Epoch 164/170 => Loss 2.911, Loss_clf 0.296, Loss_fe 0.104, Loss_kd 2.442, Train_accy 86.35, Test_accy 69.93
2024-08-02 16:30:25,560 [foster.py] => Task 12, Epoch 165/170 => Loss 2.948, Loss_clf 0.318, Loss_fe 0.114, Loss_kd 2.446, Train_accy 85.98, Test_accy 69.88
2024-08-02 16:30:28,126 [foster.py] => Task 12, Epoch 166/170 => Loss 2.868, Loss_clf 0.295, Loss_fe 0.106, Loss_kd 2.399, Train_accy 85.98
2024-08-02 16:30:32,429 [foster.py] => Task 12, Epoch 167/170 => Loss 2.871, Loss_clf 0.280, Loss_fe 0.129, Loss_kd 2.395, Train_accy 87.38, Test_accy 69.88
2024-08-02 16:30:36,701 [foster.py] => Task 12, Epoch 168/170 => Loss 2.993, Loss_clf 0.336, Loss_fe 0.132, Loss_kd 2.454, Train_accy 85.61, Test_accy 69.89
2024-08-02 16:30:41,029 [foster.py] => Task 12, Epoch 169/170 => Loss 2.836, Loss_clf 0.270, Loss_fe 0.106, Loss_kd 2.392, Train_accy 86.39, Test_accy 69.89
2024-08-02 16:30:45,343 [foster.py] => Task 12, Epoch 170/170 => Loss 2.952, Loss_clf 0.306, Loss_fe 0.128, Loss_kd 2.449, Train_accy 85.78, Test_accy 69.85
2024-08-02 16:30:45,345 [foster.py] => do not weight align teacher!
2024-08-02 16:30:45,346 [foster.py] => per cls weights : [1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955 1.01471955
 0.47009627 0.47009627]
2024-08-02 16:30:50,248 [foster.py] => SNet: Task 12, Epoch 1/130 => Loss 29.471,  Loss1 0.739, Train_accy 50.98, Test_accy 66.18
2024-08-02 16:30:53,822 [foster.py] => SNet: Task 12, Epoch 2/130 => Loss 29.293,  Loss1 0.738, Train_accy 62.21
2024-08-02 16:30:57,352 [foster.py] => SNet: Task 12, Epoch 3/130 => Loss 29.257,  Loss1 0.738, Train_accy 62.95
2024-08-02 16:31:00,939 [foster.py] => SNet: Task 12, Epoch 4/130 => Loss 29.247,  Loss1 0.739, Train_accy 63.77
2024-08-02 16:31:04,499 [foster.py] => SNet: Task 12, Epoch 5/130 => Loss 29.219,  Loss1 0.737, Train_accy 64.30
2024-08-02 16:31:09,145 [foster.py] => SNet: Task 12, Epoch 6/130 => Loss 29.280,  Loss1 0.737, Train_accy 66.72, Test_accy 66.97
2024-08-02 16:31:12,693 [foster.py] => SNet: Task 12, Epoch 7/130 => Loss 29.291,  Loss1 0.739, Train_accy 66.02
2024-08-02 16:31:16,222 [foster.py] => SNet: Task 12, Epoch 8/130 => Loss 29.297,  Loss1 0.739, Train_accy 65.82
2024-08-02 16:31:19,810 [foster.py] => SNet: Task 12, Epoch 9/130 => Loss 29.225,  Loss1 0.738, Train_accy 67.75
2024-08-02 16:31:23,390 [foster.py] => SNet: Task 12, Epoch 10/130 => Loss 29.267,  Loss1 0.738, Train_accy 68.20
2024-08-02 16:31:28,022 [foster.py] => SNet: Task 12, Epoch 11/130 => Loss 29.281,  Loss1 0.738, Train_accy 68.24, Test_accy 67.76
2024-08-02 16:31:31,555 [foster.py] => SNet: Task 12, Epoch 12/130 => Loss 29.289,  Loss1 0.738, Train_accy 70.04
2024-08-02 16:31:35,105 [foster.py] => SNet: Task 12, Epoch 13/130 => Loss 29.291,  Loss1 0.738, Train_accy 67.79
2024-08-02 16:31:38,641 [foster.py] => SNet: Task 12, Epoch 14/130 => Loss 29.360,  Loss1 0.738, Train_accy 69.22
2024-08-02 16:31:42,221 [foster.py] => SNet: Task 12, Epoch 15/130 => Loss 29.303,  Loss1 0.737, Train_accy 69.75
2024-08-02 16:31:46,862 [foster.py] => SNet: Task 12, Epoch 16/130 => Loss 29.284,  Loss1 0.737, Train_accy 69.80, Test_accy 67.85
2024-08-02 16:31:50,386 [foster.py] => SNet: Task 12, Epoch 17/130 => Loss 29.217,  Loss1 0.738, Train_accy 70.86
2024-08-02 16:31:53,951 [foster.py] => SNet: Task 12, Epoch 18/130 => Loss 29.259,  Loss1 0.738, Train_accy 70.61
2024-08-02 16:31:57,550 [foster.py] => SNet: Task 12, Epoch 19/130 => Loss 29.285,  Loss1 0.738, Train_accy 70.04
2024-08-02 16:32:01,076 [foster.py] => SNet: Task 12, Epoch 20/130 => Loss 29.261,  Loss1 0.737, Train_accy 72.01
2024-08-02 16:32:05,745 [foster.py] => SNet: Task 12, Epoch 21/130 => Loss 29.264,  Loss1 0.737, Train_accy 71.68, Test_accy 67.42
2024-08-02 16:32:09,332 [foster.py] => SNet: Task 12, Epoch 22/130 => Loss 29.314,  Loss1 0.738, Train_accy 70.57
2024-08-02 16:32:12,872 [foster.py] => SNet: Task 12, Epoch 23/130 => Loss 29.276,  Loss1 0.738, Train_accy 71.02
2024-08-02 16:32:16,425 [foster.py] => SNet: Task 12, Epoch 24/130 => Loss 29.258,  Loss1 0.738, Train_accy 70.78
2024-08-02 16:32:19,982 [foster.py] => SNet: Task 12, Epoch 25/130 => Loss 29.264,  Loss1 0.737, Train_accy 70.57
2024-08-02 16:32:24,655 [foster.py] => SNet: Task 12, Epoch 26/130 => Loss 29.261,  Loss1 0.738, Train_accy 74.75, Test_accy 68.16
2024-08-02 16:32:28,232 [foster.py] => SNet: Task 12, Epoch 27/130 => Loss 29.235,  Loss1 0.737, Train_accy 72.46
2024-08-02 16:32:31,824 [foster.py] => SNet: Task 12, Epoch 28/130 => Loss 29.268,  Loss1 0.738, Train_accy 71.64
2024-08-02 16:32:35,389 [foster.py] => SNet: Task 12, Epoch 29/130 => Loss 29.269,  Loss1 0.738, Train_accy 69.80
2024-08-02 16:32:38,941 [foster.py] => SNet: Task 12, Epoch 30/130 => Loss 29.281,  Loss1 0.738, Train_accy 74.18
2024-08-02 16:32:43,568 [foster.py] => SNet: Task 12, Epoch 31/130 => Loss 29.255,  Loss1 0.738, Train_accy 72.70, Test_accy 68.35
2024-08-02 16:32:47,101 [foster.py] => SNet: Task 12, Epoch 32/130 => Loss 29.256,  Loss1 0.737, Train_accy 72.58
2024-08-02 16:32:50,632 [foster.py] => SNet: Task 12, Epoch 33/130 => Loss 29.303,  Loss1 0.737, Train_accy 71.68
2024-08-02 16:32:54,190 [foster.py] => SNet: Task 12, Epoch 34/130 => Loss 29.259,  Loss1 0.738, Train_accy 73.24
2024-08-02 16:32:57,738 [foster.py] => SNet: Task 12, Epoch 35/130 => Loss 29.246,  Loss1 0.737, Train_accy 71.56
2024-08-02 16:33:02,401 [foster.py] => SNet: Task 12, Epoch 36/130 => Loss 29.270,  Loss1 0.739, Train_accy 71.72, Test_accy 67.36
2024-08-02 16:33:06,032 [foster.py] => SNet: Task 12, Epoch 37/130 => Loss 29.270,  Loss1 0.738, Train_accy 71.11
2024-08-02 16:33:09,583 [foster.py] => SNet: Task 12, Epoch 38/130 => Loss 29.230,  Loss1 0.736, Train_accy 73.61
2024-08-02 16:33:13,121 [foster.py] => SNet: Task 12, Epoch 39/130 => Loss 29.264,  Loss1 0.738, Train_accy 72.91
2024-08-02 16:33:16,650 [foster.py] => SNet: Task 12, Epoch 40/130 => Loss 29.300,  Loss1 0.737, Train_accy 70.90
2024-08-02 16:33:21,320 [foster.py] => SNet: Task 12, Epoch 41/130 => Loss 29.277,  Loss1 0.737, Train_accy 72.70, Test_accy 67.97
2024-08-02 16:33:24,860 [foster.py] => SNet: Task 12, Epoch 42/130 => Loss 29.217,  Loss1 0.738, Train_accy 71.97
2024-08-02 16:33:28,415 [foster.py] => SNet: Task 12, Epoch 43/130 => Loss 29.222,  Loss1 0.738, Train_accy 72.75
2024-08-02 16:33:31,956 [foster.py] => SNet: Task 12, Epoch 44/130 => Loss 29.284,  Loss1 0.738, Train_accy 73.11
2024-08-02 16:33:35,497 [foster.py] => SNet: Task 12, Epoch 45/130 => Loss 29.254,  Loss1 0.738, Train_accy 71.68
2024-08-02 16:33:40,164 [foster.py] => SNet: Task 12, Epoch 46/130 => Loss 29.222,  Loss1 0.737, Train_accy 73.57, Test_accy 67.86
2024-08-02 16:33:43,704 [foster.py] => SNet: Task 12, Epoch 47/130 => Loss 29.248,  Loss1 0.737, Train_accy 71.15
2024-08-02 16:33:47,275 [foster.py] => SNet: Task 12, Epoch 48/130 => Loss 29.275,  Loss1 0.739, Train_accy 71.07
2024-08-02 16:33:50,819 [foster.py] => SNet: Task 12, Epoch 49/130 => Loss 29.268,  Loss1 0.737, Train_accy 73.85
2024-08-02 16:33:54,365 [foster.py] => SNet: Task 12, Epoch 50/130 => Loss 29.260,  Loss1 0.737, Train_accy 72.91
2024-08-02 16:33:58,987 [foster.py] => SNet: Task 12, Epoch 51/130 => Loss 29.278,  Loss1 0.738, Train_accy 74.34, Test_accy 68.28
2024-08-02 16:34:02,524 [foster.py] => SNet: Task 12, Epoch 52/130 => Loss 29.297,  Loss1 0.738, Train_accy 73.73
2024-08-02 16:34:06,068 [foster.py] => SNet: Task 12, Epoch 53/130 => Loss 29.268,  Loss1 0.737, Train_accy 74.14
2024-08-02 16:34:09,592 [foster.py] => SNet: Task 12, Epoch 54/130 => Loss 29.240,  Loss1 0.738, Train_accy 73.89
2024-08-02 16:34:13,181 [foster.py] => SNet: Task 12, Epoch 55/130 => Loss 29.278,  Loss1 0.738, Train_accy 73.69
2024-08-02 16:34:17,825 [foster.py] => SNet: Task 12, Epoch 56/130 => Loss 29.255,  Loss1 0.738, Train_accy 73.32, Test_accy 68.08
2024-08-02 16:34:21,381 [foster.py] => SNet: Task 12, Epoch 57/130 => Loss 29.298,  Loss1 0.738, Train_accy 72.95
2024-08-02 16:34:24,926 [foster.py] => SNet: Task 12, Epoch 58/130 => Loss 29.223,  Loss1 0.737, Train_accy 71.97
2024-08-02 16:34:28,471 [foster.py] => SNet: Task 12, Epoch 59/130 => Loss 29.278,  Loss1 0.737, Train_accy 73.57
2024-08-02 16:34:32,038 [foster.py] => SNet: Task 12, Epoch 60/130 => Loss 29.202,  Loss1 0.737, Train_accy 73.40
2024-08-02 16:34:36,711 [foster.py] => SNet: Task 12, Epoch 61/130 => Loss 29.224,  Loss1 0.737, Train_accy 74.59, Test_accy 68.16
2024-08-02 16:34:40,294 [foster.py] => SNet: Task 12, Epoch 62/130 => Loss 29.228,  Loss1 0.738, Train_accy 72.70
2024-08-02 16:34:43,827 [foster.py] => SNet: Task 12, Epoch 63/130 => Loss 29.186,  Loss1 0.738, Train_accy 73.36
2024-08-02 16:34:47,375 [foster.py] => SNet: Task 12, Epoch 64/130 => Loss 29.237,  Loss1 0.738, Train_accy 73.16
2024-08-02 16:34:50,916 [foster.py] => SNet: Task 12, Epoch 65/130 => Loss 29.212,  Loss1 0.738, Train_accy 72.42
2024-08-02 16:34:55,540 [foster.py] => SNet: Task 12, Epoch 66/130 => Loss 29.255,  Loss1 0.737, Train_accy 72.38, Test_accy 67.72
2024-08-02 16:34:59,088 [foster.py] => SNet: Task 12, Epoch 67/130 => Loss 29.225,  Loss1 0.737, Train_accy 74.30
2024-08-02 16:35:02,658 [foster.py] => SNet: Task 12, Epoch 68/130 => Loss 29.283,  Loss1 0.738, Train_accy 74.39
2024-08-02 16:35:06,192 [foster.py] => SNet: Task 12, Epoch 69/130 => Loss 29.252,  Loss1 0.737, Train_accy 74.75
2024-08-02 16:35:09,741 [foster.py] => SNet: Task 12, Epoch 70/130 => Loss 29.234,  Loss1 0.737, Train_accy 73.73
2024-08-02 16:35:14,369 [foster.py] => SNet: Task 12, Epoch 71/130 => Loss 29.241,  Loss1 0.738, Train_accy 73.69, Test_accy 68.54
2024-08-02 16:35:17,911 [foster.py] => SNet: Task 12, Epoch 72/130 => Loss 29.259,  Loss1 0.738, Train_accy 72.79
2024-08-02 16:35:21,449 [foster.py] => SNet: Task 12, Epoch 73/130 => Loss 29.243,  Loss1 0.738, Train_accy 73.85
2024-08-02 16:35:25,100 [foster.py] => SNet: Task 12, Epoch 74/130 => Loss 29.256,  Loss1 0.737, Train_accy 72.34
2024-08-02 16:35:28,663 [foster.py] => SNet: Task 12, Epoch 75/130 => Loss 29.188,  Loss1 0.737, Train_accy 75.37
2024-08-02 16:35:33,291 [foster.py] => SNet: Task 12, Epoch 76/130 => Loss 29.305,  Loss1 0.737, Train_accy 73.52, Test_accy 68.34
2024-08-02 16:35:36,867 [foster.py] => SNet: Task 12, Epoch 77/130 => Loss 29.206,  Loss1 0.736, Train_accy 74.02
2024-08-02 16:35:40,474 [foster.py] => SNet: Task 12, Epoch 78/130 => Loss 29.259,  Loss1 0.737, Train_accy 73.98
2024-08-02 16:35:44,051 [foster.py] => SNet: Task 12, Epoch 79/130 => Loss 29.225,  Loss1 0.737, Train_accy 72.54
2024-08-02 16:35:47,590 [foster.py] => SNet: Task 12, Epoch 80/130 => Loss 29.195,  Loss1 0.737, Train_accy 73.77
2024-08-02 16:35:52,302 [foster.py] => SNet: Task 12, Epoch 81/130 => Loss 29.263,  Loss1 0.738, Train_accy 74.55, Test_accy 68.46
2024-08-02 16:35:55,854 [foster.py] => SNet: Task 12, Epoch 82/130 => Loss 29.247,  Loss1 0.738, Train_accy 73.98
2024-08-02 16:35:59,437 [foster.py] => SNet: Task 12, Epoch 83/130 => Loss 29.247,  Loss1 0.738, Train_accy 74.34
2024-08-02 16:36:02,974 [foster.py] => SNet: Task 12, Epoch 84/130 => Loss 29.262,  Loss1 0.738, Train_accy 75.74
2024-08-02 16:36:06,512 [foster.py] => SNet: Task 12, Epoch 85/130 => Loss 29.204,  Loss1 0.737, Train_accy 73.85
2024-08-02 16:36:11,149 [foster.py] => SNet: Task 12, Epoch 86/130 => Loss 29.232,  Loss1 0.737, Train_accy 74.47, Test_accy 68.49
2024-08-02 16:36:14,696 [foster.py] => SNet: Task 12, Epoch 87/130 => Loss 29.252,  Loss1 0.737, Train_accy 72.87
2024-08-02 16:36:18,225 [foster.py] => SNet: Task 12, Epoch 88/130 => Loss 29.200,  Loss1 0.738, Train_accy 74.96
2024-08-02 16:36:21,761 [foster.py] => SNet: Task 12, Epoch 89/130 => Loss 29.234,  Loss1 0.737, Train_accy 72.99
2024-08-02 16:36:25,316 [foster.py] => SNet: Task 12, Epoch 90/130 => Loss 29.262,  Loss1 0.737, Train_accy 73.93
2024-08-02 16:36:29,965 [foster.py] => SNet: Task 12, Epoch 91/130 => Loss 29.203,  Loss1 0.737, Train_accy 75.29, Test_accy 68.58
2024-08-02 16:36:33,554 [foster.py] => SNet: Task 12, Epoch 92/130 => Loss 29.220,  Loss1 0.737, Train_accy 75.29
2024-08-02 16:36:37,116 [foster.py] => SNet: Task 12, Epoch 93/130 => Loss 29.226,  Loss1 0.737, Train_accy 74.47
2024-08-02 16:36:40,630 [foster.py] => SNet: Task 12, Epoch 94/130 => Loss 29.192,  Loss1 0.737, Train_accy 74.30
2024-08-02 16:36:44,169 [foster.py] => SNet: Task 12, Epoch 95/130 => Loss 29.267,  Loss1 0.737, Train_accy 74.84
2024-08-02 16:36:48,882 [foster.py] => SNet: Task 12, Epoch 96/130 => Loss 29.252,  Loss1 0.737, Train_accy 74.92, Test_accy 68.51
2024-08-02 16:36:52,427 [foster.py] => SNet: Task 12, Epoch 97/130 => Loss 29.241,  Loss1 0.737, Train_accy 73.85
2024-08-02 16:36:55,978 [foster.py] => SNet: Task 12, Epoch 98/130 => Loss 29.246,  Loss1 0.737, Train_accy 75.20
2024-08-02 16:36:59,549 [foster.py] => SNet: Task 12, Epoch 99/130 => Loss 29.285,  Loss1 0.738, Train_accy 74.51
2024-08-02 16:37:03,097 [foster.py] => SNet: Task 12, Epoch 100/130 => Loss 29.236,  Loss1 0.737, Train_accy 75.29
2024-08-02 16:37:07,774 [foster.py] => SNet: Task 12, Epoch 101/130 => Loss 29.199,  Loss1 0.738, Train_accy 74.02, Test_accy 68.09
2024-08-02 16:37:11,327 [foster.py] => SNet: Task 12, Epoch 102/130 => Loss 29.259,  Loss1 0.737, Train_accy 74.75
2024-08-02 16:37:14,861 [foster.py] => SNet: Task 12, Epoch 103/130 => Loss 29.229,  Loss1 0.737, Train_accy 73.48
2024-08-02 16:37:18,405 [foster.py] => SNet: Task 12, Epoch 104/130 => Loss 29.210,  Loss1 0.737, Train_accy 75.37
2024-08-02 16:37:21,970 [foster.py] => SNet: Task 12, Epoch 105/130 => Loss 29.186,  Loss1 0.737, Train_accy 73.93
2024-08-02 16:37:26,599 [foster.py] => SNet: Task 12, Epoch 106/130 => Loss 29.240,  Loss1 0.738, Train_accy 73.61, Test_accy 68.82
2024-08-02 16:37:30,150 [foster.py] => SNet: Task 12, Epoch 107/130 => Loss 29.183,  Loss1 0.737, Train_accy 74.71
2024-08-02 16:37:33,720 [foster.py] => SNet: Task 12, Epoch 108/130 => Loss 29.207,  Loss1 0.737, Train_accy 73.73
2024-08-02 16:37:37,270 [foster.py] => SNet: Task 12, Epoch 109/130 => Loss 29.205,  Loss1 0.738, Train_accy 74.10
2024-08-02 16:37:40,882 [foster.py] => SNet: Task 12, Epoch 110/130 => Loss 29.207,  Loss1 0.737, Train_accy 74.84
2024-08-02 16:37:45,507 [foster.py] => SNet: Task 12, Epoch 111/130 => Loss 29.177,  Loss1 0.737, Train_accy 75.16, Test_accy 68.78
2024-08-02 16:37:49,045 [foster.py] => SNet: Task 12, Epoch 112/130 => Loss 29.215,  Loss1 0.737, Train_accy 75.74
2024-08-02 16:37:52,602 [foster.py] => SNet: Task 12, Epoch 113/130 => Loss 29.247,  Loss1 0.737, Train_accy 74.47
2024-08-02 16:37:56,138 [foster.py] => SNet: Task 12, Epoch 114/130 => Loss 29.263,  Loss1 0.737, Train_accy 74.47
2024-08-02 16:37:59,696 [foster.py] => SNet: Task 12, Epoch 115/130 => Loss 29.247,  Loss1 0.737, Train_accy 74.14
2024-08-02 16:38:04,358 [foster.py] => SNet: Task 12, Epoch 116/130 => Loss 29.249,  Loss1 0.737, Train_accy 74.14, Test_accy 68.26
2024-08-02 16:38:07,921 [foster.py] => SNet: Task 12, Epoch 117/130 => Loss 29.268,  Loss1 0.737, Train_accy 74.06
2024-08-02 16:38:11,494 [foster.py] => SNet: Task 12, Epoch 118/130 => Loss 29.262,  Loss1 0.737, Train_accy 73.77
2024-08-02 16:38:15,032 [foster.py] => SNet: Task 12, Epoch 119/130 => Loss 29.207,  Loss1 0.737, Train_accy 75.20
2024-08-02 16:38:18,606 [foster.py] => SNet: Task 12, Epoch 120/130 => Loss 29.219,  Loss1 0.737, Train_accy 75.16
2024-08-02 16:38:23,253 [foster.py] => SNet: Task 12, Epoch 121/130 => Loss 29.234,  Loss1 0.738, Train_accy 75.25, Test_accy 68.54
2024-08-02 16:38:26,790 [foster.py] => SNet: Task 12, Epoch 122/130 => Loss 29.238,  Loss1 0.737, Train_accy 74.51
2024-08-02 16:38:30,347 [foster.py] => SNet: Task 12, Epoch 123/130 => Loss 29.251,  Loss1 0.738, Train_accy 74.18
2024-08-02 16:38:33,866 [foster.py] => SNet: Task 12, Epoch 124/130 => Loss 29.228,  Loss1 0.737, Train_accy 74.75
2024-08-02 16:38:37,443 [foster.py] => SNet: Task 12, Epoch 125/130 => Loss 29.163,  Loss1 0.737, Train_accy 74.43
2024-08-02 16:38:42,087 [foster.py] => SNet: Task 12, Epoch 126/130 => Loss 29.256,  Loss1 0.737, Train_accy 73.61, Test_accy 68.46
2024-08-02 16:38:45,638 [foster.py] => SNet: Task 12, Epoch 127/130 => Loss 29.229,  Loss1 0.737, Train_accy 75.66
2024-08-02 16:38:49,226 [foster.py] => SNet: Task 12, Epoch 128/130 => Loss 29.197,  Loss1 0.738, Train_accy 75.37
2024-08-02 16:38:52,760 [foster.py] => SNet: Task 12, Epoch 129/130 => Loss 29.222,  Loss1 0.738, Train_accy 74.59
2024-08-02 16:38:56,311 [foster.py] => SNet: Task 12, Epoch 130/130 => Loss 29.273,  Loss1 0.737, Train_accy 73.89
2024-08-02 16:38:56,312 [foster.py] => do not weight align student!
2024-08-02 16:38:57,408 [foster.py] => darknet eval: 
2024-08-02 16:38:57,408 [foster.py] => CNN top1 curve: 68.27
2024-08-02 16:38:57,408 [foster.py] => CNN top5 curve: 90.38
2024-08-02 16:38:57,409 [foster.py] => CNN top1 平均值: 68.27
2024-08-02 16:38:57,412 [foster.py] => timees : 1167.7405574321747
2024-08-02 16:38:57,413 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 16:39:19,998 [foster.py] => Exemplar size: 1480
2024-08-02 16:39:19,998 [trainer.py] => CNN: {'total': 69.85, '00-09': 76.2, '10-19': 61.2, '20-29': 76.1, '30-39': 68.1, '40-49': 73.9, '50-59': 60.9, '60-69': 71.4, '70-79': 72.75, 'old': 69.64, 'new': 77.5}
2024-08-02 16:39:19,998 [trainer.py] => NME: {'total': 64.74, '00-09': 67.3, '10-19': 54.0, '20-29': 70.7, '30-39': 62.9, '40-49': 67.7, '50-59': 61.2, '60-69': 68.1, '70-79': 68.0, 'old': 64.03, 'new': 90.5}
2024-08-02 16:39:19,998 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85]
2024-08-02 16:39:19,998 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19]
2024-08-02 16:39:19,998 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74]
2024-08-02 16:39:19,998 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91]

2024-08-02 16:39:19,998 [trainer.py] => CNN top1 平均值: 75.43
2024-08-02 16:39:20,001 [trainer.py] => All params: 1173584
2024-08-02 16:39:20,003 [trainer.py] => Trainable params: 591630
2024-08-02 16:39:20,064 [foster.py] => Learning on 74-76
2024-08-02 16:39:20,067 [foster.py] => All params: 1174102
2024-08-02 16:39:20,069 [foster.py] => Trainable params: 592018
2024-08-02 16:39:20,109 [foster.py] => per cls weights : [1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167 1.01206167
 1.01206167 1.01206167 0.55371827 0.55371827]
2024-08-02 16:39:22,760 [foster.py] => Task 13, Epoch 1/170 => Loss 5.582, Loss_clf 1.060, Loss_fe 2.023, Loss_kd 2.432, Train_accy 66.90
2024-08-02 16:39:27,131 [foster.py] => Task 13, Epoch 2/170 => Loss 3.911, Loss_clf 0.615, Loss_fe 0.831, Loss_kd 2.399, Train_accy 68.55, Test_accy 67.28
2024-08-02 16:39:31,438 [foster.py] => Task 13, Epoch 3/170 => Loss 3.624, Loss_clf 0.512, Loss_fe 0.673, Loss_kd 2.372, Train_accy 69.44, Test_accy 67.34
2024-08-02 16:39:35,792 [foster.py] => Task 13, Epoch 4/170 => Loss 3.589, Loss_clf 0.515, Loss_fe 0.609, Loss_kd 2.398, Train_accy 70.04, Test_accy 67.71
2024-08-02 16:39:40,109 [foster.py] => Task 13, Epoch 5/170 => Loss 3.549, Loss_clf 0.519, Loss_fe 0.572, Loss_kd 2.392, Train_accy 70.60, Test_accy 67.74
2024-08-02 16:39:42,713 [foster.py] => Task 13, Epoch 6/170 => Loss 3.512, Loss_clf 0.513, Loss_fe 0.526, Loss_kd 2.407, Train_accy 70.85
2024-08-02 16:39:47,072 [foster.py] => Task 13, Epoch 7/170 => Loss 3.423, Loss_clf 0.484, Loss_fe 0.495, Loss_kd 2.378, Train_accy 71.29, Test_accy 67.83
2024-08-02 16:39:51,412 [foster.py] => Task 13, Epoch 8/170 => Loss 3.418, Loss_clf 0.486, Loss_fe 0.477, Loss_kd 2.388, Train_accy 72.78, Test_accy 67.55
2024-08-02 16:39:55,741 [foster.py] => Task 13, Epoch 9/170 => Loss 3.362, Loss_clf 0.466, Loss_fe 0.457, Loss_kd 2.373, Train_accy 73.06, Test_accy 67.83
2024-08-02 16:40:00,124 [foster.py] => Task 13, Epoch 10/170 => Loss 3.396, Loss_clf 0.482, Loss_fe 0.430, Loss_kd 2.416, Train_accy 73.59, Test_accy 67.64
2024-08-02 16:40:02,702 [foster.py] => Task 13, Epoch 11/170 => Loss 3.370, Loss_clf 0.483, Loss_fe 0.451, Loss_kd 2.371, Train_accy 73.91
2024-08-02 16:40:07,129 [foster.py] => Task 13, Epoch 12/170 => Loss 3.293, Loss_clf 0.441, Loss_fe 0.408, Loss_kd 2.378, Train_accy 75.24, Test_accy 67.79
2024-08-02 16:40:11,477 [foster.py] => Task 13, Epoch 13/170 => Loss 3.379, Loss_clf 0.473, Loss_fe 0.435, Loss_kd 2.404, Train_accy 75.04, Test_accy 67.66
2024-08-02 16:40:15,815 [foster.py] => Task 13, Epoch 14/170 => Loss 3.380, Loss_clf 0.490, Loss_fe 0.439, Loss_kd 2.385, Train_accy 74.48, Test_accy 67.88
2024-08-02 16:40:20,173 [foster.py] => Task 13, Epoch 15/170 => Loss 3.308, Loss_clf 0.459, Loss_fe 0.392, Loss_kd 2.390, Train_accy 73.63, Test_accy 68.00
2024-08-02 16:40:22,811 [foster.py] => Task 13, Epoch 16/170 => Loss 3.287, Loss_clf 0.450, Loss_fe 0.376, Loss_kd 2.394, Train_accy 74.80
2024-08-02 16:40:27,160 [foster.py] => Task 13, Epoch 17/170 => Loss 3.217, Loss_clf 0.423, Loss_fe 0.354, Loss_kd 2.374, Train_accy 76.85, Test_accy 68.05
2024-08-02 16:40:31,512 [foster.py] => Task 13, Epoch 18/170 => Loss 3.320, Loss_clf 0.449, Loss_fe 0.406, Loss_kd 2.399, Train_accy 75.69, Test_accy 67.88
2024-08-02 16:40:35,868 [foster.py] => Task 13, Epoch 19/170 => Loss 3.347, Loss_clf 0.471, Loss_fe 0.389, Loss_kd 2.419, Train_accy 75.93, Test_accy 68.20
2024-08-02 16:40:40,201 [foster.py] => Task 13, Epoch 20/170 => Loss 3.252, Loss_clf 0.433, Loss_fe 0.373, Loss_kd 2.380, Train_accy 76.05, Test_accy 67.55
2024-08-02 16:40:42,744 [foster.py] => Task 13, Epoch 21/170 => Loss 3.306, Loss_clf 0.462, Loss_fe 0.378, Loss_kd 2.399, Train_accy 76.85
2024-08-02 16:40:47,074 [foster.py] => Task 13, Epoch 22/170 => Loss 3.237, Loss_clf 0.405, Loss_fe 0.355, Loss_kd 2.410, Train_accy 77.54, Test_accy 67.92
2024-08-02 16:40:51,416 [foster.py] => Task 13, Epoch 23/170 => Loss 3.219, Loss_clf 0.436, Loss_fe 0.355, Loss_kd 2.363, Train_accy 77.78, Test_accy 68.03
2024-08-02 16:40:55,769 [foster.py] => Task 13, Epoch 24/170 => Loss 3.299, Loss_clf 0.456, Loss_fe 0.357, Loss_kd 2.419, Train_accy 75.32, Test_accy 67.89
2024-08-02 16:41:00,146 [foster.py] => Task 13, Epoch 25/170 => Loss 3.173, Loss_clf 0.406, Loss_fe 0.318, Loss_kd 2.383, Train_accy 77.30, Test_accy 68.00
2024-08-02 16:41:02,700 [foster.py] => Task 13, Epoch 26/170 => Loss 3.277, Loss_clf 0.449, Loss_fe 0.349, Loss_kd 2.412, Train_accy 75.89
2024-08-02 16:41:07,034 [foster.py] => Task 13, Epoch 27/170 => Loss 3.232, Loss_clf 0.429, Loss_fe 0.324, Loss_kd 2.412, Train_accy 77.66, Test_accy 68.18
2024-08-02 16:41:11,372 [foster.py] => Task 13, Epoch 28/170 => Loss 3.172, Loss_clf 0.416, Loss_fe 0.327, Loss_kd 2.363, Train_accy 76.05, Test_accy 67.84
2024-08-02 16:41:15,769 [foster.py] => Task 13, Epoch 29/170 => Loss 3.275, Loss_clf 0.465, Loss_fe 0.348, Loss_kd 2.395, Train_accy 77.26, Test_accy 68.09
2024-08-02 16:41:20,206 [foster.py] => Task 13, Epoch 30/170 => Loss 3.230, Loss_clf 0.445, Loss_fe 0.339, Loss_kd 2.381, Train_accy 77.78, Test_accy 68.24
2024-08-02 16:41:22,916 [foster.py] => Task 13, Epoch 31/170 => Loss 3.158, Loss_clf 0.414, Loss_fe 0.302, Loss_kd 2.377, Train_accy 77.38
2024-08-02 16:41:27,346 [foster.py] => Task 13, Epoch 32/170 => Loss 3.225, Loss_clf 0.437, Loss_fe 0.325, Loss_kd 2.397, Train_accy 77.86, Test_accy 67.84
2024-08-02 16:41:31,719 [foster.py] => Task 13, Epoch 33/170 => Loss 3.166, Loss_clf 0.415, Loss_fe 0.305, Loss_kd 2.380, Train_accy 78.23, Test_accy 68.17
2024-08-02 16:41:36,075 [foster.py] => Task 13, Epoch 34/170 => Loss 3.133, Loss_clf 0.396, Loss_fe 0.294, Loss_kd 2.377, Train_accy 79.56, Test_accy 68.07
2024-08-02 16:41:40,412 [foster.py] => Task 13, Epoch 35/170 => Loss 3.160, Loss_clf 0.405, Loss_fe 0.289, Loss_kd 2.400, Train_accy 79.03, Test_accy 68.09
2024-08-02 16:41:43,024 [foster.py] => Task 13, Epoch 36/170 => Loss 3.201, Loss_clf 0.432, Loss_fe 0.300, Loss_kd 2.402, Train_accy 79.84
2024-08-02 16:41:47,389 [foster.py] => Task 13, Epoch 37/170 => Loss 3.170, Loss_clf 0.406, Loss_fe 0.306, Loss_kd 2.392, Train_accy 80.24, Test_accy 68.34
2024-08-02 16:41:51,737 [foster.py] => Task 13, Epoch 38/170 => Loss 3.141, Loss_clf 0.390, Loss_fe 0.290, Loss_kd 2.394, Train_accy 79.56, Test_accy 67.68
2024-08-02 16:41:56,056 [foster.py] => Task 13, Epoch 39/170 => Loss 3.180, Loss_clf 0.416, Loss_fe 0.290, Loss_kd 2.407, Train_accy 79.23, Test_accy 67.75
2024-08-02 16:42:00,365 [foster.py] => Task 13, Epoch 40/170 => Loss 3.095, Loss_clf 0.373, Loss_fe 0.297, Loss_kd 2.359, Train_accy 80.56, Test_accy 68.34
2024-08-02 16:42:02,911 [foster.py] => Task 13, Epoch 41/170 => Loss 3.175, Loss_clf 0.414, Loss_fe 0.299, Loss_kd 2.395, Train_accy 80.12
2024-08-02 16:42:07,244 [foster.py] => Task 13, Epoch 42/170 => Loss 3.123, Loss_clf 0.406, Loss_fe 0.270, Loss_kd 2.382, Train_accy 79.84, Test_accy 68.25
2024-08-02 16:42:11,567 [foster.py] => Task 13, Epoch 43/170 => Loss 3.167, Loss_clf 0.407, Loss_fe 0.277, Loss_kd 2.416, Train_accy 81.05, Test_accy 67.46
2024-08-02 16:42:15,937 [foster.py] => Task 13, Epoch 44/170 => Loss 3.098, Loss_clf 0.382, Loss_fe 0.265, Loss_kd 2.385, Train_accy 80.16, Test_accy 67.76
2024-08-02 16:42:20,280 [foster.py] => Task 13, Epoch 45/170 => Loss 3.041, Loss_clf 0.341, Loss_fe 0.258, Loss_kd 2.376, Train_accy 81.77, Test_accy 68.22
2024-08-02 16:42:22,891 [foster.py] => Task 13, Epoch 46/170 => Loss 3.154, Loss_clf 0.398, Loss_fe 0.287, Loss_kd 2.403, Train_accy 80.32
2024-08-02 16:42:27,261 [foster.py] => Task 13, Epoch 47/170 => Loss 3.150, Loss_clf 0.406, Loss_fe 0.285, Loss_kd 2.393, Train_accy 79.48, Test_accy 68.22
2024-08-02 16:42:31,632 [foster.py] => Task 13, Epoch 48/170 => Loss 3.116, Loss_clf 0.382, Loss_fe 0.258, Loss_kd 2.410, Train_accy 80.16, Test_accy 68.37
2024-08-02 16:42:35,984 [foster.py] => Task 13, Epoch 49/170 => Loss 3.098, Loss_clf 0.389, Loss_fe 0.265, Loss_kd 2.378, Train_accy 80.69, Test_accy 68.45
2024-08-02 16:42:40,335 [foster.py] => Task 13, Epoch 50/170 => Loss 3.141, Loss_clf 0.396, Loss_fe 0.265, Loss_kd 2.413, Train_accy 81.01, Test_accy 68.37
2024-08-02 16:42:42,902 [foster.py] => Task 13, Epoch 51/170 => Loss 3.085, Loss_clf 0.377, Loss_fe 0.277, Loss_kd 2.366, Train_accy 81.33
2024-08-02 16:42:47,257 [foster.py] => Task 13, Epoch 52/170 => Loss 3.052, Loss_clf 0.363, Loss_fe 0.251, Loss_kd 2.372, Train_accy 81.37, Test_accy 68.28
2024-08-02 16:42:51,591 [foster.py] => Task 13, Epoch 53/170 => Loss 3.031, Loss_clf 0.370, Loss_fe 0.227, Loss_kd 2.368, Train_accy 81.37, Test_accy 67.91
2024-08-02 16:42:55,893 [foster.py] => Task 13, Epoch 54/170 => Loss 3.160, Loss_clf 0.418, Loss_fe 0.264, Loss_kd 2.412, Train_accy 81.41, Test_accy 67.70
2024-08-02 16:43:00,219 [foster.py] => Task 13, Epoch 55/170 => Loss 3.117, Loss_clf 0.385, Loss_fe 0.258, Loss_kd 2.408, Train_accy 81.98, Test_accy 68.26
2024-08-02 16:43:02,806 [foster.py] => Task 13, Epoch 56/170 => Loss 3.044, Loss_clf 0.357, Loss_fe 0.246, Loss_kd 2.376, Train_accy 82.02
2024-08-02 16:43:07,200 [foster.py] => Task 13, Epoch 57/170 => Loss 3.119, Loss_clf 0.403, Loss_fe 0.256, Loss_kd 2.394, Train_accy 80.36, Test_accy 67.97
2024-08-02 16:43:11,551 [foster.py] => Task 13, Epoch 58/170 => Loss 3.098, Loss_clf 0.386, Loss_fe 0.262, Loss_kd 2.385, Train_accy 81.37, Test_accy 68.03
2024-08-02 16:43:15,878 [foster.py] => Task 13, Epoch 59/170 => Loss 3.054, Loss_clf 0.362, Loss_fe 0.245, Loss_kd 2.381, Train_accy 81.61, Test_accy 68.22
2024-08-02 16:43:20,196 [foster.py] => Task 13, Epoch 60/170 => Loss 3.120, Loss_clf 0.399, Loss_fe 0.250, Loss_kd 2.405, Train_accy 80.56, Test_accy 68.47
2024-08-02 16:43:22,767 [foster.py] => Task 13, Epoch 61/170 => Loss 3.002, Loss_clf 0.345, Loss_fe 0.231, Loss_kd 2.360, Train_accy 82.10
2024-08-02 16:43:27,141 [foster.py] => Task 13, Epoch 62/170 => Loss 3.137, Loss_clf 0.404, Loss_fe 0.256, Loss_kd 2.411, Train_accy 82.22, Test_accy 68.26
2024-08-02 16:43:31,476 [foster.py] => Task 13, Epoch 63/170 => Loss 3.109, Loss_clf 0.396, Loss_fe 0.245, Loss_kd 2.402, Train_accy 81.85, Test_accy 68.46
2024-08-02 16:43:35,890 [foster.py] => Task 13, Epoch 64/170 => Loss 3.049, Loss_clf 0.369, Loss_fe 0.233, Loss_kd 2.382, Train_accy 82.62, Test_accy 67.97
2024-08-02 16:43:40,234 [foster.py] => Task 13, Epoch 65/170 => Loss 2.997, Loss_clf 0.338, Loss_fe 0.228, Loss_kd 2.366, Train_accy 82.02, Test_accy 68.18
2024-08-02 16:43:42,816 [foster.py] => Task 13, Epoch 66/170 => Loss 3.080, Loss_clf 0.386, Loss_fe 0.224, Loss_kd 2.404, Train_accy 81.25
2024-08-02 16:43:47,133 [foster.py] => Task 13, Epoch 67/170 => Loss 3.015, Loss_clf 0.356, Loss_fe 0.207, Loss_kd 2.385, Train_accy 80.85, Test_accy 68.03
2024-08-02 16:43:51,492 [foster.py] => Task 13, Epoch 68/170 => Loss 2.952, Loss_clf 0.337, Loss_fe 0.198, Loss_kd 2.351, Train_accy 82.98, Test_accy 68.34
2024-08-02 16:43:55,912 [foster.py] => Task 13, Epoch 69/170 => Loss 3.006, Loss_clf 0.365, Loss_fe 0.184, Loss_kd 2.391, Train_accy 83.27, Test_accy 68.34
2024-08-02 16:44:00,357 [foster.py] => Task 13, Epoch 70/170 => Loss 3.009, Loss_clf 0.359, Loss_fe 0.212, Loss_kd 2.373, Train_accy 84.23, Test_accy 68.36
2024-08-02 16:44:02,943 [foster.py] => Task 13, Epoch 71/170 => Loss 3.077, Loss_clf 0.381, Loss_fe 0.226, Loss_kd 2.404, Train_accy 82.22
2024-08-02 16:44:07,385 [foster.py] => Task 13, Epoch 72/170 => Loss 3.040, Loss_clf 0.368, Loss_fe 0.209, Loss_kd 2.396, Train_accy 82.26, Test_accy 68.22
2024-08-02 16:44:11,765 [foster.py] => Task 13, Epoch 73/170 => Loss 3.045, Loss_clf 0.364, Loss_fe 0.206, Loss_kd 2.409, Train_accy 82.74, Test_accy 68.67
2024-08-02 16:44:16,120 [foster.py] => Task 13, Epoch 74/170 => Loss 3.019, Loss_clf 0.367, Loss_fe 0.206, Loss_kd 2.380, Train_accy 82.94, Test_accy 68.32
2024-08-02 16:44:20,444 [foster.py] => Task 13, Epoch 75/170 => Loss 2.989, Loss_clf 0.335, Loss_fe 0.196, Loss_kd 2.393, Train_accy 82.70, Test_accy 68.39
2024-08-02 16:44:22,993 [foster.py] => Task 13, Epoch 76/170 => Loss 3.006, Loss_clf 0.349, Loss_fe 0.187, Loss_kd 2.403, Train_accy 82.82
2024-08-02 16:44:27,347 [foster.py] => Task 13, Epoch 77/170 => Loss 3.074, Loss_clf 0.381, Loss_fe 0.202, Loss_kd 2.424, Train_accy 82.58, Test_accy 68.38
2024-08-02 16:44:31,734 [foster.py] => Task 13, Epoch 78/170 => Loss 2.960, Loss_clf 0.316, Loss_fe 0.200, Loss_kd 2.379, Train_accy 82.62, Test_accy 68.28
2024-08-02 16:44:36,051 [foster.py] => Task 13, Epoch 79/170 => Loss 3.051, Loss_clf 0.365, Loss_fe 0.222, Loss_kd 2.398, Train_accy 82.70, Test_accy 68.62
2024-08-02 16:44:40,372 [foster.py] => Task 13, Epoch 80/170 => Loss 3.001, Loss_clf 0.341, Loss_fe 0.202, Loss_kd 2.392, Train_accy 83.27, Test_accy 68.49
2024-08-02 16:44:42,943 [foster.py] => Task 13, Epoch 81/170 => Loss 2.995, Loss_clf 0.351, Loss_fe 0.204, Loss_kd 2.375, Train_accy 82.54
2024-08-02 16:44:47,268 [foster.py] => Task 13, Epoch 82/170 => Loss 3.044, Loss_clf 0.367, Loss_fe 0.209, Loss_kd 2.402, Train_accy 81.98, Test_accy 67.89
2024-08-02 16:44:51,693 [foster.py] => Task 13, Epoch 83/170 => Loss 2.994, Loss_clf 0.348, Loss_fe 0.204, Loss_kd 2.377, Train_accy 82.78, Test_accy 68.51
2024-08-02 16:44:56,015 [foster.py] => Task 13, Epoch 84/170 => Loss 3.018, Loss_clf 0.363, Loss_fe 0.182, Loss_kd 2.406, Train_accy 84.03, Test_accy 68.34
2024-08-02 16:45:00,341 [foster.py] => Task 13, Epoch 85/170 => Loss 3.010, Loss_clf 0.356, Loss_fe 0.203, Loss_kd 2.385, Train_accy 82.34, Test_accy 68.33
2024-08-02 16:45:02,905 [foster.py] => Task 13, Epoch 86/170 => Loss 2.982, Loss_clf 0.341, Loss_fe 0.176, Loss_kd 2.399, Train_accy 81.98
2024-08-02 16:45:07,330 [foster.py] => Task 13, Epoch 87/170 => Loss 2.987, Loss_clf 0.342, Loss_fe 0.190, Loss_kd 2.389, Train_accy 84.19, Test_accy 68.24
2024-08-02 16:45:11,747 [foster.py] => Task 13, Epoch 88/170 => Loss 3.003, Loss_clf 0.349, Loss_fe 0.174, Loss_kd 2.413, Train_accy 82.66, Test_accy 68.22
2024-08-02 16:45:16,111 [foster.py] => Task 13, Epoch 89/170 => Loss 2.981, Loss_clf 0.336, Loss_fe 0.174, Loss_kd 2.404, Train_accy 84.64, Test_accy 68.68
2024-08-02 16:45:20,497 [foster.py] => Task 13, Epoch 90/170 => Loss 3.030, Loss_clf 0.367, Loss_fe 0.181, Loss_kd 2.415, Train_accy 82.30, Test_accy 68.29
2024-08-02 16:45:23,088 [foster.py] => Task 13, Epoch 91/170 => Loss 2.991, Loss_clf 0.356, Loss_fe 0.193, Loss_kd 2.376, Train_accy 82.58
2024-08-02 16:45:27,408 [foster.py] => Task 13, Epoch 92/170 => Loss 3.022, Loss_clf 0.368, Loss_fe 0.181, Loss_kd 2.406, Train_accy 82.50, Test_accy 68.46
2024-08-02 16:45:31,748 [foster.py] => Task 13, Epoch 93/170 => Loss 2.953, Loss_clf 0.346, Loss_fe 0.169, Loss_kd 2.372, Train_accy 83.59, Test_accy 68.36
2024-08-02 16:45:36,123 [foster.py] => Task 13, Epoch 94/170 => Loss 2.940, Loss_clf 0.335, Loss_fe 0.158, Loss_kd 2.381, Train_accy 84.23, Test_accy 68.59
2024-08-02 16:45:40,472 [foster.py] => Task 13, Epoch 95/170 => Loss 3.015, Loss_clf 0.350, Loss_fe 0.204, Loss_kd 2.395, Train_accy 83.99, Test_accy 68.36
2024-08-02 16:45:43,036 [foster.py] => Task 13, Epoch 96/170 => Loss 3.024, Loss_clf 0.365, Loss_fe 0.183, Loss_kd 2.409, Train_accy 85.00
2024-08-02 16:45:47,451 [foster.py] => Task 13, Epoch 97/170 => Loss 3.000, Loss_clf 0.362, Loss_fe 0.186, Loss_kd 2.386, Train_accy 83.06, Test_accy 68.16
2024-08-02 16:45:51,916 [foster.py] => Task 13, Epoch 98/170 => Loss 2.995, Loss_clf 0.350, Loss_fe 0.170, Loss_kd 2.409, Train_accy 84.07, Test_accy 68.45
2024-08-02 16:45:56,362 [foster.py] => Task 13, Epoch 99/170 => Loss 3.015, Loss_clf 0.350, Loss_fe 0.176, Loss_kd 2.422, Train_accy 84.44, Test_accy 68.12
2024-08-02 16:46:00,705 [foster.py] => Task 13, Epoch 100/170 => Loss 2.879, Loss_clf 0.295, Loss_fe 0.149, Loss_kd 2.369, Train_accy 85.73, Test_accy 68.08
2024-08-02 16:46:03,273 [foster.py] => Task 13, Epoch 101/170 => Loss 2.992, Loss_clf 0.352, Loss_fe 0.159, Loss_kd 2.414, Train_accy 83.67
2024-08-02 16:46:07,587 [foster.py] => Task 13, Epoch 102/170 => Loss 2.943, Loss_clf 0.338, Loss_fe 0.159, Loss_kd 2.380, Train_accy 85.65, Test_accy 68.47
2024-08-02 16:46:12,003 [foster.py] => Task 13, Epoch 103/170 => Loss 2.981, Loss_clf 0.345, Loss_fe 0.168, Loss_kd 2.400, Train_accy 84.52, Test_accy 68.26
2024-08-02 16:46:16,397 [foster.py] => Task 13, Epoch 104/170 => Loss 3.018, Loss_clf 0.368, Loss_fe 0.163, Loss_kd 2.420, Train_accy 83.59, Test_accy 68.24
2024-08-02 16:46:20,774 [foster.py] => Task 13, Epoch 105/170 => Loss 2.954, Loss_clf 0.332, Loss_fe 0.155, Loss_kd 2.400, Train_accy 85.08, Test_accy 68.39
2024-08-02 16:46:23,343 [foster.py] => Task 13, Epoch 106/170 => Loss 2.970, Loss_clf 0.342, Loss_fe 0.166, Loss_kd 2.396, Train_accy 84.84
2024-08-02 16:46:27,708 [foster.py] => Task 13, Epoch 107/170 => Loss 2.987, Loss_clf 0.355, Loss_fe 0.153, Loss_kd 2.412, Train_accy 82.86, Test_accy 68.39
2024-08-02 16:46:32,046 [foster.py] => Task 13, Epoch 108/170 => Loss 2.916, Loss_clf 0.321, Loss_fe 0.145, Loss_kd 2.384, Train_accy 85.93, Test_accy 68.20
2024-08-02 16:46:36,477 [foster.py] => Task 13, Epoch 109/170 => Loss 2.957, Loss_clf 0.341, Loss_fe 0.158, Loss_kd 2.392, Train_accy 84.27, Test_accy 68.39
2024-08-02 16:46:40,925 [foster.py] => Task 13, Epoch 110/170 => Loss 2.915, Loss_clf 0.322, Loss_fe 0.139, Loss_kd 2.389, Train_accy 85.52, Test_accy 68.22
2024-08-02 16:46:43,555 [foster.py] => Task 13, Epoch 111/170 => Loss 2.913, Loss_clf 0.323, Loss_fe 0.123, Loss_kd 2.401, Train_accy 85.16
2024-08-02 16:46:47,978 [foster.py] => Task 13, Epoch 112/170 => Loss 2.888, Loss_clf 0.320, Loss_fe 0.137, Loss_kd 2.366, Train_accy 84.56, Test_accy 68.42
2024-08-02 16:46:52,355 [foster.py] => Task 13, Epoch 113/170 => Loss 2.940, Loss_clf 0.344, Loss_fe 0.136, Loss_kd 2.394, Train_accy 84.88, Test_accy 68.20
2024-08-02 16:46:56,738 [foster.py] => Task 13, Epoch 114/170 => Loss 2.879, Loss_clf 0.303, Loss_fe 0.134, Loss_kd 2.377, Train_accy 86.45, Test_accy 68.59
2024-08-02 16:47:01,087 [foster.py] => Task 13, Epoch 115/170 => Loss 2.936, Loss_clf 0.323, Loss_fe 0.140, Loss_kd 2.406, Train_accy 84.52, Test_accy 68.58
2024-08-02 16:47:03,651 [foster.py] => Task 13, Epoch 116/170 => Loss 2.916, Loss_clf 0.315, Loss_fe 0.140, Loss_kd 2.394, Train_accy 86.09
2024-08-02 16:47:07,966 [foster.py] => Task 13, Epoch 117/170 => Loss 2.919, Loss_clf 0.323, Loss_fe 0.134, Loss_kd 2.396, Train_accy 84.64, Test_accy 68.66
2024-08-02 16:47:12,319 [foster.py] => Task 13, Epoch 118/170 => Loss 2.886, Loss_clf 0.317, Loss_fe 0.129, Loss_kd 2.375, Train_accy 85.24, Test_accy 68.59
2024-08-02 16:47:16,668 [foster.py] => Task 13, Epoch 119/170 => Loss 2.951, Loss_clf 0.337, Loss_fe 0.142, Loss_kd 2.406, Train_accy 84.96, Test_accy 68.33
2024-08-02 16:47:21,147 [foster.py] => Task 13, Epoch 120/170 => Loss 2.916, Loss_clf 0.320, Loss_fe 0.136, Loss_kd 2.394, Train_accy 85.77, Test_accy 68.70
2024-08-02 16:47:23,718 [foster.py] => Task 13, Epoch 121/170 => Loss 2.923, Loss_clf 0.330, Loss_fe 0.143, Loss_kd 2.384, Train_accy 85.85
2024-08-02 16:47:28,043 [foster.py] => Task 13, Epoch 122/170 => Loss 2.935, Loss_clf 0.327, Loss_fe 0.147, Loss_kd 2.395, Train_accy 85.44, Test_accy 68.42
2024-08-02 16:47:32,357 [foster.py] => Task 13, Epoch 123/170 => Loss 2.927, Loss_clf 0.334, Loss_fe 0.132, Loss_kd 2.395, Train_accy 86.05, Test_accy 68.64
2024-08-02 16:47:36,666 [foster.py] => Task 13, Epoch 124/170 => Loss 2.924, Loss_clf 0.329, Loss_fe 0.130, Loss_kd 2.399, Train_accy 85.77, Test_accy 68.80
2024-08-02 16:47:41,016 [foster.py] => Task 13, Epoch 125/170 => Loss 2.924, Loss_clf 0.338, Loss_fe 0.130, Loss_kd 2.390, Train_accy 86.61, Test_accy 68.49
2024-08-02 16:47:43,568 [foster.py] => Task 13, Epoch 126/170 => Loss 2.911, Loss_clf 0.323, Loss_fe 0.130, Loss_kd 2.392, Train_accy 86.01
2024-08-02 16:47:47,945 [foster.py] => Task 13, Epoch 127/170 => Loss 2.857, Loss_clf 0.288, Loss_fe 0.120, Loss_kd 2.383, Train_accy 87.06, Test_accy 68.38
2024-08-02 16:47:52,325 [foster.py] => Task 13, Epoch 128/170 => Loss 2.918, Loss_clf 0.316, Loss_fe 0.120, Loss_kd 2.415, Train_accy 86.45, Test_accy 68.43
2024-08-02 16:47:56,664 [foster.py] => Task 13, Epoch 129/170 => Loss 2.887, Loss_clf 0.314, Loss_fe 0.121, Loss_kd 2.385, Train_accy 87.02, Test_accy 68.46
2024-08-02 16:48:00,983 [foster.py] => Task 13, Epoch 130/170 => Loss 2.876, Loss_clf 0.309, Loss_fe 0.120, Loss_kd 2.381, Train_accy 87.22, Test_accy 68.64
2024-08-02 16:48:03,561 [foster.py] => Task 13, Epoch 131/170 => Loss 2.920, Loss_clf 0.328, Loss_fe 0.128, Loss_kd 2.398, Train_accy 85.73
2024-08-02 16:48:07,911 [foster.py] => Task 13, Epoch 132/170 => Loss 2.877, Loss_clf 0.318, Loss_fe 0.126, Loss_kd 2.368, Train_accy 86.13, Test_accy 68.51
2024-08-02 16:48:12,276 [foster.py] => Task 13, Epoch 133/170 => Loss 2.892, Loss_clf 0.302, Loss_fe 0.126, Loss_kd 2.398, Train_accy 86.90, Test_accy 68.62
2024-08-02 16:48:16,709 [foster.py] => Task 13, Epoch 134/170 => Loss 2.893, Loss_clf 0.307, Loss_fe 0.131, Loss_kd 2.390, Train_accy 86.90, Test_accy 68.50
2024-08-02 16:48:21,049 [foster.py] => Task 13, Epoch 135/170 => Loss 2.829, Loss_clf 0.295, Loss_fe 0.112, Loss_kd 2.357, Train_accy 87.74, Test_accy 68.51
2024-08-02 16:48:23,646 [foster.py] => Task 13, Epoch 136/170 => Loss 2.829, Loss_clf 0.272, Loss_fe 0.102, Loss_kd 2.388, Train_accy 87.34
2024-08-02 16:48:28,085 [foster.py] => Task 13, Epoch 137/170 => Loss 2.914, Loss_clf 0.331, Loss_fe 0.107, Loss_kd 2.409, Train_accy 85.69, Test_accy 68.55
2024-08-02 16:48:32,540 [foster.py] => Task 13, Epoch 138/170 => Loss 2.896, Loss_clf 0.317, Loss_fe 0.104, Loss_kd 2.408, Train_accy 86.94, Test_accy 68.50
2024-08-02 16:48:36,932 [foster.py] => Task 13, Epoch 139/170 => Loss 2.927, Loss_clf 0.329, Loss_fe 0.120, Loss_kd 2.411, Train_accy 86.37, Test_accy 68.54
2024-08-02 16:48:41,267 [foster.py] => Task 13, Epoch 140/170 => Loss 2.876, Loss_clf 0.313, Loss_fe 0.115, Loss_kd 2.383, Train_accy 86.29, Test_accy 68.70
2024-08-02 16:48:43,912 [foster.py] => Task 13, Epoch 141/170 => Loss 2.940, Loss_clf 0.336, Loss_fe 0.112, Loss_kd 2.425, Train_accy 86.09
2024-08-02 16:48:48,277 [foster.py] => Task 13, Epoch 142/170 => Loss 2.858, Loss_clf 0.305, Loss_fe 0.123, Loss_kd 2.364, Train_accy 87.70, Test_accy 68.49
2024-08-02 16:48:52,611 [foster.py] => Task 13, Epoch 143/170 => Loss 2.909, Loss_clf 0.313, Loss_fe 0.121, Loss_kd 2.407, Train_accy 87.90, Test_accy 68.58
2024-08-02 16:48:56,972 [foster.py] => Task 13, Epoch 144/170 => Loss 2.842, Loss_clf 0.291, Loss_fe 0.104, Loss_kd 2.381, Train_accy 87.22, Test_accy 68.61
2024-08-02 16:49:01,320 [foster.py] => Task 13, Epoch 145/170 => Loss 2.863, Loss_clf 0.299, Loss_fe 0.116, Loss_kd 2.382, Train_accy 87.30, Test_accy 68.43
2024-08-02 16:49:03,914 [foster.py] => Task 13, Epoch 146/170 => Loss 2.877, Loss_clf 0.307, Loss_fe 0.113, Loss_kd 2.391, Train_accy 87.02
2024-08-02 16:49:08,239 [foster.py] => Task 13, Epoch 147/170 => Loss 2.873, Loss_clf 0.304, Loss_fe 0.108, Loss_kd 2.394, Train_accy 87.38, Test_accy 68.62
2024-08-02 16:49:12,636 [foster.py] => Task 13, Epoch 148/170 => Loss 2.834, Loss_clf 0.280, Loss_fe 0.107, Loss_kd 2.382, Train_accy 87.14, Test_accy 68.64
2024-08-02 16:49:17,073 [foster.py] => Task 13, Epoch 149/170 => Loss 2.972, Loss_clf 0.344, Loss_fe 0.124, Loss_kd 2.437, Train_accy 86.25, Test_accy 68.54
2024-08-02 16:49:21,441 [foster.py] => Task 13, Epoch 150/170 => Loss 2.843, Loss_clf 0.299, Loss_fe 0.107, Loss_kd 2.371, Train_accy 87.50, Test_accy 68.54
2024-08-02 16:49:24,058 [foster.py] => Task 13, Epoch 151/170 => Loss 2.858, Loss_clf 0.291, Loss_fe 0.120, Loss_kd 2.380, Train_accy 87.54
2024-08-02 16:49:28,444 [foster.py] => Task 13, Epoch 152/170 => Loss 2.868, Loss_clf 0.306, Loss_fe 0.121, Loss_kd 2.375, Train_accy 87.78, Test_accy 68.49
2024-08-02 16:49:32,769 [foster.py] => Task 13, Epoch 153/170 => Loss 2.860, Loss_clf 0.303, Loss_fe 0.110, Loss_kd 2.381, Train_accy 86.73, Test_accy 68.46
2024-08-02 16:49:37,111 [foster.py] => Task 13, Epoch 154/170 => Loss 2.877, Loss_clf 0.294, Loss_fe 0.112, Loss_kd 2.404, Train_accy 87.74, Test_accy 68.51
2024-08-02 16:49:41,519 [foster.py] => Task 13, Epoch 155/170 => Loss 2.829, Loss_clf 0.267, Loss_fe 0.103, Loss_kd 2.393, Train_accy 87.94, Test_accy 68.59
2024-08-02 16:49:44,118 [foster.py] => Task 13, Epoch 156/170 => Loss 2.896, Loss_clf 0.314, Loss_fe 0.119, Loss_kd 2.397, Train_accy 87.62
2024-08-02 16:49:48,441 [foster.py] => Task 13, Epoch 157/170 => Loss 2.828, Loss_clf 0.292, Loss_fe 0.100, Loss_kd 2.371, Train_accy 87.34, Test_accy 68.59
2024-08-02 16:49:52,788 [foster.py] => Task 13, Epoch 158/170 => Loss 2.845, Loss_clf 0.297, Loss_fe 0.111, Loss_kd 2.371, Train_accy 86.49, Test_accy 68.58
2024-08-02 16:49:57,109 [foster.py] => Task 13, Epoch 159/170 => Loss 2.917, Loss_clf 0.328, Loss_fe 0.119, Loss_kd 2.404, Train_accy 86.17, Test_accy 68.61
2024-08-02 16:50:01,567 [foster.py] => Task 13, Epoch 160/170 => Loss 2.855, Loss_clf 0.292, Loss_fe 0.120, Loss_kd 2.377, Train_accy 86.85, Test_accy 68.51
2024-08-02 16:50:04,150 [foster.py] => Task 13, Epoch 161/170 => Loss 2.912, Loss_clf 0.323, Loss_fe 0.122, Loss_kd 2.401, Train_accy 86.09
2024-08-02 16:50:08,544 [foster.py] => Task 13, Epoch 162/170 => Loss 2.890, Loss_clf 0.321, Loss_fe 0.110, Loss_kd 2.392, Train_accy 86.01, Test_accy 68.54
2024-08-02 16:50:12,872 [foster.py] => Task 13, Epoch 163/170 => Loss 2.900, Loss_clf 0.326, Loss_fe 0.112, Loss_kd 2.395, Train_accy 86.90, Test_accy 68.55
2024-08-02 16:50:17,229 [foster.py] => Task 13, Epoch 164/170 => Loss 2.874, Loss_clf 0.303, Loss_fe 0.109, Loss_kd 2.396, Train_accy 87.38, Test_accy 68.61
2024-08-02 16:50:21,570 [foster.py] => Task 13, Epoch 165/170 => Loss 2.801, Loss_clf 0.282, Loss_fe 0.100, Loss_kd 2.355, Train_accy 87.42, Test_accy 68.51
2024-08-02 16:50:24,145 [foster.py] => Task 13, Epoch 166/170 => Loss 2.920, Loss_clf 0.320, Loss_fe 0.124, Loss_kd 2.410, Train_accy 86.98
2024-08-02 16:50:28,475 [foster.py] => Task 13, Epoch 167/170 => Loss 2.883, Loss_clf 0.298, Loss_fe 0.102, Loss_kd 2.416, Train_accy 88.02, Test_accy 68.54
2024-08-02 16:50:32,935 [foster.py] => Task 13, Epoch 168/170 => Loss 2.911, Loss_clf 0.333, Loss_fe 0.110, Loss_kd 2.402, Train_accy 86.45, Test_accy 68.54
2024-08-02 16:50:37,366 [foster.py] => Task 13, Epoch 169/170 => Loss 2.857, Loss_clf 0.286, Loss_fe 0.101, Loss_kd 2.404, Train_accy 88.19, Test_accy 68.57
2024-08-02 16:50:41,811 [foster.py] => Task 13, Epoch 170/170 => Loss 2.866, Loss_clf 0.297, Loss_fe 0.106, Loss_kd 2.397, Train_accy 88.27, Test_accy 68.55
2024-08-02 16:50:41,813 [foster.py] => do not weight align teacher!
2024-08-02 16:50:41,815 [foster.py] => per cls weights : [1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664 1.01432664
 1.01432664 1.01432664 0.46991425 0.46991425]
2024-08-02 16:50:46,720 [foster.py] => SNet: Task 13, Epoch 1/130 => Loss 29.496,  Loss1 0.742, Train_accy 52.82, Test_accy 65.51
2024-08-02 16:50:50,285 [foster.py] => SNet: Task 13, Epoch 2/130 => Loss 29.366,  Loss1 0.741, Train_accy 66.45
2024-08-02 16:50:53,840 [foster.py] => SNet: Task 13, Epoch 3/130 => Loss 29.372,  Loss1 0.740, Train_accy 63.31
2024-08-02 16:50:57,391 [foster.py] => SNet: Task 13, Epoch 4/130 => Loss 29.381,  Loss1 0.740, Train_accy 63.67
2024-08-02 16:51:00,943 [foster.py] => SNet: Task 13, Epoch 5/130 => Loss 29.407,  Loss1 0.740, Train_accy 66.21
2024-08-02 16:51:05,642 [foster.py] => SNet: Task 13, Epoch 6/130 => Loss 29.341,  Loss1 0.740, Train_accy 65.97, Test_accy 66.91
2024-08-02 16:51:09,236 [foster.py] => SNet: Task 13, Epoch 7/130 => Loss 29.357,  Loss1 0.740, Train_accy 67.66
2024-08-02 16:51:12,772 [foster.py] => SNet: Task 13, Epoch 8/130 => Loss 29.377,  Loss1 0.741, Train_accy 65.97
2024-08-02 16:51:16,346 [foster.py] => SNet: Task 13, Epoch 9/130 => Loss 29.345,  Loss1 0.741, Train_accy 69.44
2024-08-02 16:51:19,901 [foster.py] => SNet: Task 13, Epoch 10/130 => Loss 29.352,  Loss1 0.740, Train_accy 67.62
2024-08-02 16:51:24,615 [foster.py] => SNet: Task 13, Epoch 11/130 => Loss 29.373,  Loss1 0.740, Train_accy 67.42, Test_accy 67.36
2024-08-02 16:51:28,161 [foster.py] => SNet: Task 13, Epoch 12/130 => Loss 29.341,  Loss1 0.741, Train_accy 68.91
2024-08-02 16:51:31,723 [foster.py] => SNet: Task 13, Epoch 13/130 => Loss 29.361,  Loss1 0.740, Train_accy 68.39
2024-08-02 16:51:35,266 [foster.py] => SNet: Task 13, Epoch 14/130 => Loss 29.360,  Loss1 0.740, Train_accy 68.35
2024-08-02 16:51:38,898 [foster.py] => SNet: Task 13, Epoch 15/130 => Loss 29.341,  Loss1 0.740, Train_accy 68.27
2024-08-02 16:51:43,568 [foster.py] => SNet: Task 13, Epoch 16/130 => Loss 29.358,  Loss1 0.740, Train_accy 69.84, Test_accy 67.37
2024-08-02 16:51:47,119 [foster.py] => SNet: Task 13, Epoch 17/130 => Loss 29.342,  Loss1 0.741, Train_accy 69.40
2024-08-02 16:51:50,677 [foster.py] => SNet: Task 13, Epoch 18/130 => Loss 29.381,  Loss1 0.740, Train_accy 67.90
2024-08-02 16:51:54,250 [foster.py] => SNet: Task 13, Epoch 19/130 => Loss 29.337,  Loss1 0.740, Train_accy 68.79
2024-08-02 16:51:57,809 [foster.py] => SNet: Task 13, Epoch 20/130 => Loss 29.435,  Loss1 0.740, Train_accy 69.64
2024-08-02 16:52:02,472 [foster.py] => SNet: Task 13, Epoch 21/130 => Loss 29.385,  Loss1 0.741, Train_accy 69.84, Test_accy 67.30
2024-08-02 16:52:06,037 [foster.py] => SNet: Task 13, Epoch 22/130 => Loss 29.375,  Loss1 0.740, Train_accy 70.40
2024-08-02 16:52:09,584 [foster.py] => SNet: Task 13, Epoch 23/130 => Loss 29.398,  Loss1 0.740, Train_accy 69.92
2024-08-02 16:52:13,181 [foster.py] => SNet: Task 13, Epoch 24/130 => Loss 29.367,  Loss1 0.740, Train_accy 70.44
2024-08-02 16:52:16,761 [foster.py] => SNet: Task 13, Epoch 25/130 => Loss 29.405,  Loss1 0.740, Train_accy 69.07
2024-08-02 16:52:21,499 [foster.py] => SNet: Task 13, Epoch 26/130 => Loss 29.351,  Loss1 0.740, Train_accy 69.96, Test_accy 67.18
2024-08-02 16:52:25,093 [foster.py] => SNet: Task 13, Epoch 27/130 => Loss 29.376,  Loss1 0.740, Train_accy 69.60
2024-08-02 16:52:28,662 [foster.py] => SNet: Task 13, Epoch 28/130 => Loss 29.302,  Loss1 0.740, Train_accy 70.60
2024-08-02 16:52:32,197 [foster.py] => SNet: Task 13, Epoch 29/130 => Loss 29.321,  Loss1 0.740, Train_accy 71.05
2024-08-02 16:52:35,764 [foster.py] => SNet: Task 13, Epoch 30/130 => Loss 29.321,  Loss1 0.739, Train_accy 69.52
2024-08-02 16:52:40,418 [foster.py] => SNet: Task 13, Epoch 31/130 => Loss 29.329,  Loss1 0.740, Train_accy 69.96, Test_accy 67.37
2024-08-02 16:52:43,974 [foster.py] => SNet: Task 13, Epoch 32/130 => Loss 29.324,  Loss1 0.740, Train_accy 70.69
2024-08-02 16:52:47,512 [foster.py] => SNet: Task 13, Epoch 33/130 => Loss 29.345,  Loss1 0.740, Train_accy 71.17
2024-08-02 16:52:51,095 [foster.py] => SNet: Task 13, Epoch 34/130 => Loss 29.338,  Loss1 0.740, Train_accy 70.12
2024-08-02 16:52:54,675 [foster.py] => SNet: Task 13, Epoch 35/130 => Loss 29.362,  Loss1 0.740, Train_accy 72.22
2024-08-02 16:52:59,372 [foster.py] => SNet: Task 13, Epoch 36/130 => Loss 29.380,  Loss1 0.740, Train_accy 71.81, Test_accy 67.28
2024-08-02 16:53:02,963 [foster.py] => SNet: Task 13, Epoch 37/130 => Loss 29.341,  Loss1 0.740, Train_accy 70.20
2024-08-02 16:53:06,509 [foster.py] => SNet: Task 13, Epoch 38/130 => Loss 29.302,  Loss1 0.740, Train_accy 72.14
2024-08-02 16:53:10,069 [foster.py] => SNet: Task 13, Epoch 39/130 => Loss 29.310,  Loss1 0.741, Train_accy 71.45
2024-08-02 16:53:13,624 [foster.py] => SNet: Task 13, Epoch 40/130 => Loss 29.298,  Loss1 0.740, Train_accy 72.38
2024-08-02 16:53:18,281 [foster.py] => SNet: Task 13, Epoch 41/130 => Loss 29.338,  Loss1 0.740, Train_accy 71.77, Test_accy 67.20
2024-08-02 16:53:21,842 [foster.py] => SNet: Task 13, Epoch 42/130 => Loss 29.381,  Loss1 0.740, Train_accy 71.94
2024-08-02 16:53:25,395 [foster.py] => SNet: Task 13, Epoch 43/130 => Loss 29.325,  Loss1 0.740, Train_accy 71.41
2024-08-02 16:53:29,015 [foster.py] => SNet: Task 13, Epoch 44/130 => Loss 29.371,  Loss1 0.739, Train_accy 71.77
2024-08-02 16:53:32,565 [foster.py] => SNet: Task 13, Epoch 45/130 => Loss 29.359,  Loss1 0.739, Train_accy 71.29
2024-08-02 16:53:37,239 [foster.py] => SNet: Task 13, Epoch 46/130 => Loss 29.361,  Loss1 0.740, Train_accy 71.77, Test_accy 67.18
2024-08-02 16:53:40,793 [foster.py] => SNet: Task 13, Epoch 47/130 => Loss 29.352,  Loss1 0.739, Train_accy 70.12
2024-08-02 16:53:44,352 [foster.py] => SNet: Task 13, Epoch 48/130 => Loss 29.309,  Loss1 0.740, Train_accy 72.94
2024-08-02 16:53:47,908 [foster.py] => SNet: Task 13, Epoch 49/130 => Loss 29.343,  Loss1 0.740, Train_accy 71.53
2024-08-02 16:53:51,499 [foster.py] => SNet: Task 13, Epoch 50/130 => Loss 29.366,  Loss1 0.740, Train_accy 70.60
2024-08-02 16:53:56,206 [foster.py] => SNet: Task 13, Epoch 51/130 => Loss 29.318,  Loss1 0.740, Train_accy 71.09, Test_accy 67.03
2024-08-02 16:53:59,741 [foster.py] => SNet: Task 13, Epoch 52/130 => Loss 29.331,  Loss1 0.740, Train_accy 71.37
2024-08-02 16:54:03,323 [foster.py] => SNet: Task 13, Epoch 53/130 => Loss 29.350,  Loss1 0.740, Train_accy 72.46
2024-08-02 16:54:06,875 [foster.py] => SNet: Task 13, Epoch 54/130 => Loss 29.361,  Loss1 0.740, Train_accy 72.90
2024-08-02 16:54:10,412 [foster.py] => SNet: Task 13, Epoch 55/130 => Loss 29.341,  Loss1 0.739, Train_accy 71.41
2024-08-02 16:54:15,091 [foster.py] => SNet: Task 13, Epoch 56/130 => Loss 29.366,  Loss1 0.740, Train_accy 69.64, Test_accy 67.42
2024-08-02 16:54:18,644 [foster.py] => SNet: Task 13, Epoch 57/130 => Loss 29.303,  Loss1 0.741, Train_accy 72.90
2024-08-02 16:54:22,205 [foster.py] => SNet: Task 13, Epoch 58/130 => Loss 29.325,  Loss1 0.739, Train_accy 71.77
2024-08-02 16:54:25,767 [foster.py] => SNet: Task 13, Epoch 59/130 => Loss 29.302,  Loss1 0.740, Train_accy 72.66
2024-08-02 16:54:29,355 [foster.py] => SNet: Task 13, Epoch 60/130 => Loss 29.329,  Loss1 0.740, Train_accy 71.57
2024-08-02 16:54:34,036 [foster.py] => SNet: Task 13, Epoch 61/130 => Loss 29.302,  Loss1 0.740, Train_accy 69.68, Test_accy 67.22
2024-08-02 16:54:37,690 [foster.py] => SNet: Task 13, Epoch 62/130 => Loss 29.356,  Loss1 0.739, Train_accy 72.10
2024-08-02 16:54:41,243 [foster.py] => SNet: Task 13, Epoch 63/130 => Loss 29.395,  Loss1 0.740, Train_accy 70.89
2024-08-02 16:54:44,812 [foster.py] => SNet: Task 13, Epoch 64/130 => Loss 29.308,  Loss1 0.740, Train_accy 73.47
2024-08-02 16:54:48,365 [foster.py] => SNet: Task 13, Epoch 65/130 => Loss 29.351,  Loss1 0.740, Train_accy 73.02
2024-08-02 16:54:53,083 [foster.py] => SNet: Task 13, Epoch 66/130 => Loss 29.335,  Loss1 0.740, Train_accy 72.30, Test_accy 67.26
2024-08-02 16:54:56,625 [foster.py] => SNet: Task 13, Epoch 67/130 => Loss 29.313,  Loss1 0.740, Train_accy 73.95
2024-08-02 16:55:00,171 [foster.py] => SNet: Task 13, Epoch 68/130 => Loss 29.344,  Loss1 0.740, Train_accy 72.10
2024-08-02 16:55:03,759 [foster.py] => SNet: Task 13, Epoch 69/130 => Loss 29.342,  Loss1 0.740, Train_accy 72.50
2024-08-02 16:55:07,343 [foster.py] => SNet: Task 13, Epoch 70/130 => Loss 29.389,  Loss1 0.739, Train_accy 72.50
2024-08-02 16:55:12,022 [foster.py] => SNet: Task 13, Epoch 71/130 => Loss 29.338,  Loss1 0.740, Train_accy 71.17, Test_accy 67.47
2024-08-02 16:55:15,578 [foster.py] => SNet: Task 13, Epoch 72/130 => Loss 29.336,  Loss1 0.740, Train_accy 71.61
2024-08-02 16:55:19,128 [foster.py] => SNet: Task 13, Epoch 73/130 => Loss 29.353,  Loss1 0.739, Train_accy 71.53
2024-08-02 16:55:22,698 [foster.py] => SNet: Task 13, Epoch 74/130 => Loss 29.358,  Loss1 0.739, Train_accy 72.14
2024-08-02 16:55:26,254 [foster.py] => SNet: Task 13, Epoch 75/130 => Loss 29.337,  Loss1 0.740, Train_accy 72.66
2024-08-02 16:55:30,933 [foster.py] => SNet: Task 13, Epoch 76/130 => Loss 29.351,  Loss1 0.739, Train_accy 74.15, Test_accy 67.42
2024-08-02 16:55:34,500 [foster.py] => SNet: Task 13, Epoch 77/130 => Loss 29.340,  Loss1 0.740, Train_accy 72.94
2024-08-02 16:55:38,049 [foster.py] => SNet: Task 13, Epoch 78/130 => Loss 29.312,  Loss1 0.739, Train_accy 73.35
2024-08-02 16:55:41,596 [foster.py] => SNet: Task 13, Epoch 79/130 => Loss 29.357,  Loss1 0.740, Train_accy 72.38
2024-08-02 16:55:45,138 [foster.py] => SNet: Task 13, Epoch 80/130 => Loss 29.312,  Loss1 0.740, Train_accy 72.22
2024-08-02 16:55:49,910 [foster.py] => SNet: Task 13, Epoch 81/130 => Loss 29.359,  Loss1 0.740, Train_accy 73.63, Test_accy 67.54
2024-08-02 16:55:53,495 [foster.py] => SNet: Task 13, Epoch 82/130 => Loss 29.269,  Loss1 0.740, Train_accy 72.34
2024-08-02 16:55:57,034 [foster.py] => SNet: Task 13, Epoch 83/130 => Loss 29.319,  Loss1 0.739, Train_accy 72.42
2024-08-02 16:56:00,619 [foster.py] => SNet: Task 13, Epoch 84/130 => Loss 29.318,  Loss1 0.740, Train_accy 71.33
2024-08-02 16:56:04,164 [foster.py] => SNet: Task 13, Epoch 85/130 => Loss 29.353,  Loss1 0.740, Train_accy 73.15
2024-08-02 16:56:08,869 [foster.py] => SNet: Task 13, Epoch 86/130 => Loss 29.354,  Loss1 0.740, Train_accy 73.43, Test_accy 67.46
2024-08-02 16:56:12,424 [foster.py] => SNet: Task 13, Epoch 87/130 => Loss 29.326,  Loss1 0.740, Train_accy 72.62
2024-08-02 16:56:15,972 [foster.py] => SNet: Task 13, Epoch 88/130 => Loss 29.336,  Loss1 0.740, Train_accy 73.19
2024-08-02 16:56:19,521 [foster.py] => SNet: Task 13, Epoch 89/130 => Loss 29.302,  Loss1 0.740, Train_accy 74.03
2024-08-02 16:56:23,063 [foster.py] => SNet: Task 13, Epoch 90/130 => Loss 29.310,  Loss1 0.740, Train_accy 71.57
2024-08-02 16:56:27,719 [foster.py] => SNet: Task 13, Epoch 91/130 => Loss 29.343,  Loss1 0.740, Train_accy 74.80, Test_accy 67.32
2024-08-02 16:56:31,271 [foster.py] => SNet: Task 13, Epoch 92/130 => Loss 29.365,  Loss1 0.740, Train_accy 72.94
2024-08-02 16:56:34,826 [foster.py] => SNet: Task 13, Epoch 93/130 => Loss 29.341,  Loss1 0.740, Train_accy 73.79
2024-08-02 16:56:38,372 [foster.py] => SNet: Task 13, Epoch 94/130 => Loss 29.330,  Loss1 0.739, Train_accy 72.66
2024-08-02 16:56:41,979 [foster.py] => SNet: Task 13, Epoch 95/130 => Loss 29.312,  Loss1 0.740, Train_accy 72.66
2024-08-02 16:56:46,681 [foster.py] => SNet: Task 13, Epoch 96/130 => Loss 29.343,  Loss1 0.740, Train_accy 73.51, Test_accy 67.47
2024-08-02 16:56:50,234 [foster.py] => SNet: Task 13, Epoch 97/130 => Loss 29.334,  Loss1 0.740, Train_accy 74.56
2024-08-02 16:56:53,761 [foster.py] => SNet: Task 13, Epoch 98/130 => Loss 29.366,  Loss1 0.740, Train_accy 73.59
2024-08-02 16:56:57,343 [foster.py] => SNet: Task 13, Epoch 99/130 => Loss 29.293,  Loss1 0.740, Train_accy 72.42
2024-08-02 16:57:00,917 [foster.py] => SNet: Task 13, Epoch 100/130 => Loss 29.318,  Loss1 0.740, Train_accy 72.46
2024-08-02 16:57:05,618 [foster.py] => SNet: Task 13, Epoch 101/130 => Loss 29.337,  Loss1 0.740, Train_accy 72.22, Test_accy 67.46
2024-08-02 16:57:09,201 [foster.py] => SNet: Task 13, Epoch 102/130 => Loss 29.350,  Loss1 0.740, Train_accy 74.96
2024-08-02 16:57:12,775 [foster.py] => SNet: Task 13, Epoch 103/130 => Loss 29.318,  Loss1 0.739, Train_accy 72.90
2024-08-02 16:57:16,326 [foster.py] => SNet: Task 13, Epoch 104/130 => Loss 29.376,  Loss1 0.739, Train_accy 72.30
2024-08-02 16:57:19,894 [foster.py] => SNet: Task 13, Epoch 105/130 => Loss 29.375,  Loss1 0.740, Train_accy 73.51
2024-08-02 16:57:24,581 [foster.py] => SNet: Task 13, Epoch 106/130 => Loss 29.355,  Loss1 0.740, Train_accy 74.27, Test_accy 67.45
2024-08-02 16:57:28,149 [foster.py] => SNet: Task 13, Epoch 107/130 => Loss 29.361,  Loss1 0.740, Train_accy 72.82
2024-08-02 16:57:31,696 [foster.py] => SNet: Task 13, Epoch 108/130 => Loss 29.319,  Loss1 0.740, Train_accy 73.51
2024-08-02 16:57:35,244 [foster.py] => SNet: Task 13, Epoch 109/130 => Loss 29.310,  Loss1 0.740, Train_accy 73.67
2024-08-02 16:57:38,797 [foster.py] => SNet: Task 13, Epoch 110/130 => Loss 29.304,  Loss1 0.739, Train_accy 72.38
2024-08-02 16:57:43,474 [foster.py] => SNet: Task 13, Epoch 111/130 => Loss 29.341,  Loss1 0.739, Train_accy 71.69, Test_accy 67.25
2024-08-02 16:57:47,007 [foster.py] => SNet: Task 13, Epoch 112/130 => Loss 29.354,  Loss1 0.740, Train_accy 73.35
2024-08-02 16:57:50,609 [foster.py] => SNet: Task 13, Epoch 113/130 => Loss 29.335,  Loss1 0.740, Train_accy 73.63
2024-08-02 16:57:54,142 [foster.py] => SNet: Task 13, Epoch 114/130 => Loss 29.319,  Loss1 0.740, Train_accy 73.91
2024-08-02 16:57:57,700 [foster.py] => SNet: Task 13, Epoch 115/130 => Loss 29.281,  Loss1 0.740, Train_accy 73.31
2024-08-02 16:58:02,380 [foster.py] => SNet: Task 13, Epoch 116/130 => Loss 29.327,  Loss1 0.740, Train_accy 73.27, Test_accy 67.59
2024-08-02 16:58:05,957 [foster.py] => SNet: Task 13, Epoch 117/130 => Loss 29.371,  Loss1 0.740, Train_accy 73.23
2024-08-02 16:58:09,593 [foster.py] => SNet: Task 13, Epoch 118/130 => Loss 29.354,  Loss1 0.740, Train_accy 73.15
2024-08-02 16:58:13,139 [foster.py] => SNet: Task 13, Epoch 119/130 => Loss 29.325,  Loss1 0.740, Train_accy 74.15
2024-08-02 16:58:16,710 [foster.py] => SNet: Task 13, Epoch 120/130 => Loss 29.295,  Loss1 0.740, Train_accy 72.62
2024-08-02 16:58:21,392 [foster.py] => SNet: Task 13, Epoch 121/130 => Loss 29.331,  Loss1 0.739, Train_accy 73.39, Test_accy 67.49
2024-08-02 16:58:24,998 [foster.py] => SNet: Task 13, Epoch 122/130 => Loss 29.352,  Loss1 0.739, Train_accy 72.50
2024-08-02 16:58:28,566 [foster.py] => SNet: Task 13, Epoch 123/130 => Loss 29.336,  Loss1 0.740, Train_accy 73.63
2024-08-02 16:58:32,125 [foster.py] => SNet: Task 13, Epoch 124/130 => Loss 29.344,  Loss1 0.740, Train_accy 73.31
2024-08-02 16:58:35,679 [foster.py] => SNet: Task 13, Epoch 125/130 => Loss 29.346,  Loss1 0.739, Train_accy 73.79
2024-08-02 16:58:40,346 [foster.py] => SNet: Task 13, Epoch 126/130 => Loss 29.369,  Loss1 0.740, Train_accy 73.71, Test_accy 67.45
2024-08-02 16:58:43,938 [foster.py] => SNet: Task 13, Epoch 127/130 => Loss 29.337,  Loss1 0.739, Train_accy 73.31
2024-08-02 16:58:47,520 [foster.py] => SNet: Task 13, Epoch 128/130 => Loss 29.349,  Loss1 0.740, Train_accy 72.90
2024-08-02 16:58:51,047 [foster.py] => SNet: Task 13, Epoch 129/130 => Loss 29.344,  Loss1 0.739, Train_accy 72.30
2024-08-02 16:58:54,582 [foster.py] => SNet: Task 13, Epoch 130/130 => Loss 29.362,  Loss1 0.740, Train_accy 73.31
2024-08-02 16:58:54,583 [foster.py] => do not weight align student!
2024-08-02 16:58:55,699 [foster.py] => darknet eval: 
2024-08-02 16:58:55,699 [foster.py] => CNN top1 curve: 67.55
2024-08-02 16:58:55,699 [foster.py] => CNN top5 curve: 89.74
2024-08-02 16:58:55,699 [foster.py] => CNN top1 平均值: 67.55
2024-08-02 16:58:55,702 [foster.py] => timees : 1175.612336397171
2024-08-02 16:58:55,703 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 16:59:18,966 [foster.py] => Exemplar size: 1520
2024-08-02 16:59:18,966 [trainer.py] => CNN: {'total': 68.55, '00-09': 74.9, '10-19': 60.2, '20-29': 74.6, '30-39': 67.5, '40-49': 73.5, '50-59': 57.8, '60-69': 69.6, '70-79': 71.5, 'old': 68.31, 'new': 77.5}
2024-08-02 16:59:18,967 [trainer.py] => NME: {'total': 63.17, '00-09': 66.2, '10-19': 52.8, '20-29': 67.5, '30-39': 61.6, '40-49': 66.8, '50-59': 56.3, '60-69': 69.7, '70-79': 65.33, 'old': 62.51, 'new': 87.5}
2024-08-02 16:59:18,967 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55]
2024-08-02 16:59:18,967 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66]
2024-08-02 16:59:18,967 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17]
2024-08-02 16:59:18,967 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8]

2024-08-02 16:59:18,967 [trainer.py] => CNN top1 平均值: 74.94
2024-08-02 16:59:18,969 [trainer.py] => All params: 1174102
2024-08-02 16:59:18,972 [trainer.py] => Trainable params: 592018
2024-08-02 16:59:19,032 [foster.py] => Learning on 76-78
2024-08-02 16:59:19,036 [foster.py] => All params: 1174620
2024-08-02 16:59:19,038 [foster.py] => Trainable params: 592406
2024-08-02 16:59:19,076 [foster.py] => per cls weights : [1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876 1.01174876
 1.01174876 1.01174876 1.01174876 1.01174876 0.55354707 0.55354707]
2024-08-02 16:59:21,693 [foster.py] => Task 14, Epoch 1/170 => Loss 5.249, Loss_clf 0.984, Loss_fe 1.819, Loss_kd 2.381, Train_accy 66.07
2024-08-02 16:59:26,102 [foster.py] => Task 14, Epoch 2/170 => Loss 3.662, Loss_clf 0.529, Loss_fe 0.718, Loss_kd 2.352, Train_accy 69.80, Test_accy 66.73
2024-08-02 16:59:30,462 [foster.py] => Task 14, Epoch 3/170 => Loss 3.521, Loss_clf 0.513, Loss_fe 0.587, Loss_kd 2.357, Train_accy 68.93, Test_accy 66.82
2024-08-02 16:59:34,900 [foster.py] => Task 14, Epoch 4/170 => Loss 3.378, Loss_clf 0.463, Loss_fe 0.500, Loss_kd 2.352, Train_accy 71.87, Test_accy 67.12
2024-08-02 16:59:39,222 [foster.py] => Task 14, Epoch 5/170 => Loss 3.344, Loss_clf 0.452, Loss_fe 0.481, Loss_kd 2.347, Train_accy 71.83, Test_accy 66.96
2024-08-02 16:59:41,793 [foster.py] => Task 14, Epoch 6/170 => Loss 3.276, Loss_clf 0.442, Loss_fe 0.434, Loss_kd 2.337, Train_accy 72.22
2024-08-02 16:59:46,158 [foster.py] => Task 14, Epoch 7/170 => Loss 3.286, Loss_clf 0.459, Loss_fe 0.408, Loss_kd 2.356, Train_accy 71.39, Test_accy 67.21
2024-08-02 16:59:50,556 [foster.py] => Task 14, Epoch 8/170 => Loss 3.229, Loss_clf 0.445, Loss_fe 0.376, Loss_kd 2.344, Train_accy 72.58, Test_accy 67.27
2024-08-02 16:59:54,916 [foster.py] => Task 14, Epoch 9/170 => Loss 3.173, Loss_clf 0.416, Loss_fe 0.385, Loss_kd 2.309, Train_accy 73.41, Test_accy 66.83
2024-08-02 16:59:59,309 [foster.py] => Task 14, Epoch 10/170 => Loss 3.168, Loss_clf 0.415, Loss_fe 0.361, Loss_kd 2.329, Train_accy 73.93, Test_accy 66.74
2024-08-02 17:00:01,921 [foster.py] => Task 14, Epoch 11/170 => Loss 3.135, Loss_clf 0.401, Loss_fe 0.336, Loss_kd 2.336, Train_accy 75.44
2024-08-02 17:00:06,309 [foster.py] => Task 14, Epoch 12/170 => Loss 3.136, Loss_clf 0.410, Loss_fe 0.327, Loss_kd 2.336, Train_accy 76.27, Test_accy 66.54
2024-08-02 17:00:10,760 [foster.py] => Task 14, Epoch 13/170 => Loss 3.116, Loss_clf 0.393, Loss_fe 0.339, Loss_kd 2.321, Train_accy 75.16, Test_accy 67.13
2024-08-02 17:00:15,163 [foster.py] => Task 14, Epoch 14/170 => Loss 3.156, Loss_clf 0.413, Loss_fe 0.335, Loss_kd 2.344, Train_accy 75.16, Test_accy 66.86
2024-08-02 17:00:19,554 [foster.py] => Task 14, Epoch 15/170 => Loss 3.148, Loss_clf 0.413, Loss_fe 0.330, Loss_kd 2.342, Train_accy 73.02, Test_accy 66.97
2024-08-02 17:00:22,124 [foster.py] => Task 14, Epoch 16/170 => Loss 3.124, Loss_clf 0.411, Loss_fe 0.325, Loss_kd 2.325, Train_accy 74.33
2024-08-02 17:00:26,488 [foster.py] => Task 14, Epoch 17/170 => Loss 3.121, Loss_clf 0.393, Loss_fe 0.316, Loss_kd 2.348, Train_accy 75.63, Test_accy 67.12
2024-08-02 17:00:30,836 [foster.py] => Task 14, Epoch 18/170 => Loss 3.113, Loss_clf 0.396, Loss_fe 0.312, Loss_kd 2.341, Train_accy 76.23, Test_accy 66.41
2024-08-02 17:00:35,199 [foster.py] => Task 14, Epoch 19/170 => Loss 3.176, Loss_clf 0.427, Loss_fe 0.307, Loss_kd 2.377, Train_accy 76.31, Test_accy 66.58
2024-08-02 17:00:39,595 [foster.py] => Task 14, Epoch 20/170 => Loss 3.093, Loss_clf 0.386, Loss_fe 0.288, Loss_kd 2.355, Train_accy 75.56, Test_accy 66.91
2024-08-02 17:00:42,175 [foster.py] => Task 14, Epoch 21/170 => Loss 3.037, Loss_clf 0.374, Loss_fe 0.270, Loss_kd 2.330, Train_accy 75.75
2024-08-02 17:00:46,582 [foster.py] => Task 14, Epoch 22/170 => Loss 3.130, Loss_clf 0.416, Loss_fe 0.281, Loss_kd 2.368, Train_accy 75.60, Test_accy 67.28
2024-08-02 17:00:50,950 [foster.py] => Task 14, Epoch 23/170 => Loss 3.072, Loss_clf 0.387, Loss_fe 0.262, Loss_kd 2.359, Train_accy 77.78, Test_accy 66.85
2024-08-02 17:00:55,385 [foster.py] => Task 14, Epoch 24/170 => Loss 3.058, Loss_clf 0.388, Loss_fe 0.282, Loss_kd 2.325, Train_accy 77.46, Test_accy 66.73
2024-08-02 17:00:59,753 [foster.py] => Task 14, Epoch 25/170 => Loss 3.135, Loss_clf 0.423, Loss_fe 0.296, Loss_kd 2.353, Train_accy 74.88, Test_accy 66.64
2024-08-02 17:01:02,363 [foster.py] => Task 14, Epoch 26/170 => Loss 3.042, Loss_clf 0.386, Loss_fe 0.258, Loss_kd 2.335, Train_accy 74.48
2024-08-02 17:01:06,736 [foster.py] => Task 14, Epoch 27/170 => Loss 3.040, Loss_clf 0.374, Loss_fe 0.265, Loss_kd 2.338, Train_accy 76.59, Test_accy 67.47
2024-08-02 17:01:11,174 [foster.py] => Task 14, Epoch 28/170 => Loss 3.065, Loss_clf 0.394, Loss_fe 0.256, Loss_kd 2.351, Train_accy 76.51, Test_accy 66.97
2024-08-02 17:01:15,565 [foster.py] => Task 14, Epoch 29/170 => Loss 2.974, Loss_clf 0.350, Loss_fe 0.256, Loss_kd 2.305, Train_accy 77.98, Test_accy 67.18
2024-08-02 17:01:20,025 [foster.py] => Task 14, Epoch 30/170 => Loss 3.001, Loss_clf 0.372, Loss_fe 0.233, Loss_kd 2.333, Train_accy 76.55, Test_accy 67.09
2024-08-02 17:01:22,573 [foster.py] => Task 14, Epoch 31/170 => Loss 3.004, Loss_clf 0.376, Loss_fe 0.227, Loss_kd 2.337, Train_accy 76.11
2024-08-02 17:01:27,001 [foster.py] => Task 14, Epoch 32/170 => Loss 2.992, Loss_clf 0.358, Loss_fe 0.241, Loss_kd 2.331, Train_accy 77.82, Test_accy 67.67
2024-08-02 17:01:31,353 [foster.py] => Task 14, Epoch 33/170 => Loss 3.026, Loss_clf 0.366, Loss_fe 0.242, Loss_kd 2.354, Train_accy 77.02, Test_accy 67.28
2024-08-02 17:01:35,733 [foster.py] => Task 14, Epoch 34/170 => Loss 2.982, Loss_clf 0.366, Loss_fe 0.228, Loss_kd 2.325, Train_accy 78.17, Test_accy 67.09
2024-08-02 17:01:40,115 [foster.py] => Task 14, Epoch 35/170 => Loss 3.066, Loss_clf 0.393, Loss_fe 0.245, Loss_kd 2.364, Train_accy 77.26, Test_accy 66.79
2024-08-02 17:01:42,750 [foster.py] => Task 14, Epoch 36/170 => Loss 2.976, Loss_clf 0.364, Loss_fe 0.234, Loss_kd 2.316, Train_accy 78.10
2024-08-02 17:01:47,129 [foster.py] => Task 14, Epoch 37/170 => Loss 2.977, Loss_clf 0.342, Loss_fe 0.213, Loss_kd 2.359, Train_accy 78.37, Test_accy 67.24
2024-08-02 17:01:51,489 [foster.py] => Task 14, Epoch 38/170 => Loss 3.053, Loss_clf 0.397, Loss_fe 0.236, Loss_kd 2.357, Train_accy 78.85, Test_accy 67.46
2024-08-02 17:01:55,866 [foster.py] => Task 14, Epoch 39/170 => Loss 3.008, Loss_clf 0.363, Loss_fe 0.239, Loss_kd 2.343, Train_accy 78.93, Test_accy 67.17
2024-08-02 17:02:00,282 [foster.py] => Task 14, Epoch 40/170 => Loss 2.981, Loss_clf 0.362, Loss_fe 0.215, Loss_kd 2.340, Train_accy 78.13, Test_accy 67.53
2024-08-02 17:02:02,850 [foster.py] => Task 14, Epoch 41/170 => Loss 2.953, Loss_clf 0.349, Loss_fe 0.207, Loss_kd 2.335, Train_accy 77.54
2024-08-02 17:02:07,229 [foster.py] => Task 14, Epoch 42/170 => Loss 2.953, Loss_clf 0.345, Loss_fe 0.209, Loss_kd 2.336, Train_accy 78.93, Test_accy 66.64
2024-08-02 17:02:11,615 [foster.py] => Task 14, Epoch 43/170 => Loss 2.988, Loss_clf 0.367, Loss_fe 0.224, Loss_kd 2.334, Train_accy 78.41, Test_accy 66.77
2024-08-02 17:02:15,986 [foster.py] => Task 14, Epoch 44/170 => Loss 2.917, Loss_clf 0.340, Loss_fe 0.208, Loss_kd 2.307, Train_accy 79.09, Test_accy 67.15
2024-08-02 17:02:20,392 [foster.py] => Task 14, Epoch 45/170 => Loss 2.867, Loss_clf 0.317, Loss_fe 0.187, Loss_kd 2.301, Train_accy 79.84, Test_accy 67.09
2024-08-02 17:02:22,953 [foster.py] => Task 14, Epoch 46/170 => Loss 2.951, Loss_clf 0.355, Loss_fe 0.188, Loss_kd 2.344, Train_accy 79.09
2024-08-02 17:02:27,314 [foster.py] => Task 14, Epoch 47/170 => Loss 2.941, Loss_clf 0.360, Loss_fe 0.186, Loss_kd 2.333, Train_accy 78.93, Test_accy 67.45
2024-08-02 17:02:31,706 [foster.py] => Task 14, Epoch 48/170 => Loss 2.981, Loss_clf 0.368, Loss_fe 0.207, Loss_kd 2.342, Train_accy 78.77, Test_accy 67.03
2024-08-02 17:02:36,116 [foster.py] => Task 14, Epoch 49/170 => Loss 2.989, Loss_clf 0.359, Loss_fe 0.212, Loss_kd 2.355, Train_accy 79.88, Test_accy 67.38
2024-08-02 17:02:40,565 [foster.py] => Task 14, Epoch 50/170 => Loss 2.905, Loss_clf 0.316, Loss_fe 0.202, Loss_kd 2.325, Train_accy 80.04, Test_accy 67.27
2024-08-02 17:02:43,187 [foster.py] => Task 14, Epoch 51/170 => Loss 2.953, Loss_clf 0.339, Loss_fe 0.194, Loss_kd 2.356, Train_accy 82.62
2024-08-02 17:02:47,650 [foster.py] => Task 14, Epoch 52/170 => Loss 2.964, Loss_clf 0.361, Loss_fe 0.199, Loss_kd 2.340, Train_accy 77.62, Test_accy 67.64
2024-08-02 17:02:52,003 [foster.py] => Task 14, Epoch 53/170 => Loss 2.867, Loss_clf 0.316, Loss_fe 0.184, Loss_kd 2.305, Train_accy 82.62, Test_accy 67.72
2024-08-02 17:02:56,374 [foster.py] => Task 14, Epoch 54/170 => Loss 2.952, Loss_clf 0.347, Loss_fe 0.179, Loss_kd 2.363, Train_accy 80.24, Test_accy 67.41
2024-08-02 17:03:00,761 [foster.py] => Task 14, Epoch 55/170 => Loss 2.945, Loss_clf 0.353, Loss_fe 0.167, Loss_kd 2.361, Train_accy 79.84, Test_accy 67.22
2024-08-02 17:03:03,405 [foster.py] => Task 14, Epoch 56/170 => Loss 2.897, Loss_clf 0.335, Loss_fe 0.186, Loss_kd 2.313, Train_accy 82.58
2024-08-02 17:03:07,769 [foster.py] => Task 14, Epoch 57/170 => Loss 2.919, Loss_clf 0.329, Loss_fe 0.170, Loss_kd 2.357, Train_accy 80.56, Test_accy 66.46
2024-08-02 17:03:12,126 [foster.py] => Task 14, Epoch 58/170 => Loss 2.982, Loss_clf 0.371, Loss_fe 0.196, Loss_kd 2.352, Train_accy 80.28, Test_accy 67.14
2024-08-02 17:03:16,461 [foster.py] => Task 14, Epoch 59/170 => Loss 2.964, Loss_clf 0.358, Loss_fe 0.202, Loss_kd 2.341, Train_accy 79.72, Test_accy 67.03
2024-08-02 17:03:20,820 [foster.py] => Task 14, Epoch 60/170 => Loss 2.959, Loss_clf 0.353, Loss_fe 0.172, Loss_kd 2.370, Train_accy 78.25, Test_accy 66.99
2024-08-02 17:03:23,383 [foster.py] => Task 14, Epoch 61/170 => Loss 2.899, Loss_clf 0.327, Loss_fe 0.167, Loss_kd 2.342, Train_accy 82.02
2024-08-02 17:03:27,751 [foster.py] => Task 14, Epoch 62/170 => Loss 2.921, Loss_clf 0.323, Loss_fe 0.166, Loss_kd 2.368, Train_accy 82.34, Test_accy 67.44
2024-08-02 17:03:32,120 [foster.py] => Task 14, Epoch 63/170 => Loss 2.913, Loss_clf 0.333, Loss_fe 0.154, Loss_kd 2.362, Train_accy 79.80, Test_accy 67.08
2024-08-02 17:03:36,472 [foster.py] => Task 14, Epoch 64/170 => Loss 2.928, Loss_clf 0.347, Loss_fe 0.158, Loss_kd 2.359, Train_accy 80.40, Test_accy 67.29
2024-08-02 17:03:40,837 [foster.py] => Task 14, Epoch 65/170 => Loss 2.840, Loss_clf 0.305, Loss_fe 0.143, Loss_kd 2.329, Train_accy 82.58, Test_accy 67.33
2024-08-02 17:03:43,466 [foster.py] => Task 14, Epoch 66/170 => Loss 2.864, Loss_clf 0.320, Loss_fe 0.165, Loss_kd 2.317, Train_accy 81.98
2024-08-02 17:03:47,839 [foster.py] => Task 14, Epoch 67/170 => Loss 2.840, Loss_clf 0.323, Loss_fe 0.137, Loss_kd 2.317, Train_accy 81.43, Test_accy 67.14
2024-08-02 17:03:52,234 [foster.py] => Task 14, Epoch 68/170 => Loss 2.894, Loss_clf 0.324, Loss_fe 0.155, Loss_kd 2.352, Train_accy 80.95, Test_accy 67.56
2024-08-02 17:03:56,653 [foster.py] => Task 14, Epoch 69/170 => Loss 2.928, Loss_clf 0.350, Loss_fe 0.181, Loss_kd 2.333, Train_accy 81.67, Test_accy 67.36
2024-08-02 17:04:00,993 [foster.py] => Task 14, Epoch 70/170 => Loss 2.871, Loss_clf 0.322, Loss_fe 0.165, Loss_kd 2.321, Train_accy 81.27, Test_accy 66.77
2024-08-02 17:04:03,559 [foster.py] => Task 14, Epoch 71/170 => Loss 2.863, Loss_clf 0.318, Loss_fe 0.156, Loss_kd 2.326, Train_accy 81.79
2024-08-02 17:04:07,958 [foster.py] => Task 14, Epoch 72/170 => Loss 2.889, Loss_clf 0.347, Loss_fe 0.159, Loss_kd 2.319, Train_accy 79.84, Test_accy 67.19
2024-08-02 17:04:12,329 [foster.py] => Task 14, Epoch 73/170 => Loss 2.899, Loss_clf 0.332, Loss_fe 0.160, Loss_kd 2.343, Train_accy 81.07, Test_accy 67.44
2024-08-02 17:04:16,843 [foster.py] => Task 14, Epoch 74/170 => Loss 2.867, Loss_clf 0.316, Loss_fe 0.155, Loss_kd 2.333, Train_accy 81.47, Test_accy 67.09
2024-08-02 17:04:21,315 [foster.py] => Task 14, Epoch 75/170 => Loss 2.902, Loss_clf 0.335, Loss_fe 0.164, Loss_kd 2.339, Train_accy 81.79, Test_accy 67.14
2024-08-02 17:04:23,879 [foster.py] => Task 14, Epoch 76/170 => Loss 2.877, Loss_clf 0.319, Loss_fe 0.169, Loss_kd 2.326, Train_accy 80.95
2024-08-02 17:04:28,260 [foster.py] => Task 14, Epoch 77/170 => Loss 2.946, Loss_clf 0.347, Loss_fe 0.170, Loss_kd 2.365, Train_accy 81.43, Test_accy 67.08
2024-08-02 17:04:32,637 [foster.py] => Task 14, Epoch 78/170 => Loss 2.888, Loss_clf 0.334, Loss_fe 0.154, Loss_kd 2.337, Train_accy 81.35, Test_accy 67.76
2024-08-02 17:04:37,004 [foster.py] => Task 14, Epoch 79/170 => Loss 2.904, Loss_clf 0.344, Loss_fe 0.148, Loss_kd 2.348, Train_accy 80.99, Test_accy 67.53
2024-08-02 17:04:41,382 [foster.py] => Task 14, Epoch 80/170 => Loss 2.824, Loss_clf 0.302, Loss_fe 0.142, Loss_kd 2.317, Train_accy 83.53, Test_accy 67.31
2024-08-02 17:04:43,954 [foster.py] => Task 14, Epoch 81/170 => Loss 2.879, Loss_clf 0.339, Loss_fe 0.153, Loss_kd 2.325, Train_accy 80.52
2024-08-02 17:04:48,404 [foster.py] => Task 14, Epoch 82/170 => Loss 2.823, Loss_clf 0.308, Loss_fe 0.152, Loss_kd 2.302, Train_accy 82.30, Test_accy 67.15
2024-08-02 17:04:52,791 [foster.py] => Task 14, Epoch 83/170 => Loss 2.916, Loss_clf 0.346, Loss_fe 0.157, Loss_kd 2.350, Train_accy 80.63, Test_accy 67.51
2024-08-02 17:04:57,174 [foster.py] => Task 14, Epoch 84/170 => Loss 2.870, Loss_clf 0.331, Loss_fe 0.139, Loss_kd 2.336, Train_accy 81.71, Test_accy 67.62
2024-08-02 17:05:01,568 [foster.py] => Task 14, Epoch 85/170 => Loss 2.858, Loss_clf 0.309, Loss_fe 0.147, Loss_kd 2.339, Train_accy 82.06, Test_accy 67.58
2024-08-02 17:05:04,183 [foster.py] => Task 14, Epoch 86/170 => Loss 2.875, Loss_clf 0.324, Loss_fe 0.147, Loss_kd 2.340, Train_accy 81.15
2024-08-02 17:05:08,608 [foster.py] => Task 14, Epoch 87/170 => Loss 2.831, Loss_clf 0.307, Loss_fe 0.130, Loss_kd 2.331, Train_accy 81.98, Test_accy 67.14
2024-08-02 17:05:13,157 [foster.py] => Task 14, Epoch 88/170 => Loss 2.837, Loss_clf 0.303, Loss_fe 0.142, Loss_kd 2.329, Train_accy 82.78, Test_accy 67.50
2024-08-02 17:05:17,563 [foster.py] => Task 14, Epoch 89/170 => Loss 2.913, Loss_clf 0.343, Loss_fe 0.157, Loss_kd 2.350, Train_accy 80.83, Test_accy 67.33
2024-08-02 17:05:21,921 [foster.py] => Task 14, Epoch 90/170 => Loss 2.834, Loss_clf 0.304, Loss_fe 0.122, Loss_kd 2.344, Train_accy 83.81, Test_accy 67.76
2024-08-02 17:05:24,525 [foster.py] => Task 14, Epoch 91/170 => Loss 2.853, Loss_clf 0.320, Loss_fe 0.146, Loss_kd 2.325, Train_accy 84.48
2024-08-02 17:05:28,910 [foster.py] => Task 14, Epoch 92/170 => Loss 2.825, Loss_clf 0.300, Loss_fe 0.124, Loss_kd 2.339, Train_accy 83.13, Test_accy 67.13
2024-08-02 17:05:33,290 [foster.py] => Task 14, Epoch 93/170 => Loss 2.845, Loss_clf 0.313, Loss_fe 0.116, Loss_kd 2.352, Train_accy 85.04, Test_accy 67.44
2024-08-02 17:05:37,696 [foster.py] => Task 14, Epoch 94/170 => Loss 2.841, Loss_clf 0.313, Loss_fe 0.120, Loss_kd 2.345, Train_accy 83.57, Test_accy 67.49
2024-08-02 17:05:42,043 [foster.py] => Task 14, Epoch 95/170 => Loss 2.823, Loss_clf 0.302, Loss_fe 0.119, Loss_kd 2.339, Train_accy 83.10, Test_accy 67.37
2024-08-02 17:05:44,621 [foster.py] => Task 14, Epoch 96/170 => Loss 2.853, Loss_clf 0.320, Loss_fe 0.135, Loss_kd 2.336, Train_accy 82.66
2024-08-02 17:05:48,979 [foster.py] => Task 14, Epoch 97/170 => Loss 2.848, Loss_clf 0.304, Loss_fe 0.114, Loss_kd 2.366, Train_accy 85.79, Test_accy 67.37
2024-08-02 17:05:53,430 [foster.py] => Task 14, Epoch 98/170 => Loss 2.828, Loss_clf 0.314, Loss_fe 0.132, Loss_kd 2.320, Train_accy 83.49, Test_accy 67.79
2024-08-02 17:05:57,785 [foster.py] => Task 14, Epoch 99/170 => Loss 2.841, Loss_clf 0.308, Loss_fe 0.119, Loss_kd 2.351, Train_accy 84.84, Test_accy 67.49
2024-08-02 17:06:02,143 [foster.py] => Task 14, Epoch 100/170 => Loss 2.846, Loss_clf 0.313, Loss_fe 0.126, Loss_kd 2.344, Train_accy 82.86, Test_accy 67.05
2024-08-02 17:06:04,715 [foster.py] => Task 14, Epoch 101/170 => Loss 2.822, Loss_clf 0.300, Loss_fe 0.112, Loss_kd 2.347, Train_accy 84.64
2024-08-02 17:06:09,090 [foster.py] => Task 14, Epoch 102/170 => Loss 2.860, Loss_clf 0.309, Loss_fe 0.131, Loss_kd 2.356, Train_accy 84.33, Test_accy 67.69
2024-08-02 17:06:13,484 [foster.py] => Task 14, Epoch 103/170 => Loss 2.773, Loss_clf 0.286, Loss_fe 0.109, Loss_kd 2.315, Train_accy 83.77, Test_accy 67.79
2024-08-02 17:06:17,871 [foster.py] => Task 14, Epoch 104/170 => Loss 2.776, Loss_clf 0.281, Loss_fe 0.109, Loss_kd 2.323, Train_accy 83.65, Test_accy 67.64
2024-08-02 17:06:22,236 [foster.py] => Task 14, Epoch 105/170 => Loss 2.828, Loss_clf 0.315, Loss_fe 0.102, Loss_kd 2.349, Train_accy 83.73, Test_accy 67.42
2024-08-02 17:06:24,806 [foster.py] => Task 14, Epoch 106/170 => Loss 2.893, Loss_clf 0.339, Loss_fe 0.136, Loss_kd 2.354, Train_accy 81.47
2024-08-02 17:06:29,238 [foster.py] => Task 14, Epoch 107/170 => Loss 2.859, Loss_clf 0.321, Loss_fe 0.128, Loss_kd 2.347, Train_accy 84.17, Test_accy 67.40
2024-08-02 17:06:33,590 [foster.py] => Task 14, Epoch 108/170 => Loss 2.770, Loss_clf 0.284, Loss_fe 0.093, Loss_kd 2.330, Train_accy 84.40, Test_accy 67.42
2024-08-02 17:06:38,000 [foster.py] => Task 14, Epoch 109/170 => Loss 2.812, Loss_clf 0.293, Loss_fe 0.116, Loss_kd 2.340, Train_accy 85.87, Test_accy 67.62
2024-08-02 17:06:42,353 [foster.py] => Task 14, Epoch 110/170 => Loss 2.763, Loss_clf 0.273, Loss_fe 0.115, Loss_kd 2.312, Train_accy 84.68, Test_accy 67.41
2024-08-02 17:06:45,077 [foster.py] => Task 14, Epoch 111/170 => Loss 2.864, Loss_clf 0.324, Loss_fe 0.109, Loss_kd 2.367, Train_accy 83.85
2024-08-02 17:06:49,469 [foster.py] => Task 14, Epoch 112/170 => Loss 2.793, Loss_clf 0.295, Loss_fe 0.104, Loss_kd 2.331, Train_accy 84.01, Test_accy 67.24
2024-08-02 17:06:53,891 [foster.py] => Task 14, Epoch 113/170 => Loss 2.841, Loss_clf 0.308, Loss_fe 0.119, Loss_kd 2.351, Train_accy 85.12, Test_accy 67.15
2024-08-02 17:06:58,278 [foster.py] => Task 14, Epoch 114/170 => Loss 2.899, Loss_clf 0.339, Loss_fe 0.118, Loss_kd 2.377, Train_accy 83.29, Test_accy 67.45
2024-08-02 17:07:02,708 [foster.py] => Task 14, Epoch 115/170 => Loss 2.774, Loss_clf 0.283, Loss_fe 0.099, Loss_kd 2.329, Train_accy 84.33, Test_accy 67.50
2024-08-02 17:07:05,273 [foster.py] => Task 14, Epoch 116/170 => Loss 2.786, Loss_clf 0.287, Loss_fe 0.104, Loss_kd 2.332, Train_accy 85.48
2024-08-02 17:07:09,686 [foster.py] => Task 14, Epoch 117/170 => Loss 2.830, Loss_clf 0.303, Loss_fe 0.109, Loss_kd 2.354, Train_accy 83.37, Test_accy 67.13
2024-08-02 17:07:14,076 [foster.py] => Task 14, Epoch 118/170 => Loss 2.849, Loss_clf 0.323, Loss_fe 0.100, Loss_kd 2.362, Train_accy 83.69, Test_accy 67.10
2024-08-02 17:07:18,445 [foster.py] => Task 14, Epoch 119/170 => Loss 2.781, Loss_clf 0.303, Loss_fe 0.091, Loss_kd 2.324, Train_accy 84.13, Test_accy 67.33
2024-08-02 17:07:22,798 [foster.py] => Task 14, Epoch 120/170 => Loss 2.773, Loss_clf 0.293, Loss_fe 0.087, Loss_kd 2.330, Train_accy 83.81, Test_accy 67.04
2024-08-02 17:07:25,365 [foster.py] => Task 14, Epoch 121/170 => Loss 2.809, Loss_clf 0.301, Loss_fe 0.092, Loss_kd 2.352, Train_accy 84.33
2024-08-02 17:07:29,757 [foster.py] => Task 14, Epoch 122/170 => Loss 2.757, Loss_clf 0.288, Loss_fe 0.075, Loss_kd 2.331, Train_accy 84.60, Test_accy 67.36
2024-08-02 17:07:34,112 [foster.py] => Task 14, Epoch 123/170 => Loss 2.829, Loss_clf 0.304, Loss_fe 0.100, Loss_kd 2.362, Train_accy 84.33, Test_accy 67.09
2024-08-02 17:07:38,456 [foster.py] => Task 14, Epoch 124/170 => Loss 2.758, Loss_clf 0.284, Loss_fe 0.095, Loss_kd 2.317, Train_accy 85.00, Test_accy 67.17
2024-08-02 17:07:42,899 [foster.py] => Task 14, Epoch 125/170 => Loss 2.783, Loss_clf 0.284, Loss_fe 0.089, Loss_kd 2.347, Train_accy 84.40, Test_accy 67.35
2024-08-02 17:07:45,449 [foster.py] => Task 14, Epoch 126/170 => Loss 2.774, Loss_clf 0.284, Loss_fe 0.097, Loss_kd 2.331, Train_accy 85.20
2024-08-02 17:07:49,806 [foster.py] => Task 14, Epoch 127/170 => Loss 2.784, Loss_clf 0.299, Loss_fe 0.103, Loss_kd 2.319, Train_accy 84.52, Test_accy 67.37
2024-08-02 17:07:54,238 [foster.py] => Task 14, Epoch 128/170 => Loss 2.800, Loss_clf 0.297, Loss_fe 0.104, Loss_kd 2.336, Train_accy 85.00, Test_accy 67.24
2024-08-02 17:07:58,619 [foster.py] => Task 14, Epoch 129/170 => Loss 2.773, Loss_clf 0.282, Loss_fe 0.095, Loss_kd 2.333, Train_accy 83.89, Test_accy 67.44
2024-08-02 17:08:02,993 [foster.py] => Task 14, Epoch 130/170 => Loss 2.779, Loss_clf 0.290, Loss_fe 0.082, Loss_kd 2.343, Train_accy 83.89, Test_accy 67.31
2024-08-02 17:08:05,553 [foster.py] => Task 14, Epoch 131/170 => Loss 2.781, Loss_clf 0.298, Loss_fe 0.089, Loss_kd 2.332, Train_accy 84.09
2024-08-02 17:08:09,893 [foster.py] => Task 14, Epoch 132/170 => Loss 2.812, Loss_clf 0.308, Loss_fe 0.095, Loss_kd 2.345, Train_accy 85.71, Test_accy 67.40
2024-08-02 17:08:14,329 [foster.py] => Task 14, Epoch 133/170 => Loss 2.804, Loss_clf 0.288, Loss_fe 0.087, Loss_kd 2.366, Train_accy 85.00, Test_accy 67.36
2024-08-02 17:08:18,682 [foster.py] => Task 14, Epoch 134/170 => Loss 2.754, Loss_clf 0.272, Loss_fe 0.080, Loss_kd 2.340, Train_accy 85.16, Test_accy 67.32
2024-08-02 17:08:23,034 [foster.py] => Task 14, Epoch 135/170 => Loss 2.753, Loss_clf 0.274, Loss_fe 0.085, Loss_kd 2.331, Train_accy 85.20, Test_accy 67.38
2024-08-02 17:08:25,628 [foster.py] => Task 14, Epoch 136/170 => Loss 2.788, Loss_clf 0.298, Loss_fe 0.084, Loss_kd 2.343, Train_accy 84.96
2024-08-02 17:08:29,968 [foster.py] => Task 14, Epoch 137/170 => Loss 2.771, Loss_clf 0.282, Loss_fe 0.091, Loss_kd 2.335, Train_accy 86.47, Test_accy 67.29
2024-08-02 17:08:34,350 [foster.py] => Task 14, Epoch 138/170 => Loss 2.762, Loss_clf 0.283, Loss_fe 0.083, Loss_kd 2.334, Train_accy 86.23, Test_accy 67.27
2024-08-02 17:08:38,711 [foster.py] => Task 14, Epoch 139/170 => Loss 2.800, Loss_clf 0.293, Loss_fe 0.088, Loss_kd 2.356, Train_accy 85.04, Test_accy 67.38
2024-08-02 17:08:43,141 [foster.py] => Task 14, Epoch 140/170 => Loss 2.827, Loss_clf 0.313, Loss_fe 0.095, Loss_kd 2.355, Train_accy 84.13, Test_accy 67.31
2024-08-02 17:08:45,708 [foster.py] => Task 14, Epoch 141/170 => Loss 2.793, Loss_clf 0.292, Loss_fe 0.095, Loss_kd 2.343, Train_accy 86.27
2024-08-02 17:08:50,096 [foster.py] => Task 14, Epoch 142/170 => Loss 2.754, Loss_clf 0.281, Loss_fe 0.081, Loss_kd 2.329, Train_accy 86.19, Test_accy 67.28
2024-08-02 17:08:54,502 [foster.py] => Task 14, Epoch 143/170 => Loss 2.766, Loss_clf 0.290, Loss_fe 0.083, Loss_kd 2.330, Train_accy 85.36, Test_accy 67.29
2024-08-02 17:08:58,900 [foster.py] => Task 14, Epoch 144/170 => Loss 2.760, Loss_clf 0.277, Loss_fe 0.081, Loss_kd 2.340, Train_accy 86.83, Test_accy 67.31
2024-08-02 17:09:03,292 [foster.py] => Task 14, Epoch 145/170 => Loss 2.774, Loss_clf 0.290, Loss_fe 0.082, Loss_kd 2.339, Train_accy 85.87, Test_accy 67.28
2024-08-02 17:09:05,899 [foster.py] => Task 14, Epoch 146/170 => Loss 2.776, Loss_clf 0.283, Loss_fe 0.074, Loss_kd 2.356, Train_accy 85.75
2024-08-02 17:09:10,296 [foster.py] => Task 14, Epoch 147/170 => Loss 2.793, Loss_clf 0.291, Loss_fe 0.080, Loss_kd 2.358, Train_accy 84.84, Test_accy 67.24
2024-08-02 17:09:14,681 [foster.py] => Task 14, Epoch 148/170 => Loss 2.775, Loss_clf 0.291, Loss_fe 0.080, Loss_kd 2.341, Train_accy 84.96, Test_accy 67.26
2024-08-02 17:09:19,290 [foster.py] => Task 14, Epoch 149/170 => Loss 2.801, Loss_clf 0.291, Loss_fe 0.083, Loss_kd 2.362, Train_accy 85.95, Test_accy 67.22
2024-08-02 17:09:23,651 [foster.py] => Task 14, Epoch 150/170 => Loss 2.775, Loss_clf 0.285, Loss_fe 0.087, Loss_kd 2.339, Train_accy 85.71, Test_accy 67.23
2024-08-02 17:09:26,226 [foster.py] => Task 14, Epoch 151/170 => Loss 2.735, Loss_clf 0.264, Loss_fe 0.079, Loss_kd 2.329, Train_accy 86.51
2024-08-02 17:09:30,613 [foster.py] => Task 14, Epoch 152/170 => Loss 2.785, Loss_clf 0.282, Loss_fe 0.085, Loss_kd 2.355, Train_accy 85.56, Test_accy 67.21
2024-08-02 17:09:34,972 [foster.py] => Task 14, Epoch 153/170 => Loss 2.778, Loss_clf 0.293, Loss_fe 0.086, Loss_kd 2.336, Train_accy 85.00, Test_accy 67.15
2024-08-02 17:09:39,354 [foster.py] => Task 14, Epoch 154/170 => Loss 2.784, Loss_clf 0.291, Loss_fe 0.083, Loss_kd 2.347, Train_accy 85.28, Test_accy 67.21
2024-08-02 17:09:43,752 [foster.py] => Task 14, Epoch 155/170 => Loss 2.753, Loss_clf 0.266, Loss_fe 0.078, Loss_kd 2.346, Train_accy 86.11, Test_accy 67.26
2024-08-02 17:09:46,305 [foster.py] => Task 14, Epoch 156/170 => Loss 2.795, Loss_clf 0.298, Loss_fe 0.073, Loss_kd 2.360, Train_accy 86.98
2024-08-02 17:09:50,781 [foster.py] => Task 14, Epoch 157/170 => Loss 2.797, Loss_clf 0.292, Loss_fe 0.087, Loss_kd 2.353, Train_accy 84.76, Test_accy 67.26
2024-08-02 17:09:55,250 [foster.py] => Task 14, Epoch 158/170 => Loss 2.787, Loss_clf 0.283, Loss_fe 0.079, Loss_kd 2.362, Train_accy 86.27, Test_accy 67.29
2024-08-02 17:09:59,714 [foster.py] => Task 14, Epoch 159/170 => Loss 2.801, Loss_clf 0.287, Loss_fe 0.081, Loss_kd 2.369, Train_accy 85.75, Test_accy 67.35
2024-08-02 17:10:04,122 [foster.py] => Task 14, Epoch 160/170 => Loss 2.777, Loss_clf 0.299, Loss_fe 0.074, Loss_kd 2.340, Train_accy 85.36, Test_accy 67.33
2024-08-02 17:10:06,685 [foster.py] => Task 14, Epoch 161/170 => Loss 2.777, Loss_clf 0.289, Loss_fe 0.083, Loss_kd 2.342, Train_accy 85.63
2024-08-02 17:10:11,054 [foster.py] => Task 14, Epoch 162/170 => Loss 2.786, Loss_clf 0.301, Loss_fe 0.082, Loss_kd 2.339, Train_accy 85.20, Test_accy 67.24
2024-08-02 17:10:15,437 [foster.py] => Task 14, Epoch 163/170 => Loss 2.698, Loss_clf 0.251, Loss_fe 0.065, Loss_kd 2.320, Train_accy 87.10, Test_accy 67.27
2024-08-02 17:10:19,841 [foster.py] => Task 14, Epoch 164/170 => Loss 2.779, Loss_clf 0.295, Loss_fe 0.072, Loss_kd 2.349, Train_accy 86.07, Test_accy 67.26
2024-08-02 17:10:24,224 [foster.py] => Task 14, Epoch 165/170 => Loss 2.765, Loss_clf 0.290, Loss_fe 0.079, Loss_kd 2.332, Train_accy 85.99, Test_accy 67.31
2024-08-02 17:10:26,786 [foster.py] => Task 14, Epoch 166/170 => Loss 2.753, Loss_clf 0.271, Loss_fe 0.086, Loss_kd 2.334, Train_accy 87.14
2024-08-02 17:10:31,131 [foster.py] => Task 14, Epoch 167/170 => Loss 2.800, Loss_clf 0.291, Loss_fe 0.081, Loss_kd 2.364, Train_accy 85.71, Test_accy 67.22
2024-08-02 17:10:35,497 [foster.py] => Task 14, Epoch 168/170 => Loss 2.749, Loss_clf 0.281, Loss_fe 0.070, Loss_kd 2.336, Train_accy 86.47, Test_accy 67.26
2024-08-02 17:10:39,923 [foster.py] => Task 14, Epoch 169/170 => Loss 2.744, Loss_clf 0.263, Loss_fe 0.078, Loss_kd 2.340, Train_accy 86.55, Test_accy 67.27
2024-08-02 17:10:44,330 [foster.py] => Task 14, Epoch 170/170 => Loss 2.786, Loss_clf 0.305, Loss_fe 0.080, Loss_kd 2.338, Train_accy 85.40, Test_accy 67.21
2024-08-02 17:10:44,335 [foster.py] => do not weight align teacher!
2024-08-02 17:10:44,338 [foster.py] => per cls weights : [1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417 1.01395417
 1.01395417 1.01395417 1.01395417 1.01395417 0.46974169 0.46974169]
2024-08-02 17:10:49,365 [foster.py] => SNet: Task 14, Epoch 1/130 => Loss 29.618,  Loss1 0.751, Train_accy 54.48, Test_accy 63.18
2024-08-02 17:10:52,948 [foster.py] => SNet: Task 14, Epoch 2/130 => Loss 29.486,  Loss1 0.752, Train_accy 63.02
2024-08-02 17:10:56,550 [foster.py] => SNet: Task 14, Epoch 3/130 => Loss 29.498,  Loss1 0.752, Train_accy 62.86
2024-08-02 17:11:00,116 [foster.py] => SNet: Task 14, Epoch 4/130 => Loss 29.513,  Loss1 0.752, Train_accy 63.73
2024-08-02 17:11:03,693 [foster.py] => SNet: Task 14, Epoch 5/130 => Loss 29.507,  Loss1 0.751, Train_accy 65.20
2024-08-02 17:11:08,384 [foster.py] => SNet: Task 14, Epoch 6/130 => Loss 29.410,  Loss1 0.751, Train_accy 65.79, Test_accy 66.40
2024-08-02 17:11:11,949 [foster.py] => SNet: Task 14, Epoch 7/130 => Loss 29.442,  Loss1 0.752, Train_accy 66.35
2024-08-02 17:11:15,513 [foster.py] => SNet: Task 14, Epoch 8/130 => Loss 29.502,  Loss1 0.751, Train_accy 66.47
2024-08-02 17:11:19,052 [foster.py] => SNet: Task 14, Epoch 9/130 => Loss 29.482,  Loss1 0.751, Train_accy 67.42
2024-08-02 17:11:22,624 [foster.py] => SNet: Task 14, Epoch 10/130 => Loss 29.454,  Loss1 0.751, Train_accy 66.94
2024-08-02 17:11:27,321 [foster.py] => SNet: Task 14, Epoch 11/130 => Loss 29.430,  Loss1 0.752, Train_accy 69.09, Test_accy 66.78
2024-08-02 17:11:30,897 [foster.py] => SNet: Task 14, Epoch 12/130 => Loss 29.527,  Loss1 0.751, Train_accy 68.13
2024-08-02 17:11:34,464 [foster.py] => SNet: Task 14, Epoch 13/130 => Loss 29.396,  Loss1 0.752, Train_accy 70.20
2024-08-02 17:11:38,080 [foster.py] => SNet: Task 14, Epoch 14/130 => Loss 29.455,  Loss1 0.752, Train_accy 67.26
2024-08-02 17:11:41,636 [foster.py] => SNet: Task 14, Epoch 15/130 => Loss 29.478,  Loss1 0.751, Train_accy 68.77
2024-08-02 17:11:46,346 [foster.py] => SNet: Task 14, Epoch 16/130 => Loss 29.483,  Loss1 0.752, Train_accy 67.66, Test_accy 66.44
2024-08-02 17:11:49,893 [foster.py] => SNet: Task 14, Epoch 17/130 => Loss 29.477,  Loss1 0.752, Train_accy 69.25
2024-08-02 17:11:53,482 [foster.py] => SNet: Task 14, Epoch 18/130 => Loss 29.413,  Loss1 0.752, Train_accy 70.75
2024-08-02 17:11:57,047 [foster.py] => SNet: Task 14, Epoch 19/130 => Loss 29.454,  Loss1 0.751, Train_accy 69.52
2024-08-02 17:12:00,623 [foster.py] => SNet: Task 14, Epoch 20/130 => Loss 29.456,  Loss1 0.752, Train_accy 69.96
2024-08-02 17:12:05,369 [foster.py] => SNet: Task 14, Epoch 21/130 => Loss 29.478,  Loss1 0.752, Train_accy 68.97, Test_accy 66.23
2024-08-02 17:12:08,953 [foster.py] => SNet: Task 14, Epoch 22/130 => Loss 29.479,  Loss1 0.751, Train_accy 71.35
2024-08-02 17:12:12,519 [foster.py] => SNet: Task 14, Epoch 23/130 => Loss 29.476,  Loss1 0.752, Train_accy 70.40
2024-08-02 17:12:16,083 [foster.py] => SNet: Task 14, Epoch 24/130 => Loss 29.431,  Loss1 0.751, Train_accy 69.80
2024-08-02 17:12:19,663 [foster.py] => SNet: Task 14, Epoch 25/130 => Loss 29.428,  Loss1 0.751, Train_accy 71.03
2024-08-02 17:12:24,376 [foster.py] => SNet: Task 14, Epoch 26/130 => Loss 29.423,  Loss1 0.752, Train_accy 71.19, Test_accy 66.56
2024-08-02 17:12:27,945 [foster.py] => SNet: Task 14, Epoch 27/130 => Loss 29.441,  Loss1 0.752, Train_accy 71.55
2024-08-02 17:12:31,543 [foster.py] => SNet: Task 14, Epoch 28/130 => Loss 29.495,  Loss1 0.751, Train_accy 70.71
2024-08-02 17:12:35,097 [foster.py] => SNet: Task 14, Epoch 29/130 => Loss 29.426,  Loss1 0.751, Train_accy 71.15
2024-08-02 17:12:38,680 [foster.py] => SNet: Task 14, Epoch 30/130 => Loss 29.474,  Loss1 0.752, Train_accy 70.12
2024-08-02 17:12:43,387 [foster.py] => SNet: Task 14, Epoch 31/130 => Loss 29.471,  Loss1 0.752, Train_accy 70.28, Test_accy 67.05
2024-08-02 17:12:47,016 [foster.py] => SNet: Task 14, Epoch 32/130 => Loss 29.451,  Loss1 0.752, Train_accy 71.27
2024-08-02 17:12:50,622 [foster.py] => SNet: Task 14, Epoch 33/130 => Loss 29.391,  Loss1 0.752, Train_accy 70.95
2024-08-02 17:12:54,222 [foster.py] => SNet: Task 14, Epoch 34/130 => Loss 29.474,  Loss1 0.752, Train_accy 70.52
2024-08-02 17:12:57,801 [foster.py] => SNet: Task 14, Epoch 35/130 => Loss 29.457,  Loss1 0.752, Train_accy 70.83
2024-08-02 17:13:02,517 [foster.py] => SNet: Task 14, Epoch 36/130 => Loss 29.445,  Loss1 0.751, Train_accy 71.63, Test_accy 66.59
2024-08-02 17:13:06,080 [foster.py] => SNet: Task 14, Epoch 37/130 => Loss 29.451,  Loss1 0.752, Train_accy 71.63
2024-08-02 17:13:09,648 [foster.py] => SNet: Task 14, Epoch 38/130 => Loss 29.451,  Loss1 0.752, Train_accy 72.14
2024-08-02 17:13:13,235 [foster.py] => SNet: Task 14, Epoch 39/130 => Loss 29.454,  Loss1 0.752, Train_accy 72.38
2024-08-02 17:13:16,800 [foster.py] => SNet: Task 14, Epoch 40/130 => Loss 29.444,  Loss1 0.752, Train_accy 71.63
2024-08-02 17:13:21,494 [foster.py] => SNet: Task 14, Epoch 41/130 => Loss 29.443,  Loss1 0.751, Train_accy 71.87, Test_accy 66.51
2024-08-02 17:13:25,057 [foster.py] => SNet: Task 14, Epoch 42/130 => Loss 29.434,  Loss1 0.752, Train_accy 71.67
2024-08-02 17:13:28,624 [foster.py] => SNet: Task 14, Epoch 43/130 => Loss 29.392,  Loss1 0.752, Train_accy 69.88
2024-08-02 17:13:32,227 [foster.py] => SNet: Task 14, Epoch 44/130 => Loss 29.451,  Loss1 0.751, Train_accy 72.38
2024-08-02 17:13:35,794 [foster.py] => SNet: Task 14, Epoch 45/130 => Loss 29.492,  Loss1 0.752, Train_accy 71.31
2024-08-02 17:13:40,513 [foster.py] => SNet: Task 14, Epoch 46/130 => Loss 29.433,  Loss1 0.752, Train_accy 72.38, Test_accy 66.92
2024-08-02 17:13:44,092 [foster.py] => SNet: Task 14, Epoch 47/130 => Loss 29.408,  Loss1 0.752, Train_accy 72.58
2024-08-02 17:13:47,647 [foster.py] => SNet: Task 14, Epoch 48/130 => Loss 29.423,  Loss1 0.752, Train_accy 70.56
2024-08-02 17:13:51,217 [foster.py] => SNet: Task 14, Epoch 49/130 => Loss 29.437,  Loss1 0.752, Train_accy 72.90
2024-08-02 17:13:54,860 [foster.py] => SNet: Task 14, Epoch 50/130 => Loss 29.413,  Loss1 0.751, Train_accy 71.67
2024-08-02 17:13:59,571 [foster.py] => SNet: Task 14, Epoch 51/130 => Loss 29.466,  Loss1 0.752, Train_accy 70.99, Test_accy 66.35
2024-08-02 17:14:03,171 [foster.py] => SNet: Task 14, Epoch 52/130 => Loss 29.463,  Loss1 0.752, Train_accy 72.18
2024-08-02 17:14:06,749 [foster.py] => SNet: Task 14, Epoch 53/130 => Loss 29.414,  Loss1 0.752, Train_accy 72.66
2024-08-02 17:14:10,319 [foster.py] => SNet: Task 14, Epoch 54/130 => Loss 29.409,  Loss1 0.752, Train_accy 72.62
2024-08-02 17:14:13,904 [foster.py] => SNet: Task 14, Epoch 55/130 => Loss 29.448,  Loss1 0.752, Train_accy 71.23
2024-08-02 17:14:18,596 [foster.py] => SNet: Task 14, Epoch 56/130 => Loss 29.443,  Loss1 0.752, Train_accy 72.50, Test_accy 66.83
2024-08-02 17:14:22,171 [foster.py] => SNet: Task 14, Epoch 57/130 => Loss 29.465,  Loss1 0.752, Train_accy 71.67
2024-08-02 17:14:25,736 [foster.py] => SNet: Task 14, Epoch 58/130 => Loss 29.432,  Loss1 0.752, Train_accy 72.30
2024-08-02 17:14:29,291 [foster.py] => SNet: Task 14, Epoch 59/130 => Loss 29.439,  Loss1 0.751, Train_accy 72.46
2024-08-02 17:14:32,856 [foster.py] => SNet: Task 14, Epoch 60/130 => Loss 29.446,  Loss1 0.752, Train_accy 73.10
2024-08-02 17:14:37,591 [foster.py] => SNet: Task 14, Epoch 61/130 => Loss 29.463,  Loss1 0.752, Train_accy 73.21, Test_accy 66.54
2024-08-02 17:14:41,156 [foster.py] => SNet: Task 14, Epoch 62/130 => Loss 29.463,  Loss1 0.752, Train_accy 72.50
2024-08-02 17:14:44,732 [foster.py] => SNet: Task 14, Epoch 63/130 => Loss 29.401,  Loss1 0.752, Train_accy 73.25
2024-08-02 17:14:48,294 [foster.py] => SNet: Task 14, Epoch 64/130 => Loss 29.408,  Loss1 0.752, Train_accy 73.10
2024-08-02 17:14:51,900 [foster.py] => SNet: Task 14, Epoch 65/130 => Loss 29.461,  Loss1 0.752, Train_accy 71.90
2024-08-02 17:14:56,658 [foster.py] => SNet: Task 14, Epoch 66/130 => Loss 29.438,  Loss1 0.752, Train_accy 72.26, Test_accy 66.90
2024-08-02 17:15:00,236 [foster.py] => SNet: Task 14, Epoch 67/130 => Loss 29.481,  Loss1 0.752, Train_accy 73.29
2024-08-02 17:15:03,818 [foster.py] => SNet: Task 14, Epoch 68/130 => Loss 29.427,  Loss1 0.752, Train_accy 71.94
2024-08-02 17:15:07,456 [foster.py] => SNet: Task 14, Epoch 69/130 => Loss 29.427,  Loss1 0.751, Train_accy 72.78
2024-08-02 17:15:10,999 [foster.py] => SNet: Task 14, Epoch 70/130 => Loss 29.407,  Loss1 0.751, Train_accy 73.41
2024-08-02 17:15:15,707 [foster.py] => SNet: Task 14, Epoch 71/130 => Loss 29.465,  Loss1 0.752, Train_accy 73.41, Test_accy 66.91
2024-08-02 17:15:19,274 [foster.py] => SNet: Task 14, Epoch 72/130 => Loss 29.432,  Loss1 0.752, Train_accy 73.25
2024-08-02 17:15:22,843 [foster.py] => SNet: Task 14, Epoch 73/130 => Loss 29.396,  Loss1 0.752, Train_accy 73.41
2024-08-02 17:15:26,429 [foster.py] => SNet: Task 14, Epoch 74/130 => Loss 29.490,  Loss1 0.752, Train_accy 73.29
2024-08-02 17:15:29,994 [foster.py] => SNet: Task 14, Epoch 75/130 => Loss 29.441,  Loss1 0.752, Train_accy 72.66
2024-08-02 17:15:34,726 [foster.py] => SNet: Task 14, Epoch 76/130 => Loss 29.448,  Loss1 0.752, Train_accy 72.34, Test_accy 66.76
2024-08-02 17:15:38,292 [foster.py] => SNet: Task 14, Epoch 77/130 => Loss 29.450,  Loss1 0.752, Train_accy 73.33
2024-08-02 17:15:41,874 [foster.py] => SNet: Task 14, Epoch 78/130 => Loss 29.443,  Loss1 0.752, Train_accy 72.10
2024-08-02 17:15:45,422 [foster.py] => SNet: Task 14, Epoch 79/130 => Loss 29.472,  Loss1 0.752, Train_accy 71.67
2024-08-02 17:15:48,980 [foster.py] => SNet: Task 14, Epoch 80/130 => Loss 29.434,  Loss1 0.752, Train_accy 72.86
2024-08-02 17:15:53,683 [foster.py] => SNet: Task 14, Epoch 81/130 => Loss 29.421,  Loss1 0.752, Train_accy 72.86, Test_accy 66.76
2024-08-02 17:15:57,260 [foster.py] => SNet: Task 14, Epoch 82/130 => Loss 29.446,  Loss1 0.752, Train_accy 73.02
2024-08-02 17:16:00,851 [foster.py] => SNet: Task 14, Epoch 83/130 => Loss 29.467,  Loss1 0.752, Train_accy 73.25
2024-08-02 17:16:04,437 [foster.py] => SNet: Task 14, Epoch 84/130 => Loss 29.431,  Loss1 0.752, Train_accy 72.66
2024-08-02 17:16:08,044 [foster.py] => SNet: Task 14, Epoch 85/130 => Loss 29.455,  Loss1 0.751, Train_accy 73.06
2024-08-02 17:16:12,710 [foster.py] => SNet: Task 14, Epoch 86/130 => Loss 29.452,  Loss1 0.752, Train_accy 73.25, Test_accy 66.74
2024-08-02 17:16:16,301 [foster.py] => SNet: Task 14, Epoch 87/130 => Loss 29.422,  Loss1 0.752, Train_accy 72.94
2024-08-02 17:16:19,913 [foster.py] => SNet: Task 14, Epoch 88/130 => Loss 29.410,  Loss1 0.752, Train_accy 73.41
2024-08-02 17:16:23,497 [foster.py] => SNet: Task 14, Epoch 89/130 => Loss 29.422,  Loss1 0.752, Train_accy 72.06
2024-08-02 17:16:27,095 [foster.py] => SNet: Task 14, Epoch 90/130 => Loss 29.412,  Loss1 0.752, Train_accy 72.86
2024-08-02 17:16:31,832 [foster.py] => SNet: Task 14, Epoch 91/130 => Loss 29.455,  Loss1 0.752, Train_accy 71.71, Test_accy 66.91
2024-08-02 17:16:35,431 [foster.py] => SNet: Task 14, Epoch 92/130 => Loss 29.360,  Loss1 0.752, Train_accy 73.29
2024-08-02 17:16:39,006 [foster.py] => SNet: Task 14, Epoch 93/130 => Loss 29.429,  Loss1 0.752, Train_accy 73.77
2024-08-02 17:16:42,562 [foster.py] => SNet: Task 14, Epoch 94/130 => Loss 29.472,  Loss1 0.752, Train_accy 72.66
2024-08-02 17:16:46,144 [foster.py] => SNet: Task 14, Epoch 95/130 => Loss 29.429,  Loss1 0.751, Train_accy 73.77
2024-08-02 17:16:50,850 [foster.py] => SNet: Task 14, Epoch 96/130 => Loss 29.412,  Loss1 0.752, Train_accy 72.82, Test_accy 66.72
2024-08-02 17:16:54,430 [foster.py] => SNet: Task 14, Epoch 97/130 => Loss 29.411,  Loss1 0.752, Train_accy 73.21
2024-08-02 17:16:57,974 [foster.py] => SNet: Task 14, Epoch 98/130 => Loss 29.461,  Loss1 0.753, Train_accy 72.14
2024-08-02 17:17:01,582 [foster.py] => SNet: Task 14, Epoch 99/130 => Loss 29.450,  Loss1 0.751, Train_accy 72.54
2024-08-02 17:17:05,151 [foster.py] => SNet: Task 14, Epoch 100/130 => Loss 29.472,  Loss1 0.752, Train_accy 73.13
2024-08-02 17:17:09,856 [foster.py] => SNet: Task 14, Epoch 101/130 => Loss 29.444,  Loss1 0.751, Train_accy 73.29, Test_accy 66.45
2024-08-02 17:17:13,417 [foster.py] => SNet: Task 14, Epoch 102/130 => Loss 29.413,  Loss1 0.752, Train_accy 73.33
2024-08-02 17:17:16,975 [foster.py] => SNet: Task 14, Epoch 103/130 => Loss 29.426,  Loss1 0.752, Train_accy 72.86
2024-08-02 17:17:20,512 [foster.py] => SNet: Task 14, Epoch 104/130 => Loss 29.459,  Loss1 0.752, Train_accy 72.42
2024-08-02 17:17:24,092 [foster.py] => SNet: Task 14, Epoch 105/130 => Loss 29.402,  Loss1 0.752, Train_accy 73.29
2024-08-02 17:17:28,859 [foster.py] => SNet: Task 14, Epoch 106/130 => Loss 29.408,  Loss1 0.751, Train_accy 72.42, Test_accy 67.03
2024-08-02 17:17:32,420 [foster.py] => SNet: Task 14, Epoch 107/130 => Loss 29.437,  Loss1 0.752, Train_accy 72.10
2024-08-02 17:17:36,005 [foster.py] => SNet: Task 14, Epoch 108/130 => Loss 29.428,  Loss1 0.751, Train_accy 72.30
2024-08-02 17:17:39,576 [foster.py] => SNet: Task 14, Epoch 109/130 => Loss 29.485,  Loss1 0.752, Train_accy 71.79
2024-08-02 17:17:43,154 [foster.py] => SNet: Task 14, Epoch 110/130 => Loss 29.456,  Loss1 0.752, Train_accy 73.93
2024-08-02 17:17:47,848 [foster.py] => SNet: Task 14, Epoch 111/130 => Loss 29.502,  Loss1 0.752, Train_accy 72.50, Test_accy 66.88
2024-08-02 17:17:51,435 [foster.py] => SNet: Task 14, Epoch 112/130 => Loss 29.522,  Loss1 0.752, Train_accy 73.25
2024-08-02 17:17:55,013 [foster.py] => SNet: Task 14, Epoch 113/130 => Loss 29.455,  Loss1 0.752, Train_accy 72.54
2024-08-02 17:17:58,592 [foster.py] => SNet: Task 14, Epoch 114/130 => Loss 29.411,  Loss1 0.752, Train_accy 73.13
2024-08-02 17:18:02,152 [foster.py] => SNet: Task 14, Epoch 115/130 => Loss 29.443,  Loss1 0.752, Train_accy 72.02
2024-08-02 17:18:06,863 [foster.py] => SNet: Task 14, Epoch 116/130 => Loss 29.451,  Loss1 0.751, Train_accy 72.46, Test_accy 66.76
2024-08-02 17:18:10,449 [foster.py] => SNet: Task 14, Epoch 117/130 => Loss 29.497,  Loss1 0.751, Train_accy 71.63
2024-08-02 17:18:14,006 [foster.py] => SNet: Task 14, Epoch 118/130 => Loss 29.473,  Loss1 0.752, Train_accy 71.98
2024-08-02 17:18:17,564 [foster.py] => SNet: Task 14, Epoch 119/130 => Loss 29.448,  Loss1 0.752, Train_accy 73.02
2024-08-02 17:18:21,149 [foster.py] => SNet: Task 14, Epoch 120/130 => Loss 29.407,  Loss1 0.752, Train_accy 73.29
2024-08-02 17:18:25,846 [foster.py] => SNet: Task 14, Epoch 121/130 => Loss 29.451,  Loss1 0.752, Train_accy 72.94, Test_accy 66.67
2024-08-02 17:18:29,408 [foster.py] => SNet: Task 14, Epoch 122/130 => Loss 29.463,  Loss1 0.752, Train_accy 72.90
2024-08-02 17:18:32,966 [foster.py] => SNet: Task 14, Epoch 123/130 => Loss 29.430,  Loss1 0.752, Train_accy 72.18
2024-08-02 17:18:36,597 [foster.py] => SNet: Task 14, Epoch 124/130 => Loss 29.445,  Loss1 0.751, Train_accy 72.22
2024-08-02 17:18:40,166 [foster.py] => SNet: Task 14, Epoch 125/130 => Loss 29.486,  Loss1 0.752, Train_accy 72.74
2024-08-02 17:18:44,866 [foster.py] => SNet: Task 14, Epoch 126/130 => Loss 29.436,  Loss1 0.752, Train_accy 72.58, Test_accy 66.83
2024-08-02 17:18:48,440 [foster.py] => SNet: Task 14, Epoch 127/130 => Loss 29.446,  Loss1 0.752, Train_accy 73.41
2024-08-02 17:18:52,009 [foster.py] => SNet: Task 14, Epoch 128/130 => Loss 29.471,  Loss1 0.752, Train_accy 72.82
2024-08-02 17:18:55,564 [foster.py] => SNet: Task 14, Epoch 129/130 => Loss 29.435,  Loss1 0.752, Train_accy 72.26
2024-08-02 17:18:59,124 [foster.py] => SNet: Task 14, Epoch 130/130 => Loss 29.454,  Loss1 0.751, Train_accy 73.41
2024-08-02 17:18:59,125 [foster.py] => do not weight align student!
2024-08-02 17:19:00,260 [foster.py] => darknet eval: 
2024-08-02 17:19:00,261 [foster.py] => CNN top1 curve: 67.09
2024-08-02 17:19:00,261 [foster.py] => CNN top5 curve: 89.55
2024-08-02 17:19:00,261 [foster.py] => CNN top1 平均值: 67.09
2024-08-02 17:19:00,264 [foster.py] => timees : 1181.20680809021
2024-08-02 17:19:00,265 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 17:19:24,198 [foster.py] => Exemplar size: 1560
2024-08-02 17:19:24,198 [trainer.py] => CNN: {'total': 67.21, '00-09': 74.9, '10-19': 59.1, '20-29': 74.1, '30-39': 67.0, '40-49': 70.0, '50-59': 57.5, '60-69': 70.5, '70-79': 63.88, 'old': 67.03, 'new': 74.0}
2024-08-02 17:19:24,198 [trainer.py] => NME: {'total': 62.36, '00-09': 66.0, '10-19': 52.8, '20-29': 69.0, '30-39': 60.0, '40-49': 58.1, '50-59': 58.1, '60-69': 73.7, '70-79': 60.88, 'old': 61.63, 'new': 90.0}
2024-08-02 17:19:24,198 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21]
2024-08-02 17:19:24,198 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45]
2024-08-02 17:19:24,199 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36]
2024-08-02 17:19:24,199 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58]

2024-08-02 17:19:24,199 [trainer.py] => CNN top1 平均值: 74.42
2024-08-02 17:19:24,201 [trainer.py] => All params: 1174620
2024-08-02 17:19:24,204 [trainer.py] => Trainable params: 592406
2024-08-02 17:19:24,264 [foster.py] => Learning on 78-80
2024-08-02 17:19:24,268 [foster.py] => All params: 1175138
2024-08-02 17:19:24,270 [foster.py] => Trainable params: 592794
2024-08-02 17:19:24,309 [foster.py] => per cls weights : [1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168 1.01145168
 0.55338453 0.55338453]
2024-08-02 17:19:26,929 [foster.py] => Task 15, Epoch 1/170 => Loss 5.097, Loss_clf 1.049, Loss_fe 1.675, Loss_kd 2.311, Train_accy 68.95
2024-08-02 17:19:31,428 [foster.py] => Task 15, Epoch 2/170 => Loss 3.705, Loss_clf 0.604, Loss_fe 0.713, Loss_kd 2.326, Train_accy 69.53, Test_accy 64.81
2024-08-02 17:19:35,842 [foster.py] => Task 15, Epoch 3/170 => Loss 3.494, Loss_clf 0.526, Loss_fe 0.591, Loss_kd 2.316, Train_accy 66.37, Test_accy 65.46
2024-08-02 17:19:40,272 [foster.py] => Task 15, Epoch 4/170 => Loss 3.353, Loss_clf 0.489, Loss_fe 0.505, Loss_kd 2.298, Train_accy 69.69, Test_accy 64.85
2024-08-02 17:19:44,678 [foster.py] => Task 15, Epoch 5/170 => Loss 3.393, Loss_clf 0.521, Loss_fe 0.480, Loss_kd 2.330, Train_accy 68.67, Test_accy 64.64
2024-08-02 17:19:47,238 [foster.py] => Task 15, Epoch 6/170 => Loss 3.318, Loss_clf 0.489, Loss_fe 0.471, Loss_kd 2.297, Train_accy 69.88
2024-08-02 17:19:51,629 [foster.py] => Task 15, Epoch 7/170 => Loss 3.253, Loss_clf 0.456, Loss_fe 0.447, Loss_kd 2.289, Train_accy 69.69, Test_accy 65.12
2024-08-02 17:19:56,028 [foster.py] => Task 15, Epoch 8/170 => Loss 3.270, Loss_clf 0.472, Loss_fe 0.429, Loss_kd 2.309, Train_accy 69.73, Test_accy 65.18
2024-08-02 17:20:00,430 [foster.py] => Task 15, Epoch 9/170 => Loss 3.239, Loss_clf 0.467, Loss_fe 0.405, Loss_kd 2.307, Train_accy 72.23, Test_accy 65.01
2024-08-02 17:20:04,919 [foster.py] => Task 15, Epoch 10/170 => Loss 3.200, Loss_clf 0.452, Loss_fe 0.378, Loss_kd 2.309, Train_accy 71.80, Test_accy 65.29
2024-08-02 17:20:07,539 [foster.py] => Task 15, Epoch 11/170 => Loss 3.190, Loss_clf 0.445, Loss_fe 0.384, Loss_kd 2.300, Train_accy 73.75
2024-08-02 17:20:11,982 [foster.py] => Task 15, Epoch 12/170 => Loss 3.178, Loss_clf 0.450, Loss_fe 0.370, Loss_kd 2.298, Train_accy 71.68, Test_accy 65.42
2024-08-02 17:20:16,371 [foster.py] => Task 15, Epoch 13/170 => Loss 3.169, Loss_clf 0.431, Loss_fe 0.374, Loss_kd 2.303, Train_accy 73.05, Test_accy 65.39
2024-08-02 17:20:20,773 [foster.py] => Task 15, Epoch 14/170 => Loss 3.140, Loss_clf 0.427, Loss_fe 0.362, Loss_kd 2.291, Train_accy 74.02, Test_accy 65.40
2024-08-02 17:20:25,250 [foster.py] => Task 15, Epoch 15/170 => Loss 3.133, Loss_clf 0.426, Loss_fe 0.352, Loss_kd 2.294, Train_accy 73.01, Test_accy 65.32
2024-08-02 17:20:27,849 [foster.py] => Task 15, Epoch 16/170 => Loss 3.100, Loss_clf 0.403, Loss_fe 0.360, Loss_kd 2.277, Train_accy 73.40
2024-08-02 17:20:32,268 [foster.py] => Task 15, Epoch 17/170 => Loss 3.177, Loss_clf 0.458, Loss_fe 0.350, Loss_kd 2.308, Train_accy 73.63, Test_accy 65.32
2024-08-02 17:20:36,704 [foster.py] => Task 15, Epoch 18/170 => Loss 3.086, Loss_clf 0.411, Loss_fe 0.343, Loss_kd 2.272, Train_accy 74.96, Test_accy 65.39
2024-08-02 17:20:41,149 [foster.py] => Task 15, Epoch 19/170 => Loss 3.085, Loss_clf 0.407, Loss_fe 0.325, Loss_kd 2.293, Train_accy 74.84, Test_accy 65.69
2024-08-02 17:20:45,590 [foster.py] => Task 15, Epoch 20/170 => Loss 3.095, Loss_clf 0.427, Loss_fe 0.308, Loss_kd 2.299, Train_accy 75.12, Test_accy 65.51
2024-08-02 17:20:48,190 [foster.py] => Task 15, Epoch 21/170 => Loss 3.093, Loss_clf 0.422, Loss_fe 0.327, Loss_kd 2.283, Train_accy 73.71
2024-08-02 17:20:52,613 [foster.py] => Task 15, Epoch 22/170 => Loss 3.117, Loss_clf 0.444, Loss_fe 0.307, Loss_kd 2.305, Train_accy 75.20, Test_accy 65.70
2024-08-02 17:20:57,052 [foster.py] => Task 15, Epoch 23/170 => Loss 3.104, Loss_clf 0.432, Loss_fe 0.319, Loss_kd 2.293, Train_accy 75.43, Test_accy 65.46
2024-08-02 17:21:01,529 [foster.py] => Task 15, Epoch 24/170 => Loss 3.071, Loss_clf 0.412, Loss_fe 0.325, Loss_kd 2.274, Train_accy 75.82, Test_accy 65.32
2024-08-02 17:21:05,928 [foster.py] => Task 15, Epoch 25/170 => Loss 3.100, Loss_clf 0.423, Loss_fe 0.319, Loss_kd 2.297, Train_accy 74.49, Test_accy 65.71
2024-08-02 17:21:08,492 [foster.py] => Task 15, Epoch 26/170 => Loss 3.091, Loss_clf 0.406, Loss_fe 0.316, Loss_kd 2.308, Train_accy 76.02
2024-08-02 17:21:12,901 [foster.py] => Task 15, Epoch 27/170 => Loss 3.026, Loss_clf 0.383, Loss_fe 0.286, Loss_kd 2.297, Train_accy 78.79, Test_accy 65.34
2024-08-02 17:21:17,307 [foster.py] => Task 15, Epoch 28/170 => Loss 3.082, Loss_clf 0.408, Loss_fe 0.309, Loss_kd 2.303, Train_accy 76.48, Test_accy 65.31
2024-08-02 17:21:21,726 [foster.py] => Task 15, Epoch 29/170 => Loss 3.086, Loss_clf 0.427, Loss_fe 0.287, Loss_kd 2.312, Train_accy 76.37, Test_accy 65.10
2024-08-02 17:21:26,117 [foster.py] => Task 15, Epoch 30/170 => Loss 3.009, Loss_clf 0.382, Loss_fe 0.295, Loss_kd 2.273, Train_accy 77.66, Test_accy 65.76
2024-08-02 17:21:28,768 [foster.py] => Task 15, Epoch 31/170 => Loss 3.052, Loss_clf 0.389, Loss_fe 0.291, Loss_kd 2.312, Train_accy 77.70
2024-08-02 17:21:33,175 [foster.py] => Task 15, Epoch 32/170 => Loss 3.018, Loss_clf 0.384, Loss_fe 0.269, Loss_kd 2.304, Train_accy 78.28, Test_accy 65.68
2024-08-02 17:21:37,672 [foster.py] => Task 15, Epoch 33/170 => Loss 3.086, Loss_clf 0.425, Loss_fe 0.302, Loss_kd 2.298, Train_accy 75.90, Test_accy 65.41
2024-08-02 17:21:42,105 [foster.py] => Task 15, Epoch 34/170 => Loss 3.069, Loss_clf 0.395, Loss_fe 0.298, Loss_kd 2.315, Train_accy 78.05, Test_accy 65.70
2024-08-02 17:21:46,588 [foster.py] => Task 15, Epoch 35/170 => Loss 2.988, Loss_clf 0.374, Loss_fe 0.281, Loss_kd 2.272, Train_accy 78.63, Test_accy 65.45
2024-08-02 17:21:49,245 [foster.py] => Task 15, Epoch 36/170 => Loss 3.011, Loss_clf 0.378, Loss_fe 0.283, Loss_kd 2.289, Train_accy 78.59
2024-08-02 17:21:53,676 [foster.py] => Task 15, Epoch 37/170 => Loss 3.016, Loss_clf 0.378, Loss_fe 0.258, Loss_kd 2.318, Train_accy 76.56, Test_accy 65.61
2024-08-02 17:21:58,104 [foster.py] => Task 15, Epoch 38/170 => Loss 2.999, Loss_clf 0.390, Loss_fe 0.251, Loss_kd 2.297, Train_accy 77.93, Test_accy 65.53
2024-08-02 17:22:02,550 [foster.py] => Task 15, Epoch 39/170 => Loss 3.020, Loss_clf 0.394, Loss_fe 0.251, Loss_kd 2.313, Train_accy 77.70, Test_accy 65.97
2024-08-02 17:22:06,995 [foster.py] => Task 15, Epoch 40/170 => Loss 3.074, Loss_clf 0.421, Loss_fe 0.259, Loss_kd 2.332, Train_accy 76.99, Test_accy 65.34
2024-08-02 17:22:09,560 [foster.py] => Task 15, Epoch 41/170 => Loss 3.090, Loss_clf 0.425, Loss_fe 0.263, Loss_kd 2.340, Train_accy 77.27
2024-08-02 17:22:13,993 [foster.py] => Task 15, Epoch 42/170 => Loss 2.958, Loss_clf 0.355, Loss_fe 0.255, Loss_kd 2.287, Train_accy 78.12, Test_accy 65.90
2024-08-02 17:22:18,448 [foster.py] => Task 15, Epoch 43/170 => Loss 3.032, Loss_clf 0.414, Loss_fe 0.262, Loss_kd 2.296, Train_accy 77.73, Test_accy 65.76
2024-08-02 17:22:22,899 [foster.py] => Task 15, Epoch 44/170 => Loss 3.003, Loss_clf 0.375, Loss_fe 0.239, Loss_kd 2.327, Train_accy 80.51, Test_accy 65.78
2024-08-02 17:22:27,377 [foster.py] => Task 15, Epoch 45/170 => Loss 3.028, Loss_clf 0.397, Loss_fe 0.255, Loss_kd 2.315, Train_accy 79.14, Test_accy 65.40
2024-08-02 17:22:29,956 [foster.py] => Task 15, Epoch 46/170 => Loss 3.012, Loss_clf 0.401, Loss_fe 0.250, Loss_kd 2.300, Train_accy 77.85
2024-08-02 17:22:34,358 [foster.py] => Task 15, Epoch 47/170 => Loss 2.980, Loss_clf 0.376, Loss_fe 0.255, Loss_kd 2.288, Train_accy 78.71, Test_accy 65.60
2024-08-02 17:22:38,797 [foster.py] => Task 15, Epoch 48/170 => Loss 3.018, Loss_clf 0.393, Loss_fe 0.251, Loss_kd 2.313, Train_accy 78.87, Test_accy 65.82
2024-08-02 17:22:43,223 [foster.py] => Task 15, Epoch 49/170 => Loss 2.946, Loss_clf 0.367, Loss_fe 0.214, Loss_kd 2.304, Train_accy 78.71, Test_accy 65.90
2024-08-02 17:22:47,623 [foster.py] => Task 15, Epoch 50/170 => Loss 2.982, Loss_clf 0.369, Loss_fe 0.262, Loss_kd 2.290, Train_accy 79.30, Test_accy 65.85
2024-08-02 17:22:50,189 [foster.py] => Task 15, Epoch 51/170 => Loss 2.958, Loss_clf 0.366, Loss_fe 0.245, Loss_kd 2.287, Train_accy 79.02
2024-08-02 17:22:54,721 [foster.py] => Task 15, Epoch 52/170 => Loss 2.919, Loss_clf 0.356, Loss_fe 0.218, Loss_kd 2.286, Train_accy 78.71, Test_accy 65.65
2024-08-02 17:22:59,173 [foster.py] => Task 15, Epoch 53/170 => Loss 2.988, Loss_clf 0.383, Loss_fe 0.236, Loss_kd 2.308, Train_accy 77.66, Test_accy 65.29
2024-08-02 17:23:03,580 [foster.py] => Task 15, Epoch 54/170 => Loss 2.933, Loss_clf 0.370, Loss_fe 0.224, Loss_kd 2.279, Train_accy 79.34, Test_accy 65.71
2024-08-02 17:23:08,032 [foster.py] => Task 15, Epoch 55/170 => Loss 2.952, Loss_clf 0.361, Loss_fe 0.238, Loss_kd 2.293, Train_accy 80.59, Test_accy 65.76
2024-08-02 17:23:10,592 [foster.py] => Task 15, Epoch 56/170 => Loss 2.971, Loss_clf 0.376, Loss_fe 0.219, Loss_kd 2.315, Train_accy 78.95
2024-08-02 17:23:15,020 [foster.py] => Task 15, Epoch 57/170 => Loss 2.916, Loss_clf 0.363, Loss_fe 0.192, Loss_kd 2.300, Train_accy 80.74, Test_accy 66.00
2024-08-02 17:23:19,506 [foster.py] => Task 15, Epoch 58/170 => Loss 2.937, Loss_clf 0.356, Loss_fe 0.197, Loss_kd 2.322, Train_accy 81.09, Test_accy 65.78
2024-08-02 17:23:23,928 [foster.py] => Task 15, Epoch 59/170 => Loss 2.960, Loss_clf 0.370, Loss_fe 0.218, Loss_kd 2.312, Train_accy 79.22, Test_accy 65.49
2024-08-02 17:23:28,384 [foster.py] => Task 15, Epoch 60/170 => Loss 2.943, Loss_clf 0.364, Loss_fe 0.221, Loss_kd 2.298, Train_accy 80.27, Test_accy 65.71
2024-08-02 17:23:30,959 [foster.py] => Task 15, Epoch 61/170 => Loss 2.906, Loss_clf 0.349, Loss_fe 0.212, Loss_kd 2.284, Train_accy 80.55
2024-08-02 17:23:35,393 [foster.py] => Task 15, Epoch 62/170 => Loss 2.843, Loss_clf 0.317, Loss_fe 0.181, Loss_kd 2.285, Train_accy 82.11, Test_accy 65.74
2024-08-02 17:23:39,793 [foster.py] => Task 15, Epoch 63/170 => Loss 2.942, Loss_clf 0.370, Loss_fe 0.204, Loss_kd 2.308, Train_accy 80.27, Test_accy 65.71
2024-08-02 17:23:44,232 [foster.py] => Task 15, Epoch 64/170 => Loss 2.894, Loss_clf 0.350, Loss_fe 0.194, Loss_kd 2.289, Train_accy 80.90, Test_accy 65.80
2024-08-02 17:23:48,647 [foster.py] => Task 15, Epoch 65/170 => Loss 2.994, Loss_clf 0.400, Loss_fe 0.224, Loss_kd 2.309, Train_accy 78.48, Test_accy 65.68
2024-08-02 17:23:51,356 [foster.py] => Task 15, Epoch 66/170 => Loss 2.972, Loss_clf 0.381, Loss_fe 0.218, Loss_kd 2.312, Train_accy 79.30
2024-08-02 17:23:55,850 [foster.py] => Task 15, Epoch 67/170 => Loss 2.927, Loss_clf 0.355, Loss_fe 0.188, Loss_kd 2.323, Train_accy 80.98, Test_accy 65.74
2024-08-02 17:24:00,320 [foster.py] => Task 15, Epoch 68/170 => Loss 2.918, Loss_clf 0.354, Loss_fe 0.214, Loss_kd 2.289, Train_accy 80.78, Test_accy 66.11
2024-08-02 17:24:04,753 [foster.py] => Task 15, Epoch 69/170 => Loss 2.976, Loss_clf 0.379, Loss_fe 0.218, Loss_kd 2.318, Train_accy 80.43, Test_accy 65.70
2024-08-02 17:24:09,179 [foster.py] => Task 15, Epoch 70/170 => Loss 2.997, Loss_clf 0.388, Loss_fe 0.213, Loss_kd 2.334, Train_accy 79.57, Test_accy 65.78
2024-08-02 17:24:11,770 [foster.py] => Task 15, Epoch 71/170 => Loss 2.888, Loss_clf 0.364, Loss_fe 0.192, Loss_kd 2.271, Train_accy 78.95
2024-08-02 17:24:16,176 [foster.py] => Task 15, Epoch 72/170 => Loss 2.849, Loss_clf 0.322, Loss_fe 0.194, Loss_kd 2.273, Train_accy 81.99, Test_accy 66.26
2024-08-02 17:24:20,686 [foster.py] => Task 15, Epoch 73/170 => Loss 2.817, Loss_clf 0.324, Loss_fe 0.172, Loss_kd 2.261, Train_accy 80.55, Test_accy 66.25
2024-08-02 17:24:25,108 [foster.py] => Task 15, Epoch 74/170 => Loss 2.918, Loss_clf 0.360, Loss_fe 0.188, Loss_kd 2.309, Train_accy 82.54, Test_accy 66.06
2024-08-02 17:24:29,539 [foster.py] => Task 15, Epoch 75/170 => Loss 2.892, Loss_clf 0.352, Loss_fe 0.184, Loss_kd 2.296, Train_accy 82.77, Test_accy 65.90
2024-08-02 17:24:32,116 [foster.py] => Task 15, Epoch 76/170 => Loss 2.878, Loss_clf 0.346, Loss_fe 0.176, Loss_kd 2.296, Train_accy 79.73
2024-08-02 17:24:36,536 [foster.py] => Task 15, Epoch 77/170 => Loss 2.877, Loss_clf 0.355, Loss_fe 0.179, Loss_kd 2.283, Train_accy 81.64, Test_accy 65.82
2024-08-02 17:24:40,915 [foster.py] => Task 15, Epoch 78/170 => Loss 2.913, Loss_clf 0.362, Loss_fe 0.180, Loss_kd 2.310, Train_accy 79.92, Test_accy 66.08
2024-08-02 17:24:45,334 [foster.py] => Task 15, Epoch 79/170 => Loss 2.859, Loss_clf 0.339, Loss_fe 0.186, Loss_kd 2.275, Train_accy 81.95, Test_accy 65.91
2024-08-02 17:24:49,787 [foster.py] => Task 15, Epoch 80/170 => Loss 2.831, Loss_clf 0.324, Loss_fe 0.177, Loss_kd 2.271, Train_accy 80.94, Test_accy 65.92
2024-08-02 17:24:52,373 [foster.py] => Task 15, Epoch 81/170 => Loss 2.921, Loss_clf 0.362, Loss_fe 0.171, Loss_kd 2.327, Train_accy 82.23
2024-08-02 17:24:56,796 [foster.py] => Task 15, Epoch 82/170 => Loss 2.858, Loss_clf 0.340, Loss_fe 0.177, Loss_kd 2.281, Train_accy 81.95, Test_accy 65.92
2024-08-02 17:25:01,227 [foster.py] => Task 15, Epoch 83/170 => Loss 2.920, Loss_clf 0.350, Loss_fe 0.177, Loss_kd 2.332, Train_accy 80.35, Test_accy 66.30
2024-08-02 17:25:05,612 [foster.py] => Task 15, Epoch 84/170 => Loss 2.814, Loss_clf 0.325, Loss_fe 0.159, Loss_kd 2.269, Train_accy 81.91, Test_accy 66.12
2024-08-02 17:25:10,015 [foster.py] => Task 15, Epoch 85/170 => Loss 2.843, Loss_clf 0.330, Loss_fe 0.156, Loss_kd 2.297, Train_accy 83.20, Test_accy 66.01
2024-08-02 17:25:12,598 [foster.py] => Task 15, Epoch 86/170 => Loss 2.885, Loss_clf 0.340, Loss_fe 0.180, Loss_kd 2.304, Train_accy 82.77
2024-08-02 17:25:17,001 [foster.py] => Task 15, Epoch 87/170 => Loss 2.881, Loss_clf 0.346, Loss_fe 0.166, Loss_kd 2.309, Train_accy 81.84, Test_accy 66.09
2024-08-02 17:25:21,510 [foster.py] => Task 15, Epoch 88/170 => Loss 2.894, Loss_clf 0.368, Loss_fe 0.179, Loss_kd 2.287, Train_accy 81.52, Test_accy 66.18
2024-08-02 17:25:25,997 [foster.py] => Task 15, Epoch 89/170 => Loss 2.864, Loss_clf 0.341, Loss_fe 0.169, Loss_kd 2.293, Train_accy 84.84, Test_accy 66.14
2024-08-02 17:25:30,433 [foster.py] => Task 15, Epoch 90/170 => Loss 2.881, Loss_clf 0.351, Loss_fe 0.161, Loss_kd 2.309, Train_accy 79.69, Test_accy 66.38
2024-08-02 17:25:33,051 [foster.py] => Task 15, Epoch 91/170 => Loss 2.863, Loss_clf 0.333, Loss_fe 0.178, Loss_kd 2.292, Train_accy 83.79
2024-08-02 17:25:37,449 [foster.py] => Task 15, Epoch 92/170 => Loss 2.879, Loss_clf 0.349, Loss_fe 0.168, Loss_kd 2.302, Train_accy 82.07, Test_accy 66.16
2024-08-02 17:25:41,902 [foster.py] => Task 15, Epoch 93/170 => Loss 2.910, Loss_clf 0.364, Loss_fe 0.164, Loss_kd 2.320, Train_accy 82.70, Test_accy 66.06
2024-08-02 17:25:46,322 [foster.py] => Task 15, Epoch 94/170 => Loss 2.835, Loss_clf 0.321, Loss_fe 0.157, Loss_kd 2.297, Train_accy 81.68, Test_accy 66.14
2024-08-02 17:25:50,767 [foster.py] => Task 15, Epoch 95/170 => Loss 2.832, Loss_clf 0.333, Loss_fe 0.152, Loss_kd 2.287, Train_accy 81.05, Test_accy 66.32
2024-08-02 17:25:53,379 [foster.py] => Task 15, Epoch 96/170 => Loss 2.830, Loss_clf 0.334, Loss_fe 0.141, Loss_kd 2.295, Train_accy 82.34
2024-08-02 17:25:57,763 [foster.py] => Task 15, Epoch 97/170 => Loss 2.884, Loss_clf 0.352, Loss_fe 0.164, Loss_kd 2.307, Train_accy 81.88, Test_accy 65.95
2024-08-02 17:26:02,195 [foster.py] => Task 15, Epoch 98/170 => Loss 2.872, Loss_clf 0.344, Loss_fe 0.152, Loss_kd 2.316, Train_accy 82.38, Test_accy 66.24
2024-08-02 17:26:06,645 [foster.py] => Task 15, Epoch 99/170 => Loss 2.873, Loss_clf 0.342, Loss_fe 0.168, Loss_kd 2.302, Train_accy 84.14, Test_accy 66.26
2024-08-02 17:26:11,080 [foster.py] => Task 15, Epoch 100/170 => Loss 2.834, Loss_clf 0.328, Loss_fe 0.154, Loss_kd 2.292, Train_accy 82.62, Test_accy 66.28
2024-08-02 17:26:13,670 [foster.py] => Task 15, Epoch 101/170 => Loss 2.836, Loss_clf 0.331, Loss_fe 0.149, Loss_kd 2.296, Train_accy 82.27
2024-08-02 17:26:18,125 [foster.py] => Task 15, Epoch 102/170 => Loss 2.838, Loss_clf 0.319, Loss_fe 0.148, Loss_kd 2.310, Train_accy 83.95, Test_accy 65.94
2024-08-02 17:26:22,560 [foster.py] => Task 15, Epoch 103/170 => Loss 2.821, Loss_clf 0.312, Loss_fe 0.145, Loss_kd 2.303, Train_accy 83.01, Test_accy 66.08
2024-08-02 17:26:26,988 [foster.py] => Task 15, Epoch 104/170 => Loss 2.805, Loss_clf 0.311, Loss_fe 0.139, Loss_kd 2.294, Train_accy 83.24, Test_accy 66.18
2024-08-02 17:26:31,397 [foster.py] => Task 15, Epoch 105/170 => Loss 2.854, Loss_clf 0.331, Loss_fe 0.146, Loss_kd 2.315, Train_accy 83.59, Test_accy 66.10
2024-08-02 17:26:33,975 [foster.py] => Task 15, Epoch 106/170 => Loss 2.781, Loss_clf 0.320, Loss_fe 0.124, Loss_kd 2.277, Train_accy 83.32
2024-08-02 17:26:38,424 [foster.py] => Task 15, Epoch 107/170 => Loss 2.776, Loss_clf 0.285, Loss_fe 0.120, Loss_kd 2.311, Train_accy 83.79, Test_accy 66.31
2024-08-02 17:26:42,879 [foster.py] => Task 15, Epoch 108/170 => Loss 2.787, Loss_clf 0.302, Loss_fe 0.152, Loss_kd 2.274, Train_accy 85.04, Test_accy 66.28
2024-08-02 17:26:47,313 [foster.py] => Task 15, Epoch 109/170 => Loss 2.799, Loss_clf 0.305, Loss_fe 0.127, Loss_kd 2.306, Train_accy 85.23, Test_accy 66.31
2024-08-02 17:26:51,731 [foster.py] => Task 15, Epoch 110/170 => Loss 2.777, Loss_clf 0.310, Loss_fe 0.125, Loss_kd 2.281, Train_accy 84.02, Test_accy 66.38
2024-08-02 17:26:54,302 [foster.py] => Task 15, Epoch 111/170 => Loss 2.702, Loss_clf 0.271, Loss_fe 0.119, Loss_kd 2.253, Train_accy 86.29
2024-08-02 17:26:58,740 [foster.py] => Task 15, Epoch 112/170 => Loss 2.824, Loss_clf 0.314, Loss_fe 0.121, Loss_kd 2.328, Train_accy 85.20, Test_accy 66.29
2024-08-02 17:27:03,216 [foster.py] => Task 15, Epoch 113/170 => Loss 2.799, Loss_clf 0.317, Loss_fe 0.129, Loss_kd 2.294, Train_accy 84.38, Test_accy 66.35
2024-08-02 17:27:07,752 [foster.py] => Task 15, Epoch 114/170 => Loss 2.816, Loss_clf 0.318, Loss_fe 0.130, Loss_kd 2.307, Train_accy 84.14, Test_accy 66.21
2024-08-02 17:27:12,165 [foster.py] => Task 15, Epoch 115/170 => Loss 2.814, Loss_clf 0.316, Loss_fe 0.127, Loss_kd 2.310, Train_accy 83.95, Test_accy 66.15
2024-08-02 17:27:14,763 [foster.py] => Task 15, Epoch 116/170 => Loss 2.829, Loss_clf 0.313, Loss_fe 0.119, Loss_kd 2.335, Train_accy 85.27
2024-08-02 17:27:19,142 [foster.py] => Task 15, Epoch 117/170 => Loss 2.832, Loss_clf 0.317, Loss_fe 0.133, Loss_kd 2.321, Train_accy 85.12, Test_accy 66.22
2024-08-02 17:27:23,676 [foster.py] => Task 15, Epoch 118/170 => Loss 2.789, Loss_clf 0.303, Loss_fe 0.122, Loss_kd 2.303, Train_accy 84.34, Test_accy 66.30
2024-08-02 17:27:28,136 [foster.py] => Task 15, Epoch 119/170 => Loss 2.792, Loss_clf 0.311, Loss_fe 0.114, Loss_kd 2.307, Train_accy 85.20, Test_accy 66.38
2024-08-02 17:27:32,562 [foster.py] => Task 15, Epoch 120/170 => Loss 2.754, Loss_clf 0.296, Loss_fe 0.118, Loss_kd 2.280, Train_accy 85.20, Test_accy 66.26
2024-08-02 17:27:35,126 [foster.py] => Task 15, Epoch 121/170 => Loss 2.784, Loss_clf 0.295, Loss_fe 0.113, Loss_kd 2.315, Train_accy 85.12
2024-08-02 17:27:39,550 [foster.py] => Task 15, Epoch 122/170 => Loss 2.774, Loss_clf 0.305, Loss_fe 0.113, Loss_kd 2.295, Train_accy 85.74, Test_accy 66.42
2024-08-02 17:27:43,945 [foster.py] => Task 15, Epoch 123/170 => Loss 2.736, Loss_clf 0.287, Loss_fe 0.101, Loss_kd 2.288, Train_accy 85.82, Test_accy 66.36
2024-08-02 17:27:48,344 [foster.py] => Task 15, Epoch 124/170 => Loss 2.782, Loss_clf 0.304, Loss_fe 0.117, Loss_kd 2.299, Train_accy 85.16, Test_accy 66.39
2024-08-02 17:27:52,763 [foster.py] => Task 15, Epoch 125/170 => Loss 2.805, Loss_clf 0.321, Loss_fe 0.118, Loss_kd 2.305, Train_accy 85.31, Test_accy 66.47
2024-08-02 17:27:55,348 [foster.py] => Task 15, Epoch 126/170 => Loss 2.795, Loss_clf 0.320, Loss_fe 0.122, Loss_kd 2.292, Train_accy 84.14
2024-08-02 17:27:59,758 [foster.py] => Task 15, Epoch 127/170 => Loss 2.834, Loss_clf 0.327, Loss_fe 0.116, Loss_kd 2.330, Train_accy 84.65, Test_accy 66.32
2024-08-02 17:28:04,168 [foster.py] => Task 15, Epoch 128/170 => Loss 2.794, Loss_clf 0.312, Loss_fe 0.102, Loss_kd 2.319, Train_accy 85.12, Test_accy 66.26
2024-08-02 17:28:08,581 [foster.py] => Task 15, Epoch 129/170 => Loss 2.786, Loss_clf 0.315, Loss_fe 0.104, Loss_kd 2.306, Train_accy 84.53, Test_accy 66.34
2024-08-02 17:28:13,036 [foster.py] => Task 15, Epoch 130/170 => Loss 2.776, Loss_clf 0.301, Loss_fe 0.106, Loss_kd 2.308, Train_accy 85.55, Test_accy 66.42
2024-08-02 17:28:15,598 [foster.py] => Task 15, Epoch 131/170 => Loss 2.755, Loss_clf 0.300, Loss_fe 0.103, Loss_kd 2.292, Train_accy 85.12
2024-08-02 17:28:20,027 [foster.py] => Task 15, Epoch 132/170 => Loss 2.810, Loss_clf 0.327, Loss_fe 0.106, Loss_kd 2.317, Train_accy 85.51, Test_accy 66.34
2024-08-02 17:28:24,537 [foster.py] => Task 15, Epoch 133/170 => Loss 2.777, Loss_clf 0.305, Loss_fe 0.108, Loss_kd 2.303, Train_accy 85.31, Test_accy 66.28
2024-08-02 17:28:28,965 [foster.py] => Task 15, Epoch 134/170 => Loss 2.800, Loss_clf 0.309, Loss_fe 0.121, Loss_kd 2.309, Train_accy 85.12, Test_accy 66.14
2024-08-02 17:28:33,398 [foster.py] => Task 15, Epoch 135/170 => Loss 2.763, Loss_clf 0.298, Loss_fe 0.110, Loss_kd 2.294, Train_accy 86.33, Test_accy 66.30
2024-08-02 17:28:35,984 [foster.py] => Task 15, Epoch 136/170 => Loss 2.744, Loss_clf 0.291, Loss_fe 0.105, Loss_kd 2.287, Train_accy 85.78
2024-08-02 17:28:40,430 [foster.py] => Task 15, Epoch 137/170 => Loss 2.798, Loss_clf 0.309, Loss_fe 0.105, Loss_kd 2.324, Train_accy 85.55, Test_accy 66.45
2024-08-02 17:28:44,845 [foster.py] => Task 15, Epoch 138/170 => Loss 2.757, Loss_clf 0.303, Loss_fe 0.115, Loss_kd 2.279, Train_accy 85.51, Test_accy 66.31
2024-08-02 17:28:49,288 [foster.py] => Task 15, Epoch 139/170 => Loss 2.744, Loss_clf 0.295, Loss_fe 0.098, Loss_kd 2.291, Train_accy 85.74, Test_accy 66.36
2024-08-02 17:28:53,699 [foster.py] => Task 15, Epoch 140/170 => Loss 2.799, Loss_clf 0.308, Loss_fe 0.098, Loss_kd 2.331, Train_accy 85.27, Test_accy 66.29
2024-08-02 17:28:56,284 [foster.py] => Task 15, Epoch 141/170 => Loss 2.703, Loss_clf 0.272, Loss_fe 0.097, Loss_kd 2.274, Train_accy 85.66
2024-08-02 17:29:00,703 [foster.py] => Task 15, Epoch 142/170 => Loss 2.734, Loss_clf 0.282, Loss_fe 0.095, Loss_kd 2.297, Train_accy 86.29, Test_accy 66.25
2024-08-02 17:29:05,095 [foster.py] => Task 15, Epoch 143/170 => Loss 2.743, Loss_clf 0.287, Loss_fe 0.106, Loss_kd 2.290, Train_accy 86.41, Test_accy 66.38
2024-08-02 17:29:09,521 [foster.py] => Task 15, Epoch 144/170 => Loss 2.712, Loss_clf 0.284, Loss_fe 0.088, Loss_kd 2.281, Train_accy 85.43, Test_accy 66.26
2024-08-02 17:29:13,965 [foster.py] => Task 15, Epoch 145/170 => Loss 2.748, Loss_clf 0.296, Loss_fe 0.081, Loss_kd 2.310, Train_accy 85.78, Test_accy 66.31
2024-08-02 17:29:16,569 [foster.py] => Task 15, Epoch 146/170 => Loss 2.773, Loss_clf 0.305, Loss_fe 0.104, Loss_kd 2.303, Train_accy 85.66
2024-08-02 17:29:20,990 [foster.py] => Task 15, Epoch 147/170 => Loss 2.787, Loss_clf 0.312, Loss_fe 0.094, Loss_kd 2.320, Train_accy 85.62, Test_accy 66.30
2024-08-02 17:29:25,417 [foster.py] => Task 15, Epoch 148/170 => Loss 2.776, Loss_clf 0.304, Loss_fe 0.096, Loss_kd 2.315, Train_accy 85.70, Test_accy 66.24
2024-08-02 17:29:29,814 [foster.py] => Task 15, Epoch 149/170 => Loss 2.744, Loss_clf 0.306, Loss_fe 0.097, Loss_kd 2.281, Train_accy 85.51, Test_accy 66.28
2024-08-02 17:29:34,261 [foster.py] => Task 15, Epoch 150/170 => Loss 2.706, Loss_clf 0.277, Loss_fe 0.093, Loss_kd 2.276, Train_accy 87.03, Test_accy 66.29
2024-08-02 17:29:36,848 [foster.py] => Task 15, Epoch 151/170 => Loss 2.750, Loss_clf 0.292, Loss_fe 0.088, Loss_kd 2.309, Train_accy 86.02
2024-08-02 17:29:41,254 [foster.py] => Task 15, Epoch 152/170 => Loss 2.760, Loss_clf 0.299, Loss_fe 0.119, Loss_kd 2.281, Train_accy 85.90, Test_accy 66.29
2024-08-02 17:29:45,741 [foster.py] => Task 15, Epoch 153/170 => Loss 2.775, Loss_clf 0.299, Loss_fe 0.096, Loss_kd 2.319, Train_accy 85.78, Test_accy 66.29
2024-08-02 17:29:50,213 [foster.py] => Task 15, Epoch 154/170 => Loss 2.793, Loss_clf 0.323, Loss_fe 0.105, Loss_kd 2.305, Train_accy 85.59, Test_accy 66.31
2024-08-02 17:29:54,628 [foster.py] => Task 15, Epoch 155/170 => Loss 2.733, Loss_clf 0.293, Loss_fe 0.093, Loss_kd 2.288, Train_accy 85.82, Test_accy 66.22
2024-08-02 17:29:57,198 [foster.py] => Task 15, Epoch 156/170 => Loss 2.710, Loss_clf 0.282, Loss_fe 0.089, Loss_kd 2.279, Train_accy 85.94
2024-08-02 17:30:01,634 [foster.py] => Task 15, Epoch 157/170 => Loss 2.712, Loss_clf 0.278, Loss_fe 0.086, Loss_kd 2.287, Train_accy 85.55, Test_accy 66.31
2024-08-02 17:30:06,025 [foster.py] => Task 15, Epoch 158/170 => Loss 2.775, Loss_clf 0.293, Loss_fe 0.099, Loss_kd 2.323, Train_accy 86.41, Test_accy 66.31
2024-08-02 17:30:10,457 [foster.py] => Task 15, Epoch 159/170 => Loss 2.748, Loss_clf 0.301, Loss_fe 0.112, Loss_kd 2.275, Train_accy 85.31, Test_accy 66.30
2024-08-02 17:30:14,870 [foster.py] => Task 15, Epoch 160/170 => Loss 2.721, Loss_clf 0.280, Loss_fe 0.101, Loss_kd 2.280, Train_accy 87.15, Test_accy 66.35
2024-08-02 17:30:17,425 [foster.py] => Task 15, Epoch 161/170 => Loss 2.732, Loss_clf 0.284, Loss_fe 0.091, Loss_kd 2.297, Train_accy 85.78
2024-08-02 17:30:21,863 [foster.py] => Task 15, Epoch 162/170 => Loss 2.732, Loss_clf 0.286, Loss_fe 0.109, Loss_kd 2.277, Train_accy 86.99, Test_accy 66.36
2024-08-02 17:30:26,283 [foster.py] => Task 15, Epoch 163/170 => Loss 2.767, Loss_clf 0.291, Loss_fe 0.098, Loss_kd 2.317, Train_accy 86.56, Test_accy 66.34
2024-08-02 17:30:30,720 [foster.py] => Task 15, Epoch 164/170 => Loss 2.781, Loss_clf 0.307, Loss_fe 0.100, Loss_kd 2.313, Train_accy 86.25, Test_accy 66.45
2024-08-02 17:30:35,121 [foster.py] => Task 15, Epoch 165/170 => Loss 2.715, Loss_clf 0.284, Loss_fe 0.079, Loss_kd 2.291, Train_accy 86.25, Test_accy 66.35
2024-08-02 17:30:37,685 [foster.py] => Task 15, Epoch 166/170 => Loss 2.770, Loss_clf 0.297, Loss_fe 0.100, Loss_kd 2.312, Train_accy 86.25
2024-08-02 17:30:42,085 [foster.py] => Task 15, Epoch 167/170 => Loss 2.690, Loss_clf 0.268, Loss_fe 0.077, Loss_kd 2.284, Train_accy 86.88, Test_accy 66.35
2024-08-02 17:30:46,495 [foster.py] => Task 15, Epoch 168/170 => Loss 2.770, Loss_clf 0.308, Loss_fe 0.095, Loss_kd 2.307, Train_accy 86.09, Test_accy 66.35
2024-08-02 17:30:50,923 [foster.py] => Task 15, Epoch 169/170 => Loss 2.753, Loss_clf 0.302, Loss_fe 0.093, Loss_kd 2.297, Train_accy 84.96, Test_accy 66.42
2024-08-02 17:30:55,320 [foster.py] => Task 15, Epoch 170/170 => Loss 2.692, Loss_clf 0.267, Loss_fe 0.094, Loss_kd 2.271, Train_accy 86.80, Test_accy 66.38
2024-08-02 17:30:55,324 [foster.py] => do not weight align teacher!
2024-08-02 17:30:55,326 [foster.py] => per cls weights : [1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057 1.01360057
 0.46957787 0.46957787]
2024-08-02 17:31:00,279 [foster.py] => SNet: Task 15, Epoch 1/130 => Loss 29.741,  Loss1 0.758, Train_accy 55.47, Test_accy 62.74
2024-08-02 17:31:03,844 [foster.py] => SNet: Task 15, Epoch 2/130 => Loss 29.629,  Loss1 0.756, Train_accy 64.77
2024-08-02 17:31:07,431 [foster.py] => SNet: Task 15, Epoch 3/130 => Loss 29.604,  Loss1 0.756, Train_accy 62.62
2024-08-02 17:31:11,005 [foster.py] => SNet: Task 15, Epoch 4/130 => Loss 29.641,  Loss1 0.755, Train_accy 63.59
2024-08-02 17:31:14,578 [foster.py] => SNet: Task 15, Epoch 5/130 => Loss 29.639,  Loss1 0.755, Train_accy 65.20
2024-08-02 17:31:19,328 [foster.py] => SNet: Task 15, Epoch 6/130 => Loss 29.586,  Loss1 0.755, Train_accy 66.09, Test_accy 65.14
2024-08-02 17:31:22,898 [foster.py] => SNet: Task 15, Epoch 7/130 => Loss 29.564,  Loss1 0.755, Train_accy 66.21
2024-08-02 17:31:26,464 [foster.py] => SNet: Task 15, Epoch 8/130 => Loss 29.577,  Loss1 0.755, Train_accy 66.99
2024-08-02 17:31:30,038 [foster.py] => SNet: Task 15, Epoch 9/130 => Loss 29.602,  Loss1 0.754, Train_accy 67.19
2024-08-02 17:31:33,603 [foster.py] => SNet: Task 15, Epoch 10/130 => Loss 29.565,  Loss1 0.755, Train_accy 66.80
2024-08-02 17:31:38,396 [foster.py] => SNet: Task 15, Epoch 11/130 => Loss 29.575,  Loss1 0.754, Train_accy 67.89, Test_accy 65.11
2024-08-02 17:31:41,975 [foster.py] => SNet: Task 15, Epoch 12/130 => Loss 29.602,  Loss1 0.754, Train_accy 68.87
2024-08-02 17:31:45,576 [foster.py] => SNet: Task 15, Epoch 13/130 => Loss 29.580,  Loss1 0.754, Train_accy 67.85
2024-08-02 17:31:49,179 [foster.py] => SNet: Task 15, Epoch 14/130 => Loss 29.588,  Loss1 0.754, Train_accy 68.91
2024-08-02 17:31:52,785 [foster.py] => SNet: Task 15, Epoch 15/130 => Loss 29.630,  Loss1 0.754, Train_accy 69.18
2024-08-02 17:31:57,526 [foster.py] => SNet: Task 15, Epoch 16/130 => Loss 29.568,  Loss1 0.754, Train_accy 67.34, Test_accy 65.21
2024-08-02 17:32:01,176 [foster.py] => SNet: Task 15, Epoch 17/130 => Loss 29.571,  Loss1 0.754, Train_accy 69.14
2024-08-02 17:32:04,795 [foster.py] => SNet: Task 15, Epoch 18/130 => Loss 29.574,  Loss1 0.754, Train_accy 69.41
2024-08-02 17:32:08,382 [foster.py] => SNet: Task 15, Epoch 19/130 => Loss 29.570,  Loss1 0.753, Train_accy 69.77
2024-08-02 17:32:11,941 [foster.py] => SNet: Task 15, Epoch 20/130 => Loss 29.598,  Loss1 0.754, Train_accy 69.26
2024-08-02 17:32:16,669 [foster.py] => SNet: Task 15, Epoch 21/130 => Loss 29.666,  Loss1 0.754, Train_accy 70.43, Test_accy 65.47
2024-08-02 17:32:20,230 [foster.py] => SNet: Task 15, Epoch 22/130 => Loss 29.620,  Loss1 0.754, Train_accy 70.43
2024-08-02 17:32:23,836 [foster.py] => SNet: Task 15, Epoch 23/130 => Loss 29.547,  Loss1 0.755, Train_accy 69.10
2024-08-02 17:32:27,407 [foster.py] => SNet: Task 15, Epoch 24/130 => Loss 29.561,  Loss1 0.754, Train_accy 70.31
2024-08-02 17:32:30,979 [foster.py] => SNet: Task 15, Epoch 25/130 => Loss 29.561,  Loss1 0.753, Train_accy 70.66
2024-08-02 17:32:35,698 [foster.py] => SNet: Task 15, Epoch 26/130 => Loss 29.531,  Loss1 0.754, Train_accy 71.99, Test_accy 65.74
2024-08-02 17:32:39,274 [foster.py] => SNet: Task 15, Epoch 27/130 => Loss 29.594,  Loss1 0.754, Train_accy 70.62
2024-08-02 17:32:42,850 [foster.py] => SNet: Task 15, Epoch 28/130 => Loss 29.558,  Loss1 0.754, Train_accy 69.53
2024-08-02 17:32:46,405 [foster.py] => SNet: Task 15, Epoch 29/130 => Loss 29.596,  Loss1 0.754, Train_accy 71.68
2024-08-02 17:32:50,005 [foster.py] => SNet: Task 15, Epoch 30/130 => Loss 29.570,  Loss1 0.753, Train_accy 71.33
2024-08-02 17:32:54,777 [foster.py] => SNet: Task 15, Epoch 31/130 => Loss 29.572,  Loss1 0.753, Train_accy 70.94, Test_accy 65.49
2024-08-02 17:32:58,354 [foster.py] => SNet: Task 15, Epoch 32/130 => Loss 29.549,  Loss1 0.754, Train_accy 71.56
2024-08-02 17:33:01,920 [foster.py] => SNet: Task 15, Epoch 33/130 => Loss 29.604,  Loss1 0.753, Train_accy 70.78
2024-08-02 17:33:05,508 [foster.py] => SNet: Task 15, Epoch 34/130 => Loss 29.614,  Loss1 0.753, Train_accy 70.47
2024-08-02 17:33:09,122 [foster.py] => SNet: Task 15, Epoch 35/130 => Loss 29.583,  Loss1 0.754, Train_accy 71.99
2024-08-02 17:33:13,852 [foster.py] => SNet: Task 15, Epoch 36/130 => Loss 29.518,  Loss1 0.753, Train_accy 72.38, Test_accy 65.44
2024-08-02 17:33:17,405 [foster.py] => SNet: Task 15, Epoch 37/130 => Loss 29.566,  Loss1 0.754, Train_accy 71.80
2024-08-02 17:33:20,986 [foster.py] => SNet: Task 15, Epoch 38/130 => Loss 29.604,  Loss1 0.753, Train_accy 70.59
2024-08-02 17:33:24,581 [foster.py] => SNet: Task 15, Epoch 39/130 => Loss 29.573,  Loss1 0.753, Train_accy 71.56
2024-08-02 17:33:28,149 [foster.py] => SNet: Task 15, Epoch 40/130 => Loss 29.588,  Loss1 0.754, Train_accy 71.84
2024-08-02 17:33:32,876 [foster.py] => SNet: Task 15, Epoch 41/130 => Loss 29.578,  Loss1 0.753, Train_accy 72.03, Test_accy 65.54
2024-08-02 17:33:36,467 [foster.py] => SNet: Task 15, Epoch 42/130 => Loss 29.568,  Loss1 0.754, Train_accy 70.55
2024-08-02 17:33:40,033 [foster.py] => SNet: Task 15, Epoch 43/130 => Loss 29.575,  Loss1 0.753, Train_accy 70.78
2024-08-02 17:33:43,659 [foster.py] => SNet: Task 15, Epoch 44/130 => Loss 29.619,  Loss1 0.753, Train_accy 70.20
2024-08-02 17:33:47,258 [foster.py] => SNet: Task 15, Epoch 45/130 => Loss 29.618,  Loss1 0.753, Train_accy 72.03
2024-08-02 17:33:51,991 [foster.py] => SNet: Task 15, Epoch 46/130 => Loss 29.562,  Loss1 0.754, Train_accy 71.21, Test_accy 65.66
2024-08-02 17:33:55,563 [foster.py] => SNet: Task 15, Epoch 47/130 => Loss 29.547,  Loss1 0.754, Train_accy 71.91
2024-08-02 17:33:59,139 [foster.py] => SNet: Task 15, Epoch 48/130 => Loss 29.575,  Loss1 0.754, Train_accy 72.30
2024-08-02 17:34:02,725 [foster.py] => SNet: Task 15, Epoch 49/130 => Loss 29.604,  Loss1 0.753, Train_accy 71.60
2024-08-02 17:34:06,305 [foster.py] => SNet: Task 15, Epoch 50/130 => Loss 29.572,  Loss1 0.753, Train_accy 71.21
2024-08-02 17:34:11,060 [foster.py] => SNet: Task 15, Epoch 51/130 => Loss 29.620,  Loss1 0.753, Train_accy 72.38, Test_accy 65.79
2024-08-02 17:34:14,643 [foster.py] => SNet: Task 15, Epoch 52/130 => Loss 29.616,  Loss1 0.753, Train_accy 70.20
2024-08-02 17:34:18,302 [foster.py] => SNet: Task 15, Epoch 53/130 => Loss 29.560,  Loss1 0.754, Train_accy 72.70
2024-08-02 17:34:21,917 [foster.py] => SNet: Task 15, Epoch 54/130 => Loss 29.553,  Loss1 0.754, Train_accy 73.20
2024-08-02 17:34:25,503 [foster.py] => SNet: Task 15, Epoch 55/130 => Loss 29.538,  Loss1 0.754, Train_accy 72.50
2024-08-02 17:34:30,235 [foster.py] => SNet: Task 15, Epoch 56/130 => Loss 29.574,  Loss1 0.753, Train_accy 72.38, Test_accy 65.88
2024-08-02 17:34:33,809 [foster.py] => SNet: Task 15, Epoch 57/130 => Loss 29.576,  Loss1 0.754, Train_accy 71.99
2024-08-02 17:34:37,381 [foster.py] => SNet: Task 15, Epoch 58/130 => Loss 29.572,  Loss1 0.753, Train_accy 72.97
2024-08-02 17:34:40,983 [foster.py] => SNet: Task 15, Epoch 59/130 => Loss 29.594,  Loss1 0.753, Train_accy 72.62
2024-08-02 17:34:44,564 [foster.py] => SNet: Task 15, Epoch 60/130 => Loss 29.605,  Loss1 0.753, Train_accy 71.80
2024-08-02 17:34:49,322 [foster.py] => SNet: Task 15, Epoch 61/130 => Loss 29.586,  Loss1 0.753, Train_accy 72.81, Test_accy 65.81
2024-08-02 17:34:52,928 [foster.py] => SNet: Task 15, Epoch 62/130 => Loss 29.618,  Loss1 0.753, Train_accy 72.81
2024-08-02 17:34:56,505 [foster.py] => SNet: Task 15, Epoch 63/130 => Loss 29.586,  Loss1 0.753, Train_accy 72.97
2024-08-02 17:35:00,108 [foster.py] => SNet: Task 15, Epoch 64/130 => Loss 29.584,  Loss1 0.754, Train_accy 72.81
2024-08-02 17:35:03,705 [foster.py] => SNet: Task 15, Epoch 65/130 => Loss 29.565,  Loss1 0.753, Train_accy 72.89
2024-08-02 17:35:08,464 [foster.py] => SNet: Task 15, Epoch 66/130 => Loss 29.556,  Loss1 0.753, Train_accy 73.05, Test_accy 65.46
2024-08-02 17:35:12,037 [foster.py] => SNet: Task 15, Epoch 67/130 => Loss 29.577,  Loss1 0.754, Train_accy 72.46
2024-08-02 17:35:15,622 [foster.py] => SNet: Task 15, Epoch 68/130 => Loss 29.592,  Loss1 0.753, Train_accy 72.54
2024-08-02 17:35:19,208 [foster.py] => SNet: Task 15, Epoch 69/130 => Loss 29.603,  Loss1 0.753, Train_accy 73.01
2024-08-02 17:35:22,801 [foster.py] => SNet: Task 15, Epoch 70/130 => Loss 29.569,  Loss1 0.753, Train_accy 73.01
2024-08-02 17:35:27,628 [foster.py] => SNet: Task 15, Epoch 71/130 => Loss 29.566,  Loss1 0.753, Train_accy 73.48, Test_accy 65.84
2024-08-02 17:35:31,197 [foster.py] => SNet: Task 15, Epoch 72/130 => Loss 29.554,  Loss1 0.752, Train_accy 72.77
2024-08-02 17:35:34,797 [foster.py] => SNet: Task 15, Epoch 73/130 => Loss 29.596,  Loss1 0.754, Train_accy 71.25
2024-08-02 17:35:38,348 [foster.py] => SNet: Task 15, Epoch 74/130 => Loss 29.496,  Loss1 0.754, Train_accy 71.52
2024-08-02 17:35:41,941 [foster.py] => SNet: Task 15, Epoch 75/130 => Loss 29.573,  Loss1 0.754, Train_accy 73.05
2024-08-02 17:35:46,705 [foster.py] => SNet: Task 15, Epoch 76/130 => Loss 29.549,  Loss1 0.753, Train_accy 73.59, Test_accy 65.70
2024-08-02 17:35:50,271 [foster.py] => SNet: Task 15, Epoch 77/130 => Loss 29.567,  Loss1 0.753, Train_accy 73.95
2024-08-02 17:35:53,858 [foster.py] => SNet: Task 15, Epoch 78/130 => Loss 29.616,  Loss1 0.753, Train_accy 72.11
2024-08-02 17:35:57,448 [foster.py] => SNet: Task 15, Epoch 79/130 => Loss 29.586,  Loss1 0.754, Train_accy 72.34
2024-08-02 17:36:01,038 [foster.py] => SNet: Task 15, Epoch 80/130 => Loss 29.572,  Loss1 0.753, Train_accy 72.85
2024-08-02 17:36:05,828 [foster.py] => SNet: Task 15, Epoch 81/130 => Loss 29.563,  Loss1 0.753, Train_accy 73.59, Test_accy 65.82
2024-08-02 17:36:09,461 [foster.py] => SNet: Task 15, Epoch 82/130 => Loss 29.557,  Loss1 0.753, Train_accy 71.95
2024-08-02 17:36:13,056 [foster.py] => SNet: Task 15, Epoch 83/130 => Loss 29.539,  Loss1 0.753, Train_accy 72.73
2024-08-02 17:36:16,637 [foster.py] => SNet: Task 15, Epoch 84/130 => Loss 29.560,  Loss1 0.753, Train_accy 72.07
2024-08-02 17:36:20,200 [foster.py] => SNet: Task 15, Epoch 85/130 => Loss 29.580,  Loss1 0.753, Train_accy 73.12
2024-08-02 17:36:24,941 [foster.py] => SNet: Task 15, Epoch 86/130 => Loss 29.580,  Loss1 0.753, Train_accy 73.48, Test_accy 65.71
2024-08-02 17:36:28,514 [foster.py] => SNet: Task 15, Epoch 87/130 => Loss 29.593,  Loss1 0.753, Train_accy 73.05
2024-08-02 17:36:32,101 [foster.py] => SNet: Task 15, Epoch 88/130 => Loss 29.551,  Loss1 0.753, Train_accy 73.79
2024-08-02 17:36:35,735 [foster.py] => SNet: Task 15, Epoch 89/130 => Loss 29.559,  Loss1 0.753, Train_accy 72.85
2024-08-02 17:36:39,316 [foster.py] => SNet: Task 15, Epoch 90/130 => Loss 29.582,  Loss1 0.753, Train_accy 72.81
2024-08-02 17:36:44,088 [foster.py] => SNet: Task 15, Epoch 91/130 => Loss 29.585,  Loss1 0.754, Train_accy 73.20, Test_accy 65.71
2024-08-02 17:36:47,666 [foster.py] => SNet: Task 15, Epoch 92/130 => Loss 29.587,  Loss1 0.753, Train_accy 72.58
2024-08-02 17:36:51,271 [foster.py] => SNet: Task 15, Epoch 93/130 => Loss 29.605,  Loss1 0.753, Train_accy 72.42
2024-08-02 17:36:54,880 [foster.py] => SNet: Task 15, Epoch 94/130 => Loss 29.601,  Loss1 0.754, Train_accy 73.05
2024-08-02 17:36:58,474 [foster.py] => SNet: Task 15, Epoch 95/130 => Loss 29.561,  Loss1 0.754, Train_accy 73.40
2024-08-02 17:37:03,212 [foster.py] => SNet: Task 15, Epoch 96/130 => Loss 29.575,  Loss1 0.753, Train_accy 73.87, Test_accy 65.86
2024-08-02 17:37:06,811 [foster.py] => SNet: Task 15, Epoch 97/130 => Loss 29.591,  Loss1 0.753, Train_accy 72.58
2024-08-02 17:37:10,406 [foster.py] => SNet: Task 15, Epoch 98/130 => Loss 29.582,  Loss1 0.753, Train_accy 73.98
2024-08-02 17:37:14,017 [foster.py] => SNet: Task 15, Epoch 99/130 => Loss 29.509,  Loss1 0.753, Train_accy 73.20
2024-08-02 17:37:17,576 [foster.py] => SNet: Task 15, Epoch 100/130 => Loss 29.605,  Loss1 0.754, Train_accy 73.01
2024-08-02 17:37:22,344 [foster.py] => SNet: Task 15, Epoch 101/130 => Loss 29.589,  Loss1 0.753, Train_accy 71.76, Test_accy 65.79
2024-08-02 17:37:25,946 [foster.py] => SNet: Task 15, Epoch 102/130 => Loss 29.578,  Loss1 0.753, Train_accy 71.76
2024-08-02 17:37:29,542 [foster.py] => SNet: Task 15, Epoch 103/130 => Loss 29.579,  Loss1 0.753, Train_accy 73.24
2024-08-02 17:37:33,167 [foster.py] => SNet: Task 15, Epoch 104/130 => Loss 29.540,  Loss1 0.753, Train_accy 72.27
2024-08-02 17:37:36,730 [foster.py] => SNet: Task 15, Epoch 105/130 => Loss 29.609,  Loss1 0.754, Train_accy 71.13
2024-08-02 17:37:41,500 [foster.py] => SNet: Task 15, Epoch 106/130 => Loss 29.568,  Loss1 0.753, Train_accy 73.52, Test_accy 65.82
2024-08-02 17:37:45,103 [foster.py] => SNet: Task 15, Epoch 107/130 => Loss 29.588,  Loss1 0.753, Train_accy 72.73
2024-08-02 17:37:48,742 [foster.py] => SNet: Task 15, Epoch 108/130 => Loss 29.541,  Loss1 0.753, Train_accy 73.20
2024-08-02 17:37:52,323 [foster.py] => SNet: Task 15, Epoch 109/130 => Loss 29.580,  Loss1 0.754, Train_accy 73.12
2024-08-02 17:37:55,893 [foster.py] => SNet: Task 15, Epoch 110/130 => Loss 29.557,  Loss1 0.753, Train_accy 73.01
2024-08-02 17:38:00,628 [foster.py] => SNet: Task 15, Epoch 111/130 => Loss 29.617,  Loss1 0.753, Train_accy 73.05, Test_accy 65.69
2024-08-02 17:38:04,220 [foster.py] => SNet: Task 15, Epoch 112/130 => Loss 29.581,  Loss1 0.754, Train_accy 72.42
2024-08-02 17:38:07,797 [foster.py] => SNet: Task 15, Epoch 113/130 => Loss 29.591,  Loss1 0.753, Train_accy 73.16
2024-08-02 17:38:11,375 [foster.py] => SNet: Task 15, Epoch 114/130 => Loss 29.587,  Loss1 0.754, Train_accy 72.15
2024-08-02 17:38:14,929 [foster.py] => SNet: Task 15, Epoch 115/130 => Loss 29.593,  Loss1 0.753, Train_accy 72.42
2024-08-02 17:38:19,687 [foster.py] => SNet: Task 15, Epoch 116/130 => Loss 29.582,  Loss1 0.753, Train_accy 73.01, Test_accy 65.74
2024-08-02 17:38:23,273 [foster.py] => SNet: Task 15, Epoch 117/130 => Loss 29.604,  Loss1 0.753, Train_accy 74.14
2024-08-02 17:38:26,843 [foster.py] => SNet: Task 15, Epoch 118/130 => Loss 29.580,  Loss1 0.753, Train_accy 73.20
2024-08-02 17:38:30,427 [foster.py] => SNet: Task 15, Epoch 119/130 => Loss 29.579,  Loss1 0.753, Train_accy 73.75
2024-08-02 17:38:34,010 [foster.py] => SNet: Task 15, Epoch 120/130 => Loss 29.570,  Loss1 0.753, Train_accy 73.16
2024-08-02 17:38:38,742 [foster.py] => SNet: Task 15, Epoch 121/130 => Loss 29.557,  Loss1 0.754, Train_accy 73.67, Test_accy 65.81
2024-08-02 17:38:42,319 [foster.py] => SNet: Task 15, Epoch 122/130 => Loss 29.560,  Loss1 0.753, Train_accy 73.63
2024-08-02 17:38:45,897 [foster.py] => SNet: Task 15, Epoch 123/130 => Loss 29.561,  Loss1 0.754, Train_accy 72.97
2024-08-02 17:38:49,463 [foster.py] => SNet: Task 15, Epoch 124/130 => Loss 29.519,  Loss1 0.754, Train_accy 73.05
2024-08-02 17:38:53,051 [foster.py] => SNet: Task 15, Epoch 125/130 => Loss 29.628,  Loss1 0.753, Train_accy 74.18
2024-08-02 17:38:57,881 [foster.py] => SNet: Task 15, Epoch 126/130 => Loss 29.622,  Loss1 0.753, Train_accy 72.73, Test_accy 65.81
2024-08-02 17:39:01,456 [foster.py] => SNet: Task 15, Epoch 127/130 => Loss 29.603,  Loss1 0.753, Train_accy 72.85
2024-08-02 17:39:05,072 [foster.py] => SNet: Task 15, Epoch 128/130 => Loss 29.553,  Loss1 0.753, Train_accy 73.63
2024-08-02 17:39:08,657 [foster.py] => SNet: Task 15, Epoch 129/130 => Loss 29.537,  Loss1 0.753, Train_accy 73.32
2024-08-02 17:39:12,236 [foster.py] => SNet: Task 15, Epoch 130/130 => Loss 29.571,  Loss1 0.754, Train_accy 73.40
2024-08-02 17:39:12,236 [foster.py] => do not weight align student!
2024-08-02 17:39:13,405 [foster.py] => darknet eval: 
2024-08-02 17:39:13,405 [foster.py] => CNN top1 curve: 65.8
2024-08-02 17:39:13,406 [foster.py] => CNN top5 curve: 89.1
2024-08-02 17:39:13,406 [foster.py] => CNN top1 平均值: 65.80
2024-08-02 17:39:13,412 [foster.py] => timees : 1189.1225264072418
2024-08-02 17:39:13,414 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 17:39:37,896 [foster.py] => Exemplar size: 1600
2024-08-02 17:39:37,896 [trainer.py] => CNN: {'total': 66.38, '00-09': 73.2, '10-19': 59.4, '20-29': 73.4, '30-39': 66.1, '40-49': 70.8, '50-59': 56.0, '60-69': 69.2, '70-79': 62.9, 'old': 66.68, 'new': 54.5}
2024-08-02 17:39:37,896 [trainer.py] => NME: {'total': 60.9, '00-09': 62.9, '10-19': 49.8, '20-29': 67.8, '30-39': 57.7, '40-49': 63.1, '50-59': 49.3, '60-69': 69.2, '70-79': 67.4, 'old': 60.18, 'new': 89.0}
2024-08-02 17:39:37,896 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38]
2024-08-02 17:39:37,896 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56]
2024-08-02 17:39:37,896 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9]
2024-08-02 17:39:37,896 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4]

2024-08-02 17:39:37,897 [trainer.py] => CNN top1 平均值: 73.92
2024-08-02 17:39:37,899 [trainer.py] => All params: 1175138
2024-08-02 17:39:37,902 [trainer.py] => Trainable params: 592794
2024-08-02 17:39:37,962 [foster.py] => Learning on 80-82
2024-08-02 17:39:37,966 [foster.py] => All params: 1175656
2024-08-02 17:39:37,968 [foster.py] => Trainable params: 593182
2024-08-02 17:39:38,009 [foster.py] => per cls weights : [1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925 1.01116925
 1.01116925 1.01116925 0.55323001 0.55323001]
2024-08-02 17:39:40,684 [foster.py] => Task 16, Epoch 1/170 => Loss 5.418, Loss_clf 1.099, Loss_fe 1.785, Loss_kd 2.470, Train_accy 68.81
2024-08-02 17:39:45,245 [foster.py] => Task 16, Epoch 2/170 => Loss 3.686, Loss_clf 0.481, Loss_fe 0.717, Loss_kd 2.425, Train_accy 73.92, Test_accy 64.13
2024-08-02 17:39:49,868 [foster.py] => Task 16, Epoch 3/170 => Loss 3.526, Loss_clf 0.467, Loss_fe 0.580, Loss_kd 2.417, Train_accy 73.31, Test_accy 64.85
2024-08-02 17:39:54,464 [foster.py] => Task 16, Epoch 4/170 => Loss 3.418, Loss_clf 0.436, Loss_fe 0.504, Loss_kd 2.416, Train_accy 74.42, Test_accy 64.83
2024-08-02 17:39:59,026 [foster.py] => Task 16, Epoch 5/170 => Loss 3.342, Loss_clf 0.417, Loss_fe 0.459, Loss_kd 2.404, Train_accy 75.73, Test_accy 65.21
2024-08-02 17:40:01,718 [foster.py] => Task 16, Epoch 6/170 => Loss 3.322, Loss_clf 0.414, Loss_fe 0.423, Loss_kd 2.423, Train_accy 77.92
2024-08-02 17:40:06,310 [foster.py] => Task 16, Epoch 7/170 => Loss 3.278, Loss_clf 0.404, Loss_fe 0.402, Loss_kd 2.410, Train_accy 76.42, Test_accy 64.89
2024-08-02 17:40:10,874 [foster.py] => Task 16, Epoch 8/170 => Loss 3.230, Loss_clf 0.388, Loss_fe 0.390, Loss_kd 2.390, Train_accy 76.23, Test_accy 65.16
2024-08-02 17:40:15,452 [foster.py] => Task 16, Epoch 9/170 => Loss 3.207, Loss_clf 0.386, Loss_fe 0.363, Loss_kd 2.397, Train_accy 77.73, Test_accy 65.11
2024-08-02 17:40:19,985 [foster.py] => Task 16, Epoch 10/170 => Loss 3.282, Loss_clf 0.426, Loss_fe 0.374, Loss_kd 2.420, Train_accy 77.38, Test_accy 65.38
2024-08-02 17:40:22,662 [foster.py] => Task 16, Epoch 11/170 => Loss 3.234, Loss_clf 0.421, Loss_fe 0.366, Loss_kd 2.386, Train_accy 76.23
2024-08-02 17:40:27,267 [foster.py] => Task 16, Epoch 12/170 => Loss 3.244, Loss_clf 0.402, Loss_fe 0.351, Loss_kd 2.428, Train_accy 78.42, Test_accy 65.28
2024-08-02 17:40:31,848 [foster.py] => Task 16, Epoch 13/170 => Loss 3.234, Loss_clf 0.399, Loss_fe 0.349, Loss_kd 2.423, Train_accy 78.12, Test_accy 65.12
2024-08-02 17:40:36,429 [foster.py] => Task 16, Epoch 14/170 => Loss 3.206, Loss_clf 0.387, Loss_fe 0.347, Loss_kd 2.410, Train_accy 78.54, Test_accy 65.18
2024-08-02 17:40:41,036 [foster.py] => Task 16, Epoch 15/170 => Loss 3.100, Loss_clf 0.335, Loss_fe 0.314, Loss_kd 2.390, Train_accy 79.88, Test_accy 65.30
2024-08-02 17:40:43,707 [foster.py] => Task 16, Epoch 16/170 => Loss 3.234, Loss_clf 0.410, Loss_fe 0.351, Loss_kd 2.410, Train_accy 79.00
2024-08-02 17:40:48,290 [foster.py] => Task 16, Epoch 17/170 => Loss 3.261, Loss_clf 0.429, Loss_fe 0.344, Loss_kd 2.425, Train_accy 78.65, Test_accy 65.09
2024-08-02 17:40:52,887 [foster.py] => Task 16, Epoch 18/170 => Loss 3.177, Loss_clf 0.399, Loss_fe 0.323, Loss_kd 2.393, Train_accy 80.77, Test_accy 65.09
2024-08-02 17:40:57,434 [foster.py] => Task 16, Epoch 19/170 => Loss 3.143, Loss_clf 0.371, Loss_fe 0.309, Loss_kd 2.401, Train_accy 80.58, Test_accy 65.22
2024-08-02 17:41:02,058 [foster.py] => Task 16, Epoch 20/170 => Loss 3.188, Loss_clf 0.412, Loss_fe 0.314, Loss_kd 2.401, Train_accy 79.62, Test_accy 65.50
2024-08-02 17:41:04,747 [foster.py] => Task 16, Epoch 21/170 => Loss 3.191, Loss_clf 0.415, Loss_fe 0.314, Loss_kd 2.401, Train_accy 78.35
2024-08-02 17:41:09,287 [foster.py] => Task 16, Epoch 22/170 => Loss 3.152, Loss_clf 0.386, Loss_fe 0.284, Loss_kd 2.419, Train_accy 79.27, Test_accy 65.49
2024-08-02 17:41:13,884 [foster.py] => Task 16, Epoch 23/170 => Loss 3.155, Loss_clf 0.395, Loss_fe 0.288, Loss_kd 2.410, Train_accy 78.88, Test_accy 65.54
2024-08-02 17:41:18,496 [foster.py] => Task 16, Epoch 24/170 => Loss 3.124, Loss_clf 0.374, Loss_fe 0.284, Loss_kd 2.404, Train_accy 80.08, Test_accy 65.35
2024-08-02 17:41:23,036 [foster.py] => Task 16, Epoch 25/170 => Loss 3.140, Loss_clf 0.380, Loss_fe 0.277, Loss_kd 2.421, Train_accy 79.35, Test_accy 65.56
2024-08-02 17:41:25,702 [foster.py] => Task 16, Epoch 26/170 => Loss 3.146, Loss_clf 0.386, Loss_fe 0.285, Loss_kd 2.413, Train_accy 80.65
2024-08-02 17:41:30,251 [foster.py] => Task 16, Epoch 27/170 => Loss 3.109, Loss_clf 0.381, Loss_fe 0.277, Loss_kd 2.390, Train_accy 79.54, Test_accy 65.40
2024-08-02 17:41:34,803 [foster.py] => Task 16, Epoch 28/170 => Loss 3.126, Loss_clf 0.389, Loss_fe 0.261, Loss_kd 2.413, Train_accy 80.23, Test_accy 65.54
2024-08-02 17:41:39,471 [foster.py] => Task 16, Epoch 29/170 => Loss 3.045, Loss_clf 0.345, Loss_fe 0.244, Loss_kd 2.394, Train_accy 80.85, Test_accy 65.44
2024-08-02 17:41:44,021 [foster.py] => Task 16, Epoch 30/170 => Loss 3.086, Loss_clf 0.357, Loss_fe 0.257, Loss_kd 2.411, Train_accy 81.69, Test_accy 65.44
2024-08-02 17:41:46,711 [foster.py] => Task 16, Epoch 31/170 => Loss 3.090, Loss_clf 0.369, Loss_fe 0.235, Loss_kd 2.423, Train_accy 81.81
2024-08-02 17:41:51,341 [foster.py] => Task 16, Epoch 32/170 => Loss 3.090, Loss_clf 0.377, Loss_fe 0.239, Loss_kd 2.412, Train_accy 82.08, Test_accy 65.05
2024-08-02 17:41:55,929 [foster.py] => Task 16, Epoch 33/170 => Loss 3.084, Loss_clf 0.366, Loss_fe 0.256, Loss_kd 2.400, Train_accy 79.08, Test_accy 65.48
2024-08-02 17:42:00,511 [foster.py] => Task 16, Epoch 34/170 => Loss 3.184, Loss_clf 0.420, Loss_fe 0.249, Loss_kd 2.452, Train_accy 78.81, Test_accy 66.21
2024-08-02 17:42:05,116 [foster.py] => Task 16, Epoch 35/170 => Loss 3.103, Loss_clf 0.382, Loss_fe 0.231, Loss_kd 2.428, Train_accy 81.96, Test_accy 65.26
2024-08-02 17:42:07,814 [foster.py] => Task 16, Epoch 36/170 => Loss 3.120, Loss_clf 0.386, Loss_fe 0.241, Loss_kd 2.431, Train_accy 81.35
2024-08-02 17:42:12,400 [foster.py] => Task 16, Epoch 37/170 => Loss 3.080, Loss_clf 0.362, Loss_fe 0.231, Loss_kd 2.425, Train_accy 80.73, Test_accy 65.55
2024-08-02 17:42:16,964 [foster.py] => Task 16, Epoch 38/170 => Loss 3.134, Loss_clf 0.397, Loss_fe 0.237, Loss_kd 2.437, Train_accy 79.81, Test_accy 65.44
2024-08-02 17:42:21,539 [foster.py] => Task 16, Epoch 39/170 => Loss 3.030, Loss_clf 0.347, Loss_fe 0.245, Loss_kd 2.377, Train_accy 81.92, Test_accy 65.22
2024-08-02 17:42:26,132 [foster.py] => Task 16, Epoch 40/170 => Loss 3.068, Loss_clf 0.366, Loss_fe 0.231, Loss_kd 2.408, Train_accy 81.77, Test_accy 65.18
2024-08-02 17:42:28,814 [foster.py] => Task 16, Epoch 41/170 => Loss 3.048, Loss_clf 0.371, Loss_fe 0.230, Loss_kd 2.386, Train_accy 80.54
2024-08-02 17:42:33,391 [foster.py] => Task 16, Epoch 42/170 => Loss 3.072, Loss_clf 0.379, Loss_fe 0.228, Loss_kd 2.403, Train_accy 81.35, Test_accy 65.39
2024-08-02 17:42:37,952 [foster.py] => Task 16, Epoch 43/170 => Loss 3.055, Loss_clf 0.362, Loss_fe 0.197, Loss_kd 2.433, Train_accy 81.04, Test_accy 65.41
2024-08-02 17:42:42,512 [foster.py] => Task 16, Epoch 44/170 => Loss 3.032, Loss_clf 0.345, Loss_fe 0.215, Loss_kd 2.410, Train_accy 81.15, Test_accy 65.12
2024-08-02 17:42:47,111 [foster.py] => Task 16, Epoch 45/170 => Loss 3.050, Loss_clf 0.353, Loss_fe 0.225, Loss_kd 2.410, Train_accy 82.96, Test_accy 65.79
2024-08-02 17:42:49,790 [foster.py] => Task 16, Epoch 46/170 => Loss 2.985, Loss_clf 0.327, Loss_fe 0.199, Loss_kd 2.397, Train_accy 83.08
2024-08-02 17:42:54,359 [foster.py] => Task 16, Epoch 47/170 => Loss 2.996, Loss_clf 0.345, Loss_fe 0.182, Loss_kd 2.407, Train_accy 82.96, Test_accy 65.59
2024-08-02 17:42:58,908 [foster.py] => Task 16, Epoch 48/170 => Loss 3.019, Loss_clf 0.342, Loss_fe 0.212, Loss_kd 2.403, Train_accy 83.92, Test_accy 65.91
2024-08-02 17:43:03,456 [foster.py] => Task 16, Epoch 49/170 => Loss 2.988, Loss_clf 0.332, Loss_fe 0.196, Loss_kd 2.398, Train_accy 85.31, Test_accy 65.54
2024-08-02 17:43:08,044 [foster.py] => Task 16, Epoch 50/170 => Loss 2.959, Loss_clf 0.329, Loss_fe 0.195, Loss_kd 2.374, Train_accy 82.38, Test_accy 65.70
2024-08-02 17:43:10,719 [foster.py] => Task 16, Epoch 51/170 => Loss 2.962, Loss_clf 0.318, Loss_fe 0.188, Loss_kd 2.395, Train_accy 82.69
2024-08-02 17:43:15,367 [foster.py] => Task 16, Epoch 52/170 => Loss 2.963, Loss_clf 0.324, Loss_fe 0.184, Loss_kd 2.394, Train_accy 83.69, Test_accy 65.50
2024-08-02 17:43:19,955 [foster.py] => Task 16, Epoch 53/170 => Loss 3.011, Loss_clf 0.348, Loss_fe 0.191, Loss_kd 2.410, Train_accy 84.19, Test_accy 65.56
2024-08-02 17:43:24,520 [foster.py] => Task 16, Epoch 54/170 => Loss 2.959, Loss_clf 0.324, Loss_fe 0.179, Loss_kd 2.394, Train_accy 82.77, Test_accy 65.59
2024-08-02 17:43:29,072 [foster.py] => Task 16, Epoch 55/170 => Loss 3.004, Loss_clf 0.342, Loss_fe 0.196, Loss_kd 2.405, Train_accy 84.58, Test_accy 65.44
2024-08-02 17:43:31,775 [foster.py] => Task 16, Epoch 56/170 => Loss 3.030, Loss_clf 0.344, Loss_fe 0.217, Loss_kd 2.407, Train_accy 84.58
2024-08-02 17:43:36,382 [foster.py] => Task 16, Epoch 57/170 => Loss 3.055, Loss_clf 0.355, Loss_fe 0.210, Loss_kd 2.427, Train_accy 82.46, Test_accy 65.94
2024-08-02 17:43:40,945 [foster.py] => Task 16, Epoch 58/170 => Loss 3.097, Loss_clf 0.368, Loss_fe 0.242, Loss_kd 2.425, Train_accy 81.62, Test_accy 65.62
2024-08-02 17:43:45,531 [foster.py] => Task 16, Epoch 59/170 => Loss 2.995, Loss_clf 0.339, Loss_fe 0.201, Loss_kd 2.394, Train_accy 81.77, Test_accy 65.67
2024-08-02 17:43:50,082 [foster.py] => Task 16, Epoch 60/170 => Loss 2.977, Loss_clf 0.325, Loss_fe 0.194, Loss_kd 2.396, Train_accy 82.42, Test_accy 65.94
2024-08-02 17:43:52,749 [foster.py] => Task 16, Epoch 61/170 => Loss 2.998, Loss_clf 0.343, Loss_fe 0.201, Loss_kd 2.392, Train_accy 81.54
2024-08-02 17:43:57,329 [foster.py] => Task 16, Epoch 62/170 => Loss 2.951, Loss_clf 0.318, Loss_fe 0.172, Loss_kd 2.398, Train_accy 84.23, Test_accy 65.80
2024-08-02 17:44:01,875 [foster.py] => Task 16, Epoch 63/170 => Loss 3.007, Loss_clf 0.358, Loss_fe 0.177, Loss_kd 2.411, Train_accy 82.58, Test_accy 65.77
2024-08-02 17:44:06,462 [foster.py] => Task 16, Epoch 64/170 => Loss 2.997, Loss_clf 0.358, Loss_fe 0.186, Loss_kd 2.392, Train_accy 83.62, Test_accy 65.72
2024-08-02 17:44:11,034 [foster.py] => Task 16, Epoch 65/170 => Loss 2.967, Loss_clf 0.318, Loss_fe 0.172, Loss_kd 2.416, Train_accy 84.12, Test_accy 65.85
2024-08-02 17:44:13,718 [foster.py] => Task 16, Epoch 66/170 => Loss 2.977, Loss_clf 0.330, Loss_fe 0.180, Loss_kd 2.405, Train_accy 82.88
2024-08-02 17:44:18,309 [foster.py] => Task 16, Epoch 67/170 => Loss 2.946, Loss_clf 0.316, Loss_fe 0.172, Loss_kd 2.396, Train_accy 84.96, Test_accy 65.83
2024-08-02 17:44:22,915 [foster.py] => Task 16, Epoch 68/170 => Loss 2.930, Loss_clf 0.311, Loss_fe 0.167, Loss_kd 2.391, Train_accy 82.58, Test_accy 66.01
2024-08-02 17:44:27,491 [foster.py] => Task 16, Epoch 69/170 => Loss 2.966, Loss_clf 0.339, Loss_fe 0.164, Loss_kd 2.401, Train_accy 82.92, Test_accy 65.99
2024-08-02 17:44:32,123 [foster.py] => Task 16, Epoch 70/170 => Loss 3.010, Loss_clf 0.338, Loss_fe 0.185, Loss_kd 2.425, Train_accy 83.42, Test_accy 65.67
2024-08-02 17:44:34,895 [foster.py] => Task 16, Epoch 71/170 => Loss 3.008, Loss_clf 0.346, Loss_fe 0.173, Loss_kd 2.427, Train_accy 83.19
2024-08-02 17:44:39,583 [foster.py] => Task 16, Epoch 72/170 => Loss 3.029, Loss_clf 0.337, Loss_fe 0.174, Loss_kd 2.455, Train_accy 83.58, Test_accy 65.63
2024-08-02 17:44:44,140 [foster.py] => Task 16, Epoch 73/170 => Loss 3.018, Loss_clf 0.347, Loss_fe 0.185, Loss_kd 2.424, Train_accy 83.54, Test_accy 65.74
2024-08-02 17:44:48,690 [foster.py] => Task 16, Epoch 74/170 => Loss 2.950, Loss_clf 0.323, Loss_fe 0.154, Loss_kd 2.411, Train_accy 82.69, Test_accy 65.79
2024-08-02 17:44:53,282 [foster.py] => Task 16, Epoch 75/170 => Loss 2.991, Loss_clf 0.335, Loss_fe 0.183, Loss_kd 2.411, Train_accy 84.96, Test_accy 65.71
2024-08-02 17:44:55,947 [foster.py] => Task 16, Epoch 76/170 => Loss 2.947, Loss_clf 0.324, Loss_fe 0.166, Loss_kd 2.395, Train_accy 84.23
2024-08-02 17:45:00,608 [foster.py] => Task 16, Epoch 77/170 => Loss 2.952, Loss_clf 0.328, Loss_fe 0.165, Loss_kd 2.397, Train_accy 83.85, Test_accy 65.15
2024-08-02 17:45:05,171 [foster.py] => Task 16, Epoch 78/170 => Loss 2.951, Loss_clf 0.320, Loss_fe 0.139, Loss_kd 2.430, Train_accy 84.96, Test_accy 65.80
2024-08-02 17:45:09,773 [foster.py] => Task 16, Epoch 79/170 => Loss 2.955, Loss_clf 0.307, Loss_fe 0.162, Loss_kd 2.424, Train_accy 85.92, Test_accy 65.73
2024-08-02 17:45:14,364 [foster.py] => Task 16, Epoch 80/170 => Loss 2.978, Loss_clf 0.351, Loss_fe 0.158, Loss_kd 2.407, Train_accy 84.04, Test_accy 65.95
2024-08-02 17:45:17,097 [foster.py] => Task 16, Epoch 81/170 => Loss 2.943, Loss_clf 0.319, Loss_fe 0.157, Loss_kd 2.404, Train_accy 83.38
2024-08-02 17:45:21,670 [foster.py] => Task 16, Epoch 82/170 => Loss 3.004, Loss_clf 0.347, Loss_fe 0.175, Loss_kd 2.420, Train_accy 84.58, Test_accy 65.59
2024-08-02 17:45:26,217 [foster.py] => Task 16, Epoch 83/170 => Loss 2.955, Loss_clf 0.320, Loss_fe 0.157, Loss_kd 2.416, Train_accy 85.04, Test_accy 65.88
2024-08-02 17:45:30,796 [foster.py] => Task 16, Epoch 84/170 => Loss 2.950, Loss_clf 0.337, Loss_fe 0.160, Loss_kd 2.392, Train_accy 82.73, Test_accy 65.72
2024-08-02 17:45:35,407 [foster.py] => Task 16, Epoch 85/170 => Loss 2.958, Loss_clf 0.320, Loss_fe 0.139, Loss_kd 2.435, Train_accy 85.12, Test_accy 65.45
2024-08-02 17:45:38,102 [foster.py] => Task 16, Epoch 86/170 => Loss 2.982, Loss_clf 0.341, Loss_fe 0.165, Loss_kd 2.414, Train_accy 84.15
2024-08-02 17:45:42,682 [foster.py] => Task 16, Epoch 87/170 => Loss 2.994, Loss_clf 0.348, Loss_fe 0.152, Loss_kd 2.432, Train_accy 84.46, Test_accy 65.99
2024-08-02 17:45:47,242 [foster.py] => Task 16, Epoch 88/170 => Loss 2.888, Loss_clf 0.309, Loss_fe 0.132, Loss_kd 2.386, Train_accy 83.73, Test_accy 65.90
2024-08-02 17:45:51,843 [foster.py] => Task 16, Epoch 89/170 => Loss 2.953, Loss_clf 0.325, Loss_fe 0.146, Loss_kd 2.420, Train_accy 84.85, Test_accy 65.96
2024-08-02 17:45:56,444 [foster.py] => Task 16, Epoch 90/170 => Loss 2.948, Loss_clf 0.318, Loss_fe 0.140, Loss_kd 2.427, Train_accy 85.54, Test_accy 66.01
2024-08-02 17:45:59,109 [foster.py] => Task 16, Epoch 91/170 => Loss 2.915, Loss_clf 0.315, Loss_fe 0.136, Loss_kd 2.402, Train_accy 86.54
2024-08-02 17:46:03,765 [foster.py] => Task 16, Epoch 92/170 => Loss 2.879, Loss_clf 0.305, Loss_fe 0.138, Loss_kd 2.375, Train_accy 85.27, Test_accy 65.70
2024-08-02 17:46:08,360 [foster.py] => Task 16, Epoch 93/170 => Loss 2.985, Loss_clf 0.347, Loss_fe 0.151, Loss_kd 2.426, Train_accy 84.46, Test_accy 65.87
2024-08-02 17:46:12,902 [foster.py] => Task 16, Epoch 94/170 => Loss 2.911, Loss_clf 0.311, Loss_fe 0.143, Loss_kd 2.395, Train_accy 86.62, Test_accy 65.32
2024-08-02 17:46:17,479 [foster.py] => Task 16, Epoch 95/170 => Loss 2.917, Loss_clf 0.322, Loss_fe 0.121, Loss_kd 2.412, Train_accy 85.38, Test_accy 65.83
2024-08-02 17:46:20,156 [foster.py] => Task 16, Epoch 96/170 => Loss 2.956, Loss_clf 0.335, Loss_fe 0.135, Loss_kd 2.423, Train_accy 84.88
2024-08-02 17:46:24,727 [foster.py] => Task 16, Epoch 97/170 => Loss 2.875, Loss_clf 0.306, Loss_fe 0.117, Loss_kd 2.391, Train_accy 85.81, Test_accy 65.67
2024-08-02 17:46:29,290 [foster.py] => Task 16, Epoch 98/170 => Loss 2.881, Loss_clf 0.306, Loss_fe 0.128, Loss_kd 2.386, Train_accy 85.73, Test_accy 65.94
2024-08-02 17:46:33,865 [foster.py] => Task 16, Epoch 99/170 => Loss 2.895, Loss_clf 0.311, Loss_fe 0.128, Loss_kd 2.394, Train_accy 84.96, Test_accy 65.88
2024-08-02 17:46:38,454 [foster.py] => Task 16, Epoch 100/170 => Loss 2.958, Loss_clf 0.338, Loss_fe 0.134, Loss_kd 2.424, Train_accy 86.00, Test_accy 65.56
2024-08-02 17:46:41,138 [foster.py] => Task 16, Epoch 101/170 => Loss 2.887, Loss_clf 0.302, Loss_fe 0.131, Loss_kd 2.393, Train_accy 86.31
2024-08-02 17:46:45,713 [foster.py] => Task 16, Epoch 102/170 => Loss 2.929, Loss_clf 0.329, Loss_fe 0.120, Loss_kd 2.418, Train_accy 85.27, Test_accy 66.00
2024-08-02 17:46:50,324 [foster.py] => Task 16, Epoch 103/170 => Loss 2.904, Loss_clf 0.314, Loss_fe 0.107, Loss_kd 2.421, Train_accy 85.27, Test_accy 66.00
2024-08-02 17:46:54,893 [foster.py] => Task 16, Epoch 104/170 => Loss 2.911, Loss_clf 0.316, Loss_fe 0.127, Loss_kd 2.406, Train_accy 85.96, Test_accy 66.02
2024-08-02 17:46:59,465 [foster.py] => Task 16, Epoch 105/170 => Loss 2.885, Loss_clf 0.290, Loss_fe 0.109, Loss_kd 2.424, Train_accy 85.77, Test_accy 65.94
2024-08-02 17:47:02,138 [foster.py] => Task 16, Epoch 106/170 => Loss 2.884, Loss_clf 0.297, Loss_fe 0.113, Loss_kd 2.412, Train_accy 86.31
2024-08-02 17:47:06,723 [foster.py] => Task 16, Epoch 107/170 => Loss 2.839, Loss_clf 0.283, Loss_fe 0.104, Loss_kd 2.390, Train_accy 87.27, Test_accy 65.94
2024-08-02 17:47:11,274 [foster.py] => Task 16, Epoch 108/170 => Loss 2.893, Loss_clf 0.306, Loss_fe 0.118, Loss_kd 2.407, Train_accy 85.81, Test_accy 65.66
2024-08-02 17:47:15,831 [foster.py] => Task 16, Epoch 109/170 => Loss 2.859, Loss_clf 0.294, Loss_fe 0.112, Loss_kd 2.392, Train_accy 87.08, Test_accy 65.79
2024-08-02 17:47:20,396 [foster.py] => Task 16, Epoch 110/170 => Loss 2.874, Loss_clf 0.310, Loss_fe 0.108, Loss_kd 2.394, Train_accy 85.73, Test_accy 65.74
2024-08-02 17:47:23,180 [foster.py] => Task 16, Epoch 111/170 => Loss 2.943, Loss_clf 0.327, Loss_fe 0.118, Loss_kd 2.434, Train_accy 85.42
2024-08-02 17:47:27,942 [foster.py] => Task 16, Epoch 112/170 => Loss 2.816, Loss_clf 0.272, Loss_fe 0.106, Loss_kd 2.377, Train_accy 86.88, Test_accy 65.91
2024-08-02 17:47:32,550 [foster.py] => Task 16, Epoch 113/170 => Loss 2.859, Loss_clf 0.296, Loss_fe 0.109, Loss_kd 2.392, Train_accy 85.85, Test_accy 65.89
2024-08-02 17:47:37,104 [foster.py] => Task 16, Epoch 114/170 => Loss 2.964, Loss_clf 0.334, Loss_fe 0.131, Loss_kd 2.437, Train_accy 86.27, Test_accy 66.04
2024-08-02 17:47:41,703 [foster.py] => Task 16, Epoch 115/170 => Loss 2.911, Loss_clf 0.325, Loss_fe 0.103, Loss_kd 2.421, Train_accy 85.35, Test_accy 65.93
2024-08-02 17:47:44,386 [foster.py] => Task 16, Epoch 116/170 => Loss 2.904, Loss_clf 0.311, Loss_fe 0.103, Loss_kd 2.427, Train_accy 85.88
2024-08-02 17:47:49,026 [foster.py] => Task 16, Epoch 117/170 => Loss 2.843, Loss_clf 0.288, Loss_fe 0.100, Loss_kd 2.394, Train_accy 87.27, Test_accy 65.88
2024-08-02 17:47:53,561 [foster.py] => Task 16, Epoch 118/170 => Loss 2.903, Loss_clf 0.322, Loss_fe 0.116, Loss_kd 2.404, Train_accy 85.85, Test_accy 65.91
2024-08-02 17:47:58,104 [foster.py] => Task 16, Epoch 119/170 => Loss 2.892, Loss_clf 0.298, Loss_fe 0.103, Loss_kd 2.429, Train_accy 86.73, Test_accy 66.07
2024-08-02 17:48:02,702 [foster.py] => Task 16, Epoch 120/170 => Loss 2.867, Loss_clf 0.288, Loss_fe 0.108, Loss_kd 2.410, Train_accy 87.31, Test_accy 66.17
2024-08-02 17:48:05,398 [foster.py] => Task 16, Epoch 121/170 => Loss 2.904, Loss_clf 0.328, Loss_fe 0.098, Loss_kd 2.416, Train_accy 86.04
2024-08-02 17:48:10,072 [foster.py] => Task 16, Epoch 122/170 => Loss 2.891, Loss_clf 0.301, Loss_fe 0.103, Loss_kd 2.425, Train_accy 86.23, Test_accy 65.80
2024-08-02 17:48:14,624 [foster.py] => Task 16, Epoch 123/170 => Loss 2.842, Loss_clf 0.286, Loss_fe 0.106, Loss_kd 2.390, Train_accy 87.12, Test_accy 65.94
2024-08-02 17:48:19,217 [foster.py] => Task 16, Epoch 124/170 => Loss 2.864, Loss_clf 0.293, Loss_fe 0.098, Loss_kd 2.412, Train_accy 87.04, Test_accy 66.09
2024-08-02 17:48:23,849 [foster.py] => Task 16, Epoch 125/170 => Loss 2.808, Loss_clf 0.267, Loss_fe 0.098, Loss_kd 2.382, Train_accy 87.73, Test_accy 65.90
2024-08-02 17:48:26,535 [foster.py] => Task 16, Epoch 126/170 => Loss 2.904, Loss_clf 0.310, Loss_fe 0.096, Loss_kd 2.435, Train_accy 86.00
2024-08-02 17:48:31,114 [foster.py] => Task 16, Epoch 127/170 => Loss 2.867, Loss_clf 0.298, Loss_fe 0.097, Loss_kd 2.410, Train_accy 86.62, Test_accy 65.82
2024-08-02 17:48:35,795 [foster.py] => Task 16, Epoch 128/170 => Loss 2.827, Loss_clf 0.279, Loss_fe 0.102, Loss_kd 2.385, Train_accy 87.42, Test_accy 65.89
2024-08-02 17:48:40,362 [foster.py] => Task 16, Epoch 129/170 => Loss 2.907, Loss_clf 0.306, Loss_fe 0.088, Loss_kd 2.451, Train_accy 87.12, Test_accy 65.57
2024-08-02 17:48:44,945 [foster.py] => Task 16, Epoch 130/170 => Loss 2.833, Loss_clf 0.280, Loss_fe 0.086, Loss_kd 2.406, Train_accy 87.42, Test_accy 65.84
2024-08-02 17:48:47,617 [foster.py] => Task 16, Epoch 131/170 => Loss 2.864, Loss_clf 0.291, Loss_fe 0.092, Loss_kd 2.419, Train_accy 87.12
2024-08-02 17:48:52,228 [foster.py] => Task 16, Epoch 132/170 => Loss 2.872, Loss_clf 0.306, Loss_fe 0.097, Loss_kd 2.407, Train_accy 86.77, Test_accy 65.94
2024-08-02 17:48:56,787 [foster.py] => Task 16, Epoch 133/170 => Loss 2.824, Loss_clf 0.274, Loss_fe 0.089, Loss_kd 2.398, Train_accy 88.12, Test_accy 65.82
2024-08-02 17:49:01,401 [foster.py] => Task 16, Epoch 134/170 => Loss 2.863, Loss_clf 0.309, Loss_fe 0.086, Loss_kd 2.407, Train_accy 86.92, Test_accy 65.90
2024-08-02 17:49:06,005 [foster.py] => Task 16, Epoch 135/170 => Loss 2.904, Loss_clf 0.302, Loss_fe 0.095, Loss_kd 2.444, Train_accy 86.62, Test_accy 65.93
2024-08-02 17:49:08,740 [foster.py] => Task 16, Epoch 136/170 => Loss 2.852, Loss_clf 0.298, Loss_fe 0.102, Loss_kd 2.391, Train_accy 86.65
2024-08-02 17:49:13,304 [foster.py] => Task 16, Epoch 137/170 => Loss 2.814, Loss_clf 0.286, Loss_fe 0.088, Loss_kd 2.378, Train_accy 87.19, Test_accy 66.01
2024-08-02 17:49:17,837 [foster.py] => Task 16, Epoch 138/170 => Loss 2.832, Loss_clf 0.280, Loss_fe 0.091, Loss_kd 2.400, Train_accy 87.96, Test_accy 65.96
2024-08-02 17:49:22,457 [foster.py] => Task 16, Epoch 139/170 => Loss 2.925, Loss_clf 0.336, Loss_fe 0.103, Loss_kd 2.424, Train_accy 85.92, Test_accy 65.89
2024-08-02 17:49:27,029 [foster.py] => Task 16, Epoch 140/170 => Loss 2.889, Loss_clf 0.300, Loss_fe 0.107, Loss_kd 2.419, Train_accy 87.77, Test_accy 65.89
2024-08-02 17:49:29,739 [foster.py] => Task 16, Epoch 141/170 => Loss 2.869, Loss_clf 0.290, Loss_fe 0.095, Loss_kd 2.422, Train_accy 87.77
2024-08-02 17:49:34,284 [foster.py] => Task 16, Epoch 142/170 => Loss 2.902, Loss_clf 0.320, Loss_fe 0.092, Loss_kd 2.428, Train_accy 86.19, Test_accy 65.93
2024-08-02 17:49:38,862 [foster.py] => Task 16, Epoch 143/170 => Loss 2.868, Loss_clf 0.315, Loss_fe 0.087, Loss_kd 2.405, Train_accy 86.65, Test_accy 65.89
2024-08-02 17:49:43,426 [foster.py] => Task 16, Epoch 144/170 => Loss 2.837, Loss_clf 0.277, Loss_fe 0.089, Loss_kd 2.409, Train_accy 88.50, Test_accy 65.98
2024-08-02 17:49:47,947 [foster.py] => Task 16, Epoch 145/170 => Loss 2.912, Loss_clf 0.317, Loss_fe 0.095, Loss_kd 2.437, Train_accy 86.42, Test_accy 65.88
2024-08-02 17:49:50,629 [foster.py] => Task 16, Epoch 146/170 => Loss 2.910, Loss_clf 0.312, Loss_fe 0.089, Loss_kd 2.446, Train_accy 86.15
2024-08-02 17:49:55,209 [foster.py] => Task 16, Epoch 147/170 => Loss 2.836, Loss_clf 0.280, Loss_fe 0.092, Loss_kd 2.402, Train_accy 87.19, Test_accy 65.88
2024-08-02 17:49:59,749 [foster.py] => Task 16, Epoch 148/170 => Loss 2.848, Loss_clf 0.285, Loss_fe 0.088, Loss_kd 2.413, Train_accy 86.62, Test_accy 65.85
2024-08-02 17:50:04,311 [foster.py] => Task 16, Epoch 149/170 => Loss 2.883, Loss_clf 0.311, Loss_fe 0.097, Loss_kd 2.413, Train_accy 86.31, Test_accy 65.82
2024-08-02 17:50:08,906 [foster.py] => Task 16, Epoch 150/170 => Loss 2.828, Loss_clf 0.277, Loss_fe 0.075, Loss_kd 2.415, Train_accy 87.42, Test_accy 65.83
2024-08-02 17:50:11,572 [foster.py] => Task 16, Epoch 151/170 => Loss 2.846, Loss_clf 0.294, Loss_fe 0.083, Loss_kd 2.407, Train_accy 87.58
2024-08-02 17:50:16,192 [foster.py] => Task 16, Epoch 152/170 => Loss 2.792, Loss_clf 0.271, Loss_fe 0.085, Loss_kd 2.375, Train_accy 87.35, Test_accy 65.90
2024-08-02 17:50:20,752 [foster.py] => Task 16, Epoch 153/170 => Loss 2.825, Loss_clf 0.273, Loss_fe 0.088, Loss_kd 2.402, Train_accy 87.77, Test_accy 65.93
2024-08-02 17:50:25,310 [foster.py] => Task 16, Epoch 154/170 => Loss 2.791, Loss_clf 0.264, Loss_fe 0.076, Loss_kd 2.390, Train_accy 88.88, Test_accy 65.90
2024-08-02 17:50:29,934 [foster.py] => Task 16, Epoch 155/170 => Loss 2.808, Loss_clf 0.274, Loss_fe 0.079, Loss_kd 2.393, Train_accy 86.58, Test_accy 65.93
2024-08-02 17:50:32,604 [foster.py] => Task 16, Epoch 156/170 => Loss 2.839, Loss_clf 0.289, Loss_fe 0.079, Loss_kd 2.410, Train_accy 86.65
2024-08-02 17:50:37,190 [foster.py] => Task 16, Epoch 157/170 => Loss 2.852, Loss_clf 0.288, Loss_fe 0.072, Loss_kd 2.428, Train_accy 87.92, Test_accy 65.93
2024-08-02 17:50:41,764 [foster.py] => Task 16, Epoch 158/170 => Loss 2.873, Loss_clf 0.307, Loss_fe 0.089, Loss_kd 2.415, Train_accy 86.77, Test_accy 65.85
2024-08-02 17:50:46,393 [foster.py] => Task 16, Epoch 159/170 => Loss 2.829, Loss_clf 0.273, Loss_fe 0.077, Loss_kd 2.417, Train_accy 87.88, Test_accy 65.88
2024-08-02 17:50:50,973 [foster.py] => Task 16, Epoch 160/170 => Loss 2.810, Loss_clf 0.294, Loss_fe 0.064, Loss_kd 2.391, Train_accy 87.46, Test_accy 65.89
2024-08-02 17:50:53,664 [foster.py] => Task 16, Epoch 161/170 => Loss 2.886, Loss_clf 0.290, Loss_fe 0.089, Loss_kd 2.445, Train_accy 86.92
2024-08-02 17:50:58,258 [foster.py] => Task 16, Epoch 162/170 => Loss 2.850, Loss_clf 0.300, Loss_fe 0.086, Loss_kd 2.402, Train_accy 86.62, Test_accy 65.90
2024-08-02 17:51:02,834 [foster.py] => Task 16, Epoch 163/170 => Loss 2.908, Loss_clf 0.310, Loss_fe 0.091, Loss_kd 2.444, Train_accy 87.19, Test_accy 65.93
2024-08-02 17:51:07,373 [foster.py] => Task 16, Epoch 164/170 => Loss 2.834, Loss_clf 0.287, Loss_fe 0.089, Loss_kd 2.396, Train_accy 87.42, Test_accy 65.91
2024-08-02 17:51:11,949 [foster.py] => Task 16, Epoch 165/170 => Loss 2.844, Loss_clf 0.285, Loss_fe 0.094, Loss_kd 2.404, Train_accy 87.85, Test_accy 65.91
2024-08-02 17:51:14,620 [foster.py] => Task 16, Epoch 166/170 => Loss 2.849, Loss_clf 0.304, Loss_fe 0.080, Loss_kd 2.404, Train_accy 85.92
2024-08-02 17:51:19,185 [foster.py] => Task 16, Epoch 167/170 => Loss 2.891, Loss_clf 0.318, Loss_fe 0.105, Loss_kd 2.406, Train_accy 86.35, Test_accy 65.88
2024-08-02 17:51:23,751 [foster.py] => Task 16, Epoch 168/170 => Loss 2.875, Loss_clf 0.315, Loss_fe 0.092, Loss_kd 2.407, Train_accy 86.58, Test_accy 65.88
2024-08-02 17:51:28,306 [foster.py] => Task 16, Epoch 169/170 => Loss 2.871, Loss_clf 0.316, Loss_fe 0.088, Loss_kd 2.406, Train_accy 86.73, Test_accy 65.91
2024-08-02 17:51:32,891 [foster.py] => Task 16, Epoch 170/170 => Loss 2.874, Loss_clf 0.300, Loss_fe 0.083, Loss_kd 2.429, Train_accy 87.46, Test_accy 65.95
2024-08-02 17:51:32,895 [foster.py] => do not weight align teacher!
2024-08-02 17:51:32,898 [foster.py] => per cls weights : [1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445 1.01326445
 1.01326445 1.01326445 0.46942216 0.46942216]
2024-08-02 17:51:38,096 [foster.py] => SNet: Task 16, Epoch 1/130 => Loss 29.939,  Loss1 0.760, Train_accy 56.73, Test_accy 63.02
2024-08-02 17:51:41,804 [foster.py] => SNet: Task 16, Epoch 2/130 => Loss 29.871,  Loss1 0.758, Train_accy 64.62
2024-08-02 17:51:45,491 [foster.py] => SNet: Task 16, Epoch 3/130 => Loss 29.853,  Loss1 0.758, Train_accy 63.27
2024-08-02 17:51:49,205 [foster.py] => SNet: Task 16, Epoch 4/130 => Loss 29.868,  Loss1 0.757, Train_accy 68.50
2024-08-02 17:51:52,945 [foster.py] => SNet: Task 16, Epoch 5/130 => Loss 29.858,  Loss1 0.757, Train_accy 68.85
2024-08-02 17:51:57,860 [foster.py] => SNet: Task 16, Epoch 6/130 => Loss 29.860,  Loss1 0.757, Train_accy 69.08, Test_accy 64.70
2024-08-02 17:52:01,584 [foster.py] => SNet: Task 16, Epoch 7/130 => Loss 29.853,  Loss1 0.757, Train_accy 70.08
2024-08-02 17:52:05,357 [foster.py] => SNet: Task 16, Epoch 8/130 => Loss 29.873,  Loss1 0.757, Train_accy 69.62
2024-08-02 17:52:09,067 [foster.py] => SNet: Task 16, Epoch 9/130 => Loss 29.843,  Loss1 0.757, Train_accy 70.65
2024-08-02 17:52:12,767 [foster.py] => SNet: Task 16, Epoch 10/130 => Loss 29.873,  Loss1 0.757, Train_accy 71.00
2024-08-02 17:52:17,679 [foster.py] => SNet: Task 16, Epoch 11/130 => Loss 29.833,  Loss1 0.756, Train_accy 71.35, Test_accy 64.94
2024-08-02 17:52:21,374 [foster.py] => SNet: Task 16, Epoch 12/130 => Loss 29.852,  Loss1 0.755, Train_accy 70.15
2024-08-02 17:52:25,081 [foster.py] => SNet: Task 16, Epoch 13/130 => Loss 29.832,  Loss1 0.756, Train_accy 72.08
2024-08-02 17:52:28,788 [foster.py] => SNet: Task 16, Epoch 14/130 => Loss 29.861,  Loss1 0.756, Train_accy 72.50
2024-08-02 17:52:32,487 [foster.py] => SNet: Task 16, Epoch 15/130 => Loss 29.862,  Loss1 0.756, Train_accy 71.92
2024-08-02 17:52:37,382 [foster.py] => SNet: Task 16, Epoch 16/130 => Loss 29.835,  Loss1 0.755, Train_accy 73.50, Test_accy 65.21
2024-08-02 17:52:41,200 [foster.py] => SNet: Task 16, Epoch 17/130 => Loss 29.810,  Loss1 0.756, Train_accy 72.73
2024-08-02 17:52:44,907 [foster.py] => SNet: Task 16, Epoch 18/130 => Loss 29.847,  Loss1 0.756, Train_accy 73.04
2024-08-02 17:52:48,625 [foster.py] => SNet: Task 16, Epoch 19/130 => Loss 29.806,  Loss1 0.756, Train_accy 73.85
2024-08-02 17:52:52,362 [foster.py] => SNet: Task 16, Epoch 20/130 => Loss 29.811,  Loss1 0.756, Train_accy 74.19
2024-08-02 17:52:57,260 [foster.py] => SNet: Task 16, Epoch 21/130 => Loss 29.873,  Loss1 0.756, Train_accy 73.31, Test_accy 65.21
2024-08-02 17:53:00,968 [foster.py] => SNet: Task 16, Epoch 22/130 => Loss 29.828,  Loss1 0.756, Train_accy 72.15
2024-08-02 17:53:04,731 [foster.py] => SNet: Task 16, Epoch 23/130 => Loss 29.836,  Loss1 0.756, Train_accy 73.81
2024-08-02 17:53:08,469 [foster.py] => SNet: Task 16, Epoch 24/130 => Loss 29.819,  Loss1 0.756, Train_accy 73.58
2024-08-02 17:53:12,169 [foster.py] => SNet: Task 16, Epoch 25/130 => Loss 29.873,  Loss1 0.756, Train_accy 73.50
2024-08-02 17:53:17,086 [foster.py] => SNet: Task 16, Epoch 26/130 => Loss 29.845,  Loss1 0.756, Train_accy 73.88, Test_accy 65.34
2024-08-02 17:53:20,807 [foster.py] => SNet: Task 16, Epoch 27/130 => Loss 29.840,  Loss1 0.756, Train_accy 73.65
2024-08-02 17:53:24,519 [foster.py] => SNet: Task 16, Epoch 28/130 => Loss 29.811,  Loss1 0.756, Train_accy 74.92
2024-08-02 17:53:28,241 [foster.py] => SNet: Task 16, Epoch 29/130 => Loss 29.812,  Loss1 0.756, Train_accy 74.85
2024-08-02 17:53:31,954 [foster.py] => SNet: Task 16, Epoch 30/130 => Loss 29.849,  Loss1 0.756, Train_accy 73.50
2024-08-02 17:53:36,921 [foster.py] => SNet: Task 16, Epoch 31/130 => Loss 29.832,  Loss1 0.756, Train_accy 75.15, Test_accy 65.15
2024-08-02 17:53:40,643 [foster.py] => SNet: Task 16, Epoch 32/130 => Loss 29.876,  Loss1 0.755, Train_accy 74.73
2024-08-02 17:53:44,377 [foster.py] => SNet: Task 16, Epoch 33/130 => Loss 29.844,  Loss1 0.755, Train_accy 74.19
2024-08-02 17:53:48,152 [foster.py] => SNet: Task 16, Epoch 34/130 => Loss 29.815,  Loss1 0.756, Train_accy 75.35
2024-08-02 17:53:51,929 [foster.py] => SNet: Task 16, Epoch 35/130 => Loss 29.863,  Loss1 0.755, Train_accy 74.12
2024-08-02 17:53:56,808 [foster.py] => SNet: Task 16, Epoch 36/130 => Loss 29.807,  Loss1 0.756, Train_accy 76.42, Test_accy 65.45
2024-08-02 17:54:00,508 [foster.py] => SNet: Task 16, Epoch 37/130 => Loss 29.843,  Loss1 0.756, Train_accy 74.54
2024-08-02 17:54:04,237 [foster.py] => SNet: Task 16, Epoch 38/130 => Loss 29.796,  Loss1 0.755, Train_accy 74.96
2024-08-02 17:54:07,958 [foster.py] => SNet: Task 16, Epoch 39/130 => Loss 29.839,  Loss1 0.755, Train_accy 74.35
2024-08-02 17:54:11,668 [foster.py] => SNet: Task 16, Epoch 40/130 => Loss 29.850,  Loss1 0.755, Train_accy 73.69
2024-08-02 17:54:16,566 [foster.py] => SNet: Task 16, Epoch 41/130 => Loss 29.847,  Loss1 0.755, Train_accy 74.31, Test_accy 65.21
2024-08-02 17:54:20,276 [foster.py] => SNet: Task 16, Epoch 42/130 => Loss 29.835,  Loss1 0.756, Train_accy 75.00
2024-08-02 17:54:23,998 [foster.py] => SNet: Task 16, Epoch 43/130 => Loss 29.857,  Loss1 0.755, Train_accy 74.23
2024-08-02 17:54:27,730 [foster.py] => SNet: Task 16, Epoch 44/130 => Loss 29.843,  Loss1 0.756, Train_accy 76.35
2024-08-02 17:54:31,473 [foster.py] => SNet: Task 16, Epoch 45/130 => Loss 29.832,  Loss1 0.756, Train_accy 75.65
2024-08-02 17:54:36,362 [foster.py] => SNet: Task 16, Epoch 46/130 => Loss 29.850,  Loss1 0.755, Train_accy 74.27, Test_accy 65.33
2024-08-02 17:54:40,142 [foster.py] => SNet: Task 16, Epoch 47/130 => Loss 29.870,  Loss1 0.755, Train_accy 75.58
2024-08-02 17:54:43,846 [foster.py] => SNet: Task 16, Epoch 48/130 => Loss 29.861,  Loss1 0.755, Train_accy 74.00
2024-08-02 17:54:47,565 [foster.py] => SNet: Task 16, Epoch 49/130 => Loss 29.811,  Loss1 0.755, Train_accy 75.54
2024-08-02 17:54:51,318 [foster.py] => SNet: Task 16, Epoch 50/130 => Loss 29.828,  Loss1 0.755, Train_accy 76.69
2024-08-02 17:54:56,249 [foster.py] => SNet: Task 16, Epoch 51/130 => Loss 29.826,  Loss1 0.756, Train_accy 75.65, Test_accy 65.13
2024-08-02 17:55:00,058 [foster.py] => SNet: Task 16, Epoch 52/130 => Loss 29.817,  Loss1 0.756, Train_accy 76.42
2024-08-02 17:55:03,815 [foster.py] => SNet: Task 16, Epoch 53/130 => Loss 29.811,  Loss1 0.756, Train_accy 76.27
2024-08-02 17:55:07,584 [foster.py] => SNet: Task 16, Epoch 54/130 => Loss 29.791,  Loss1 0.755, Train_accy 75.65
2024-08-02 17:55:11,303 [foster.py] => SNet: Task 16, Epoch 55/130 => Loss 29.785,  Loss1 0.755, Train_accy 75.23
2024-08-02 17:55:16,217 [foster.py] => SNet: Task 16, Epoch 56/130 => Loss 29.849,  Loss1 0.755, Train_accy 76.00, Test_accy 65.07
2024-08-02 17:55:19,940 [foster.py] => SNet: Task 16, Epoch 57/130 => Loss 29.825,  Loss1 0.755, Train_accy 77.88
2024-08-02 17:55:23,676 [foster.py] => SNet: Task 16, Epoch 58/130 => Loss 29.825,  Loss1 0.755, Train_accy 74.92
2024-08-02 17:55:27,382 [foster.py] => SNet: Task 16, Epoch 59/130 => Loss 29.837,  Loss1 0.755, Train_accy 76.15
2024-08-02 17:55:31,131 [foster.py] => SNet: Task 16, Epoch 60/130 => Loss 29.833,  Loss1 0.756, Train_accy 74.58
2024-08-02 17:55:36,048 [foster.py] => SNet: Task 16, Epoch 61/130 => Loss 29.889,  Loss1 0.755, Train_accy 75.73, Test_accy 65.33
2024-08-02 17:55:39,764 [foster.py] => SNet: Task 16, Epoch 62/130 => Loss 29.825,  Loss1 0.755, Train_accy 76.00
2024-08-02 17:55:43,493 [foster.py] => SNet: Task 16, Epoch 63/130 => Loss 29.812,  Loss1 0.755, Train_accy 75.42
2024-08-02 17:55:47,221 [foster.py] => SNet: Task 16, Epoch 64/130 => Loss 29.827,  Loss1 0.756, Train_accy 76.65
2024-08-02 17:55:50,953 [foster.py] => SNet: Task 16, Epoch 65/130 => Loss 29.862,  Loss1 0.755, Train_accy 76.58
2024-08-02 17:55:55,883 [foster.py] => SNet: Task 16, Epoch 66/130 => Loss 29.864,  Loss1 0.755, Train_accy 75.96, Test_accy 65.43
2024-08-02 17:55:59,579 [foster.py] => SNet: Task 16, Epoch 67/130 => Loss 29.826,  Loss1 0.755, Train_accy 76.85
2024-08-02 17:56:03,324 [foster.py] => SNet: Task 16, Epoch 68/130 => Loss 29.783,  Loss1 0.755, Train_accy 76.27
2024-08-02 17:56:07,039 [foster.py] => SNet: Task 16, Epoch 69/130 => Loss 29.810,  Loss1 0.755, Train_accy 75.73
2024-08-02 17:56:10,798 [foster.py] => SNet: Task 16, Epoch 70/130 => Loss 29.820,  Loss1 0.755, Train_accy 76.88
2024-08-02 17:56:15,729 [foster.py] => SNet: Task 16, Epoch 71/130 => Loss 29.851,  Loss1 0.756, Train_accy 75.38, Test_accy 65.13
2024-08-02 17:56:19,435 [foster.py] => SNet: Task 16, Epoch 72/130 => Loss 29.877,  Loss1 0.755, Train_accy 74.62
2024-08-02 17:56:23,152 [foster.py] => SNet: Task 16, Epoch 73/130 => Loss 29.844,  Loss1 0.755, Train_accy 75.96
2024-08-02 17:56:26,880 [foster.py] => SNet: Task 16, Epoch 74/130 => Loss 29.855,  Loss1 0.755, Train_accy 76.69
2024-08-02 17:56:30,574 [foster.py] => SNet: Task 16, Epoch 75/130 => Loss 29.861,  Loss1 0.755, Train_accy 76.35
2024-08-02 17:56:35,517 [foster.py] => SNet: Task 16, Epoch 76/130 => Loss 29.833,  Loss1 0.755, Train_accy 76.00, Test_accy 65.27
2024-08-02 17:56:39,225 [foster.py] => SNet: Task 16, Epoch 77/130 => Loss 29.820,  Loss1 0.755, Train_accy 77.27
2024-08-02 17:56:43,000 [foster.py] => SNet: Task 16, Epoch 78/130 => Loss 29.843,  Loss1 0.755, Train_accy 75.62
2024-08-02 17:56:46,720 [foster.py] => SNet: Task 16, Epoch 79/130 => Loss 29.785,  Loss1 0.755, Train_accy 76.69
2024-08-02 17:56:50,466 [foster.py] => SNet: Task 16, Epoch 80/130 => Loss 29.831,  Loss1 0.755, Train_accy 76.12
2024-08-02 17:56:55,401 [foster.py] => SNet: Task 16, Epoch 81/130 => Loss 29.838,  Loss1 0.755, Train_accy 77.08, Test_accy 65.20
2024-08-02 17:56:59,147 [foster.py] => SNet: Task 16, Epoch 82/130 => Loss 29.835,  Loss1 0.755, Train_accy 76.77
2024-08-02 17:57:02,899 [foster.py] => SNet: Task 16, Epoch 83/130 => Loss 29.844,  Loss1 0.754, Train_accy 77.58
2024-08-02 17:57:06,672 [foster.py] => SNet: Task 16, Epoch 84/130 => Loss 29.841,  Loss1 0.755, Train_accy 75.58
2024-08-02 17:57:10,444 [foster.py] => SNet: Task 16, Epoch 85/130 => Loss 29.868,  Loss1 0.755, Train_accy 76.08
2024-08-02 17:57:15,335 [foster.py] => SNet: Task 16, Epoch 86/130 => Loss 29.845,  Loss1 0.756, Train_accy 76.35, Test_accy 65.60
2024-08-02 17:57:19,077 [foster.py] => SNet: Task 16, Epoch 87/130 => Loss 29.826,  Loss1 0.755, Train_accy 76.69
2024-08-02 17:57:22,833 [foster.py] => SNet: Task 16, Epoch 88/130 => Loss 29.826,  Loss1 0.756, Train_accy 76.00
2024-08-02 17:57:26,566 [foster.py] => SNet: Task 16, Epoch 89/130 => Loss 29.798,  Loss1 0.754, Train_accy 75.62
2024-08-02 17:57:30,287 [foster.py] => SNet: Task 16, Epoch 90/130 => Loss 29.818,  Loss1 0.754, Train_accy 76.81
2024-08-02 17:57:35,169 [foster.py] => SNet: Task 16, Epoch 91/130 => Loss 29.803,  Loss1 0.755, Train_accy 76.12, Test_accy 65.70
2024-08-02 17:57:38,866 [foster.py] => SNet: Task 16, Epoch 92/130 => Loss 29.809,  Loss1 0.755, Train_accy 75.38
2024-08-02 17:57:42,574 [foster.py] => SNet: Task 16, Epoch 93/130 => Loss 29.890,  Loss1 0.755, Train_accy 75.65
2024-08-02 17:57:46,293 [foster.py] => SNet: Task 16, Epoch 94/130 => Loss 29.828,  Loss1 0.755, Train_accy 76.35
2024-08-02 17:57:50,003 [foster.py] => SNet: Task 16, Epoch 95/130 => Loss 29.856,  Loss1 0.755, Train_accy 76.46
2024-08-02 17:57:54,925 [foster.py] => SNet: Task 16, Epoch 96/130 => Loss 29.815,  Loss1 0.755, Train_accy 76.62, Test_accy 65.12
2024-08-02 17:57:58,630 [foster.py] => SNet: Task 16, Epoch 97/130 => Loss 29.806,  Loss1 0.755, Train_accy 78.50
2024-08-02 17:58:02,337 [foster.py] => SNet: Task 16, Epoch 98/130 => Loss 29.847,  Loss1 0.756, Train_accy 74.85
2024-08-02 17:58:06,091 [foster.py] => SNet: Task 16, Epoch 99/130 => Loss 29.841,  Loss1 0.755, Train_accy 76.42
2024-08-02 17:58:09,824 [foster.py] => SNet: Task 16, Epoch 100/130 => Loss 29.855,  Loss1 0.755, Train_accy 75.50
2024-08-02 17:58:14,742 [foster.py] => SNet: Task 16, Epoch 101/130 => Loss 29.823,  Loss1 0.756, Train_accy 75.96, Test_accy 65.52
2024-08-02 17:58:18,461 [foster.py] => SNet: Task 16, Epoch 102/130 => Loss 29.808,  Loss1 0.754, Train_accy 76.12
2024-08-02 17:58:22,193 [foster.py] => SNet: Task 16, Epoch 103/130 => Loss 29.830,  Loss1 0.755, Train_accy 77.27
2024-08-02 17:58:25,910 [foster.py] => SNet: Task 16, Epoch 104/130 => Loss 29.775,  Loss1 0.755, Train_accy 77.77
2024-08-02 17:58:29,662 [foster.py] => SNet: Task 16, Epoch 105/130 => Loss 29.827,  Loss1 0.755, Train_accy 76.04
2024-08-02 17:58:34,567 [foster.py] => SNet: Task 16, Epoch 106/130 => Loss 29.832,  Loss1 0.756, Train_accy 75.73, Test_accy 65.50
2024-08-02 17:58:38,305 [foster.py] => SNet: Task 16, Epoch 107/130 => Loss 29.809,  Loss1 0.755, Train_accy 76.42
2024-08-02 17:58:42,039 [foster.py] => SNet: Task 16, Epoch 108/130 => Loss 29.839,  Loss1 0.755, Train_accy 75.73
2024-08-02 17:58:45,755 [foster.py] => SNet: Task 16, Epoch 109/130 => Loss 29.793,  Loss1 0.755, Train_accy 76.58
2024-08-02 17:58:49,452 [foster.py] => SNet: Task 16, Epoch 110/130 => Loss 29.864,  Loss1 0.755, Train_accy 77.08
2024-08-02 17:58:54,392 [foster.py] => SNet: Task 16, Epoch 111/130 => Loss 29.869,  Loss1 0.755, Train_accy 77.38, Test_accy 65.50
2024-08-02 17:58:58,129 [foster.py] => SNet: Task 16, Epoch 112/130 => Loss 29.878,  Loss1 0.755, Train_accy 75.23
2024-08-02 17:59:01,862 [foster.py] => SNet: Task 16, Epoch 113/130 => Loss 29.806,  Loss1 0.755, Train_accy 77.23
2024-08-02 17:59:05,588 [foster.py] => SNet: Task 16, Epoch 114/130 => Loss 29.878,  Loss1 0.755, Train_accy 76.31
2024-08-02 17:59:09,300 [foster.py] => SNet: Task 16, Epoch 115/130 => Loss 29.844,  Loss1 0.754, Train_accy 76.38
2024-08-02 17:59:14,222 [foster.py] => SNet: Task 16, Epoch 116/130 => Loss 29.816,  Loss1 0.755, Train_accy 76.31, Test_accy 65.39
2024-08-02 17:59:17,943 [foster.py] => SNet: Task 16, Epoch 117/130 => Loss 29.839,  Loss1 0.755, Train_accy 75.85
2024-08-02 17:59:21,655 [foster.py] => SNet: Task 16, Epoch 118/130 => Loss 29.842,  Loss1 0.755, Train_accy 78.12
2024-08-02 17:59:25,370 [foster.py] => SNet: Task 16, Epoch 119/130 => Loss 29.794,  Loss1 0.754, Train_accy 76.27
2024-08-02 17:59:29,086 [foster.py] => SNet: Task 16, Epoch 120/130 => Loss 29.799,  Loss1 0.755, Train_accy 75.73
2024-08-02 17:59:34,015 [foster.py] => SNet: Task 16, Epoch 121/130 => Loss 29.824,  Loss1 0.755, Train_accy 76.23, Test_accy 65.39
2024-08-02 17:59:37,708 [foster.py] => SNet: Task 16, Epoch 122/130 => Loss 29.827,  Loss1 0.755, Train_accy 77.00
2024-08-02 17:59:41,466 [foster.py] => SNet: Task 16, Epoch 123/130 => Loss 29.852,  Loss1 0.755, Train_accy 76.65
2024-08-02 17:59:45,176 [foster.py] => SNet: Task 16, Epoch 124/130 => Loss 29.831,  Loss1 0.755, Train_accy 75.54
2024-08-02 17:59:48,869 [foster.py] => SNet: Task 16, Epoch 125/130 => Loss 29.818,  Loss1 0.756, Train_accy 76.27
2024-08-02 17:59:53,812 [foster.py] => SNet: Task 16, Epoch 126/130 => Loss 29.846,  Loss1 0.755, Train_accy 75.38, Test_accy 65.61
2024-08-02 17:59:57,507 [foster.py] => SNet: Task 16, Epoch 127/130 => Loss 29.806,  Loss1 0.755, Train_accy 75.54
2024-08-02 18:00:01,210 [foster.py] => SNet: Task 16, Epoch 128/130 => Loss 29.840,  Loss1 0.755, Train_accy 77.15
2024-08-02 18:00:04,928 [foster.py] => SNet: Task 16, Epoch 129/130 => Loss 29.810,  Loss1 0.755, Train_accy 76.27
2024-08-02 18:00:08,645 [foster.py] => SNet: Task 16, Epoch 130/130 => Loss 29.794,  Loss1 0.755, Train_accy 75.85
2024-08-02 18:00:08,646 [foster.py] => do not weight align student!
2024-08-02 18:00:09,834 [foster.py] => darknet eval: 
2024-08-02 18:00:09,834 [foster.py] => CNN top1 curve: 65.61
2024-08-02 18:00:09,834 [foster.py] => CNN top5 curve: 89.01
2024-08-02 18:00:09,835 [foster.py] => CNN top1 平均值: 65.61
2024-08-02 18:00:09,841 [foster.py] => timees : 1231.8514244556427
2024-08-02 18:00:09,842 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 18:00:35,109 [foster.py] => Exemplar size: 1640
2024-08-02 18:00:35,109 [trainer.py] => CNN: {'total': 65.95, '00-09': 73.2, '10-19': 56.6, '20-29': 72.3, '30-39': 65.5, '40-49': 70.6, '50-59': 54.6, '60-69': 69.1, '70-79': 62.8, '80-89': 80.5, 'old': 65.59, 'new': 80.5}
2024-08-02 18:00:35,110 [trainer.py] => NME: {'total': 60.26, '00-09': 64.2, '10-19': 46.3, '20-29': 63.0, '30-39': 56.1, '40-49': 63.7, '50-59': 51.9, '60-69': 70.2, '70-79': 60.2, '80-89': 92.5, 'old': 59.45, 'new': 92.5}
2024-08-02 18:00:35,110 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95]
2024-08-02 18:00:35,110 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54]
2024-08-02 18:00:35,110 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26]
2024-08-02 18:00:35,110 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16]

2024-08-02 18:00:35,110 [trainer.py] => CNN top1 平均值: 73.45
2024-08-02 18:00:35,112 [trainer.py] => All params: 1175656
2024-08-02 18:00:35,115 [trainer.py] => Trainable params: 593182
2024-08-02 18:00:35,175 [foster.py] => Learning on 82-84
2024-08-02 18:00:35,179 [foster.py] => All params: 1176174
2024-08-02 18:00:35,181 [foster.py] => Trainable params: 593570
2024-08-02 18:00:35,222 [foster.py] => per cls weights : [1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042 1.01090042
 1.01090042 1.01090042 1.01090042 1.01090042 0.55308293 0.55308293]
2024-08-02 18:00:37,919 [foster.py] => Task 17, Epoch 1/170 => Loss 4.947, Loss_clf 0.972, Loss_fe 1.527, Loss_kd 2.387, Train_accy 71.17
2024-08-02 18:00:42,517 [foster.py] => Task 17, Epoch 2/170 => Loss 3.671, Loss_clf 0.522, Loss_fe 0.708, Loss_kd 2.381, Train_accy 75.53, Test_accy 63.51
2024-08-02 18:00:47,073 [foster.py] => Task 17, Epoch 3/170 => Loss 3.523, Loss_clf 0.468, Loss_fe 0.590, Loss_kd 2.404, Train_accy 76.70, Test_accy 64.18
2024-08-02 18:00:51,653 [foster.py] => Task 17, Epoch 4/170 => Loss 3.412, Loss_clf 0.443, Loss_fe 0.520, Loss_kd 2.389, Train_accy 72.88, Test_accy 64.33
2024-08-02 18:00:56,285 [foster.py] => Task 17, Epoch 5/170 => Loss 3.243, Loss_clf 0.393, Loss_fe 0.456, Loss_kd 2.335, Train_accy 77.73, Test_accy 64.37
2024-08-02 18:00:58,975 [foster.py] => Task 17, Epoch 6/170 => Loss 3.340, Loss_clf 0.452, Loss_fe 0.421, Loss_kd 2.406, Train_accy 77.12
2024-08-02 18:01:03,577 [foster.py] => Task 17, Epoch 7/170 => Loss 3.218, Loss_clf 0.385, Loss_fe 0.392, Loss_kd 2.381, Train_accy 79.28, Test_accy 64.51
2024-08-02 18:01:08,205 [foster.py] => Task 17, Epoch 8/170 => Loss 3.161, Loss_clf 0.386, Loss_fe 0.361, Loss_kd 2.355, Train_accy 78.22, Test_accy 64.75
2024-08-02 18:01:12,878 [foster.py] => Task 17, Epoch 9/170 => Loss 3.230, Loss_clf 0.430, Loss_fe 0.366, Loss_kd 2.374, Train_accy 79.70, Test_accy 64.58
2024-08-02 18:01:17,464 [foster.py] => Task 17, Epoch 10/170 => Loss 3.212, Loss_clf 0.420, Loss_fe 0.368, Loss_kd 2.364, Train_accy 77.88, Test_accy 64.87
2024-08-02 18:01:20,141 [foster.py] => Task 17, Epoch 11/170 => Loss 3.198, Loss_clf 0.424, Loss_fe 0.341, Loss_kd 2.372, Train_accy 76.93
2024-08-02 18:01:24,744 [foster.py] => Task 17, Epoch 12/170 => Loss 3.173, Loss_clf 0.412, Loss_fe 0.328, Loss_kd 2.373, Train_accy 77.92, Test_accy 64.65
2024-08-02 18:01:29,341 [foster.py] => Task 17, Epoch 13/170 => Loss 3.130, Loss_clf 0.402, Loss_fe 0.305, Loss_kd 2.364, Train_accy 79.43, Test_accy 65.02
2024-08-02 18:01:33,923 [foster.py] => Task 17, Epoch 14/170 => Loss 3.136, Loss_clf 0.394, Loss_fe 0.298, Loss_kd 2.384, Train_accy 80.34, Test_accy 64.43
2024-08-02 18:01:38,533 [foster.py] => Task 17, Epoch 15/170 => Loss 3.129, Loss_clf 0.381, Loss_fe 0.314, Loss_kd 2.373, Train_accy 80.38, Test_accy 64.73
2024-08-02 18:01:41,204 [foster.py] => Task 17, Epoch 16/170 => Loss 3.079, Loss_clf 0.360, Loss_fe 0.300, Loss_kd 2.359, Train_accy 81.63
2024-08-02 18:01:45,781 [foster.py] => Task 17, Epoch 17/170 => Loss 3.055, Loss_clf 0.359, Loss_fe 0.271, Loss_kd 2.366, Train_accy 81.14, Test_accy 65.06
2024-08-02 18:01:50,409 [foster.py] => Task 17, Epoch 18/170 => Loss 3.109, Loss_clf 0.383, Loss_fe 0.304, Loss_kd 2.362, Train_accy 81.86, Test_accy 64.70
2024-08-02 18:01:55,026 [foster.py] => Task 17, Epoch 19/170 => Loss 3.100, Loss_clf 0.375, Loss_fe 0.278, Loss_kd 2.387, Train_accy 80.83, Test_accy 65.01
2024-08-02 18:01:59,626 [foster.py] => Task 17, Epoch 20/170 => Loss 3.078, Loss_clf 0.362, Loss_fe 0.284, Loss_kd 2.372, Train_accy 81.97, Test_accy 64.81
2024-08-02 18:02:02,412 [foster.py] => Task 17, Epoch 21/170 => Loss 3.149, Loss_clf 0.420, Loss_fe 0.278, Loss_kd 2.391, Train_accy 80.08
2024-08-02 18:02:07,117 [foster.py] => Task 17, Epoch 22/170 => Loss 3.125, Loss_clf 0.390, Loss_fe 0.268, Loss_kd 2.407, Train_accy 82.01, Test_accy 64.98
2024-08-02 18:02:11,705 [foster.py] => Task 17, Epoch 23/170 => Loss 3.117, Loss_clf 0.386, Loss_fe 0.271, Loss_kd 2.400, Train_accy 80.30, Test_accy 65.19
2024-08-02 18:02:16,321 [foster.py] => Task 17, Epoch 24/170 => Loss 3.041, Loss_clf 0.378, Loss_fe 0.241, Loss_kd 2.363, Train_accy 82.23, Test_accy 64.89
2024-08-02 18:02:20,926 [foster.py] => Task 17, Epoch 25/170 => Loss 3.062, Loss_clf 0.371, Loss_fe 0.250, Loss_kd 2.381, Train_accy 81.82, Test_accy 64.98
2024-08-02 18:02:23,628 [foster.py] => Task 17, Epoch 26/170 => Loss 3.053, Loss_clf 0.365, Loss_fe 0.240, Loss_kd 2.388, Train_accy 81.82
2024-08-02 18:02:28,240 [foster.py] => Task 17, Epoch 27/170 => Loss 3.076, Loss_clf 0.381, Loss_fe 0.240, Loss_kd 2.395, Train_accy 80.72, Test_accy 65.17
2024-08-02 18:02:32,844 [foster.py] => Task 17, Epoch 28/170 => Loss 3.068, Loss_clf 0.371, Loss_fe 0.267, Loss_kd 2.371, Train_accy 82.31, Test_accy 65.06
2024-08-02 18:02:37,493 [foster.py] => Task 17, Epoch 29/170 => Loss 3.021, Loss_clf 0.354, Loss_fe 0.225, Loss_kd 2.382, Train_accy 82.88, Test_accy 65.24
2024-08-02 18:02:42,057 [foster.py] => Task 17, Epoch 30/170 => Loss 3.026, Loss_clf 0.357, Loss_fe 0.231, Loss_kd 2.378, Train_accy 83.33, Test_accy 64.74
2024-08-02 18:02:44,734 [foster.py] => Task 17, Epoch 31/170 => Loss 3.037, Loss_clf 0.368, Loss_fe 0.241, Loss_kd 2.368, Train_accy 83.52
2024-08-02 18:02:49,327 [foster.py] => Task 17, Epoch 32/170 => Loss 3.011, Loss_clf 0.363, Loss_fe 0.227, Loss_kd 2.362, Train_accy 83.75, Test_accy 65.46
2024-08-02 18:02:53,914 [foster.py] => Task 17, Epoch 33/170 => Loss 3.072, Loss_clf 0.380, Loss_fe 0.234, Loss_kd 2.397, Train_accy 82.95, Test_accy 65.01
2024-08-02 18:02:58,516 [foster.py] => Task 17, Epoch 34/170 => Loss 2.984, Loss_clf 0.339, Loss_fe 0.216, Loss_kd 2.370, Train_accy 83.67, Test_accy 64.83
2024-08-02 18:03:03,117 [foster.py] => Task 17, Epoch 35/170 => Loss 3.028, Loss_clf 0.377, Loss_fe 0.230, Loss_kd 2.362, Train_accy 82.95, Test_accy 65.13
2024-08-02 18:03:05,809 [foster.py] => Task 17, Epoch 36/170 => Loss 3.007, Loss_clf 0.351, Loss_fe 0.229, Loss_kd 2.368, Train_accy 83.41
2024-08-02 18:03:10,403 [foster.py] => Task 17, Epoch 37/170 => Loss 3.017, Loss_clf 0.354, Loss_fe 0.226, Loss_kd 2.378, Train_accy 83.64, Test_accy 65.31
2024-08-02 18:03:15,012 [foster.py] => Task 17, Epoch 38/170 => Loss 3.040, Loss_clf 0.369, Loss_fe 0.217, Loss_kd 2.393, Train_accy 81.93, Test_accy 64.83
2024-08-02 18:03:19,614 [foster.py] => Task 17, Epoch 39/170 => Loss 2.974, Loss_clf 0.348, Loss_fe 0.192, Loss_kd 2.374, Train_accy 83.98, Test_accy 65.64
2024-08-02 18:03:24,233 [foster.py] => Task 17, Epoch 40/170 => Loss 2.987, Loss_clf 0.351, Loss_fe 0.208, Loss_kd 2.368, Train_accy 84.17, Test_accy 65.58
2024-08-02 18:03:26,908 [foster.py] => Task 17, Epoch 41/170 => Loss 2.997, Loss_clf 0.350, Loss_fe 0.191, Loss_kd 2.396, Train_accy 84.24
2024-08-02 18:03:31,496 [foster.py] => Task 17, Epoch 42/170 => Loss 2.977, Loss_clf 0.340, Loss_fe 0.207, Loss_kd 2.371, Train_accy 84.24, Test_accy 65.42
2024-08-02 18:03:36,098 [foster.py] => Task 17, Epoch 43/170 => Loss 2.979, Loss_clf 0.353, Loss_fe 0.195, Loss_kd 2.372, Train_accy 83.83, Test_accy 65.54
2024-08-02 18:03:40,670 [foster.py] => Task 17, Epoch 44/170 => Loss 2.997, Loss_clf 0.356, Loss_fe 0.195, Loss_kd 2.387, Train_accy 83.67, Test_accy 65.12
2024-08-02 18:03:45,263 [foster.py] => Task 17, Epoch 45/170 => Loss 2.981, Loss_clf 0.350, Loss_fe 0.184, Loss_kd 2.388, Train_accy 83.90, Test_accy 65.13
2024-08-02 18:03:47,975 [foster.py] => Task 17, Epoch 46/170 => Loss 2.974, Loss_clf 0.349, Loss_fe 0.202, Loss_kd 2.363, Train_accy 84.62
2024-08-02 18:03:52,613 [foster.py] => Task 17, Epoch 47/170 => Loss 2.919, Loss_clf 0.317, Loss_fe 0.177, Loss_kd 2.365, Train_accy 83.48, Test_accy 65.33
2024-08-02 18:03:57,210 [foster.py] => Task 17, Epoch 48/170 => Loss 2.938, Loss_clf 0.329, Loss_fe 0.187, Loss_kd 2.363, Train_accy 84.09, Test_accy 65.21
2024-08-02 18:04:01,866 [foster.py] => Task 17, Epoch 49/170 => Loss 2.975, Loss_clf 0.354, Loss_fe 0.186, Loss_kd 2.375, Train_accy 83.64, Test_accy 65.38
2024-08-02 18:04:06,516 [foster.py] => Task 17, Epoch 50/170 => Loss 2.968, Loss_clf 0.345, Loss_fe 0.184, Loss_kd 2.379, Train_accy 84.20, Test_accy 65.13
2024-08-02 18:04:09,205 [foster.py] => Task 17, Epoch 51/170 => Loss 2.951, Loss_clf 0.339, Loss_fe 0.182, Loss_kd 2.370, Train_accy 85.45
2024-08-02 18:04:13,801 [foster.py] => Task 17, Epoch 52/170 => Loss 2.951, Loss_clf 0.334, Loss_fe 0.203, Loss_kd 2.355, Train_accy 83.79, Test_accy 65.17
2024-08-02 18:04:18,417 [foster.py] => Task 17, Epoch 53/170 => Loss 2.934, Loss_clf 0.334, Loss_fe 0.181, Loss_kd 2.360, Train_accy 86.06, Test_accy 64.94
2024-08-02 18:04:23,053 [foster.py] => Task 17, Epoch 54/170 => Loss 2.921, Loss_clf 0.321, Loss_fe 0.169, Loss_kd 2.371, Train_accy 85.83, Test_accy 65.48
2024-08-02 18:04:27,648 [foster.py] => Task 17, Epoch 55/170 => Loss 2.948, Loss_clf 0.326, Loss_fe 0.179, Loss_kd 2.383, Train_accy 84.24, Test_accy 65.39
2024-08-02 18:04:30,360 [foster.py] => Task 17, Epoch 56/170 => Loss 2.919, Loss_clf 0.323, Loss_fe 0.168, Loss_kd 2.368, Train_accy 85.19
2024-08-02 18:04:34,965 [foster.py] => Task 17, Epoch 57/170 => Loss 2.960, Loss_clf 0.343, Loss_fe 0.168, Loss_kd 2.388, Train_accy 84.17, Test_accy 65.36
2024-08-02 18:04:39,577 [foster.py] => Task 17, Epoch 58/170 => Loss 2.996, Loss_clf 0.356, Loss_fe 0.191, Loss_kd 2.389, Train_accy 83.22, Test_accy 65.27
2024-08-02 18:04:44,140 [foster.py] => Task 17, Epoch 59/170 => Loss 2.881, Loss_clf 0.307, Loss_fe 0.175, Loss_kd 2.340, Train_accy 85.95, Test_accy 65.02
2024-08-02 18:04:48,741 [foster.py] => Task 17, Epoch 60/170 => Loss 2.887, Loss_clf 0.310, Loss_fe 0.170, Loss_kd 2.348, Train_accy 86.17, Test_accy 65.46
2024-08-02 18:04:51,427 [foster.py] => Task 17, Epoch 61/170 => Loss 2.924, Loss_clf 0.337, Loss_fe 0.168, Loss_kd 2.360, Train_accy 85.15
2024-08-02 18:04:56,025 [foster.py] => Task 17, Epoch 62/170 => Loss 2.926, Loss_clf 0.331, Loss_fe 0.163, Loss_kd 2.372, Train_accy 84.09, Test_accy 65.46
2024-08-02 18:05:00,604 [foster.py] => Task 17, Epoch 63/170 => Loss 3.003, Loss_clf 0.355, Loss_fe 0.179, Loss_kd 2.408, Train_accy 84.39, Test_accy 65.25
2024-08-02 18:05:05,183 [foster.py] => Task 17, Epoch 64/170 => Loss 2.977, Loss_clf 0.349, Loss_fe 0.181, Loss_kd 2.387, Train_accy 85.61, Test_accy 65.64
2024-08-02 18:05:09,847 [foster.py] => Task 17, Epoch 65/170 => Loss 2.926, Loss_clf 0.333, Loss_fe 0.162, Loss_kd 2.372, Train_accy 84.92, Test_accy 65.51
2024-08-02 18:05:12,638 [foster.py] => Task 17, Epoch 66/170 => Loss 2.950, Loss_clf 0.345, Loss_fe 0.160, Loss_kd 2.385, Train_accy 85.76
2024-08-02 18:05:17,275 [foster.py] => Task 17, Epoch 67/170 => Loss 2.924, Loss_clf 0.335, Loss_fe 0.152, Loss_kd 2.377, Train_accy 85.57, Test_accy 65.39
2024-08-02 18:05:21,869 [foster.py] => Task 17, Epoch 68/170 => Loss 2.959, Loss_clf 0.347, Loss_fe 0.180, Loss_kd 2.372, Train_accy 84.70, Test_accy 65.26
2024-08-02 18:05:26,519 [foster.py] => Task 17, Epoch 69/170 => Loss 2.932, Loss_clf 0.311, Loss_fe 0.165, Loss_kd 2.396, Train_accy 86.06, Test_accy 65.30
2024-08-02 18:05:31,193 [foster.py] => Task 17, Epoch 70/170 => Loss 2.923, Loss_clf 0.324, Loss_fe 0.160, Loss_kd 2.378, Train_accy 86.25, Test_accy 65.30
2024-08-02 18:05:33,856 [foster.py] => Task 17, Epoch 71/170 => Loss 2.929, Loss_clf 0.332, Loss_fe 0.143, Loss_kd 2.393, Train_accy 84.62
2024-08-02 18:05:38,448 [foster.py] => Task 17, Epoch 72/170 => Loss 2.879, Loss_clf 0.325, Loss_fe 0.144, Loss_kd 2.350, Train_accy 86.36, Test_accy 65.44
2024-08-02 18:05:43,026 [foster.py] => Task 17, Epoch 73/170 => Loss 2.935, Loss_clf 0.332, Loss_fe 0.161, Loss_kd 2.383, Train_accy 85.98, Test_accy 65.25
2024-08-02 18:05:47,663 [foster.py] => Task 17, Epoch 74/170 => Loss 2.893, Loss_clf 0.314, Loss_fe 0.145, Loss_kd 2.374, Train_accy 85.91, Test_accy 65.31
2024-08-02 18:05:52,247 [foster.py] => Task 17, Epoch 75/170 => Loss 2.896, Loss_clf 0.306, Loss_fe 0.145, Loss_kd 2.386, Train_accy 86.89, Test_accy 65.68
2024-08-02 18:05:54,919 [foster.py] => Task 17, Epoch 76/170 => Loss 2.957, Loss_clf 0.341, Loss_fe 0.145, Loss_kd 2.410, Train_accy 85.19
2024-08-02 18:05:59,485 [foster.py] => Task 17, Epoch 77/170 => Loss 2.943, Loss_clf 0.342, Loss_fe 0.150, Loss_kd 2.392, Train_accy 85.87, Test_accy 65.50
2024-08-02 18:06:04,096 [foster.py] => Task 17, Epoch 78/170 => Loss 2.963, Loss_clf 0.347, Loss_fe 0.136, Loss_kd 2.419, Train_accy 84.96, Test_accy 65.93
2024-08-02 18:06:08,660 [foster.py] => Task 17, Epoch 79/170 => Loss 2.879, Loss_clf 0.309, Loss_fe 0.141, Loss_kd 2.369, Train_accy 86.93, Test_accy 65.63
2024-08-02 18:06:13,219 [foster.py] => Task 17, Epoch 80/170 => Loss 2.928, Loss_clf 0.326, Loss_fe 0.148, Loss_kd 2.393, Train_accy 86.21, Test_accy 65.65
2024-08-02 18:06:15,969 [foster.py] => Task 17, Epoch 81/170 => Loss 2.910, Loss_clf 0.327, Loss_fe 0.129, Loss_kd 2.394, Train_accy 86.82
2024-08-02 18:06:20,618 [foster.py] => Task 17, Epoch 82/170 => Loss 2.914, Loss_clf 0.340, Loss_fe 0.143, Loss_kd 2.370, Train_accy 85.38, Test_accy 65.39
2024-08-02 18:06:25,261 [foster.py] => Task 17, Epoch 83/170 => Loss 2.908, Loss_clf 0.323, Loss_fe 0.150, Loss_kd 2.375, Train_accy 86.52, Test_accy 65.27
2024-08-02 18:06:29,898 [foster.py] => Task 17, Epoch 84/170 => Loss 2.890, Loss_clf 0.315, Loss_fe 0.149, Loss_kd 2.367, Train_accy 84.70, Test_accy 65.63
2024-08-02 18:06:34,504 [foster.py] => Task 17, Epoch 85/170 => Loss 2.867, Loss_clf 0.305, Loss_fe 0.122, Loss_kd 2.380, Train_accy 87.12, Test_accy 65.36
2024-08-02 18:06:37,192 [foster.py] => Task 17, Epoch 86/170 => Loss 2.845, Loss_clf 0.303, Loss_fe 0.121, Loss_kd 2.361, Train_accy 85.83
2024-08-02 18:06:41,807 [foster.py] => Task 17, Epoch 87/170 => Loss 2.860, Loss_clf 0.314, Loss_fe 0.121, Loss_kd 2.366, Train_accy 86.55, Test_accy 65.57
2024-08-02 18:06:46,377 [foster.py] => Task 17, Epoch 88/170 => Loss 2.903, Loss_clf 0.327, Loss_fe 0.142, Loss_kd 2.374, Train_accy 85.87, Test_accy 65.52
2024-08-02 18:06:51,062 [foster.py] => Task 17, Epoch 89/170 => Loss 2.913, Loss_clf 0.323, Loss_fe 0.144, Loss_kd 2.386, Train_accy 85.87, Test_accy 65.44
2024-08-02 18:06:55,709 [foster.py] => Task 17, Epoch 90/170 => Loss 2.900, Loss_clf 0.317, Loss_fe 0.127, Loss_kd 2.395, Train_accy 87.99, Test_accy 65.58
2024-08-02 18:06:58,412 [foster.py] => Task 17, Epoch 91/170 => Loss 2.872, Loss_clf 0.312, Loss_fe 0.122, Loss_kd 2.378, Train_accy 87.16
2024-08-02 18:07:03,031 [foster.py] => Task 17, Epoch 92/170 => Loss 2.849, Loss_clf 0.296, Loss_fe 0.135, Loss_kd 2.359, Train_accy 86.40, Test_accy 65.73
2024-08-02 18:07:07,642 [foster.py] => Task 17, Epoch 93/170 => Loss 2.866, Loss_clf 0.308, Loss_fe 0.122, Loss_kd 2.376, Train_accy 86.02, Test_accy 65.56
2024-08-02 18:07:12,200 [foster.py] => Task 17, Epoch 94/170 => Loss 2.864, Loss_clf 0.304, Loss_fe 0.119, Loss_kd 2.382, Train_accy 87.69, Test_accy 65.44
2024-08-02 18:07:16,815 [foster.py] => Task 17, Epoch 95/170 => Loss 2.858, Loss_clf 0.309, Loss_fe 0.116, Loss_kd 2.374, Train_accy 86.89, Test_accy 65.49
2024-08-02 18:07:19,518 [foster.py] => Task 17, Epoch 96/170 => Loss 2.878, Loss_clf 0.319, Loss_fe 0.126, Loss_kd 2.374, Train_accy 86.97
2024-08-02 18:07:24,102 [foster.py] => Task 17, Epoch 97/170 => Loss 2.866, Loss_clf 0.308, Loss_fe 0.112, Loss_kd 2.386, Train_accy 87.23, Test_accy 65.54
2024-08-02 18:07:28,736 [foster.py] => Task 17, Epoch 98/170 => Loss 2.867, Loss_clf 0.314, Loss_fe 0.126, Loss_kd 2.369, Train_accy 86.82, Test_accy 65.76
2024-08-02 18:07:33,338 [foster.py] => Task 17, Epoch 99/170 => Loss 2.907, Loss_clf 0.329, Loss_fe 0.134, Loss_kd 2.385, Train_accy 86.97, Test_accy 65.60
2024-08-02 18:07:37,960 [foster.py] => Task 17, Epoch 100/170 => Loss 2.877, Loss_clf 0.306, Loss_fe 0.129, Loss_kd 2.383, Train_accy 86.93, Test_accy 65.60
2024-08-02 18:07:40,630 [foster.py] => Task 17, Epoch 101/170 => Loss 2.871, Loss_clf 0.317, Loss_fe 0.114, Loss_kd 2.380, Train_accy 87.35
2024-08-02 18:07:45,295 [foster.py] => Task 17, Epoch 102/170 => Loss 2.836, Loss_clf 0.287, Loss_fe 0.115, Loss_kd 2.374, Train_accy 87.65, Test_accy 65.76
2024-08-02 18:07:49,926 [foster.py] => Task 17, Epoch 103/170 => Loss 2.859, Loss_clf 0.312, Loss_fe 0.105, Loss_kd 2.383, Train_accy 86.82, Test_accy 65.88
2024-08-02 18:07:54,541 [foster.py] => Task 17, Epoch 104/170 => Loss 2.846, Loss_clf 0.307, Loss_fe 0.108, Loss_kd 2.373, Train_accy 87.77, Test_accy 65.44
2024-08-02 18:07:59,113 [foster.py] => Task 17, Epoch 105/170 => Loss 2.841, Loss_clf 0.298, Loss_fe 0.133, Loss_kd 2.352, Train_accy 86.89, Test_accy 65.64
2024-08-02 18:08:01,850 [foster.py] => Task 17, Epoch 106/170 => Loss 2.849, Loss_clf 0.306, Loss_fe 0.113, Loss_kd 2.371, Train_accy 87.84
2024-08-02 18:08:06,432 [foster.py] => Task 17, Epoch 107/170 => Loss 2.874, Loss_clf 0.316, Loss_fe 0.106, Loss_kd 2.391, Train_accy 87.01, Test_accy 65.49
2024-08-02 18:08:11,034 [foster.py] => Task 17, Epoch 108/170 => Loss 2.785, Loss_clf 0.291, Loss_fe 0.094, Loss_kd 2.342, Train_accy 87.54, Test_accy 65.73
2024-08-02 18:08:15,659 [foster.py] => Task 17, Epoch 109/170 => Loss 2.845, Loss_clf 0.295, Loss_fe 0.107, Loss_kd 2.383, Train_accy 88.41, Test_accy 65.50
2024-08-02 18:08:20,242 [foster.py] => Task 17, Epoch 110/170 => Loss 2.862, Loss_clf 0.303, Loss_fe 0.123, Loss_kd 2.376, Train_accy 87.01, Test_accy 65.60
2024-08-02 18:08:22,961 [foster.py] => Task 17, Epoch 111/170 => Loss 2.894, Loss_clf 0.318, Loss_fe 0.122, Loss_kd 2.393, Train_accy 87.50
2024-08-02 18:08:27,568 [foster.py] => Task 17, Epoch 112/170 => Loss 2.849, Loss_clf 0.302, Loss_fe 0.102, Loss_kd 2.384, Train_accy 87.54, Test_accy 65.75
2024-08-02 18:08:32,225 [foster.py] => Task 17, Epoch 113/170 => Loss 2.801, Loss_clf 0.289, Loss_fe 0.094, Loss_kd 2.359, Train_accy 88.71, Test_accy 65.69
2024-08-02 18:08:36,910 [foster.py] => Task 17, Epoch 114/170 => Loss 2.864, Loss_clf 0.306, Loss_fe 0.106, Loss_kd 2.392, Train_accy 86.74, Test_accy 65.68
2024-08-02 18:08:41,504 [foster.py] => Task 17, Epoch 115/170 => Loss 2.831, Loss_clf 0.304, Loss_fe 0.102, Loss_kd 2.366, Train_accy 88.03, Test_accy 65.81
2024-08-02 18:08:44,177 [foster.py] => Task 17, Epoch 116/170 => Loss 2.840, Loss_clf 0.302, Loss_fe 0.099, Loss_kd 2.380, Train_accy 87.42
2024-08-02 18:08:48,781 [foster.py] => Task 17, Epoch 117/170 => Loss 2.844, Loss_clf 0.311, Loss_fe 0.103, Loss_kd 2.370, Train_accy 87.01, Test_accy 65.79
2024-08-02 18:08:53,349 [foster.py] => Task 17, Epoch 118/170 => Loss 2.849, Loss_clf 0.303, Loss_fe 0.101, Loss_kd 2.384, Train_accy 86.44, Test_accy 65.83
2024-08-02 18:08:57,933 [foster.py] => Task 17, Epoch 119/170 => Loss 2.879, Loss_clf 0.322, Loss_fe 0.108, Loss_kd 2.388, Train_accy 86.44, Test_accy 66.01
2024-08-02 18:09:02,562 [foster.py] => Task 17, Epoch 120/170 => Loss 2.766, Loss_clf 0.274, Loss_fe 0.091, Loss_kd 2.342, Train_accy 87.99, Test_accy 65.73
2024-08-02 18:09:05,261 [foster.py] => Task 17, Epoch 121/170 => Loss 2.858, Loss_clf 0.316, Loss_fe 0.094, Loss_kd 2.388, Train_accy 87.31
2024-08-02 18:09:09,864 [foster.py] => Task 17, Epoch 122/170 => Loss 2.885, Loss_clf 0.323, Loss_fe 0.100, Loss_kd 2.402, Train_accy 86.33, Test_accy 65.71
2024-08-02 18:09:14,415 [foster.py] => Task 17, Epoch 123/170 => Loss 2.773, Loss_clf 0.260, Loss_fe 0.090, Loss_kd 2.363, Train_accy 89.20, Test_accy 65.63
2024-08-02 18:09:19,070 [foster.py] => Task 17, Epoch 124/170 => Loss 2.811, Loss_clf 0.282, Loss_fe 0.079, Loss_kd 2.390, Train_accy 88.60, Test_accy 65.62
2024-08-02 18:09:23,673 [foster.py] => Task 17, Epoch 125/170 => Loss 2.846, Loss_clf 0.295, Loss_fe 0.099, Loss_kd 2.392, Train_accy 88.37, Test_accy 65.61
2024-08-02 18:09:26,371 [foster.py] => Task 17, Epoch 126/170 => Loss 2.784, Loss_clf 0.290, Loss_fe 0.085, Loss_kd 2.351, Train_accy 88.56
2024-08-02 18:09:31,078 [foster.py] => Task 17, Epoch 127/170 => Loss 2.753, Loss_clf 0.276, Loss_fe 0.081, Loss_kd 2.337, Train_accy 88.11, Test_accy 65.63
2024-08-02 18:09:35,658 [foster.py] => Task 17, Epoch 128/170 => Loss 2.875, Loss_clf 0.319, Loss_fe 0.103, Loss_kd 2.393, Train_accy 88.18, Test_accy 65.74
2024-08-02 18:09:40,242 [foster.py] => Task 17, Epoch 129/170 => Loss 2.818, Loss_clf 0.301, Loss_fe 0.092, Loss_kd 2.366, Train_accy 87.84, Test_accy 65.63
2024-08-02 18:09:44,868 [foster.py] => Task 17, Epoch 130/170 => Loss 2.791, Loss_clf 0.277, Loss_fe 0.072, Loss_kd 2.382, Train_accy 88.67, Test_accy 65.70
2024-08-02 18:09:47,522 [foster.py] => Task 17, Epoch 131/170 => Loss 2.855, Loss_clf 0.312, Loss_fe 0.089, Loss_kd 2.395, Train_accy 87.54
2024-08-02 18:09:52,113 [foster.py] => Task 17, Epoch 132/170 => Loss 2.783, Loss_clf 0.276, Loss_fe 0.090, Loss_kd 2.358, Train_accy 88.56, Test_accy 65.67
2024-08-02 18:09:56,723 [foster.py] => Task 17, Epoch 133/170 => Loss 2.797, Loss_clf 0.282, Loss_fe 0.082, Loss_kd 2.373, Train_accy 89.66, Test_accy 65.52
2024-08-02 18:10:01,316 [foster.py] => Task 17, Epoch 134/170 => Loss 2.849, Loss_clf 0.301, Loss_fe 0.086, Loss_kd 2.401, Train_accy 88.33, Test_accy 65.57
2024-08-02 18:10:05,942 [foster.py] => Task 17, Epoch 135/170 => Loss 2.796, Loss_clf 0.289, Loss_fe 0.092, Loss_kd 2.356, Train_accy 88.67, Test_accy 65.54
2024-08-02 18:10:08,644 [foster.py] => Task 17, Epoch 136/170 => Loss 2.842, Loss_clf 0.295, Loss_fe 0.097, Loss_kd 2.390, Train_accy 88.75
2024-08-02 18:10:13,241 [foster.py] => Task 17, Epoch 137/170 => Loss 2.794, Loss_clf 0.271, Loss_fe 0.071, Loss_kd 2.391, Train_accy 89.20, Test_accy 65.63
2024-08-02 18:10:17,824 [foster.py] => Task 17, Epoch 138/170 => Loss 2.746, Loss_clf 0.251, Loss_fe 0.081, Loss_kd 2.354, Train_accy 89.36, Test_accy 65.48
2024-08-02 18:10:22,406 [foster.py] => Task 17, Epoch 139/170 => Loss 2.780, Loss_clf 0.278, Loss_fe 0.089, Loss_kd 2.353, Train_accy 88.71, Test_accy 65.57
2024-08-02 18:10:27,022 [foster.py] => Task 17, Epoch 140/170 => Loss 2.817, Loss_clf 0.303, Loss_fe 0.094, Loss_kd 2.361, Train_accy 88.11, Test_accy 65.62
2024-08-02 18:10:29,748 [foster.py] => Task 17, Epoch 141/170 => Loss 2.824, Loss_clf 0.290, Loss_fe 0.088, Loss_kd 2.387, Train_accy 88.71
2024-08-02 18:10:34,332 [foster.py] => Task 17, Epoch 142/170 => Loss 2.806, Loss_clf 0.286, Loss_fe 0.077, Loss_kd 2.383, Train_accy 89.13, Test_accy 65.71
2024-08-02 18:10:38,911 [foster.py] => Task 17, Epoch 143/170 => Loss 2.786, Loss_clf 0.273, Loss_fe 0.075, Loss_kd 2.379, Train_accy 89.02, Test_accy 65.69
2024-08-02 18:10:43,516 [foster.py] => Task 17, Epoch 144/170 => Loss 2.785, Loss_clf 0.276, Loss_fe 0.088, Loss_kd 2.362, Train_accy 88.83, Test_accy 65.76
2024-08-02 18:10:48,087 [foster.py] => Task 17, Epoch 145/170 => Loss 2.802, Loss_clf 0.284, Loss_fe 0.081, Loss_kd 2.377, Train_accy 88.45, Test_accy 65.69
2024-08-02 18:10:50,817 [foster.py] => Task 17, Epoch 146/170 => Loss 2.760, Loss_clf 0.280, Loss_fe 0.085, Loss_kd 2.336, Train_accy 88.52
2024-08-02 18:10:55,394 [foster.py] => Task 17, Epoch 147/170 => Loss 2.796, Loss_clf 0.281, Loss_fe 0.081, Loss_kd 2.375, Train_accy 88.71, Test_accy 65.75
2024-08-02 18:11:00,022 [foster.py] => Task 17, Epoch 148/170 => Loss 2.811, Loss_clf 0.291, Loss_fe 0.092, Loss_kd 2.368, Train_accy 88.67, Test_accy 65.73
2024-08-02 18:11:04,622 [foster.py] => Task 17, Epoch 149/170 => Loss 2.784, Loss_clf 0.285, Loss_fe 0.067, Loss_kd 2.372, Train_accy 87.61, Test_accy 65.76
2024-08-02 18:11:09,257 [foster.py] => Task 17, Epoch 150/170 => Loss 2.808, Loss_clf 0.285, Loss_fe 0.069, Loss_kd 2.393, Train_accy 88.98, Test_accy 65.71
2024-08-02 18:11:11,914 [foster.py] => Task 17, Epoch 151/170 => Loss 2.826, Loss_clf 0.298, Loss_fe 0.088, Loss_kd 2.381, Train_accy 88.41
2024-08-02 18:11:16,482 [foster.py] => Task 17, Epoch 152/170 => Loss 2.867, Loss_clf 0.317, Loss_fe 0.086, Loss_kd 2.404, Train_accy 87.84, Test_accy 65.69
2024-08-02 18:11:21,064 [foster.py] => Task 17, Epoch 153/170 => Loss 2.863, Loss_clf 0.317, Loss_fe 0.088, Loss_kd 2.398, Train_accy 87.50, Test_accy 65.70
2024-08-02 18:11:25,656 [foster.py] => Task 17, Epoch 154/170 => Loss 2.799, Loss_clf 0.292, Loss_fe 0.075, Loss_kd 2.373, Train_accy 88.64, Test_accy 65.74
2024-08-02 18:11:30,244 [foster.py] => Task 17, Epoch 155/170 => Loss 2.778, Loss_clf 0.277, Loss_fe 0.088, Loss_kd 2.353, Train_accy 89.17, Test_accy 65.75
2024-08-02 18:11:32,902 [foster.py] => Task 17, Epoch 156/170 => Loss 2.829, Loss_clf 0.295, Loss_fe 0.090, Loss_kd 2.384, Train_accy 88.37
2024-08-02 18:11:37,474 [foster.py] => Task 17, Epoch 157/170 => Loss 2.826, Loss_clf 0.286, Loss_fe 0.078, Loss_kd 2.401, Train_accy 89.70, Test_accy 65.76
2024-08-02 18:11:42,021 [foster.py] => Task 17, Epoch 158/170 => Loss 2.822, Loss_clf 0.301, Loss_fe 0.086, Loss_kd 2.376, Train_accy 88.07, Test_accy 65.74
2024-08-02 18:11:46,610 [foster.py] => Task 17, Epoch 159/170 => Loss 2.789, Loss_clf 0.262, Loss_fe 0.078, Loss_kd 2.390, Train_accy 89.66, Test_accy 65.70
2024-08-02 18:11:51,180 [foster.py] => Task 17, Epoch 160/170 => Loss 2.764, Loss_clf 0.263, Loss_fe 0.079, Loss_kd 2.363, Train_accy 89.24, Test_accy 65.74
2024-08-02 18:11:53,952 [foster.py] => Task 17, Epoch 161/170 => Loss 2.810, Loss_clf 0.291, Loss_fe 0.089, Loss_kd 2.371, Train_accy 87.69
2024-08-02 18:11:58,638 [foster.py] => Task 17, Epoch 162/170 => Loss 2.798, Loss_clf 0.292, Loss_fe 0.077, Loss_kd 2.370, Train_accy 88.07, Test_accy 65.71
2024-08-02 18:12:03,298 [foster.py] => Task 17, Epoch 163/170 => Loss 2.795, Loss_clf 0.288, Loss_fe 0.081, Loss_kd 2.368, Train_accy 88.64, Test_accy 65.75
2024-08-02 18:12:07,939 [foster.py] => Task 17, Epoch 164/170 => Loss 2.802, Loss_clf 0.289, Loss_fe 0.087, Loss_kd 2.366, Train_accy 88.56, Test_accy 65.73
2024-08-02 18:12:12,518 [foster.py] => Task 17, Epoch 165/170 => Loss 2.820, Loss_clf 0.288, Loss_fe 0.085, Loss_kd 2.387, Train_accy 88.67, Test_accy 65.73
2024-08-02 18:12:15,174 [foster.py] => Task 17, Epoch 166/170 => Loss 2.802, Loss_clf 0.293, Loss_fe 0.062, Loss_kd 2.387, Train_accy 88.67
2024-08-02 18:12:19,778 [foster.py] => Task 17, Epoch 167/170 => Loss 2.833, Loss_clf 0.309, Loss_fe 0.075, Loss_kd 2.389, Train_accy 87.88, Test_accy 65.70
2024-08-02 18:12:24,340 [foster.py] => Task 17, Epoch 168/170 => Loss 2.815, Loss_clf 0.281, Loss_fe 0.084, Loss_kd 2.390, Train_accy 88.98, Test_accy 65.77
2024-08-02 18:12:28,931 [foster.py] => Task 17, Epoch 169/170 => Loss 2.801, Loss_clf 0.292, Loss_fe 0.074, Loss_kd 2.376, Train_accy 88.03, Test_accy 65.75
2024-08-02 18:12:33,617 [foster.py] => Task 17, Epoch 170/170 => Loss 2.790, Loss_clf 0.274, Loss_fe 0.064, Loss_kd 2.392, Train_accy 89.55, Test_accy 65.73
2024-08-02 18:12:33,621 [foster.py] => do not weight align teacher!
2024-08-02 18:12:33,624 [foster.py] => per cls weights : [1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454 1.01294454
 1.01294454 1.01294454 1.01294454 1.01294454 0.46927395 0.46927395]
2024-08-02 18:12:38,768 [foster.py] => SNet: Task 17, Epoch 1/130 => Loss 30.112,  Loss1 0.758, Train_accy 56.17, Test_accy 61.81
2024-08-02 18:12:42,486 [foster.py] => SNet: Task 17, Epoch 2/130 => Loss 29.984,  Loss1 0.754, Train_accy 66.70
2024-08-02 18:12:46,197 [foster.py] => SNet: Task 17, Epoch 3/130 => Loss 29.957,  Loss1 0.755, Train_accy 66.10
2024-08-02 18:12:49,932 [foster.py] => SNet: Task 17, Epoch 4/130 => Loss 29.958,  Loss1 0.754, Train_accy 67.65
2024-08-02 18:12:53,694 [foster.py] => SNet: Task 17, Epoch 5/130 => Loss 29.942,  Loss1 0.754, Train_accy 69.32
2024-08-02 18:12:58,609 [foster.py] => SNet: Task 17, Epoch 6/130 => Loss 29.943,  Loss1 0.754, Train_accy 69.13, Test_accy 63.89
2024-08-02 18:13:02,357 [foster.py] => SNet: Task 17, Epoch 7/130 => Loss 29.970,  Loss1 0.754, Train_accy 70.11
2024-08-02 18:13:06,067 [foster.py] => SNet: Task 17, Epoch 8/130 => Loss 29.978,  Loss1 0.754, Train_accy 70.68
2024-08-02 18:13:09,798 [foster.py] => SNet: Task 17, Epoch 9/130 => Loss 29.899,  Loss1 0.754, Train_accy 72.77
2024-08-02 18:13:13,506 [foster.py] => SNet: Task 17, Epoch 10/130 => Loss 29.944,  Loss1 0.754, Train_accy 71.97
2024-08-02 18:13:18,448 [foster.py] => SNet: Task 17, Epoch 11/130 => Loss 29.979,  Loss1 0.754, Train_accy 71.70, Test_accy 64.19
2024-08-02 18:13:22,205 [foster.py] => SNet: Task 17, Epoch 12/130 => Loss 29.941,  Loss1 0.754, Train_accy 71.93
2024-08-02 18:13:25,947 [foster.py] => SNet: Task 17, Epoch 13/130 => Loss 29.962,  Loss1 0.754, Train_accy 74.02
2024-08-02 18:13:29,754 [foster.py] => SNet: Task 17, Epoch 14/130 => Loss 29.974,  Loss1 0.754, Train_accy 73.33
2024-08-02 18:13:33,484 [foster.py] => SNet: Task 17, Epoch 15/130 => Loss 29.958,  Loss1 0.754, Train_accy 71.78
2024-08-02 18:13:38,408 [foster.py] => SNet: Task 17, Epoch 16/130 => Loss 29.903,  Loss1 0.754, Train_accy 74.70, Test_accy 64.45
2024-08-02 18:13:42,151 [foster.py] => SNet: Task 17, Epoch 17/130 => Loss 29.920,  Loss1 0.754, Train_accy 74.85
2024-08-02 18:13:45,878 [foster.py] => SNet: Task 17, Epoch 18/130 => Loss 29.960,  Loss1 0.754, Train_accy 73.41
2024-08-02 18:13:49,585 [foster.py] => SNet: Task 17, Epoch 19/130 => Loss 29.967,  Loss1 0.754, Train_accy 74.58
2024-08-02 18:13:53,313 [foster.py] => SNet: Task 17, Epoch 20/130 => Loss 29.935,  Loss1 0.754, Train_accy 74.20
2024-08-02 18:13:58,251 [foster.py] => SNet: Task 17, Epoch 21/130 => Loss 29.952,  Loss1 0.754, Train_accy 75.23, Test_accy 64.81
2024-08-02 18:14:01,986 [foster.py] => SNet: Task 17, Epoch 22/130 => Loss 30.007,  Loss1 0.754, Train_accy 72.95
2024-08-02 18:14:05,688 [foster.py] => SNet: Task 17, Epoch 23/130 => Loss 29.973,  Loss1 0.754, Train_accy 75.72
2024-08-02 18:14:09,414 [foster.py] => SNet: Task 17, Epoch 24/130 => Loss 29.912,  Loss1 0.754, Train_accy 75.42
2024-08-02 18:14:13,155 [foster.py] => SNet: Task 17, Epoch 25/130 => Loss 29.947,  Loss1 0.754, Train_accy 75.64
2024-08-02 18:14:18,113 [foster.py] => SNet: Task 17, Epoch 26/130 => Loss 29.929,  Loss1 0.754, Train_accy 75.30, Test_accy 64.68
2024-08-02 18:14:21,854 [foster.py] => SNet: Task 17, Epoch 27/130 => Loss 29.916,  Loss1 0.754, Train_accy 75.08
2024-08-02 18:14:25,597 [foster.py] => SNet: Task 17, Epoch 28/130 => Loss 29.944,  Loss1 0.754, Train_accy 76.10
2024-08-02 18:14:29,308 [foster.py] => SNet: Task 17, Epoch 29/130 => Loss 29.961,  Loss1 0.754, Train_accy 76.17
2024-08-02 18:14:33,049 [foster.py] => SNet: Task 17, Epoch 30/130 => Loss 29.941,  Loss1 0.754, Train_accy 75.91
2024-08-02 18:14:38,019 [foster.py] => SNet: Task 17, Epoch 31/130 => Loss 29.938,  Loss1 0.754, Train_accy 75.19, Test_accy 64.89
2024-08-02 18:14:41,734 [foster.py] => SNet: Task 17, Epoch 32/130 => Loss 29.960,  Loss1 0.754, Train_accy 75.23
2024-08-02 18:14:45,460 [foster.py] => SNet: Task 17, Epoch 33/130 => Loss 29.907,  Loss1 0.753, Train_accy 75.76
2024-08-02 18:14:49,192 [foster.py] => SNet: Task 17, Epoch 34/130 => Loss 29.935,  Loss1 0.754, Train_accy 75.83
2024-08-02 18:14:52,924 [foster.py] => SNet: Task 17, Epoch 35/130 => Loss 29.945,  Loss1 0.754, Train_accy 76.25
2024-08-02 18:14:57,867 [foster.py] => SNet: Task 17, Epoch 36/130 => Loss 30.006,  Loss1 0.754, Train_accy 75.11, Test_accy 64.69
2024-08-02 18:15:01,601 [foster.py] => SNet: Task 17, Epoch 37/130 => Loss 29.963,  Loss1 0.754, Train_accy 77.35
2024-08-02 18:15:05,359 [foster.py] => SNet: Task 17, Epoch 38/130 => Loss 29.949,  Loss1 0.754, Train_accy 74.51
2024-08-02 18:15:09,113 [foster.py] => SNet: Task 17, Epoch 39/130 => Loss 29.909,  Loss1 0.753, Train_accy 76.29
2024-08-02 18:15:12,860 [foster.py] => SNet: Task 17, Epoch 40/130 => Loss 29.871,  Loss1 0.753, Train_accy 76.70
2024-08-02 18:15:17,854 [foster.py] => SNet: Task 17, Epoch 41/130 => Loss 29.936,  Loss1 0.754, Train_accy 76.40, Test_accy 64.83
2024-08-02 18:15:21,598 [foster.py] => SNet: Task 17, Epoch 42/130 => Loss 29.922,  Loss1 0.754, Train_accy 77.01
2024-08-02 18:15:25,327 [foster.py] => SNet: Task 17, Epoch 43/130 => Loss 29.919,  Loss1 0.753, Train_accy 76.40
2024-08-02 18:15:29,048 [foster.py] => SNet: Task 17, Epoch 44/130 => Loss 29.943,  Loss1 0.754, Train_accy 76.67
2024-08-02 18:15:32,787 [foster.py] => SNet: Task 17, Epoch 45/130 => Loss 29.937,  Loss1 0.754, Train_accy 76.63
2024-08-02 18:15:37,765 [foster.py] => SNet: Task 17, Epoch 46/130 => Loss 29.935,  Loss1 0.754, Train_accy 76.02, Test_accy 64.95
2024-08-02 18:15:41,506 [foster.py] => SNet: Task 17, Epoch 47/130 => Loss 29.981,  Loss1 0.754, Train_accy 76.44
2024-08-02 18:15:45,263 [foster.py] => SNet: Task 17, Epoch 48/130 => Loss 29.967,  Loss1 0.753, Train_accy 75.91
2024-08-02 18:15:49,055 [foster.py] => SNet: Task 17, Epoch 49/130 => Loss 29.965,  Loss1 0.754, Train_accy 76.74
2024-08-02 18:15:52,800 [foster.py] => SNet: Task 17, Epoch 50/130 => Loss 29.923,  Loss1 0.754, Train_accy 76.55
2024-08-02 18:15:57,735 [foster.py] => SNet: Task 17, Epoch 51/130 => Loss 29.908,  Loss1 0.753, Train_accy 77.20, Test_accy 64.75
2024-08-02 18:16:01,475 [foster.py] => SNet: Task 17, Epoch 52/130 => Loss 29.971,  Loss1 0.754, Train_accy 76.29
2024-08-02 18:16:05,191 [foster.py] => SNet: Task 17, Epoch 53/130 => Loss 29.974,  Loss1 0.753, Train_accy 76.89
2024-08-02 18:16:08,965 [foster.py] => SNet: Task 17, Epoch 54/130 => Loss 29.935,  Loss1 0.753, Train_accy 77.65
2024-08-02 18:16:12,696 [foster.py] => SNet: Task 17, Epoch 55/130 => Loss 29.935,  Loss1 0.754, Train_accy 77.39
2024-08-02 18:16:17,644 [foster.py] => SNet: Task 17, Epoch 56/130 => Loss 29.940,  Loss1 0.753, Train_accy 75.91, Test_accy 64.55
2024-08-02 18:16:21,379 [foster.py] => SNet: Task 17, Epoch 57/130 => Loss 29.970,  Loss1 0.754, Train_accy 75.42
2024-08-02 18:16:25,123 [foster.py] => SNet: Task 17, Epoch 58/130 => Loss 29.960,  Loss1 0.754, Train_accy 76.63
2024-08-02 18:16:28,849 [foster.py] => SNet: Task 17, Epoch 59/130 => Loss 29.992,  Loss1 0.754, Train_accy 76.59
2024-08-02 18:16:32,568 [foster.py] => SNet: Task 17, Epoch 60/130 => Loss 29.905,  Loss1 0.753, Train_accy 77.50
2024-08-02 18:16:37,523 [foster.py] => SNet: Task 17, Epoch 61/130 => Loss 29.922,  Loss1 0.753, Train_accy 76.10, Test_accy 64.89
2024-08-02 18:16:41,237 [foster.py] => SNet: Task 17, Epoch 62/130 => Loss 29.903,  Loss1 0.754, Train_accy 77.05
2024-08-02 18:16:44,971 [foster.py] => SNet: Task 17, Epoch 63/130 => Loss 29.924,  Loss1 0.754, Train_accy 75.95
2024-08-02 18:16:48,680 [foster.py] => SNet: Task 17, Epoch 64/130 => Loss 29.926,  Loss1 0.753, Train_accy 77.99
2024-08-02 18:16:52,417 [foster.py] => SNet: Task 17, Epoch 65/130 => Loss 29.950,  Loss1 0.754, Train_accy 77.35
2024-08-02 18:16:57,358 [foster.py] => SNet: Task 17, Epoch 66/130 => Loss 29.937,  Loss1 0.753, Train_accy 76.97, Test_accy 64.69
2024-08-02 18:17:01,153 [foster.py] => SNet: Task 17, Epoch 67/130 => Loss 29.988,  Loss1 0.754, Train_accy 76.59
2024-08-02 18:17:04,914 [foster.py] => SNet: Task 17, Epoch 68/130 => Loss 29.947,  Loss1 0.754, Train_accy 76.67
2024-08-02 18:17:08,666 [foster.py] => SNet: Task 17, Epoch 69/130 => Loss 29.892,  Loss1 0.753, Train_accy 76.21
2024-08-02 18:17:12,384 [foster.py] => SNet: Task 17, Epoch 70/130 => Loss 29.918,  Loss1 0.753, Train_accy 77.58
2024-08-02 18:17:17,386 [foster.py] => SNet: Task 17, Epoch 71/130 => Loss 29.954,  Loss1 0.754, Train_accy 78.07, Test_accy 64.95
2024-08-02 18:17:21,118 [foster.py] => SNet: Task 17, Epoch 72/130 => Loss 29.964,  Loss1 0.753, Train_accy 76.74
2024-08-02 18:17:24,848 [foster.py] => SNet: Task 17, Epoch 73/130 => Loss 29.952,  Loss1 0.754, Train_accy 76.63
2024-08-02 18:17:28,597 [foster.py] => SNet: Task 17, Epoch 74/130 => Loss 29.920,  Loss1 0.754, Train_accy 76.74
2024-08-02 18:17:32,350 [foster.py] => SNet: Task 17, Epoch 75/130 => Loss 29.884,  Loss1 0.754, Train_accy 77.16
2024-08-02 18:17:37,292 [foster.py] => SNet: Task 17, Epoch 76/130 => Loss 29.944,  Loss1 0.753, Train_accy 78.18, Test_accy 64.77
2024-08-02 18:17:41,050 [foster.py] => SNet: Task 17, Epoch 77/130 => Loss 29.927,  Loss1 0.753, Train_accy 77.27
2024-08-02 18:17:44,771 [foster.py] => SNet: Task 17, Epoch 78/130 => Loss 29.965,  Loss1 0.753, Train_accy 76.78
2024-08-02 18:17:48,519 [foster.py] => SNet: Task 17, Epoch 79/130 => Loss 29.914,  Loss1 0.753, Train_accy 77.42
2024-08-02 18:17:52,258 [foster.py] => SNet: Task 17, Epoch 80/130 => Loss 29.936,  Loss1 0.753, Train_accy 77.08
2024-08-02 18:17:57,184 [foster.py] => SNet: Task 17, Epoch 81/130 => Loss 29.907,  Loss1 0.753, Train_accy 77.01, Test_accy 64.77
2024-08-02 18:18:00,942 [foster.py] => SNet: Task 17, Epoch 82/130 => Loss 29.955,  Loss1 0.753, Train_accy 76.25
2024-08-02 18:18:04,665 [foster.py] => SNet: Task 17, Epoch 83/130 => Loss 29.917,  Loss1 0.754, Train_accy 77.77
2024-08-02 18:18:08,433 [foster.py] => SNet: Task 17, Epoch 84/130 => Loss 29.939,  Loss1 0.753, Train_accy 77.95
2024-08-02 18:18:12,226 [foster.py] => SNet: Task 17, Epoch 85/130 => Loss 29.957,  Loss1 0.754, Train_accy 76.29
2024-08-02 18:18:17,164 [foster.py] => SNet: Task 17, Epoch 86/130 => Loss 29.956,  Loss1 0.754, Train_accy 76.44, Test_accy 64.96
2024-08-02 18:18:20,893 [foster.py] => SNet: Task 17, Epoch 87/130 => Loss 29.903,  Loss1 0.753, Train_accy 76.70
2024-08-02 18:18:24,623 [foster.py] => SNet: Task 17, Epoch 88/130 => Loss 29.950,  Loss1 0.754, Train_accy 77.95
2024-08-02 18:18:28,352 [foster.py] => SNet: Task 17, Epoch 89/130 => Loss 29.858,  Loss1 0.753, Train_accy 78.26
2024-08-02 18:18:32,083 [foster.py] => SNet: Task 17, Epoch 90/130 => Loss 29.945,  Loss1 0.753, Train_accy 77.95
2024-08-02 18:18:37,028 [foster.py] => SNet: Task 17, Epoch 91/130 => Loss 29.944,  Loss1 0.754, Train_accy 76.63, Test_accy 64.62
2024-08-02 18:18:40,771 [foster.py] => SNet: Task 17, Epoch 92/130 => Loss 29.909,  Loss1 0.754, Train_accy 78.79
2024-08-02 18:18:44,502 [foster.py] => SNet: Task 17, Epoch 93/130 => Loss 29.947,  Loss1 0.754, Train_accy 77.05
2024-08-02 18:18:48,224 [foster.py] => SNet: Task 17, Epoch 94/130 => Loss 29.894,  Loss1 0.754, Train_accy 78.03
2024-08-02 18:18:51,942 [foster.py] => SNet: Task 17, Epoch 95/130 => Loss 30.002,  Loss1 0.754, Train_accy 78.45
2024-08-02 18:18:56,883 [foster.py] => SNet: Task 17, Epoch 96/130 => Loss 29.937,  Loss1 0.754, Train_accy 77.35, Test_accy 65.04
2024-08-02 18:19:00,626 [foster.py] => SNet: Task 17, Epoch 97/130 => Loss 29.912,  Loss1 0.754, Train_accy 78.71
2024-08-02 18:19:04,355 [foster.py] => SNet: Task 17, Epoch 98/130 => Loss 29.948,  Loss1 0.754, Train_accy 77.23
2024-08-02 18:19:08,085 [foster.py] => SNet: Task 17, Epoch 99/130 => Loss 29.920,  Loss1 0.753, Train_accy 76.70
2024-08-02 18:19:11,795 [foster.py] => SNet: Task 17, Epoch 100/130 => Loss 29.965,  Loss1 0.753, Train_accy 77.46
2024-08-02 18:19:16,715 [foster.py] => SNet: Task 17, Epoch 101/130 => Loss 29.931,  Loss1 0.754, Train_accy 78.71, Test_accy 64.80
2024-08-02 18:19:20,429 [foster.py] => SNet: Task 17, Epoch 102/130 => Loss 29.870,  Loss1 0.754, Train_accy 76.52
2024-08-02 18:19:24,215 [foster.py] => SNet: Task 17, Epoch 103/130 => Loss 29.972,  Loss1 0.754, Train_accy 77.54
2024-08-02 18:19:27,936 [foster.py] => SNet: Task 17, Epoch 104/130 => Loss 29.934,  Loss1 0.753, Train_accy 77.58
2024-08-02 18:19:31,660 [foster.py] => SNet: Task 17, Epoch 105/130 => Loss 29.962,  Loss1 0.754, Train_accy 77.20
2024-08-02 18:19:36,638 [foster.py] => SNet: Task 17, Epoch 106/130 => Loss 29.913,  Loss1 0.753, Train_accy 77.27, Test_accy 65.06
2024-08-02 18:19:40,378 [foster.py] => SNet: Task 17, Epoch 107/130 => Loss 29.957,  Loss1 0.753, Train_accy 76.93
2024-08-02 18:19:44,105 [foster.py] => SNet: Task 17, Epoch 108/130 => Loss 29.907,  Loss1 0.754, Train_accy 77.61
2024-08-02 18:19:47,841 [foster.py] => SNet: Task 17, Epoch 109/130 => Loss 29.926,  Loss1 0.754, Train_accy 77.54
2024-08-02 18:19:51,580 [foster.py] => SNet: Task 17, Epoch 110/130 => Loss 29.917,  Loss1 0.754, Train_accy 78.14
2024-08-02 18:19:56,568 [foster.py] => SNet: Task 17, Epoch 111/130 => Loss 29.949,  Loss1 0.754, Train_accy 77.16, Test_accy 64.65
2024-08-02 18:20:00,292 [foster.py] => SNet: Task 17, Epoch 112/130 => Loss 29.970,  Loss1 0.754, Train_accy 77.65
2024-08-02 18:20:04,063 [foster.py] => SNet: Task 17, Epoch 113/130 => Loss 29.895,  Loss1 0.753, Train_accy 77.88
2024-08-02 18:20:07,784 [foster.py] => SNet: Task 17, Epoch 114/130 => Loss 29.929,  Loss1 0.754, Train_accy 77.58
2024-08-02 18:20:11,496 [foster.py] => SNet: Task 17, Epoch 115/130 => Loss 29.942,  Loss1 0.753, Train_accy 78.64
2024-08-02 18:20:16,422 [foster.py] => SNet: Task 17, Epoch 116/130 => Loss 29.934,  Loss1 0.754, Train_accy 76.59, Test_accy 64.80
2024-08-02 18:20:20,151 [foster.py] => SNet: Task 17, Epoch 117/130 => Loss 29.922,  Loss1 0.753, Train_accy 76.29
2024-08-02 18:20:23,903 [foster.py] => SNet: Task 17, Epoch 118/130 => Loss 29.933,  Loss1 0.753, Train_accy 78.56
2024-08-02 18:20:27,633 [foster.py] => SNet: Task 17, Epoch 119/130 => Loss 29.902,  Loss1 0.753, Train_accy 77.23
2024-08-02 18:20:31,364 [foster.py] => SNet: Task 17, Epoch 120/130 => Loss 29.977,  Loss1 0.754, Train_accy 78.07
2024-08-02 18:20:36,390 [foster.py] => SNet: Task 17, Epoch 121/130 => Loss 29.906,  Loss1 0.754, Train_accy 77.80, Test_accy 65.07
2024-08-02 18:20:40,133 [foster.py] => SNet: Task 17, Epoch 122/130 => Loss 29.932,  Loss1 0.754, Train_accy 78.79
2024-08-02 18:20:43,845 [foster.py] => SNet: Task 17, Epoch 123/130 => Loss 29.917,  Loss1 0.753, Train_accy 76.63
2024-08-02 18:20:47,563 [foster.py] => SNet: Task 17, Epoch 124/130 => Loss 29.884,  Loss1 0.754, Train_accy 77.08
2024-08-02 18:20:51,360 [foster.py] => SNet: Task 17, Epoch 125/130 => Loss 29.915,  Loss1 0.753, Train_accy 77.23
2024-08-02 18:20:56,318 [foster.py] => SNet: Task 17, Epoch 126/130 => Loss 29.888,  Loss1 0.753, Train_accy 77.12, Test_accy 64.76
2024-08-02 18:21:00,017 [foster.py] => SNet: Task 17, Epoch 127/130 => Loss 29.929,  Loss1 0.753, Train_accy 78.67
2024-08-02 18:21:03,738 [foster.py] => SNet: Task 17, Epoch 128/130 => Loss 29.942,  Loss1 0.753, Train_accy 77.12
2024-08-02 18:21:07,470 [foster.py] => SNet: Task 17, Epoch 129/130 => Loss 29.905,  Loss1 0.754, Train_accy 77.58
2024-08-02 18:21:11,226 [foster.py] => SNet: Task 17, Epoch 130/130 => Loss 29.888,  Loss1 0.754, Train_accy 76.67
2024-08-02 18:21:11,227 [foster.py] => do not weight align student!
2024-08-02 18:21:12,431 [foster.py] => darknet eval: 
2024-08-02 18:21:12,432 [foster.py] => CNN top1 curve: 64.87
2024-08-02 18:21:12,432 [foster.py] => CNN top5 curve: 88.63
2024-08-02 18:21:12,432 [foster.py] => CNN top1 平均值: 64.87
2024-08-02 18:21:12,436 [foster.py] => timees : 1237.2332994937897
2024-08-02 18:21:12,440 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 18:21:38,169 [foster.py] => Exemplar size: 1680
2024-08-02 18:21:38,170 [trainer.py] => CNN: {'total': 65.73, '00-09': 73.0, '10-19': 57.0, '20-29': 71.4, '30-39': 64.4, '40-49': 69.1, '50-59': 53.4, '60-69': 68.3, '70-79': 65.9, '80-89': 74.0, 'old': 65.46, 'new': 76.5}
2024-08-02 18:21:38,170 [trainer.py] => NME: {'total': 59.67, '00-09': 63.2, '10-19': 47.5, '20-29': 63.7, '30-39': 54.5, '40-49': 60.7, '50-59': 49.7, '60-69': 65.5, '70-79': 65.4, '80-89': 77.5, 'old': 58.9, 'new': 91.0}
2024-08-02 18:21:38,170 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73]
2024-08-02 18:21:38,170 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1]
2024-08-02 18:21:38,170 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67]
2024-08-02 18:21:38,170 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65]

2024-08-02 18:21:38,170 [trainer.py] => CNN top1 平均值: 73.02
2024-08-02 18:21:38,173 [trainer.py] => All params: 1176174
2024-08-02 18:21:38,175 [trainer.py] => Trainable params: 593570
2024-08-02 18:21:38,236 [foster.py] => Learning on 84-86
2024-08-02 18:21:38,239 [foster.py] => All params: 1176692
2024-08-02 18:21:38,242 [foster.py] => Trainable params: 593958
2024-08-02 18:21:38,284 [foster.py] => per cls weights : [1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422 1.01064422
 0.55294276 0.55294276]
2024-08-02 18:21:40,958 [foster.py] => Task 18, Epoch 1/170 => Loss 5.165, Loss_clf 0.822, Loss_fe 1.783, Loss_kd 2.498, Train_accy 67.13
2024-08-02 18:21:45,611 [foster.py] => Task 18, Epoch 2/170 => Loss 3.893, Loss_clf 0.612, Loss_fe 0.732, Loss_kd 2.488, Train_accy 72.84, Test_accy 63.38
2024-08-02 18:21:50,262 [foster.py] => Task 18, Epoch 3/170 => Loss 3.753, Loss_clf 0.566, Loss_fe 0.623, Loss_kd 2.503, Train_accy 74.70, Test_accy 63.58
2024-08-02 18:21:54,928 [foster.py] => Task 18, Epoch 4/170 => Loss 3.558, Loss_clf 0.483, Loss_fe 0.560, Loss_kd 2.456, Train_accy 76.57, Test_accy 63.90
2024-08-02 18:21:59,572 [foster.py] => Task 18, Epoch 5/170 => Loss 3.590, Loss_clf 0.513, Loss_fe 0.525, Loss_kd 2.491, Train_accy 75.60, Test_accy 63.51
2024-08-02 18:22:02,328 [foster.py] => Task 18, Epoch 6/170 => Loss 3.515, Loss_clf 0.486, Loss_fe 0.491, Loss_kd 2.477, Train_accy 76.64
2024-08-02 18:22:06,939 [foster.py] => Task 18, Epoch 7/170 => Loss 3.547, Loss_clf 0.498, Loss_fe 0.500, Loss_kd 2.488, Train_accy 75.34, Test_accy 63.55
2024-08-02 18:22:11,605 [foster.py] => Task 18, Epoch 8/170 => Loss 3.521, Loss_clf 0.507, Loss_fe 0.481, Loss_kd 2.472, Train_accy 76.23, Test_accy 63.85
2024-08-02 18:22:16,226 [foster.py] => Task 18, Epoch 9/170 => Loss 3.445, Loss_clf 0.469, Loss_fe 0.438, Loss_kd 2.477, Train_accy 76.60, Test_accy 63.73
2024-08-02 18:22:20,878 [foster.py] => Task 18, Epoch 10/170 => Loss 3.449, Loss_clf 0.471, Loss_fe 0.437, Loss_kd 2.480, Train_accy 78.25, Test_accy 63.51
2024-08-02 18:22:23,573 [foster.py] => Task 18, Epoch 11/170 => Loss 3.448, Loss_clf 0.478, Loss_fe 0.413, Loss_kd 2.495, Train_accy 76.60
2024-08-02 18:22:28,213 [foster.py] => Task 18, Epoch 12/170 => Loss 3.392, Loss_clf 0.454, Loss_fe 0.403, Loss_kd 2.474, Train_accy 78.21, Test_accy 63.76
2024-08-02 18:22:32,828 [foster.py] => Task 18, Epoch 13/170 => Loss 3.366, Loss_clf 0.434, Loss_fe 0.395, Loss_kd 2.476, Train_accy 79.78, Test_accy 63.42
2024-08-02 18:22:37,458 [foster.py] => Task 18, Epoch 14/170 => Loss 3.357, Loss_clf 0.437, Loss_fe 0.387, Loss_kd 2.472, Train_accy 78.10, Test_accy 63.76
2024-08-02 18:22:42,160 [foster.py] => Task 18, Epoch 15/170 => Loss 3.349, Loss_clf 0.451, Loss_fe 0.379, Loss_kd 2.459, Train_accy 79.70, Test_accy 63.40
2024-08-02 18:22:44,841 [foster.py] => Task 18, Epoch 16/170 => Loss 3.371, Loss_clf 0.460, Loss_fe 0.364, Loss_kd 2.487, Train_accy 78.10
2024-08-02 18:22:49,486 [foster.py] => Task 18, Epoch 17/170 => Loss 3.357, Loss_clf 0.451, Loss_fe 0.363, Loss_kd 2.481, Train_accy 78.06, Test_accy 63.59
2024-08-02 18:22:54,133 [foster.py] => Task 18, Epoch 18/170 => Loss 3.338, Loss_clf 0.440, Loss_fe 0.361, Loss_kd 2.477, Train_accy 80.15, Test_accy 63.27
2024-08-02 18:22:58,779 [foster.py] => Task 18, Epoch 19/170 => Loss 3.369, Loss_clf 0.450, Loss_fe 0.360, Loss_kd 2.498, Train_accy 78.84, Test_accy 63.67
2024-08-02 18:23:03,435 [foster.py] => Task 18, Epoch 20/170 => Loss 3.294, Loss_clf 0.413, Loss_fe 0.340, Loss_kd 2.480, Train_accy 80.86, Test_accy 63.79
2024-08-02 18:23:06,133 [foster.py] => Task 18, Epoch 21/170 => Loss 3.292, Loss_clf 0.425, Loss_fe 0.311, Loss_kd 2.495, Train_accy 80.15
2024-08-02 18:23:10,755 [foster.py] => Task 18, Epoch 22/170 => Loss 3.272, Loss_clf 0.409, Loss_fe 0.339, Loss_kd 2.462, Train_accy 80.04, Test_accy 63.27
2024-08-02 18:23:15,413 [foster.py] => Task 18, Epoch 23/170 => Loss 3.259, Loss_clf 0.433, Loss_fe 0.303, Loss_kd 2.463, Train_accy 79.48, Test_accy 63.00
2024-08-02 18:23:20,132 [foster.py] => Task 18, Epoch 24/170 => Loss 3.287, Loss_clf 0.420, Loss_fe 0.318, Loss_kd 2.488, Train_accy 80.63, Test_accy 63.58
2024-08-02 18:23:24,792 [foster.py] => Task 18, Epoch 25/170 => Loss 3.297, Loss_clf 0.436, Loss_fe 0.325, Loss_kd 2.475, Train_accy 80.67, Test_accy 64.02
2024-08-02 18:23:27,542 [foster.py] => Task 18, Epoch 26/170 => Loss 3.292, Loss_clf 0.428, Loss_fe 0.319, Loss_kd 2.483, Train_accy 80.52
2024-08-02 18:23:32,208 [foster.py] => Task 18, Epoch 27/170 => Loss 3.305, Loss_clf 0.444, Loss_fe 0.310, Loss_kd 2.490, Train_accy 79.29, Test_accy 63.98
2024-08-02 18:23:36,846 [foster.py] => Task 18, Epoch 28/170 => Loss 3.250, Loss_clf 0.412, Loss_fe 0.305, Loss_kd 2.472, Train_accy 80.71, Test_accy 63.31
2024-08-02 18:23:41,468 [foster.py] => Task 18, Epoch 29/170 => Loss 3.311, Loss_clf 0.444, Loss_fe 0.324, Loss_kd 2.482, Train_accy 79.14, Test_accy 64.20
2024-08-02 18:23:46,129 [foster.py] => Task 18, Epoch 30/170 => Loss 3.273, Loss_clf 0.422, Loss_fe 0.301, Loss_kd 2.489, Train_accy 80.71, Test_accy 63.99
2024-08-02 18:23:48,808 [foster.py] => Task 18, Epoch 31/170 => Loss 3.267, Loss_clf 0.427, Loss_fe 0.306, Loss_kd 2.474, Train_accy 80.45
2024-08-02 18:23:53,459 [foster.py] => Task 18, Epoch 32/170 => Loss 3.256, Loss_clf 0.424, Loss_fe 0.288, Loss_kd 2.483, Train_accy 81.12, Test_accy 63.56
2024-08-02 18:23:58,132 [foster.py] => Task 18, Epoch 33/170 => Loss 3.213, Loss_clf 0.414, Loss_fe 0.262, Loss_kd 2.476, Train_accy 81.90, Test_accy 63.72
2024-08-02 18:24:02,891 [foster.py] => Task 18, Epoch 34/170 => Loss 3.195, Loss_clf 0.388, Loss_fe 0.276, Loss_kd 2.471, Train_accy 82.54, Test_accy 64.40
2024-08-02 18:24:07,505 [foster.py] => Task 18, Epoch 35/170 => Loss 3.210, Loss_clf 0.396, Loss_fe 0.266, Loss_kd 2.487, Train_accy 81.72, Test_accy 64.14
2024-08-02 18:24:10,168 [foster.py] => Task 18, Epoch 36/170 => Loss 3.233, Loss_clf 0.412, Loss_fe 0.283, Loss_kd 2.477, Train_accy 80.90
2024-08-02 18:24:14,825 [foster.py] => Task 18, Epoch 37/170 => Loss 3.183, Loss_clf 0.394, Loss_fe 0.268, Loss_kd 2.461, Train_accy 82.13, Test_accy 64.42
2024-08-02 18:24:19,477 [foster.py] => Task 18, Epoch 38/170 => Loss 3.112, Loss_clf 0.365, Loss_fe 0.229, Loss_kd 2.457, Train_accy 83.62, Test_accy 63.92
2024-08-02 18:24:24,124 [foster.py] => Task 18, Epoch 39/170 => Loss 3.289, Loss_clf 0.439, Loss_fe 0.298, Loss_kd 2.491, Train_accy 81.27, Test_accy 64.01
2024-08-02 18:24:28,731 [foster.py] => Task 18, Epoch 40/170 => Loss 3.211, Loss_clf 0.389, Loss_fe 0.286, Loss_kd 2.475, Train_accy 82.43, Test_accy 63.53
2024-08-02 18:24:31,400 [foster.py] => Task 18, Epoch 41/170 => Loss 3.166, Loss_clf 0.386, Loss_fe 0.262, Loss_kd 2.457, Train_accy 83.02
2024-08-02 18:24:36,087 [foster.py] => Task 18, Epoch 42/170 => Loss 3.146, Loss_clf 0.362, Loss_fe 0.244, Loss_kd 2.479, Train_accy 82.87, Test_accy 63.84
2024-08-02 18:24:40,720 [foster.py] => Task 18, Epoch 43/170 => Loss 3.207, Loss_clf 0.403, Loss_fe 0.260, Loss_kd 2.484, Train_accy 82.61, Test_accy 64.15
2024-08-02 18:24:45,362 [foster.py] => Task 18, Epoch 44/170 => Loss 3.190, Loss_clf 0.392, Loss_fe 0.259, Loss_kd 2.478, Train_accy 83.13, Test_accy 64.20
2024-08-02 18:24:50,002 [foster.py] => Task 18, Epoch 45/170 => Loss 3.137, Loss_clf 0.366, Loss_fe 0.234, Loss_kd 2.475, Train_accy 83.43, Test_accy 64.14
2024-08-02 18:24:52,718 [foster.py] => Task 18, Epoch 46/170 => Loss 3.172, Loss_clf 0.384, Loss_fe 0.261, Loss_kd 2.467, Train_accy 83.77
2024-08-02 18:24:57,300 [foster.py] => Task 18, Epoch 47/170 => Loss 3.165, Loss_clf 0.386, Loss_fe 0.253, Loss_kd 2.466, Train_accy 83.25, Test_accy 64.84
2024-08-02 18:25:01,937 [foster.py] => Task 18, Epoch 48/170 => Loss 3.230, Loss_clf 0.407, Loss_fe 0.274, Loss_kd 2.488, Train_accy 81.94, Test_accy 64.28
2024-08-02 18:25:06,590 [foster.py] => Task 18, Epoch 49/170 => Loss 3.107, Loss_clf 0.351, Loss_fe 0.237, Loss_kd 2.459, Train_accy 82.65, Test_accy 63.94
2024-08-02 18:25:11,255 [foster.py] => Task 18, Epoch 50/170 => Loss 3.205, Loss_clf 0.403, Loss_fe 0.251, Loss_kd 2.491, Train_accy 81.83, Test_accy 64.59
2024-08-02 18:25:13,938 [foster.py] => Task 18, Epoch 51/170 => Loss 3.241, Loss_clf 0.421, Loss_fe 0.251, Loss_kd 2.508, Train_accy 82.61
2024-08-02 18:25:18,618 [foster.py] => Task 18, Epoch 52/170 => Loss 3.195, Loss_clf 0.391, Loss_fe 0.244, Loss_kd 2.498, Train_accy 82.46, Test_accy 64.56
2024-08-02 18:25:23,277 [foster.py] => Task 18, Epoch 53/170 => Loss 3.162, Loss_clf 0.383, Loss_fe 0.238, Loss_kd 2.480, Train_accy 83.25, Test_accy 64.24
2024-08-02 18:25:27,910 [foster.py] => Task 18, Epoch 54/170 => Loss 3.173, Loss_clf 0.394, Loss_fe 0.229, Loss_kd 2.489, Train_accy 83.17, Test_accy 63.65
2024-08-02 18:25:32,536 [foster.py] => Task 18, Epoch 55/170 => Loss 3.176, Loss_clf 0.392, Loss_fe 0.238, Loss_kd 2.485, Train_accy 83.51, Test_accy 64.31
2024-08-02 18:25:35,215 [foster.py] => Task 18, Epoch 56/170 => Loss 3.095, Loss_clf 0.364, Loss_fe 0.227, Loss_kd 2.444, Train_accy 83.51
2024-08-02 18:25:39,850 [foster.py] => Task 18, Epoch 57/170 => Loss 3.135, Loss_clf 0.381, Loss_fe 0.234, Loss_kd 2.460, Train_accy 84.29, Test_accy 64.24
2024-08-02 18:25:44,465 [foster.py] => Task 18, Epoch 58/170 => Loss 3.096, Loss_clf 0.367, Loss_fe 0.209, Loss_kd 2.459, Train_accy 82.76, Test_accy 64.03
2024-08-02 18:25:49,096 [foster.py] => Task 18, Epoch 59/170 => Loss 3.102, Loss_clf 0.363, Loss_fe 0.218, Loss_kd 2.461, Train_accy 84.81, Test_accy 64.26
2024-08-02 18:25:53,710 [foster.py] => Task 18, Epoch 60/170 => Loss 3.144, Loss_clf 0.375, Loss_fe 0.204, Loss_kd 2.502, Train_accy 83.66, Test_accy 64.34
2024-08-02 18:25:56,383 [foster.py] => Task 18, Epoch 61/170 => Loss 3.088, Loss_clf 0.353, Loss_fe 0.220, Loss_kd 2.455, Train_accy 84.63
2024-08-02 18:26:01,030 [foster.py] => Task 18, Epoch 62/170 => Loss 3.115, Loss_clf 0.362, Loss_fe 0.199, Loss_kd 2.493, Train_accy 83.62, Test_accy 64.35
2024-08-02 18:26:05,671 [foster.py] => Task 18, Epoch 63/170 => Loss 3.144, Loss_clf 0.377, Loss_fe 0.219, Loss_kd 2.486, Train_accy 83.58, Test_accy 64.45
2024-08-02 18:26:10,292 [foster.py] => Task 18, Epoch 64/170 => Loss 3.077, Loss_clf 0.356, Loss_fe 0.209, Loss_kd 2.452, Train_accy 84.74, Test_accy 64.29
2024-08-02 18:26:14,951 [foster.py] => Task 18, Epoch 65/170 => Loss 3.120, Loss_clf 0.364, Loss_fe 0.214, Loss_kd 2.481, Train_accy 84.25, Test_accy 64.35
2024-08-02 18:26:17,706 [foster.py] => Task 18, Epoch 66/170 => Loss 3.038, Loss_clf 0.341, Loss_fe 0.194, Loss_kd 2.443, Train_accy 84.25
2024-08-02 18:26:22,389 [foster.py] => Task 18, Epoch 67/170 => Loss 3.146, Loss_clf 0.363, Loss_fe 0.216, Loss_kd 2.506, Train_accy 84.44, Test_accy 64.23
2024-08-02 18:26:27,031 [foster.py] => Task 18, Epoch 68/170 => Loss 3.098, Loss_clf 0.354, Loss_fe 0.206, Loss_kd 2.478, Train_accy 85.26, Test_accy 64.51
2024-08-02 18:26:31,681 [foster.py] => Task 18, Epoch 69/170 => Loss 3.088, Loss_clf 0.359, Loss_fe 0.198, Loss_kd 2.470, Train_accy 84.51, Test_accy 64.28
2024-08-02 18:26:36,300 [foster.py] => Task 18, Epoch 70/170 => Loss 3.145, Loss_clf 0.386, Loss_fe 0.216, Loss_kd 2.483, Train_accy 84.10, Test_accy 64.80
2024-08-02 18:26:38,976 [foster.py] => Task 18, Epoch 71/170 => Loss 3.116, Loss_clf 0.371, Loss_fe 0.200, Loss_kd 2.484, Train_accy 84.55
2024-08-02 18:26:43,641 [foster.py] => Task 18, Epoch 72/170 => Loss 3.088, Loss_clf 0.363, Loss_fe 0.191, Loss_kd 2.473, Train_accy 85.30, Test_accy 64.40
2024-08-02 18:26:48,277 [foster.py] => Task 18, Epoch 73/170 => Loss 3.110, Loss_clf 0.376, Loss_fe 0.191, Loss_kd 2.483, Train_accy 83.84, Test_accy 64.71
2024-08-02 18:26:52,991 [foster.py] => Task 18, Epoch 74/170 => Loss 3.050, Loss_clf 0.340, Loss_fe 0.195, Loss_kd 2.455, Train_accy 85.34, Test_accy 64.52
2024-08-02 18:26:57,734 [foster.py] => Task 18, Epoch 75/170 => Loss 3.078, Loss_clf 0.356, Loss_fe 0.195, Loss_kd 2.467, Train_accy 84.07, Test_accy 64.50
2024-08-02 18:27:00,490 [foster.py] => Task 18, Epoch 76/170 => Loss 3.110, Loss_clf 0.357, Loss_fe 0.189, Loss_kd 2.502, Train_accy 83.99
2024-08-02 18:27:05,222 [foster.py] => Task 18, Epoch 77/170 => Loss 3.070, Loss_clf 0.350, Loss_fe 0.181, Loss_kd 2.478, Train_accy 85.15, Test_accy 64.76
2024-08-02 18:27:09,876 [foster.py] => Task 18, Epoch 78/170 => Loss 3.050, Loss_clf 0.339, Loss_fe 0.181, Loss_kd 2.470, Train_accy 85.26, Test_accy 64.58
2024-08-02 18:27:14,517 [foster.py] => Task 18, Epoch 79/170 => Loss 3.079, Loss_clf 0.372, Loss_fe 0.180, Loss_kd 2.466, Train_accy 83.88, Test_accy 64.48
2024-08-02 18:27:19,173 [foster.py] => Task 18, Epoch 80/170 => Loss 3.111, Loss_clf 0.367, Loss_fe 0.196, Loss_kd 2.488, Train_accy 86.08, Test_accy 64.79
2024-08-02 18:27:21,854 [foster.py] => Task 18, Epoch 81/170 => Loss 3.059, Loss_clf 0.349, Loss_fe 0.178, Loss_kd 2.471, Train_accy 85.37
2024-08-02 18:27:26,503 [foster.py] => Task 18, Epoch 82/170 => Loss 3.077, Loss_clf 0.354, Loss_fe 0.172, Loss_kd 2.491, Train_accy 84.66, Test_accy 64.15
2024-08-02 18:27:31,206 [foster.py] => Task 18, Epoch 83/170 => Loss 3.098, Loss_clf 0.362, Loss_fe 0.191, Loss_kd 2.484, Train_accy 85.75, Test_accy 64.60
2024-08-02 18:27:35,862 [foster.py] => Task 18, Epoch 84/170 => Loss 3.093, Loss_clf 0.373, Loss_fe 0.168, Loss_kd 2.491, Train_accy 84.37, Test_accy 64.09
2024-08-02 18:27:40,609 [foster.py] => Task 18, Epoch 85/170 => Loss 3.021, Loss_clf 0.325, Loss_fe 0.160, Loss_kd 2.475, Train_accy 85.86, Test_accy 64.48
2024-08-02 18:27:43,361 [foster.py] => Task 18, Epoch 86/170 => Loss 3.036, Loss_clf 0.340, Loss_fe 0.173, Loss_kd 2.463, Train_accy 85.11
2024-08-02 18:27:48,055 [foster.py] => Task 18, Epoch 87/170 => Loss 3.047, Loss_clf 0.339, Loss_fe 0.167, Loss_kd 2.480, Train_accy 86.38, Test_accy 64.73
2024-08-02 18:27:52,700 [foster.py] => Task 18, Epoch 88/170 => Loss 3.028, Loss_clf 0.335, Loss_fe 0.176, Loss_kd 2.456, Train_accy 85.63, Test_accy 64.47
2024-08-02 18:27:57,329 [foster.py] => Task 18, Epoch 89/170 => Loss 3.030, Loss_clf 0.341, Loss_fe 0.157, Loss_kd 2.472, Train_accy 85.90, Test_accy 64.57
2024-08-02 18:28:01,924 [foster.py] => Task 18, Epoch 90/170 => Loss 3.116, Loss_clf 0.386, Loss_fe 0.188, Loss_kd 2.481, Train_accy 83.47, Test_accy 64.91
2024-08-02 18:28:04,681 [foster.py] => Task 18, Epoch 91/170 => Loss 3.029, Loss_clf 0.334, Loss_fe 0.172, Loss_kd 2.462, Train_accy 86.19
2024-08-02 18:28:09,334 [foster.py] => Task 18, Epoch 92/170 => Loss 3.011, Loss_clf 0.336, Loss_fe 0.156, Loss_kd 2.458, Train_accy 85.00, Test_accy 64.78
2024-08-02 18:28:13,971 [foster.py] => Task 18, Epoch 93/170 => Loss 3.048, Loss_clf 0.349, Loss_fe 0.152, Loss_kd 2.486, Train_accy 85.26, Test_accy 64.74
2024-08-02 18:28:18,640 [foster.py] => Task 18, Epoch 94/170 => Loss 3.022, Loss_clf 0.346, Loss_fe 0.177, Loss_kd 2.439, Train_accy 85.37, Test_accy 64.81
2024-08-02 18:28:23,299 [foster.py] => Task 18, Epoch 95/170 => Loss 3.006, Loss_clf 0.318, Loss_fe 0.156, Loss_kd 2.472, Train_accy 85.60, Test_accy 64.79
2024-08-02 18:28:25,975 [foster.py] => Task 18, Epoch 96/170 => Loss 3.061, Loss_clf 0.348, Loss_fe 0.162, Loss_kd 2.490, Train_accy 85.56
2024-08-02 18:28:30,577 [foster.py] => Task 18, Epoch 97/170 => Loss 2.982, Loss_clf 0.312, Loss_fe 0.147, Loss_kd 2.462, Train_accy 87.20, Test_accy 64.65
2024-08-02 18:28:35,205 [foster.py] => Task 18, Epoch 98/170 => Loss 3.031, Loss_clf 0.320, Loss_fe 0.156, Loss_kd 2.494, Train_accy 86.68, Test_accy 64.85
2024-08-02 18:28:39,866 [foster.py] => Task 18, Epoch 99/170 => Loss 3.062, Loss_clf 0.348, Loss_fe 0.160, Loss_kd 2.493, Train_accy 85.75, Test_accy 64.99
2024-08-02 18:28:44,489 [foster.py] => Task 18, Epoch 100/170 => Loss 3.087, Loss_clf 0.374, Loss_fe 0.161, Loss_kd 2.492, Train_accy 84.37, Test_accy 64.57
2024-08-02 18:28:47,233 [foster.py] => Task 18, Epoch 101/170 => Loss 2.986, Loss_clf 0.323, Loss_fe 0.152, Loss_kd 2.452, Train_accy 86.31
2024-08-02 18:28:51,909 [foster.py] => Task 18, Epoch 102/170 => Loss 2.996, Loss_clf 0.334, Loss_fe 0.150, Loss_kd 2.452, Train_accy 86.04, Test_accy 64.79
2024-08-02 18:28:56,568 [foster.py] => Task 18, Epoch 103/170 => Loss 3.030, Loss_clf 0.341, Loss_fe 0.149, Loss_kd 2.480, Train_accy 86.27, Test_accy 64.56
2024-08-02 18:29:01,213 [foster.py] => Task 18, Epoch 104/170 => Loss 2.994, Loss_clf 0.325, Loss_fe 0.154, Loss_kd 2.455, Train_accy 86.60, Test_accy 64.78
2024-08-02 18:29:05,840 [foster.py] => Task 18, Epoch 105/170 => Loss 3.022, Loss_clf 0.336, Loss_fe 0.150, Loss_kd 2.475, Train_accy 85.11, Test_accy 64.79
2024-08-02 18:29:08,497 [foster.py] => Task 18, Epoch 106/170 => Loss 3.020, Loss_clf 0.335, Loss_fe 0.151, Loss_kd 2.474, Train_accy 86.83
2024-08-02 18:29:13,226 [foster.py] => Task 18, Epoch 107/170 => Loss 3.050, Loss_clf 0.351, Loss_fe 0.146, Loss_kd 2.491, Train_accy 86.46, Test_accy 64.72
2024-08-02 18:29:17,932 [foster.py] => Task 18, Epoch 108/170 => Loss 3.032, Loss_clf 0.352, Loss_fe 0.152, Loss_kd 2.468, Train_accy 85.49, Test_accy 64.93
2024-08-02 18:29:22,636 [foster.py] => Task 18, Epoch 109/170 => Loss 2.967, Loss_clf 0.314, Loss_fe 0.121, Loss_kd 2.472, Train_accy 87.87, Test_accy 64.67
2024-08-02 18:29:27,253 [foster.py] => Task 18, Epoch 110/170 => Loss 2.974, Loss_clf 0.310, Loss_fe 0.140, Loss_kd 2.464, Train_accy 87.50, Test_accy 64.91
2024-08-02 18:29:29,923 [foster.py] => Task 18, Epoch 111/170 => Loss 2.936, Loss_clf 0.298, Loss_fe 0.135, Loss_kd 2.444, Train_accy 86.90
2024-08-02 18:29:34,559 [foster.py] => Task 18, Epoch 112/170 => Loss 2.999, Loss_clf 0.318, Loss_fe 0.136, Loss_kd 2.484, Train_accy 85.82, Test_accy 64.72
2024-08-02 18:29:39,223 [foster.py] => Task 18, Epoch 113/170 => Loss 3.055, Loss_clf 0.344, Loss_fe 0.149, Loss_kd 2.501, Train_accy 85.90, Test_accy 64.80
2024-08-02 18:29:43,904 [foster.py] => Task 18, Epoch 114/170 => Loss 2.994, Loss_clf 0.321, Loss_fe 0.129, Loss_kd 2.483, Train_accy 87.61, Test_accy 64.55
2024-08-02 18:29:48,600 [foster.py] => Task 18, Epoch 115/170 => Loss 3.039, Loss_clf 0.338, Loss_fe 0.132, Loss_kd 2.507, Train_accy 87.24, Test_accy 64.77
2024-08-02 18:29:51,274 [foster.py] => Task 18, Epoch 116/170 => Loss 3.014, Loss_clf 0.330, Loss_fe 0.127, Loss_kd 2.496, Train_accy 86.75
2024-08-02 18:29:55,973 [foster.py] => Task 18, Epoch 117/170 => Loss 3.037, Loss_clf 0.354, Loss_fe 0.134, Loss_kd 2.489, Train_accy 86.75, Test_accy 64.98
2024-08-02 18:30:00,639 [foster.py] => Task 18, Epoch 118/170 => Loss 2.997, Loss_clf 0.320, Loss_fe 0.131, Loss_kd 2.486, Train_accy 86.60, Test_accy 65.02
2024-08-02 18:30:05,346 [foster.py] => Task 18, Epoch 119/170 => Loss 2.992, Loss_clf 0.320, Loss_fe 0.112, Loss_kd 2.499, Train_accy 86.53, Test_accy 64.95
2024-08-02 18:30:10,045 [foster.py] => Task 18, Epoch 120/170 => Loss 2.987, Loss_clf 0.319, Loss_fe 0.121, Loss_kd 2.486, Train_accy 87.54, Test_accy 65.09
2024-08-02 18:30:12,729 [foster.py] => Task 18, Epoch 121/170 => Loss 3.037, Loss_clf 0.345, Loss_fe 0.133, Loss_kd 2.498, Train_accy 86.49
2024-08-02 18:30:17,394 [foster.py] => Task 18, Epoch 122/170 => Loss 3.031, Loss_clf 0.331, Loss_fe 0.126, Loss_kd 2.512, Train_accy 87.61, Test_accy 64.67
2024-08-02 18:30:22,053 [foster.py] => Task 18, Epoch 123/170 => Loss 3.030, Loss_clf 0.340, Loss_fe 0.136, Loss_kd 2.493, Train_accy 87.24, Test_accy 64.84
2024-08-02 18:30:26,701 [foster.py] => Task 18, Epoch 124/170 => Loss 2.949, Loss_clf 0.307, Loss_fe 0.126, Loss_kd 2.455, Train_accy 87.35, Test_accy 64.94
2024-08-02 18:30:31,349 [foster.py] => Task 18, Epoch 125/170 => Loss 2.996, Loss_clf 0.331, Loss_fe 0.132, Loss_kd 2.472, Train_accy 85.86, Test_accy 64.94
2024-08-02 18:30:34,036 [foster.py] => Task 18, Epoch 126/170 => Loss 2.989, Loss_clf 0.326, Loss_fe 0.128, Loss_kd 2.474, Train_accy 86.12
2024-08-02 18:30:38,714 [foster.py] => Task 18, Epoch 127/170 => Loss 3.002, Loss_clf 0.329, Loss_fe 0.120, Loss_kd 2.492, Train_accy 87.01, Test_accy 64.92
2024-08-02 18:30:43,343 [foster.py] => Task 18, Epoch 128/170 => Loss 3.002, Loss_clf 0.324, Loss_fe 0.119, Loss_kd 2.497, Train_accy 87.39, Test_accy 64.87
2024-08-02 18:30:47,996 [foster.py] => Task 18, Epoch 129/170 => Loss 2.977, Loss_clf 0.324, Loss_fe 0.129, Loss_kd 2.464, Train_accy 87.16, Test_accy 65.00
2024-08-02 18:30:52,661 [foster.py] => Task 18, Epoch 130/170 => Loss 2.959, Loss_clf 0.308, Loss_fe 0.106, Loss_kd 2.484, Train_accy 87.61, Test_accy 65.07
2024-08-02 18:30:55,335 [foster.py] => Task 18, Epoch 131/170 => Loss 3.037, Loss_clf 0.334, Loss_fe 0.127, Loss_kd 2.515, Train_accy 86.57
2024-08-02 18:30:59,961 [foster.py] => Task 18, Epoch 132/170 => Loss 2.966, Loss_clf 0.300, Loss_fe 0.112, Loss_kd 2.494, Train_accy 88.62, Test_accy 65.01
2024-08-02 18:31:04,611 [foster.py] => Task 18, Epoch 133/170 => Loss 2.967, Loss_clf 0.313, Loss_fe 0.121, Loss_kd 2.472, Train_accy 87.31, Test_accy 64.97
2024-08-02 18:31:09,238 [foster.py] => Task 18, Epoch 134/170 => Loss 2.951, Loss_clf 0.311, Loss_fe 0.109, Loss_kd 2.472, Train_accy 88.06, Test_accy 64.83
2024-08-02 18:31:13,889 [foster.py] => Task 18, Epoch 135/170 => Loss 2.937, Loss_clf 0.305, Loss_fe 0.111, Loss_kd 2.461, Train_accy 88.10, Test_accy 65.07
2024-08-02 18:31:16,548 [foster.py] => Task 18, Epoch 136/170 => Loss 2.953, Loss_clf 0.310, Loss_fe 0.100, Loss_kd 2.482, Train_accy 86.79
2024-08-02 18:31:21,216 [foster.py] => Task 18, Epoch 137/170 => Loss 2.997, Loss_clf 0.325, Loss_fe 0.126, Loss_kd 2.485, Train_accy 87.76, Test_accy 65.07
2024-08-02 18:31:25,873 [foster.py] => Task 18, Epoch 138/170 => Loss 2.980, Loss_clf 0.323, Loss_fe 0.102, Loss_kd 2.494, Train_accy 86.94, Test_accy 64.87
2024-08-02 18:31:30,527 [foster.py] => Task 18, Epoch 139/170 => Loss 2.935, Loss_clf 0.310, Loss_fe 0.123, Loss_kd 2.443, Train_accy 87.28, Test_accy 64.97
2024-08-02 18:31:35,192 [foster.py] => Task 18, Epoch 140/170 => Loss 2.985, Loss_clf 0.321, Loss_fe 0.108, Loss_kd 2.495, Train_accy 88.13, Test_accy 64.95
2024-08-02 18:31:37,881 [foster.py] => Task 18, Epoch 141/170 => Loss 2.945, Loss_clf 0.311, Loss_fe 0.101, Loss_kd 2.472, Train_accy 88.21
2024-08-02 18:31:42,530 [foster.py] => Task 18, Epoch 142/170 => Loss 2.964, Loss_clf 0.316, Loss_fe 0.120, Loss_kd 2.468, Train_accy 87.09, Test_accy 64.90
2024-08-02 18:31:47,187 [foster.py] => Task 18, Epoch 143/170 => Loss 3.000, Loss_clf 0.329, Loss_fe 0.113, Loss_kd 2.496, Train_accy 86.90, Test_accy 64.84
2024-08-02 18:31:51,829 [foster.py] => Task 18, Epoch 144/170 => Loss 2.958, Loss_clf 0.307, Loss_fe 0.098, Loss_kd 2.491, Train_accy 87.91, Test_accy 64.79
2024-08-02 18:31:56,442 [foster.py] => Task 18, Epoch 145/170 => Loss 2.915, Loss_clf 0.291, Loss_fe 0.116, Loss_kd 2.448, Train_accy 87.99, Test_accy 64.86
2024-08-02 18:31:59,129 [foster.py] => Task 18, Epoch 146/170 => Loss 2.981, Loss_clf 0.330, Loss_fe 0.108, Loss_kd 2.482, Train_accy 87.16
2024-08-02 18:32:03,808 [foster.py] => Task 18, Epoch 147/170 => Loss 2.989, Loss_clf 0.313, Loss_fe 0.115, Loss_kd 2.499, Train_accy 88.40, Test_accy 64.93
2024-08-02 18:32:08,477 [foster.py] => Task 18, Epoch 148/170 => Loss 2.997, Loss_clf 0.333, Loss_fe 0.102, Loss_kd 2.500, Train_accy 88.10, Test_accy 64.97
2024-08-02 18:32:13,168 [foster.py] => Task 18, Epoch 149/170 => Loss 3.061, Loss_clf 0.347, Loss_fe 0.121, Loss_kd 2.531, Train_accy 86.23, Test_accy 64.90
2024-08-02 18:32:17,824 [foster.py] => Task 18, Epoch 150/170 => Loss 2.964, Loss_clf 0.314, Loss_fe 0.100, Loss_kd 2.489, Train_accy 87.57, Test_accy 64.93
2024-08-02 18:32:20,503 [foster.py] => Task 18, Epoch 151/170 => Loss 3.015, Loss_clf 0.335, Loss_fe 0.121, Loss_kd 2.498, Train_accy 87.46
2024-08-02 18:32:25,139 [foster.py] => Task 18, Epoch 152/170 => Loss 2.950, Loss_clf 0.305, Loss_fe 0.109, Loss_kd 2.475, Train_accy 87.57, Test_accy 64.97
2024-08-02 18:32:29,820 [foster.py] => Task 18, Epoch 153/170 => Loss 2.925, Loss_clf 0.303, Loss_fe 0.097, Loss_kd 2.464, Train_accy 88.02, Test_accy 64.86
2024-08-02 18:32:34,436 [foster.py] => Task 18, Epoch 154/170 => Loss 2.986, Loss_clf 0.322, Loss_fe 0.119, Loss_kd 2.484, Train_accy 87.76, Test_accy 64.91
2024-08-02 18:32:39,068 [foster.py] => Task 18, Epoch 155/170 => Loss 3.018, Loss_clf 0.331, Loss_fe 0.104, Loss_kd 2.522, Train_accy 87.46, Test_accy 64.95
2024-08-02 18:32:41,750 [foster.py] => Task 18, Epoch 156/170 => Loss 2.989, Loss_clf 0.321, Loss_fe 0.121, Loss_kd 2.485, Train_accy 87.87
2024-08-02 18:32:46,465 [foster.py] => Task 18, Epoch 157/170 => Loss 2.972, Loss_clf 0.319, Loss_fe 0.106, Loss_kd 2.486, Train_accy 87.46, Test_accy 64.88
2024-08-02 18:32:51,226 [foster.py] => Task 18, Epoch 158/170 => Loss 2.961, Loss_clf 0.305, Loss_fe 0.105, Loss_kd 2.489, Train_accy 88.77, Test_accy 64.95
2024-08-02 18:32:55,864 [foster.py] => Task 18, Epoch 159/170 => Loss 2.983, Loss_clf 0.307, Loss_fe 0.118, Loss_kd 2.497, Train_accy 87.61, Test_accy 64.92
2024-08-02 18:33:00,515 [foster.py] => Task 18, Epoch 160/170 => Loss 2.954, Loss_clf 0.299, Loss_fe 0.112, Loss_kd 2.482, Train_accy 88.25, Test_accy 64.92
2024-08-02 18:33:03,221 [foster.py] => Task 18, Epoch 161/170 => Loss 2.966, Loss_clf 0.307, Loss_fe 0.108, Loss_kd 2.489, Train_accy 87.80
2024-08-02 18:33:07,911 [foster.py] => Task 18, Epoch 162/170 => Loss 2.979, Loss_clf 0.311, Loss_fe 0.104, Loss_kd 2.503, Train_accy 88.21, Test_accy 64.87
2024-08-02 18:33:12,544 [foster.py] => Task 18, Epoch 163/170 => Loss 2.943, Loss_clf 0.301, Loss_fe 0.100, Loss_kd 2.482, Train_accy 88.10, Test_accy 64.95
2024-08-02 18:33:17,199 [foster.py] => Task 18, Epoch 164/170 => Loss 2.921, Loss_clf 0.293, Loss_fe 0.099, Loss_kd 2.469, Train_accy 88.77, Test_accy 64.92
2024-08-02 18:33:21,828 [foster.py] => Task 18, Epoch 165/170 => Loss 3.015, Loss_clf 0.334, Loss_fe 0.109, Loss_kd 2.511, Train_accy 87.35, Test_accy 64.91
2024-08-02 18:33:24,522 [foster.py] => Task 18, Epoch 166/170 => Loss 2.909, Loss_clf 0.291, Loss_fe 0.094, Loss_kd 2.464, Train_accy 89.25
2024-08-02 18:33:29,180 [foster.py] => Task 18, Epoch 167/170 => Loss 2.958, Loss_clf 0.321, Loss_fe 0.102, Loss_kd 2.475, Train_accy 87.80, Test_accy 64.92
2024-08-02 18:33:33,836 [foster.py] => Task 18, Epoch 168/170 => Loss 3.046, Loss_clf 0.353, Loss_fe 0.114, Loss_kd 2.517, Train_accy 86.90, Test_accy 64.97
2024-08-02 18:33:38,485 [foster.py] => Task 18, Epoch 169/170 => Loss 2.979, Loss_clf 0.323, Loss_fe 0.112, Loss_kd 2.483, Train_accy 87.54, Test_accy 64.94
2024-08-02 18:33:43,083 [foster.py] => Task 18, Epoch 170/170 => Loss 2.963, Loss_clf 0.320, Loss_fe 0.102, Loss_kd 2.480, Train_accy 87.99, Test_accy 64.95
2024-08-02 18:33:43,088 [foster.py] => do not weight align teacher!
2024-08-02 18:33:43,089 [foster.py] => per cls weights : [1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 1.0126397  1.0126397  1.0126397  1.0126397  1.0126397  1.0126397
 0.46913272 0.46913272]
2024-08-02 18:33:48,265 [foster.py] => SNet: Task 18, Epoch 1/130 => Loss 30.376,  Loss1 0.765, Train_accy 57.54, Test_accy 61.47
2024-08-02 18:33:52,009 [foster.py] => SNet: Task 18, Epoch 2/130 => Loss 30.254,  Loss1 0.763, Train_accy 65.26
2024-08-02 18:33:55,773 [foster.py] => SNet: Task 18, Epoch 3/130 => Loss 30.267,  Loss1 0.762, Train_accy 64.59
2024-08-02 18:33:59,522 [foster.py] => SNet: Task 18, Epoch 4/130 => Loss 30.240,  Loss1 0.762, Train_accy 67.13
2024-08-02 18:34:03,256 [foster.py] => SNet: Task 18, Epoch 5/130 => Loss 30.268,  Loss1 0.762, Train_accy 67.28
2024-08-02 18:34:08,197 [foster.py] => SNet: Task 18, Epoch 6/130 => Loss 30.188,  Loss1 0.762, Train_accy 68.69, Test_accy 63.00
2024-08-02 18:34:11,927 [foster.py] => SNet: Task 18, Epoch 7/130 => Loss 30.224,  Loss1 0.762, Train_accy 69.10
2024-08-02 18:34:15,652 [foster.py] => SNet: Task 18, Epoch 8/130 => Loss 30.229,  Loss1 0.762, Train_accy 69.93
2024-08-02 18:34:19,388 [foster.py] => SNet: Task 18, Epoch 9/130 => Loss 30.221,  Loss1 0.761, Train_accy 70.49
2024-08-02 18:34:23,120 [foster.py] => SNet: Task 18, Epoch 10/130 => Loss 30.211,  Loss1 0.762, Train_accy 70.30
2024-08-02 18:34:28,104 [foster.py] => SNet: Task 18, Epoch 11/130 => Loss 30.190,  Loss1 0.761, Train_accy 71.98, Test_accy 62.85
2024-08-02 18:34:31,880 [foster.py] => SNet: Task 18, Epoch 12/130 => Loss 30.233,  Loss1 0.761, Train_accy 71.31
2024-08-02 18:34:35,626 [foster.py] => SNet: Task 18, Epoch 13/130 => Loss 30.218,  Loss1 0.762, Train_accy 71.83
2024-08-02 18:34:39,363 [foster.py] => SNet: Task 18, Epoch 14/130 => Loss 30.229,  Loss1 0.761, Train_accy 70.78
2024-08-02 18:34:43,126 [foster.py] => SNet: Task 18, Epoch 15/130 => Loss 30.165,  Loss1 0.761, Train_accy 72.54
2024-08-02 18:34:48,136 [foster.py] => SNet: Task 18, Epoch 16/130 => Loss 30.207,  Loss1 0.761, Train_accy 72.84, Test_accy 63.47
2024-08-02 18:34:51,901 [foster.py] => SNet: Task 18, Epoch 17/130 => Loss 30.207,  Loss1 0.761, Train_accy 71.90
2024-08-02 18:34:55,654 [foster.py] => SNet: Task 18, Epoch 18/130 => Loss 30.240,  Loss1 0.761, Train_accy 71.04
2024-08-02 18:34:59,398 [foster.py] => SNet: Task 18, Epoch 19/130 => Loss 30.194,  Loss1 0.761, Train_accy 73.10
2024-08-02 18:35:03,145 [foster.py] => SNet: Task 18, Epoch 20/130 => Loss 30.220,  Loss1 0.760, Train_accy 73.84
2024-08-02 18:35:08,121 [foster.py] => SNet: Task 18, Epoch 21/130 => Loss 30.218,  Loss1 0.761, Train_accy 73.02, Test_accy 63.38
2024-08-02 18:35:11,913 [foster.py] => SNet: Task 18, Epoch 22/130 => Loss 30.248,  Loss1 0.761, Train_accy 73.43
2024-08-02 18:35:15,678 [foster.py] => SNet: Task 18, Epoch 23/130 => Loss 30.152,  Loss1 0.761, Train_accy 74.07
2024-08-02 18:35:19,440 [foster.py] => SNet: Task 18, Epoch 24/130 => Loss 30.155,  Loss1 0.761, Train_accy 74.85
2024-08-02 18:35:23,221 [foster.py] => SNet: Task 18, Epoch 25/130 => Loss 30.201,  Loss1 0.760, Train_accy 73.21
2024-08-02 18:35:28,246 [foster.py] => SNet: Task 18, Epoch 26/130 => Loss 30.195,  Loss1 0.761, Train_accy 74.25, Test_accy 63.05
2024-08-02 18:35:31,970 [foster.py] => SNet: Task 18, Epoch 27/130 => Loss 30.185,  Loss1 0.761, Train_accy 75.49
2024-08-02 18:35:35,727 [foster.py] => SNet: Task 18, Epoch 28/130 => Loss 30.161,  Loss1 0.761, Train_accy 73.51
2024-08-02 18:35:39,537 [foster.py] => SNet: Task 18, Epoch 29/130 => Loss 30.202,  Loss1 0.760, Train_accy 75.30
2024-08-02 18:35:43,271 [foster.py] => SNet: Task 18, Epoch 30/130 => Loss 30.199,  Loss1 0.761, Train_accy 74.22
2024-08-02 18:35:48,268 [foster.py] => SNet: Task 18, Epoch 31/130 => Loss 30.181,  Loss1 0.761, Train_accy 74.18, Test_accy 63.41
2024-08-02 18:35:52,020 [foster.py] => SNet: Task 18, Epoch 32/130 => Loss 30.224,  Loss1 0.761, Train_accy 74.03
2024-08-02 18:35:55,759 [foster.py] => SNet: Task 18, Epoch 33/130 => Loss 30.207,  Loss1 0.760, Train_accy 74.48
2024-08-02 18:35:59,513 [foster.py] => SNet: Task 18, Epoch 34/130 => Loss 30.216,  Loss1 0.760, Train_accy 75.56
2024-08-02 18:36:03,292 [foster.py] => SNet: Task 18, Epoch 35/130 => Loss 30.178,  Loss1 0.761, Train_accy 73.96
2024-08-02 18:36:08,296 [foster.py] => SNet: Task 18, Epoch 36/130 => Loss 30.192,  Loss1 0.761, Train_accy 76.23, Test_accy 63.45
2024-08-02 18:36:12,052 [foster.py] => SNet: Task 18, Epoch 37/130 => Loss 30.156,  Loss1 0.760, Train_accy 75.52
2024-08-02 18:36:15,827 [foster.py] => SNet: Task 18, Epoch 38/130 => Loss 30.169,  Loss1 0.760, Train_accy 75.07
2024-08-02 18:36:19,582 [foster.py] => SNet: Task 18, Epoch 39/130 => Loss 30.194,  Loss1 0.761, Train_accy 75.63
2024-08-02 18:36:23,308 [foster.py] => SNet: Task 18, Epoch 40/130 => Loss 30.173,  Loss1 0.760, Train_accy 76.16
2024-08-02 18:36:28,282 [foster.py] => SNet: Task 18, Epoch 41/130 => Loss 30.159,  Loss1 0.760, Train_accy 76.98, Test_accy 63.40
2024-08-02 18:36:32,016 [foster.py] => SNet: Task 18, Epoch 42/130 => Loss 30.237,  Loss1 0.761, Train_accy 75.19
2024-08-02 18:36:35,775 [foster.py] => SNet: Task 18, Epoch 43/130 => Loss 30.177,  Loss1 0.761, Train_accy 75.11
2024-08-02 18:36:39,547 [foster.py] => SNet: Task 18, Epoch 44/130 => Loss 30.243,  Loss1 0.760, Train_accy 76.68
2024-08-02 18:36:43,290 [foster.py] => SNet: Task 18, Epoch 45/130 => Loss 30.190,  Loss1 0.761, Train_accy 75.86
2024-08-02 18:36:48,255 [foster.py] => SNet: Task 18, Epoch 46/130 => Loss 30.169,  Loss1 0.760, Train_accy 76.12, Test_accy 63.62
2024-08-02 18:36:52,071 [foster.py] => SNet: Task 18, Epoch 47/130 => Loss 30.210,  Loss1 0.760, Train_accy 75.00
2024-08-02 18:36:55,813 [foster.py] => SNet: Task 18, Epoch 48/130 => Loss 30.180,  Loss1 0.761, Train_accy 76.12
2024-08-02 18:36:59,537 [foster.py] => SNet: Task 18, Epoch 49/130 => Loss 30.203,  Loss1 0.760, Train_accy 75.90
2024-08-02 18:37:03,258 [foster.py] => SNet: Task 18, Epoch 50/130 => Loss 30.182,  Loss1 0.760, Train_accy 76.08
2024-08-02 18:37:08,260 [foster.py] => SNet: Task 18, Epoch 51/130 => Loss 30.202,  Loss1 0.760, Train_accy 74.93, Test_accy 63.58
2024-08-02 18:37:11,986 [foster.py] => SNet: Task 18, Epoch 52/130 => Loss 30.189,  Loss1 0.761, Train_accy 75.90
2024-08-02 18:37:15,730 [foster.py] => SNet: Task 18, Epoch 53/130 => Loss 30.222,  Loss1 0.760, Train_accy 75.63
2024-08-02 18:37:19,494 [foster.py] => SNet: Task 18, Epoch 54/130 => Loss 30.203,  Loss1 0.760, Train_accy 76.04
2024-08-02 18:37:23,252 [foster.py] => SNet: Task 18, Epoch 55/130 => Loss 30.216,  Loss1 0.760, Train_accy 76.12
2024-08-02 18:37:28,295 [foster.py] => SNet: Task 18, Epoch 56/130 => Loss 30.150,  Loss1 0.760, Train_accy 75.90, Test_accy 63.50
2024-08-02 18:37:32,032 [foster.py] => SNet: Task 18, Epoch 57/130 => Loss 30.225,  Loss1 0.760, Train_accy 75.26
2024-08-02 18:37:35,785 [foster.py] => SNet: Task 18, Epoch 58/130 => Loss 30.235,  Loss1 0.760, Train_accy 77.31
2024-08-02 18:37:39,521 [foster.py] => SNet: Task 18, Epoch 59/130 => Loss 30.215,  Loss1 0.761, Train_accy 75.97
2024-08-02 18:37:43,261 [foster.py] => SNet: Task 18, Epoch 60/130 => Loss 30.159,  Loss1 0.760, Train_accy 76.60
2024-08-02 18:37:48,243 [foster.py] => SNet: Task 18, Epoch 61/130 => Loss 30.221,  Loss1 0.761, Train_accy 75.11, Test_accy 63.40
2024-08-02 18:37:51,980 [foster.py] => SNet: Task 18, Epoch 62/130 => Loss 30.195,  Loss1 0.760, Train_accy 76.57
2024-08-02 18:37:55,719 [foster.py] => SNet: Task 18, Epoch 63/130 => Loss 30.192,  Loss1 0.761, Train_accy 74.93
2024-08-02 18:37:59,452 [foster.py] => SNet: Task 18, Epoch 64/130 => Loss 30.190,  Loss1 0.760, Train_accy 75.56
2024-08-02 18:38:03,246 [foster.py] => SNet: Task 18, Epoch 65/130 => Loss 30.156,  Loss1 0.760, Train_accy 76.01
2024-08-02 18:38:08,237 [foster.py] => SNet: Task 18, Epoch 66/130 => Loss 30.144,  Loss1 0.760, Train_accy 76.16, Test_accy 63.37
2024-08-02 18:38:12,001 [foster.py] => SNet: Task 18, Epoch 67/130 => Loss 30.135,  Loss1 0.760, Train_accy 76.68
2024-08-02 18:38:15,727 [foster.py] => SNet: Task 18, Epoch 68/130 => Loss 30.135,  Loss1 0.760, Train_accy 76.49
2024-08-02 18:38:19,505 [foster.py] => SNet: Task 18, Epoch 69/130 => Loss 30.198,  Loss1 0.760, Train_accy 77.05
2024-08-02 18:38:23,240 [foster.py] => SNet: Task 18, Epoch 70/130 => Loss 30.209,  Loss1 0.760, Train_accy 76.42
2024-08-02 18:38:28,181 [foster.py] => SNet: Task 18, Epoch 71/130 => Loss 30.173,  Loss1 0.760, Train_accy 76.53, Test_accy 63.45
2024-08-02 18:38:31,931 [foster.py] => SNet: Task 18, Epoch 72/130 => Loss 30.185,  Loss1 0.760, Train_accy 76.08
2024-08-02 18:38:35,665 [foster.py] => SNet: Task 18, Epoch 73/130 => Loss 30.150,  Loss1 0.760, Train_accy 76.68
2024-08-02 18:38:39,402 [foster.py] => SNet: Task 18, Epoch 74/130 => Loss 30.170,  Loss1 0.760, Train_accy 75.67
2024-08-02 18:38:43,160 [foster.py] => SNet: Task 18, Epoch 75/130 => Loss 30.198,  Loss1 0.760, Train_accy 76.49
2024-08-02 18:38:48,162 [foster.py] => SNet: Task 18, Epoch 76/130 => Loss 30.209,  Loss1 0.760, Train_accy 75.86, Test_accy 63.60
2024-08-02 18:38:51,894 [foster.py] => SNet: Task 18, Epoch 77/130 => Loss 30.154,  Loss1 0.761, Train_accy 78.21
2024-08-02 18:38:55,653 [foster.py] => SNet: Task 18, Epoch 78/130 => Loss 30.213,  Loss1 0.761, Train_accy 75.67
2024-08-02 18:38:59,405 [foster.py] => SNet: Task 18, Epoch 79/130 => Loss 30.208,  Loss1 0.760, Train_accy 77.13
2024-08-02 18:39:03,159 [foster.py] => SNet: Task 18, Epoch 80/130 => Loss 30.194,  Loss1 0.760, Train_accy 77.13
2024-08-02 18:39:08,181 [foster.py] => SNet: Task 18, Epoch 81/130 => Loss 30.194,  Loss1 0.760, Train_accy 76.16, Test_accy 63.42
2024-08-02 18:39:11,931 [foster.py] => SNet: Task 18, Epoch 82/130 => Loss 30.201,  Loss1 0.760, Train_accy 74.93
2024-08-02 18:39:15,727 [foster.py] => SNet: Task 18, Epoch 83/130 => Loss 30.201,  Loss1 0.760, Train_accy 76.57
2024-08-02 18:39:19,443 [foster.py] => SNet: Task 18, Epoch 84/130 => Loss 30.174,  Loss1 0.760, Train_accy 76.60
2024-08-02 18:39:23,199 [foster.py] => SNet: Task 18, Epoch 85/130 => Loss 30.203,  Loss1 0.760, Train_accy 76.53
2024-08-02 18:39:28,166 [foster.py] => SNet: Task 18, Epoch 86/130 => Loss 30.211,  Loss1 0.760, Train_accy 76.12, Test_accy 63.56
2024-08-02 18:39:31,924 [foster.py] => SNet: Task 18, Epoch 87/130 => Loss 30.193,  Loss1 0.760, Train_accy 76.01
2024-08-02 18:39:35,695 [foster.py] => SNet: Task 18, Epoch 88/130 => Loss 30.190,  Loss1 0.760, Train_accy 75.93
2024-08-02 18:39:39,422 [foster.py] => SNet: Task 18, Epoch 89/130 => Loss 30.204,  Loss1 0.760, Train_accy 76.27
2024-08-02 18:39:43,169 [foster.py] => SNet: Task 18, Epoch 90/130 => Loss 30.170,  Loss1 0.760, Train_accy 77.20
2024-08-02 18:39:48,149 [foster.py] => SNet: Task 18, Epoch 91/130 => Loss 30.172,  Loss1 0.761, Train_accy 78.25, Test_accy 63.47
2024-08-02 18:39:51,890 [foster.py] => SNet: Task 18, Epoch 92/130 => Loss 30.232,  Loss1 0.761, Train_accy 76.72
2024-08-02 18:39:55,621 [foster.py] => SNet: Task 18, Epoch 93/130 => Loss 30.184,  Loss1 0.760, Train_accy 77.80
2024-08-02 18:39:59,365 [foster.py] => SNet: Task 18, Epoch 94/130 => Loss 30.214,  Loss1 0.761, Train_accy 76.04
2024-08-02 18:40:03,118 [foster.py] => SNet: Task 18, Epoch 95/130 => Loss 30.177,  Loss1 0.761, Train_accy 77.24
2024-08-02 18:40:08,085 [foster.py] => SNet: Task 18, Epoch 96/130 => Loss 30.177,  Loss1 0.760, Train_accy 77.35, Test_accy 63.42
2024-08-02 18:40:11,831 [foster.py] => SNet: Task 18, Epoch 97/130 => Loss 30.231,  Loss1 0.760, Train_accy 77.31
2024-08-02 18:40:15,576 [foster.py] => SNet: Task 18, Epoch 98/130 => Loss 30.178,  Loss1 0.760, Train_accy 76.60
2024-08-02 18:40:19,315 [foster.py] => SNet: Task 18, Epoch 99/130 => Loss 30.172,  Loss1 0.760, Train_accy 76.72
2024-08-02 18:40:23,152 [foster.py] => SNet: Task 18, Epoch 100/130 => Loss 30.188,  Loss1 0.760, Train_accy 78.36
2024-08-02 18:40:28,108 [foster.py] => SNet: Task 18, Epoch 101/130 => Loss 30.178,  Loss1 0.760, Train_accy 76.19, Test_accy 63.45
2024-08-02 18:40:31,820 [foster.py] => SNet: Task 18, Epoch 102/130 => Loss 30.165,  Loss1 0.761, Train_accy 77.76
2024-08-02 18:40:35,542 [foster.py] => SNet: Task 18, Epoch 103/130 => Loss 30.201,  Loss1 0.760, Train_accy 77.35
2024-08-02 18:40:39,266 [foster.py] => SNet: Task 18, Epoch 104/130 => Loss 30.177,  Loss1 0.760, Train_accy 76.23
2024-08-02 18:40:42,995 [foster.py] => SNet: Task 18, Epoch 105/130 => Loss 30.179,  Loss1 0.760, Train_accy 77.54
2024-08-02 18:40:47,970 [foster.py] => SNet: Task 18, Epoch 106/130 => Loss 30.103,  Loss1 0.760, Train_accy 78.47, Test_accy 63.40
2024-08-02 18:40:51,719 [foster.py] => SNet: Task 18, Epoch 107/130 => Loss 30.159,  Loss1 0.761, Train_accy 77.01
2024-08-02 18:40:55,444 [foster.py] => SNet: Task 18, Epoch 108/130 => Loss 30.168,  Loss1 0.760, Train_accy 77.39
2024-08-02 18:40:59,173 [foster.py] => SNet: Task 18, Epoch 109/130 => Loss 30.200,  Loss1 0.760, Train_accy 76.08
2024-08-02 18:41:02,941 [foster.py] => SNet: Task 18, Epoch 110/130 => Loss 30.179,  Loss1 0.761, Train_accy 77.09
2024-08-02 18:41:07,888 [foster.py] => SNet: Task 18, Epoch 111/130 => Loss 30.153,  Loss1 0.761, Train_accy 76.42, Test_accy 63.65
2024-08-02 18:41:11,644 [foster.py] => SNet: Task 18, Epoch 112/130 => Loss 30.227,  Loss1 0.760, Train_accy 76.34
2024-08-02 18:41:15,365 [foster.py] => SNet: Task 18, Epoch 113/130 => Loss 30.207,  Loss1 0.760, Train_accy 76.19
2024-08-02 18:41:19,112 [foster.py] => SNet: Task 18, Epoch 114/130 => Loss 30.169,  Loss1 0.760, Train_accy 77.57
2024-08-02 18:41:22,878 [foster.py] => SNet: Task 18, Epoch 115/130 => Loss 30.209,  Loss1 0.760, Train_accy 75.71
2024-08-02 18:41:27,830 [foster.py] => SNet: Task 18, Epoch 116/130 => Loss 30.177,  Loss1 0.761, Train_accy 76.53, Test_accy 63.56
2024-08-02 18:41:31,553 [foster.py] => SNet: Task 18, Epoch 117/130 => Loss 30.172,  Loss1 0.760, Train_accy 76.72
2024-08-02 18:41:35,335 [foster.py] => SNet: Task 18, Epoch 118/130 => Loss 30.197,  Loss1 0.760, Train_accy 77.31
2024-08-02 18:41:39,084 [foster.py] => SNet: Task 18, Epoch 119/130 => Loss 30.164,  Loss1 0.760, Train_accy 76.83
2024-08-02 18:41:42,838 [foster.py] => SNet: Task 18, Epoch 120/130 => Loss 30.190,  Loss1 0.760, Train_accy 76.98
2024-08-02 18:41:47,800 [foster.py] => SNet: Task 18, Epoch 121/130 => Loss 30.161,  Loss1 0.760, Train_accy 77.61, Test_accy 63.41
2024-08-02 18:41:51,551 [foster.py] => SNet: Task 18, Epoch 122/130 => Loss 30.190,  Loss1 0.760, Train_accy 77.13
2024-08-02 18:41:55,267 [foster.py] => SNet: Task 18, Epoch 123/130 => Loss 30.187,  Loss1 0.760, Train_accy 76.90
2024-08-02 18:41:59,022 [foster.py] => SNet: Task 18, Epoch 124/130 => Loss 30.150,  Loss1 0.760, Train_accy 77.16
2024-08-02 18:42:02,774 [foster.py] => SNet: Task 18, Epoch 125/130 => Loss 30.165,  Loss1 0.761, Train_accy 77.95
2024-08-02 18:42:07,743 [foster.py] => SNet: Task 18, Epoch 126/130 => Loss 30.181,  Loss1 0.760, Train_accy 76.68, Test_accy 63.53
2024-08-02 18:42:11,504 [foster.py] => SNet: Task 18, Epoch 127/130 => Loss 30.131,  Loss1 0.760, Train_accy 77.76
2024-08-02 18:42:15,237 [foster.py] => SNet: Task 18, Epoch 128/130 => Loss 30.204,  Loss1 0.760, Train_accy 75.52
2024-08-02 18:42:18,989 [foster.py] => SNet: Task 18, Epoch 129/130 => Loss 30.171,  Loss1 0.760, Train_accy 77.46
2024-08-02 18:42:22,726 [foster.py] => SNet: Task 18, Epoch 130/130 => Loss 30.210,  Loss1 0.760, Train_accy 76.94
2024-08-02 18:42:22,729 [foster.py] => do not weight align student!
2024-08-02 18:42:23,956 [foster.py] => darknet eval: 
2024-08-02 18:42:23,956 [foster.py] => CNN top1 curve: 63.4
2024-08-02 18:42:23,957 [foster.py] => CNN top5 curve: 87.74
2024-08-02 18:42:23,957 [foster.py] => CNN top1 平均值: 63.40
2024-08-02 18:42:23,961 [foster.py] => timees : 1245.6963925361633
2024-08-02 18:42:23,962 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 18:42:50,366 [foster.py] => Exemplar size: 1720
2024-08-02 18:42:50,367 [trainer.py] => CNN: {'total': 64.95, '00-09': 70.7, '10-19': 55.9, '20-29': 70.9, '30-39': 64.1, '40-49': 69.4, '50-59': 52.2, '60-69': 65.3, '70-79': 67.0, '80-89': 71.83, 'old': 64.71, 'new': 75.0}
2024-08-02 18:42:50,367 [trainer.py] => NME: {'total': 59.05, '00-09': 61.2, '10-19': 47.8, '20-29': 64.6, '30-39': 53.7, '40-49': 60.6, '50-59': 48.8, '60-69': 61.6, '70-79': 68.3, '80-89': 68.67, 'old': 58.43, 'new': 85.0}
2024-08-02 18:42:50,367 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95]
2024-08-02 18:42:50,367 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45]
2024-08-02 18:42:50,367 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05]
2024-08-02 18:42:50,367 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38]

2024-08-02 18:42:50,367 [trainer.py] => CNN top1 平均值: 72.60
2024-08-02 18:42:50,370 [trainer.py] => All params: 1176692
2024-08-02 18:42:50,372 [trainer.py] => Trainable params: 593958
2024-08-02 18:42:50,433 [foster.py] => Learning on 86-88
2024-08-02 18:42:50,436 [foster.py] => All params: 1177210
2024-08-02 18:42:50,438 [foster.py] => Trainable params: 594346
2024-08-02 18:42:50,480 [foster.py] => per cls weights : [1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979 1.01039979
 1.01039979 1.01039979 0.55280903 0.55280903]
2024-08-02 18:42:53,286 [foster.py] => Task 19, Epoch 1/170 => Loss 5.363, Loss_clf 1.026, Loss_fe 1.727, Loss_kd 2.549, Train_accy 71.54
2024-08-02 18:42:58,060 [foster.py] => Task 19, Epoch 2/170 => Loss 3.850, Loss_clf 0.577, Loss_fe 0.710, Loss_kd 2.502, Train_accy 78.60, Test_accy 62.18
2024-08-02 18:43:02,902 [foster.py] => Task 19, Epoch 3/170 => Loss 3.693, Loss_clf 0.503, Loss_fe 0.582, Loss_kd 2.547, Train_accy 79.74, Test_accy 62.52
2024-08-02 18:43:07,681 [foster.py] => Task 19, Epoch 4/170 => Loss 3.531, Loss_clf 0.454, Loss_fe 0.504, Loss_kd 2.513, Train_accy 81.91, Test_accy 62.56
2024-08-02 18:43:12,440 [foster.py] => Task 19, Epoch 5/170 => Loss 3.450, Loss_clf 0.425, Loss_fe 0.444, Loss_kd 2.520, Train_accy 80.44, Test_accy 62.68
2024-08-02 18:43:15,223 [foster.py] => Task 19, Epoch 6/170 => Loss 3.415, Loss_clf 0.432, Loss_fe 0.435, Loss_kd 2.488, Train_accy 82.28
2024-08-02 18:43:20,000 [foster.py] => Task 19, Epoch 7/170 => Loss 3.395, Loss_clf 0.423, Loss_fe 0.407, Loss_kd 2.505, Train_accy 82.50, Test_accy 62.50
2024-08-02 18:43:24,749 [foster.py] => Task 19, Epoch 8/170 => Loss 3.403, Loss_clf 0.420, Loss_fe 0.415, Loss_kd 2.508, Train_accy 83.35, Test_accy 62.70
2024-08-02 18:43:29,544 [foster.py] => Task 19, Epoch 9/170 => Loss 3.414, Loss_clf 0.431, Loss_fe 0.401, Loss_kd 2.521, Train_accy 81.58, Test_accy 62.72
2024-08-02 18:43:34,307 [foster.py] => Task 19, Epoch 10/170 => Loss 3.362, Loss_clf 0.431, Loss_fe 0.364, Loss_kd 2.507, Train_accy 81.95, Test_accy 62.86
2024-08-02 18:43:37,108 [foster.py] => Task 19, Epoch 11/170 => Loss 3.336, Loss_clf 0.416, Loss_fe 0.349, Loss_kd 2.510, Train_accy 82.50
2024-08-02 18:43:41,856 [foster.py] => Task 19, Epoch 12/170 => Loss 3.310, Loss_clf 0.391, Loss_fe 0.321, Loss_kd 2.537, Train_accy 83.97, Test_accy 62.62
2024-08-02 18:43:46,633 [foster.py] => Task 19, Epoch 13/170 => Loss 3.378, Loss_clf 0.443, Loss_fe 0.333, Loss_kd 2.541, Train_accy 83.05, Test_accy 62.65
2024-08-02 18:43:51,456 [foster.py] => Task 19, Epoch 14/170 => Loss 3.283, Loss_clf 0.404, Loss_fe 0.318, Loss_kd 2.501, Train_accy 84.01, Test_accy 62.84
2024-08-02 18:43:56,300 [foster.py] => Task 19, Epoch 15/170 => Loss 3.252, Loss_clf 0.397, Loss_fe 0.309, Loss_kd 2.486, Train_accy 83.46, Test_accy 62.95
2024-08-02 18:43:59,064 [foster.py] => Task 19, Epoch 16/170 => Loss 3.231, Loss_clf 0.367, Loss_fe 0.296, Loss_kd 2.508, Train_accy 83.93
2024-08-02 18:44:03,890 [foster.py] => Task 19, Epoch 17/170 => Loss 3.272, Loss_clf 0.400, Loss_fe 0.314, Loss_kd 2.499, Train_accy 83.38, Test_accy 62.80
2024-08-02 18:44:08,666 [foster.py] => Task 19, Epoch 18/170 => Loss 3.287, Loss_clf 0.408, Loss_fe 0.296, Loss_kd 2.523, Train_accy 83.60, Test_accy 62.72
2024-08-02 18:44:13,461 [foster.py] => Task 19, Epoch 19/170 => Loss 3.170, Loss_clf 0.363, Loss_fe 0.272, Loss_kd 2.475, Train_accy 84.60, Test_accy 63.25
2024-08-02 18:44:18,250 [foster.py] => Task 19, Epoch 20/170 => Loss 3.279, Loss_clf 0.398, Loss_fe 0.297, Loss_kd 2.524, Train_accy 84.12, Test_accy 63.05
2024-08-02 18:44:21,027 [foster.py] => Task 19, Epoch 21/170 => Loss 3.258, Loss_clf 0.413, Loss_fe 0.272, Loss_kd 2.512, Train_accy 83.01
2024-08-02 18:44:25,859 [foster.py] => Task 19, Epoch 22/170 => Loss 3.183, Loss_clf 0.365, Loss_fe 0.256, Loss_kd 2.501, Train_accy 85.26, Test_accy 63.08
2024-08-02 18:44:30,608 [foster.py] => Task 19, Epoch 23/170 => Loss 3.220, Loss_clf 0.388, Loss_fe 0.271, Loss_kd 2.500, Train_accy 85.33, Test_accy 62.99
2024-08-02 18:44:35,382 [foster.py] => Task 19, Epoch 24/170 => Loss 3.210, Loss_clf 0.392, Loss_fe 0.260, Loss_kd 2.499, Train_accy 85.26, Test_accy 63.16
2024-08-02 18:44:40,143 [foster.py] => Task 19, Epoch 25/170 => Loss 3.214, Loss_clf 0.385, Loss_fe 0.257, Loss_kd 2.512, Train_accy 84.23, Test_accy 63.23
2024-08-02 18:44:42,898 [foster.py] => Task 19, Epoch 26/170 => Loss 3.210, Loss_clf 0.366, Loss_fe 0.265, Loss_kd 2.518, Train_accy 86.03
2024-08-02 18:44:47,643 [foster.py] => Task 19, Epoch 27/170 => Loss 3.235, Loss_clf 0.409, Loss_fe 0.262, Loss_kd 2.504, Train_accy 84.04, Test_accy 63.10
2024-08-02 18:44:52,390 [foster.py] => Task 19, Epoch 28/170 => Loss 3.225, Loss_clf 0.395, Loss_fe 0.250, Loss_kd 2.520, Train_accy 83.86, Test_accy 63.24
2024-08-02 18:44:57,216 [foster.py] => Task 19, Epoch 29/170 => Loss 3.261, Loss_clf 0.404, Loss_fe 0.257, Loss_kd 2.539, Train_accy 83.79, Test_accy 63.06
2024-08-02 18:45:01,974 [foster.py] => Task 19, Epoch 30/170 => Loss 3.189, Loss_clf 0.383, Loss_fe 0.246, Loss_kd 2.501, Train_accy 85.11, Test_accy 63.05
2024-08-02 18:45:04,797 [foster.py] => Task 19, Epoch 31/170 => Loss 3.159, Loss_clf 0.368, Loss_fe 0.241, Loss_kd 2.490, Train_accy 84.26
2024-08-02 18:45:09,546 [foster.py] => Task 19, Epoch 32/170 => Loss 3.166, Loss_clf 0.375, Loss_fe 0.226, Loss_kd 2.504, Train_accy 85.99, Test_accy 63.40
2024-08-02 18:45:14,316 [foster.py] => Task 19, Epoch 33/170 => Loss 3.200, Loss_clf 0.386, Loss_fe 0.244, Loss_kd 2.510, Train_accy 85.11, Test_accy 62.85
2024-08-02 18:45:19,150 [foster.py] => Task 19, Epoch 34/170 => Loss 3.174, Loss_clf 0.380, Loss_fe 0.226, Loss_kd 2.508, Train_accy 84.96, Test_accy 63.09
2024-08-02 18:45:23,920 [foster.py] => Task 19, Epoch 35/170 => Loss 3.178, Loss_clf 0.355, Loss_fe 0.251, Loss_kd 2.511, Train_accy 86.99, Test_accy 62.59
2024-08-02 18:45:26,725 [foster.py] => Task 19, Epoch 36/170 => Loss 3.133, Loss_clf 0.349, Loss_fe 0.225, Loss_kd 2.499, Train_accy 85.07
2024-08-02 18:45:31,508 [foster.py] => Task 19, Epoch 37/170 => Loss 3.213, Loss_clf 0.389, Loss_fe 0.252, Loss_kd 2.511, Train_accy 85.37, Test_accy 63.43
2024-08-02 18:45:36,263 [foster.py] => Task 19, Epoch 38/170 => Loss 3.128, Loss_clf 0.356, Loss_fe 0.237, Loss_kd 2.475, Train_accy 86.43, Test_accy 62.56
2024-08-02 18:45:41,020 [foster.py] => Task 19, Epoch 39/170 => Loss 3.164, Loss_clf 0.374, Loss_fe 0.218, Loss_kd 2.512, Train_accy 85.33, Test_accy 63.31
2024-08-02 18:45:45,783 [foster.py] => Task 19, Epoch 40/170 => Loss 3.147, Loss_clf 0.364, Loss_fe 0.213, Loss_kd 2.510, Train_accy 84.71, Test_accy 63.31
2024-08-02 18:45:48,559 [foster.py] => Task 19, Epoch 41/170 => Loss 3.145, Loss_clf 0.358, Loss_fe 0.224, Loss_kd 2.503, Train_accy 85.77
2024-08-02 18:45:53,407 [foster.py] => Task 19, Epoch 42/170 => Loss 3.144, Loss_clf 0.368, Loss_fe 0.229, Loss_kd 2.487, Train_accy 86.07, Test_accy 63.05
2024-08-02 18:45:58,165 [foster.py] => Task 19, Epoch 43/170 => Loss 3.241, Loss_clf 0.419, Loss_fe 0.227, Loss_kd 2.534, Train_accy 84.74, Test_accy 63.27
2024-08-02 18:46:02,947 [foster.py] => Task 19, Epoch 44/170 => Loss 3.147, Loss_clf 0.355, Loss_fe 0.217, Loss_kd 2.515, Train_accy 86.54, Test_accy 63.22
2024-08-02 18:46:07,751 [foster.py] => Task 19, Epoch 45/170 => Loss 3.142, Loss_clf 0.361, Loss_fe 0.202, Loss_kd 2.519, Train_accy 86.10, Test_accy 62.93
2024-08-02 18:46:10,553 [foster.py] => Task 19, Epoch 46/170 => Loss 3.134, Loss_clf 0.360, Loss_fe 0.194, Loss_kd 2.520, Train_accy 85.74
2024-08-02 18:46:15,307 [foster.py] => Task 19, Epoch 47/170 => Loss 3.155, Loss_clf 0.367, Loss_fe 0.207, Loss_kd 2.520, Train_accy 85.85, Test_accy 62.67
2024-08-02 18:46:20,037 [foster.py] => Task 19, Epoch 48/170 => Loss 3.122, Loss_clf 0.362, Loss_fe 0.190, Loss_kd 2.510, Train_accy 86.43, Test_accy 63.06
2024-08-02 18:46:24,789 [foster.py] => Task 19, Epoch 49/170 => Loss 3.169, Loss_clf 0.371, Loss_fe 0.211, Loss_kd 2.526, Train_accy 86.21, Test_accy 62.67
2024-08-02 18:46:29,627 [foster.py] => Task 19, Epoch 50/170 => Loss 3.174, Loss_clf 0.372, Loss_fe 0.216, Loss_kd 2.526, Train_accy 86.99, Test_accy 62.89
2024-08-02 18:46:32,401 [foster.py] => Task 19, Epoch 51/170 => Loss 3.126, Loss_clf 0.352, Loss_fe 0.208, Loss_kd 2.505, Train_accy 85.81
2024-08-02 18:46:37,137 [foster.py] => Task 19, Epoch 52/170 => Loss 3.119, Loss_clf 0.362, Loss_fe 0.214, Loss_kd 2.484, Train_accy 85.70, Test_accy 62.97
2024-08-02 18:46:41,907 [foster.py] => Task 19, Epoch 53/170 => Loss 3.133, Loss_clf 0.360, Loss_fe 0.207, Loss_kd 2.506, Train_accy 86.29, Test_accy 62.40
2024-08-02 18:46:46,650 [foster.py] => Task 19, Epoch 54/170 => Loss 3.182, Loss_clf 0.368, Loss_fe 0.219, Loss_kd 2.534, Train_accy 85.22, Test_accy 63.42
2024-08-02 18:46:51,424 [foster.py] => Task 19, Epoch 55/170 => Loss 3.130, Loss_clf 0.362, Loss_fe 0.208, Loss_kd 2.500, Train_accy 86.88, Test_accy 63.08
2024-08-02 18:46:54,201 [foster.py] => Task 19, Epoch 56/170 => Loss 3.113, Loss_clf 0.345, Loss_fe 0.195, Loss_kd 2.513, Train_accy 86.40
2024-08-02 18:46:58,952 [foster.py] => Task 19, Epoch 57/170 => Loss 3.157, Loss_clf 0.367, Loss_fe 0.179, Loss_kd 2.550, Train_accy 86.21, Test_accy 62.80
2024-08-02 18:47:03,761 [foster.py] => Task 19, Epoch 58/170 => Loss 3.066, Loss_clf 0.339, Loss_fe 0.164, Loss_kd 2.504, Train_accy 87.02, Test_accy 63.20
2024-08-02 18:47:08,496 [foster.py] => Task 19, Epoch 59/170 => Loss 3.124, Loss_clf 0.368, Loss_fe 0.178, Loss_kd 2.518, Train_accy 85.85, Test_accy 63.35
2024-08-02 18:47:13,353 [foster.py] => Task 19, Epoch 60/170 => Loss 3.133, Loss_clf 0.360, Loss_fe 0.191, Loss_kd 2.522, Train_accy 86.51, Test_accy 63.53
2024-08-02 18:47:16,216 [foster.py] => Task 19, Epoch 61/170 => Loss 3.104, Loss_clf 0.364, Loss_fe 0.190, Loss_kd 2.490, Train_accy 87.13
2024-08-02 18:47:21,040 [foster.py] => Task 19, Epoch 62/170 => Loss 3.113, Loss_clf 0.364, Loss_fe 0.181, Loss_kd 2.508, Train_accy 85.92, Test_accy 63.30
2024-08-02 18:47:25,874 [foster.py] => Task 19, Epoch 63/170 => Loss 3.196, Loss_clf 0.399, Loss_fe 0.195, Loss_kd 2.541, Train_accy 84.56, Test_accy 63.27
2024-08-02 18:47:30,642 [foster.py] => Task 19, Epoch 64/170 => Loss 3.092, Loss_clf 0.336, Loss_fe 0.183, Loss_kd 2.513, Train_accy 87.39, Test_accy 63.49
2024-08-02 18:47:35,483 [foster.py] => Task 19, Epoch 65/170 => Loss 3.088, Loss_clf 0.338, Loss_fe 0.185, Loss_kd 2.505, Train_accy 86.29, Test_accy 64.09
2024-08-02 18:47:38,264 [foster.py] => Task 19, Epoch 66/170 => Loss 3.140, Loss_clf 0.365, Loss_fe 0.193, Loss_kd 2.521, Train_accy 86.62
2024-08-02 18:47:43,016 [foster.py] => Task 19, Epoch 67/170 => Loss 3.090, Loss_clf 0.353, Loss_fe 0.176, Loss_kd 2.501, Train_accy 86.99, Test_accy 63.35
2024-08-02 18:47:47,746 [foster.py] => Task 19, Epoch 68/170 => Loss 3.122, Loss_clf 0.357, Loss_fe 0.180, Loss_kd 2.525, Train_accy 86.47, Test_accy 63.05
2024-08-02 18:47:52,554 [foster.py] => Task 19, Epoch 69/170 => Loss 3.095, Loss_clf 0.351, Loss_fe 0.157, Loss_kd 2.526, Train_accy 87.21, Test_accy 63.02
2024-08-02 18:47:57,355 [foster.py] => Task 19, Epoch 70/170 => Loss 3.119, Loss_clf 0.359, Loss_fe 0.169, Loss_kd 2.531, Train_accy 86.25, Test_accy 63.70
2024-08-02 18:48:00,145 [foster.py] => Task 19, Epoch 71/170 => Loss 3.073, Loss_clf 0.337, Loss_fe 0.163, Loss_kd 2.513, Train_accy 88.01
2024-08-02 18:48:04,933 [foster.py] => Task 19, Epoch 72/170 => Loss 3.094, Loss_clf 0.358, Loss_fe 0.155, Loss_kd 2.521, Train_accy 87.79, Test_accy 63.64
2024-08-02 18:48:09,751 [foster.py] => Task 19, Epoch 73/170 => Loss 3.083, Loss_clf 0.336, Loss_fe 0.174, Loss_kd 2.513, Train_accy 86.95, Test_accy 63.44
2024-08-02 18:48:14,512 [foster.py] => Task 19, Epoch 74/170 => Loss 3.123, Loss_clf 0.344, Loss_fe 0.184, Loss_kd 2.534, Train_accy 87.24, Test_accy 63.32
2024-08-02 18:48:19,276 [foster.py] => Task 19, Epoch 75/170 => Loss 3.045, Loss_clf 0.326, Loss_fe 0.169, Loss_kd 2.491, Train_accy 87.83, Test_accy 63.53
2024-08-02 18:48:22,060 [foster.py] => Task 19, Epoch 76/170 => Loss 3.097, Loss_clf 0.350, Loss_fe 0.165, Loss_kd 2.521, Train_accy 87.46
2024-08-02 18:48:26,816 [foster.py] => Task 19, Epoch 77/170 => Loss 3.081, Loss_clf 0.348, Loss_fe 0.166, Loss_kd 2.507, Train_accy 86.32, Test_accy 63.59
2024-08-02 18:48:31,591 [foster.py] => Task 19, Epoch 78/170 => Loss 3.102, Loss_clf 0.341, Loss_fe 0.173, Loss_kd 2.528, Train_accy 88.09, Test_accy 63.38
2024-08-02 18:48:36,465 [foster.py] => Task 19, Epoch 79/170 => Loss 3.040, Loss_clf 0.332, Loss_fe 0.157, Loss_kd 2.492, Train_accy 86.69, Test_accy 63.40
2024-08-02 18:48:41,223 [foster.py] => Task 19, Epoch 80/170 => Loss 3.125, Loss_clf 0.355, Loss_fe 0.177, Loss_kd 2.532, Train_accy 87.72, Test_accy 63.56
2024-08-02 18:48:44,067 [foster.py] => Task 19, Epoch 81/170 => Loss 3.038, Loss_clf 0.320, Loss_fe 0.141, Loss_kd 2.517, Train_accy 87.46
2024-08-02 18:48:48,832 [foster.py] => Task 19, Epoch 82/170 => Loss 3.047, Loss_clf 0.336, Loss_fe 0.149, Loss_kd 2.503, Train_accy 87.79, Test_accy 63.60
2024-08-02 18:48:53,603 [foster.py] => Task 19, Epoch 83/170 => Loss 3.047, Loss_clf 0.321, Loss_fe 0.153, Loss_kd 2.513, Train_accy 88.42, Test_accy 63.59
2024-08-02 18:48:58,409 [foster.py] => Task 19, Epoch 84/170 => Loss 3.015, Loss_clf 0.314, Loss_fe 0.143, Loss_kd 2.498, Train_accy 88.05, Test_accy 63.78
2024-08-02 18:49:03,182 [foster.py] => Task 19, Epoch 85/170 => Loss 3.018, Loss_clf 0.331, Loss_fe 0.139, Loss_kd 2.488, Train_accy 86.84, Test_accy 63.49
2024-08-02 18:49:05,997 [foster.py] => Task 19, Epoch 86/170 => Loss 3.023, Loss_clf 0.317, Loss_fe 0.130, Loss_kd 2.516, Train_accy 89.08
2024-08-02 18:49:10,767 [foster.py] => Task 19, Epoch 87/170 => Loss 3.093, Loss_clf 0.347, Loss_fe 0.148, Loss_kd 2.537, Train_accy 87.79, Test_accy 63.94
2024-08-02 18:49:15,526 [foster.py] => Task 19, Epoch 88/170 => Loss 3.100, Loss_clf 0.365, Loss_fe 0.142, Loss_kd 2.532, Train_accy 87.50, Test_accy 63.88
2024-08-02 18:49:20,268 [foster.py] => Task 19, Epoch 89/170 => Loss 3.023, Loss_clf 0.320, Loss_fe 0.140, Loss_kd 2.503, Train_accy 88.01, Test_accy 63.92
2024-08-02 18:49:25,065 [foster.py] => Task 19, Epoch 90/170 => Loss 3.052, Loss_clf 0.338, Loss_fe 0.146, Loss_kd 2.508, Train_accy 88.24, Test_accy 63.92
2024-08-02 18:49:27,850 [foster.py] => Task 19, Epoch 91/170 => Loss 3.004, Loss_clf 0.320, Loss_fe 0.134, Loss_kd 2.490, Train_accy 89.15
2024-08-02 18:49:32,694 [foster.py] => Task 19, Epoch 92/170 => Loss 3.029, Loss_clf 0.342, Loss_fe 0.140, Loss_kd 2.487, Train_accy 88.42, Test_accy 63.85
2024-08-02 18:49:37,500 [foster.py] => Task 19, Epoch 93/170 => Loss 3.037, Loss_clf 0.337, Loss_fe 0.125, Loss_kd 2.516, Train_accy 87.10, Test_accy 63.74
2024-08-02 18:49:42,274 [foster.py] => Task 19, Epoch 94/170 => Loss 2.998, Loss_clf 0.316, Loss_fe 0.135, Loss_kd 2.487, Train_accy 88.90, Test_accy 63.83
2024-08-02 18:49:47,046 [foster.py] => Task 19, Epoch 95/170 => Loss 3.043, Loss_clf 0.336, Loss_fe 0.152, Loss_kd 2.495, Train_accy 87.61, Test_accy 63.40
2024-08-02 18:49:49,846 [foster.py] => Task 19, Epoch 96/170 => Loss 3.051, Loss_clf 0.338, Loss_fe 0.153, Loss_kd 2.501, Train_accy 87.90
2024-08-02 18:49:54,612 [foster.py] => Task 19, Epoch 97/170 => Loss 3.009, Loss_clf 0.321, Loss_fe 0.123, Loss_kd 2.505, Train_accy 88.09, Test_accy 63.88
2024-08-02 18:49:59,371 [foster.py] => Task 19, Epoch 98/170 => Loss 3.026, Loss_clf 0.323, Loss_fe 0.117, Loss_kd 2.525, Train_accy 88.42, Test_accy 64.01
2024-08-02 18:50:04,254 [foster.py] => Task 19, Epoch 99/170 => Loss 3.013, Loss_clf 0.328, Loss_fe 0.130, Loss_kd 2.496, Train_accy 88.42, Test_accy 63.82
2024-08-02 18:50:09,123 [foster.py] => Task 19, Epoch 100/170 => Loss 3.016, Loss_clf 0.316, Loss_fe 0.120, Loss_kd 2.520, Train_accy 89.04, Test_accy 63.92
2024-08-02 18:50:11,939 [foster.py] => Task 19, Epoch 101/170 => Loss 3.019, Loss_clf 0.321, Loss_fe 0.127, Loss_kd 2.510, Train_accy 88.71
2024-08-02 18:50:16,689 [foster.py] => Task 19, Epoch 102/170 => Loss 3.045, Loss_clf 0.317, Loss_fe 0.127, Loss_kd 2.541, Train_accy 88.97, Test_accy 63.83
2024-08-02 18:50:21,460 [foster.py] => Task 19, Epoch 103/170 => Loss 3.034, Loss_clf 0.330, Loss_fe 0.125, Loss_kd 2.519, Train_accy 88.49, Test_accy 64.06
2024-08-02 18:50:26,213 [foster.py] => Task 19, Epoch 104/170 => Loss 3.017, Loss_clf 0.318, Loss_fe 0.126, Loss_kd 2.513, Train_accy 88.90, Test_accy 64.07
2024-08-02 18:50:31,003 [foster.py] => Task 19, Epoch 105/170 => Loss 2.999, Loss_clf 0.309, Loss_fe 0.112, Loss_kd 2.519, Train_accy 89.15, Test_accy 63.97
2024-08-02 18:50:33,794 [foster.py] => Task 19, Epoch 106/170 => Loss 2.943, Loss_clf 0.290, Loss_fe 0.123, Loss_kd 2.470, Train_accy 90.00
2024-08-02 18:50:38,553 [foster.py] => Task 19, Epoch 107/170 => Loss 2.987, Loss_clf 0.305, Loss_fe 0.124, Loss_kd 2.498, Train_accy 89.12, Test_accy 63.89
2024-08-02 18:50:43,346 [foster.py] => Task 19, Epoch 108/170 => Loss 2.965, Loss_clf 0.296, Loss_fe 0.110, Loss_kd 2.500, Train_accy 89.08, Test_accy 64.02
2024-08-02 18:50:48,113 [foster.py] => Task 19, Epoch 109/170 => Loss 3.053, Loss_clf 0.333, Loss_fe 0.124, Loss_kd 2.535, Train_accy 88.86, Test_accy 63.85
2024-08-02 18:50:52,877 [foster.py] => Task 19, Epoch 110/170 => Loss 3.024, Loss_clf 0.311, Loss_fe 0.119, Loss_kd 2.533, Train_accy 88.97, Test_accy 64.01
2024-08-02 18:50:55,664 [foster.py] => Task 19, Epoch 111/170 => Loss 2.987, Loss_clf 0.304, Loss_fe 0.135, Loss_kd 2.488, Train_accy 90.07
2024-08-02 18:51:00,435 [foster.py] => Task 19, Epoch 112/170 => Loss 2.973, Loss_clf 0.300, Loss_fe 0.106, Loss_kd 2.508, Train_accy 89.52, Test_accy 64.05
2024-08-02 18:51:05,235 [foster.py] => Task 19, Epoch 113/170 => Loss 3.010, Loss_clf 0.321, Loss_fe 0.101, Loss_kd 2.528, Train_accy 87.76, Test_accy 64.06
2024-08-02 18:51:10,020 [foster.py] => Task 19, Epoch 114/170 => Loss 3.010, Loss_clf 0.310, Loss_fe 0.122, Loss_kd 2.517, Train_accy 88.68, Test_accy 64.35
2024-08-02 18:51:14,803 [foster.py] => Task 19, Epoch 115/170 => Loss 2.995, Loss_clf 0.310, Loss_fe 0.103, Loss_kd 2.521, Train_accy 89.60, Test_accy 64.28
2024-08-02 18:51:17,680 [foster.py] => Task 19, Epoch 116/170 => Loss 3.025, Loss_clf 0.331, Loss_fe 0.114, Loss_kd 2.519, Train_accy 88.49
2024-08-02 18:51:22,588 [foster.py] => Task 19, Epoch 117/170 => Loss 3.050, Loss_clf 0.341, Loss_fe 0.122, Loss_kd 2.526, Train_accy 88.09, Test_accy 63.88
2024-08-02 18:51:27,366 [foster.py] => Task 19, Epoch 118/170 => Loss 2.978, Loss_clf 0.310, Loss_fe 0.110, Loss_kd 2.499, Train_accy 89.38, Test_accy 63.66
2024-08-02 18:51:32,151 [foster.py] => Task 19, Epoch 119/170 => Loss 3.015, Loss_clf 0.328, Loss_fe 0.117, Loss_kd 2.509, Train_accy 89.34, Test_accy 64.03
2024-08-02 18:51:36,966 [foster.py] => Task 19, Epoch 120/170 => Loss 2.962, Loss_clf 0.303, Loss_fe 0.113, Loss_kd 2.486, Train_accy 89.15, Test_accy 63.89
2024-08-02 18:51:39,834 [foster.py] => Task 19, Epoch 121/170 => Loss 2.979, Loss_clf 0.296, Loss_fe 0.109, Loss_kd 2.514, Train_accy 89.78
2024-08-02 18:51:44,662 [foster.py] => Task 19, Epoch 122/170 => Loss 3.001, Loss_clf 0.317, Loss_fe 0.098, Loss_kd 2.526, Train_accy 89.08, Test_accy 64.06
2024-08-02 18:51:49,413 [foster.py] => Task 19, Epoch 123/170 => Loss 2.971, Loss_clf 0.314, Loss_fe 0.105, Loss_kd 2.492, Train_accy 89.85, Test_accy 63.93
2024-08-02 18:51:54,208 [foster.py] => Task 19, Epoch 124/170 => Loss 2.995, Loss_clf 0.307, Loss_fe 0.106, Loss_kd 2.522, Train_accy 89.15, Test_accy 64.07
2024-08-02 18:51:58,994 [foster.py] => Task 19, Epoch 125/170 => Loss 2.963, Loss_clf 0.303, Loss_fe 0.113, Loss_kd 2.487, Train_accy 89.04, Test_accy 64.11
2024-08-02 18:52:01,785 [foster.py] => Task 19, Epoch 126/170 => Loss 2.974, Loss_clf 0.307, Loss_fe 0.099, Loss_kd 2.508, Train_accy 89.38
2024-08-02 18:52:06,573 [foster.py] => Task 19, Epoch 127/170 => Loss 2.986, Loss_clf 0.316, Loss_fe 0.111, Loss_kd 2.499, Train_accy 89.34, Test_accy 63.99
2024-08-02 18:52:11,317 [foster.py] => Task 19, Epoch 128/170 => Loss 2.954, Loss_clf 0.290, Loss_fe 0.100, Loss_kd 2.504, Train_accy 90.66, Test_accy 64.07
2024-08-02 18:52:16,126 [foster.py] => Task 19, Epoch 129/170 => Loss 3.006, Loss_clf 0.321, Loss_fe 0.101, Loss_kd 2.524, Train_accy 89.08, Test_accy 64.03
2024-08-02 18:52:20,972 [foster.py] => Task 19, Epoch 130/170 => Loss 2.966, Loss_clf 0.316, Loss_fe 0.099, Loss_kd 2.491, Train_accy 88.82, Test_accy 64.03
2024-08-02 18:52:23,746 [foster.py] => Task 19, Epoch 131/170 => Loss 2.993, Loss_clf 0.326, Loss_fe 0.096, Loss_kd 2.511, Train_accy 88.64
2024-08-02 18:52:28,515 [foster.py] => Task 19, Epoch 132/170 => Loss 2.934, Loss_clf 0.288, Loss_fe 0.091, Loss_kd 2.495, Train_accy 89.49, Test_accy 64.03
2024-08-02 18:52:33,261 [foster.py] => Task 19, Epoch 133/170 => Loss 2.955, Loss_clf 0.292, Loss_fe 0.094, Loss_kd 2.509, Train_accy 90.11, Test_accy 64.10
2024-08-02 18:52:38,022 [foster.py] => Task 19, Epoch 134/170 => Loss 3.037, Loss_clf 0.315, Loss_fe 0.109, Loss_kd 2.553, Train_accy 89.41, Test_accy 64.15
2024-08-02 18:52:42,773 [foster.py] => Task 19, Epoch 135/170 => Loss 2.993, Loss_clf 0.312, Loss_fe 0.108, Loss_kd 2.513, Train_accy 88.93, Test_accy 64.11
2024-08-02 18:52:45,570 [foster.py] => Task 19, Epoch 136/170 => Loss 2.958, Loss_clf 0.291, Loss_fe 0.105, Loss_kd 2.503, Train_accy 89.63
2024-08-02 18:52:50,398 [foster.py] => Task 19, Epoch 137/170 => Loss 2.967, Loss_clf 0.318, Loss_fe 0.094, Loss_kd 2.496, Train_accy 90.18, Test_accy 64.12
2024-08-02 18:52:55,208 [foster.py] => Task 19, Epoch 138/170 => Loss 2.965, Loss_clf 0.313, Loss_fe 0.096, Loss_kd 2.497, Train_accy 88.79, Test_accy 64.03
2024-08-02 18:52:59,977 [foster.py] => Task 19, Epoch 139/170 => Loss 2.969, Loss_clf 0.312, Loss_fe 0.084, Loss_kd 2.513, Train_accy 89.08, Test_accy 64.19
2024-08-02 18:53:04,764 [foster.py] => Task 19, Epoch 140/170 => Loss 2.922, Loss_clf 0.287, Loss_fe 0.087, Loss_kd 2.489, Train_accy 89.93, Test_accy 64.15
2024-08-02 18:53:07,602 [foster.py] => Task 19, Epoch 141/170 => Loss 3.021, Loss_clf 0.314, Loss_fe 0.104, Loss_kd 2.542, Train_accy 90.22
2024-08-02 18:53:12,364 [foster.py] => Task 19, Epoch 142/170 => Loss 3.009, Loss_clf 0.322, Loss_fe 0.094, Loss_kd 2.532, Train_accy 88.05, Test_accy 64.19
2024-08-02 18:53:17,147 [foster.py] => Task 19, Epoch 143/170 => Loss 2.947, Loss_clf 0.300, Loss_fe 0.101, Loss_kd 2.487, Train_accy 89.60, Test_accy 64.19
2024-08-02 18:53:21,881 [foster.py] => Task 19, Epoch 144/170 => Loss 2.971, Loss_clf 0.314, Loss_fe 0.089, Loss_kd 2.509, Train_accy 88.24, Test_accy 64.10
2024-08-02 18:53:26,633 [foster.py] => Task 19, Epoch 145/170 => Loss 2.971, Loss_clf 0.305, Loss_fe 0.085, Loss_kd 2.520, Train_accy 89.60, Test_accy 64.18
2024-08-02 18:53:29,456 [foster.py] => Task 19, Epoch 146/170 => Loss 2.990, Loss_clf 0.309, Loss_fe 0.092, Loss_kd 2.529, Train_accy 90.26
2024-08-02 18:53:34,212 [foster.py] => Task 19, Epoch 147/170 => Loss 2.973, Loss_clf 0.309, Loss_fe 0.092, Loss_kd 2.512, Train_accy 90.07, Test_accy 64.11
2024-08-02 18:53:39,077 [foster.py] => Task 19, Epoch 148/170 => Loss 2.937, Loss_clf 0.290, Loss_fe 0.099, Loss_kd 2.489, Train_accy 89.38, Test_accy 64.07
2024-08-02 18:53:43,879 [foster.py] => Task 19, Epoch 149/170 => Loss 2.992, Loss_clf 0.313, Loss_fe 0.090, Loss_kd 2.529, Train_accy 89.71, Test_accy 64.16
2024-08-02 18:53:48,651 [foster.py] => Task 19, Epoch 150/170 => Loss 2.919, Loss_clf 0.281, Loss_fe 0.081, Loss_kd 2.497, Train_accy 90.40, Test_accy 64.09
2024-08-02 18:53:51,434 [foster.py] => Task 19, Epoch 151/170 => Loss 2.974, Loss_clf 0.314, Loss_fe 0.101, Loss_kd 2.500, Train_accy 90.59
2024-08-02 18:53:56,226 [foster.py] => Task 19, Epoch 152/170 => Loss 2.931, Loss_clf 0.282, Loss_fe 0.087, Loss_kd 2.502, Train_accy 89.85, Test_accy 64.19
2024-08-02 18:54:00,989 [foster.py] => Task 19, Epoch 153/170 => Loss 2.951, Loss_clf 0.297, Loss_fe 0.099, Loss_kd 2.495, Train_accy 89.63, Test_accy 64.14
2024-08-02 18:54:05,714 [foster.py] => Task 19, Epoch 154/170 => Loss 3.011, Loss_clf 0.302, Loss_fe 0.094, Loss_kd 2.554, Train_accy 89.63, Test_accy 64.14
2024-08-02 18:54:10,505 [foster.py] => Task 19, Epoch 155/170 => Loss 2.916, Loss_clf 0.284, Loss_fe 0.072, Loss_kd 2.500, Train_accy 89.96, Test_accy 64.10
2024-08-02 18:54:13,264 [foster.py] => Task 19, Epoch 156/170 => Loss 2.898, Loss_clf 0.276, Loss_fe 0.095, Loss_kd 2.468, Train_accy 90.81
2024-08-02 18:54:18,020 [foster.py] => Task 19, Epoch 157/170 => Loss 2.962, Loss_clf 0.294, Loss_fe 0.088, Loss_kd 2.520, Train_accy 89.74, Test_accy 64.16
2024-08-02 18:54:22,840 [foster.py] => Task 19, Epoch 158/170 => Loss 2.955, Loss_clf 0.297, Loss_fe 0.090, Loss_kd 2.508, Train_accy 90.77, Test_accy 64.10
2024-08-02 18:54:27,594 [foster.py] => Task 19, Epoch 159/170 => Loss 2.972, Loss_clf 0.319, Loss_fe 0.092, Loss_kd 2.502, Train_accy 89.60, Test_accy 64.07
2024-08-02 18:54:32,378 [foster.py] => Task 19, Epoch 160/170 => Loss 2.982, Loss_clf 0.309, Loss_fe 0.085, Loss_kd 2.527, Train_accy 90.70, Test_accy 64.12
2024-08-02 18:54:35,197 [foster.py] => Task 19, Epoch 161/170 => Loss 2.951, Loss_clf 0.289, Loss_fe 0.104, Loss_kd 2.498, Train_accy 90.62
2024-08-02 18:54:40,005 [foster.py] => Task 19, Epoch 162/170 => Loss 3.016, Loss_clf 0.318, Loss_fe 0.106, Loss_kd 2.531, Train_accy 90.11, Test_accy 64.06
2024-08-02 18:54:44,786 [foster.py] => Task 19, Epoch 163/170 => Loss 2.903, Loss_clf 0.275, Loss_fe 0.078, Loss_kd 2.490, Train_accy 90.81, Test_accy 64.09
2024-08-02 18:54:49,556 [foster.py] => Task 19, Epoch 164/170 => Loss 2.946, Loss_clf 0.285, Loss_fe 0.093, Loss_kd 2.508, Train_accy 90.07, Test_accy 64.15
2024-08-02 18:54:54,358 [foster.py] => Task 19, Epoch 165/170 => Loss 2.946, Loss_clf 0.295, Loss_fe 0.079, Loss_kd 2.512, Train_accy 89.60, Test_accy 64.08
2024-08-02 18:54:57,130 [foster.py] => Task 19, Epoch 166/170 => Loss 2.974, Loss_clf 0.307, Loss_fe 0.096, Loss_kd 2.512, Train_accy 90.66
2024-08-02 18:55:01,869 [foster.py] => Task 19, Epoch 167/170 => Loss 2.938, Loss_clf 0.303, Loss_fe 0.083, Loss_kd 2.493, Train_accy 89.26, Test_accy 64.16
2024-08-02 18:55:06,622 [foster.py] => Task 19, Epoch 168/170 => Loss 2.952, Loss_clf 0.287, Loss_fe 0.080, Loss_kd 2.525, Train_accy 90.40, Test_accy 64.16
2024-08-02 18:55:11,416 [foster.py] => Task 19, Epoch 169/170 => Loss 2.962, Loss_clf 0.295, Loss_fe 0.095, Loss_kd 2.512, Train_accy 89.96, Test_accy 64.20
2024-08-02 18:55:16,217 [foster.py] => Task 19, Epoch 170/170 => Loss 2.961, Loss_clf 0.304, Loss_fe 0.098, Loss_kd 2.498, Train_accy 89.71, Test_accy 64.19
2024-08-02 18:55:16,219 [foster.py] => do not weight align teacher!
2024-08-02 18:55:16,220 [foster.py] => per cls weights : [1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888 1.01234888
 1.01234888 1.01234888 0.468998   0.468998  ]
2024-08-02 18:55:21,554 [foster.py] => SNet: Task 19, Epoch 1/130 => Loss 30.467,  Loss1 0.772, Train_accy 59.85, Test_accy 59.88
2024-08-02 18:55:25,401 [foster.py] => SNet: Task 19, Epoch 2/130 => Loss 30.409,  Loss1 0.770, Train_accy 70.88
2024-08-02 18:55:29,277 [foster.py] => SNet: Task 19, Epoch 3/130 => Loss 30.372,  Loss1 0.771, Train_accy 70.70
2024-08-02 18:55:33,128 [foster.py] => SNet: Task 19, Epoch 4/130 => Loss 30.322,  Loss1 0.771, Train_accy 74.34
2024-08-02 18:55:37,071 [foster.py] => SNet: Task 19, Epoch 5/130 => Loss 30.369,  Loss1 0.771, Train_accy 74.63
2024-08-02 18:55:42,189 [foster.py] => SNet: Task 19, Epoch 6/130 => Loss 30.391,  Loss1 0.771, Train_accy 73.38, Test_accy 62.50
2024-08-02 18:55:46,070 [foster.py] => SNet: Task 19, Epoch 7/130 => Loss 30.404,  Loss1 0.770, Train_accy 75.11
2024-08-02 18:55:49,935 [foster.py] => SNet: Task 19, Epoch 8/130 => Loss 30.370,  Loss1 0.771, Train_accy 76.10
2024-08-02 18:55:53,848 [foster.py] => SNet: Task 19, Epoch 9/130 => Loss 30.349,  Loss1 0.770, Train_accy 76.18
2024-08-02 18:55:57,700 [foster.py] => SNet: Task 19, Epoch 10/130 => Loss 30.358,  Loss1 0.771, Train_accy 77.35
2024-08-02 18:56:02,826 [foster.py] => SNet: Task 19, Epoch 11/130 => Loss 30.388,  Loss1 0.770, Train_accy 75.66, Test_accy 62.26
2024-08-02 18:56:06,683 [foster.py] => SNet: Task 19, Epoch 12/130 => Loss 30.349,  Loss1 0.770, Train_accy 76.73
2024-08-02 18:56:10,561 [foster.py] => SNet: Task 19, Epoch 13/130 => Loss 30.346,  Loss1 0.770, Train_accy 78.24
2024-08-02 18:56:14,457 [foster.py] => SNet: Task 19, Epoch 14/130 => Loss 30.392,  Loss1 0.771, Train_accy 78.35
2024-08-02 18:56:18,339 [foster.py] => SNet: Task 19, Epoch 15/130 => Loss 30.377,  Loss1 0.770, Train_accy 78.05
2024-08-02 18:56:23,462 [foster.py] => SNet: Task 19, Epoch 16/130 => Loss 30.348,  Loss1 0.771, Train_accy 78.31, Test_accy 62.55
2024-08-02 18:56:27,329 [foster.py] => SNet: Task 19, Epoch 17/130 => Loss 30.394,  Loss1 0.771, Train_accy 77.83
2024-08-02 18:56:31,219 [foster.py] => SNet: Task 19, Epoch 18/130 => Loss 30.352,  Loss1 0.770, Train_accy 76.95
2024-08-02 18:56:35,090 [foster.py] => SNet: Task 19, Epoch 19/130 => Loss 30.378,  Loss1 0.770, Train_accy 79.71
2024-08-02 18:56:38,969 [foster.py] => SNet: Task 19, Epoch 20/130 => Loss 30.369,  Loss1 0.771, Train_accy 78.46
2024-08-02 18:56:44,093 [foster.py] => SNet: Task 19, Epoch 21/130 => Loss 30.395,  Loss1 0.770, Train_accy 77.87, Test_accy 62.68
2024-08-02 18:56:48,029 [foster.py] => SNet: Task 19, Epoch 22/130 => Loss 30.372,  Loss1 0.770, Train_accy 77.50
2024-08-02 18:56:51,928 [foster.py] => SNet: Task 19, Epoch 23/130 => Loss 30.368,  Loss1 0.771, Train_accy 79.08
2024-08-02 18:56:55,793 [foster.py] => SNet: Task 19, Epoch 24/130 => Loss 30.389,  Loss1 0.771, Train_accy 80.15
2024-08-02 18:56:59,700 [foster.py] => SNet: Task 19, Epoch 25/130 => Loss 30.357,  Loss1 0.770, Train_accy 79.23
2024-08-02 18:57:04,819 [foster.py] => SNet: Task 19, Epoch 26/130 => Loss 30.385,  Loss1 0.771, Train_accy 79.38, Test_accy 62.93
2024-08-02 18:57:08,685 [foster.py] => SNet: Task 19, Epoch 27/130 => Loss 30.353,  Loss1 0.770, Train_accy 78.86
2024-08-02 18:57:12,568 [foster.py] => SNet: Task 19, Epoch 28/130 => Loss 30.308,  Loss1 0.770, Train_accy 80.04
2024-08-02 18:57:16,449 [foster.py] => SNet: Task 19, Epoch 29/130 => Loss 30.348,  Loss1 0.770, Train_accy 80.07
2024-08-02 18:57:20,354 [foster.py] => SNet: Task 19, Epoch 30/130 => Loss 30.432,  Loss1 0.770, Train_accy 79.19
2024-08-02 18:57:25,494 [foster.py] => SNet: Task 19, Epoch 31/130 => Loss 30.362,  Loss1 0.770, Train_accy 79.08, Test_accy 62.99
2024-08-02 18:57:29,366 [foster.py] => SNet: Task 19, Epoch 32/130 => Loss 30.349,  Loss1 0.770, Train_accy 79.71
2024-08-02 18:57:33,224 [foster.py] => SNet: Task 19, Epoch 33/130 => Loss 30.367,  Loss1 0.770, Train_accy 79.12
2024-08-02 18:57:37,112 [foster.py] => SNet: Task 19, Epoch 34/130 => Loss 30.403,  Loss1 0.771, Train_accy 78.82
2024-08-02 18:57:41,016 [foster.py] => SNet: Task 19, Epoch 35/130 => Loss 30.324,  Loss1 0.771, Train_accy 79.04
2024-08-02 18:57:46,138 [foster.py] => SNet: Task 19, Epoch 36/130 => Loss 30.395,  Loss1 0.770, Train_accy 79.30, Test_accy 62.48
2024-08-02 18:57:49,994 [foster.py] => SNet: Task 19, Epoch 37/130 => Loss 30.358,  Loss1 0.771, Train_accy 78.93
2024-08-02 18:57:53,871 [foster.py] => SNet: Task 19, Epoch 38/130 => Loss 30.376,  Loss1 0.770, Train_accy 79.41
2024-08-02 18:57:57,796 [foster.py] => SNet: Task 19, Epoch 39/130 => Loss 30.332,  Loss1 0.771, Train_accy 79.52
2024-08-02 18:58:01,703 [foster.py] => SNet: Task 19, Epoch 40/130 => Loss 30.343,  Loss1 0.770, Train_accy 79.82
2024-08-02 18:58:06,832 [foster.py] => SNet: Task 19, Epoch 41/130 => Loss 30.362,  Loss1 0.770, Train_accy 79.60, Test_accy 62.73
2024-08-02 18:58:10,707 [foster.py] => SNet: Task 19, Epoch 42/130 => Loss 30.324,  Loss1 0.770, Train_accy 79.74
2024-08-02 18:58:14,586 [foster.py] => SNet: Task 19, Epoch 43/130 => Loss 30.359,  Loss1 0.771, Train_accy 80.77
2024-08-02 18:58:18,440 [foster.py] => SNet: Task 19, Epoch 44/130 => Loss 30.358,  Loss1 0.770, Train_accy 80.44
2024-08-02 18:58:22,323 [foster.py] => SNet: Task 19, Epoch 45/130 => Loss 30.377,  Loss1 0.769, Train_accy 80.26
2024-08-02 18:58:27,486 [foster.py] => SNet: Task 19, Epoch 46/130 => Loss 30.298,  Loss1 0.771, Train_accy 79.89, Test_accy 62.82
2024-08-02 18:58:31,373 [foster.py] => SNet: Task 19, Epoch 47/130 => Loss 30.386,  Loss1 0.770, Train_accy 80.48
2024-08-02 18:58:35,244 [foster.py] => SNet: Task 19, Epoch 48/130 => Loss 30.347,  Loss1 0.770, Train_accy 79.30
2024-08-02 18:58:39,116 [foster.py] => SNet: Task 19, Epoch 49/130 => Loss 30.373,  Loss1 0.770, Train_accy 79.71
2024-08-02 18:58:42,993 [foster.py] => SNet: Task 19, Epoch 50/130 => Loss 30.379,  Loss1 0.770, Train_accy 80.77
2024-08-02 18:58:48,124 [foster.py] => SNet: Task 19, Epoch 51/130 => Loss 30.318,  Loss1 0.770, Train_accy 79.49, Test_accy 62.77
2024-08-02 18:58:52,003 [foster.py] => SNet: Task 19, Epoch 52/130 => Loss 30.357,  Loss1 0.770, Train_accy 80.51
2024-08-02 18:58:55,891 [foster.py] => SNet: Task 19, Epoch 53/130 => Loss 30.380,  Loss1 0.770, Train_accy 79.96
2024-08-02 18:58:59,772 [foster.py] => SNet: Task 19, Epoch 54/130 => Loss 30.367,  Loss1 0.770, Train_accy 79.60
2024-08-02 18:59:03,676 [foster.py] => SNet: Task 19, Epoch 55/130 => Loss 30.362,  Loss1 0.771, Train_accy 80.99
2024-08-02 18:59:08,847 [foster.py] => SNet: Task 19, Epoch 56/130 => Loss 30.357,  Loss1 0.770, Train_accy 81.47, Test_accy 62.57
2024-08-02 18:59:12,735 [foster.py] => SNet: Task 19, Epoch 57/130 => Loss 30.358,  Loss1 0.770, Train_accy 81.10
2024-08-02 18:59:16,634 [foster.py] => SNet: Task 19, Epoch 58/130 => Loss 30.312,  Loss1 0.770, Train_accy 80.55
2024-08-02 18:59:20,524 [foster.py] => SNet: Task 19, Epoch 59/130 => Loss 30.332,  Loss1 0.770, Train_accy 80.92
2024-08-02 18:59:24,414 [foster.py] => SNet: Task 19, Epoch 60/130 => Loss 30.380,  Loss1 0.770, Train_accy 79.26
2024-08-02 18:59:29,560 [foster.py] => SNet: Task 19, Epoch 61/130 => Loss 30.342,  Loss1 0.771, Train_accy 79.12, Test_accy 63.10
2024-08-02 18:59:33,426 [foster.py] => SNet: Task 19, Epoch 62/130 => Loss 30.355,  Loss1 0.771, Train_accy 79.30
2024-08-02 18:59:37,306 [foster.py] => SNet: Task 19, Epoch 63/130 => Loss 30.370,  Loss1 0.770, Train_accy 80.81
2024-08-02 18:59:41,152 [foster.py] => SNet: Task 19, Epoch 64/130 => Loss 30.384,  Loss1 0.771, Train_accy 78.79
2024-08-02 18:59:45,060 [foster.py] => SNet: Task 19, Epoch 65/130 => Loss 30.354,  Loss1 0.771, Train_accy 81.32
2024-08-02 18:59:50,196 [foster.py] => SNet: Task 19, Epoch 66/130 => Loss 30.345,  Loss1 0.770, Train_accy 78.46, Test_accy 62.81
2024-08-02 18:59:54,073 [foster.py] => SNet: Task 19, Epoch 67/130 => Loss 30.361,  Loss1 0.771, Train_accy 80.48
2024-08-02 18:59:57,950 [foster.py] => SNet: Task 19, Epoch 68/130 => Loss 30.376,  Loss1 0.770, Train_accy 81.07
2024-08-02 19:00:01,825 [foster.py] => SNet: Task 19, Epoch 69/130 => Loss 30.379,  Loss1 0.770, Train_accy 79.45
2024-08-02 19:00:05,715 [foster.py] => SNet: Task 19, Epoch 70/130 => Loss 30.334,  Loss1 0.771, Train_accy 81.32
2024-08-02 19:00:10,877 [foster.py] => SNet: Task 19, Epoch 71/130 => Loss 30.405,  Loss1 0.770, Train_accy 81.18, Test_accy 63.15
2024-08-02 19:00:14,751 [foster.py] => SNet: Task 19, Epoch 72/130 => Loss 30.354,  Loss1 0.770, Train_accy 80.62
2024-08-02 19:00:18,717 [foster.py] => SNet: Task 19, Epoch 73/130 => Loss 30.353,  Loss1 0.771, Train_accy 79.52
2024-08-02 19:00:22,584 [foster.py] => SNet: Task 19, Epoch 74/130 => Loss 30.379,  Loss1 0.770, Train_accy 80.66
2024-08-02 19:00:26,480 [foster.py] => SNet: Task 19, Epoch 75/130 => Loss 30.367,  Loss1 0.770, Train_accy 80.55
2024-08-02 19:00:31,606 [foster.py] => SNet: Task 19, Epoch 76/130 => Loss 30.307,  Loss1 0.770, Train_accy 81.54, Test_accy 62.97
2024-08-02 19:00:35,489 [foster.py] => SNet: Task 19, Epoch 77/130 => Loss 30.378,  Loss1 0.770, Train_accy 80.40
2024-08-02 19:00:39,381 [foster.py] => SNet: Task 19, Epoch 78/130 => Loss 30.364,  Loss1 0.771, Train_accy 80.99
2024-08-02 19:00:43,303 [foster.py] => SNet: Task 19, Epoch 79/130 => Loss 30.364,  Loss1 0.770, Train_accy 79.45
2024-08-02 19:00:47,206 [foster.py] => SNet: Task 19, Epoch 80/130 => Loss 30.352,  Loss1 0.770, Train_accy 79.30
2024-08-02 19:00:52,328 [foster.py] => SNet: Task 19, Epoch 81/130 => Loss 30.366,  Loss1 0.770, Train_accy 80.26, Test_accy 62.64
2024-08-02 19:00:56,231 [foster.py] => SNet: Task 19, Epoch 82/130 => Loss 30.300,  Loss1 0.770, Train_accy 81.18
2024-08-02 19:01:00,137 [foster.py] => SNet: Task 19, Epoch 83/130 => Loss 30.362,  Loss1 0.771, Train_accy 80.81
2024-08-02 19:01:04,000 [foster.py] => SNet: Task 19, Epoch 84/130 => Loss 30.396,  Loss1 0.770, Train_accy 79.96
2024-08-02 19:01:07,879 [foster.py] => SNet: Task 19, Epoch 85/130 => Loss 30.310,  Loss1 0.771, Train_accy 80.77
2024-08-02 19:01:12,997 [foster.py] => SNet: Task 19, Epoch 86/130 => Loss 30.353,  Loss1 0.770, Train_accy 80.44, Test_accy 63.25
2024-08-02 19:01:16,871 [foster.py] => SNet: Task 19, Epoch 87/130 => Loss 30.310,  Loss1 0.769, Train_accy 80.85
2024-08-02 19:01:20,740 [foster.py] => SNet: Task 19, Epoch 88/130 => Loss 30.361,  Loss1 0.770, Train_accy 80.66
2024-08-02 19:01:24,648 [foster.py] => SNet: Task 19, Epoch 89/130 => Loss 30.382,  Loss1 0.770, Train_accy 81.43
2024-08-02 19:01:28,580 [foster.py] => SNet: Task 19, Epoch 90/130 => Loss 30.386,  Loss1 0.770, Train_accy 80.92
2024-08-02 19:01:33,719 [foster.py] => SNet: Task 19, Epoch 91/130 => Loss 30.385,  Loss1 0.770, Train_accy 80.00, Test_accy 63.07
2024-08-02 19:01:37,593 [foster.py] => SNet: Task 19, Epoch 92/130 => Loss 30.385,  Loss1 0.770, Train_accy 81.07
2024-08-02 19:01:41,474 [foster.py] => SNet: Task 19, Epoch 93/130 => Loss 30.365,  Loss1 0.770, Train_accy 80.48
2024-08-02 19:01:45,370 [foster.py] => SNet: Task 19, Epoch 94/130 => Loss 30.346,  Loss1 0.771, Train_accy 81.07
2024-08-02 19:01:49,259 [foster.py] => SNet: Task 19, Epoch 95/130 => Loss 30.367,  Loss1 0.770, Train_accy 80.59
2024-08-02 19:01:54,421 [foster.py] => SNet: Task 19, Epoch 96/130 => Loss 30.369,  Loss1 0.770, Train_accy 80.96, Test_accy 62.77
2024-08-02 19:01:58,300 [foster.py] => SNet: Task 19, Epoch 97/130 => Loss 30.368,  Loss1 0.770, Train_accy 80.59
2024-08-02 19:02:02,182 [foster.py] => SNet: Task 19, Epoch 98/130 => Loss 30.333,  Loss1 0.770, Train_accy 81.21
2024-08-02 19:02:06,048 [foster.py] => SNet: Task 19, Epoch 99/130 => Loss 30.342,  Loss1 0.770, Train_accy 81.21
2024-08-02 19:02:09,907 [foster.py] => SNet: Task 19, Epoch 100/130 => Loss 30.376,  Loss1 0.770, Train_accy 81.03
2024-08-02 19:02:15,046 [foster.py] => SNet: Task 19, Epoch 101/130 => Loss 30.330,  Loss1 0.770, Train_accy 80.44, Test_accy 62.68
2024-08-02 19:02:18,927 [foster.py] => SNet: Task 19, Epoch 102/130 => Loss 30.349,  Loss1 0.770, Train_accy 79.63
2024-08-02 19:02:22,801 [foster.py] => SNet: Task 19, Epoch 103/130 => Loss 30.325,  Loss1 0.770, Train_accy 80.85
2024-08-02 19:02:26,697 [foster.py] => SNet: Task 19, Epoch 104/130 => Loss 30.389,  Loss1 0.770, Train_accy 81.58
2024-08-02 19:02:30,572 [foster.py] => SNet: Task 19, Epoch 105/130 => Loss 30.376,  Loss1 0.770, Train_accy 80.07
2024-08-02 19:02:35,731 [foster.py] => SNet: Task 19, Epoch 106/130 => Loss 30.425,  Loss1 0.771, Train_accy 79.01, Test_accy 63.15
2024-08-02 19:02:39,665 [foster.py] => SNet: Task 19, Epoch 107/130 => Loss 30.314,  Loss1 0.771, Train_accy 80.96
2024-08-02 19:02:43,534 [foster.py] => SNet: Task 19, Epoch 108/130 => Loss 30.315,  Loss1 0.771, Train_accy 81.21
2024-08-02 19:02:47,428 [foster.py] => SNet: Task 19, Epoch 109/130 => Loss 30.361,  Loss1 0.770, Train_accy 80.15
2024-08-02 19:02:51,323 [foster.py] => SNet: Task 19, Epoch 110/130 => Loss 30.366,  Loss1 0.770, Train_accy 80.55
2024-08-02 19:02:56,449 [foster.py] => SNet: Task 19, Epoch 111/130 => Loss 30.383,  Loss1 0.770, Train_accy 80.59, Test_accy 62.72
2024-08-02 19:03:00,319 [foster.py] => SNet: Task 19, Epoch 112/130 => Loss 30.369,  Loss1 0.770, Train_accy 81.29
2024-08-02 19:03:04,191 [foster.py] => SNet: Task 19, Epoch 113/130 => Loss 30.348,  Loss1 0.770, Train_accy 81.91
2024-08-02 19:03:08,069 [foster.py] => SNet: Task 19, Epoch 114/130 => Loss 30.355,  Loss1 0.770, Train_accy 80.51
2024-08-02 19:03:11,978 [foster.py] => SNet: Task 19, Epoch 115/130 => Loss 30.384,  Loss1 0.770, Train_accy 81.10
2024-08-02 19:03:17,108 [foster.py] => SNet: Task 19, Epoch 116/130 => Loss 30.360,  Loss1 0.770, Train_accy 80.96, Test_accy 63.06
2024-08-02 19:03:20,980 [foster.py] => SNet: Task 19, Epoch 117/130 => Loss 30.301,  Loss1 0.771, Train_accy 80.33
2024-08-02 19:03:24,858 [foster.py] => SNet: Task 19, Epoch 118/130 => Loss 30.361,  Loss1 0.771, Train_accy 79.78
2024-08-02 19:03:28,739 [foster.py] => SNet: Task 19, Epoch 119/130 => Loss 30.341,  Loss1 0.770, Train_accy 81.54
2024-08-02 19:03:32,616 [foster.py] => SNet: Task 19, Epoch 120/130 => Loss 30.329,  Loss1 0.770, Train_accy 81.51
2024-08-02 19:03:37,704 [foster.py] => SNet: Task 19, Epoch 121/130 => Loss 30.385,  Loss1 0.771, Train_accy 79.78, Test_accy 62.67
2024-08-02 19:03:41,579 [foster.py] => SNet: Task 19, Epoch 122/130 => Loss 30.326,  Loss1 0.771, Train_accy 81.84
2024-08-02 19:03:45,442 [foster.py] => SNet: Task 19, Epoch 123/130 => Loss 30.368,  Loss1 0.770, Train_accy 80.22
2024-08-02 19:03:49,403 [foster.py] => SNet: Task 19, Epoch 124/130 => Loss 30.346,  Loss1 0.771, Train_accy 81.32
2024-08-02 19:03:53,294 [foster.py] => SNet: Task 19, Epoch 125/130 => Loss 30.370,  Loss1 0.770, Train_accy 80.59
2024-08-02 19:03:58,392 [foster.py] => SNet: Task 19, Epoch 126/130 => Loss 30.374,  Loss1 0.771, Train_accy 80.74, Test_accy 62.84
2024-08-02 19:04:02,264 [foster.py] => SNet: Task 19, Epoch 127/130 => Loss 30.376,  Loss1 0.770, Train_accy 81.29
2024-08-02 19:04:06,206 [foster.py] => SNet: Task 19, Epoch 128/130 => Loss 30.343,  Loss1 0.770, Train_accy 80.07
2024-08-02 19:04:10,075 [foster.py] => SNet: Task 19, Epoch 129/130 => Loss 30.328,  Loss1 0.770, Train_accy 81.03
2024-08-02 19:04:13,936 [foster.py] => SNet: Task 19, Epoch 130/130 => Loss 30.346,  Loss1 0.770, Train_accy 80.33
2024-08-02 19:04:13,937 [foster.py] => do not weight align student!
2024-08-02 19:04:15,168 [foster.py] => darknet eval: 
2024-08-02 19:04:15,168 [foster.py] => CNN top1 curve: 62.91
2024-08-02 19:04:15,168 [foster.py] => CNN top5 curve: 87.2
2024-08-02 19:04:15,169 [foster.py] => CNN top1 平均值: 62.91
2024-08-02 19:04:15,175 [foster.py] => timees : 1284.7138364315033
2024-08-02 19:04:15,177 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 19:04:41,755 [foster.py] => Exemplar size: 1760
2024-08-02 19:04:41,755 [trainer.py] => CNN: {'total': 64.19, '00-09': 70.8, '10-19': 54.4, '20-29': 70.0, '30-39': 63.2, '40-49': 68.3, '50-59': 50.7, '60-69': 64.1, '70-79': 64.9, '80-89': 73.12, 'old': 63.76, 'new': 83.0}
2024-08-02 19:04:41,755 [trainer.py] => NME: {'total': 58.08, '00-09': 59.0, '10-19': 44.5, '20-29': 62.9, '30-39': 51.3, '40-49': 60.8, '50-59': 49.0, '60-69': 63.8, '70-79': 67.1, '80-89': 65.88, 'old': 57.3, 'new': 91.5}
2024-08-02 19:04:41,755 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19]
2024-08-02 19:04:41,755 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03]
2024-08-02 19:04:41,755 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08]
2024-08-02 19:04:41,755 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42]

2024-08-02 19:04:41,755 [trainer.py] => CNN top1 平均值: 72.18
2024-08-02 19:04:41,758 [trainer.py] => All params: 1177210
2024-08-02 19:04:41,760 [trainer.py] => Trainable params: 594346
2024-08-02 19:04:41,821 [foster.py] => Learning on 88-90
2024-08-02 19:04:41,825 [foster.py] => All params: 1177728
2024-08-02 19:04:41,827 [foster.py] => Trainable params: 594734
2024-08-02 19:04:41,869 [foster.py] => per cls weights : [1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633 1.01016633
 1.01016633 1.01016633 1.01016633 1.01016633 0.5526813  0.5526813 ]
2024-08-02 19:04:44,664 [foster.py] => Task 20, Epoch 1/170 => Loss 5.762, Loss_clf 1.165, Loss_fe 1.970, Loss_kd 2.567, Train_accy 63.91
2024-08-02 19:04:49,463 [foster.py] => Task 20, Epoch 2/170 => Loss 4.163, Loss_clf 0.662, Loss_fe 0.898, Loss_kd 2.543, Train_accy 72.61, Test_accy 60.74
2024-08-02 19:04:54,290 [foster.py] => Task 20, Epoch 3/170 => Loss 3.882, Loss_clf 0.607, Loss_fe 0.710, Loss_kd 2.506, Train_accy 74.31, Test_accy 61.16
2024-08-02 19:04:59,147 [foster.py] => Task 20, Epoch 4/170 => Loss 3.806, Loss_clf 0.578, Loss_fe 0.629, Loss_kd 2.539, Train_accy 73.91, Test_accy 61.43
2024-08-02 19:05:03,962 [foster.py] => Task 20, Epoch 5/170 => Loss 3.784, Loss_clf 0.593, Loss_fe 0.602, Loss_kd 2.530, Train_accy 75.62, Test_accy 61.26
2024-08-02 19:05:06,738 [foster.py] => Task 20, Epoch 6/170 => Loss 3.664, Loss_clf 0.545, Loss_fe 0.561, Loss_kd 2.499, Train_accy 75.69
2024-08-02 19:05:11,579 [foster.py] => Task 20, Epoch 7/170 => Loss 3.658, Loss_clf 0.532, Loss_fe 0.540, Loss_kd 2.526, Train_accy 77.07, Test_accy 61.86
2024-08-02 19:05:16,438 [foster.py] => Task 20, Epoch 8/170 => Loss 3.598, Loss_clf 0.509, Loss_fe 0.512, Loss_kd 2.518, Train_accy 77.10, Test_accy 60.57
2024-08-02 19:05:21,380 [foster.py] => Task 20, Epoch 9/170 => Loss 3.656, Loss_clf 0.543, Loss_fe 0.507, Loss_kd 2.548, Train_accy 77.21, Test_accy 61.69
2024-08-02 19:05:26,211 [foster.py] => Task 20, Epoch 10/170 => Loss 3.646, Loss_clf 0.534, Loss_fe 0.505, Loss_kd 2.547, Train_accy 77.03, Test_accy 61.58
2024-08-02 19:05:29,024 [foster.py] => Task 20, Epoch 11/170 => Loss 3.610, Loss_clf 0.545, Loss_fe 0.506, Loss_kd 2.500, Train_accy 76.34
2024-08-02 19:05:33,864 [foster.py] => Task 20, Epoch 12/170 => Loss 3.567, Loss_clf 0.510, Loss_fe 0.463, Loss_kd 2.535, Train_accy 77.72, Test_accy 61.56
2024-08-02 19:05:38,675 [foster.py] => Task 20, Epoch 13/170 => Loss 3.532, Loss_clf 0.504, Loss_fe 0.452, Loss_kd 2.518, Train_accy 78.73, Test_accy 61.69
2024-08-02 19:05:43,482 [foster.py] => Task 20, Epoch 14/170 => Loss 3.553, Loss_clf 0.510, Loss_fe 0.460, Loss_kd 2.523, Train_accy 78.48, Test_accy 61.27
2024-08-02 19:05:48,311 [foster.py] => Task 20, Epoch 15/170 => Loss 3.595, Loss_clf 0.526, Loss_fe 0.471, Loss_kd 2.538, Train_accy 78.33, Test_accy 61.46
2024-08-02 19:05:51,084 [foster.py] => Task 20, Epoch 16/170 => Loss 3.545, Loss_clf 0.505, Loss_fe 0.468, Loss_kd 2.514, Train_accy 79.17
2024-08-02 19:05:55,878 [foster.py] => Task 20, Epoch 17/170 => Loss 3.506, Loss_clf 0.500, Loss_fe 0.426, Loss_kd 2.521, Train_accy 78.73, Test_accy 61.39
2024-08-02 19:06:00,691 [foster.py] => Task 20, Epoch 18/170 => Loss 3.463, Loss_clf 0.485, Loss_fe 0.420, Loss_kd 2.500, Train_accy 79.57, Test_accy 61.63
2024-08-02 19:06:05,525 [foster.py] => Task 20, Epoch 19/170 => Loss 3.478, Loss_clf 0.475, Loss_fe 0.428, Loss_kd 2.516, Train_accy 80.18, Test_accy 61.08
2024-08-02 19:06:10,366 [foster.py] => Task 20, Epoch 20/170 => Loss 3.472, Loss_clf 0.481, Loss_fe 0.407, Loss_kd 2.525, Train_accy 79.42, Test_accy 61.94
2024-08-02 19:06:13,241 [foster.py] => Task 20, Epoch 21/170 => Loss 3.446, Loss_clf 0.468, Loss_fe 0.405, Loss_kd 2.514, Train_accy 80.69
2024-08-02 19:06:18,062 [foster.py] => Task 20, Epoch 22/170 => Loss 3.493, Loss_clf 0.498, Loss_fe 0.407, Loss_kd 2.527, Train_accy 80.36, Test_accy 62.22
2024-08-02 19:06:22,921 [foster.py] => Task 20, Epoch 23/170 => Loss 3.416, Loss_clf 0.445, Loss_fe 0.381, Loss_kd 2.531, Train_accy 80.76, Test_accy 61.56
2024-08-02 19:06:27,756 [foster.py] => Task 20, Epoch 24/170 => Loss 3.446, Loss_clf 0.463, Loss_fe 0.395, Loss_kd 2.528, Train_accy 79.89, Test_accy 61.96
2024-08-02 19:06:32,560 [foster.py] => Task 20, Epoch 25/170 => Loss 3.395, Loss_clf 0.449, Loss_fe 0.368, Loss_kd 2.518, Train_accy 81.23, Test_accy 61.82
2024-08-02 19:06:35,374 [foster.py] => Task 20, Epoch 26/170 => Loss 3.422, Loss_clf 0.469, Loss_fe 0.389, Loss_kd 2.506, Train_accy 80.36
2024-08-02 19:06:40,205 [foster.py] => Task 20, Epoch 27/170 => Loss 3.426, Loss_clf 0.469, Loss_fe 0.368, Loss_kd 2.529, Train_accy 79.64, Test_accy 62.00
2024-08-02 19:06:45,034 [foster.py] => Task 20, Epoch 28/170 => Loss 3.409, Loss_clf 0.469, Loss_fe 0.357, Loss_kd 2.524, Train_accy 81.09, Test_accy 62.33
2024-08-02 19:06:49,885 [foster.py] => Task 20, Epoch 29/170 => Loss 3.420, Loss_clf 0.459, Loss_fe 0.349, Loss_kd 2.551, Train_accy 81.56, Test_accy 61.39
2024-08-02 19:06:54,709 [foster.py] => Task 20, Epoch 30/170 => Loss 3.370, Loss_clf 0.439, Loss_fe 0.373, Loss_kd 2.501, Train_accy 82.21, Test_accy 62.07
2024-08-02 19:06:57,509 [foster.py] => Task 20, Epoch 31/170 => Loss 3.447, Loss_clf 0.485, Loss_fe 0.371, Loss_kd 2.531, Train_accy 81.12
2024-08-02 19:07:02,311 [foster.py] => Task 20, Epoch 32/170 => Loss 3.446, Loss_clf 0.481, Loss_fe 0.378, Loss_kd 2.527, Train_accy 81.05, Test_accy 62.13
2024-08-02 19:07:07,177 [foster.py] => Task 20, Epoch 33/170 => Loss 3.380, Loss_clf 0.453, Loss_fe 0.344, Loss_kd 2.525, Train_accy 80.87, Test_accy 61.93
2024-08-02 19:07:12,001 [foster.py] => Task 20, Epoch 34/170 => Loss 3.391, Loss_clf 0.458, Loss_fe 0.358, Loss_kd 2.516, Train_accy 81.05, Test_accy 61.30
2024-08-02 19:07:16,880 [foster.py] => Task 20, Epoch 35/170 => Loss 3.411, Loss_clf 0.474, Loss_fe 0.368, Loss_kd 2.509, Train_accy 80.11, Test_accy 62.00
2024-08-02 19:07:19,672 [foster.py] => Task 20, Epoch 36/170 => Loss 3.394, Loss_clf 0.451, Loss_fe 0.362, Loss_kd 2.521, Train_accy 81.85
2024-08-02 19:07:24,535 [foster.py] => Task 20, Epoch 37/170 => Loss 3.306, Loss_clf 0.411, Loss_fe 0.330, Loss_kd 2.506, Train_accy 82.46, Test_accy 61.80
2024-08-02 19:07:29,364 [foster.py] => Task 20, Epoch 38/170 => Loss 3.317, Loss_clf 0.431, Loss_fe 0.325, Loss_kd 2.502, Train_accy 82.54, Test_accy 61.92
2024-08-02 19:07:34,260 [foster.py] => Task 20, Epoch 39/170 => Loss 3.422, Loss_clf 0.471, Loss_fe 0.340, Loss_kd 2.551, Train_accy 80.72, Test_accy 62.12
2024-08-02 19:07:39,059 [foster.py] => Task 20, Epoch 40/170 => Loss 3.348, Loss_clf 0.430, Loss_fe 0.341, Loss_kd 2.518, Train_accy 82.07, Test_accy 62.56
2024-08-02 19:07:41,860 [foster.py] => Task 20, Epoch 41/170 => Loss 3.329, Loss_clf 0.421, Loss_fe 0.316, Loss_kd 2.533, Train_accy 81.63
2024-08-02 19:07:46,705 [foster.py] => Task 20, Epoch 42/170 => Loss 3.395, Loss_clf 0.462, Loss_fe 0.344, Loss_kd 2.530, Train_accy 82.43, Test_accy 62.10
2024-08-02 19:07:51,554 [foster.py] => Task 20, Epoch 43/170 => Loss 3.283, Loss_clf 0.421, Loss_fe 0.305, Loss_kd 2.499, Train_accy 82.75, Test_accy 60.82
2024-08-02 19:07:56,410 [foster.py] => Task 20, Epoch 44/170 => Loss 3.371, Loss_clf 0.450, Loss_fe 0.328, Loss_kd 2.534, Train_accy 81.20, Test_accy 61.76
2024-08-02 19:08:01,285 [foster.py] => Task 20, Epoch 45/170 => Loss 3.314, Loss_clf 0.422, Loss_fe 0.316, Loss_kd 2.517, Train_accy 82.75, Test_accy 62.53
2024-08-02 19:08:04,068 [foster.py] => Task 20, Epoch 46/170 => Loss 3.359, Loss_clf 0.445, Loss_fe 0.332, Loss_kd 2.524, Train_accy 81.70
2024-08-02 19:08:08,900 [foster.py] => Task 20, Epoch 47/170 => Loss 3.287, Loss_clf 0.411, Loss_fe 0.312, Loss_kd 2.505, Train_accy 83.66, Test_accy 61.33
2024-08-02 19:08:13,798 [foster.py] => Task 20, Epoch 48/170 => Loss 3.286, Loss_clf 0.415, Loss_fe 0.308, Loss_kd 2.504, Train_accy 82.28, Test_accy 61.62
2024-08-02 19:08:18,661 [foster.py] => Task 20, Epoch 49/170 => Loss 3.347, Loss_clf 0.451, Loss_fe 0.301, Loss_kd 2.536, Train_accy 81.81, Test_accy 62.37
2024-08-02 19:08:23,632 [foster.py] => Task 20, Epoch 50/170 => Loss 3.314, Loss_clf 0.436, Loss_fe 0.291, Loss_kd 2.528, Train_accy 82.86, Test_accy 62.14
2024-08-02 19:08:26,486 [foster.py] => Task 20, Epoch 51/170 => Loss 3.376, Loss_clf 0.452, Loss_fe 0.322, Loss_kd 2.542, Train_accy 82.72
2024-08-02 19:08:31,389 [foster.py] => Task 20, Epoch 52/170 => Loss 3.332, Loss_clf 0.425, Loss_fe 0.307, Loss_kd 2.540, Train_accy 82.68, Test_accy 61.98
2024-08-02 19:08:36,223 [foster.py] => Task 20, Epoch 53/170 => Loss 3.281, Loss_clf 0.415, Loss_fe 0.308, Loss_kd 2.499, Train_accy 82.93, Test_accy 61.98
2024-08-02 19:08:41,054 [foster.py] => Task 20, Epoch 54/170 => Loss 3.265, Loss_clf 0.410, Loss_fe 0.281, Loss_kd 2.515, Train_accy 82.79, Test_accy 62.23
2024-08-02 19:08:45,864 [foster.py] => Task 20, Epoch 55/170 => Loss 3.339, Loss_clf 0.448, Loss_fe 0.288, Loss_kd 2.543, Train_accy 81.67, Test_accy 62.99
2024-08-02 19:08:48,613 [foster.py] => Task 20, Epoch 56/170 => Loss 3.271, Loss_clf 0.417, Loss_fe 0.286, Loss_kd 2.509, Train_accy 84.49
2024-08-02 19:08:53,447 [foster.py] => Task 20, Epoch 57/170 => Loss 3.278, Loss_clf 0.437, Loss_fe 0.285, Loss_kd 2.497, Train_accy 82.64, Test_accy 62.33
2024-08-02 19:08:58,272 [foster.py] => Task 20, Epoch 58/170 => Loss 3.287, Loss_clf 0.410, Loss_fe 0.295, Loss_kd 2.523, Train_accy 82.50, Test_accy 62.32
2024-08-02 19:09:03,104 [foster.py] => Task 20, Epoch 59/170 => Loss 3.330, Loss_clf 0.430, Loss_fe 0.290, Loss_kd 2.550, Train_accy 83.04, Test_accy 62.47
2024-08-02 19:09:07,918 [foster.py] => Task 20, Epoch 60/170 => Loss 3.309, Loss_clf 0.419, Loss_fe 0.265, Loss_kd 2.564, Train_accy 82.79, Test_accy 61.62
2024-08-02 19:09:10,722 [foster.py] => Task 20, Epoch 61/170 => Loss 3.241, Loss_clf 0.395, Loss_fe 0.266, Loss_kd 2.522, Train_accy 84.31
2024-08-02 19:09:15,527 [foster.py] => Task 20, Epoch 62/170 => Loss 3.283, Loss_clf 0.419, Loss_fe 0.275, Loss_kd 2.530, Train_accy 84.09, Test_accy 62.68
2024-08-02 19:09:20,339 [foster.py] => Task 20, Epoch 63/170 => Loss 3.263, Loss_clf 0.409, Loss_fe 0.278, Loss_kd 2.518, Train_accy 82.64, Test_accy 62.47
2024-08-02 19:09:25,187 [foster.py] => Task 20, Epoch 64/170 => Loss 3.312, Loss_clf 0.434, Loss_fe 0.286, Loss_kd 2.532, Train_accy 83.59, Test_accy 60.34
2024-08-02 19:09:30,006 [foster.py] => Task 20, Epoch 65/170 => Loss 3.263, Loss_clf 0.405, Loss_fe 0.257, Loss_kd 2.541, Train_accy 84.38, Test_accy 62.08
2024-08-02 19:09:32,790 [foster.py] => Task 20, Epoch 66/170 => Loss 3.264, Loss_clf 0.421, Loss_fe 0.255, Loss_kd 2.529, Train_accy 83.44
2024-08-02 19:09:37,635 [foster.py] => Task 20, Epoch 67/170 => Loss 3.221, Loss_clf 0.400, Loss_fe 0.265, Loss_kd 2.498, Train_accy 83.66, Test_accy 62.68
2024-08-02 19:09:42,525 [foster.py] => Task 20, Epoch 68/170 => Loss 3.245, Loss_clf 0.404, Loss_fe 0.256, Loss_kd 2.526, Train_accy 84.46, Test_accy 62.23
2024-08-02 19:09:47,352 [foster.py] => Task 20, Epoch 69/170 => Loss 3.210, Loss_clf 0.387, Loss_fe 0.251, Loss_kd 2.513, Train_accy 84.71, Test_accy 62.36
2024-08-02 19:09:52,185 [foster.py] => Task 20, Epoch 70/170 => Loss 3.192, Loss_clf 0.377, Loss_fe 0.241, Loss_kd 2.515, Train_accy 85.43, Test_accy 62.63
2024-08-02 19:09:54,993 [foster.py] => Task 20, Epoch 71/170 => Loss 3.255, Loss_clf 0.400, Loss_fe 0.243, Loss_kd 2.553, Train_accy 85.14
2024-08-02 19:09:59,790 [foster.py] => Task 20, Epoch 72/170 => Loss 3.188, Loss_clf 0.371, Loss_fe 0.230, Loss_kd 2.528, Train_accy 86.56, Test_accy 63.01
2024-08-02 19:10:04,609 [foster.py] => Task 20, Epoch 73/170 => Loss 3.249, Loss_clf 0.397, Loss_fe 0.251, Loss_kd 2.542, Train_accy 83.80, Test_accy 61.47
2024-08-02 19:10:09,521 [foster.py] => Task 20, Epoch 74/170 => Loss 3.228, Loss_clf 0.398, Loss_fe 0.244, Loss_kd 2.526, Train_accy 84.38, Test_accy 62.38
2024-08-02 19:10:14,352 [foster.py] => Task 20, Epoch 75/170 => Loss 3.166, Loss_clf 0.379, Loss_fe 0.234, Loss_kd 2.495, Train_accy 84.64, Test_accy 62.42
2024-08-02 19:10:17,138 [foster.py] => Task 20, Epoch 76/170 => Loss 3.162, Loss_clf 0.357, Loss_fe 0.232, Loss_kd 2.514, Train_accy 86.67
2024-08-02 19:10:21,969 [foster.py] => Task 20, Epoch 77/170 => Loss 3.208, Loss_clf 0.390, Loss_fe 0.223, Loss_kd 2.536, Train_accy 85.29, Test_accy 62.73
2024-08-02 19:10:26,839 [foster.py] => Task 20, Epoch 78/170 => Loss 3.196, Loss_clf 0.381, Loss_fe 0.243, Loss_kd 2.514, Train_accy 84.28, Test_accy 62.92
2024-08-02 19:10:31,687 [foster.py] => Task 20, Epoch 79/170 => Loss 3.207, Loss_clf 0.390, Loss_fe 0.236, Loss_kd 2.521, Train_accy 84.46, Test_accy 62.52
2024-08-02 19:10:36,627 [foster.py] => Task 20, Epoch 80/170 => Loss 3.190, Loss_clf 0.385, Loss_fe 0.224, Loss_kd 2.522, Train_accy 84.60, Test_accy 62.67
2024-08-02 19:10:39,416 [foster.py] => Task 20, Epoch 81/170 => Loss 3.207, Loss_clf 0.389, Loss_fe 0.255, Loss_kd 2.505, Train_accy 85.54
2024-08-02 19:10:44,244 [foster.py] => Task 20, Epoch 82/170 => Loss 3.222, Loss_clf 0.393, Loss_fe 0.231, Loss_kd 2.538, Train_accy 83.80, Test_accy 62.47
2024-08-02 19:10:49,074 [foster.py] => Task 20, Epoch 83/170 => Loss 3.165, Loss_clf 0.381, Loss_fe 0.232, Loss_kd 2.493, Train_accy 84.71, Test_accy 62.51
2024-08-02 19:10:53,870 [foster.py] => Task 20, Epoch 84/170 => Loss 3.177, Loss_clf 0.377, Loss_fe 0.215, Loss_kd 2.526, Train_accy 85.43, Test_accy 62.88
2024-08-02 19:10:58,686 [foster.py] => Task 20, Epoch 85/170 => Loss 3.173, Loss_clf 0.373, Loss_fe 0.220, Loss_kd 2.521, Train_accy 85.33, Test_accy 62.71
2024-08-02 19:11:01,459 [foster.py] => Task 20, Epoch 86/170 => Loss 3.232, Loss_clf 0.406, Loss_fe 0.222, Loss_kd 2.544, Train_accy 84.24
2024-08-02 19:11:06,371 [foster.py] => Task 20, Epoch 87/170 => Loss 3.172, Loss_clf 0.381, Loss_fe 0.216, Loss_kd 2.516, Train_accy 85.29, Test_accy 62.78
2024-08-02 19:11:11,203 [foster.py] => Task 20, Epoch 88/170 => Loss 3.195, Loss_clf 0.377, Loss_fe 0.200, Loss_kd 2.558, Train_accy 85.54, Test_accy 62.71
2024-08-02 19:11:16,015 [foster.py] => Task 20, Epoch 89/170 => Loss 3.146, Loss_clf 0.380, Loss_fe 0.192, Loss_kd 2.515, Train_accy 86.23, Test_accy 62.80
2024-08-02 19:11:20,865 [foster.py] => Task 20, Epoch 90/170 => Loss 3.143, Loss_clf 0.372, Loss_fe 0.198, Loss_kd 2.514, Train_accy 85.51, Test_accy 62.07
2024-08-02 19:11:23,648 [foster.py] => Task 20, Epoch 91/170 => Loss 3.192, Loss_clf 0.390, Loss_fe 0.226, Loss_kd 2.517, Train_accy 85.33
2024-08-02 19:11:28,457 [foster.py] => Task 20, Epoch 92/170 => Loss 3.137, Loss_clf 0.361, Loss_fe 0.197, Loss_kd 2.520, Train_accy 85.94, Test_accy 62.73
2024-08-02 19:11:33,287 [foster.py] => Task 20, Epoch 93/170 => Loss 3.106, Loss_clf 0.340, Loss_fe 0.188, Loss_kd 2.519, Train_accy 87.43, Test_accy 62.23
2024-08-02 19:11:38,143 [foster.py] => Task 20, Epoch 94/170 => Loss 3.133, Loss_clf 0.366, Loss_fe 0.191, Loss_kd 2.518, Train_accy 86.45, Test_accy 62.88
2024-08-02 19:11:43,016 [foster.py] => Task 20, Epoch 95/170 => Loss 3.155, Loss_clf 0.362, Loss_fe 0.202, Loss_kd 2.532, Train_accy 86.78, Test_accy 62.59
2024-08-02 19:11:45,867 [foster.py] => Task 20, Epoch 96/170 => Loss 3.169, Loss_clf 0.378, Loss_fe 0.197, Loss_kd 2.535, Train_accy 86.05
2024-08-02 19:11:50,713 [foster.py] => Task 20, Epoch 97/170 => Loss 3.162, Loss_clf 0.375, Loss_fe 0.193, Loss_kd 2.534, Train_accy 86.38, Test_accy 62.79
2024-08-02 19:11:55,523 [foster.py] => Task 20, Epoch 98/170 => Loss 3.107, Loss_clf 0.355, Loss_fe 0.191, Loss_kd 2.502, Train_accy 85.98, Test_accy 62.74
2024-08-02 19:12:00,354 [foster.py] => Task 20, Epoch 99/170 => Loss 3.196, Loss_clf 0.376, Loss_fe 0.216, Loss_kd 2.544, Train_accy 85.18, Test_accy 62.79
2024-08-02 19:12:05,245 [foster.py] => Task 20, Epoch 100/170 => Loss 3.112, Loss_clf 0.348, Loss_fe 0.192, Loss_kd 2.512, Train_accy 86.52, Test_accy 63.01
2024-08-02 19:12:08,044 [foster.py] => Task 20, Epoch 101/170 => Loss 3.225, Loss_clf 0.394, Loss_fe 0.203, Loss_kd 2.569, Train_accy 85.94
2024-08-02 19:12:12,877 [foster.py] => Task 20, Epoch 102/170 => Loss 3.126, Loss_clf 0.352, Loss_fe 0.187, Loss_kd 2.527, Train_accy 86.78, Test_accy 62.99
2024-08-02 19:12:17,726 [foster.py] => Task 20, Epoch 103/170 => Loss 3.087, Loss_clf 0.346, Loss_fe 0.164, Loss_kd 2.518, Train_accy 87.86, Test_accy 62.93
2024-08-02 19:12:22,618 [foster.py] => Task 20, Epoch 104/170 => Loss 3.090, Loss_clf 0.353, Loss_fe 0.165, Loss_kd 2.513, Train_accy 86.45, Test_accy 62.89
2024-08-02 19:12:27,456 [foster.py] => Task 20, Epoch 105/170 => Loss 3.165, Loss_clf 0.383, Loss_fe 0.180, Loss_kd 2.543, Train_accy 85.43, Test_accy 62.90
2024-08-02 19:12:30,286 [foster.py] => Task 20, Epoch 106/170 => Loss 3.091, Loss_clf 0.352, Loss_fe 0.182, Loss_kd 2.499, Train_accy 87.10
2024-08-02 19:12:35,148 [foster.py] => Task 20, Epoch 107/170 => Loss 3.087, Loss_clf 0.344, Loss_fe 0.165, Loss_kd 2.518, Train_accy 86.56, Test_accy 62.72
2024-08-02 19:12:40,002 [foster.py] => Task 20, Epoch 108/170 => Loss 3.110, Loss_clf 0.370, Loss_fe 0.172, Loss_kd 2.510, Train_accy 84.89, Test_accy 62.43
2024-08-02 19:12:44,819 [foster.py] => Task 20, Epoch 109/170 => Loss 3.074, Loss_clf 0.344, Loss_fe 0.152, Loss_kd 2.518, Train_accy 87.54, Test_accy 63.08
2024-08-02 19:12:49,632 [foster.py] => Task 20, Epoch 110/170 => Loss 3.089, Loss_clf 0.350, Loss_fe 0.161, Loss_kd 2.520, Train_accy 87.28, Test_accy 63.02
2024-08-02 19:12:52,427 [foster.py] => Task 20, Epoch 111/170 => Loss 3.084, Loss_clf 0.354, Loss_fe 0.153, Loss_kd 2.518, Train_accy 87.43
2024-08-02 19:12:57,225 [foster.py] => Task 20, Epoch 112/170 => Loss 3.116, Loss_clf 0.356, Loss_fe 0.164, Loss_kd 2.536, Train_accy 86.56, Test_accy 63.09
2024-08-02 19:13:02,037 [foster.py] => Task 20, Epoch 113/170 => Loss 3.102, Loss_clf 0.341, Loss_fe 0.161, Loss_kd 2.541, Train_accy 87.50, Test_accy 62.87
2024-08-02 19:13:06,853 [foster.py] => Task 20, Epoch 114/170 => Loss 3.079, Loss_clf 0.351, Loss_fe 0.152, Loss_kd 2.517, Train_accy 87.50, Test_accy 62.87
2024-08-02 19:13:11,668 [foster.py] => Task 20, Epoch 115/170 => Loss 3.074, Loss_clf 0.347, Loss_fe 0.158, Loss_kd 2.510, Train_accy 87.61, Test_accy 63.17
2024-08-02 19:13:14,448 [foster.py] => Task 20, Epoch 116/170 => Loss 3.062, Loss_clf 0.340, Loss_fe 0.159, Loss_kd 2.506, Train_accy 86.88
2024-08-02 19:13:19,242 [foster.py] => Task 20, Epoch 117/170 => Loss 3.027, Loss_clf 0.306, Loss_fe 0.146, Loss_kd 2.515, Train_accy 88.95, Test_accy 62.87
2024-08-02 19:13:24,066 [foster.py] => Task 20, Epoch 118/170 => Loss 3.069, Loss_clf 0.350, Loss_fe 0.151, Loss_kd 2.510, Train_accy 87.36, Test_accy 62.98
2024-08-02 19:13:28,857 [foster.py] => Task 20, Epoch 119/170 => Loss 3.099, Loss_clf 0.352, Loss_fe 0.145, Loss_kd 2.542, Train_accy 87.54, Test_accy 62.93
2024-08-02 19:13:33,676 [foster.py] => Task 20, Epoch 120/170 => Loss 3.126, Loss_clf 0.368, Loss_fe 0.158, Loss_kd 2.541, Train_accy 86.34, Test_accy 62.82
2024-08-02 19:13:36,460 [foster.py] => Task 20, Epoch 121/170 => Loss 3.092, Loss_clf 0.343, Loss_fe 0.152, Loss_kd 2.537, Train_accy 87.90
2024-08-02 19:13:41,284 [foster.py] => Task 20, Epoch 122/170 => Loss 3.055, Loss_clf 0.328, Loss_fe 0.140, Loss_kd 2.528, Train_accy 88.01, Test_accy 63.22
2024-08-02 19:13:46,120 [foster.py] => Task 20, Epoch 123/170 => Loss 3.072, Loss_clf 0.337, Loss_fe 0.148, Loss_kd 2.528, Train_accy 87.93, Test_accy 62.94
2024-08-02 19:13:50,954 [foster.py] => Task 20, Epoch 124/170 => Loss 3.098, Loss_clf 0.351, Loss_fe 0.155, Loss_kd 2.533, Train_accy 88.22, Test_accy 63.11
2024-08-02 19:13:55,786 [foster.py] => Task 20, Epoch 125/170 => Loss 3.023, Loss_clf 0.330, Loss_fe 0.134, Loss_kd 2.502, Train_accy 87.36, Test_accy 62.93
2024-08-02 19:13:58,621 [foster.py] => Task 20, Epoch 126/170 => Loss 3.090, Loss_clf 0.349, Loss_fe 0.146, Loss_kd 2.535, Train_accy 87.68
2024-08-02 19:14:03,419 [foster.py] => Task 20, Epoch 127/170 => Loss 3.042, Loss_clf 0.324, Loss_fe 0.142, Loss_kd 2.517, Train_accy 88.12, Test_accy 63.08
2024-08-02 19:14:08,241 [foster.py] => Task 20, Epoch 128/170 => Loss 2.997, Loss_clf 0.312, Loss_fe 0.128, Loss_kd 2.499, Train_accy 88.51, Test_accy 62.98
2024-08-02 19:14:13,074 [foster.py] => Task 20, Epoch 129/170 => Loss 3.047, Loss_clf 0.330, Loss_fe 0.146, Loss_kd 2.513, Train_accy 87.83, Test_accy 63.13
2024-08-02 19:14:17,880 [foster.py] => Task 20, Epoch 130/170 => Loss 3.049, Loss_clf 0.336, Loss_fe 0.138, Loss_kd 2.517, Train_accy 88.80, Test_accy 63.20
2024-08-02 19:14:20,709 [foster.py] => Task 20, Epoch 131/170 => Loss 3.086, Loss_clf 0.357, Loss_fe 0.143, Loss_kd 2.527, Train_accy 87.07
2024-08-02 19:14:25,571 [foster.py] => Task 20, Epoch 132/170 => Loss 3.107, Loss_clf 0.349, Loss_fe 0.152, Loss_kd 2.546, Train_accy 87.83, Test_accy 63.19
2024-08-02 19:14:30,436 [foster.py] => Task 20, Epoch 133/170 => Loss 3.028, Loss_clf 0.321, Loss_fe 0.131, Loss_kd 2.517, Train_accy 87.83, Test_accy 63.21
2024-08-02 19:14:35,297 [foster.py] => Task 20, Epoch 134/170 => Loss 2.986, Loss_clf 0.303, Loss_fe 0.124, Loss_kd 2.501, Train_accy 89.24, Test_accy 63.06
2024-08-02 19:14:40,122 [foster.py] => Task 20, Epoch 135/170 => Loss 3.073, Loss_clf 0.329, Loss_fe 0.141, Loss_kd 2.544, Train_accy 88.84, Test_accy 63.23
2024-08-02 19:14:42,900 [foster.py] => Task 20, Epoch 136/170 => Loss 3.019, Loss_clf 0.326, Loss_fe 0.134, Loss_kd 2.501, Train_accy 87.61
2024-08-02 19:14:47,729 [foster.py] => Task 20, Epoch 137/170 => Loss 3.024, Loss_clf 0.334, Loss_fe 0.136, Loss_kd 2.496, Train_accy 88.44, Test_accy 63.20
2024-08-02 19:14:52,574 [foster.py] => Task 20, Epoch 138/170 => Loss 3.040, Loss_clf 0.332, Loss_fe 0.131, Loss_kd 2.518, Train_accy 88.48, Test_accy 63.06
2024-08-02 19:14:57,387 [foster.py] => Task 20, Epoch 139/170 => Loss 3.062, Loss_clf 0.345, Loss_fe 0.131, Loss_kd 2.527, Train_accy 87.86, Test_accy 63.22
2024-08-02 19:15:02,239 [foster.py] => Task 20, Epoch 140/170 => Loss 3.103, Loss_clf 0.356, Loss_fe 0.128, Loss_kd 2.559, Train_accy 86.67, Test_accy 63.28
2024-08-02 19:15:05,037 [foster.py] => Task 20, Epoch 141/170 => Loss 3.047, Loss_clf 0.342, Loss_fe 0.136, Loss_kd 2.510, Train_accy 88.37
2024-08-02 19:15:09,832 [foster.py] => Task 20, Epoch 142/170 => Loss 2.980, Loss_clf 0.293, Loss_fe 0.128, Loss_kd 2.500, Train_accy 89.67, Test_accy 63.19
2024-08-02 19:15:14,682 [foster.py] => Task 20, Epoch 143/170 => Loss 3.030, Loss_clf 0.319, Loss_fe 0.138, Loss_kd 2.514, Train_accy 88.59, Test_accy 63.21
2024-08-02 19:15:19,516 [foster.py] => Task 20, Epoch 144/170 => Loss 3.029, Loss_clf 0.320, Loss_fe 0.126, Loss_kd 2.524, Train_accy 88.33, Test_accy 63.16
2024-08-02 19:15:24,450 [foster.py] => Task 20, Epoch 145/170 => Loss 3.005, Loss_clf 0.314, Loss_fe 0.127, Loss_kd 2.506, Train_accy 88.44, Test_accy 63.28
2024-08-02 19:15:27,376 [foster.py] => Task 20, Epoch 146/170 => Loss 3.046, Loss_clf 0.336, Loss_fe 0.121, Loss_kd 2.530, Train_accy 88.08
2024-08-02 19:15:32,205 [foster.py] => Task 20, Epoch 147/170 => Loss 3.052, Loss_clf 0.333, Loss_fe 0.126, Loss_kd 2.534, Train_accy 88.70, Test_accy 63.16
2024-08-02 19:15:37,081 [foster.py] => Task 20, Epoch 148/170 => Loss 3.046, Loss_clf 0.343, Loss_fe 0.131, Loss_kd 2.514, Train_accy 87.21, Test_accy 63.14
2024-08-02 19:15:41,935 [foster.py] => Task 20, Epoch 149/170 => Loss 3.003, Loss_clf 0.314, Loss_fe 0.121, Loss_kd 2.510, Train_accy 88.62, Test_accy 63.11
2024-08-02 19:15:46,754 [foster.py] => Task 20, Epoch 150/170 => Loss 3.005, Loss_clf 0.316, Loss_fe 0.119, Loss_kd 2.511, Train_accy 88.33, Test_accy 63.18
2024-08-02 19:15:49,563 [foster.py] => Task 20, Epoch 151/170 => Loss 3.104, Loss_clf 0.369, Loss_fe 0.131, Loss_kd 2.545, Train_accy 87.54
2024-08-02 19:15:54,430 [foster.py] => Task 20, Epoch 152/170 => Loss 3.062, Loss_clf 0.334, Loss_fe 0.138, Loss_kd 2.532, Train_accy 87.86, Test_accy 63.07
2024-08-02 19:15:59,283 [foster.py] => Task 20, Epoch 153/170 => Loss 3.062, Loss_clf 0.347, Loss_fe 0.133, Loss_kd 2.523, Train_accy 87.93, Test_accy 63.06
2024-08-02 19:16:04,123 [foster.py] => Task 20, Epoch 154/170 => Loss 3.060, Loss_clf 0.336, Loss_fe 0.138, Loss_kd 2.527, Train_accy 88.48, Test_accy 63.10
2024-08-02 19:16:08,939 [foster.py] => Task 20, Epoch 155/170 => Loss 2.963, Loss_clf 0.287, Loss_fe 0.110, Loss_kd 2.507, Train_accy 89.57, Test_accy 63.07
2024-08-02 19:16:11,732 [foster.py] => Task 20, Epoch 156/170 => Loss 3.062, Loss_clf 0.341, Loss_fe 0.126, Loss_kd 2.536, Train_accy 87.97
2024-08-02 19:16:16,548 [foster.py] => Task 20, Epoch 157/170 => Loss 3.028, Loss_clf 0.322, Loss_fe 0.119, Loss_kd 2.528, Train_accy 89.42, Test_accy 63.10
2024-08-02 19:16:21,415 [foster.py] => Task 20, Epoch 158/170 => Loss 3.012, Loss_clf 0.309, Loss_fe 0.124, Loss_kd 2.520, Train_accy 89.60, Test_accy 63.12
2024-08-02 19:16:26,275 [foster.py] => Task 20, Epoch 159/170 => Loss 2.973, Loss_clf 0.302, Loss_fe 0.117, Loss_kd 2.495, Train_accy 89.02, Test_accy 63.04
2024-08-02 19:16:31,110 [foster.py] => Task 20, Epoch 160/170 => Loss 3.004, Loss_clf 0.321, Loss_fe 0.116, Loss_kd 2.508, Train_accy 89.09, Test_accy 63.06
2024-08-02 19:16:33,914 [foster.py] => Task 20, Epoch 161/170 => Loss 2.976, Loss_clf 0.311, Loss_fe 0.120, Loss_kd 2.487, Train_accy 88.77
2024-08-02 19:16:38,779 [foster.py] => Task 20, Epoch 162/170 => Loss 3.039, Loss_clf 0.321, Loss_fe 0.115, Loss_kd 2.544, Train_accy 89.13, Test_accy 63.07
2024-08-02 19:16:43,611 [foster.py] => Task 20, Epoch 163/170 => Loss 3.022, Loss_clf 0.326, Loss_fe 0.106, Loss_kd 2.531, Train_accy 88.33, Test_accy 63.01
2024-08-02 19:16:48,579 [foster.py] => Task 20, Epoch 164/170 => Loss 3.014, Loss_clf 0.326, Loss_fe 0.125, Loss_kd 2.504, Train_accy 88.55, Test_accy 63.11
2024-08-02 19:16:53,414 [foster.py] => Task 20, Epoch 165/170 => Loss 3.006, Loss_clf 0.333, Loss_fe 0.118, Loss_kd 2.496, Train_accy 88.73, Test_accy 63.12
2024-08-02 19:16:56,291 [foster.py] => Task 20, Epoch 166/170 => Loss 3.038, Loss_clf 0.336, Loss_fe 0.119, Loss_kd 2.524, Train_accy 87.46
2024-08-02 19:17:01,245 [foster.py] => Task 20, Epoch 167/170 => Loss 3.043, Loss_clf 0.330, Loss_fe 0.124, Loss_kd 2.530, Train_accy 89.09, Test_accy 63.11
2024-08-02 19:17:06,154 [foster.py] => Task 20, Epoch 168/170 => Loss 3.047, Loss_clf 0.333, Loss_fe 0.118, Loss_kd 2.536, Train_accy 88.01, Test_accy 63.09
2024-08-02 19:17:11,023 [foster.py] => Task 20, Epoch 169/170 => Loss 3.027, Loss_clf 0.325, Loss_fe 0.128, Loss_kd 2.515, Train_accy 88.95, Test_accy 63.10
2024-08-02 19:17:15,811 [foster.py] => Task 20, Epoch 170/170 => Loss 3.070, Loss_clf 0.337, Loss_fe 0.131, Loss_kd 2.543, Train_accy 88.70, Test_accy 63.13
2024-08-02 19:17:15,814 [foster.py] => do not weight align teacher!
2024-08-02 19:17:15,817 [foster.py] => per cls weights : [1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115 1.01207115
 1.01207115 1.01207115 1.01207115 1.01207115 0.46886933 0.46886933]
2024-08-02 19:17:21,175 [foster.py] => SNet: Task 20, Epoch 1/130 => Loss 30.619,  Loss1 0.774, Train_accy 60.47, Test_accy 59.32
2024-08-02 19:17:25,071 [foster.py] => SNet: Task 20, Epoch 2/130 => Loss 30.549,  Loss1 0.774, Train_accy 66.34
2024-08-02 19:17:28,962 [foster.py] => SNet: Task 20, Epoch 3/130 => Loss 30.546,  Loss1 0.774, Train_accy 67.25
2024-08-02 19:17:32,825 [foster.py] => SNet: Task 20, Epoch 4/130 => Loss 30.564,  Loss1 0.774, Train_accy 67.14
2024-08-02 19:17:36,711 [foster.py] => SNet: Task 20, Epoch 5/130 => Loss 30.571,  Loss1 0.773, Train_accy 69.71
2024-08-02 19:17:41,872 [foster.py] => SNet: Task 20, Epoch 6/130 => Loss 30.549,  Loss1 0.774, Train_accy 69.46, Test_accy 61.21
2024-08-02 19:17:45,780 [foster.py] => SNet: Task 20, Epoch 7/130 => Loss 30.560,  Loss1 0.774, Train_accy 69.09
2024-08-02 19:17:49,671 [foster.py] => SNet: Task 20, Epoch 8/130 => Loss 30.540,  Loss1 0.774, Train_accy 68.70
2024-08-02 19:17:53,635 [foster.py] => SNet: Task 20, Epoch 9/130 => Loss 30.563,  Loss1 0.774, Train_accy 70.98
2024-08-02 19:17:57,545 [foster.py] => SNet: Task 20, Epoch 10/130 => Loss 30.520,  Loss1 0.774, Train_accy 70.62
2024-08-02 19:18:02,691 [foster.py] => SNet: Task 20, Epoch 11/130 => Loss 30.552,  Loss1 0.774, Train_accy 70.18, Test_accy 61.00
2024-08-02 19:18:06,559 [foster.py] => SNet: Task 20, Epoch 12/130 => Loss 30.539,  Loss1 0.774, Train_accy 70.83
2024-08-02 19:18:10,445 [foster.py] => SNet: Task 20, Epoch 13/130 => Loss 30.508,  Loss1 0.774, Train_accy 72.10
2024-08-02 19:18:14,352 [foster.py] => SNet: Task 20, Epoch 14/130 => Loss 30.500,  Loss1 0.774, Train_accy 71.99
2024-08-02 19:18:18,274 [foster.py] => SNet: Task 20, Epoch 15/130 => Loss 30.551,  Loss1 0.774, Train_accy 72.21
2024-08-02 19:18:23,449 [foster.py] => SNet: Task 20, Epoch 16/130 => Loss 30.511,  Loss1 0.774, Train_accy 71.01, Test_accy 61.52
2024-08-02 19:18:27,336 [foster.py] => SNet: Task 20, Epoch 17/130 => Loss 30.536,  Loss1 0.774, Train_accy 72.14
2024-08-02 19:18:31,232 [foster.py] => SNet: Task 20, Epoch 18/130 => Loss 30.506,  Loss1 0.774, Train_accy 72.36
2024-08-02 19:18:35,108 [foster.py] => SNet: Task 20, Epoch 19/130 => Loss 30.511,  Loss1 0.774, Train_accy 72.54
2024-08-02 19:18:39,016 [foster.py] => SNet: Task 20, Epoch 20/130 => Loss 30.571,  Loss1 0.774, Train_accy 71.99
2024-08-02 19:18:44,181 [foster.py] => SNet: Task 20, Epoch 21/130 => Loss 30.490,  Loss1 0.774, Train_accy 73.44, Test_accy 61.78
2024-08-02 19:18:48,076 [foster.py] => SNet: Task 20, Epoch 22/130 => Loss 30.561,  Loss1 0.774, Train_accy 73.91
2024-08-02 19:18:51,962 [foster.py] => SNet: Task 20, Epoch 23/130 => Loss 30.506,  Loss1 0.774, Train_accy 73.62
2024-08-02 19:18:55,862 [foster.py] => SNet: Task 20, Epoch 24/130 => Loss 30.551,  Loss1 0.774, Train_accy 72.68
2024-08-02 19:18:59,753 [foster.py] => SNet: Task 20, Epoch 25/130 => Loss 30.515,  Loss1 0.774, Train_accy 73.77
2024-08-02 19:19:04,999 [foster.py] => SNet: Task 20, Epoch 26/130 => Loss 30.542,  Loss1 0.775, Train_accy 73.48, Test_accy 61.67
2024-08-02 19:19:08,929 [foster.py] => SNet: Task 20, Epoch 27/130 => Loss 30.554,  Loss1 0.774, Train_accy 73.59
2024-08-02 19:19:12,844 [foster.py] => SNet: Task 20, Epoch 28/130 => Loss 30.505,  Loss1 0.774, Train_accy 74.57
2024-08-02 19:19:16,725 [foster.py] => SNet: Task 20, Epoch 29/130 => Loss 30.530,  Loss1 0.774, Train_accy 73.99
2024-08-02 19:19:20,617 [foster.py] => SNet: Task 20, Epoch 30/130 => Loss 30.536,  Loss1 0.774, Train_accy 74.57
2024-08-02 19:19:25,752 [foster.py] => SNet: Task 20, Epoch 31/130 => Loss 30.537,  Loss1 0.774, Train_accy 74.42, Test_accy 61.48
2024-08-02 19:19:29,620 [foster.py] => SNet: Task 20, Epoch 32/130 => Loss 30.520,  Loss1 0.774, Train_accy 73.73
2024-08-02 19:19:33,520 [foster.py] => SNet: Task 20, Epoch 33/130 => Loss 30.497,  Loss1 0.774, Train_accy 75.83
2024-08-02 19:19:37,387 [foster.py] => SNet: Task 20, Epoch 34/130 => Loss 30.534,  Loss1 0.774, Train_accy 73.37
2024-08-02 19:19:41,278 [foster.py] => SNet: Task 20, Epoch 35/130 => Loss 30.520,  Loss1 0.774, Train_accy 74.53
2024-08-02 19:19:46,461 [foster.py] => SNet: Task 20, Epoch 36/130 => Loss 30.553,  Loss1 0.774, Train_accy 75.11, Test_accy 61.87
2024-08-02 19:19:50,347 [foster.py] => SNet: Task 20, Epoch 37/130 => Loss 30.566,  Loss1 0.775, Train_accy 74.93
2024-08-02 19:19:54,274 [foster.py] => SNet: Task 20, Epoch 38/130 => Loss 30.508,  Loss1 0.774, Train_accy 75.22
2024-08-02 19:19:58,173 [foster.py] => SNet: Task 20, Epoch 39/130 => Loss 30.541,  Loss1 0.774, Train_accy 74.67
2024-08-02 19:20:02,070 [foster.py] => SNet: Task 20, Epoch 40/130 => Loss 30.600,  Loss1 0.773, Train_accy 73.66
2024-08-02 19:20:07,244 [foster.py] => SNet: Task 20, Epoch 41/130 => Loss 30.549,  Loss1 0.774, Train_accy 75.14, Test_accy 61.68
2024-08-02 19:20:11,131 [foster.py] => SNet: Task 20, Epoch 42/130 => Loss 30.504,  Loss1 0.774, Train_accy 74.78
2024-08-02 19:20:15,093 [foster.py] => SNet: Task 20, Epoch 43/130 => Loss 30.539,  Loss1 0.774, Train_accy 75.22
2024-08-02 19:20:18,973 [foster.py] => SNet: Task 20, Epoch 44/130 => Loss 30.518,  Loss1 0.774, Train_accy 74.31
2024-08-02 19:20:22,853 [foster.py] => SNet: Task 20, Epoch 45/130 => Loss 30.481,  Loss1 0.774, Train_accy 75.07
2024-08-02 19:20:28,039 [foster.py] => SNet: Task 20, Epoch 46/130 => Loss 30.523,  Loss1 0.774, Train_accy 75.22, Test_accy 61.67
2024-08-02 19:20:31,925 [foster.py] => SNet: Task 20, Epoch 47/130 => Loss 30.467,  Loss1 0.773, Train_accy 74.86
2024-08-02 19:20:35,829 [foster.py] => SNet: Task 20, Epoch 48/130 => Loss 30.534,  Loss1 0.774, Train_accy 75.47
2024-08-02 19:20:39,730 [foster.py] => SNet: Task 20, Epoch 49/130 => Loss 30.530,  Loss1 0.774, Train_accy 73.99
2024-08-02 19:20:43,623 [foster.py] => SNet: Task 20, Epoch 50/130 => Loss 30.514,  Loss1 0.774, Train_accy 77.17
2024-08-02 19:20:48,755 [foster.py] => SNet: Task 20, Epoch 51/130 => Loss 30.531,  Loss1 0.774, Train_accy 76.85, Test_accy 61.82
2024-08-02 19:20:52,629 [foster.py] => SNet: Task 20, Epoch 52/130 => Loss 30.525,  Loss1 0.774, Train_accy 74.86
2024-08-02 19:20:56,509 [foster.py] => SNet: Task 20, Epoch 53/130 => Loss 30.493,  Loss1 0.774, Train_accy 74.93
2024-08-02 19:21:00,374 [foster.py] => SNet: Task 20, Epoch 54/130 => Loss 30.478,  Loss1 0.774, Train_accy 76.74
2024-08-02 19:21:04,236 [foster.py] => SNet: Task 20, Epoch 55/130 => Loss 30.510,  Loss1 0.774, Train_accy 75.69
2024-08-02 19:21:09,410 [foster.py] => SNet: Task 20, Epoch 56/130 => Loss 30.544,  Loss1 0.773, Train_accy 75.18, Test_accy 61.82
2024-08-02 19:21:13,316 [foster.py] => SNet: Task 20, Epoch 57/130 => Loss 30.542,  Loss1 0.774, Train_accy 76.74
2024-08-02 19:21:17,175 [foster.py] => SNet: Task 20, Epoch 58/130 => Loss 30.496,  Loss1 0.774, Train_accy 75.51
2024-08-02 19:21:21,065 [foster.py] => SNet: Task 20, Epoch 59/130 => Loss 30.539,  Loss1 0.774, Train_accy 75.33
2024-08-02 19:21:25,022 [foster.py] => SNet: Task 20, Epoch 60/130 => Loss 30.508,  Loss1 0.774, Train_accy 75.29
2024-08-02 19:21:30,191 [foster.py] => SNet: Task 20, Epoch 61/130 => Loss 30.547,  Loss1 0.774, Train_accy 74.31, Test_accy 61.43
2024-08-02 19:21:34,069 [foster.py] => SNet: Task 20, Epoch 62/130 => Loss 30.475,  Loss1 0.775, Train_accy 76.34
2024-08-02 19:21:37,949 [foster.py] => SNet: Task 20, Epoch 63/130 => Loss 30.537,  Loss1 0.773, Train_accy 75.72
2024-08-02 19:21:41,811 [foster.py] => SNet: Task 20, Epoch 64/130 => Loss 30.567,  Loss1 0.773, Train_accy 74.96
2024-08-02 19:21:45,701 [foster.py] => SNet: Task 20, Epoch 65/130 => Loss 30.541,  Loss1 0.774, Train_accy 75.07
2024-08-02 19:21:50,897 [foster.py] => SNet: Task 20, Epoch 66/130 => Loss 30.585,  Loss1 0.774, Train_accy 76.30, Test_accy 61.86
2024-08-02 19:21:54,810 [foster.py] => SNet: Task 20, Epoch 67/130 => Loss 30.557,  Loss1 0.774, Train_accy 74.35
2024-08-02 19:21:58,728 [foster.py] => SNet: Task 20, Epoch 68/130 => Loss 30.520,  Loss1 0.774, Train_accy 77.14
2024-08-02 19:22:02,633 [foster.py] => SNet: Task 20, Epoch 69/130 => Loss 30.523,  Loss1 0.774, Train_accy 75.04
2024-08-02 19:22:06,551 [foster.py] => SNet: Task 20, Epoch 70/130 => Loss 30.513,  Loss1 0.774, Train_accy 75.04
2024-08-02 19:22:11,727 [foster.py] => SNet: Task 20, Epoch 71/130 => Loss 30.535,  Loss1 0.774, Train_accy 76.38, Test_accy 61.87
2024-08-02 19:22:15,608 [foster.py] => SNet: Task 20, Epoch 72/130 => Loss 30.556,  Loss1 0.774, Train_accy 76.05
2024-08-02 19:22:19,499 [foster.py] => SNet: Task 20, Epoch 73/130 => Loss 30.496,  Loss1 0.774, Train_accy 75.43
2024-08-02 19:22:23,370 [foster.py] => SNet: Task 20, Epoch 74/130 => Loss 30.550,  Loss1 0.774, Train_accy 75.62
2024-08-02 19:22:27,263 [foster.py] => SNet: Task 20, Epoch 75/130 => Loss 30.521,  Loss1 0.774, Train_accy 76.30
2024-08-02 19:22:32,450 [foster.py] => SNet: Task 20, Epoch 76/130 => Loss 30.511,  Loss1 0.774, Train_accy 76.01, Test_accy 61.91
2024-08-02 19:22:36,383 [foster.py] => SNet: Task 20, Epoch 77/130 => Loss 30.522,  Loss1 0.774, Train_accy 77.28
2024-08-02 19:22:40,278 [foster.py] => SNet: Task 20, Epoch 78/130 => Loss 30.516,  Loss1 0.774, Train_accy 75.29
2024-08-02 19:22:44,196 [foster.py] => SNet: Task 20, Epoch 79/130 => Loss 30.484,  Loss1 0.774, Train_accy 76.85
2024-08-02 19:22:48,083 [foster.py] => SNet: Task 20, Epoch 80/130 => Loss 30.509,  Loss1 0.774, Train_accy 77.43
2024-08-02 19:22:53,244 [foster.py] => SNet: Task 20, Epoch 81/130 => Loss 30.555,  Loss1 0.774, Train_accy 75.18, Test_accy 62.16
2024-08-02 19:22:57,126 [foster.py] => SNet: Task 20, Epoch 82/130 => Loss 30.521,  Loss1 0.774, Train_accy 77.14
2024-08-02 19:23:01,023 [foster.py] => SNet: Task 20, Epoch 83/130 => Loss 30.506,  Loss1 0.774, Train_accy 76.88
2024-08-02 19:23:04,917 [foster.py] => SNet: Task 20, Epoch 84/130 => Loss 30.551,  Loss1 0.774, Train_accy 75.91
2024-08-02 19:23:08,798 [foster.py] => SNet: Task 20, Epoch 85/130 => Loss 30.516,  Loss1 0.774, Train_accy 76.49
2024-08-02 19:23:13,950 [foster.py] => SNet: Task 20, Epoch 86/130 => Loss 30.528,  Loss1 0.773, Train_accy 76.70, Test_accy 61.81
2024-08-02 19:23:17,855 [foster.py] => SNet: Task 20, Epoch 87/130 => Loss 30.469,  Loss1 0.774, Train_accy 77.46
2024-08-02 19:23:21,764 [foster.py] => SNet: Task 20, Epoch 88/130 => Loss 30.489,  Loss1 0.774, Train_accy 76.81
2024-08-02 19:23:25,643 [foster.py] => SNet: Task 20, Epoch 89/130 => Loss 30.500,  Loss1 0.774, Train_accy 77.64
2024-08-02 19:23:29,576 [foster.py] => SNet: Task 20, Epoch 90/130 => Loss 30.512,  Loss1 0.773, Train_accy 76.30
2024-08-02 19:23:34,754 [foster.py] => SNet: Task 20, Epoch 91/130 => Loss 30.474,  Loss1 0.774, Train_accy 75.72, Test_accy 62.03
2024-08-02 19:23:38,617 [foster.py] => SNet: Task 20, Epoch 92/130 => Loss 30.539,  Loss1 0.773, Train_accy 75.43
2024-08-02 19:23:42,509 [foster.py] => SNet: Task 20, Epoch 93/130 => Loss 30.516,  Loss1 0.774, Train_accy 75.98
2024-08-02 19:23:46,451 [foster.py] => SNet: Task 20, Epoch 94/130 => Loss 30.519,  Loss1 0.773, Train_accy 76.56
2024-08-02 19:23:50,325 [foster.py] => SNet: Task 20, Epoch 95/130 => Loss 30.506,  Loss1 0.774, Train_accy 76.56
2024-08-02 19:23:55,485 [foster.py] => SNet: Task 20, Epoch 96/130 => Loss 30.501,  Loss1 0.774, Train_accy 77.83, Test_accy 61.82
2024-08-02 19:23:59,351 [foster.py] => SNet: Task 20, Epoch 97/130 => Loss 30.506,  Loss1 0.774, Train_accy 76.49
2024-08-02 19:24:03,222 [foster.py] => SNet: Task 20, Epoch 98/130 => Loss 30.522,  Loss1 0.774, Train_accy 76.16
2024-08-02 19:24:07,090 [foster.py] => SNet: Task 20, Epoch 99/130 => Loss 30.497,  Loss1 0.774, Train_accy 75.94
2024-08-02 19:24:11,002 [foster.py] => SNet: Task 20, Epoch 100/130 => Loss 30.513,  Loss1 0.774, Train_accy 76.41
2024-08-02 19:24:16,155 [foster.py] => SNet: Task 20, Epoch 101/130 => Loss 30.534,  Loss1 0.774, Train_accy 78.01, Test_accy 61.99
2024-08-02 19:24:20,061 [foster.py] => SNet: Task 20, Epoch 102/130 => Loss 30.529,  Loss1 0.774, Train_accy 75.87
2024-08-02 19:24:23,961 [foster.py] => SNet: Task 20, Epoch 103/130 => Loss 30.489,  Loss1 0.774, Train_accy 76.12
2024-08-02 19:24:27,864 [foster.py] => SNet: Task 20, Epoch 104/130 => Loss 30.565,  Loss1 0.774, Train_accy 75.18
2024-08-02 19:24:31,735 [foster.py] => SNet: Task 20, Epoch 105/130 => Loss 30.475,  Loss1 0.774, Train_accy 75.91
2024-08-02 19:24:36,938 [foster.py] => SNet: Task 20, Epoch 106/130 => Loss 30.543,  Loss1 0.774, Train_accy 76.74, Test_accy 61.90
2024-08-02 19:24:40,829 [foster.py] => SNet: Task 20, Epoch 107/130 => Loss 30.487,  Loss1 0.774, Train_accy 77.28
2024-08-02 19:24:44,761 [foster.py] => SNet: Task 20, Epoch 108/130 => Loss 30.465,  Loss1 0.774, Train_accy 77.97
2024-08-02 19:24:48,665 [foster.py] => SNet: Task 20, Epoch 109/130 => Loss 30.533,  Loss1 0.774, Train_accy 76.56
2024-08-02 19:24:52,544 [foster.py] => SNet: Task 20, Epoch 110/130 => Loss 30.512,  Loss1 0.774, Train_accy 76.38
2024-08-02 19:24:57,743 [foster.py] => SNet: Task 20, Epoch 111/130 => Loss 30.504,  Loss1 0.774, Train_accy 76.49, Test_accy 61.92
2024-08-02 19:25:01,654 [foster.py] => SNet: Task 20, Epoch 112/130 => Loss 30.487,  Loss1 0.774, Train_accy 77.07
2024-08-02 19:25:05,576 [foster.py] => SNet: Task 20, Epoch 113/130 => Loss 30.489,  Loss1 0.774, Train_accy 77.50
2024-08-02 19:25:09,503 [foster.py] => SNet: Task 20, Epoch 114/130 => Loss 30.518,  Loss1 0.774, Train_accy 76.92
2024-08-02 19:25:13,378 [foster.py] => SNet: Task 20, Epoch 115/130 => Loss 30.476,  Loss1 0.774, Train_accy 75.94
2024-08-02 19:25:18,517 [foster.py] => SNet: Task 20, Epoch 116/130 => Loss 30.527,  Loss1 0.773, Train_accy 74.60, Test_accy 62.01
2024-08-02 19:25:22,429 [foster.py] => SNet: Task 20, Epoch 117/130 => Loss 30.509,  Loss1 0.774, Train_accy 76.67
2024-08-02 19:25:26,301 [foster.py] => SNet: Task 20, Epoch 118/130 => Loss 30.518,  Loss1 0.774, Train_accy 77.17
2024-08-02 19:25:30,203 [foster.py] => SNet: Task 20, Epoch 119/130 => Loss 30.518,  Loss1 0.774, Train_accy 76.67
2024-08-02 19:25:34,116 [foster.py] => SNet: Task 20, Epoch 120/130 => Loss 30.537,  Loss1 0.774, Train_accy 76.23
2024-08-02 19:25:39,267 [foster.py] => SNet: Task 20, Epoch 121/130 => Loss 30.524,  Loss1 0.774, Train_accy 76.52, Test_accy 61.76
2024-08-02 19:25:43,158 [foster.py] => SNet: Task 20, Epoch 122/130 => Loss 30.550,  Loss1 0.773, Train_accy 76.99
2024-08-02 19:25:47,088 [foster.py] => SNet: Task 20, Epoch 123/130 => Loss 30.541,  Loss1 0.774, Train_accy 75.36
2024-08-02 19:25:51,002 [foster.py] => SNet: Task 20, Epoch 124/130 => Loss 30.449,  Loss1 0.774, Train_accy 77.32
2024-08-02 19:25:54,896 [foster.py] => SNet: Task 20, Epoch 125/130 => Loss 30.548,  Loss1 0.774, Train_accy 76.74
2024-08-02 19:26:00,047 [foster.py] => SNet: Task 20, Epoch 126/130 => Loss 30.505,  Loss1 0.774, Train_accy 77.36, Test_accy 61.79
2024-08-02 19:26:03,948 [foster.py] => SNet: Task 20, Epoch 127/130 => Loss 30.530,  Loss1 0.773, Train_accy 76.30
2024-08-02 19:26:07,904 [foster.py] => SNet: Task 20, Epoch 128/130 => Loss 30.494,  Loss1 0.774, Train_accy 76.85
2024-08-02 19:26:11,794 [foster.py] => SNet: Task 20, Epoch 129/130 => Loss 30.544,  Loss1 0.774, Train_accy 76.99
2024-08-02 19:26:15,694 [foster.py] => SNet: Task 20, Epoch 130/130 => Loss 30.510,  Loss1 0.774, Train_accy 76.59
2024-08-02 19:26:15,695 [foster.py] => do not weight align student!
2024-08-02 19:26:16,976 [foster.py] => darknet eval: 
2024-08-02 19:26:16,976 [foster.py] => CNN top1 curve: 62.12
2024-08-02 19:26:16,976 [foster.py] => CNN top5 curve: 86.12
2024-08-02 19:26:16,977 [foster.py] => CNN top1 平均值: 62.12
2024-08-02 19:26:16,982 [foster.py] => timees : 1295.132571220398
2024-08-02 19:26:16,983 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 19:26:44,401 [foster.py] => Exemplar size: 1800
2024-08-02 19:26:44,401 [trainer.py] => CNN: {'total': 63.13, '00-09': 70.0, '10-19': 52.4, '20-29': 69.3, '30-39': 61.9, '40-49': 66.5, '50-59': 49.2, '60-69': 64.2, '70-79': 64.1, '80-89': 70.6, 'old': 62.93, 'new': 72.0}
2024-08-02 19:26:44,401 [trainer.py] => NME: {'total': 58.09, '00-09': 58.3, '10-19': 44.4, '20-29': 61.7, '30-39': 52.7, '40-49': 59.6, '50-59': 48.3, '60-69': 63.5, '70-79': 68.9, '80-89': 65.4, 'old': 57.57, 'new': 81.0}
2024-08-02 19:26:44,401 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13]
2024-08-02 19:26:44,401 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99]
2024-08-02 19:26:44,401 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09]
2024-08-02 19:26:44,401 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79]

2024-08-02 19:26:44,401 [trainer.py] => CNN top1 平均值: 71.75
2024-08-02 19:26:44,404 [trainer.py] => All params: 1177728
2024-08-02 19:26:44,407 [trainer.py] => Trainable params: 594734
2024-08-02 19:26:44,467 [foster.py] => Learning on 90-92
2024-08-02 19:26:44,471 [foster.py] => All params: 1178246
2024-08-02 19:26:44,473 [foster.py] => Trainable params: 595122
2024-08-02 19:26:44,516 [foster.py] => per cls weights : [1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313 1.00994313
 0.55255918 0.55255918]
2024-08-02 19:26:47,324 [foster.py] => Task 21, Epoch 1/170 => Loss 5.588, Loss_clf 0.924, Loss_fe 2.045, Loss_kd 2.560, Train_accy 69.14
2024-08-02 19:26:52,246 [foster.py] => Task 21, Epoch 2/170 => Loss 3.848, Loss_clf 0.525, Loss_fe 0.691, Loss_kd 2.573, Train_accy 79.61, Test_accy 61.52
2024-08-02 19:26:57,171 [foster.py] => Task 21, Epoch 3/170 => Loss 3.598, Loss_clf 0.466, Loss_fe 0.558, Loss_kd 2.516, Train_accy 79.89, Test_accy 61.67
2024-08-02 19:27:02,010 [foster.py] => Task 21, Epoch 4/170 => Loss 3.530, Loss_clf 0.470, Loss_fe 0.473, Loss_kd 2.529, Train_accy 79.32, Test_accy 61.29
2024-08-02 19:27:06,909 [foster.py] => Task 21, Epoch 5/170 => Loss 3.449, Loss_clf 0.430, Loss_fe 0.444, Loss_kd 2.517, Train_accy 81.07, Test_accy 61.47
2024-08-02 19:27:09,729 [foster.py] => Task 21, Epoch 6/170 => Loss 3.498, Loss_clf 0.452, Loss_fe 0.425, Loss_kd 2.563, Train_accy 80.79
2024-08-02 19:27:14,631 [foster.py] => Task 21, Epoch 7/170 => Loss 3.416, Loss_clf 0.439, Loss_fe 0.396, Loss_kd 2.524, Train_accy 81.21, Test_accy 61.55
2024-08-02 19:27:19,460 [foster.py] => Task 21, Epoch 8/170 => Loss 3.382, Loss_clf 0.424, Loss_fe 0.376, Loss_kd 2.523, Train_accy 81.61, Test_accy 61.39
2024-08-02 19:27:24,298 [foster.py] => Task 21, Epoch 9/170 => Loss 3.395, Loss_clf 0.431, Loss_fe 0.371, Loss_kd 2.535, Train_accy 81.54, Test_accy 61.39
2024-08-02 19:27:29,128 [foster.py] => Task 21, Epoch 10/170 => Loss 3.340, Loss_clf 0.403, Loss_fe 0.363, Loss_kd 2.516, Train_accy 82.29, Test_accy 61.25
2024-08-02 19:27:31,920 [foster.py] => Task 21, Epoch 11/170 => Loss 3.335, Loss_clf 0.405, Loss_fe 0.360, Loss_kd 2.512, Train_accy 82.46
2024-08-02 19:27:36,753 [foster.py] => Task 21, Epoch 12/170 => Loss 3.405, Loss_clf 0.447, Loss_fe 0.365, Loss_kd 2.534, Train_accy 80.57, Test_accy 60.22
2024-08-02 19:27:41,595 [foster.py] => Task 21, Epoch 13/170 => Loss 3.334, Loss_clf 0.412, Loss_fe 0.320, Loss_kd 2.544, Train_accy 82.64, Test_accy 61.33
2024-08-02 19:27:46,502 [foster.py] => Task 21, Epoch 14/170 => Loss 3.272, Loss_clf 0.383, Loss_fe 0.312, Loss_kd 2.518, Train_accy 82.75, Test_accy 61.45
2024-08-02 19:27:51,357 [foster.py] => Task 21, Epoch 15/170 => Loss 3.323, Loss_clf 0.425, Loss_fe 0.323, Loss_kd 2.516, Train_accy 82.39, Test_accy 60.55
2024-08-02 19:27:54,169 [foster.py] => Task 21, Epoch 16/170 => Loss 3.305, Loss_clf 0.395, Loss_fe 0.319, Loss_kd 2.533, Train_accy 82.79
2024-08-02 19:27:59,077 [foster.py] => Task 21, Epoch 17/170 => Loss 3.323, Loss_clf 0.403, Loss_fe 0.320, Loss_kd 2.542, Train_accy 82.61, Test_accy 61.45
2024-08-02 19:28:03,980 [foster.py] => Task 21, Epoch 18/170 => Loss 3.312, Loss_clf 0.414, Loss_fe 0.312, Loss_kd 2.529, Train_accy 82.54, Test_accy 61.58
2024-08-02 19:28:08,825 [foster.py] => Task 21, Epoch 19/170 => Loss 3.235, Loss_clf 0.381, Loss_fe 0.284, Loss_kd 2.513, Train_accy 82.96, Test_accy 61.47
2024-08-02 19:28:13,681 [foster.py] => Task 21, Epoch 20/170 => Loss 3.241, Loss_clf 0.376, Loss_fe 0.269, Loss_kd 2.537, Train_accy 84.32, Test_accy 60.85
2024-08-02 19:28:16,483 [foster.py] => Task 21, Epoch 21/170 => Loss 3.259, Loss_clf 0.388, Loss_fe 0.285, Loss_kd 2.528, Train_accy 84.07
2024-08-02 19:28:21,371 [foster.py] => Task 21, Epoch 22/170 => Loss 3.194, Loss_clf 0.352, Loss_fe 0.278, Loss_kd 2.506, Train_accy 84.96, Test_accy 61.04
2024-08-02 19:28:26,201 [foster.py] => Task 21, Epoch 23/170 => Loss 3.242, Loss_clf 0.404, Loss_fe 0.257, Loss_kd 2.523, Train_accy 84.36, Test_accy 61.33
2024-08-02 19:28:31,078 [foster.py] => Task 21, Epoch 24/170 => Loss 3.220, Loss_clf 0.366, Loss_fe 0.245, Loss_kd 2.550, Train_accy 85.14, Test_accy 61.83
2024-08-02 19:28:35,958 [foster.py] => Task 21, Epoch 25/170 => Loss 3.235, Loss_clf 0.402, Loss_fe 0.268, Loss_kd 2.508, Train_accy 84.64, Test_accy 61.67
2024-08-02 19:28:38,729 [foster.py] => Task 21, Epoch 26/170 => Loss 3.226, Loss_clf 0.377, Loss_fe 0.277, Loss_kd 2.515, Train_accy 85.11
2024-08-02 19:28:43,574 [foster.py] => Task 21, Epoch 27/170 => Loss 3.250, Loss_clf 0.407, Loss_fe 0.273, Loss_kd 2.512, Train_accy 84.18, Test_accy 61.01
2024-08-02 19:28:48,402 [foster.py] => Task 21, Epoch 28/170 => Loss 3.223, Loss_clf 0.396, Loss_fe 0.265, Loss_kd 2.505, Train_accy 84.89, Test_accy 61.64
2024-08-02 19:28:53,241 [foster.py] => Task 21, Epoch 29/170 => Loss 3.237, Loss_clf 0.384, Loss_fe 0.250, Loss_kd 2.545, Train_accy 85.25, Test_accy 61.78
2024-08-02 19:28:58,068 [foster.py] => Task 21, Epoch 30/170 => Loss 3.209, Loss_clf 0.369, Loss_fe 0.269, Loss_kd 2.514, Train_accy 84.21, Test_accy 61.74
2024-08-02 19:29:00,846 [foster.py] => Task 21, Epoch 31/170 => Loss 3.276, Loss_clf 0.411, Loss_fe 0.268, Loss_kd 2.539, Train_accy 84.68
2024-08-02 19:29:05,794 [foster.py] => Task 21, Epoch 32/170 => Loss 3.258, Loss_clf 0.403, Loss_fe 0.259, Loss_kd 2.538, Train_accy 83.54, Test_accy 61.46
2024-08-02 19:29:10,725 [foster.py] => Task 21, Epoch 33/170 => Loss 3.154, Loss_clf 0.362, Loss_fe 0.223, Loss_kd 2.511, Train_accy 83.96, Test_accy 61.57
2024-08-02 19:29:15,566 [foster.py] => Task 21, Epoch 34/170 => Loss 3.225, Loss_clf 0.393, Loss_fe 0.231, Loss_kd 2.543, Train_accy 84.71, Test_accy 61.86
2024-08-02 19:29:20,413 [foster.py] => Task 21, Epoch 35/170 => Loss 3.203, Loss_clf 0.377, Loss_fe 0.239, Loss_kd 2.528, Train_accy 84.36, Test_accy 61.68
2024-08-02 19:29:23,198 [foster.py] => Task 21, Epoch 36/170 => Loss 3.113, Loss_clf 0.344, Loss_fe 0.209, Loss_kd 2.503, Train_accy 85.86
2024-08-02 19:29:28,076 [foster.py] => Task 21, Epoch 37/170 => Loss 3.193, Loss_clf 0.385, Loss_fe 0.216, Loss_kd 2.534, Train_accy 84.25, Test_accy 61.68
2024-08-02 19:29:32,934 [foster.py] => Task 21, Epoch 38/170 => Loss 3.179, Loss_clf 0.379, Loss_fe 0.211, Loss_kd 2.530, Train_accy 86.04, Test_accy 61.85
2024-08-02 19:29:37,819 [foster.py] => Task 21, Epoch 39/170 => Loss 3.167, Loss_clf 0.368, Loss_fe 0.203, Loss_kd 2.538, Train_accy 86.29, Test_accy 61.59
2024-08-02 19:29:42,681 [foster.py] => Task 21, Epoch 40/170 => Loss 3.121, Loss_clf 0.341, Loss_fe 0.219, Loss_kd 2.503, Train_accy 87.32, Test_accy 61.82
2024-08-02 19:29:45,469 [foster.py] => Task 21, Epoch 41/170 => Loss 3.180, Loss_clf 0.372, Loss_fe 0.226, Loss_kd 2.524, Train_accy 86.29
2024-08-02 19:29:50,336 [foster.py] => Task 21, Epoch 42/170 => Loss 3.142, Loss_clf 0.348, Loss_fe 0.216, Loss_kd 2.520, Train_accy 85.86, Test_accy 61.78
2024-08-02 19:29:55,231 [foster.py] => Task 21, Epoch 43/170 => Loss 3.169, Loss_clf 0.372, Loss_fe 0.204, Loss_kd 2.535, Train_accy 85.14, Test_accy 61.75
2024-08-02 19:30:00,118 [foster.py] => Task 21, Epoch 44/170 => Loss 3.147, Loss_clf 0.348, Loss_fe 0.202, Loss_kd 2.539, Train_accy 86.32, Test_accy 61.70
2024-08-02 19:30:04,983 [foster.py] => Task 21, Epoch 45/170 => Loss 3.121, Loss_clf 0.353, Loss_fe 0.212, Loss_kd 2.498, Train_accy 85.79, Test_accy 61.82
2024-08-02 19:30:07,835 [foster.py] => Task 21, Epoch 46/170 => Loss 3.170, Loss_clf 0.369, Loss_fe 0.217, Loss_kd 2.526, Train_accy 86.36
2024-08-02 19:30:12,680 [foster.py] => Task 21, Epoch 47/170 => Loss 3.130, Loss_clf 0.347, Loss_fe 0.195, Loss_kd 2.529, Train_accy 85.82, Test_accy 61.57
2024-08-02 19:30:17,520 [foster.py] => Task 21, Epoch 48/170 => Loss 3.139, Loss_clf 0.343, Loss_fe 0.210, Loss_kd 2.528, Train_accy 86.57, Test_accy 62.04
2024-08-02 19:30:22,333 [foster.py] => Task 21, Epoch 49/170 => Loss 3.094, Loss_clf 0.333, Loss_fe 0.210, Loss_kd 2.494, Train_accy 87.29, Test_accy 62.10
2024-08-02 19:30:27,170 [foster.py] => Task 21, Epoch 50/170 => Loss 3.145, Loss_clf 0.364, Loss_fe 0.201, Loss_kd 2.522, Train_accy 86.32, Test_accy 61.85
2024-08-02 19:30:30,001 [foster.py] => Task 21, Epoch 51/170 => Loss 3.108, Loss_clf 0.351, Loss_fe 0.185, Loss_kd 2.514, Train_accy 86.57
2024-08-02 19:30:34,931 [foster.py] => Task 21, Epoch 52/170 => Loss 3.113, Loss_clf 0.355, Loss_fe 0.170, Loss_kd 2.530, Train_accy 86.57, Test_accy 62.05
2024-08-02 19:30:39,847 [foster.py] => Task 21, Epoch 53/170 => Loss 3.105, Loss_clf 0.342, Loss_fe 0.182, Loss_kd 2.523, Train_accy 87.04, Test_accy 61.96
2024-08-02 19:30:44,735 [foster.py] => Task 21, Epoch 54/170 => Loss 3.061, Loss_clf 0.338, Loss_fe 0.180, Loss_kd 2.486, Train_accy 87.86, Test_accy 61.77
2024-08-02 19:30:49,570 [foster.py] => Task 21, Epoch 55/170 => Loss 3.056, Loss_clf 0.330, Loss_fe 0.164, Loss_kd 2.504, Train_accy 87.86, Test_accy 61.90
2024-08-02 19:30:52,351 [foster.py] => Task 21, Epoch 56/170 => Loss 3.094, Loss_clf 0.350, Loss_fe 0.173, Loss_kd 2.513, Train_accy 87.14
2024-08-02 19:30:57,191 [foster.py] => Task 21, Epoch 57/170 => Loss 3.151, Loss_clf 0.362, Loss_fe 0.187, Loss_kd 2.544, Train_accy 86.14, Test_accy 61.75
2024-08-02 19:31:02,127 [foster.py] => Task 21, Epoch 58/170 => Loss 3.128, Loss_clf 0.369, Loss_fe 0.186, Loss_kd 2.516, Train_accy 86.14, Test_accy 61.66
2024-08-02 19:31:07,017 [foster.py] => Task 21, Epoch 59/170 => Loss 3.119, Loss_clf 0.352, Loss_fe 0.178, Loss_kd 2.531, Train_accy 87.29, Test_accy 62.10
2024-08-02 19:31:11,887 [foster.py] => Task 21, Epoch 60/170 => Loss 3.098, Loss_clf 0.336, Loss_fe 0.175, Loss_kd 2.529, Train_accy 87.71, Test_accy 61.67
2024-08-02 19:31:14,661 [foster.py] => Task 21, Epoch 61/170 => Loss 3.083, Loss_clf 0.333, Loss_fe 0.173, Loss_kd 2.519, Train_accy 87.07
2024-08-02 19:31:19,495 [foster.py] => Task 21, Epoch 62/170 => Loss 3.091, Loss_clf 0.344, Loss_fe 0.174, Loss_kd 2.515, Train_accy 86.93, Test_accy 61.68
2024-08-02 19:31:24,330 [foster.py] => Task 21, Epoch 63/170 => Loss 3.144, Loss_clf 0.368, Loss_fe 0.170, Loss_kd 2.548, Train_accy 87.18, Test_accy 62.17
2024-08-02 19:31:29,175 [foster.py] => Task 21, Epoch 64/170 => Loss 3.122, Loss_clf 0.356, Loss_fe 0.188, Loss_kd 2.521, Train_accy 87.04, Test_accy 62.10
2024-08-02 19:31:34,056 [foster.py] => Task 21, Epoch 65/170 => Loss 3.110, Loss_clf 0.345, Loss_fe 0.161, Loss_kd 2.545, Train_accy 86.29, Test_accy 62.09
2024-08-02 19:31:36,854 [foster.py] => Task 21, Epoch 66/170 => Loss 3.094, Loss_clf 0.346, Loss_fe 0.147, Loss_kd 2.541, Train_accy 87.64
2024-08-02 19:31:41,727 [foster.py] => Task 21, Epoch 67/170 => Loss 3.093, Loss_clf 0.336, Loss_fe 0.165, Loss_kd 2.534, Train_accy 88.46, Test_accy 62.02
2024-08-02 19:31:46,575 [foster.py] => Task 21, Epoch 68/170 => Loss 3.090, Loss_clf 0.331, Loss_fe 0.167, Loss_kd 2.534, Train_accy 88.50, Test_accy 62.29
2024-08-02 19:31:51,440 [foster.py] => Task 21, Epoch 69/170 => Loss 3.120, Loss_clf 0.356, Loss_fe 0.166, Loss_kd 2.540, Train_accy 86.46, Test_accy 61.95
2024-08-02 19:31:56,464 [foster.py] => Task 21, Epoch 70/170 => Loss 3.101, Loss_clf 0.342, Loss_fe 0.179, Loss_kd 2.523, Train_accy 87.79, Test_accy 62.17
2024-08-02 19:31:59,245 [foster.py] => Task 21, Epoch 71/170 => Loss 3.103, Loss_clf 0.352, Loss_fe 0.170, Loss_kd 2.523, Train_accy 86.86
2024-08-02 19:32:04,157 [foster.py] => Task 21, Epoch 72/170 => Loss 3.067, Loss_clf 0.327, Loss_fe 0.155, Loss_kd 2.526, Train_accy 88.50, Test_accy 62.55
2024-08-02 19:32:08,984 [foster.py] => Task 21, Epoch 73/170 => Loss 3.101, Loss_clf 0.365, Loss_fe 0.161, Loss_kd 2.518, Train_accy 85.79, Test_accy 61.83
2024-08-02 19:32:13,880 [foster.py] => Task 21, Epoch 74/170 => Loss 3.081, Loss_clf 0.341, Loss_fe 0.145, Loss_kd 2.538, Train_accy 87.57, Test_accy 62.02
2024-08-02 19:32:18,777 [foster.py] => Task 21, Epoch 75/170 => Loss 3.107, Loss_clf 0.351, Loss_fe 0.164, Loss_kd 2.535, Train_accy 86.64, Test_accy 61.76
2024-08-02 19:32:21,590 [foster.py] => Task 21, Epoch 76/170 => Loss 3.007, Loss_clf 0.311, Loss_fe 0.130, Loss_kd 2.509, Train_accy 88.43
2024-08-02 19:32:26,490 [foster.py] => Task 21, Epoch 77/170 => Loss 3.036, Loss_clf 0.331, Loss_fe 0.134, Loss_kd 2.514, Train_accy 88.29, Test_accy 62.11
2024-08-02 19:32:31,331 [foster.py] => Task 21, Epoch 78/170 => Loss 3.031, Loss_clf 0.329, Loss_fe 0.138, Loss_kd 2.506, Train_accy 87.71, Test_accy 62.33
2024-08-02 19:32:36,186 [foster.py] => Task 21, Epoch 79/170 => Loss 3.031, Loss_clf 0.308, Loss_fe 0.156, Loss_kd 2.510, Train_accy 89.46, Test_accy 62.03
2024-08-02 19:32:41,021 [foster.py] => Task 21, Epoch 80/170 => Loss 3.033, Loss_clf 0.321, Loss_fe 0.139, Loss_kd 2.515, Train_accy 88.64, Test_accy 61.64
2024-08-02 19:32:43,817 [foster.py] => Task 21, Epoch 81/170 => Loss 3.017, Loss_clf 0.312, Loss_fe 0.160, Loss_kd 2.488, Train_accy 88.57
2024-08-02 19:32:48,635 [foster.py] => Task 21, Epoch 82/170 => Loss 3.104, Loss_clf 0.348, Loss_fe 0.151, Loss_kd 2.547, Train_accy 86.93, Test_accy 62.25
2024-08-02 19:32:53,494 [foster.py] => Task 21, Epoch 83/170 => Loss 3.052, Loss_clf 0.335, Loss_fe 0.143, Loss_kd 2.517, Train_accy 88.18, Test_accy 62.12
2024-08-02 19:32:58,326 [foster.py] => Task 21, Epoch 84/170 => Loss 3.060, Loss_clf 0.339, Loss_fe 0.131, Loss_kd 2.532, Train_accy 88.32, Test_accy 62.34
2024-08-02 19:33:03,192 [foster.py] => Task 21, Epoch 85/170 => Loss 3.070, Loss_clf 0.338, Loss_fe 0.126, Loss_kd 2.548, Train_accy 87.21, Test_accy 62.29
2024-08-02 19:33:05,992 [foster.py] => Task 21, Epoch 86/170 => Loss 3.038, Loss_clf 0.330, Loss_fe 0.126, Loss_kd 2.525, Train_accy 88.50
2024-08-02 19:33:10,863 [foster.py] => Task 21, Epoch 87/170 => Loss 3.088, Loss_clf 0.354, Loss_fe 0.146, Loss_kd 2.531, Train_accy 86.18, Test_accy 62.46
2024-08-02 19:33:15,732 [foster.py] => Task 21, Epoch 88/170 => Loss 3.015, Loss_clf 0.309, Loss_fe 0.143, Loss_kd 2.506, Train_accy 88.82, Test_accy 61.99
2024-08-02 19:33:20,603 [foster.py] => Task 21, Epoch 89/170 => Loss 3.042, Loss_clf 0.322, Loss_fe 0.127, Loss_kd 2.535, Train_accy 87.93, Test_accy 62.45
2024-08-02 19:33:25,437 [foster.py] => Task 21, Epoch 90/170 => Loss 3.041, Loss_clf 0.330, Loss_fe 0.123, Loss_kd 2.531, Train_accy 88.18, Test_accy 62.02
2024-08-02 19:33:28,281 [foster.py] => Task 21, Epoch 91/170 => Loss 3.026, Loss_clf 0.321, Loss_fe 0.132, Loss_kd 2.516, Train_accy 89.18
2024-08-02 19:33:33,118 [foster.py] => Task 21, Epoch 92/170 => Loss 3.078, Loss_clf 0.339, Loss_fe 0.126, Loss_kd 2.554, Train_accy 88.25, Test_accy 62.30
2024-08-02 19:33:37,970 [foster.py] => Task 21, Epoch 93/170 => Loss 3.050, Loss_clf 0.328, Loss_fe 0.137, Loss_kd 2.528, Train_accy 89.21, Test_accy 62.48
2024-08-02 19:33:42,931 [foster.py] => Task 21, Epoch 94/170 => Loss 3.037, Loss_clf 0.324, Loss_fe 0.115, Loss_kd 2.539, Train_accy 88.36, Test_accy 62.33
2024-08-02 19:33:47,807 [foster.py] => Task 21, Epoch 95/170 => Loss 3.062, Loss_clf 0.338, Loss_fe 0.124, Loss_kd 2.542, Train_accy 87.93, Test_accy 62.33
2024-08-02 19:33:50,605 [foster.py] => Task 21, Epoch 96/170 => Loss 3.015, Loss_clf 0.308, Loss_fe 0.121, Loss_kd 2.528, Train_accy 88.86
2024-08-02 19:33:55,454 [foster.py] => Task 21, Epoch 97/170 => Loss 3.040, Loss_clf 0.322, Loss_fe 0.128, Loss_kd 2.532, Train_accy 88.29, Test_accy 62.37
2024-08-02 19:34:00,328 [foster.py] => Task 21, Epoch 98/170 => Loss 3.021, Loss_clf 0.328, Loss_fe 0.119, Loss_kd 2.517, Train_accy 88.39, Test_accy 62.48
2024-08-02 19:34:05,168 [foster.py] => Task 21, Epoch 99/170 => Loss 3.032, Loss_clf 0.319, Loss_fe 0.137, Loss_kd 2.519, Train_accy 88.86, Test_accy 62.38
2024-08-02 19:34:10,022 [foster.py] => Task 21, Epoch 100/170 => Loss 3.016, Loss_clf 0.334, Loss_fe 0.117, Loss_kd 2.508, Train_accy 88.64, Test_accy 62.04
2024-08-02 19:34:12,814 [foster.py] => Task 21, Epoch 101/170 => Loss 3.012, Loss_clf 0.317, Loss_fe 0.122, Loss_kd 2.516, Train_accy 88.64
2024-08-02 19:34:17,735 [foster.py] => Task 21, Epoch 102/170 => Loss 3.047, Loss_clf 0.331, Loss_fe 0.132, Loss_kd 2.526, Train_accy 87.93, Test_accy 62.11
2024-08-02 19:34:22,620 [foster.py] => Task 21, Epoch 103/170 => Loss 3.022, Loss_clf 0.319, Loss_fe 0.111, Loss_kd 2.534, Train_accy 89.11, Test_accy 62.16
2024-08-02 19:34:27,482 [foster.py] => Task 21, Epoch 104/170 => Loss 3.024, Loss_clf 0.315, Loss_fe 0.115, Loss_kd 2.536, Train_accy 88.57, Test_accy 62.48
2024-08-02 19:34:32,359 [foster.py] => Task 21, Epoch 105/170 => Loss 3.003, Loss_clf 0.309, Loss_fe 0.118, Loss_kd 2.519, Train_accy 89.29, Test_accy 62.48
2024-08-02 19:34:35,152 [foster.py] => Task 21, Epoch 106/170 => Loss 3.064, Loss_clf 0.340, Loss_fe 0.118, Loss_kd 2.548, Train_accy 87.25
2024-08-02 19:34:40,005 [foster.py] => Task 21, Epoch 107/170 => Loss 3.010, Loss_clf 0.311, Loss_fe 0.121, Loss_kd 2.521, Train_accy 89.18, Test_accy 62.27
2024-08-02 19:34:44,940 [foster.py] => Task 21, Epoch 108/170 => Loss 2.924, Loss_clf 0.285, Loss_fe 0.095, Loss_kd 2.487, Train_accy 90.29, Test_accy 62.41
2024-08-02 19:34:49,912 [foster.py] => Task 21, Epoch 109/170 => Loss 2.986, Loss_clf 0.310, Loss_fe 0.098, Loss_kd 2.520, Train_accy 89.14, Test_accy 62.37
2024-08-02 19:34:54,866 [foster.py] => Task 21, Epoch 110/170 => Loss 2.997, Loss_clf 0.311, Loss_fe 0.107, Loss_kd 2.521, Train_accy 88.54, Test_accy 62.45
2024-08-02 19:34:57,737 [foster.py] => Task 21, Epoch 111/170 => Loss 2.983, Loss_clf 0.310, Loss_fe 0.099, Loss_kd 2.517, Train_accy 88.93
2024-08-02 19:35:02,568 [foster.py] => Task 21, Epoch 112/170 => Loss 2.999, Loss_clf 0.304, Loss_fe 0.103, Loss_kd 2.534, Train_accy 89.54, Test_accy 62.40
2024-08-02 19:35:07,440 [foster.py] => Task 21, Epoch 113/170 => Loss 3.025, Loss_clf 0.341, Loss_fe 0.102, Loss_kd 2.524, Train_accy 88.07, Test_accy 62.30
2024-08-02 19:35:12,259 [foster.py] => Task 21, Epoch 114/170 => Loss 2.957, Loss_clf 0.296, Loss_fe 0.094, Loss_kd 2.509, Train_accy 89.57, Test_accy 62.46
2024-08-02 19:35:17,152 [foster.py] => Task 21, Epoch 115/170 => Loss 2.979, Loss_clf 0.305, Loss_fe 0.085, Loss_kd 2.530, Train_accy 89.21, Test_accy 62.30
2024-08-02 19:35:19,961 [foster.py] => Task 21, Epoch 116/170 => Loss 2.993, Loss_clf 0.309, Loss_fe 0.107, Loss_kd 2.519, Train_accy 89.32
2024-08-02 19:35:24,790 [foster.py] => Task 21, Epoch 117/170 => Loss 2.999, Loss_clf 0.320, Loss_fe 0.092, Loss_kd 2.530, Train_accy 88.54, Test_accy 62.27
2024-08-02 19:35:29,648 [foster.py] => Task 21, Epoch 118/170 => Loss 3.019, Loss_clf 0.327, Loss_fe 0.104, Loss_kd 2.530, Train_accy 88.96, Test_accy 62.25
2024-08-02 19:35:34,492 [foster.py] => Task 21, Epoch 119/170 => Loss 2.984, Loss_clf 0.316, Loss_fe 0.095, Loss_kd 2.516, Train_accy 89.00, Test_accy 62.39
2024-08-02 19:35:39,360 [foster.py] => Task 21, Epoch 120/170 => Loss 2.927, Loss_clf 0.295, Loss_fe 0.094, Loss_kd 2.482, Train_accy 89.50, Test_accy 62.34
2024-08-02 19:35:42,167 [foster.py] => Task 21, Epoch 121/170 => Loss 2.993, Loss_clf 0.307, Loss_fe 0.101, Loss_kd 2.527, Train_accy 89.68
2024-08-02 19:35:47,037 [foster.py] => Task 21, Epoch 122/170 => Loss 2.950, Loss_clf 0.287, Loss_fe 0.091, Loss_kd 2.514, Train_accy 90.04, Test_accy 62.37
2024-08-02 19:35:51,922 [foster.py] => Task 21, Epoch 123/170 => Loss 3.010, Loss_clf 0.316, Loss_fe 0.108, Loss_kd 2.529, Train_accy 89.25, Test_accy 62.54
2024-08-02 19:35:56,719 [foster.py] => Task 21, Epoch 124/170 => Loss 3.064, Loss_clf 0.341, Loss_fe 0.099, Loss_kd 2.566, Train_accy 88.43, Test_accy 62.61
2024-08-02 19:36:01,604 [foster.py] => Task 21, Epoch 125/170 => Loss 2.955, Loss_clf 0.286, Loss_fe 0.093, Loss_kd 2.518, Train_accy 90.07, Test_accy 62.63
2024-08-02 19:36:04,393 [foster.py] => Task 21, Epoch 126/170 => Loss 2.977, Loss_clf 0.304, Loss_fe 0.096, Loss_kd 2.520, Train_accy 89.89
2024-08-02 19:36:09,231 [foster.py] => Task 21, Epoch 127/170 => Loss 2.993, Loss_clf 0.307, Loss_fe 0.090, Loss_kd 2.538, Train_accy 89.79, Test_accy 62.49
2024-08-02 19:36:14,074 [foster.py] => Task 21, Epoch 128/170 => Loss 2.993, Loss_clf 0.309, Loss_fe 0.089, Loss_kd 2.538, Train_accy 89.21, Test_accy 62.58
2024-08-02 19:36:18,930 [foster.py] => Task 21, Epoch 129/170 => Loss 2.974, Loss_clf 0.300, Loss_fe 0.088, Loss_kd 2.528, Train_accy 89.61, Test_accy 62.50
2024-08-02 19:36:23,892 [foster.py] => Task 21, Epoch 130/170 => Loss 3.012, Loss_clf 0.315, Loss_fe 0.098, Loss_kd 2.541, Train_accy 89.04, Test_accy 62.48
2024-08-02 19:36:26,671 [foster.py] => Task 21, Epoch 131/170 => Loss 3.010, Loss_clf 0.312, Loss_fe 0.091, Loss_kd 2.549, Train_accy 89.18
2024-08-02 19:36:31,502 [foster.py] => Task 21, Epoch 132/170 => Loss 3.037, Loss_clf 0.332, Loss_fe 0.083, Loss_kd 2.564, Train_accy 88.82, Test_accy 62.66
2024-08-02 19:36:36,358 [foster.py] => Task 21, Epoch 133/170 => Loss 2.958, Loss_clf 0.291, Loss_fe 0.077, Loss_kd 2.533, Train_accy 90.04, Test_accy 62.58
2024-08-02 19:36:41,169 [foster.py] => Task 21, Epoch 134/170 => Loss 2.935, Loss_clf 0.290, Loss_fe 0.087, Loss_kd 2.501, Train_accy 89.79, Test_accy 62.62
2024-08-02 19:36:46,048 [foster.py] => Task 21, Epoch 135/170 => Loss 2.975, Loss_clf 0.293, Loss_fe 0.093, Loss_kd 2.531, Train_accy 89.68, Test_accy 62.64
2024-08-02 19:36:48,838 [foster.py] => Task 21, Epoch 136/170 => Loss 2.965, Loss_clf 0.310, Loss_fe 0.084, Loss_kd 2.514, Train_accy 89.75
2024-08-02 19:36:53,658 [foster.py] => Task 21, Epoch 137/170 => Loss 2.997, Loss_clf 0.309, Loss_fe 0.089, Loss_kd 2.541, Train_accy 89.36, Test_accy 62.66
2024-08-02 19:36:58,528 [foster.py] => Task 21, Epoch 138/170 => Loss 2.969, Loss_clf 0.296, Loss_fe 0.094, Loss_kd 2.520, Train_accy 90.00, Test_accy 62.76
2024-08-02 19:37:03,444 [foster.py] => Task 21, Epoch 139/170 => Loss 2.965, Loss_clf 0.291, Loss_fe 0.079, Loss_kd 2.537, Train_accy 90.11, Test_accy 62.70
2024-08-02 19:37:08,389 [foster.py] => Task 21, Epoch 140/170 => Loss 2.951, Loss_clf 0.291, Loss_fe 0.087, Loss_kd 2.515, Train_accy 90.46, Test_accy 62.65
2024-08-02 19:37:11,276 [foster.py] => Task 21, Epoch 141/170 => Loss 2.969, Loss_clf 0.290, Loss_fe 0.086, Loss_kd 2.535, Train_accy 90.32
2024-08-02 19:37:16,253 [foster.py] => Task 21, Epoch 142/170 => Loss 2.966, Loss_clf 0.293, Loss_fe 0.079, Loss_kd 2.535, Train_accy 90.61, Test_accy 62.80
2024-08-02 19:37:21,155 [foster.py] => Task 21, Epoch 143/170 => Loss 2.980, Loss_clf 0.300, Loss_fe 0.090, Loss_kd 2.532, Train_accy 90.00, Test_accy 62.77
2024-08-02 19:37:26,179 [foster.py] => Task 21, Epoch 144/170 => Loss 2.946, Loss_clf 0.287, Loss_fe 0.075, Loss_kd 2.526, Train_accy 90.29, Test_accy 62.77
2024-08-02 19:37:31,089 [foster.py] => Task 21, Epoch 145/170 => Loss 2.941, Loss_clf 0.298, Loss_fe 0.083, Loss_kd 2.503, Train_accy 89.71, Test_accy 62.73
2024-08-02 19:37:33,877 [foster.py] => Task 21, Epoch 146/170 => Loss 2.983, Loss_clf 0.314, Loss_fe 0.080, Loss_kd 2.530, Train_accy 89.86
2024-08-02 19:37:38,717 [foster.py] => Task 21, Epoch 147/170 => Loss 2.956, Loss_clf 0.295, Loss_fe 0.080, Loss_kd 2.524, Train_accy 90.43, Test_accy 62.75
2024-08-02 19:37:43,588 [foster.py] => Task 21, Epoch 148/170 => Loss 2.924, Loss_clf 0.293, Loss_fe 0.077, Loss_kd 2.496, Train_accy 89.54, Test_accy 62.73
2024-08-02 19:37:48,404 [foster.py] => Task 21, Epoch 149/170 => Loss 2.939, Loss_clf 0.299, Loss_fe 0.077, Loss_kd 2.505, Train_accy 89.89, Test_accy 62.74
2024-08-02 19:37:53,380 [foster.py] => Task 21, Epoch 150/170 => Loss 2.983, Loss_clf 0.310, Loss_fe 0.083, Loss_kd 2.532, Train_accy 89.29, Test_accy 62.74
2024-08-02 19:37:56,165 [foster.py] => Task 21, Epoch 151/170 => Loss 2.984, Loss_clf 0.315, Loss_fe 0.085, Loss_kd 2.526, Train_accy 89.36
2024-08-02 19:38:01,053 [foster.py] => Task 21, Epoch 152/170 => Loss 2.977, Loss_clf 0.293, Loss_fe 0.080, Loss_kd 2.546, Train_accy 90.61, Test_accy 62.70
2024-08-02 19:38:05,926 [foster.py] => Task 21, Epoch 153/170 => Loss 2.934, Loss_clf 0.293, Loss_fe 0.080, Loss_kd 2.504, Train_accy 89.96, Test_accy 62.71
2024-08-02 19:38:10,779 [foster.py] => Task 21, Epoch 154/170 => Loss 2.961, Loss_clf 0.290, Loss_fe 0.076, Loss_kd 2.537, Train_accy 89.54, Test_accy 62.73
2024-08-02 19:38:15,764 [foster.py] => Task 21, Epoch 155/170 => Loss 2.934, Loss_clf 0.281, Loss_fe 0.079, Loss_kd 2.515, Train_accy 89.96, Test_accy 62.73
2024-08-02 19:38:18,570 [foster.py] => Task 21, Epoch 156/170 => Loss 2.974, Loss_clf 0.304, Loss_fe 0.084, Loss_kd 2.527, Train_accy 89.32
2024-08-02 19:38:23,410 [foster.py] => Task 21, Epoch 157/170 => Loss 2.962, Loss_clf 0.301, Loss_fe 0.080, Loss_kd 2.523, Train_accy 90.00, Test_accy 62.68
2024-08-02 19:38:28,274 [foster.py] => Task 21, Epoch 158/170 => Loss 2.989, Loss_clf 0.304, Loss_fe 0.084, Loss_kd 2.543, Train_accy 89.61, Test_accy 62.72
2024-08-02 19:38:33,108 [foster.py] => Task 21, Epoch 159/170 => Loss 3.009, Loss_clf 0.325, Loss_fe 0.082, Loss_kd 2.543, Train_accy 88.54, Test_accy 62.72
2024-08-02 19:38:37,960 [foster.py] => Task 21, Epoch 160/170 => Loss 2.946, Loss_clf 0.283, Loss_fe 0.094, Loss_kd 2.512, Train_accy 89.93, Test_accy 62.68
2024-08-02 19:38:40,738 [foster.py] => Task 21, Epoch 161/170 => Loss 2.982, Loss_clf 0.303, Loss_fe 0.079, Loss_kd 2.542, Train_accy 90.14
2024-08-02 19:38:45,590 [foster.py] => Task 21, Epoch 162/170 => Loss 2.989, Loss_clf 0.308, Loss_fe 0.086, Loss_kd 2.536, Train_accy 89.61, Test_accy 62.75
2024-08-02 19:38:50,434 [foster.py] => Task 21, Epoch 163/170 => Loss 2.930, Loss_clf 0.298, Loss_fe 0.078, Loss_kd 2.496, Train_accy 89.18, Test_accy 62.73
2024-08-02 19:38:55,337 [foster.py] => Task 21, Epoch 164/170 => Loss 2.981, Loss_clf 0.300, Loss_fe 0.080, Loss_kd 2.543, Train_accy 90.04, Test_accy 62.66
2024-08-02 19:39:00,198 [foster.py] => Task 21, Epoch 165/170 => Loss 2.970, Loss_clf 0.310, Loss_fe 0.081, Loss_kd 2.521, Train_accy 89.11, Test_accy 62.74
2024-08-02 19:39:02,989 [foster.py] => Task 21, Epoch 166/170 => Loss 2.982, Loss_clf 0.306, Loss_fe 0.077, Loss_kd 2.542, Train_accy 89.93
2024-08-02 19:39:07,812 [foster.py] => Task 21, Epoch 167/170 => Loss 2.957, Loss_clf 0.289, Loss_fe 0.083, Loss_kd 2.527, Train_accy 90.82, Test_accy 62.75
2024-08-02 19:39:12,690 [foster.py] => Task 21, Epoch 168/170 => Loss 2.991, Loss_clf 0.311, Loss_fe 0.093, Loss_kd 2.529, Train_accy 89.14, Test_accy 62.71
2024-08-02 19:39:17,577 [foster.py] => Task 21, Epoch 169/170 => Loss 2.961, Loss_clf 0.305, Loss_fe 0.081, Loss_kd 2.517, Train_accy 89.43, Test_accy 62.73
2024-08-02 19:39:22,434 [foster.py] => Task 21, Epoch 170/170 => Loss 2.948, Loss_clf 0.295, Loss_fe 0.070, Loss_kd 2.525, Train_accy 89.93, Test_accy 62.75
2024-08-02 19:39:22,436 [foster.py] => do not weight align teacher!
2024-08-02 19:39:22,438 [foster.py] => per cls weights : [1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564 1.01180564
 0.46874632 0.46874632]
2024-08-02 19:39:27,816 [foster.py] => SNet: Task 21, Epoch 1/130 => Loss 30.813,  Loss1 0.785, Train_accy 59.18, Test_accy 56.86
2024-08-02 19:39:31,715 [foster.py] => SNet: Task 21, Epoch 2/130 => Loss 30.705,  Loss1 0.786, Train_accy 72.25
2024-08-02 19:39:35,615 [foster.py] => SNet: Task 21, Epoch 3/130 => Loss 30.736,  Loss1 0.785, Train_accy 71.00
2024-08-02 19:39:39,533 [foster.py] => SNet: Task 21, Epoch 4/130 => Loss 30.646,  Loss1 0.785, Train_accy 71.82
2024-08-02 19:39:43,412 [foster.py] => SNet: Task 21, Epoch 5/130 => Loss 30.673,  Loss1 0.785, Train_accy 74.11
2024-08-02 19:39:48,595 [foster.py] => SNet: Task 21, Epoch 6/130 => Loss 30.648,  Loss1 0.786, Train_accy 74.04, Test_accy 60.87
2024-08-02 19:39:52,490 [foster.py] => SNet: Task 21, Epoch 7/130 => Loss 30.656,  Loss1 0.785, Train_accy 75.93
2024-08-02 19:39:56,380 [foster.py] => SNet: Task 21, Epoch 8/130 => Loss 30.628,  Loss1 0.785, Train_accy 75.50
2024-08-02 19:40:00,293 [foster.py] => SNet: Task 21, Epoch 9/130 => Loss 30.669,  Loss1 0.785, Train_accy 74.82
2024-08-02 19:40:04,201 [foster.py] => SNet: Task 21, Epoch 10/130 => Loss 30.650,  Loss1 0.785, Train_accy 74.89
2024-08-02 19:40:09,377 [foster.py] => SNet: Task 21, Epoch 11/130 => Loss 30.581,  Loss1 0.786, Train_accy 77.39, Test_accy 61.15
2024-08-02 19:40:13,349 [foster.py] => SNet: Task 21, Epoch 12/130 => Loss 30.621,  Loss1 0.785, Train_accy 77.46
2024-08-02 19:40:17,290 [foster.py] => SNet: Task 21, Epoch 13/130 => Loss 30.667,  Loss1 0.785, Train_accy 76.29
2024-08-02 19:40:21,206 [foster.py] => SNet: Task 21, Epoch 14/130 => Loss 30.670,  Loss1 0.786, Train_accy 75.36
2024-08-02 19:40:25,070 [foster.py] => SNet: Task 21, Epoch 15/130 => Loss 30.690,  Loss1 0.785, Train_accy 76.75
2024-08-02 19:40:30,233 [foster.py] => SNet: Task 21, Epoch 16/130 => Loss 30.664,  Loss1 0.786, Train_accy 77.18, Test_accy 60.96
2024-08-02 19:40:34,123 [foster.py] => SNet: Task 21, Epoch 17/130 => Loss 30.691,  Loss1 0.786, Train_accy 77.71
2024-08-02 19:40:38,023 [foster.py] => SNet: Task 21, Epoch 18/130 => Loss 30.662,  Loss1 0.785, Train_accy 77.00
2024-08-02 19:40:41,937 [foster.py] => SNet: Task 21, Epoch 19/130 => Loss 30.650,  Loss1 0.785, Train_accy 77.61
2024-08-02 19:40:45,853 [foster.py] => SNet: Task 21, Epoch 20/130 => Loss 30.648,  Loss1 0.785, Train_accy 78.00
2024-08-02 19:40:51,047 [foster.py] => SNet: Task 21, Epoch 21/130 => Loss 30.660,  Loss1 0.785, Train_accy 77.43, Test_accy 61.29
2024-08-02 19:40:54,957 [foster.py] => SNet: Task 21, Epoch 22/130 => Loss 30.616,  Loss1 0.786, Train_accy 76.96
2024-08-02 19:40:58,861 [foster.py] => SNet: Task 21, Epoch 23/130 => Loss 30.661,  Loss1 0.785, Train_accy 77.86
2024-08-02 19:41:02,792 [foster.py] => SNet: Task 21, Epoch 24/130 => Loss 30.678,  Loss1 0.786, Train_accy 77.43
2024-08-02 19:41:06,742 [foster.py] => SNet: Task 21, Epoch 25/130 => Loss 30.651,  Loss1 0.785, Train_accy 77.50
2024-08-02 19:41:11,927 [foster.py] => SNet: Task 21, Epoch 26/130 => Loss 30.630,  Loss1 0.786, Train_accy 77.96, Test_accy 61.51
2024-08-02 19:41:15,843 [foster.py] => SNet: Task 21, Epoch 27/130 => Loss 30.629,  Loss1 0.786, Train_accy 76.71
2024-08-02 19:41:19,792 [foster.py] => SNet: Task 21, Epoch 28/130 => Loss 30.653,  Loss1 0.786, Train_accy 77.36
2024-08-02 19:41:23,748 [foster.py] => SNet: Task 21, Epoch 29/130 => Loss 30.687,  Loss1 0.786, Train_accy 77.21
2024-08-02 19:41:27,653 [foster.py] => SNet: Task 21, Epoch 30/130 => Loss 30.683,  Loss1 0.785, Train_accy 77.93
2024-08-02 19:41:32,884 [foster.py] => SNet: Task 21, Epoch 31/130 => Loss 30.648,  Loss1 0.786, Train_accy 79.00, Test_accy 61.05
2024-08-02 19:41:36,778 [foster.py] => SNet: Task 21, Epoch 32/130 => Loss 30.653,  Loss1 0.786, Train_accy 79.21
2024-08-02 19:41:40,651 [foster.py] => SNet: Task 21, Epoch 33/130 => Loss 30.676,  Loss1 0.785, Train_accy 77.64
2024-08-02 19:41:44,558 [foster.py] => SNet: Task 21, Epoch 34/130 => Loss 30.612,  Loss1 0.786, Train_accy 78.54
2024-08-02 19:41:48,437 [foster.py] => SNet: Task 21, Epoch 35/130 => Loss 30.629,  Loss1 0.785, Train_accy 79.61
2024-08-02 19:41:53,636 [foster.py] => SNet: Task 21, Epoch 36/130 => Loss 30.655,  Loss1 0.786, Train_accy 79.29, Test_accy 61.29
2024-08-02 19:41:57,560 [foster.py] => SNet: Task 21, Epoch 37/130 => Loss 30.679,  Loss1 0.785, Train_accy 79.21
2024-08-02 19:42:01,452 [foster.py] => SNet: Task 21, Epoch 38/130 => Loss 30.674,  Loss1 0.786, Train_accy 78.64
2024-08-02 19:42:05,348 [foster.py] => SNet: Task 21, Epoch 39/130 => Loss 30.629,  Loss1 0.786, Train_accy 78.64
2024-08-02 19:42:09,250 [foster.py] => SNet: Task 21, Epoch 40/130 => Loss 30.634,  Loss1 0.785, Train_accy 78.07
2024-08-02 19:42:14,409 [foster.py] => SNet: Task 21, Epoch 41/130 => Loss 30.653,  Loss1 0.786, Train_accy 79.07, Test_accy 61.16
2024-08-02 19:42:18,292 [foster.py] => SNet: Task 21, Epoch 42/130 => Loss 30.659,  Loss1 0.786, Train_accy 78.04
2024-08-02 19:42:22,163 [foster.py] => SNet: Task 21, Epoch 43/130 => Loss 30.627,  Loss1 0.786, Train_accy 79.18
2024-08-02 19:42:26,099 [foster.py] => SNet: Task 21, Epoch 44/130 => Loss 30.647,  Loss1 0.786, Train_accy 78.50
2024-08-02 19:42:30,012 [foster.py] => SNet: Task 21, Epoch 45/130 => Loss 30.625,  Loss1 0.786, Train_accy 78.82
2024-08-02 19:42:35,191 [foster.py] => SNet: Task 21, Epoch 46/130 => Loss 30.707,  Loss1 0.785, Train_accy 77.89, Test_accy 60.63
2024-08-02 19:42:39,125 [foster.py] => SNet: Task 21, Epoch 47/130 => Loss 30.589,  Loss1 0.786, Train_accy 79.29
2024-08-02 19:42:43,042 [foster.py] => SNet: Task 21, Epoch 48/130 => Loss 30.638,  Loss1 0.785, Train_accy 79.04
2024-08-02 19:42:46,945 [foster.py] => SNet: Task 21, Epoch 49/130 => Loss 30.647,  Loss1 0.786, Train_accy 80.04
2024-08-02 19:42:50,830 [foster.py] => SNet: Task 21, Epoch 50/130 => Loss 30.647,  Loss1 0.786, Train_accy 80.43
2024-08-02 19:42:56,044 [foster.py] => SNet: Task 21, Epoch 51/130 => Loss 30.616,  Loss1 0.786, Train_accy 80.00, Test_accy 61.46
2024-08-02 19:42:59,947 [foster.py] => SNet: Task 21, Epoch 52/130 => Loss 30.653,  Loss1 0.785, Train_accy 79.07
2024-08-02 19:43:03,847 [foster.py] => SNet: Task 21, Epoch 53/130 => Loss 30.634,  Loss1 0.786, Train_accy 80.00
2024-08-02 19:43:07,795 [foster.py] => SNet: Task 21, Epoch 54/130 => Loss 30.673,  Loss1 0.786, Train_accy 78.75
2024-08-02 19:43:11,760 [foster.py] => SNet: Task 21, Epoch 55/130 => Loss 30.599,  Loss1 0.786, Train_accy 78.39
2024-08-02 19:43:16,949 [foster.py] => SNet: Task 21, Epoch 56/130 => Loss 30.681,  Loss1 0.785, Train_accy 77.93, Test_accy 61.21
2024-08-02 19:43:20,851 [foster.py] => SNet: Task 21, Epoch 57/130 => Loss 30.630,  Loss1 0.786, Train_accy 79.43
2024-08-02 19:43:24,758 [foster.py] => SNet: Task 21, Epoch 58/130 => Loss 30.616,  Loss1 0.786, Train_accy 79.96
2024-08-02 19:43:28,629 [foster.py] => SNet: Task 21, Epoch 59/130 => Loss 30.706,  Loss1 0.785, Train_accy 79.61
2024-08-02 19:43:32,561 [foster.py] => SNet: Task 21, Epoch 60/130 => Loss 30.612,  Loss1 0.786, Train_accy 79.64
2024-08-02 19:43:37,779 [foster.py] => SNet: Task 21, Epoch 61/130 => Loss 30.677,  Loss1 0.786, Train_accy 79.32, Test_accy 61.68
2024-08-02 19:43:41,681 [foster.py] => SNet: Task 21, Epoch 62/130 => Loss 30.652,  Loss1 0.786, Train_accy 78.57
2024-08-02 19:43:45,572 [foster.py] => SNet: Task 21, Epoch 63/130 => Loss 30.656,  Loss1 0.786, Train_accy 80.29
2024-08-02 19:43:49,521 [foster.py] => SNet: Task 21, Epoch 64/130 => Loss 30.597,  Loss1 0.786, Train_accy 80.32
2024-08-02 19:43:53,415 [foster.py] => SNet: Task 21, Epoch 65/130 => Loss 30.600,  Loss1 0.786, Train_accy 80.00
2024-08-02 19:43:58,571 [foster.py] => SNet: Task 21, Epoch 66/130 => Loss 30.671,  Loss1 0.785, Train_accy 79.79, Test_accy 61.26
2024-08-02 19:44:02,474 [foster.py] => SNet: Task 21, Epoch 67/130 => Loss 30.674,  Loss1 0.786, Train_accy 78.32
2024-08-02 19:44:06,386 [foster.py] => SNet: Task 21, Epoch 68/130 => Loss 30.622,  Loss1 0.786, Train_accy 81.25
2024-08-02 19:44:10,268 [foster.py] => SNet: Task 21, Epoch 69/130 => Loss 30.622,  Loss1 0.786, Train_accy 80.14
2024-08-02 19:44:14,171 [foster.py] => SNet: Task 21, Epoch 70/130 => Loss 30.655,  Loss1 0.786, Train_accy 78.96
2024-08-02 19:44:19,371 [foster.py] => SNet: Task 21, Epoch 71/130 => Loss 30.590,  Loss1 0.786, Train_accy 79.11, Test_accy 61.38
2024-08-02 19:44:23,305 [foster.py] => SNet: Task 21, Epoch 72/130 => Loss 30.613,  Loss1 0.786, Train_accy 79.39
2024-08-02 19:44:27,176 [foster.py] => SNet: Task 21, Epoch 73/130 => Loss 30.652,  Loss1 0.786, Train_accy 80.61
2024-08-02 19:44:31,068 [foster.py] => SNet: Task 21, Epoch 74/130 => Loss 30.660,  Loss1 0.786, Train_accy 80.07
2024-08-02 19:44:34,989 [foster.py] => SNet: Task 21, Epoch 75/130 => Loss 30.597,  Loss1 0.786, Train_accy 80.00
2024-08-02 19:44:40,233 [foster.py] => SNet: Task 21, Epoch 76/130 => Loss 30.654,  Loss1 0.786, Train_accy 80.14, Test_accy 61.64
2024-08-02 19:44:44,119 [foster.py] => SNet: Task 21, Epoch 77/130 => Loss 30.650,  Loss1 0.786, Train_accy 80.11
2024-08-02 19:44:48,001 [foster.py] => SNet: Task 21, Epoch 78/130 => Loss 30.623,  Loss1 0.786, Train_accy 80.64
2024-08-02 19:44:51,891 [foster.py] => SNet: Task 21, Epoch 79/130 => Loss 30.680,  Loss1 0.786, Train_accy 80.07
2024-08-02 19:44:55,774 [foster.py] => SNet: Task 21, Epoch 80/130 => Loss 30.687,  Loss1 0.786, Train_accy 79.79
2024-08-02 19:45:00,997 [foster.py] => SNet: Task 21, Epoch 81/130 => Loss 30.693,  Loss1 0.786, Train_accy 79.96, Test_accy 61.74
2024-08-02 19:45:04,914 [foster.py] => SNet: Task 21, Epoch 82/130 => Loss 30.608,  Loss1 0.786, Train_accy 80.82
2024-08-02 19:45:08,799 [foster.py] => SNet: Task 21, Epoch 83/130 => Loss 30.618,  Loss1 0.786, Train_accy 80.82
2024-08-02 19:45:12,676 [foster.py] => SNet: Task 21, Epoch 84/130 => Loss 30.644,  Loss1 0.786, Train_accy 79.46
2024-08-02 19:45:16,594 [foster.py] => SNet: Task 21, Epoch 85/130 => Loss 30.694,  Loss1 0.786, Train_accy 79.89
2024-08-02 19:45:21,765 [foster.py] => SNet: Task 21, Epoch 86/130 => Loss 30.606,  Loss1 0.786, Train_accy 79.50, Test_accy 61.58
2024-08-02 19:45:25,662 [foster.py] => SNet: Task 21, Epoch 87/130 => Loss 30.638,  Loss1 0.785, Train_accy 78.46
2024-08-02 19:45:29,560 [foster.py] => SNet: Task 21, Epoch 88/130 => Loss 30.643,  Loss1 0.785, Train_accy 79.61
2024-08-02 19:45:33,467 [foster.py] => SNet: Task 21, Epoch 89/130 => Loss 30.661,  Loss1 0.786, Train_accy 79.71
2024-08-02 19:45:37,397 [foster.py] => SNet: Task 21, Epoch 90/130 => Loss 30.643,  Loss1 0.786, Train_accy 79.46
2024-08-02 19:45:42,554 [foster.py] => SNet: Task 21, Epoch 91/130 => Loss 30.593,  Loss1 0.786, Train_accy 81.43, Test_accy 61.61
2024-08-02 19:45:46,453 [foster.py] => SNet: Task 21, Epoch 92/130 => Loss 30.655,  Loss1 0.786, Train_accy 79.43
2024-08-02 19:45:50,369 [foster.py] => SNet: Task 21, Epoch 93/130 => Loss 30.615,  Loss1 0.786, Train_accy 80.21
2024-08-02 19:45:54,282 [foster.py] => SNet: Task 21, Epoch 94/130 => Loss 30.671,  Loss1 0.786, Train_accy 79.32
2024-08-02 19:45:58,182 [foster.py] => SNet: Task 21, Epoch 95/130 => Loss 30.679,  Loss1 0.786, Train_accy 80.32
2024-08-02 19:46:03,355 [foster.py] => SNet: Task 21, Epoch 96/130 => Loss 30.668,  Loss1 0.786, Train_accy 79.18, Test_accy 61.51
2024-08-02 19:46:07,254 [foster.py] => SNet: Task 21, Epoch 97/130 => Loss 30.675,  Loss1 0.786, Train_accy 80.18
2024-08-02 19:46:11,209 [foster.py] => SNet: Task 21, Epoch 98/130 => Loss 30.634,  Loss1 0.785, Train_accy 80.04
2024-08-02 19:46:15,093 [foster.py] => SNet: Task 21, Epoch 99/130 => Loss 30.647,  Loss1 0.786, Train_accy 80.18
2024-08-02 19:46:19,001 [foster.py] => SNet: Task 21, Epoch 100/130 => Loss 30.630,  Loss1 0.785, Train_accy 78.82
2024-08-02 19:46:24,168 [foster.py] => SNet: Task 21, Epoch 101/130 => Loss 30.626,  Loss1 0.786, Train_accy 79.96, Test_accy 61.32
2024-08-02 19:46:28,070 [foster.py] => SNet: Task 21, Epoch 102/130 => Loss 30.669,  Loss1 0.786, Train_accy 80.43
2024-08-02 19:46:31,947 [foster.py] => SNet: Task 21, Epoch 103/130 => Loss 30.636,  Loss1 0.785, Train_accy 79.39
2024-08-02 19:46:35,866 [foster.py] => SNet: Task 21, Epoch 104/130 => Loss 30.639,  Loss1 0.786, Train_accy 80.68
2024-08-02 19:46:39,746 [foster.py] => SNet: Task 21, Epoch 105/130 => Loss 30.672,  Loss1 0.786, Train_accy 81.07
2024-08-02 19:46:44,912 [foster.py] => SNet: Task 21, Epoch 106/130 => Loss 30.657,  Loss1 0.786, Train_accy 79.29, Test_accy 61.60
2024-08-02 19:46:48,838 [foster.py] => SNet: Task 21, Epoch 107/130 => Loss 30.639,  Loss1 0.786, Train_accy 80.57
2024-08-02 19:46:52,739 [foster.py] => SNet: Task 21, Epoch 108/130 => Loss 30.645,  Loss1 0.786, Train_accy 81.18
2024-08-02 19:46:56,651 [foster.py] => SNet: Task 21, Epoch 109/130 => Loss 30.635,  Loss1 0.785, Train_accy 81.86
2024-08-02 19:47:00,605 [foster.py] => SNet: Task 21, Epoch 110/130 => Loss 30.657,  Loss1 0.785, Train_accy 80.11
2024-08-02 19:47:05,791 [foster.py] => SNet: Task 21, Epoch 111/130 => Loss 30.575,  Loss1 0.786, Train_accy 80.82, Test_accy 61.52
2024-08-02 19:47:09,689 [foster.py] => SNet: Task 21, Epoch 112/130 => Loss 30.607,  Loss1 0.786, Train_accy 80.07
2024-08-02 19:47:13,580 [foster.py] => SNet: Task 21, Epoch 113/130 => Loss 30.654,  Loss1 0.785, Train_accy 80.79
2024-08-02 19:47:17,492 [foster.py] => SNet: Task 21, Epoch 114/130 => Loss 30.627,  Loss1 0.785, Train_accy 80.68
2024-08-02 19:47:21,457 [foster.py] => SNet: Task 21, Epoch 115/130 => Loss 30.625,  Loss1 0.786, Train_accy 79.82
2024-08-02 19:47:26,678 [foster.py] => SNet: Task 21, Epoch 116/130 => Loss 30.618,  Loss1 0.785, Train_accy 80.36, Test_accy 61.50
2024-08-02 19:47:30,595 [foster.py] => SNet: Task 21, Epoch 117/130 => Loss 30.615,  Loss1 0.785, Train_accy 79.50
2024-08-02 19:47:34,494 [foster.py] => SNet: Task 21, Epoch 118/130 => Loss 30.644,  Loss1 0.787, Train_accy 80.32
2024-08-02 19:47:38,396 [foster.py] => SNet: Task 21, Epoch 119/130 => Loss 30.613,  Loss1 0.786, Train_accy 80.86
2024-08-02 19:47:42,317 [foster.py] => SNet: Task 21, Epoch 120/130 => Loss 30.619,  Loss1 0.786, Train_accy 80.29
2024-08-02 19:47:47,540 [foster.py] => SNet: Task 21, Epoch 121/130 => Loss 30.631,  Loss1 0.786, Train_accy 80.93, Test_accy 61.53
2024-08-02 19:47:51,442 [foster.py] => SNet: Task 21, Epoch 122/130 => Loss 30.697,  Loss1 0.786, Train_accy 80.64
2024-08-02 19:47:55,358 [foster.py] => SNet: Task 21, Epoch 123/130 => Loss 30.638,  Loss1 0.786, Train_accy 79.68
2024-08-02 19:47:59,244 [foster.py] => SNet: Task 21, Epoch 124/130 => Loss 30.667,  Loss1 0.786, Train_accy 79.50
2024-08-02 19:48:03,159 [foster.py] => SNet: Task 21, Epoch 125/130 => Loss 30.633,  Loss1 0.786, Train_accy 79.96
2024-08-02 19:48:08,363 [foster.py] => SNet: Task 21, Epoch 126/130 => Loss 30.645,  Loss1 0.785, Train_accy 79.64, Test_accy 61.72
2024-08-02 19:48:12,242 [foster.py] => SNet: Task 21, Epoch 127/130 => Loss 30.622,  Loss1 0.786, Train_accy 80.29
2024-08-02 19:48:16,164 [foster.py] => SNet: Task 21, Epoch 128/130 => Loss 30.663,  Loss1 0.787, Train_accy 80.68
2024-08-02 19:48:20,058 [foster.py] => SNet: Task 21, Epoch 129/130 => Loss 30.648,  Loss1 0.786, Train_accy 80.68
2024-08-02 19:48:23,931 [foster.py] => SNet: Task 21, Epoch 130/130 => Loss 30.635,  Loss1 0.786, Train_accy 79.96
2024-08-02 19:48:23,932 [foster.py] => do not weight align student!
2024-08-02 19:48:25,215 [foster.py] => darknet eval: 
2024-08-02 19:48:25,216 [foster.py] => CNN top1 curve: 61.41
2024-08-02 19:48:25,216 [foster.py] => CNN top5 curve: 85.73
2024-08-02 19:48:25,216 [foster.py] => CNN top1 平均值: 61.41
2024-08-02 19:48:25,220 [foster.py] => timees : 1300.7239470481873
2024-08-02 19:48:25,221 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 19:48:53,191 [foster.py] => Exemplar size: 1840
2024-08-02 19:48:53,191 [trainer.py] => CNN: {'total': 62.75, '00-09': 69.7, '10-19': 50.1, '20-29': 67.6, '30-39': 60.7, '40-49': 66.4, '50-59': 49.1, '60-69': 62.3, '70-79': 65.1, '80-89': 68.7, '90-99': 88.0, 'old': 62.19, 'new': 88.0}
2024-08-02 19:48:53,192 [trainer.py] => NME: {'total': 57.52, '00-09': 55.2, '10-19': 43.3, '20-29': 61.0, '30-39': 51.7, '40-49': 59.0, '50-59': 48.0, '60-69': 63.4, '70-79': 70.6, '80-89': 58.4, '90-99': 93.0, 'old': 56.73, 'new': 93.0}
2024-08-02 19:48:53,192 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13, 62.75]
2024-08-02 19:48:53,192 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99, 86.89]
2024-08-02 19:48:53,193 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09, 57.52]
2024-08-02 19:48:53,193 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79, 83.43]

2024-08-02 19:48:53,193 [trainer.py] => CNN top1 平均值: 71.34
2024-08-02 19:48:53,196 [trainer.py] => All params: 1178246
2024-08-02 19:48:53,199 [trainer.py] => Trainable params: 595122
2024-08-02 19:48:53,307 [foster.py] => Learning on 92-94
2024-08-02 19:48:53,311 [foster.py] => All params: 1178764
2024-08-02 19:48:53,313 [foster.py] => Trainable params: 595510
2024-08-02 19:48:53,357 [foster.py] => per cls weights : [1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952 1.00972952
 1.00972952 1.00972952 0.55244231 0.55244231]
2024-08-02 19:48:56,265 [foster.py] => Task 22, Epoch 1/170 => Loss 5.254, Loss_clf 0.953, Loss_fe 1.671, Loss_kd 2.572, Train_accy 66.80
2024-08-02 19:49:01,300 [foster.py] => Task 22, Epoch 2/170 => Loss 3.956, Loss_clf 0.612, Loss_fe 0.788, Loss_kd 2.500, Train_accy 72.18, Test_accy 59.95
2024-08-02 19:49:06,313 [foster.py] => Task 22, Epoch 3/170 => Loss 3.896, Loss_clf 0.631, Loss_fe 0.668, Loss_kd 2.539, Train_accy 70.63, Test_accy 60.54
2024-08-02 19:49:11,339 [foster.py] => Task 22, Epoch 4/170 => Loss 3.753, Loss_clf 0.572, Loss_fe 0.606, Loss_kd 2.518, Train_accy 73.20, Test_accy 60.06
2024-08-02 19:49:16,288 [foster.py] => Task 22, Epoch 5/170 => Loss 3.754, Loss_clf 0.576, Loss_fe 0.586, Loss_kd 2.535, Train_accy 74.82, Test_accy 60.02
2024-08-02 19:49:19,237 [foster.py] => Task 22, Epoch 6/170 => Loss 3.715, Loss_clf 0.570, Loss_fe 0.583, Loss_kd 2.505, Train_accy 74.15
2024-08-02 19:49:24,327 [foster.py] => Task 22, Epoch 7/170 => Loss 3.645, Loss_clf 0.518, Loss_fe 0.558, Loss_kd 2.512, Train_accy 76.23, Test_accy 60.48
2024-08-02 19:49:29,326 [foster.py] => Task 22, Epoch 8/170 => Loss 3.670, Loss_clf 0.545, Loss_fe 0.548, Loss_kd 2.520, Train_accy 75.21, Test_accy 60.22
2024-08-02 19:49:34,329 [foster.py] => Task 22, Epoch 9/170 => Loss 3.616, Loss_clf 0.527, Loss_fe 0.516, Loss_kd 2.516, Train_accy 73.63, Test_accy 59.65
2024-08-02 19:49:39,328 [foster.py] => Task 22, Epoch 10/170 => Loss 3.631, Loss_clf 0.555, Loss_fe 0.518, Loss_kd 2.502, Train_accy 77.01, Test_accy 60.15
2024-08-02 19:49:42,330 [foster.py] => Task 22, Epoch 11/170 => Loss 3.578, Loss_clf 0.516, Loss_fe 0.477, Loss_kd 2.528, Train_accy 76.20
2024-08-02 19:49:47,332 [foster.py] => Task 22, Epoch 12/170 => Loss 3.583, Loss_clf 0.554, Loss_fe 0.463, Loss_kd 2.509, Train_accy 76.27, Test_accy 60.05
2024-08-02 19:49:52,339 [foster.py] => Task 22, Epoch 13/170 => Loss 3.659, Loss_clf 0.578, Loss_fe 0.480, Loss_kd 2.544, Train_accy 75.49, Test_accy 59.86
2024-08-02 19:49:57,351 [foster.py] => Task 22, Epoch 14/170 => Loss 3.523, Loss_clf 0.503, Loss_fe 0.463, Loss_kd 2.500, Train_accy 76.94, Test_accy 60.19
2024-08-02 19:50:02,351 [foster.py] => Task 22, Epoch 15/170 => Loss 3.455, Loss_clf 0.472, Loss_fe 0.437, Loss_kd 2.491, Train_accy 77.36, Test_accy 60.03
2024-08-02 19:50:05,273 [foster.py] => Task 22, Epoch 16/170 => Loss 3.484, Loss_clf 0.504, Loss_fe 0.424, Loss_kd 2.500, Train_accy 79.12
2024-08-02 19:50:10,277 [foster.py] => Task 22, Epoch 17/170 => Loss 3.586, Loss_clf 0.537, Loss_fe 0.455, Loss_kd 2.537, Train_accy 76.55, Test_accy 60.44
2024-08-02 19:50:15,267 [foster.py] => Task 22, Epoch 18/170 => Loss 3.463, Loss_clf 0.472, Loss_fe 0.423, Loss_kd 2.511, Train_accy 78.42, Test_accy 59.57
2024-08-02 19:50:20,268 [foster.py] => Task 22, Epoch 19/170 => Loss 3.500, Loss_clf 0.507, Loss_fe 0.433, Loss_kd 2.503, Train_accy 77.71, Test_accy 60.36
2024-08-02 19:50:25,431 [foster.py] => Task 22, Epoch 20/170 => Loss 3.526, Loss_clf 0.501, Loss_fe 0.436, Loss_kd 2.532, Train_accy 78.77, Test_accy 60.31
2024-08-02 19:50:28,360 [foster.py] => Task 22, Epoch 21/170 => Loss 3.475, Loss_clf 0.498, Loss_fe 0.418, Loss_kd 2.503, Train_accy 78.06
2024-08-02 19:50:33,351 [foster.py] => Task 22, Epoch 22/170 => Loss 3.490, Loss_clf 0.495, Loss_fe 0.389, Loss_kd 2.549, Train_accy 77.36, Test_accy 60.77
2024-08-02 19:50:38,361 [foster.py] => Task 22, Epoch 23/170 => Loss 3.473, Loss_clf 0.482, Loss_fe 0.436, Loss_kd 2.499, Train_accy 77.99, Test_accy 60.32
2024-08-02 19:50:43,369 [foster.py] => Task 22, Epoch 24/170 => Loss 3.455, Loss_clf 0.476, Loss_fe 0.401, Loss_kd 2.520, Train_accy 79.05, Test_accy 60.71
2024-08-02 19:50:48,431 [foster.py] => Task 22, Epoch 25/170 => Loss 3.383, Loss_clf 0.466, Loss_fe 0.381, Loss_kd 2.481, Train_accy 80.14, Test_accy 60.37
2024-08-02 19:50:51,316 [foster.py] => Task 22, Epoch 26/170 => Loss 3.434, Loss_clf 0.503, Loss_fe 0.359, Loss_kd 2.516, Train_accy 78.98
2024-08-02 19:50:56,367 [foster.py] => Task 22, Epoch 27/170 => Loss 3.430, Loss_clf 0.480, Loss_fe 0.405, Loss_kd 2.489, Train_accy 79.40, Test_accy 58.98
2024-08-02 19:51:01,360 [foster.py] => Task 22, Epoch 28/170 => Loss 3.483, Loss_clf 0.513, Loss_fe 0.393, Loss_kd 2.520, Train_accy 78.42, Test_accy 60.67
2024-08-02 19:51:06,339 [foster.py] => Task 22, Epoch 29/170 => Loss 3.375, Loss_clf 0.455, Loss_fe 0.379, Loss_kd 2.485, Train_accy 79.61, Test_accy 60.53
2024-08-02 19:51:11,396 [foster.py] => Task 22, Epoch 30/170 => Loss 3.346, Loss_clf 0.432, Loss_fe 0.359, Loss_kd 2.499, Train_accy 80.42, Test_accy 60.52
2024-08-02 19:51:14,310 [foster.py] => Task 22, Epoch 31/170 => Loss 3.379, Loss_clf 0.456, Loss_fe 0.359, Loss_kd 2.508, Train_accy 79.93
2024-08-02 19:51:19,298 [foster.py] => Task 22, Epoch 32/170 => Loss 3.441, Loss_clf 0.466, Loss_fe 0.383, Loss_kd 2.535, Train_accy 79.86, Test_accy 60.94
2024-08-02 19:51:24,292 [foster.py] => Task 22, Epoch 33/170 => Loss 3.429, Loss_clf 0.490, Loss_fe 0.381, Loss_kd 2.502, Train_accy 78.98, Test_accy 60.70
2024-08-02 19:51:29,278 [foster.py] => Task 22, Epoch 34/170 => Loss 3.422, Loss_clf 0.472, Loss_fe 0.363, Loss_kd 2.530, Train_accy 80.07, Test_accy 59.33
2024-08-02 19:51:34,266 [foster.py] => Task 22, Epoch 35/170 => Loss 3.434, Loss_clf 0.477, Loss_fe 0.387, Loss_kd 2.514, Train_accy 78.98, Test_accy 60.91
2024-08-02 19:51:37,124 [foster.py] => Task 22, Epoch 36/170 => Loss 3.421, Loss_clf 0.466, Loss_fe 0.367, Loss_kd 2.531, Train_accy 79.82
2024-08-02 19:51:42,098 [foster.py] => Task 22, Epoch 37/170 => Loss 3.462, Loss_clf 0.498, Loss_fe 0.395, Loss_kd 2.512, Train_accy 79.79, Test_accy 60.32
2024-08-02 19:51:47,084 [foster.py] => Task 22, Epoch 38/170 => Loss 3.397, Loss_clf 0.465, Loss_fe 0.351, Loss_kd 2.525, Train_accy 78.35, Test_accy 60.70
2024-08-02 19:51:52,150 [foster.py] => Task 22, Epoch 39/170 => Loss 3.381, Loss_clf 0.483, Loss_fe 0.345, Loss_kd 2.498, Train_accy 79.47, Test_accy 60.74
2024-08-02 19:51:57,191 [foster.py] => Task 22, Epoch 40/170 => Loss 3.427, Loss_clf 0.475, Loss_fe 0.338, Loss_kd 2.557, Train_accy 79.30, Test_accy 60.91
2024-08-02 19:52:00,094 [foster.py] => Task 22, Epoch 41/170 => Loss 3.369, Loss_clf 0.453, Loss_fe 0.356, Loss_kd 2.504, Train_accy 79.15
2024-08-02 19:52:05,107 [foster.py] => Task 22, Epoch 42/170 => Loss 3.351, Loss_clf 0.438, Loss_fe 0.356, Loss_kd 2.500, Train_accy 79.96, Test_accy 60.68
2024-08-02 19:52:10,116 [foster.py] => Task 22, Epoch 43/170 => Loss 3.360, Loss_clf 0.445, Loss_fe 0.318, Loss_kd 2.540, Train_accy 80.00, Test_accy 60.60
2024-08-02 19:52:15,137 [foster.py] => Task 22, Epoch 44/170 => Loss 3.315, Loss_clf 0.428, Loss_fe 0.314, Loss_kd 2.516, Train_accy 81.41, Test_accy 61.00
2024-08-02 19:52:20,146 [foster.py] => Task 22, Epoch 45/170 => Loss 3.291, Loss_clf 0.428, Loss_fe 0.291, Loss_kd 2.516, Train_accy 80.81, Test_accy 61.01
2024-08-02 19:52:23,058 [foster.py] => Task 22, Epoch 46/170 => Loss 3.255, Loss_clf 0.418, Loss_fe 0.295, Loss_kd 2.485, Train_accy 81.90
2024-08-02 19:52:28,070 [foster.py] => Task 22, Epoch 47/170 => Loss 3.323, Loss_clf 0.427, Loss_fe 0.323, Loss_kd 2.517, Train_accy 81.34, Test_accy 60.68
2024-08-02 19:52:33,104 [foster.py] => Task 22, Epoch 48/170 => Loss 3.302, Loss_clf 0.426, Loss_fe 0.295, Loss_kd 2.525, Train_accy 81.51, Test_accy 60.68
2024-08-02 19:52:38,103 [foster.py] => Task 22, Epoch 49/170 => Loss 3.252, Loss_clf 0.409, Loss_fe 0.314, Loss_kd 2.474, Train_accy 81.69, Test_accy 61.07
2024-08-02 19:52:43,112 [foster.py] => Task 22, Epoch 50/170 => Loss 3.362, Loss_clf 0.442, Loss_fe 0.350, Loss_kd 2.514, Train_accy 81.41, Test_accy 61.01
2024-08-02 19:52:46,039 [foster.py] => Task 22, Epoch 51/170 => Loss 3.319, Loss_clf 0.420, Loss_fe 0.305, Loss_kd 2.536, Train_accy 80.28
2024-08-02 19:52:51,030 [foster.py] => Task 22, Epoch 52/170 => Loss 3.288, Loss_clf 0.417, Loss_fe 0.315, Loss_kd 2.500, Train_accy 81.30, Test_accy 60.80
2024-08-02 19:52:56,036 [foster.py] => Task 22, Epoch 53/170 => Loss 3.269, Loss_clf 0.429, Loss_fe 0.286, Loss_kd 2.497, Train_accy 80.46, Test_accy 61.10
2024-08-02 19:53:01,063 [foster.py] => Task 22, Epoch 54/170 => Loss 3.318, Loss_clf 0.434, Loss_fe 0.322, Loss_kd 2.506, Train_accy 81.58, Test_accy 60.81
2024-08-02 19:53:06,107 [foster.py] => Task 22, Epoch 55/170 => Loss 3.272, Loss_clf 0.400, Loss_fe 0.296, Loss_kd 2.519, Train_accy 81.76, Test_accy 60.83
2024-08-02 19:53:08,976 [foster.py] => Task 22, Epoch 56/170 => Loss 3.272, Loss_clf 0.425, Loss_fe 0.289, Loss_kd 2.501, Train_accy 81.37
2024-08-02 19:53:13,963 [foster.py] => Task 22, Epoch 57/170 => Loss 3.293, Loss_clf 0.438, Loss_fe 0.283, Loss_kd 2.515, Train_accy 81.09, Test_accy 60.72
2024-08-02 19:53:19,054 [foster.py] => Task 22, Epoch 58/170 => Loss 3.268, Loss_clf 0.424, Loss_fe 0.285, Loss_kd 2.502, Train_accy 81.02, Test_accy 61.19
2024-08-02 19:53:24,058 [foster.py] => Task 22, Epoch 59/170 => Loss 3.344, Loss_clf 0.443, Loss_fe 0.293, Loss_kd 2.552, Train_accy 81.73, Test_accy 60.70
2024-08-02 19:53:29,062 [foster.py] => Task 22, Epoch 60/170 => Loss 3.268, Loss_clf 0.430, Loss_fe 0.290, Loss_kd 2.492, Train_accy 81.27, Test_accy 60.63
2024-08-02 19:53:32,058 [foster.py] => Task 22, Epoch 61/170 => Loss 3.283, Loss_clf 0.400, Loss_fe 0.299, Loss_kd 2.527, Train_accy 83.17
2024-08-02 19:53:37,049 [foster.py] => Task 22, Epoch 62/170 => Loss 3.368, Loss_clf 0.460, Loss_fe 0.304, Loss_kd 2.547, Train_accy 81.20, Test_accy 61.30
2024-08-02 19:53:42,031 [foster.py] => Task 22, Epoch 63/170 => Loss 3.249, Loss_clf 0.403, Loss_fe 0.274, Loss_kd 2.516, Train_accy 82.04, Test_accy 60.73
2024-08-02 19:53:47,008 [foster.py] => Task 22, Epoch 64/170 => Loss 3.241, Loss_clf 0.396, Loss_fe 0.276, Loss_kd 2.512, Train_accy 82.82, Test_accy 60.95
2024-08-02 19:53:52,034 [foster.py] => Task 22, Epoch 65/170 => Loss 3.277, Loss_clf 0.424, Loss_fe 0.276, Loss_kd 2.521, Train_accy 81.06, Test_accy 60.87
2024-08-02 19:53:54,925 [foster.py] => Task 22, Epoch 66/170 => Loss 3.259, Loss_clf 0.415, Loss_fe 0.303, Loss_kd 2.486, Train_accy 81.76
2024-08-02 19:54:00,005 [foster.py] => Task 22, Epoch 67/170 => Loss 3.302, Loss_clf 0.446, Loss_fe 0.308, Loss_kd 2.493, Train_accy 80.77, Test_accy 60.53
2024-08-02 19:54:05,122 [foster.py] => Task 22, Epoch 68/170 => Loss 3.197, Loss_clf 0.387, Loss_fe 0.281, Loss_kd 2.473, Train_accy 82.46, Test_accy 60.81
2024-08-02 19:54:10,125 [foster.py] => Task 22, Epoch 69/170 => Loss 3.206, Loss_clf 0.379, Loss_fe 0.279, Loss_kd 2.492, Train_accy 82.32, Test_accy 60.51
2024-08-02 19:54:15,090 [foster.py] => Task 22, Epoch 70/170 => Loss 3.197, Loss_clf 0.384, Loss_fe 0.273, Loss_kd 2.484, Train_accy 82.15, Test_accy 60.91
2024-08-02 19:54:18,030 [foster.py] => Task 22, Epoch 71/170 => Loss 3.241, Loss_clf 0.404, Loss_fe 0.268, Loss_kd 2.513, Train_accy 83.24
2024-08-02 19:54:23,039 [foster.py] => Task 22, Epoch 72/170 => Loss 3.237, Loss_clf 0.423, Loss_fe 0.244, Loss_kd 2.513, Train_accy 82.43, Test_accy 60.94
2024-08-02 19:54:28,048 [foster.py] => Task 22, Epoch 73/170 => Loss 3.212, Loss_clf 0.407, Loss_fe 0.234, Loss_kd 2.514, Train_accy 82.89, Test_accy 61.09
2024-08-02 19:54:33,036 [foster.py] => Task 22, Epoch 74/170 => Loss 3.318, Loss_clf 0.444, Loss_fe 0.266, Loss_kd 2.551, Train_accy 83.52, Test_accy 61.17
2024-08-02 19:54:38,065 [foster.py] => Task 22, Epoch 75/170 => Loss 3.240, Loss_clf 0.401, Loss_fe 0.245, Loss_kd 2.537, Train_accy 82.18, Test_accy 61.54
2024-08-02 19:54:40,966 [foster.py] => Task 22, Epoch 76/170 => Loss 3.243, Loss_clf 0.410, Loss_fe 0.250, Loss_kd 2.526, Train_accy 82.57
2024-08-02 19:54:46,017 [foster.py] => Task 22, Epoch 77/170 => Loss 3.228, Loss_clf 0.408, Loss_fe 0.255, Loss_kd 2.508, Train_accy 83.63, Test_accy 60.80
2024-08-02 19:54:50,992 [foster.py] => Task 22, Epoch 78/170 => Loss 3.231, Loss_clf 0.410, Loss_fe 0.234, Loss_kd 2.530, Train_accy 83.10, Test_accy 61.16
2024-08-02 19:54:55,989 [foster.py] => Task 22, Epoch 79/170 => Loss 3.246, Loss_clf 0.432, Loss_fe 0.241, Loss_kd 2.516, Train_accy 83.13, Test_accy 61.11
2024-08-02 19:55:00,987 [foster.py] => Task 22, Epoch 80/170 => Loss 3.190, Loss_clf 0.386, Loss_fe 0.253, Loss_kd 2.495, Train_accy 84.01, Test_accy 60.97
2024-08-02 19:55:03,895 [foster.py] => Task 22, Epoch 81/170 => Loss 3.199, Loss_clf 0.396, Loss_fe 0.233, Loss_kd 2.514, Train_accy 83.13
2024-08-02 19:55:08,995 [foster.py] => Task 22, Epoch 82/170 => Loss 3.279, Loss_clf 0.420, Loss_fe 0.257, Loss_kd 2.545, Train_accy 82.64, Test_accy 60.77
2024-08-02 19:55:14,099 [foster.py] => Task 22, Epoch 83/170 => Loss 3.234, Loss_clf 0.412, Loss_fe 0.233, Loss_kd 2.532, Train_accy 83.13, Test_accy 61.23
2024-08-02 19:55:19,111 [foster.py] => Task 22, Epoch 84/170 => Loss 3.227, Loss_clf 0.411, Loss_fe 0.248, Loss_kd 2.511, Train_accy 83.13, Test_accy 60.97
2024-08-02 19:55:24,106 [foster.py] => Task 22, Epoch 85/170 => Loss 3.149, Loss_clf 0.372, Loss_fe 0.217, Loss_kd 2.504, Train_accy 84.37, Test_accy 61.02
2024-08-02 19:55:27,025 [foster.py] => Task 22, Epoch 86/170 => Loss 3.148, Loss_clf 0.371, Loss_fe 0.231, Loss_kd 2.490, Train_accy 83.59
2024-08-02 19:55:32,070 [foster.py] => Task 22, Epoch 87/170 => Loss 3.132, Loss_clf 0.358, Loss_fe 0.209, Loss_kd 2.510, Train_accy 84.75, Test_accy 61.26
2024-08-02 19:55:37,108 [foster.py] => Task 22, Epoch 88/170 => Loss 3.165, Loss_clf 0.387, Loss_fe 0.202, Loss_kd 2.520, Train_accy 83.42, Test_accy 61.24
2024-08-02 19:55:42,104 [foster.py] => Task 22, Epoch 89/170 => Loss 3.210, Loss_clf 0.419, Loss_fe 0.229, Loss_kd 2.506, Train_accy 83.42, Test_accy 60.99
2024-08-02 19:55:47,066 [foster.py] => Task 22, Epoch 90/170 => Loss 3.236, Loss_clf 0.399, Loss_fe 0.232, Loss_kd 2.548, Train_accy 83.27, Test_accy 60.70
2024-08-02 19:55:49,951 [foster.py] => Task 22, Epoch 91/170 => Loss 3.190, Loss_clf 0.415, Loss_fe 0.229, Loss_kd 2.490, Train_accy 83.10
2024-08-02 19:55:54,910 [foster.py] => Task 22, Epoch 92/170 => Loss 3.160, Loss_clf 0.377, Loss_fe 0.221, Loss_kd 2.506, Train_accy 84.86, Test_accy 60.99
2024-08-02 19:55:59,880 [foster.py] => Task 22, Epoch 93/170 => Loss 3.194, Loss_clf 0.397, Loss_fe 0.221, Loss_kd 2.520, Train_accy 82.29, Test_accy 61.16
2024-08-02 19:56:04,918 [foster.py] => Task 22, Epoch 94/170 => Loss 3.129, Loss_clf 0.372, Loss_fe 0.195, Loss_kd 2.507, Train_accy 84.37, Test_accy 61.20
2024-08-02 19:56:09,917 [foster.py] => Task 22, Epoch 95/170 => Loss 3.151, Loss_clf 0.375, Loss_fe 0.190, Loss_kd 2.529, Train_accy 83.52, Test_accy 60.96
2024-08-02 19:56:12,970 [foster.py] => Task 22, Epoch 96/170 => Loss 3.146, Loss_clf 0.369, Loss_fe 0.196, Loss_kd 2.524, Train_accy 83.20
2024-08-02 19:56:18,023 [foster.py] => Task 22, Epoch 97/170 => Loss 3.180, Loss_clf 0.390, Loss_fe 0.201, Loss_kd 2.532, Train_accy 83.98, Test_accy 60.95
2024-08-02 19:56:23,021 [foster.py] => Task 22, Epoch 98/170 => Loss 3.137, Loss_clf 0.372, Loss_fe 0.199, Loss_kd 2.510, Train_accy 85.81, Test_accy 61.13
2024-08-02 19:56:28,061 [foster.py] => Task 22, Epoch 99/170 => Loss 3.190, Loss_clf 0.400, Loss_fe 0.207, Loss_kd 2.526, Train_accy 84.47, Test_accy 61.01
2024-08-02 19:56:33,073 [foster.py] => Task 22, Epoch 100/170 => Loss 3.109, Loss_clf 0.369, Loss_fe 0.192, Loss_kd 2.492, Train_accy 84.08, Test_accy 61.23
2024-08-02 19:56:35,976 [foster.py] => Task 22, Epoch 101/170 => Loss 3.081, Loss_clf 0.342, Loss_fe 0.199, Loss_kd 2.484, Train_accy 86.06
2024-08-02 19:56:41,044 [foster.py] => Task 22, Epoch 102/170 => Loss 3.071, Loss_clf 0.355, Loss_fe 0.179, Loss_kd 2.483, Train_accy 84.47, Test_accy 61.13
2024-08-02 19:56:46,021 [foster.py] => Task 22, Epoch 103/170 => Loss 3.080, Loss_clf 0.352, Loss_fe 0.176, Loss_kd 2.496, Train_accy 85.46, Test_accy 61.26
2024-08-02 19:56:51,031 [foster.py] => Task 22, Epoch 104/170 => Loss 3.115, Loss_clf 0.372, Loss_fe 0.198, Loss_kd 2.489, Train_accy 83.80, Test_accy 61.15
2024-08-02 19:56:56,053 [foster.py] => Task 22, Epoch 105/170 => Loss 3.114, Loss_clf 0.372, Loss_fe 0.191, Loss_kd 2.494, Train_accy 84.72, Test_accy 60.97
2024-08-02 19:56:59,077 [foster.py] => Task 22, Epoch 106/170 => Loss 3.104, Loss_clf 0.366, Loss_fe 0.172, Loss_kd 2.510, Train_accy 85.67
2024-08-02 19:57:04,127 [foster.py] => Task 22, Epoch 107/170 => Loss 3.132, Loss_clf 0.364, Loss_fe 0.206, Loss_kd 2.507, Train_accy 84.54, Test_accy 61.29
2024-08-02 19:57:09,131 [foster.py] => Task 22, Epoch 108/170 => Loss 3.097, Loss_clf 0.362, Loss_fe 0.176, Loss_kd 2.504, Train_accy 84.93, Test_accy 61.07
2024-08-02 19:57:14,131 [foster.py] => Task 22, Epoch 109/170 => Loss 3.146, Loss_clf 0.389, Loss_fe 0.172, Loss_kd 2.529, Train_accy 84.33, Test_accy 61.11
2024-08-02 19:57:19,200 [foster.py] => Task 22, Epoch 110/170 => Loss 3.122, Loss_clf 0.365, Loss_fe 0.176, Loss_kd 2.524, Train_accy 85.35, Test_accy 61.46
2024-08-02 19:57:22,110 [foster.py] => Task 22, Epoch 111/170 => Loss 3.094, Loss_clf 0.347, Loss_fe 0.163, Loss_kd 2.528, Train_accy 85.49
2024-08-02 19:57:27,207 [foster.py] => Task 22, Epoch 112/170 => Loss 3.103, Loss_clf 0.357, Loss_fe 0.179, Loss_kd 2.510, Train_accy 85.18, Test_accy 61.26
2024-08-02 19:57:32,194 [foster.py] => Task 22, Epoch 113/170 => Loss 3.128, Loss_clf 0.376, Loss_fe 0.174, Loss_kd 2.522, Train_accy 84.58, Test_accy 61.17
2024-08-02 19:57:37,207 [foster.py] => Task 22, Epoch 114/170 => Loss 3.112, Loss_clf 0.371, Loss_fe 0.175, Loss_kd 2.509, Train_accy 85.28, Test_accy 61.32
2024-08-02 19:57:42,269 [foster.py] => Task 22, Epoch 115/170 => Loss 3.025, Loss_clf 0.343, Loss_fe 0.138, Loss_kd 2.488, Train_accy 85.42, Test_accy 61.43
2024-08-02 19:57:45,179 [foster.py] => Task 22, Epoch 116/170 => Loss 3.048, Loss_clf 0.348, Loss_fe 0.150, Loss_kd 2.494, Train_accy 86.37
2024-08-02 19:57:50,227 [foster.py] => Task 22, Epoch 117/170 => Loss 3.047, Loss_clf 0.329, Loss_fe 0.154, Loss_kd 2.508, Train_accy 86.51, Test_accy 61.37
2024-08-02 19:57:55,269 [foster.py] => Task 22, Epoch 118/170 => Loss 3.108, Loss_clf 0.373, Loss_fe 0.159, Loss_kd 2.520, Train_accy 84.37, Test_accy 61.39
2024-08-02 19:58:00,280 [foster.py] => Task 22, Epoch 119/170 => Loss 3.114, Loss_clf 0.365, Loss_fe 0.162, Loss_kd 2.530, Train_accy 86.02, Test_accy 61.40
2024-08-02 19:58:05,287 [foster.py] => Task 22, Epoch 120/170 => Loss 3.116, Loss_clf 0.377, Loss_fe 0.157, Loss_kd 2.525, Train_accy 85.32, Test_accy 61.18
2024-08-02 19:58:08,187 [foster.py] => Task 22, Epoch 121/170 => Loss 3.090, Loss_clf 0.356, Loss_fe 0.172, Loss_kd 2.506, Train_accy 85.81
2024-08-02 19:58:13,190 [foster.py] => Task 22, Epoch 122/170 => Loss 3.078, Loss_clf 0.348, Loss_fe 0.174, Loss_kd 2.500, Train_accy 85.77, Test_accy 61.04
2024-08-02 19:58:18,223 [foster.py] => Task 22, Epoch 123/170 => Loss 3.092, Loss_clf 0.360, Loss_fe 0.154, Loss_kd 2.522, Train_accy 86.48, Test_accy 61.22
2024-08-02 19:58:23,208 [foster.py] => Task 22, Epoch 124/170 => Loss 3.068, Loss_clf 0.340, Loss_fe 0.158, Loss_kd 2.514, Train_accy 85.67, Test_accy 61.30
2024-08-02 19:58:28,260 [foster.py] => Task 22, Epoch 125/170 => Loss 3.110, Loss_clf 0.361, Loss_fe 0.167, Loss_kd 2.525, Train_accy 85.18, Test_accy 61.29
2024-08-02 19:58:31,180 [foster.py] => Task 22, Epoch 126/170 => Loss 3.012, Loss_clf 0.343, Loss_fe 0.130, Loss_kd 2.483, Train_accy 87.18
2024-08-02 19:58:36,201 [foster.py] => Task 22, Epoch 127/170 => Loss 3.095, Loss_clf 0.363, Loss_fe 0.174, Loss_kd 2.502, Train_accy 86.27, Test_accy 61.11
2024-08-02 19:58:41,211 [foster.py] => Task 22, Epoch 128/170 => Loss 3.096, Loss_clf 0.357, Loss_fe 0.159, Loss_kd 2.524, Train_accy 86.06, Test_accy 61.03
2024-08-02 19:58:46,216 [foster.py] => Task 22, Epoch 129/170 => Loss 3.056, Loss_clf 0.348, Loss_fe 0.155, Loss_kd 2.497, Train_accy 85.81, Test_accy 61.14
2024-08-02 19:58:51,360 [foster.py] => Task 22, Epoch 130/170 => Loss 2.996, Loss_clf 0.324, Loss_fe 0.140, Loss_kd 2.476, Train_accy 86.62, Test_accy 61.07
2024-08-02 19:58:54,381 [foster.py] => Task 22, Epoch 131/170 => Loss 3.043, Loss_clf 0.325, Loss_fe 0.133, Loss_kd 2.529, Train_accy 87.08
2024-08-02 19:58:59,380 [foster.py] => Task 22, Epoch 132/170 => Loss 3.046, Loss_clf 0.349, Loss_fe 0.139, Loss_kd 2.501, Train_accy 85.46, Test_accy 61.29
2024-08-02 19:59:04,402 [foster.py] => Task 22, Epoch 133/170 => Loss 2.986, Loss_clf 0.308, Loss_fe 0.131, Loss_kd 2.491, Train_accy 87.50, Test_accy 61.31
2024-08-02 19:59:09,437 [foster.py] => Task 22, Epoch 134/170 => Loss 3.044, Loss_clf 0.358, Loss_fe 0.127, Loss_kd 2.503, Train_accy 85.74, Test_accy 61.16
2024-08-02 19:59:14,490 [foster.py] => Task 22, Epoch 135/170 => Loss 3.016, Loss_clf 0.327, Loss_fe 0.113, Loss_kd 2.520, Train_accy 86.94, Test_accy 61.27
2024-08-02 19:59:17,432 [foster.py] => Task 22, Epoch 136/170 => Loss 3.048, Loss_clf 0.344, Loss_fe 0.131, Loss_kd 2.516, Train_accy 85.67
2024-08-02 19:59:22,483 [foster.py] => Task 22, Epoch 137/170 => Loss 3.029, Loss_clf 0.347, Loss_fe 0.142, Loss_kd 2.485, Train_accy 86.55, Test_accy 61.34
2024-08-02 19:59:27,500 [foster.py] => Task 22, Epoch 138/170 => Loss 3.051, Loss_clf 0.339, Loss_fe 0.127, Loss_kd 2.528, Train_accy 86.23, Test_accy 61.29
2024-08-02 19:59:32,592 [foster.py] => Task 22, Epoch 139/170 => Loss 2.996, Loss_clf 0.321, Loss_fe 0.127, Loss_kd 2.492, Train_accy 87.01, Test_accy 61.33
2024-08-02 19:59:37,600 [foster.py] => Task 22, Epoch 140/170 => Loss 3.018, Loss_clf 0.336, Loss_fe 0.120, Loss_kd 2.505, Train_accy 86.87, Test_accy 61.44
2024-08-02 19:59:40,487 [foster.py] => Task 22, Epoch 141/170 => Loss 3.042, Loss_clf 0.341, Loss_fe 0.140, Loss_kd 2.504, Train_accy 87.11
2024-08-02 19:59:45,470 [foster.py] => Task 22, Epoch 142/170 => Loss 3.061, Loss_clf 0.342, Loss_fe 0.145, Loss_kd 2.518, Train_accy 86.02, Test_accy 61.35
2024-08-02 19:59:50,515 [foster.py] => Task 22, Epoch 143/170 => Loss 3.032, Loss_clf 0.329, Loss_fe 0.130, Loss_kd 2.517, Train_accy 86.76, Test_accy 61.39
2024-08-02 19:59:55,498 [foster.py] => Task 22, Epoch 144/170 => Loss 3.048, Loss_clf 0.355, Loss_fe 0.135, Loss_kd 2.501, Train_accy 85.46, Test_accy 61.38
2024-08-02 20:00:00,502 [foster.py] => Task 22, Epoch 145/170 => Loss 3.021, Loss_clf 0.334, Loss_fe 0.123, Loss_kd 2.507, Train_accy 86.02, Test_accy 61.36
2024-08-02 20:00:03,504 [foster.py] => Task 22, Epoch 146/170 => Loss 3.037, Loss_clf 0.352, Loss_fe 0.135, Loss_kd 2.495, Train_accy 85.70
2024-08-02 20:00:08,602 [foster.py] => Task 22, Epoch 147/170 => Loss 3.042, Loss_clf 0.336, Loss_fe 0.128, Loss_kd 2.521, Train_accy 86.80, Test_accy 61.36
2024-08-02 20:00:13,696 [foster.py] => Task 22, Epoch 148/170 => Loss 3.047, Loss_clf 0.344, Loss_fe 0.127, Loss_kd 2.519, Train_accy 87.29, Test_accy 61.33
2024-08-02 20:00:18,726 [foster.py] => Task 22, Epoch 149/170 => Loss 3.045, Loss_clf 0.342, Loss_fe 0.135, Loss_kd 2.511, Train_accy 86.97, Test_accy 61.32
2024-08-02 20:00:23,764 [foster.py] => Task 22, Epoch 150/170 => Loss 3.052, Loss_clf 0.360, Loss_fe 0.126, Loss_kd 2.510, Train_accy 86.20, Test_accy 61.29
2024-08-02 20:00:26,640 [foster.py] => Task 22, Epoch 151/170 => Loss 3.042, Loss_clf 0.335, Loss_fe 0.126, Loss_kd 2.524, Train_accy 86.55
2024-08-02 20:00:31,658 [foster.py] => Task 22, Epoch 152/170 => Loss 3.038, Loss_clf 0.324, Loss_fe 0.124, Loss_kd 2.533, Train_accy 87.54, Test_accy 61.31
2024-08-02 20:00:36,780 [foster.py] => Task 22, Epoch 153/170 => Loss 2.998, Loss_clf 0.313, Loss_fe 0.114, Loss_kd 2.515, Train_accy 87.78, Test_accy 61.34
2024-08-02 20:00:41,828 [foster.py] => Task 22, Epoch 154/170 => Loss 2.998, Loss_clf 0.308, Loss_fe 0.127, Loss_kd 2.507, Train_accy 88.06, Test_accy 61.20
2024-08-02 20:00:46,876 [foster.py] => Task 22, Epoch 155/170 => Loss 3.012, Loss_clf 0.325, Loss_fe 0.105, Loss_kd 2.525, Train_accy 87.43, Test_accy 61.26
2024-08-02 20:00:49,769 [foster.py] => Task 22, Epoch 156/170 => Loss 3.105, Loss_clf 0.365, Loss_fe 0.145, Loss_kd 2.538, Train_accy 86.37
2024-08-02 20:00:54,785 [foster.py] => Task 22, Epoch 157/170 => Loss 3.088, Loss_clf 0.361, Loss_fe 0.142, Loss_kd 2.528, Train_accy 86.20, Test_accy 61.35
2024-08-02 20:00:59,945 [foster.py] => Task 22, Epoch 158/170 => Loss 3.024, Loss_clf 0.338, Loss_fe 0.130, Loss_kd 2.499, Train_accy 86.48, Test_accy 61.32
2024-08-02 20:01:04,988 [foster.py] => Task 22, Epoch 159/170 => Loss 3.080, Loss_clf 0.362, Loss_fe 0.124, Loss_kd 2.536, Train_accy 86.62, Test_accy 61.28
2024-08-02 20:01:10,025 [foster.py] => Task 22, Epoch 160/170 => Loss 2.980, Loss_clf 0.318, Loss_fe 0.124, Loss_kd 2.482, Train_accy 87.57, Test_accy 61.33
2024-08-02 20:01:12,955 [foster.py] => Task 22, Epoch 161/170 => Loss 3.056, Loss_clf 0.333, Loss_fe 0.144, Loss_kd 2.523, Train_accy 87.36
2024-08-02 20:01:17,987 [foster.py] => Task 22, Epoch 162/170 => Loss 3.040, Loss_clf 0.332, Loss_fe 0.114, Loss_kd 2.537, Train_accy 87.15, Test_accy 61.31
2024-08-02 20:01:22,996 [foster.py] => Task 22, Epoch 163/170 => Loss 3.055, Loss_clf 0.358, Loss_fe 0.121, Loss_kd 2.520, Train_accy 86.13, Test_accy 61.28
2024-08-02 20:01:28,004 [foster.py] => Task 22, Epoch 164/170 => Loss 3.033, Loss_clf 0.319, Loss_fe 0.125, Loss_kd 2.532, Train_accy 87.25, Test_accy 61.28
2024-08-02 20:01:33,016 [foster.py] => Task 22, Epoch 165/170 => Loss 3.033, Loss_clf 0.335, Loss_fe 0.125, Loss_kd 2.516, Train_accy 87.11, Test_accy 61.29
2024-08-02 20:01:35,973 [foster.py] => Task 22, Epoch 166/170 => Loss 3.048, Loss_clf 0.336, Loss_fe 0.138, Loss_kd 2.517, Train_accy 86.51
2024-08-02 20:01:41,050 [foster.py] => Task 22, Epoch 167/170 => Loss 3.030, Loss_clf 0.337, Loss_fe 0.132, Loss_kd 2.505, Train_accy 87.04, Test_accy 61.23
2024-08-02 20:01:46,051 [foster.py] => Task 22, Epoch 168/170 => Loss 3.041, Loss_clf 0.322, Loss_fe 0.127, Loss_kd 2.535, Train_accy 88.63, Test_accy 61.31
2024-08-02 20:01:51,078 [foster.py] => Task 22, Epoch 169/170 => Loss 3.058, Loss_clf 0.340, Loss_fe 0.134, Loss_kd 2.527, Train_accy 86.73, Test_accy 61.29
2024-08-02 20:01:56,096 [foster.py] => Task 22, Epoch 170/170 => Loss 3.026, Loss_clf 0.339, Loss_fe 0.122, Loss_kd 2.509, Train_accy 86.65, Test_accy 61.26
2024-08-02 20:01:56,100 [foster.py] => do not weight align teacher!
2024-08-02 20:01:56,103 [foster.py] => per cls weights : [1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155 1.01155155
 1.01155155 1.01155155 0.46862861 0.46862861]
2024-08-02 20:02:01,706 [foster.py] => SNet: Task 22, Epoch 1/130 => Loss 30.946,  Loss1 0.782, Train_accy 58.45, Test_accy 58.19
2024-08-02 20:02:05,737 [foster.py] => SNet: Task 22, Epoch 2/130 => Loss 30.866,  Loss1 0.783, Train_accy 65.46
2024-08-02 20:02:09,761 [foster.py] => SNet: Task 22, Epoch 3/130 => Loss 30.787,  Loss1 0.782, Train_accy 65.42
2024-08-02 20:02:13,806 [foster.py] => SNet: Task 22, Epoch 4/130 => Loss 30.868,  Loss1 0.783, Train_accy 64.47
2024-08-02 20:02:17,873 [foster.py] => SNet: Task 22, Epoch 5/130 => Loss 30.803,  Loss1 0.782, Train_accy 67.01
2024-08-02 20:02:23,241 [foster.py] => SNet: Task 22, Epoch 6/130 => Loss 30.804,  Loss1 0.782, Train_accy 68.03, Test_accy 59.87
2024-08-02 20:02:27,317 [foster.py] => SNet: Task 22, Epoch 7/130 => Loss 30.788,  Loss1 0.782, Train_accy 67.11
2024-08-02 20:02:31,383 [foster.py] => SNet: Task 22, Epoch 8/130 => Loss 30.818,  Loss1 0.783, Train_accy 68.38
2024-08-02 20:02:35,429 [foster.py] => SNet: Task 22, Epoch 9/130 => Loss 30.801,  Loss1 0.782, Train_accy 68.70
2024-08-02 20:02:39,475 [foster.py] => SNet: Task 22, Epoch 10/130 => Loss 30.807,  Loss1 0.782, Train_accy 69.15
2024-08-02 20:02:44,875 [foster.py] => SNet: Task 22, Epoch 11/130 => Loss 30.807,  Loss1 0.782, Train_accy 68.98, Test_accy 60.21
2024-08-02 20:02:48,934 [foster.py] => SNet: Task 22, Epoch 12/130 => Loss 30.854,  Loss1 0.783, Train_accy 68.94
2024-08-02 20:02:52,993 [foster.py] => SNet: Task 22, Epoch 13/130 => Loss 30.803,  Loss1 0.782, Train_accy 69.86
2024-08-02 20:02:57,006 [foster.py] => SNet: Task 22, Epoch 14/130 => Loss 30.830,  Loss1 0.782, Train_accy 68.10
2024-08-02 20:03:01,087 [foster.py] => SNet: Task 22, Epoch 15/130 => Loss 30.805,  Loss1 0.782, Train_accy 70.25
2024-08-02 20:03:06,438 [foster.py] => SNet: Task 22, Epoch 16/130 => Loss 30.831,  Loss1 0.782, Train_accy 69.47, Test_accy 60.24
2024-08-02 20:03:10,492 [foster.py] => SNet: Task 22, Epoch 17/130 => Loss 30.866,  Loss1 0.783, Train_accy 69.23
2024-08-02 20:03:14,547 [foster.py] => SNet: Task 22, Epoch 18/130 => Loss 30.813,  Loss1 0.782, Train_accy 69.37
2024-08-02 20:03:18,580 [foster.py] => SNet: Task 22, Epoch 19/130 => Loss 30.810,  Loss1 0.783, Train_accy 70.39
2024-08-02 20:03:22,606 [foster.py] => SNet: Task 22, Epoch 20/130 => Loss 30.847,  Loss1 0.783, Train_accy 70.18
2024-08-02 20:03:27,975 [foster.py] => SNet: Task 22, Epoch 21/130 => Loss 30.792,  Loss1 0.782, Train_accy 70.11, Test_accy 60.07
2024-08-02 20:03:32,000 [foster.py] => SNet: Task 22, Epoch 22/130 => Loss 30.805,  Loss1 0.783, Train_accy 70.95
2024-08-02 20:03:36,045 [foster.py] => SNet: Task 22, Epoch 23/130 => Loss 30.787,  Loss1 0.782, Train_accy 70.11
2024-08-02 20:03:40,081 [foster.py] => SNet: Task 22, Epoch 24/130 => Loss 30.761,  Loss1 0.783, Train_accy 70.81
2024-08-02 20:03:44,105 [foster.py] => SNet: Task 22, Epoch 25/130 => Loss 30.817,  Loss1 0.783, Train_accy 69.82
2024-08-02 20:03:49,457 [foster.py] => SNet: Task 22, Epoch 26/130 => Loss 30.791,  Loss1 0.782, Train_accy 70.04, Test_accy 59.74
2024-08-02 20:03:53,496 [foster.py] => SNet: Task 22, Epoch 27/130 => Loss 30.795,  Loss1 0.783, Train_accy 71.02
2024-08-02 20:03:57,524 [foster.py] => SNet: Task 22, Epoch 28/130 => Loss 30.758,  Loss1 0.783, Train_accy 71.06
2024-08-02 20:04:01,575 [foster.py] => SNet: Task 22, Epoch 29/130 => Loss 30.819,  Loss1 0.783, Train_accy 70.85
2024-08-02 20:04:05,629 [foster.py] => SNet: Task 22, Epoch 30/130 => Loss 30.782,  Loss1 0.782, Train_accy 70.53
2024-08-02 20:04:10,953 [foster.py] => SNet: Task 22, Epoch 31/130 => Loss 30.797,  Loss1 0.782, Train_accy 72.32, Test_accy 60.13
2024-08-02 20:04:15,052 [foster.py] => SNet: Task 22, Epoch 32/130 => Loss 30.874,  Loss1 0.781, Train_accy 70.56
2024-08-02 20:04:19,075 [foster.py] => SNet: Task 22, Epoch 33/130 => Loss 30.834,  Loss1 0.782, Train_accy 71.02
2024-08-02 20:04:23,158 [foster.py] => SNet: Task 22, Epoch 34/130 => Loss 30.838,  Loss1 0.782, Train_accy 69.96
2024-08-02 20:04:27,195 [foster.py] => SNet: Task 22, Epoch 35/130 => Loss 30.803,  Loss1 0.783, Train_accy 71.73
2024-08-02 20:04:32,569 [foster.py] => SNet: Task 22, Epoch 36/130 => Loss 30.806,  Loss1 0.782, Train_accy 71.06, Test_accy 60.37
2024-08-02 20:04:36,610 [foster.py] => SNet: Task 22, Epoch 37/130 => Loss 30.784,  Loss1 0.782, Train_accy 71.65
2024-08-02 20:04:40,636 [foster.py] => SNet: Task 22, Epoch 38/130 => Loss 30.786,  Loss1 0.782, Train_accy 70.95
2024-08-02 20:04:44,668 [foster.py] => SNet: Task 22, Epoch 39/130 => Loss 30.772,  Loss1 0.782, Train_accy 72.01
2024-08-02 20:04:48,698 [foster.py] => SNet: Task 22, Epoch 40/130 => Loss 30.788,  Loss1 0.782, Train_accy 71.87
2024-08-02 20:04:54,053 [foster.py] => SNet: Task 22, Epoch 41/130 => Loss 30.744,  Loss1 0.782, Train_accy 72.11, Test_accy 60.38
2024-08-02 20:04:58,122 [foster.py] => SNet: Task 22, Epoch 42/130 => Loss 30.803,  Loss1 0.782, Train_accy 71.23
2024-08-02 20:05:02,171 [foster.py] => SNet: Task 22, Epoch 43/130 => Loss 30.813,  Loss1 0.782, Train_accy 72.08
2024-08-02 20:05:06,197 [foster.py] => SNet: Task 22, Epoch 44/130 => Loss 30.813,  Loss1 0.782, Train_accy 72.78
2024-08-02 20:05:10,217 [foster.py] => SNet: Task 22, Epoch 45/130 => Loss 30.825,  Loss1 0.781, Train_accy 71.69
2024-08-02 20:05:15,552 [foster.py] => SNet: Task 22, Epoch 46/130 => Loss 30.831,  Loss1 0.782, Train_accy 71.41, Test_accy 60.45
2024-08-02 20:05:19,571 [foster.py] => SNet: Task 22, Epoch 47/130 => Loss 30.796,  Loss1 0.782, Train_accy 72.50
2024-08-02 20:05:23,667 [foster.py] => SNet: Task 22, Epoch 48/130 => Loss 30.793,  Loss1 0.782, Train_accy 72.01
2024-08-02 20:05:27,713 [foster.py] => SNet: Task 22, Epoch 49/130 => Loss 30.832,  Loss1 0.783, Train_accy 73.17
2024-08-02 20:05:31,766 [foster.py] => SNet: Task 22, Epoch 50/130 => Loss 30.758,  Loss1 0.782, Train_accy 72.54
2024-08-02 20:05:37,117 [foster.py] => SNet: Task 22, Epoch 51/130 => Loss 30.793,  Loss1 0.782, Train_accy 71.76, Test_accy 60.31
2024-08-02 20:05:41,154 [foster.py] => SNet: Task 22, Epoch 52/130 => Loss 30.810,  Loss1 0.781, Train_accy 72.61
2024-08-02 20:05:45,178 [foster.py] => SNet: Task 22, Epoch 53/130 => Loss 30.789,  Loss1 0.782, Train_accy 72.43
2024-08-02 20:05:49,227 [foster.py] => SNet: Task 22, Epoch 54/130 => Loss 30.789,  Loss1 0.782, Train_accy 73.31
2024-08-02 20:05:53,264 [foster.py] => SNet: Task 22, Epoch 55/130 => Loss 30.838,  Loss1 0.782, Train_accy 73.77
2024-08-02 20:05:58,628 [foster.py] => SNet: Task 22, Epoch 56/130 => Loss 30.782,  Loss1 0.783, Train_accy 72.82, Test_accy 60.53
2024-08-02 20:06:02,695 [foster.py] => SNet: Task 22, Epoch 57/130 => Loss 30.786,  Loss1 0.782, Train_accy 72.39
2024-08-02 20:06:06,763 [foster.py] => SNet: Task 22, Epoch 58/130 => Loss 30.816,  Loss1 0.782, Train_accy 73.17
2024-08-02 20:06:10,777 [foster.py] => SNet: Task 22, Epoch 59/130 => Loss 30.822,  Loss1 0.782, Train_accy 72.36
2024-08-02 20:06:14,839 [foster.py] => SNet: Task 22, Epoch 60/130 => Loss 30.814,  Loss1 0.782, Train_accy 73.59
2024-08-02 20:06:20,230 [foster.py] => SNet: Task 22, Epoch 61/130 => Loss 30.818,  Loss1 0.782, Train_accy 72.22, Test_accy 60.13
2024-08-02 20:06:24,293 [foster.py] => SNet: Task 22, Epoch 62/130 => Loss 30.825,  Loss1 0.783, Train_accy 72.68
2024-08-02 20:06:28,358 [foster.py] => SNet: Task 22, Epoch 63/130 => Loss 30.799,  Loss1 0.781, Train_accy 70.85
2024-08-02 20:06:32,473 [foster.py] => SNet: Task 22, Epoch 64/130 => Loss 30.825,  Loss1 0.782, Train_accy 72.46
2024-08-02 20:06:36,512 [foster.py] => SNet: Task 22, Epoch 65/130 => Loss 30.786,  Loss1 0.782, Train_accy 72.08
2024-08-02 20:06:41,877 [foster.py] => SNet: Task 22, Epoch 66/130 => Loss 30.815,  Loss1 0.781, Train_accy 73.73, Test_accy 60.00
2024-08-02 20:06:45,945 [foster.py] => SNet: Task 22, Epoch 67/130 => Loss 30.782,  Loss1 0.782, Train_accy 73.06
2024-08-02 20:06:49,971 [foster.py] => SNet: Task 22, Epoch 68/130 => Loss 30.796,  Loss1 0.782, Train_accy 72.85
2024-08-02 20:06:54,020 [foster.py] => SNet: Task 22, Epoch 69/130 => Loss 30.769,  Loss1 0.783, Train_accy 73.73
2024-08-02 20:06:58,054 [foster.py] => SNet: Task 22, Epoch 70/130 => Loss 30.826,  Loss1 0.782, Train_accy 72.78
2024-08-02 20:07:03,426 [foster.py] => SNet: Task 22, Epoch 71/130 => Loss 30.802,  Loss1 0.782, Train_accy 73.10, Test_accy 60.31
2024-08-02 20:07:07,475 [foster.py] => SNet: Task 22, Epoch 72/130 => Loss 30.806,  Loss1 0.782, Train_accy 73.49
2024-08-02 20:07:11,533 [foster.py] => SNet: Task 22, Epoch 73/130 => Loss 30.807,  Loss1 0.782, Train_accy 73.87
2024-08-02 20:07:15,571 [foster.py] => SNet: Task 22, Epoch 74/130 => Loss 30.798,  Loss1 0.782, Train_accy 72.11
2024-08-02 20:07:19,623 [foster.py] => SNet: Task 22, Epoch 75/130 => Loss 30.776,  Loss1 0.782, Train_accy 72.71
2024-08-02 20:07:24,986 [foster.py] => SNet: Task 22, Epoch 76/130 => Loss 30.841,  Loss1 0.782, Train_accy 72.85, Test_accy 60.13
2024-08-02 20:07:29,023 [foster.py] => SNet: Task 22, Epoch 77/130 => Loss 30.797,  Loss1 0.782, Train_accy 73.63
2024-08-02 20:07:33,037 [foster.py] => SNet: Task 22, Epoch 78/130 => Loss 30.799,  Loss1 0.782, Train_accy 72.78
2024-08-02 20:07:37,074 [foster.py] => SNet: Task 22, Epoch 79/130 => Loss 30.813,  Loss1 0.782, Train_accy 72.01
2024-08-02 20:07:41,111 [foster.py] => SNet: Task 22, Epoch 80/130 => Loss 30.824,  Loss1 0.782, Train_accy 72.22
2024-08-02 20:07:46,533 [foster.py] => SNet: Task 22, Epoch 81/130 => Loss 30.791,  Loss1 0.782, Train_accy 73.31, Test_accy 60.24
2024-08-02 20:07:50,619 [foster.py] => SNet: Task 22, Epoch 82/130 => Loss 30.809,  Loss1 0.782, Train_accy 72.46
2024-08-02 20:07:54,656 [foster.py] => SNet: Task 22, Epoch 83/130 => Loss 30.799,  Loss1 0.782, Train_accy 72.39
2024-08-02 20:07:58,687 [foster.py] => SNet: Task 22, Epoch 84/130 => Loss 30.752,  Loss1 0.782, Train_accy 72.85
2024-08-02 20:08:02,753 [foster.py] => SNet: Task 22, Epoch 85/130 => Loss 30.792,  Loss1 0.783, Train_accy 72.75
2024-08-02 20:08:08,075 [foster.py] => SNet: Task 22, Epoch 86/130 => Loss 30.823,  Loss1 0.782, Train_accy 72.92, Test_accy 60.48
2024-08-02 20:08:12,097 [foster.py] => SNet: Task 22, Epoch 87/130 => Loss 30.814,  Loss1 0.783, Train_accy 72.92
2024-08-02 20:08:16,151 [foster.py] => SNet: Task 22, Epoch 88/130 => Loss 30.754,  Loss1 0.782, Train_accy 73.70
2024-08-02 20:08:20,178 [foster.py] => SNet: Task 22, Epoch 89/130 => Loss 30.818,  Loss1 0.782, Train_accy 74.26
2024-08-02 20:08:24,245 [foster.py] => SNet: Task 22, Epoch 90/130 => Loss 30.777,  Loss1 0.782, Train_accy 74.47
2024-08-02 20:08:29,617 [foster.py] => SNet: Task 22, Epoch 91/130 => Loss 30.855,  Loss1 0.783, Train_accy 72.54, Test_accy 60.37
2024-08-02 20:08:33,668 [foster.py] => SNet: Task 22, Epoch 92/130 => Loss 30.807,  Loss1 0.782, Train_accy 73.59
2024-08-02 20:08:37,726 [foster.py] => SNet: Task 22, Epoch 93/130 => Loss 30.795,  Loss1 0.782, Train_accy 73.20
2024-08-02 20:08:41,751 [foster.py] => SNet: Task 22, Epoch 94/130 => Loss 30.804,  Loss1 0.782, Train_accy 74.15
2024-08-02 20:08:45,776 [foster.py] => SNet: Task 22, Epoch 95/130 => Loss 30.776,  Loss1 0.782, Train_accy 73.52
2024-08-02 20:08:51,137 [foster.py] => SNet: Task 22, Epoch 96/130 => Loss 30.777,  Loss1 0.782, Train_accy 74.08, Test_accy 60.39
2024-08-02 20:08:55,273 [foster.py] => SNet: Task 22, Epoch 97/130 => Loss 30.823,  Loss1 0.782, Train_accy 73.31
2024-08-02 20:08:59,311 [foster.py] => SNet: Task 22, Epoch 98/130 => Loss 30.824,  Loss1 0.782, Train_accy 71.97
2024-08-02 20:09:03,358 [foster.py] => SNet: Task 22, Epoch 99/130 => Loss 30.804,  Loss1 0.781, Train_accy 72.96
2024-08-02 20:09:07,438 [foster.py] => SNet: Task 22, Epoch 100/130 => Loss 30.776,  Loss1 0.782, Train_accy 73.77
2024-08-02 20:09:12,815 [foster.py] => SNet: Task 22, Epoch 101/130 => Loss 30.833,  Loss1 0.781, Train_accy 73.80, Test_accy 60.60
2024-08-02 20:09:16,888 [foster.py] => SNet: Task 22, Epoch 102/130 => Loss 30.795,  Loss1 0.783, Train_accy 74.12
2024-08-02 20:09:20,942 [foster.py] => SNet: Task 22, Epoch 103/130 => Loss 30.787,  Loss1 0.782, Train_accy 72.89
2024-08-02 20:09:25,002 [foster.py] => SNet: Task 22, Epoch 104/130 => Loss 30.771,  Loss1 0.782, Train_accy 73.98
2024-08-02 20:09:29,047 [foster.py] => SNet: Task 22, Epoch 105/130 => Loss 30.805,  Loss1 0.782, Train_accy 73.80
2024-08-02 20:09:34,443 [foster.py] => SNet: Task 22, Epoch 106/130 => Loss 30.798,  Loss1 0.782, Train_accy 73.80, Test_accy 60.46
2024-08-02 20:09:38,513 [foster.py] => SNet: Task 22, Epoch 107/130 => Loss 30.798,  Loss1 0.782, Train_accy 73.20
2024-08-02 20:09:42,550 [foster.py] => SNet: Task 22, Epoch 108/130 => Loss 30.796,  Loss1 0.782, Train_accy 72.78
2024-08-02 20:09:46,625 [foster.py] => SNet: Task 22, Epoch 109/130 => Loss 30.821,  Loss1 0.782, Train_accy 73.98
2024-08-02 20:09:50,666 [foster.py] => SNet: Task 22, Epoch 110/130 => Loss 30.784,  Loss1 0.782, Train_accy 73.94
2024-08-02 20:09:56,029 [foster.py] => SNet: Task 22, Epoch 111/130 => Loss 30.794,  Loss1 0.782, Train_accy 72.54, Test_accy 60.52
2024-08-02 20:10:00,084 [foster.py] => SNet: Task 22, Epoch 112/130 => Loss 30.806,  Loss1 0.782, Train_accy 72.08
2024-08-02 20:10:04,143 [foster.py] => SNet: Task 22, Epoch 113/130 => Loss 30.766,  Loss1 0.783, Train_accy 73.13
2024-08-02 20:10:08,259 [foster.py] => SNet: Task 22, Epoch 114/130 => Loss 30.817,  Loss1 0.782, Train_accy 73.31
2024-08-02 20:10:12,303 [foster.py] => SNet: Task 22, Epoch 115/130 => Loss 30.809,  Loss1 0.782, Train_accy 74.26
2024-08-02 20:10:17,618 [foster.py] => SNet: Task 22, Epoch 116/130 => Loss 30.836,  Loss1 0.781, Train_accy 72.82, Test_accy 60.52
2024-08-02 20:10:21,678 [foster.py] => SNet: Task 22, Epoch 117/130 => Loss 30.765,  Loss1 0.782, Train_accy 73.17
2024-08-02 20:10:25,675 [foster.py] => SNet: Task 22, Epoch 118/130 => Loss 30.786,  Loss1 0.782, Train_accy 74.82
2024-08-02 20:10:29,736 [foster.py] => SNet: Task 22, Epoch 119/130 => Loss 30.804,  Loss1 0.783, Train_accy 73.91
2024-08-02 20:10:33,788 [foster.py] => SNet: Task 22, Epoch 120/130 => Loss 30.817,  Loss1 0.782, Train_accy 72.71
2024-08-02 20:10:39,124 [foster.py] => SNet: Task 22, Epoch 121/130 => Loss 30.782,  Loss1 0.782, Train_accy 73.98, Test_accy 60.45
2024-08-02 20:10:43,174 [foster.py] => SNet: Task 22, Epoch 122/130 => Loss 30.769,  Loss1 0.782, Train_accy 73.56
2024-08-02 20:10:47,216 [foster.py] => SNet: Task 22, Epoch 123/130 => Loss 30.742,  Loss1 0.782, Train_accy 74.30
2024-08-02 20:10:51,253 [foster.py] => SNet: Task 22, Epoch 124/130 => Loss 30.773,  Loss1 0.782, Train_accy 73.87
2024-08-02 20:10:55,308 [foster.py] => SNet: Task 22, Epoch 125/130 => Loss 30.827,  Loss1 0.782, Train_accy 73.77
2024-08-02 20:11:00,665 [foster.py] => SNet: Task 22, Epoch 126/130 => Loss 30.813,  Loss1 0.782, Train_accy 73.87, Test_accy 60.45
2024-08-02 20:11:04,686 [foster.py] => SNet: Task 22, Epoch 127/130 => Loss 30.817,  Loss1 0.782, Train_accy 74.30
2024-08-02 20:11:08,708 [foster.py] => SNet: Task 22, Epoch 128/130 => Loss 30.773,  Loss1 0.782, Train_accy 73.63
2024-08-02 20:11:12,740 [foster.py] => SNet: Task 22, Epoch 129/130 => Loss 30.777,  Loss1 0.782, Train_accy 73.59
2024-08-02 20:11:16,836 [foster.py] => SNet: Task 22, Epoch 130/130 => Loss 30.769,  Loss1 0.782, Train_accy 73.03
2024-08-02 20:11:16,837 [foster.py] => do not weight align student!
2024-08-02 20:11:18,135 [foster.py] => darknet eval: 
2024-08-02 20:11:18,136 [foster.py] => CNN top1 curve: 60.5
2024-08-02 20:11:18,136 [foster.py] => CNN top5 curve: 85.49
2024-08-02 20:11:18,136 [foster.py] => CNN top1 平均值: 60.50
2024-08-02 20:11:18,143 [foster.py] => timees : 1344.8047931194305
2024-08-02 20:11:18,144 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 20:11:46,602 [foster.py] => Exemplar size: 1880
2024-08-02 20:11:46,603 [trainer.py] => CNN: {'total': 61.26, '00-09': 68.0, '10-19': 49.4, '20-29': 65.8, '30-39': 60.1, '40-49': 64.7, '50-59': 49.0, '60-69': 61.3, '70-79': 61.8, '80-89': 68.4, '90-99': 68.25, 'old': 61.39, 'new': 55.0}
2024-08-02 20:11:46,603 [trainer.py] => NME: {'total': 55.7, '00-09': 55.2, '10-19': 40.4, '20-29': 59.6, '30-39': 51.6, '40-49': 57.1, '50-59': 45.2, '60-69': 60.6, '70-79': 63.5, '80-89': 63.0, '90-99': 68.5, 'old': 55.27, 'new': 75.5}
2024-08-02 20:11:46,604 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13, 62.75, 61.26]
2024-08-02 20:11:46,604 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99, 86.89, 85.94]
2024-08-02 20:11:46,604 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09, 57.52, 55.7]
2024-08-02 20:11:46,607 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79, 83.43, 81.69]

2024-08-02 20:11:46,607 [trainer.py] => CNN top1 平均值: 70.90
2024-08-02 20:11:46,610 [trainer.py] => All params: 1178764
2024-08-02 20:11:46,613 [trainer.py] => Trainable params: 595510
2024-08-02 20:11:46,674 [foster.py] => Learning on 94-96
2024-08-02 20:11:46,677 [foster.py] => All params: 1179282
2024-08-02 20:11:46,680 [foster.py] => Trainable params: 595898
2024-08-02 20:11:46,724 [foster.py] => per cls weights : [1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489 1.00952489
 1.00952489 1.00952489 1.00952489 1.00952489 0.55233035 0.55233035]
2024-08-02 20:11:49,708 [foster.py] => Task 23, Epoch 1/170 => Loss 5.428, Loss_clf 0.875, Loss_fe 1.897, Loss_kd 2.598, Train_accy 69.93
2024-08-02 20:11:54,721 [foster.py] => Task 23, Epoch 2/170 => Loss 3.921, Loss_clf 0.583, Loss_fe 0.696, Loss_kd 2.585, Train_accy 76.77, Test_accy 59.16
2024-08-02 20:11:59,776 [foster.py] => Task 23, Epoch 3/170 => Loss 3.652, Loss_clf 0.490, Loss_fe 0.571, Loss_kd 2.536, Train_accy 79.65, Test_accy 59.61
2024-08-02 20:12:04,830 [foster.py] => Task 23, Epoch 4/170 => Loss 3.638, Loss_clf 0.493, Loss_fe 0.528, Loss_kd 2.560, Train_accy 79.93, Test_accy 59.53
2024-08-02 20:12:09,897 [foster.py] => Task 23, Epoch 5/170 => Loss 3.557, Loss_clf 0.457, Loss_fe 0.480, Loss_kd 2.563, Train_accy 79.83, Test_accy 60.14
2024-08-02 20:12:12,797 [foster.py] => Task 23, Epoch 6/170 => Loss 3.492, Loss_clf 0.456, Loss_fe 0.444, Loss_kd 2.537, Train_accy 80.73
2024-08-02 20:12:17,864 [foster.py] => Task 23, Epoch 7/170 => Loss 3.527, Loss_clf 0.480, Loss_fe 0.432, Loss_kd 2.558, Train_accy 80.03, Test_accy 59.77
2024-08-02 20:12:22,927 [foster.py] => Task 23, Epoch 8/170 => Loss 3.429, Loss_clf 0.439, Loss_fe 0.405, Loss_kd 2.529, Train_accy 81.39, Test_accy 60.02
2024-08-02 20:12:28,031 [foster.py] => Task 23, Epoch 9/170 => Loss 3.525, Loss_clf 0.489, Loss_fe 0.396, Loss_kd 2.583, Train_accy 80.94, Test_accy 59.99
2024-08-02 20:12:33,053 [foster.py] => Task 23, Epoch 10/170 => Loss 3.469, Loss_clf 0.451, Loss_fe 0.391, Loss_kd 2.571, Train_accy 82.43, Test_accy 59.95
2024-08-02 20:12:35,927 [foster.py] => Task 23, Epoch 11/170 => Loss 3.412, Loss_clf 0.439, Loss_fe 0.361, Loss_kd 2.555, Train_accy 81.04
2024-08-02 20:12:41,039 [foster.py] => Task 23, Epoch 12/170 => Loss 3.397, Loss_clf 0.433, Loss_fe 0.368, Loss_kd 2.541, Train_accy 81.28, Test_accy 60.02
2024-08-02 20:12:46,138 [foster.py] => Task 23, Epoch 13/170 => Loss 3.418, Loss_clf 0.440, Loss_fe 0.378, Loss_kd 2.544, Train_accy 81.01, Test_accy 59.90
2024-08-02 20:12:51,213 [foster.py] => Task 23, Epoch 14/170 => Loss 3.415, Loss_clf 0.423, Loss_fe 0.357, Loss_kd 2.579, Train_accy 82.50, Test_accy 59.73
2024-08-02 20:12:56,262 [foster.py] => Task 23, Epoch 15/170 => Loss 3.327, Loss_clf 0.395, Loss_fe 0.341, Loss_kd 2.536, Train_accy 82.57, Test_accy 59.18
2024-08-02 20:12:59,218 [foster.py] => Task 23, Epoch 16/170 => Loss 3.388, Loss_clf 0.428, Loss_fe 0.346, Loss_kd 2.558, Train_accy 82.74
2024-08-02 20:13:04,350 [foster.py] => Task 23, Epoch 17/170 => Loss 3.315, Loss_clf 0.404, Loss_fe 0.319, Loss_kd 2.535, Train_accy 82.71, Test_accy 58.08
2024-08-02 20:13:09,454 [foster.py] => Task 23, Epoch 18/170 => Loss 3.398, Loss_clf 0.440, Loss_fe 0.346, Loss_kd 2.555, Train_accy 81.01, Test_accy 59.70
2024-08-02 20:13:14,445 [foster.py] => Task 23, Epoch 19/170 => Loss 3.323, Loss_clf 0.423, Loss_fe 0.310, Loss_kd 2.533, Train_accy 82.95, Test_accy 60.09
2024-08-02 20:13:19,459 [foster.py] => Task 23, Epoch 20/170 => Loss 3.392, Loss_clf 0.450, Loss_fe 0.311, Loss_kd 2.574, Train_accy 82.15, Test_accy 60.05
2024-08-02 20:13:22,448 [foster.py] => Task 23, Epoch 21/170 => Loss 3.314, Loss_clf 0.412, Loss_fe 0.318, Loss_kd 2.529, Train_accy 83.12
2024-08-02 20:13:27,602 [foster.py] => Task 23, Epoch 22/170 => Loss 3.348, Loss_clf 0.439, Loss_fe 0.298, Loss_kd 2.556, Train_accy 82.81, Test_accy 59.96
2024-08-02 20:13:32,608 [foster.py] => Task 23, Epoch 23/170 => Loss 3.294, Loss_clf 0.402, Loss_fe 0.297, Loss_kd 2.539, Train_accy 83.40, Test_accy 59.83
2024-08-02 20:13:37,607 [foster.py] => Task 23, Epoch 24/170 => Loss 3.318, Loss_clf 0.418, Loss_fe 0.315, Loss_kd 2.529, Train_accy 83.02, Test_accy 58.81
2024-08-02 20:13:42,692 [foster.py] => Task 23, Epoch 25/170 => Loss 3.353, Loss_clf 0.429, Loss_fe 0.294, Loss_kd 2.573, Train_accy 83.68, Test_accy 59.91
2024-08-02 20:13:45,601 [foster.py] => Task 23, Epoch 26/170 => Loss 3.394, Loss_clf 0.440, Loss_fe 0.315, Loss_kd 2.582, Train_accy 82.19
2024-08-02 20:13:50,606 [foster.py] => Task 23, Epoch 27/170 => Loss 3.233, Loss_clf 0.382, Loss_fe 0.263, Loss_kd 2.532, Train_accy 84.48, Test_accy 60.21
2024-08-02 20:13:55,638 [foster.py] => Task 23, Epoch 28/170 => Loss 3.299, Loss_clf 0.415, Loss_fe 0.285, Loss_kd 2.543, Train_accy 83.51, Test_accy 59.51
2024-08-02 20:14:00,646 [foster.py] => Task 23, Epoch 29/170 => Loss 3.279, Loss_clf 0.390, Loss_fe 0.277, Loss_kd 2.556, Train_accy 83.54, Test_accy 60.38
2024-08-02 20:14:05,701 [foster.py] => Task 23, Epoch 30/170 => Loss 3.286, Loss_clf 0.407, Loss_fe 0.263, Loss_kd 2.559, Train_accy 84.24, Test_accy 60.41
2024-08-02 20:14:08,630 [foster.py] => Task 23, Epoch 31/170 => Loss 3.278, Loss_clf 0.387, Loss_fe 0.261, Loss_kd 2.573, Train_accy 84.79
2024-08-02 20:14:13,666 [foster.py] => Task 23, Epoch 32/170 => Loss 3.312, Loss_clf 0.425, Loss_fe 0.273, Loss_kd 2.558, Train_accy 83.99, Test_accy 60.09
2024-08-02 20:14:18,732 [foster.py] => Task 23, Epoch 33/170 => Loss 3.294, Loss_clf 0.403, Loss_fe 0.265, Loss_kd 2.570, Train_accy 83.19, Test_accy 60.32
2024-08-02 20:14:23,751 [foster.py] => Task 23, Epoch 34/170 => Loss 3.299, Loss_clf 0.422, Loss_fe 0.249, Loss_kd 2.571, Train_accy 83.85, Test_accy 60.49
2024-08-02 20:14:28,743 [foster.py] => Task 23, Epoch 35/170 => Loss 3.239, Loss_clf 0.386, Loss_fe 0.263, Loss_kd 2.535, Train_accy 84.65, Test_accy 59.95
2024-08-02 20:14:31,698 [foster.py] => Task 23, Epoch 36/170 => Loss 3.287, Loss_clf 0.397, Loss_fe 0.259, Loss_kd 2.574, Train_accy 84.31
2024-08-02 20:14:36,762 [foster.py] => Task 23, Epoch 37/170 => Loss 3.256, Loss_clf 0.390, Loss_fe 0.252, Loss_kd 2.558, Train_accy 85.10, Test_accy 60.10
2024-08-02 20:14:41,822 [foster.py] => Task 23, Epoch 38/170 => Loss 3.236, Loss_clf 0.389, Loss_fe 0.236, Loss_kd 2.555, Train_accy 83.92, Test_accy 60.08
2024-08-02 20:14:46,879 [foster.py] => Task 23, Epoch 39/170 => Loss 3.224, Loss_clf 0.380, Loss_fe 0.249, Loss_kd 2.540, Train_accy 84.27, Test_accy 59.86
2024-08-02 20:14:51,947 [foster.py] => Task 23, Epoch 40/170 => Loss 3.224, Loss_clf 0.382, Loss_fe 0.243, Loss_kd 2.543, Train_accy 84.34, Test_accy 59.84
2024-08-02 20:14:54,982 [foster.py] => Task 23, Epoch 41/170 => Loss 3.271, Loss_clf 0.399, Loss_fe 0.250, Loss_kd 2.565, Train_accy 84.69
2024-08-02 20:15:00,023 [foster.py] => Task 23, Epoch 42/170 => Loss 3.313, Loss_clf 0.415, Loss_fe 0.273, Loss_kd 2.570, Train_accy 83.85, Test_accy 59.56
2024-08-02 20:15:05,115 [foster.py] => Task 23, Epoch 43/170 => Loss 3.215, Loss_clf 0.397, Loss_fe 0.237, Loss_kd 2.526, Train_accy 83.89, Test_accy 60.16
2024-08-02 20:15:10,188 [foster.py] => Task 23, Epoch 44/170 => Loss 3.199, Loss_clf 0.373, Loss_fe 0.232, Loss_kd 2.538, Train_accy 85.21, Test_accy 60.25
2024-08-02 20:15:15,269 [foster.py] => Task 23, Epoch 45/170 => Loss 3.176, Loss_clf 0.367, Loss_fe 0.216, Loss_kd 2.537, Train_accy 85.24, Test_accy 60.07
2024-08-02 20:15:18,203 [foster.py] => Task 23, Epoch 46/170 => Loss 3.317, Loss_clf 0.420, Loss_fe 0.247, Loss_kd 2.593, Train_accy 83.96
2024-08-02 20:15:23,265 [foster.py] => Task 23, Epoch 47/170 => Loss 3.244, Loss_clf 0.391, Loss_fe 0.227, Loss_kd 2.569, Train_accy 84.34, Test_accy 60.30
2024-08-02 20:15:28,318 [foster.py] => Task 23, Epoch 48/170 => Loss 3.215, Loss_clf 0.383, Loss_fe 0.205, Loss_kd 2.571, Train_accy 85.31, Test_accy 60.24
2024-08-02 20:15:33,345 [foster.py] => Task 23, Epoch 49/170 => Loss 3.232, Loss_clf 0.379, Loss_fe 0.226, Loss_kd 2.571, Train_accy 84.90, Test_accy 60.30
2024-08-02 20:15:38,389 [foster.py] => Task 23, Epoch 50/170 => Loss 3.218, Loss_clf 0.375, Loss_fe 0.223, Loss_kd 2.563, Train_accy 85.52, Test_accy 60.04
2024-08-02 20:15:41,339 [foster.py] => Task 23, Epoch 51/170 => Loss 3.235, Loss_clf 0.389, Loss_fe 0.222, Loss_kd 2.567, Train_accy 84.72
2024-08-02 20:15:46,449 [foster.py] => Task 23, Epoch 52/170 => Loss 3.292, Loss_clf 0.416, Loss_fe 0.233, Loss_kd 2.586, Train_accy 83.54, Test_accy 60.06
2024-08-02 20:15:51,470 [foster.py] => Task 23, Epoch 53/170 => Loss 3.160, Loss_clf 0.356, Loss_fe 0.200, Loss_kd 2.548, Train_accy 87.01, Test_accy 60.24
2024-08-02 20:15:56,537 [foster.py] => Task 23, Epoch 54/170 => Loss 3.195, Loss_clf 0.371, Loss_fe 0.203, Loss_kd 2.565, Train_accy 85.83, Test_accy 60.17
2024-08-02 20:16:01,620 [foster.py] => Task 23, Epoch 55/170 => Loss 3.142, Loss_clf 0.359, Loss_fe 0.200, Loss_kd 2.527, Train_accy 86.08, Test_accy 60.29
2024-08-02 20:16:04,547 [foster.py] => Task 23, Epoch 56/170 => Loss 3.119, Loss_clf 0.343, Loss_fe 0.194, Loss_kd 2.527, Train_accy 87.71
2024-08-02 20:16:09,668 [foster.py] => Task 23, Epoch 57/170 => Loss 3.143, Loss_clf 0.354, Loss_fe 0.181, Loss_kd 2.552, Train_accy 86.98, Test_accy 59.60
2024-08-02 20:16:14,678 [foster.py] => Task 23, Epoch 58/170 => Loss 3.166, Loss_clf 0.365, Loss_fe 0.178, Loss_kd 2.566, Train_accy 86.53, Test_accy 60.33
2024-08-02 20:16:19,710 [foster.py] => Task 23, Epoch 59/170 => Loss 3.170, Loss_clf 0.370, Loss_fe 0.188, Loss_kd 2.557, Train_accy 85.97, Test_accy 60.31
2024-08-02 20:16:24,763 [foster.py] => Task 23, Epoch 60/170 => Loss 3.144, Loss_clf 0.366, Loss_fe 0.185, Loss_kd 2.538, Train_accy 86.56, Test_accy 60.04
2024-08-02 20:16:27,658 [foster.py] => Task 23, Epoch 61/170 => Loss 3.105, Loss_clf 0.341, Loss_fe 0.188, Loss_kd 2.521, Train_accy 86.60
2024-08-02 20:16:32,801 [foster.py] => Task 23, Epoch 62/170 => Loss 3.163, Loss_clf 0.363, Loss_fe 0.196, Loss_kd 2.548, Train_accy 86.18, Test_accy 60.42
2024-08-02 20:16:37,854 [foster.py] => Task 23, Epoch 63/170 => Loss 3.179, Loss_clf 0.355, Loss_fe 0.199, Loss_kd 2.568, Train_accy 87.29, Test_accy 60.31
2024-08-02 20:16:42,920 [foster.py] => Task 23, Epoch 64/170 => Loss 3.166, Loss_clf 0.354, Loss_fe 0.189, Loss_kd 2.567, Train_accy 86.53, Test_accy 60.67
2024-08-02 20:16:47,986 [foster.py] => Task 23, Epoch 65/170 => Loss 3.197, Loss_clf 0.380, Loss_fe 0.195, Loss_kd 2.565, Train_accy 85.49, Test_accy 59.92
2024-08-02 20:16:50,910 [foster.py] => Task 23, Epoch 66/170 => Loss 3.139, Loss_clf 0.357, Loss_fe 0.179, Loss_kd 2.548, Train_accy 86.77
2024-08-02 20:16:55,967 [foster.py] => Task 23, Epoch 67/170 => Loss 3.152, Loss_clf 0.363, Loss_fe 0.187, Loss_kd 2.547, Train_accy 85.35, Test_accy 60.44
2024-08-02 20:17:00,988 [foster.py] => Task 23, Epoch 68/170 => Loss 3.088, Loss_clf 0.321, Loss_fe 0.177, Loss_kd 2.535, Train_accy 86.49, Test_accy 60.53
2024-08-02 20:17:06,011 [foster.py] => Task 23, Epoch 69/170 => Loss 3.130, Loss_clf 0.354, Loss_fe 0.169, Loss_kd 2.551, Train_accy 85.83, Test_accy 60.28
2024-08-02 20:17:11,099 [foster.py] => Task 23, Epoch 70/170 => Loss 3.132, Loss_clf 0.340, Loss_fe 0.181, Loss_kd 2.555, Train_accy 86.84, Test_accy 60.38
2024-08-02 20:17:14,024 [foster.py] => Task 23, Epoch 71/170 => Loss 3.177, Loss_clf 0.377, Loss_fe 0.162, Loss_kd 2.582, Train_accy 85.97
2024-08-02 20:17:19,066 [foster.py] => Task 23, Epoch 72/170 => Loss 3.110, Loss_clf 0.344, Loss_fe 0.166, Loss_kd 2.544, Train_accy 86.77, Test_accy 60.38
2024-08-02 20:17:24,098 [foster.py] => Task 23, Epoch 73/170 => Loss 3.182, Loss_clf 0.375, Loss_fe 0.175, Loss_kd 2.575, Train_accy 85.87, Test_accy 60.32
2024-08-02 20:17:29,252 [foster.py] => Task 23, Epoch 74/170 => Loss 3.134, Loss_clf 0.353, Loss_fe 0.175, Loss_kd 2.550, Train_accy 86.35, Test_accy 60.32
2024-08-02 20:17:34,381 [foster.py] => Task 23, Epoch 75/170 => Loss 3.139, Loss_clf 0.354, Loss_fe 0.179, Loss_kd 2.549, Train_accy 86.81, Test_accy 60.29
2024-08-02 20:17:37,306 [foster.py] => Task 23, Epoch 76/170 => Loss 3.134, Loss_clf 0.358, Loss_fe 0.180, Loss_kd 2.541, Train_accy 86.67
2024-08-02 20:17:42,356 [foster.py] => Task 23, Epoch 77/170 => Loss 3.122, Loss_clf 0.340, Loss_fe 0.169, Loss_kd 2.557, Train_accy 87.33, Test_accy 60.43
2024-08-02 20:17:47,468 [foster.py] => Task 23, Epoch 78/170 => Loss 3.167, Loss_clf 0.368, Loss_fe 0.164, Loss_kd 2.579, Train_accy 86.22, Test_accy 60.15
2024-08-02 20:17:52,515 [foster.py] => Task 23, Epoch 79/170 => Loss 3.154, Loss_clf 0.373, Loss_fe 0.162, Loss_kd 2.563, Train_accy 86.81, Test_accy 60.05
2024-08-02 20:17:57,548 [foster.py] => Task 23, Epoch 80/170 => Loss 3.174, Loss_clf 0.368, Loss_fe 0.173, Loss_kd 2.576, Train_accy 86.53, Test_accy 60.45
2024-08-02 20:18:00,476 [foster.py] => Task 23, Epoch 81/170 => Loss 3.121, Loss_clf 0.348, Loss_fe 0.159, Loss_kd 2.558, Train_accy 87.64
2024-08-02 20:18:05,484 [foster.py] => Task 23, Epoch 82/170 => Loss 3.106, Loss_clf 0.340, Loss_fe 0.140, Loss_kd 2.570, Train_accy 86.67, Test_accy 60.23
2024-08-02 20:18:10,502 [foster.py] => Task 23, Epoch 83/170 => Loss 3.098, Loss_clf 0.330, Loss_fe 0.147, Loss_kd 2.564, Train_accy 87.78, Test_accy 60.49
2024-08-02 20:18:15,628 [foster.py] => Task 23, Epoch 84/170 => Loss 3.084, Loss_clf 0.342, Loss_fe 0.151, Loss_kd 2.535, Train_accy 87.74, Test_accy 60.56
2024-08-02 20:18:20,696 [foster.py] => Task 23, Epoch 85/170 => Loss 3.165, Loss_clf 0.359, Loss_fe 0.162, Loss_kd 2.587, Train_accy 86.94, Test_accy 60.32
2024-08-02 20:18:23,672 [foster.py] => Task 23, Epoch 86/170 => Loss 3.142, Loss_clf 0.359, Loss_fe 0.163, Loss_kd 2.564, Train_accy 86.81
2024-08-02 20:18:28,779 [foster.py] => Task 23, Epoch 87/170 => Loss 3.138, Loss_clf 0.358, Loss_fe 0.148, Loss_kd 2.576, Train_accy 87.67, Test_accy 60.58
2024-08-02 20:18:33,849 [foster.py] => Task 23, Epoch 88/170 => Loss 3.128, Loss_clf 0.347, Loss_fe 0.152, Loss_kd 2.572, Train_accy 87.01, Test_accy 60.44
2024-08-02 20:18:39,009 [foster.py] => Task 23, Epoch 89/170 => Loss 3.075, Loss_clf 0.334, Loss_fe 0.142, Loss_kd 2.544, Train_accy 86.88, Test_accy 60.61
2024-08-02 20:18:44,172 [foster.py] => Task 23, Epoch 90/170 => Loss 3.089, Loss_clf 0.335, Loss_fe 0.148, Loss_kd 2.550, Train_accy 88.51, Test_accy 60.33
2024-08-02 20:18:47,188 [foster.py] => Task 23, Epoch 91/170 => Loss 3.123, Loss_clf 0.351, Loss_fe 0.141, Loss_kd 2.573, Train_accy 87.33
2024-08-02 20:18:52,312 [foster.py] => Task 23, Epoch 92/170 => Loss 3.083, Loss_clf 0.329, Loss_fe 0.130, Loss_kd 2.567, Train_accy 87.92, Test_accy 60.67
2024-08-02 20:18:57,386 [foster.py] => Task 23, Epoch 93/170 => Loss 3.100, Loss_clf 0.358, Loss_fe 0.139, Loss_kd 2.547, Train_accy 87.36, Test_accy 60.66
2024-08-02 20:19:02,434 [foster.py] => Task 23, Epoch 94/170 => Loss 3.029, Loss_clf 0.306, Loss_fe 0.121, Loss_kd 2.546, Train_accy 88.51, Test_accy 60.51
2024-08-02 20:19:07,465 [foster.py] => Task 23, Epoch 95/170 => Loss 3.073, Loss_clf 0.349, Loss_fe 0.127, Loss_kd 2.541, Train_accy 86.32, Test_accy 60.45
2024-08-02 20:19:10,413 [foster.py] => Task 23, Epoch 96/170 => Loss 3.175, Loss_clf 0.375, Loss_fe 0.149, Loss_kd 2.595, Train_accy 87.05
2024-08-02 20:19:15,437 [foster.py] => Task 23, Epoch 97/170 => Loss 3.061, Loss_clf 0.325, Loss_fe 0.125, Loss_kd 2.556, Train_accy 87.60, Test_accy 60.57
2024-08-02 20:19:20,457 [foster.py] => Task 23, Epoch 98/170 => Loss 3.086, Loss_clf 0.340, Loss_fe 0.141, Loss_kd 2.549, Train_accy 87.53, Test_accy 60.36
2024-08-02 20:19:25,457 [foster.py] => Task 23, Epoch 99/170 => Loss 3.094, Loss_clf 0.330, Loss_fe 0.135, Loss_kd 2.574, Train_accy 88.09, Test_accy 60.58
2024-08-02 20:19:30,475 [foster.py] => Task 23, Epoch 100/170 => Loss 3.053, Loss_clf 0.318, Loss_fe 0.131, Loss_kd 2.549, Train_accy 88.12, Test_accy 60.35
2024-08-02 20:19:33,519 [foster.py] => Task 23, Epoch 101/170 => Loss 3.022, Loss_clf 0.321, Loss_fe 0.121, Loss_kd 2.525, Train_accy 89.03
2024-08-02 20:19:38,554 [foster.py] => Task 23, Epoch 102/170 => Loss 3.069, Loss_clf 0.330, Loss_fe 0.124, Loss_kd 2.559, Train_accy 88.26, Test_accy 60.42
2024-08-02 20:19:43,575 [foster.py] => Task 23, Epoch 103/170 => Loss 3.113, Loss_clf 0.356, Loss_fe 0.119, Loss_kd 2.582, Train_accy 86.98, Test_accy 60.75
2024-08-02 20:19:48,738 [foster.py] => Task 23, Epoch 104/170 => Loss 3.014, Loss_clf 0.312, Loss_fe 0.115, Loss_kd 2.531, Train_accy 88.96, Test_accy 60.53
2024-08-02 20:19:53,767 [foster.py] => Task 23, Epoch 105/170 => Loss 3.096, Loss_clf 0.358, Loss_fe 0.135, Loss_kd 2.547, Train_accy 87.95, Test_accy 60.52
2024-08-02 20:19:56,673 [foster.py] => Task 23, Epoch 106/170 => Loss 3.101, Loss_clf 0.337, Loss_fe 0.137, Loss_kd 2.570, Train_accy 88.30
2024-08-02 20:20:01,690 [foster.py] => Task 23, Epoch 107/170 => Loss 3.064, Loss_clf 0.331, Loss_fe 0.117, Loss_kd 2.560, Train_accy 88.72, Test_accy 60.48
2024-08-02 20:20:06,709 [foster.py] => Task 23, Epoch 108/170 => Loss 3.069, Loss_clf 0.332, Loss_fe 0.124, Loss_kd 2.557, Train_accy 87.67, Test_accy 60.60
2024-08-02 20:20:11,730 [foster.py] => Task 23, Epoch 109/170 => Loss 3.035, Loss_clf 0.320, Loss_fe 0.108, Loss_kd 2.551, Train_accy 87.67, Test_accy 60.56
2024-08-02 20:20:16,707 [foster.py] => Task 23, Epoch 110/170 => Loss 3.070, Loss_clf 0.329, Loss_fe 0.111, Loss_kd 2.573, Train_accy 87.92, Test_accy 60.71
2024-08-02 20:20:19,620 [foster.py] => Task 23, Epoch 111/170 => Loss 3.159, Loss_clf 0.375, Loss_fe 0.118, Loss_kd 2.608, Train_accy 86.88
2024-08-02 20:20:24,659 [foster.py] => Task 23, Epoch 112/170 => Loss 3.075, Loss_clf 0.330, Loss_fe 0.113, Loss_kd 2.575, Train_accy 88.02, Test_accy 60.65
2024-08-02 20:20:29,725 [foster.py] => Task 23, Epoch 113/170 => Loss 3.091, Loss_clf 0.358, Loss_fe 0.115, Loss_kd 2.562, Train_accy 87.50, Test_accy 60.53
2024-08-02 20:20:34,727 [foster.py] => Task 23, Epoch 114/170 => Loss 3.082, Loss_clf 0.331, Loss_fe 0.117, Loss_kd 2.578, Train_accy 88.75, Test_accy 60.44
2024-08-02 20:20:39,730 [foster.py] => Task 23, Epoch 115/170 => Loss 2.986, Loss_clf 0.297, Loss_fe 0.106, Loss_kd 2.528, Train_accy 89.06, Test_accy 60.48
2024-08-02 20:20:42,611 [foster.py] => Task 23, Epoch 116/170 => Loss 3.067, Loss_clf 0.338, Loss_fe 0.113, Loss_kd 2.560, Train_accy 88.47
2024-08-02 20:20:47,647 [foster.py] => Task 23, Epoch 117/170 => Loss 3.022, Loss_clf 0.305, Loss_fe 0.096, Loss_kd 2.565, Train_accy 88.85, Test_accy 60.54
2024-08-02 20:20:52,674 [foster.py] => Task 23, Epoch 118/170 => Loss 3.027, Loss_clf 0.314, Loss_fe 0.106, Loss_kd 2.551, Train_accy 88.78, Test_accy 60.57
2024-08-02 20:20:57,703 [foster.py] => Task 23, Epoch 119/170 => Loss 3.027, Loss_clf 0.318, Loss_fe 0.103, Loss_kd 2.550, Train_accy 89.31, Test_accy 60.61
2024-08-02 20:21:02,710 [foster.py] => Task 23, Epoch 120/170 => Loss 3.082, Loss_clf 0.346, Loss_fe 0.124, Loss_kd 2.555, Train_accy 87.85, Test_accy 60.80
2024-08-02 20:21:05,606 [foster.py] => Task 23, Epoch 121/170 => Loss 3.010, Loss_clf 0.302, Loss_fe 0.105, Loss_kd 2.547, Train_accy 89.34
2024-08-02 20:21:10,667 [foster.py] => Task 23, Epoch 122/170 => Loss 3.054, Loss_clf 0.335, Loss_fe 0.101, Loss_kd 2.562, Train_accy 87.88, Test_accy 60.82
2024-08-02 20:21:15,736 [foster.py] => Task 23, Epoch 123/170 => Loss 3.024, Loss_clf 0.314, Loss_fe 0.101, Loss_kd 2.553, Train_accy 88.99, Test_accy 60.61
2024-08-02 20:21:20,799 [foster.py] => Task 23, Epoch 124/170 => Loss 3.018, Loss_clf 0.313, Loss_fe 0.096, Loss_kd 2.553, Train_accy 89.34, Test_accy 60.79
2024-08-02 20:21:25,845 [foster.py] => Task 23, Epoch 125/170 => Loss 3.029, Loss_clf 0.323, Loss_fe 0.103, Loss_kd 2.547, Train_accy 88.58, Test_accy 60.61
2024-08-02 20:21:28,728 [foster.py] => Task 23, Epoch 126/170 => Loss 3.025, Loss_clf 0.316, Loss_fe 0.090, Loss_kd 2.563, Train_accy 89.48
2024-08-02 20:21:33,785 [foster.py] => Task 23, Epoch 127/170 => Loss 3.065, Loss_clf 0.323, Loss_fe 0.113, Loss_kd 2.573, Train_accy 89.31, Test_accy 60.71
2024-08-02 20:21:38,779 [foster.py] => Task 23, Epoch 128/170 => Loss 2.983, Loss_clf 0.293, Loss_fe 0.078, Loss_kd 2.556, Train_accy 89.20, Test_accy 60.79
2024-08-02 20:21:43,830 [foster.py] => Task 23, Epoch 129/170 => Loss 3.031, Loss_clf 0.327, Loss_fe 0.097, Loss_kd 2.551, Train_accy 88.26, Test_accy 60.65
2024-08-02 20:21:48,902 [foster.py] => Task 23, Epoch 130/170 => Loss 2.999, Loss_clf 0.294, Loss_fe 0.099, Loss_kd 2.550, Train_accy 89.51, Test_accy 60.77
2024-08-02 20:21:51,768 [foster.py] => Task 23, Epoch 131/170 => Loss 2.997, Loss_clf 0.304, Loss_fe 0.088, Loss_kd 2.550, Train_accy 90.07
2024-08-02 20:21:56,905 [foster.py] => Task 23, Epoch 132/170 => Loss 3.055, Loss_clf 0.336, Loss_fe 0.109, Loss_kd 2.555, Train_accy 88.75, Test_accy 60.79
2024-08-02 20:22:01,961 [foster.py] => Task 23, Epoch 133/170 => Loss 2.972, Loss_clf 0.295, Loss_fe 0.078, Loss_kd 2.544, Train_accy 89.72, Test_accy 60.71
2024-08-02 20:22:06,957 [foster.py] => Task 23, Epoch 134/170 => Loss 3.032, Loss_clf 0.332, Loss_fe 0.101, Loss_kd 2.542, Train_accy 88.92, Test_accy 60.66
2024-08-02 20:22:11,990 [foster.py] => Task 23, Epoch 135/170 => Loss 2.990, Loss_clf 0.318, Loss_fe 0.078, Loss_kd 2.538, Train_accy 90.07, Test_accy 60.76
2024-08-02 20:22:14,850 [foster.py] => Task 23, Epoch 136/170 => Loss 3.037, Loss_clf 0.333, Loss_fe 0.091, Loss_kd 2.557, Train_accy 88.82
2024-08-02 20:22:19,848 [foster.py] => Task 23, Epoch 137/170 => Loss 3.037, Loss_clf 0.322, Loss_fe 0.092, Loss_kd 2.568, Train_accy 89.24, Test_accy 60.57
2024-08-02 20:22:24,900 [foster.py] => Task 23, Epoch 138/170 => Loss 3.065, Loss_clf 0.326, Loss_fe 0.098, Loss_kd 2.584, Train_accy 89.44, Test_accy 60.67
2024-08-02 20:22:29,925 [foster.py] => Task 23, Epoch 139/170 => Loss 3.039, Loss_clf 0.318, Loss_fe 0.094, Loss_kd 2.571, Train_accy 89.27, Test_accy 60.69
2024-08-02 20:22:34,933 [foster.py] => Task 23, Epoch 140/170 => Loss 3.031, Loss_clf 0.312, Loss_fe 0.108, Loss_kd 2.554, Train_accy 89.58, Test_accy 60.70
2024-08-02 20:22:37,838 [foster.py] => Task 23, Epoch 141/170 => Loss 3.046, Loss_clf 0.322, Loss_fe 0.097, Loss_kd 2.571, Train_accy 89.41
2024-08-02 20:22:42,859 [foster.py] => Task 23, Epoch 142/170 => Loss 2.984, Loss_clf 0.296, Loss_fe 0.089, Loss_kd 2.543, Train_accy 89.55, Test_accy 60.62
2024-08-02 20:22:47,855 [foster.py] => Task 23, Epoch 143/170 => Loss 2.971, Loss_clf 0.294, Loss_fe 0.087, Loss_kd 2.535, Train_accy 90.00, Test_accy 60.70
2024-08-02 20:22:52,925 [foster.py] => Task 23, Epoch 144/170 => Loss 3.040, Loss_clf 0.322, Loss_fe 0.097, Loss_kd 2.565, Train_accy 89.31, Test_accy 60.64
2024-08-02 20:22:57,916 [foster.py] => Task 23, Epoch 145/170 => Loss 2.999, Loss_clf 0.310, Loss_fe 0.087, Loss_kd 2.546, Train_accy 89.51, Test_accy 60.68
2024-08-02 20:23:00,931 [foster.py] => Task 23, Epoch 146/170 => Loss 3.009, Loss_clf 0.311, Loss_fe 0.094, Loss_kd 2.547, Train_accy 89.38
2024-08-02 20:23:05,978 [foster.py] => Task 23, Epoch 147/170 => Loss 2.995, Loss_clf 0.296, Loss_fe 0.083, Loss_kd 2.559, Train_accy 89.86, Test_accy 60.70
2024-08-02 20:23:11,022 [foster.py] => Task 23, Epoch 148/170 => Loss 3.101, Loss_clf 0.356, Loss_fe 0.098, Loss_kd 2.591, Train_accy 88.44, Test_accy 60.73
2024-08-02 20:23:16,093 [foster.py] => Task 23, Epoch 149/170 => Loss 3.042, Loss_clf 0.325, Loss_fe 0.093, Loss_kd 2.568, Train_accy 89.10, Test_accy 60.77
2024-08-02 20:23:21,118 [foster.py] => Task 23, Epoch 150/170 => Loss 3.031, Loss_clf 0.316, Loss_fe 0.086, Loss_kd 2.573, Train_accy 90.10, Test_accy 60.81
2024-08-02 20:23:23,997 [foster.py] => Task 23, Epoch 151/170 => Loss 3.025, Loss_clf 0.312, Loss_fe 0.080, Loss_kd 2.576, Train_accy 89.17
2024-08-02 20:23:29,003 [foster.py] => Task 23, Epoch 152/170 => Loss 3.024, Loss_clf 0.313, Loss_fe 0.078, Loss_kd 2.577, Train_accy 89.65, Test_accy 60.80
2024-08-02 20:23:34,015 [foster.py] => Task 23, Epoch 153/170 => Loss 3.035, Loss_clf 0.308, Loss_fe 0.093, Loss_kd 2.578, Train_accy 90.07, Test_accy 60.73
2024-08-02 20:23:39,037 [foster.py] => Task 23, Epoch 154/170 => Loss 3.021, Loss_clf 0.321, Loss_fe 0.085, Loss_kd 2.559, Train_accy 88.82, Test_accy 60.78
2024-08-02 20:23:44,042 [foster.py] => Task 23, Epoch 155/170 => Loss 3.028, Loss_clf 0.321, Loss_fe 0.089, Loss_kd 2.561, Train_accy 89.13, Test_accy 60.70
2024-08-02 20:23:46,918 [foster.py] => Task 23, Epoch 156/170 => Loss 3.005, Loss_clf 0.303, Loss_fe 0.094, Loss_kd 2.552, Train_accy 89.20
2024-08-02 20:23:51,918 [foster.py] => Task 23, Epoch 157/170 => Loss 2.985, Loss_clf 0.308, Loss_fe 0.084, Loss_kd 2.537, Train_accy 88.96, Test_accy 60.72
2024-08-02 20:23:56,952 [foster.py] => Task 23, Epoch 158/170 => Loss 2.993, Loss_clf 0.300, Loss_fe 0.079, Loss_kd 2.557, Train_accy 89.79, Test_accy 60.70
2024-08-02 20:24:01,956 [foster.py] => Task 23, Epoch 159/170 => Loss 2.980, Loss_clf 0.298, Loss_fe 0.093, Loss_kd 2.533, Train_accy 89.79, Test_accy 60.78
2024-08-02 20:24:06,971 [foster.py] => Task 23, Epoch 160/170 => Loss 3.019, Loss_clf 0.313, Loss_fe 0.098, Loss_kd 2.552, Train_accy 89.86, Test_accy 60.70
2024-08-02 20:24:09,874 [foster.py] => Task 23, Epoch 161/170 => Loss 2.969, Loss_clf 0.293, Loss_fe 0.083, Loss_kd 2.537, Train_accy 89.24
2024-08-02 20:24:14,964 [foster.py] => Task 23, Epoch 162/170 => Loss 3.008, Loss_clf 0.313, Loss_fe 0.079, Loss_kd 2.560, Train_accy 88.89, Test_accy 60.78
2024-08-02 20:24:20,010 [foster.py] => Task 23, Epoch 163/170 => Loss 3.008, Loss_clf 0.311, Loss_fe 0.090, Loss_kd 2.550, Train_accy 89.10, Test_accy 60.80
2024-08-02 20:24:25,012 [foster.py] => Task 23, Epoch 164/170 => Loss 2.992, Loss_clf 0.298, Loss_fe 0.083, Loss_kd 2.555, Train_accy 89.79, Test_accy 60.74
2024-08-02 20:24:30,000 [foster.py] => Task 23, Epoch 165/170 => Loss 3.011, Loss_clf 0.312, Loss_fe 0.077, Loss_kd 2.566, Train_accy 88.89, Test_accy 60.76
2024-08-02 20:24:32,917 [foster.py] => Task 23, Epoch 166/170 => Loss 2.988, Loss_clf 0.306, Loss_fe 0.090, Loss_kd 2.537, Train_accy 90.07
2024-08-02 20:24:38,042 [foster.py] => Task 23, Epoch 167/170 => Loss 3.018, Loss_clf 0.307, Loss_fe 0.090, Loss_kd 2.565, Train_accy 89.76, Test_accy 60.76
2024-08-02 20:24:43,238 [foster.py] => Task 23, Epoch 168/170 => Loss 3.021, Loss_clf 0.314, Loss_fe 0.084, Loss_kd 2.567, Train_accy 89.34, Test_accy 60.76
2024-08-02 20:24:48,275 [foster.py] => Task 23, Epoch 169/170 => Loss 3.030, Loss_clf 0.331, Loss_fe 0.076, Loss_kd 2.567, Train_accy 88.99, Test_accy 60.80
2024-08-02 20:24:53,301 [foster.py] => Task 23, Epoch 170/170 => Loss 2.976, Loss_clf 0.293, Loss_fe 0.078, Loss_kd 2.549, Train_accy 90.45, Test_accy 60.76
2024-08-02 20:24:53,303 [foster.py] => do not weight align teacher!
2024-08-02 20:24:53,305 [foster.py] => per cls weights : [1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817 1.01130817
 1.01130817 1.01130817 1.01130817 1.01130817 0.46851586 0.46851586]
2024-08-02 20:24:58,860 [foster.py] => SNet: Task 23, Epoch 1/130 => Loss 31.049,  Loss1 0.789, Train_accy 63.78, Test_accy 58.15
2024-08-02 20:25:02,944 [foster.py] => SNet: Task 23, Epoch 2/130 => Loss 30.996,  Loss1 0.788, Train_accy 71.08
2024-08-02 20:25:06,971 [foster.py] => SNet: Task 23, Epoch 3/130 => Loss 30.958,  Loss1 0.787, Train_accy 71.77
2024-08-02 20:25:11,044 [foster.py] => SNet: Task 23, Epoch 4/130 => Loss 30.997,  Loss1 0.786, Train_accy 73.58
2024-08-02 20:25:15,096 [foster.py] => SNet: Task 23, Epoch 5/130 => Loss 30.942,  Loss1 0.786, Train_accy 73.51
2024-08-02 20:25:20,472 [foster.py] => SNet: Task 23, Epoch 6/130 => Loss 30.959,  Loss1 0.787, Train_accy 75.49, Test_accy 59.59
2024-08-02 20:25:24,544 [foster.py] => SNet: Task 23, Epoch 7/130 => Loss 30.952,  Loss1 0.786, Train_accy 75.76
2024-08-02 20:25:28,611 [foster.py] => SNet: Task 23, Epoch 8/130 => Loss 30.948,  Loss1 0.786, Train_accy 76.04
2024-08-02 20:25:32,661 [foster.py] => SNet: Task 23, Epoch 9/130 => Loss 30.909,  Loss1 0.786, Train_accy 77.08
2024-08-02 20:25:36,723 [foster.py] => SNet: Task 23, Epoch 10/130 => Loss 30.918,  Loss1 0.786, Train_accy 76.74
2024-08-02 20:25:42,157 [foster.py] => SNet: Task 23, Epoch 11/130 => Loss 30.954,  Loss1 0.785, Train_accy 75.80, Test_accy 60.06
2024-08-02 20:25:46,200 [foster.py] => SNet: Task 23, Epoch 12/130 => Loss 30.911,  Loss1 0.785, Train_accy 77.47
2024-08-02 20:25:50,259 [foster.py] => SNet: Task 23, Epoch 13/130 => Loss 31.000,  Loss1 0.786, Train_accy 77.19
2024-08-02 20:25:54,357 [foster.py] => SNet: Task 23, Epoch 14/130 => Loss 30.947,  Loss1 0.785, Train_accy 77.85
2024-08-02 20:25:58,394 [foster.py] => SNet: Task 23, Epoch 15/130 => Loss 30.974,  Loss1 0.785, Train_accy 77.88
2024-08-02 20:26:03,813 [foster.py] => SNet: Task 23, Epoch 16/130 => Loss 30.935,  Loss1 0.785, Train_accy 77.50, Test_accy 59.92
2024-08-02 20:26:07,866 [foster.py] => SNet: Task 23, Epoch 17/130 => Loss 30.921,  Loss1 0.785, Train_accy 78.30
2024-08-02 20:26:11,912 [foster.py] => SNet: Task 23, Epoch 18/130 => Loss 30.922,  Loss1 0.786, Train_accy 78.51
2024-08-02 20:26:15,937 [foster.py] => SNet: Task 23, Epoch 19/130 => Loss 30.965,  Loss1 0.785, Train_accy 76.84
2024-08-02 20:26:19,955 [foster.py] => SNet: Task 23, Epoch 20/130 => Loss 30.959,  Loss1 0.785, Train_accy 78.78
2024-08-02 20:26:25,361 [foster.py] => SNet: Task 23, Epoch 21/130 => Loss 30.968,  Loss1 0.785, Train_accy 77.74, Test_accy 60.22
2024-08-02 20:26:29,408 [foster.py] => SNet: Task 23, Epoch 22/130 => Loss 30.935,  Loss1 0.785, Train_accy 78.75
2024-08-02 20:26:33,457 [foster.py] => SNet: Task 23, Epoch 23/130 => Loss 30.930,  Loss1 0.786, Train_accy 80.49
2024-08-02 20:26:37,528 [foster.py] => SNet: Task 23, Epoch 24/130 => Loss 30.943,  Loss1 0.785, Train_accy 78.78
2024-08-02 20:26:41,579 [foster.py] => SNet: Task 23, Epoch 25/130 => Loss 31.007,  Loss1 0.785, Train_accy 78.78
2024-08-02 20:26:46,967 [foster.py] => SNet: Task 23, Epoch 26/130 => Loss 30.905,  Loss1 0.785, Train_accy 79.97, Test_accy 60.42
2024-08-02 20:26:51,085 [foster.py] => SNet: Task 23, Epoch 27/130 => Loss 30.946,  Loss1 0.785, Train_accy 79.06
2024-08-02 20:26:55,168 [foster.py] => SNet: Task 23, Epoch 28/130 => Loss 30.963,  Loss1 0.785, Train_accy 80.21
2024-08-02 20:26:59,188 [foster.py] => SNet: Task 23, Epoch 29/130 => Loss 30.936,  Loss1 0.785, Train_accy 79.90
2024-08-02 20:27:03,259 [foster.py] => SNet: Task 23, Epoch 30/130 => Loss 30.955,  Loss1 0.785, Train_accy 79.65
2024-08-02 20:27:08,630 [foster.py] => SNet: Task 23, Epoch 31/130 => Loss 30.933,  Loss1 0.785, Train_accy 80.73, Test_accy 59.90
2024-08-02 20:27:12,663 [foster.py] => SNet: Task 23, Epoch 32/130 => Loss 30.948,  Loss1 0.785, Train_accy 78.92
2024-08-02 20:27:16,718 [foster.py] => SNet: Task 23, Epoch 33/130 => Loss 30.971,  Loss1 0.784, Train_accy 79.51
2024-08-02 20:27:20,746 [foster.py] => SNet: Task 23, Epoch 34/130 => Loss 30.954,  Loss1 0.784, Train_accy 80.31
2024-08-02 20:27:24,806 [foster.py] => SNet: Task 23, Epoch 35/130 => Loss 30.927,  Loss1 0.785, Train_accy 79.76
2024-08-02 20:27:30,205 [foster.py] => SNet: Task 23, Epoch 36/130 => Loss 30.918,  Loss1 0.785, Train_accy 78.89, Test_accy 60.30
2024-08-02 20:27:34,259 [foster.py] => SNet: Task 23, Epoch 37/130 => Loss 30.921,  Loss1 0.785, Train_accy 79.79
2024-08-02 20:27:38,303 [foster.py] => SNet: Task 23, Epoch 38/130 => Loss 30.960,  Loss1 0.784, Train_accy 79.51
2024-08-02 20:27:42,340 [foster.py] => SNet: Task 23, Epoch 39/130 => Loss 30.938,  Loss1 0.785, Train_accy 80.24
2024-08-02 20:27:46,418 [foster.py] => SNet: Task 23, Epoch 40/130 => Loss 30.931,  Loss1 0.785, Train_accy 80.24
2024-08-02 20:27:51,779 [foster.py] => SNet: Task 23, Epoch 41/130 => Loss 30.924,  Loss1 0.785, Train_accy 79.34, Test_accy 60.33
2024-08-02 20:27:55,834 [foster.py] => SNet: Task 23, Epoch 42/130 => Loss 30.936,  Loss1 0.785, Train_accy 80.62
2024-08-02 20:27:59,863 [foster.py] => SNet: Task 23, Epoch 43/130 => Loss 30.919,  Loss1 0.785, Train_accy 79.48
2024-08-02 20:28:03,996 [foster.py] => SNet: Task 23, Epoch 44/130 => Loss 30.936,  Loss1 0.785, Train_accy 80.28
2024-08-02 20:28:08,051 [foster.py] => SNet: Task 23, Epoch 45/130 => Loss 30.961,  Loss1 0.785, Train_accy 80.35
2024-08-02 20:28:13,437 [foster.py] => SNet: Task 23, Epoch 46/130 => Loss 30.938,  Loss1 0.785, Train_accy 80.24, Test_accy 60.34
2024-08-02 20:28:17,475 [foster.py] => SNet: Task 23, Epoch 47/130 => Loss 30.928,  Loss1 0.784, Train_accy 79.31
2024-08-02 20:28:21,518 [foster.py] => SNet: Task 23, Epoch 48/130 => Loss 30.900,  Loss1 0.784, Train_accy 80.73
2024-08-02 20:28:25,591 [foster.py] => SNet: Task 23, Epoch 49/130 => Loss 30.921,  Loss1 0.784, Train_accy 79.93
2024-08-02 20:28:29,629 [foster.py] => SNet: Task 23, Epoch 50/130 => Loss 30.885,  Loss1 0.785, Train_accy 80.66
2024-08-02 20:28:34,990 [foster.py] => SNet: Task 23, Epoch 51/130 => Loss 30.925,  Loss1 0.785, Train_accy 80.52, Test_accy 59.99
2024-08-02 20:28:39,046 [foster.py] => SNet: Task 23, Epoch 52/130 => Loss 30.927,  Loss1 0.784, Train_accy 80.62
2024-08-02 20:28:43,082 [foster.py] => SNet: Task 23, Epoch 53/130 => Loss 30.892,  Loss1 0.785, Train_accy 80.21
2024-08-02 20:28:47,118 [foster.py] => SNet: Task 23, Epoch 54/130 => Loss 30.935,  Loss1 0.785, Train_accy 81.15
2024-08-02 20:28:51,161 [foster.py] => SNet: Task 23, Epoch 55/130 => Loss 30.892,  Loss1 0.785, Train_accy 79.93
2024-08-02 20:28:56,532 [foster.py] => SNet: Task 23, Epoch 56/130 => Loss 30.933,  Loss1 0.785, Train_accy 80.56, Test_accy 60.43
2024-08-02 20:29:00,599 [foster.py] => SNet: Task 23, Epoch 57/130 => Loss 30.983,  Loss1 0.785, Train_accy 80.49
2024-08-02 20:29:04,638 [foster.py] => SNet: Task 23, Epoch 58/130 => Loss 30.971,  Loss1 0.785, Train_accy 79.83
2024-08-02 20:29:08,673 [foster.py] => SNet: Task 23, Epoch 59/130 => Loss 30.940,  Loss1 0.785, Train_accy 80.14
2024-08-02 20:29:12,777 [foster.py] => SNet: Task 23, Epoch 60/130 => Loss 30.869,  Loss1 0.784, Train_accy 79.97
2024-08-02 20:29:18,134 [foster.py] => SNet: Task 23, Epoch 61/130 => Loss 30.933,  Loss1 0.784, Train_accy 80.87, Test_accy 60.34
2024-08-02 20:29:22,160 [foster.py] => SNet: Task 23, Epoch 62/130 => Loss 30.918,  Loss1 0.785, Train_accy 81.32
2024-08-02 20:29:26,259 [foster.py] => SNet: Task 23, Epoch 63/130 => Loss 30.949,  Loss1 0.785, Train_accy 81.39
2024-08-02 20:29:30,301 [foster.py] => SNet: Task 23, Epoch 64/130 => Loss 30.896,  Loss1 0.784, Train_accy 80.45
2024-08-02 20:29:34,316 [foster.py] => SNet: Task 23, Epoch 65/130 => Loss 30.929,  Loss1 0.785, Train_accy 79.62
2024-08-02 20:29:39,703 [foster.py] => SNet: Task 23, Epoch 66/130 => Loss 30.898,  Loss1 0.784, Train_accy 81.08, Test_accy 60.47
2024-08-02 20:29:43,740 [foster.py] => SNet: Task 23, Epoch 67/130 => Loss 30.937,  Loss1 0.785, Train_accy 80.73
2024-08-02 20:29:47,788 [foster.py] => SNet: Task 23, Epoch 68/130 => Loss 30.932,  Loss1 0.785, Train_accy 81.42
2024-08-02 20:29:51,845 [foster.py] => SNet: Task 23, Epoch 69/130 => Loss 30.930,  Loss1 0.784, Train_accy 81.39
2024-08-02 20:29:55,912 [foster.py] => SNet: Task 23, Epoch 70/130 => Loss 30.890,  Loss1 0.784, Train_accy 81.84
2024-08-02 20:30:01,289 [foster.py] => SNet: Task 23, Epoch 71/130 => Loss 30.938,  Loss1 0.785, Train_accy 80.38, Test_accy 60.45
2024-08-02 20:30:05,337 [foster.py] => SNet: Task 23, Epoch 72/130 => Loss 30.930,  Loss1 0.785, Train_accy 81.70
2024-08-02 20:30:09,385 [foster.py] => SNet: Task 23, Epoch 73/130 => Loss 30.976,  Loss1 0.784, Train_accy 80.56
2024-08-02 20:30:13,471 [foster.py] => SNet: Task 23, Epoch 74/130 => Loss 30.943,  Loss1 0.784, Train_accy 80.62
2024-08-02 20:30:17,500 [foster.py] => SNet: Task 23, Epoch 75/130 => Loss 30.928,  Loss1 0.784, Train_accy 79.62
2024-08-02 20:30:22,908 [foster.py] => SNet: Task 23, Epoch 76/130 => Loss 30.917,  Loss1 0.785, Train_accy 79.76, Test_accy 60.58
2024-08-02 20:30:27,034 [foster.py] => SNet: Task 23, Epoch 77/130 => Loss 30.945,  Loss1 0.785, Train_accy 81.63
2024-08-02 20:30:31,116 [foster.py] => SNet: Task 23, Epoch 78/130 => Loss 30.919,  Loss1 0.784, Train_accy 81.70
2024-08-02 20:30:35,170 [foster.py] => SNet: Task 23, Epoch 79/130 => Loss 30.950,  Loss1 0.785, Train_accy 79.93
2024-08-02 20:30:39,211 [foster.py] => SNet: Task 23, Epoch 80/130 => Loss 30.937,  Loss1 0.784, Train_accy 80.76
2024-08-02 20:30:44,567 [foster.py] => SNet: Task 23, Epoch 81/130 => Loss 30.918,  Loss1 0.785, Train_accy 80.59, Test_accy 60.53
2024-08-02 20:30:48,636 [foster.py] => SNet: Task 23, Epoch 82/130 => Loss 30.917,  Loss1 0.784, Train_accy 82.67
2024-08-02 20:30:52,702 [foster.py] => SNet: Task 23, Epoch 83/130 => Loss 30.941,  Loss1 0.785, Train_accy 80.35
2024-08-02 20:30:56,756 [foster.py] => SNet: Task 23, Epoch 84/130 => Loss 30.934,  Loss1 0.785, Train_accy 79.44
2024-08-02 20:31:00,800 [foster.py] => SNet: Task 23, Epoch 85/130 => Loss 30.975,  Loss1 0.784, Train_accy 81.25
2024-08-02 20:31:06,169 [foster.py] => SNet: Task 23, Epoch 86/130 => Loss 30.877,  Loss1 0.785, Train_accy 82.29, Test_accy 60.54
2024-08-02 20:31:10,210 [foster.py] => SNet: Task 23, Epoch 87/130 => Loss 30.954,  Loss1 0.785, Train_accy 80.49
2024-08-02 20:31:14,283 [foster.py] => SNet: Task 23, Epoch 88/130 => Loss 30.953,  Loss1 0.784, Train_accy 80.62
2024-08-02 20:31:18,310 [foster.py] => SNet: Task 23, Epoch 89/130 => Loss 30.927,  Loss1 0.784, Train_accy 81.32
2024-08-02 20:31:22,343 [foster.py] => SNet: Task 23, Epoch 90/130 => Loss 30.919,  Loss1 0.785, Train_accy 81.42
2024-08-02 20:31:27,678 [foster.py] => SNet: Task 23, Epoch 91/130 => Loss 30.946,  Loss1 0.784, Train_accy 81.25, Test_accy 60.32
2024-08-02 20:31:31,742 [foster.py] => SNet: Task 23, Epoch 92/130 => Loss 30.951,  Loss1 0.785, Train_accy 80.97
2024-08-02 20:31:35,759 [foster.py] => SNet: Task 23, Epoch 93/130 => Loss 30.951,  Loss1 0.784, Train_accy 81.32
2024-08-02 20:31:39,860 [foster.py] => SNet: Task 23, Epoch 94/130 => Loss 30.917,  Loss1 0.784, Train_accy 81.18
2024-08-02 20:31:43,899 [foster.py] => SNet: Task 23, Epoch 95/130 => Loss 30.903,  Loss1 0.785, Train_accy 81.46
2024-08-02 20:31:49,284 [foster.py] => SNet: Task 23, Epoch 96/130 => Loss 30.978,  Loss1 0.785, Train_accy 80.69, Test_accy 60.31
2024-08-02 20:31:53,357 [foster.py] => SNet: Task 23, Epoch 97/130 => Loss 30.944,  Loss1 0.784, Train_accy 80.38
2024-08-02 20:31:57,451 [foster.py] => SNet: Task 23, Epoch 98/130 => Loss 30.967,  Loss1 0.784, Train_accy 81.70
2024-08-02 20:32:01,522 [foster.py] => SNet: Task 23, Epoch 99/130 => Loss 30.906,  Loss1 0.785, Train_accy 80.45
2024-08-02 20:32:05,575 [foster.py] => SNet: Task 23, Epoch 100/130 => Loss 30.942,  Loss1 0.785, Train_accy 81.77
2024-08-02 20:32:10,986 [foster.py] => SNet: Task 23, Epoch 101/130 => Loss 30.942,  Loss1 0.785, Train_accy 80.49, Test_accy 60.50
2024-08-02 20:32:15,016 [foster.py] => SNet: Task 23, Epoch 102/130 => Loss 30.956,  Loss1 0.785, Train_accy 80.56
2024-08-02 20:32:19,093 [foster.py] => SNet: Task 23, Epoch 103/130 => Loss 30.949,  Loss1 0.784, Train_accy 80.45
2024-08-02 20:32:23,188 [foster.py] => SNet: Task 23, Epoch 104/130 => Loss 30.942,  Loss1 0.785, Train_accy 81.01
2024-08-02 20:32:27,257 [foster.py] => SNet: Task 23, Epoch 105/130 => Loss 30.944,  Loss1 0.785, Train_accy 81.01
2024-08-02 20:32:32,605 [foster.py] => SNet: Task 23, Epoch 106/130 => Loss 30.918,  Loss1 0.784, Train_accy 81.94, Test_accy 60.67
2024-08-02 20:32:36,655 [foster.py] => SNet: Task 23, Epoch 107/130 => Loss 30.970,  Loss1 0.784, Train_accy 81.63
2024-08-02 20:32:40,713 [foster.py] => SNet: Task 23, Epoch 108/130 => Loss 30.916,  Loss1 0.784, Train_accy 81.98
2024-08-02 20:32:44,738 [foster.py] => SNet: Task 23, Epoch 109/130 => Loss 30.939,  Loss1 0.785, Train_accy 82.05
2024-08-02 20:32:48,835 [foster.py] => SNet: Task 23, Epoch 110/130 => Loss 30.937,  Loss1 0.784, Train_accy 79.62
2024-08-02 20:32:54,203 [foster.py] => SNet: Task 23, Epoch 111/130 => Loss 30.933,  Loss1 0.785, Train_accy 81.91, Test_accy 60.66
2024-08-02 20:32:58,256 [foster.py] => SNet: Task 23, Epoch 112/130 => Loss 30.970,  Loss1 0.784, Train_accy 80.59
2024-08-02 20:33:02,303 [foster.py] => SNet: Task 23, Epoch 113/130 => Loss 30.926,  Loss1 0.784, Train_accy 80.80
2024-08-02 20:33:06,345 [foster.py] => SNet: Task 23, Epoch 114/130 => Loss 30.952,  Loss1 0.784, Train_accy 80.83
2024-08-02 20:33:10,420 [foster.py] => SNet: Task 23, Epoch 115/130 => Loss 30.917,  Loss1 0.785, Train_accy 81.60
2024-08-02 20:33:15,812 [foster.py] => SNet: Task 23, Epoch 116/130 => Loss 30.938,  Loss1 0.784, Train_accy 80.87, Test_accy 60.54
2024-08-02 20:33:19,839 [foster.py] => SNet: Task 23, Epoch 117/130 => Loss 30.928,  Loss1 0.784, Train_accy 82.19
2024-08-02 20:33:23,915 [foster.py] => SNet: Task 23, Epoch 118/130 => Loss 30.942,  Loss1 0.785, Train_accy 81.22
2024-08-02 20:33:27,953 [foster.py] => SNet: Task 23, Epoch 119/130 => Loss 30.893,  Loss1 0.784, Train_accy 82.01
2024-08-02 20:33:31,989 [foster.py] => SNet: Task 23, Epoch 120/130 => Loss 30.922,  Loss1 0.785, Train_accy 81.25
2024-08-02 20:33:37,316 [foster.py] => SNet: Task 23, Epoch 121/130 => Loss 30.939,  Loss1 0.785, Train_accy 80.56, Test_accy 60.66
2024-08-02 20:33:41,397 [foster.py] => SNet: Task 23, Epoch 122/130 => Loss 30.904,  Loss1 0.784, Train_accy 81.28
2024-08-02 20:33:45,478 [foster.py] => SNet: Task 23, Epoch 123/130 => Loss 30.960,  Loss1 0.784, Train_accy 80.56
2024-08-02 20:33:49,528 [foster.py] => SNet: Task 23, Epoch 124/130 => Loss 30.922,  Loss1 0.784, Train_accy 81.28
2024-08-02 20:33:53,578 [foster.py] => SNet: Task 23, Epoch 125/130 => Loss 30.949,  Loss1 0.785, Train_accy 81.67
2024-08-02 20:33:58,956 [foster.py] => SNet: Task 23, Epoch 126/130 => Loss 30.947,  Loss1 0.785, Train_accy 80.90, Test_accy 60.33
2024-08-02 20:34:03,095 [foster.py] => SNet: Task 23, Epoch 127/130 => Loss 30.936,  Loss1 0.785, Train_accy 81.98
2024-08-02 20:34:07,166 [foster.py] => SNet: Task 23, Epoch 128/130 => Loss 30.919,  Loss1 0.784, Train_accy 81.35
2024-08-02 20:34:11,217 [foster.py] => SNet: Task 23, Epoch 129/130 => Loss 30.938,  Loss1 0.784, Train_accy 81.28
2024-08-02 20:34:15,233 [foster.py] => SNet: Task 23, Epoch 130/130 => Loss 30.925,  Loss1 0.785, Train_accy 81.22
2024-08-02 20:34:15,234 [foster.py] => do not weight align student!
2024-08-02 20:34:16,555 [foster.py] => darknet eval: 
2024-08-02 20:34:16,555 [foster.py] => CNN top1 curve: 60.89
2024-08-02 20:34:16,555 [foster.py] => CNN top5 curve: 85.21
2024-08-02 20:34:16,556 [foster.py] => CNN top1 平均值: 60.89
2024-08-02 20:34:16,560 [foster.py] => timees : 1349.8560574054718
2024-08-02 20:34:16,561 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 20:34:45,816 [foster.py] => Exemplar size: 1920
2024-08-02 20:34:45,816 [trainer.py] => CNN: {'total': 60.76, '00-09': 67.3, '10-19': 49.2, '20-29': 65.9, '30-39': 60.1, '40-49': 65.3, '50-59': 47.5, '60-69': 60.3, '70-79': 60.0, '80-89': 68.1, '90-99': 66.0, 'old': 60.39, 'new': 78.0}
2024-08-02 20:34:45,816 [trainer.py] => NME: {'total': 54.34, '00-09': 51.7, '10-19': 39.4, '20-29': 58.5, '30-39': 49.4, '40-49': 56.9, '50-59': 43.9, '60-69': 59.7, '70-79': 61.9, '80-89': 67.3, '90-99': 55.0, 'old': 53.64, 'new': 87.5}
2024-08-02 20:34:45,816 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13, 62.75, 61.26, 60.76]
2024-08-02 20:34:45,817 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99, 86.89, 85.94, 85.82]
2024-08-02 20:34:45,817 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09, 57.52, 55.7, 54.34]
2024-08-02 20:34:45,817 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79, 83.43, 81.69, 80.6]

2024-08-02 20:34:45,817 [trainer.py] => CNN top1 平均值: 70.48
2024-08-02 20:34:45,819 [trainer.py] => All params: 1179282
2024-08-02 20:34:45,822 [trainer.py] => Trainable params: 595898
2024-08-02 20:34:45,882 [foster.py] => Learning on 96-98
2024-08-02 20:34:45,886 [foster.py] => All params: 1179800
2024-08-02 20:34:45,888 [foster.py] => Trainable params: 596286
2024-08-02 20:34:45,934 [foster.py] => per cls weights : [1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869 1.00932869
 0.552223   0.552223  ]
2024-08-02 20:34:48,835 [foster.py] => Task 24, Epoch 1/170 => Loss 5.261, Loss_clf 0.864, Loss_fe 1.712, Loss_kd 2.628, Train_accy 71.75
2024-08-02 20:34:53,896 [foster.py] => Task 24, Epoch 2/170 => Loss 3.822, Loss_clf 0.495, Loss_fe 0.692, Loss_kd 2.579, Train_accy 79.01, Test_accy 59.28
2024-08-02 20:34:58,961 [foster.py] => Task 24, Epoch 3/170 => Loss 3.699, Loss_clf 0.509, Loss_fe 0.537, Loss_kd 2.597, Train_accy 79.59, Test_accy 60.03
2024-08-02 20:35:04,079 [foster.py] => Task 24, Epoch 4/170 => Loss 3.636, Loss_clf 0.484, Loss_fe 0.471, Loss_kd 2.624, Train_accy 80.10, Test_accy 59.83
2024-08-02 20:35:09,174 [foster.py] => Task 24, Epoch 5/170 => Loss 3.527, Loss_clf 0.467, Loss_fe 0.440, Loss_kd 2.565, Train_accy 81.23, Test_accy 59.47
2024-08-02 20:35:12,076 [foster.py] => Task 24, Epoch 6/170 => Loss 3.522, Loss_clf 0.457, Loss_fe 0.420, Loss_kd 2.589, Train_accy 80.82
2024-08-02 20:35:17,146 [foster.py] => Task 24, Epoch 7/170 => Loss 3.480, Loss_clf 0.452, Loss_fe 0.393, Loss_kd 2.580, Train_accy 81.92, Test_accy 59.76
2024-08-02 20:35:22,211 [foster.py] => Task 24, Epoch 8/170 => Loss 3.493, Loss_clf 0.459, Loss_fe 0.395, Loss_kd 2.584, Train_accy 80.86, Test_accy 60.18
2024-08-02 20:35:27,297 [foster.py] => Task 24, Epoch 9/170 => Loss 3.475, Loss_clf 0.439, Loss_fe 0.389, Loss_kd 2.591, Train_accy 81.78, Test_accy 59.69
2024-08-02 20:35:32,358 [foster.py] => Task 24, Epoch 10/170 => Loss 3.440, Loss_clf 0.456, Loss_fe 0.354, Loss_kd 2.574, Train_accy 80.68, Test_accy 60.14
2024-08-02 20:35:35,245 [foster.py] => Task 24, Epoch 11/170 => Loss 3.440, Loss_clf 0.447, Loss_fe 0.351, Loss_kd 2.586, Train_accy 82.98
2024-08-02 20:35:40,316 [foster.py] => Task 24, Epoch 12/170 => Loss 3.438, Loss_clf 0.435, Loss_fe 0.364, Loss_kd 2.583, Train_accy 82.05, Test_accy 59.88
2024-08-02 20:35:45,459 [foster.py] => Task 24, Epoch 13/170 => Loss 3.408, Loss_clf 0.431, Loss_fe 0.321, Loss_kd 2.601, Train_accy 82.71, Test_accy 59.83
2024-08-02 20:35:50,630 [foster.py] => Task 24, Epoch 14/170 => Loss 3.368, Loss_clf 0.401, Loss_fe 0.325, Loss_kd 2.586, Train_accy 83.08, Test_accy 60.28
2024-08-02 20:35:55,688 [foster.py] => Task 24, Epoch 15/170 => Loss 3.341, Loss_clf 0.403, Loss_fe 0.307, Loss_kd 2.575, Train_accy 83.08, Test_accy 60.00
2024-08-02 20:35:58,620 [foster.py] => Task 24, Epoch 16/170 => Loss 3.382, Loss_clf 0.421, Loss_fe 0.342, Loss_kd 2.563, Train_accy 83.08
2024-08-02 20:36:03,703 [foster.py] => Task 24, Epoch 17/170 => Loss 3.385, Loss_clf 0.426, Loss_fe 0.321, Loss_kd 2.582, Train_accy 82.23, Test_accy 60.29
2024-08-02 20:36:08,890 [foster.py] => Task 24, Epoch 18/170 => Loss 3.337, Loss_clf 0.400, Loss_fe 0.299, Loss_kd 2.583, Train_accy 83.29, Test_accy 60.10
2024-08-02 20:36:13,974 [foster.py] => Task 24, Epoch 19/170 => Loss 3.350, Loss_clf 0.410, Loss_fe 0.309, Loss_kd 2.575, Train_accy 83.29, Test_accy 60.16
2024-08-02 20:36:19,052 [foster.py] => Task 24, Epoch 20/170 => Loss 3.372, Loss_clf 0.422, Loss_fe 0.287, Loss_kd 2.606, Train_accy 83.42, Test_accy 59.85
2024-08-02 20:36:21,931 [foster.py] => Task 24, Epoch 21/170 => Loss 3.317, Loss_clf 0.401, Loss_fe 0.288, Loss_kd 2.573, Train_accy 84.59
2024-08-02 20:36:26,995 [foster.py] => Task 24, Epoch 22/170 => Loss 3.342, Loss_clf 0.409, Loss_fe 0.309, Loss_kd 2.569, Train_accy 83.22, Test_accy 59.98
2024-08-02 20:36:32,109 [foster.py] => Task 24, Epoch 23/170 => Loss 3.286, Loss_clf 0.377, Loss_fe 0.280, Loss_kd 2.573, Train_accy 85.55, Test_accy 60.14
2024-08-02 20:36:37,206 [foster.py] => Task 24, Epoch 24/170 => Loss 3.295, Loss_clf 0.389, Loss_fe 0.280, Loss_kd 2.570, Train_accy 84.76, Test_accy 59.67
2024-08-02 20:36:42,289 [foster.py] => Task 24, Epoch 25/170 => Loss 3.279, Loss_clf 0.391, Loss_fe 0.263, Loss_kd 2.570, Train_accy 83.63, Test_accy 59.61
2024-08-02 20:36:45,180 [foster.py] => Task 24, Epoch 26/170 => Loss 3.338, Loss_clf 0.410, Loss_fe 0.282, Loss_kd 2.590, Train_accy 83.49
2024-08-02 20:36:50,365 [foster.py] => Task 24, Epoch 27/170 => Loss 3.355, Loss_clf 0.413, Loss_fe 0.284, Loss_kd 2.602, Train_accy 83.70, Test_accy 60.33
2024-08-02 20:36:55,513 [foster.py] => Task 24, Epoch 28/170 => Loss 3.293, Loss_clf 0.386, Loss_fe 0.278, Loss_kd 2.574, Train_accy 84.35, Test_accy 59.89
2024-08-02 20:37:00,625 [foster.py] => Task 24, Epoch 29/170 => Loss 3.267, Loss_clf 0.368, Loss_fe 0.261, Loss_kd 2.582, Train_accy 83.97, Test_accy 60.30
2024-08-02 20:37:05,776 [foster.py] => Task 24, Epoch 30/170 => Loss 3.362, Loss_clf 0.423, Loss_fe 0.277, Loss_kd 2.606, Train_accy 83.12, Test_accy 60.26
2024-08-02 20:37:08,734 [foster.py] => Task 24, Epoch 31/170 => Loss 3.275, Loss_clf 0.393, Loss_fe 0.237, Loss_kd 2.589, Train_accy 84.55
2024-08-02 20:37:13,835 [foster.py] => Task 24, Epoch 32/170 => Loss 3.278, Loss_clf 0.382, Loss_fe 0.249, Loss_kd 2.592, Train_accy 84.76, Test_accy 59.93
2024-08-02 20:37:18,923 [foster.py] => Task 24, Epoch 33/170 => Loss 3.274, Loss_clf 0.376, Loss_fe 0.251, Loss_kd 2.591, Train_accy 85.38, Test_accy 60.01
2024-08-02 20:37:23,980 [foster.py] => Task 24, Epoch 34/170 => Loss 3.299, Loss_clf 0.397, Loss_fe 0.237, Loss_kd 2.609, Train_accy 84.79, Test_accy 60.42
2024-08-02 20:37:29,083 [foster.py] => Task 24, Epoch 35/170 => Loss 3.288, Loss_clf 0.399, Loss_fe 0.234, Loss_kd 2.600, Train_accy 84.01, Test_accy 60.05
2024-08-02 20:37:31,984 [foster.py] => Task 24, Epoch 36/170 => Loss 3.248, Loss_clf 0.378, Loss_fe 0.243, Loss_kd 2.572, Train_accy 85.14
2024-08-02 20:37:37,072 [foster.py] => Task 24, Epoch 37/170 => Loss 3.243, Loss_clf 0.377, Loss_fe 0.235, Loss_kd 2.576, Train_accy 84.73, Test_accy 60.19
2024-08-02 20:37:42,333 [foster.py] => Task 24, Epoch 38/170 => Loss 3.308, Loss_clf 0.408, Loss_fe 0.243, Loss_kd 2.601, Train_accy 84.28, Test_accy 60.16
2024-08-02 20:37:47,398 [foster.py] => Task 24, Epoch 39/170 => Loss 3.298, Loss_clf 0.400, Loss_fe 0.250, Loss_kd 2.592, Train_accy 84.18, Test_accy 60.03
2024-08-02 20:37:52,544 [foster.py] => Task 24, Epoch 40/170 => Loss 3.255, Loss_clf 0.373, Loss_fe 0.230, Loss_kd 2.596, Train_accy 84.35, Test_accy 60.11
2024-08-02 20:37:55,433 [foster.py] => Task 24, Epoch 41/170 => Loss 3.246, Loss_clf 0.366, Loss_fe 0.228, Loss_kd 2.596, Train_accy 86.44
2024-08-02 20:38:00,521 [foster.py] => Task 24, Epoch 42/170 => Loss 3.264, Loss_clf 0.382, Loss_fe 0.221, Loss_kd 2.605, Train_accy 85.96, Test_accy 59.92
2024-08-02 20:38:05,613 [foster.py] => Task 24, Epoch 43/170 => Loss 3.289, Loss_clf 0.404, Loss_fe 0.241, Loss_kd 2.588, Train_accy 84.83, Test_accy 60.21
2024-08-02 20:38:10,704 [foster.py] => Task 24, Epoch 44/170 => Loss 3.284, Loss_clf 0.406, Loss_fe 0.226, Loss_kd 2.596, Train_accy 84.66, Test_accy 60.44
2024-08-02 20:38:15,802 [foster.py] => Task 24, Epoch 45/170 => Loss 3.224, Loss_clf 0.380, Loss_fe 0.223, Loss_kd 2.566, Train_accy 84.59, Test_accy 59.93
2024-08-02 20:38:18,688 [foster.py] => Task 24, Epoch 46/170 => Loss 3.242, Loss_clf 0.382, Loss_fe 0.211, Loss_kd 2.593, Train_accy 84.86
2024-08-02 20:38:23,753 [foster.py] => Task 24, Epoch 47/170 => Loss 3.222, Loss_clf 0.374, Loss_fe 0.206, Loss_kd 2.587, Train_accy 85.17, Test_accy 60.18
2024-08-02 20:38:28,815 [foster.py] => Task 24, Epoch 48/170 => Loss 3.264, Loss_clf 0.391, Loss_fe 0.221, Loss_kd 2.596, Train_accy 85.38, Test_accy 60.38
2024-08-02 20:38:33,990 [foster.py] => Task 24, Epoch 49/170 => Loss 3.254, Loss_clf 0.378, Loss_fe 0.214, Loss_kd 2.606, Train_accy 85.96, Test_accy 60.26
2024-08-02 20:38:39,052 [foster.py] => Task 24, Epoch 50/170 => Loss 3.190, Loss_clf 0.346, Loss_fe 0.205, Loss_kd 2.583, Train_accy 86.30, Test_accy 60.34
2024-08-02 20:38:42,103 [foster.py] => Task 24, Epoch 51/170 => Loss 3.261, Loss_clf 0.396, Loss_fe 0.198, Loss_kd 2.611, Train_accy 85.38
2024-08-02 20:38:47,340 [foster.py] => Task 24, Epoch 52/170 => Loss 3.264, Loss_clf 0.401, Loss_fe 0.210, Loss_kd 2.597, Train_accy 84.62, Test_accy 60.41
2024-08-02 20:38:52,572 [foster.py] => Task 24, Epoch 53/170 => Loss 3.213, Loss_clf 0.374, Loss_fe 0.195, Loss_kd 2.588, Train_accy 85.68, Test_accy 60.52
2024-08-02 20:38:57,735 [foster.py] => Task 24, Epoch 54/170 => Loss 3.208, Loss_clf 0.380, Loss_fe 0.197, Loss_kd 2.575, Train_accy 86.13, Test_accy 60.20
2024-08-02 20:39:02,846 [foster.py] => Task 24, Epoch 55/170 => Loss 3.183, Loss_clf 0.364, Loss_fe 0.175, Loss_kd 2.588, Train_accy 85.58, Test_accy 60.21
2024-08-02 20:39:05,766 [foster.py] => Task 24, Epoch 56/170 => Loss 3.193, Loss_clf 0.374, Loss_fe 0.195, Loss_kd 2.568, Train_accy 85.75
2024-08-02 20:39:10,922 [foster.py] => Task 24, Epoch 57/170 => Loss 3.239, Loss_clf 0.385, Loss_fe 0.217, Loss_kd 2.582, Train_accy 85.14, Test_accy 60.37
2024-08-02 20:39:16,006 [foster.py] => Task 24, Epoch 58/170 => Loss 3.212, Loss_clf 0.378, Loss_fe 0.184, Loss_kd 2.595, Train_accy 85.41, Test_accy 60.38
2024-08-02 20:39:21,101 [foster.py] => Task 24, Epoch 59/170 => Loss 3.185, Loss_clf 0.356, Loss_fe 0.196, Loss_kd 2.577, Train_accy 85.99, Test_accy 60.30
2024-08-02 20:39:26,215 [foster.py] => Task 24, Epoch 60/170 => Loss 3.211, Loss_clf 0.370, Loss_fe 0.184, Loss_kd 2.602, Train_accy 86.88, Test_accy 60.39
2024-08-02 20:39:29,093 [foster.py] => Task 24, Epoch 61/170 => Loss 3.224, Loss_clf 0.379, Loss_fe 0.205, Loss_kd 2.585, Train_accy 86.03
2024-08-02 20:39:34,173 [foster.py] => Task 24, Epoch 62/170 => Loss 3.172, Loss_clf 0.358, Loss_fe 0.195, Loss_kd 2.565, Train_accy 86.37, Test_accy 60.22
2024-08-02 20:39:39,236 [foster.py] => Task 24, Epoch 63/170 => Loss 3.198, Loss_clf 0.357, Loss_fe 0.182, Loss_kd 2.602, Train_accy 86.40, Test_accy 60.37
2024-08-02 20:39:44,331 [foster.py] => Task 24, Epoch 64/170 => Loss 3.166, Loss_clf 0.360, Loss_fe 0.180, Loss_kd 2.571, Train_accy 85.92, Test_accy 60.29
2024-08-02 20:39:49,520 [foster.py] => Task 24, Epoch 65/170 => Loss 3.195, Loss_clf 0.357, Loss_fe 0.182, Loss_kd 2.600, Train_accy 86.68, Test_accy 60.54
2024-08-02 20:39:52,431 [foster.py] => Task 24, Epoch 66/170 => Loss 3.200, Loss_clf 0.367, Loss_fe 0.181, Loss_kd 2.597, Train_accy 85.62
2024-08-02 20:39:57,508 [foster.py] => Task 24, Epoch 67/170 => Loss 3.173, Loss_clf 0.360, Loss_fe 0.171, Loss_kd 2.587, Train_accy 86.85, Test_accy 60.44
2024-08-02 20:40:02,647 [foster.py] => Task 24, Epoch 68/170 => Loss 3.126, Loss_clf 0.361, Loss_fe 0.151, Loss_kd 2.559, Train_accy 86.71, Test_accy 60.06
2024-08-02 20:40:07,728 [foster.py] => Task 24, Epoch 69/170 => Loss 3.200, Loss_clf 0.370, Loss_fe 0.171, Loss_kd 2.603, Train_accy 86.75, Test_accy 60.66
2024-08-02 20:40:12,843 [foster.py] => Task 24, Epoch 70/170 => Loss 3.200, Loss_clf 0.368, Loss_fe 0.178, Loss_kd 2.598, Train_accy 86.44, Test_accy 60.36
2024-08-02 20:40:15,756 [foster.py] => Task 24, Epoch 71/170 => Loss 3.209, Loss_clf 0.369, Loss_fe 0.172, Loss_kd 2.611, Train_accy 86.40
2024-08-02 20:40:20,830 [foster.py] => Task 24, Epoch 72/170 => Loss 3.185, Loss_clf 0.358, Loss_fe 0.169, Loss_kd 2.602, Train_accy 86.78, Test_accy 60.47
2024-08-02 20:40:25,925 [foster.py] => Task 24, Epoch 73/170 => Loss 3.173, Loss_clf 0.359, Loss_fe 0.179, Loss_kd 2.579, Train_accy 86.20, Test_accy 60.09
2024-08-02 20:40:30,976 [foster.py] => Task 24, Epoch 74/170 => Loss 3.156, Loss_clf 0.345, Loss_fe 0.175, Loss_kd 2.580, Train_accy 87.26, Test_accy 60.30
2024-08-02 20:40:36,086 [foster.py] => Task 24, Epoch 75/170 => Loss 3.176, Loss_clf 0.359, Loss_fe 0.167, Loss_kd 2.594, Train_accy 86.51, Test_accy 60.48
2024-08-02 20:40:38,979 [foster.py] => Task 24, Epoch 76/170 => Loss 3.163, Loss_clf 0.358, Loss_fe 0.166, Loss_kd 2.582, Train_accy 86.54
2024-08-02 20:40:44,043 [foster.py] => Task 24, Epoch 77/170 => Loss 3.152, Loss_clf 0.360, Loss_fe 0.163, Loss_kd 2.573, Train_accy 86.71, Test_accy 60.72
2024-08-02 20:40:49,086 [foster.py] => Task 24, Epoch 78/170 => Loss 3.168, Loss_clf 0.359, Loss_fe 0.155, Loss_kd 2.597, Train_accy 87.09, Test_accy 60.56
2024-08-02 20:40:54,147 [foster.py] => Task 24, Epoch 79/170 => Loss 3.145, Loss_clf 0.354, Loss_fe 0.155, Loss_kd 2.580, Train_accy 86.92, Test_accy 60.33
2024-08-02 20:40:59,291 [foster.py] => Task 24, Epoch 80/170 => Loss 3.158, Loss_clf 0.353, Loss_fe 0.151, Loss_kd 2.598, Train_accy 87.19, Test_accy 60.46
2024-08-02 20:41:02,171 [foster.py] => Task 24, Epoch 81/170 => Loss 3.143, Loss_clf 0.348, Loss_fe 0.158, Loss_kd 2.581, Train_accy 87.33
2024-08-02 20:41:07,235 [foster.py] => Task 24, Epoch 82/170 => Loss 3.167, Loss_clf 0.353, Loss_fe 0.151, Loss_kd 2.607, Train_accy 87.81, Test_accy 60.44
2024-08-02 20:41:12,256 [foster.py] => Task 24, Epoch 83/170 => Loss 3.135, Loss_clf 0.345, Loss_fe 0.141, Loss_kd 2.592, Train_accy 87.33, Test_accy 60.77
2024-08-02 20:41:17,308 [foster.py] => Task 24, Epoch 84/170 => Loss 3.164, Loss_clf 0.363, Loss_fe 0.156, Loss_kd 2.590, Train_accy 87.88, Test_accy 60.56
2024-08-02 20:41:22,402 [foster.py] => Task 24, Epoch 85/170 => Loss 3.144, Loss_clf 0.342, Loss_fe 0.151, Loss_kd 2.595, Train_accy 87.67, Test_accy 60.36
2024-08-02 20:41:25,432 [foster.py] => Task 24, Epoch 86/170 => Loss 3.116, Loss_clf 0.337, Loss_fe 0.149, Loss_kd 2.575, Train_accy 88.32
2024-08-02 20:41:30,507 [foster.py] => Task 24, Epoch 87/170 => Loss 3.082, Loss_clf 0.317, Loss_fe 0.141, Loss_kd 2.569, Train_accy 88.94, Test_accy 60.67
2024-08-02 20:41:35,620 [foster.py] => Task 24, Epoch 88/170 => Loss 3.068, Loss_clf 0.310, Loss_fe 0.140, Loss_kd 2.563, Train_accy 88.53, Test_accy 60.57
2024-08-02 20:41:40,699 [foster.py] => Task 24, Epoch 89/170 => Loss 3.093, Loss_clf 0.329, Loss_fe 0.129, Loss_kd 2.579, Train_accy 88.63, Test_accy 60.58
2024-08-02 20:41:45,805 [foster.py] => Task 24, Epoch 90/170 => Loss 3.128, Loss_clf 0.341, Loss_fe 0.138, Loss_kd 2.593, Train_accy 87.57, Test_accy 60.67
2024-08-02 20:41:48,673 [foster.py] => Task 24, Epoch 91/170 => Loss 3.112, Loss_clf 0.326, Loss_fe 0.147, Loss_kd 2.583, Train_accy 87.40
2024-08-02 20:41:53,730 [foster.py] => Task 24, Epoch 92/170 => Loss 3.086, Loss_clf 0.318, Loss_fe 0.141, Loss_kd 2.571, Train_accy 87.81, Test_accy 60.29
2024-08-02 20:41:58,782 [foster.py] => Task 24, Epoch 93/170 => Loss 3.109, Loss_clf 0.337, Loss_fe 0.150, Loss_kd 2.567, Train_accy 87.84, Test_accy 60.36
2024-08-02 20:42:03,800 [foster.py] => Task 24, Epoch 94/170 => Loss 3.137, Loss_clf 0.344, Loss_fe 0.161, Loss_kd 2.577, Train_accy 86.30, Test_accy 60.21
2024-08-02 20:42:08,905 [foster.py] => Task 24, Epoch 95/170 => Loss 3.173, Loss_clf 0.363, Loss_fe 0.158, Loss_kd 2.595, Train_accy 87.19, Test_accy 60.26
2024-08-02 20:42:11,834 [foster.py] => Task 24, Epoch 96/170 => Loss 3.095, Loss_clf 0.336, Loss_fe 0.141, Loss_kd 2.564, Train_accy 87.64
2024-08-02 20:42:16,899 [foster.py] => Task 24, Epoch 97/170 => Loss 3.129, Loss_clf 0.346, Loss_fe 0.135, Loss_kd 2.592, Train_accy 88.39, Test_accy 60.51
2024-08-02 20:42:22,015 [foster.py] => Task 24, Epoch 98/170 => Loss 3.122, Loss_clf 0.340, Loss_fe 0.138, Loss_kd 2.588, Train_accy 87.53, Test_accy 60.68
2024-08-02 20:42:27,127 [foster.py] => Task 24, Epoch 99/170 => Loss 3.119, Loss_clf 0.358, Loss_fe 0.142, Loss_kd 2.564, Train_accy 87.91, Test_accy 60.44
2024-08-02 20:42:32,189 [foster.py] => Task 24, Epoch 100/170 => Loss 3.094, Loss_clf 0.324, Loss_fe 0.121, Loss_kd 2.594, Train_accy 87.91, Test_accy 60.48
2024-08-02 20:42:35,087 [foster.py] => Task 24, Epoch 101/170 => Loss 3.122, Loss_clf 0.351, Loss_fe 0.118, Loss_kd 2.596, Train_accy 87.91
2024-08-02 20:42:40,167 [foster.py] => Task 24, Epoch 102/170 => Loss 3.111, Loss_clf 0.336, Loss_fe 0.117, Loss_kd 2.602, Train_accy 88.05, Test_accy 60.64
2024-08-02 20:42:45,253 [foster.py] => Task 24, Epoch 103/170 => Loss 3.111, Loss_clf 0.345, Loss_fe 0.137, Loss_kd 2.574, Train_accy 86.75, Test_accy 60.53
2024-08-02 20:42:50,463 [foster.py] => Task 24, Epoch 104/170 => Loss 3.137, Loss_clf 0.347, Loss_fe 0.120, Loss_kd 2.614, Train_accy 87.33, Test_accy 60.70
2024-08-02 20:42:55,528 [foster.py] => Task 24, Epoch 105/170 => Loss 3.082, Loss_clf 0.338, Loss_fe 0.119, Loss_kd 2.570, Train_accy 87.64, Test_accy 60.40
2024-08-02 20:42:58,439 [foster.py] => Task 24, Epoch 106/170 => Loss 3.113, Loss_clf 0.340, Loss_fe 0.119, Loss_kd 2.598, Train_accy 88.22
2024-08-02 20:43:03,580 [foster.py] => Task 24, Epoch 107/170 => Loss 3.113, Loss_clf 0.343, Loss_fe 0.111, Loss_kd 2.603, Train_accy 88.08, Test_accy 60.73
2024-08-02 20:43:08,628 [foster.py] => Task 24, Epoch 108/170 => Loss 3.166, Loss_clf 0.357, Loss_fe 0.142, Loss_kd 2.611, Train_accy 88.42, Test_accy 60.73
2024-08-02 20:43:13,684 [foster.py] => Task 24, Epoch 109/170 => Loss 3.043, Loss_clf 0.298, Loss_fe 0.116, Loss_kd 2.574, Train_accy 89.04, Test_accy 60.88
2024-08-02 20:43:18,802 [foster.py] => Task 24, Epoch 110/170 => Loss 3.063, Loss_clf 0.317, Loss_fe 0.109, Loss_kd 2.581, Train_accy 88.12, Test_accy 60.62
2024-08-02 20:43:21,671 [foster.py] => Task 24, Epoch 111/170 => Loss 3.080, Loss_clf 0.329, Loss_fe 0.114, Loss_kd 2.581, Train_accy 88.25
2024-08-02 20:43:26,740 [foster.py] => Task 24, Epoch 112/170 => Loss 3.128, Loss_clf 0.355, Loss_fe 0.114, Loss_kd 2.603, Train_accy 88.42, Test_accy 60.68
2024-08-02 20:43:31,802 [foster.py] => Task 24, Epoch 113/170 => Loss 3.018, Loss_clf 0.301, Loss_fe 0.096, Loss_kd 2.565, Train_accy 88.97, Test_accy 60.84
2024-08-02 20:43:36,866 [foster.py] => Task 24, Epoch 114/170 => Loss 3.035, Loss_clf 0.306, Loss_fe 0.105, Loss_kd 2.569, Train_accy 88.94, Test_accy 60.69
2024-08-02 20:43:41,932 [foster.py] => Task 24, Epoch 115/170 => Loss 3.036, Loss_clf 0.314, Loss_fe 0.098, Loss_kd 2.569, Train_accy 88.80, Test_accy 60.65
2024-08-02 20:43:44,814 [foster.py] => Task 24, Epoch 116/170 => Loss 3.067, Loss_clf 0.320, Loss_fe 0.113, Loss_kd 2.578, Train_accy 88.53
2024-08-02 20:43:49,944 [foster.py] => Task 24, Epoch 117/170 => Loss 3.115, Loss_clf 0.334, Loss_fe 0.117, Loss_kd 2.608, Train_accy 88.42, Test_accy 60.88
2024-08-02 20:43:55,031 [foster.py] => Task 24, Epoch 118/170 => Loss 3.151, Loss_clf 0.347, Loss_fe 0.115, Loss_kd 2.633, Train_accy 87.74, Test_accy 60.84
2024-08-02 20:44:00,083 [foster.py] => Task 24, Epoch 119/170 => Loss 3.078, Loss_clf 0.326, Loss_fe 0.119, Loss_kd 2.577, Train_accy 88.42, Test_accy 60.63
2024-08-02 20:44:05,127 [foster.py] => Task 24, Epoch 120/170 => Loss 3.069, Loss_clf 0.320, Loss_fe 0.100, Loss_kd 2.594, Train_accy 88.94, Test_accy 60.79
2024-08-02 20:44:08,043 [foster.py] => Task 24, Epoch 121/170 => Loss 3.105, Loss_clf 0.338, Loss_fe 0.114, Loss_kd 2.598, Train_accy 87.84
2024-08-02 20:44:13,128 [foster.py] => Task 24, Epoch 122/170 => Loss 3.115, Loss_clf 0.354, Loss_fe 0.111, Loss_kd 2.594, Train_accy 88.29, Test_accy 60.74
2024-08-02 20:44:18,225 [foster.py] => Task 24, Epoch 123/170 => Loss 3.050, Loss_clf 0.317, Loss_fe 0.097, Loss_kd 2.581, Train_accy 89.52, Test_accy 60.74
2024-08-02 20:44:23,311 [foster.py] => Task 24, Epoch 124/170 => Loss 3.044, Loss_clf 0.305, Loss_fe 0.091, Loss_kd 2.592, Train_accy 89.73, Test_accy 60.81
2024-08-02 20:44:28,400 [foster.py] => Task 24, Epoch 125/170 => Loss 3.040, Loss_clf 0.316, Loss_fe 0.102, Loss_kd 2.567, Train_accy 89.04, Test_accy 60.69
2024-08-02 20:44:31,341 [foster.py] => Task 24, Epoch 126/170 => Loss 3.047, Loss_clf 0.308, Loss_fe 0.101, Loss_kd 2.582, Train_accy 90.07
2024-08-02 20:44:36,384 [foster.py] => Task 24, Epoch 127/170 => Loss 3.049, Loss_clf 0.317, Loss_fe 0.104, Loss_kd 2.572, Train_accy 88.32, Test_accy 60.79
2024-08-02 20:44:41,460 [foster.py] => Task 24, Epoch 128/170 => Loss 3.045, Loss_clf 0.317, Loss_fe 0.090, Loss_kd 2.582, Train_accy 89.04, Test_accy 60.58
2024-08-02 20:44:46,528 [foster.py] => Task 24, Epoch 129/170 => Loss 3.099, Loss_clf 0.336, Loss_fe 0.099, Loss_kd 2.608, Train_accy 88.08, Test_accy 60.59
2024-08-02 20:44:51,591 [foster.py] => Task 24, Epoch 130/170 => Loss 3.097, Loss_clf 0.335, Loss_fe 0.098, Loss_kd 2.608, Train_accy 89.11, Test_accy 60.72
2024-08-02 20:44:54,523 [foster.py] => Task 24, Epoch 131/170 => Loss 3.044, Loss_clf 0.315, Loss_fe 0.091, Loss_kd 2.583, Train_accy 89.14
2024-08-02 20:44:59,689 [foster.py] => Task 24, Epoch 132/170 => Loss 3.079, Loss_clf 0.324, Loss_fe 0.106, Loss_kd 2.593, Train_accy 89.28, Test_accy 60.79
2024-08-02 20:45:04,752 [foster.py] => Task 24, Epoch 133/170 => Loss 3.056, Loss_clf 0.311, Loss_fe 0.097, Loss_kd 2.592, Train_accy 89.38, Test_accy 60.86
2024-08-02 20:45:09,838 [foster.py] => Task 24, Epoch 134/170 => Loss 3.047, Loss_clf 0.316, Loss_fe 0.102, Loss_kd 2.574, Train_accy 88.70, Test_accy 60.84
2024-08-02 20:45:14,938 [foster.py] => Task 24, Epoch 135/170 => Loss 3.037, Loss_clf 0.317, Loss_fe 0.097, Loss_kd 2.569, Train_accy 89.14, Test_accy 60.90
2024-08-02 20:45:17,825 [foster.py] => Task 24, Epoch 136/170 => Loss 3.022, Loss_clf 0.319, Loss_fe 0.088, Loss_kd 2.560, Train_accy 88.84
2024-08-02 20:45:22,898 [foster.py] => Task 24, Epoch 137/170 => Loss 3.119, Loss_clf 0.354, Loss_fe 0.103, Loss_kd 2.606, Train_accy 88.56, Test_accy 60.84
2024-08-02 20:45:27,958 [foster.py] => Task 24, Epoch 138/170 => Loss 3.005, Loss_clf 0.308, Loss_fe 0.090, Loss_kd 2.552, Train_accy 89.42, Test_accy 60.87
2024-08-02 20:45:33,031 [foster.py] => Task 24, Epoch 139/170 => Loss 3.049, Loss_clf 0.324, Loss_fe 0.087, Loss_kd 2.582, Train_accy 88.97, Test_accy 60.88
2024-08-02 20:45:38,082 [foster.py] => Task 24, Epoch 140/170 => Loss 3.058, Loss_clf 0.314, Loss_fe 0.105, Loss_kd 2.583, Train_accy 89.59, Test_accy 60.92
2024-08-02 20:45:40,951 [foster.py] => Task 24, Epoch 141/170 => Loss 3.047, Loss_clf 0.327, Loss_fe 0.091, Loss_kd 2.574, Train_accy 88.84
2024-08-02 20:45:46,066 [foster.py] => Task 24, Epoch 142/170 => Loss 3.050, Loss_clf 0.320, Loss_fe 0.095, Loss_kd 2.579, Train_accy 88.97, Test_accy 60.94
2024-08-02 20:45:51,139 [foster.py] => Task 24, Epoch 143/170 => Loss 3.093, Loss_clf 0.335, Loss_fe 0.110, Loss_kd 2.592, Train_accy 88.15, Test_accy 60.83
2024-08-02 20:45:56,269 [foster.py] => Task 24, Epoch 144/170 => Loss 3.001, Loss_clf 0.296, Loss_fe 0.084, Loss_kd 2.567, Train_accy 89.66, Test_accy 60.84
2024-08-02 20:46:01,393 [foster.py] => Task 24, Epoch 145/170 => Loss 3.008, Loss_clf 0.307, Loss_fe 0.086, Loss_kd 2.560, Train_accy 89.32, Test_accy 60.80
2024-08-02 20:46:04,305 [foster.py] => Task 24, Epoch 146/170 => Loss 3.030, Loss_clf 0.312, Loss_fe 0.092, Loss_kd 2.571, Train_accy 88.84
2024-08-02 20:46:09,522 [foster.py] => Task 24, Epoch 147/170 => Loss 3.112, Loss_clf 0.343, Loss_fe 0.104, Loss_kd 2.609, Train_accy 88.60, Test_accy 60.82
2024-08-02 20:46:14,590 [foster.py] => Task 24, Epoch 148/170 => Loss 3.026, Loss_clf 0.316, Loss_fe 0.082, Loss_kd 2.573, Train_accy 89.18, Test_accy 60.79
2024-08-02 20:46:19,739 [foster.py] => Task 24, Epoch 149/170 => Loss 3.003, Loss_clf 0.297, Loss_fe 0.087, Loss_kd 2.563, Train_accy 90.14, Test_accy 60.78
2024-08-02 20:46:24,853 [foster.py] => Task 24, Epoch 150/170 => Loss 3.019, Loss_clf 0.301, Loss_fe 0.082, Loss_kd 2.581, Train_accy 90.17, Test_accy 60.77
2024-08-02 20:46:27,753 [foster.py] => Task 24, Epoch 151/170 => Loss 3.060, Loss_clf 0.318, Loss_fe 0.100, Loss_kd 2.587, Train_accy 89.35
2024-08-02 20:46:32,810 [foster.py] => Task 24, Epoch 152/170 => Loss 3.062, Loss_clf 0.313, Loss_fe 0.095, Loss_kd 2.598, Train_accy 90.34, Test_accy 60.74
2024-08-02 20:46:37,932 [foster.py] => Task 24, Epoch 153/170 => Loss 3.082, Loss_clf 0.334, Loss_fe 0.086, Loss_kd 2.606, Train_accy 89.52, Test_accy 60.80
2024-08-02 20:46:43,015 [foster.py] => Task 24, Epoch 154/170 => Loss 3.023, Loss_clf 0.307, Loss_fe 0.088, Loss_kd 2.573, Train_accy 89.28, Test_accy 60.77
2024-08-02 20:46:48,061 [foster.py] => Task 24, Epoch 155/170 => Loss 3.028, Loss_clf 0.308, Loss_fe 0.089, Loss_kd 2.575, Train_accy 89.52, Test_accy 60.70
2024-08-02 20:46:50,966 [foster.py] => Task 24, Epoch 156/170 => Loss 3.019, Loss_clf 0.316, Loss_fe 0.089, Loss_kd 2.558, Train_accy 89.25
2024-08-02 20:46:56,071 [foster.py] => Task 24, Epoch 157/170 => Loss 3.017, Loss_clf 0.301, Loss_fe 0.095, Loss_kd 2.566, Train_accy 89.76, Test_accy 60.68
2024-08-02 20:47:01,143 [foster.py] => Task 24, Epoch 158/170 => Loss 3.052, Loss_clf 0.316, Loss_fe 0.088, Loss_kd 2.591, Train_accy 89.66, Test_accy 60.73
2024-08-02 20:47:06,285 [foster.py] => Task 24, Epoch 159/170 => Loss 3.035, Loss_clf 0.313, Loss_fe 0.071, Loss_kd 2.596, Train_accy 89.69, Test_accy 60.69
2024-08-02 20:47:11,357 [foster.py] => Task 24, Epoch 160/170 => Loss 3.025, Loss_clf 0.308, Loss_fe 0.088, Loss_kd 2.572, Train_accy 89.59, Test_accy 60.68
2024-08-02 20:47:14,250 [foster.py] => Task 24, Epoch 161/170 => Loss 3.068, Loss_clf 0.323, Loss_fe 0.088, Loss_kd 2.601, Train_accy 89.73
2024-08-02 20:47:19,332 [foster.py] => Task 24, Epoch 162/170 => Loss 3.013, Loss_clf 0.298, Loss_fe 0.081, Loss_kd 2.579, Train_accy 90.38, Test_accy 60.69
2024-08-02 20:47:24,396 [foster.py] => Task 24, Epoch 163/170 => Loss 3.066, Loss_clf 0.315, Loss_fe 0.098, Loss_kd 2.597, Train_accy 89.38, Test_accy 60.73
2024-08-02 20:47:29,546 [foster.py] => Task 24, Epoch 164/170 => Loss 3.044, Loss_clf 0.310, Loss_fe 0.087, Loss_kd 2.591, Train_accy 89.55, Test_accy 60.68
2024-08-02 20:47:34,613 [foster.py] => Task 24, Epoch 165/170 => Loss 3.089, Loss_clf 0.329, Loss_fe 0.086, Loss_kd 2.618, Train_accy 88.80, Test_accy 60.71
2024-08-02 20:47:37,540 [foster.py] => Task 24, Epoch 166/170 => Loss 3.020, Loss_clf 0.305, Loss_fe 0.088, Loss_kd 2.571, Train_accy 89.11
2024-08-02 20:47:42,590 [foster.py] => Task 24, Epoch 167/170 => Loss 3.026, Loss_clf 0.306, Loss_fe 0.089, Loss_kd 2.575, Train_accy 89.42, Test_accy 60.70
2024-08-02 20:47:47,750 [foster.py] => Task 24, Epoch 168/170 => Loss 3.081, Loss_clf 0.322, Loss_fe 0.082, Loss_kd 2.620, Train_accy 88.77, Test_accy 60.74
2024-08-02 20:47:52,811 [foster.py] => Task 24, Epoch 169/170 => Loss 3.051, Loss_clf 0.317, Loss_fe 0.084, Loss_kd 2.593, Train_accy 89.73, Test_accy 60.73
2024-08-02 20:47:57,906 [foster.py] => Task 24, Epoch 170/170 => Loss 3.027, Loss_clf 0.305, Loss_fe 0.083, Loss_kd 2.583, Train_accy 89.76, Test_accy 60.71
2024-08-02 20:47:57,908 [foster.py] => do not weight align teacher!
2024-08-02 20:47:57,909 [foster.py] => per cls weights : [1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484 1.01107484
 0.46840776 0.46840776]
2024-08-02 20:48:03,518 [foster.py] => SNet: Task 24, Epoch 1/130 => Loss 31.219,  Loss1 0.792, Train_accy 62.71, Test_accy 57.90
2024-08-02 20:48:07,600 [foster.py] => SNet: Task 24, Epoch 2/130 => Loss 31.161,  Loss1 0.792, Train_accy 70.55
2024-08-02 20:48:11,662 [foster.py] => SNet: Task 24, Epoch 3/130 => Loss 31.118,  Loss1 0.792, Train_accy 71.85
2024-08-02 20:48:15,729 [foster.py] => SNet: Task 24, Epoch 4/130 => Loss 31.154,  Loss1 0.792, Train_accy 71.40
2024-08-02 20:48:19,809 [foster.py] => SNet: Task 24, Epoch 5/130 => Loss 31.131,  Loss1 0.792, Train_accy 73.01
2024-08-02 20:48:25,277 [foster.py] => SNet: Task 24, Epoch 6/130 => Loss 31.124,  Loss1 0.792, Train_accy 72.67, Test_accy 59.07
2024-08-02 20:48:29,376 [foster.py] => SNet: Task 24, Epoch 7/130 => Loss 31.144,  Loss1 0.793, Train_accy 75.55
2024-08-02 20:48:33,519 [foster.py] => SNet: Task 24, Epoch 8/130 => Loss 31.182,  Loss1 0.792, Train_accy 73.60
2024-08-02 20:48:37,583 [foster.py] => SNet: Task 24, Epoch 9/130 => Loss 31.149,  Loss1 0.792, Train_accy 75.27
2024-08-02 20:48:41,651 [foster.py] => SNet: Task 24, Epoch 10/130 => Loss 31.123,  Loss1 0.792, Train_accy 74.35
2024-08-02 20:48:47,126 [foster.py] => SNet: Task 24, Epoch 11/130 => Loss 31.140,  Loss1 0.792, Train_accy 75.51, Test_accy 59.96
2024-08-02 20:48:51,188 [foster.py] => SNet: Task 24, Epoch 12/130 => Loss 31.083,  Loss1 0.791, Train_accy 75.72
2024-08-02 20:48:55,320 [foster.py] => SNet: Task 24, Epoch 13/130 => Loss 31.089,  Loss1 0.792, Train_accy 75.89
2024-08-02 20:48:59,373 [foster.py] => SNet: Task 24, Epoch 14/130 => Loss 31.101,  Loss1 0.792, Train_accy 76.06
2024-08-02 20:49:03,436 [foster.py] => SNet: Task 24, Epoch 15/130 => Loss 31.114,  Loss1 0.792, Train_accy 76.64
2024-08-02 20:49:08,839 [foster.py] => SNet: Task 24, Epoch 16/130 => Loss 31.156,  Loss1 0.792, Train_accy 75.72, Test_accy 59.88
2024-08-02 20:49:12,950 [foster.py] => SNet: Task 24, Epoch 17/130 => Loss 31.116,  Loss1 0.792, Train_accy 75.34
2024-08-02 20:49:17,031 [foster.py] => SNet: Task 24, Epoch 18/130 => Loss 31.113,  Loss1 0.792, Train_accy 76.99
2024-08-02 20:49:21,103 [foster.py] => SNet: Task 24, Epoch 19/130 => Loss 31.150,  Loss1 0.792, Train_accy 76.75
2024-08-02 20:49:25,183 [foster.py] => SNet: Task 24, Epoch 20/130 => Loss 31.114,  Loss1 0.792, Train_accy 76.71
2024-08-02 20:49:30,662 [foster.py] => SNet: Task 24, Epoch 21/130 => Loss 31.124,  Loss1 0.792, Train_accy 77.47, Test_accy 59.99
2024-08-02 20:49:34,759 [foster.py] => SNet: Task 24, Epoch 22/130 => Loss 31.082,  Loss1 0.792, Train_accy 76.78
2024-08-02 20:49:38,823 [foster.py] => SNet: Task 24, Epoch 23/130 => Loss 31.121,  Loss1 0.792, Train_accy 76.75
2024-08-02 20:49:42,978 [foster.py] => SNet: Task 24, Epoch 24/130 => Loss 31.073,  Loss1 0.792, Train_accy 78.39
2024-08-02 20:49:47,080 [foster.py] => SNet: Task 24, Epoch 25/130 => Loss 31.094,  Loss1 0.792, Train_accy 77.71
2024-08-02 20:49:52,503 [foster.py] => SNet: Task 24, Epoch 26/130 => Loss 31.161,  Loss1 0.791, Train_accy 76.82, Test_accy 59.60
2024-08-02 20:49:56,592 [foster.py] => SNet: Task 24, Epoch 27/130 => Loss 31.136,  Loss1 0.793, Train_accy 78.05
2024-08-02 20:50:00,680 [foster.py] => SNet: Task 24, Epoch 28/130 => Loss 31.128,  Loss1 0.792, Train_accy 76.51
2024-08-02 20:50:04,783 [foster.py] => SNet: Task 24, Epoch 29/130 => Loss 31.130,  Loss1 0.792, Train_accy 77.23
2024-08-02 20:50:08,864 [foster.py] => SNet: Task 24, Epoch 30/130 => Loss 31.130,  Loss1 0.792, Train_accy 76.82
2024-08-02 20:50:14,304 [foster.py] => SNet: Task 24, Epoch 31/130 => Loss 31.118,  Loss1 0.792, Train_accy 78.22, Test_accy 59.54
2024-08-02 20:50:18,357 [foster.py] => SNet: Task 24, Epoch 32/130 => Loss 31.121,  Loss1 0.792, Train_accy 79.52
2024-08-02 20:50:22,441 [foster.py] => SNet: Task 24, Epoch 33/130 => Loss 31.151,  Loss1 0.792, Train_accy 76.68
2024-08-02 20:50:26,492 [foster.py] => SNet: Task 24, Epoch 34/130 => Loss 31.120,  Loss1 0.792, Train_accy 77.57
2024-08-02 20:50:30,576 [foster.py] => SNet: Task 24, Epoch 35/130 => Loss 31.103,  Loss1 0.792, Train_accy 77.67
2024-08-02 20:50:35,949 [foster.py] => SNet: Task 24, Epoch 36/130 => Loss 31.115,  Loss1 0.792, Train_accy 76.95, Test_accy 59.93
2024-08-02 20:50:40,020 [foster.py] => SNet: Task 24, Epoch 37/130 => Loss 31.123,  Loss1 0.792, Train_accy 78.15
2024-08-02 20:50:44,070 [foster.py] => SNet: Task 24, Epoch 38/130 => Loss 31.102,  Loss1 0.791, Train_accy 76.20
2024-08-02 20:50:48,148 [foster.py] => SNet: Task 24, Epoch 39/130 => Loss 31.111,  Loss1 0.793, Train_accy 78.15
2024-08-02 20:50:52,231 [foster.py] => SNet: Task 24, Epoch 40/130 => Loss 31.080,  Loss1 0.792, Train_accy 79.11
2024-08-02 20:50:57,704 [foster.py] => SNet: Task 24, Epoch 41/130 => Loss 31.093,  Loss1 0.792, Train_accy 78.12, Test_accy 60.00
2024-08-02 20:51:01,768 [foster.py] => SNet: Task 24, Epoch 42/130 => Loss 31.108,  Loss1 0.792, Train_accy 78.25
2024-08-02 20:51:05,836 [foster.py] => SNet: Task 24, Epoch 43/130 => Loss 31.117,  Loss1 0.792, Train_accy 77.53
2024-08-02 20:51:09,920 [foster.py] => SNet: Task 24, Epoch 44/130 => Loss 31.140,  Loss1 0.792, Train_accy 78.53
2024-08-02 20:51:14,027 [foster.py] => SNet: Task 24, Epoch 45/130 => Loss 31.094,  Loss1 0.792, Train_accy 79.59
2024-08-02 20:51:19,437 [foster.py] => SNet: Task 24, Epoch 46/130 => Loss 31.099,  Loss1 0.792, Train_accy 78.66, Test_accy 59.96
2024-08-02 20:51:23,502 [foster.py] => SNet: Task 24, Epoch 47/130 => Loss 31.141,  Loss1 0.793, Train_accy 78.01
2024-08-02 20:51:27,552 [foster.py] => SNet: Task 24, Epoch 48/130 => Loss 31.112,  Loss1 0.792, Train_accy 77.43
2024-08-02 20:51:31,612 [foster.py] => SNet: Task 24, Epoch 49/130 => Loss 31.105,  Loss1 0.792, Train_accy 78.25
2024-08-02 20:51:35,693 [foster.py] => SNet: Task 24, Epoch 50/130 => Loss 31.113,  Loss1 0.792, Train_accy 78.22
2024-08-02 20:51:41,111 [foster.py] => SNet: Task 24, Epoch 51/130 => Loss 31.100,  Loss1 0.792, Train_accy 78.36, Test_accy 60.44
2024-08-02 20:51:45,172 [foster.py] => SNet: Task 24, Epoch 52/130 => Loss 31.094,  Loss1 0.792, Train_accy 78.70
2024-08-02 20:51:49,249 [foster.py] => SNet: Task 24, Epoch 53/130 => Loss 31.083,  Loss1 0.793, Train_accy 78.60
2024-08-02 20:51:53,329 [foster.py] => SNet: Task 24, Epoch 54/130 => Loss 31.057,  Loss1 0.792, Train_accy 78.97
2024-08-02 20:51:57,384 [foster.py] => SNet: Task 24, Epoch 55/130 => Loss 31.093,  Loss1 0.792, Train_accy 77.77
2024-08-02 20:52:02,798 [foster.py] => SNet: Task 24, Epoch 56/130 => Loss 31.117,  Loss1 0.792, Train_accy 78.80, Test_accy 59.93
2024-08-02 20:52:06,941 [foster.py] => SNet: Task 24, Epoch 57/130 => Loss 31.122,  Loss1 0.793, Train_accy 78.87
2024-08-02 20:52:11,050 [foster.py] => SNet: Task 24, Epoch 58/130 => Loss 31.111,  Loss1 0.792, Train_accy 77.50
2024-08-02 20:52:15,103 [foster.py] => SNet: Task 24, Epoch 59/130 => Loss 31.078,  Loss1 0.792, Train_accy 78.36
2024-08-02 20:52:19,164 [foster.py] => SNet: Task 24, Epoch 60/130 => Loss 31.077,  Loss1 0.793, Train_accy 78.90
2024-08-02 20:52:24,628 [foster.py] => SNet: Task 24, Epoch 61/130 => Loss 31.125,  Loss1 0.792, Train_accy 77.84, Test_accy 60.30
2024-08-02 20:52:28,675 [foster.py] => SNet: Task 24, Epoch 62/130 => Loss 31.130,  Loss1 0.792, Train_accy 77.81
2024-08-02 20:52:32,749 [foster.py] => SNet: Task 24, Epoch 63/130 => Loss 31.107,  Loss1 0.792, Train_accy 79.49
2024-08-02 20:52:36,807 [foster.py] => SNet: Task 24, Epoch 64/130 => Loss 31.101,  Loss1 0.792, Train_accy 77.64
2024-08-02 20:52:40,859 [foster.py] => SNet: Task 24, Epoch 65/130 => Loss 31.097,  Loss1 0.792, Train_accy 79.79
2024-08-02 20:52:46,271 [foster.py] => SNet: Task 24, Epoch 66/130 => Loss 31.094,  Loss1 0.792, Train_accy 78.70, Test_accy 60.19
2024-08-02 20:52:50,387 [foster.py] => SNet: Task 24, Epoch 67/130 => Loss 31.133,  Loss1 0.792, Train_accy 78.18
2024-08-02 20:52:54,452 [foster.py] => SNet: Task 24, Epoch 68/130 => Loss 31.150,  Loss1 0.792, Train_accy 78.73
2024-08-02 20:52:58,555 [foster.py] => SNet: Task 24, Epoch 69/130 => Loss 31.142,  Loss1 0.792, Train_accy 77.88
2024-08-02 20:53:02,651 [foster.py] => SNet: Task 24, Epoch 70/130 => Loss 31.075,  Loss1 0.792, Train_accy 76.99
2024-08-02 20:53:08,068 [foster.py] => SNet: Task 24, Epoch 71/130 => Loss 31.096,  Loss1 0.792, Train_accy 78.22, Test_accy 60.18
2024-08-02 20:53:12,144 [foster.py] => SNet: Task 24, Epoch 72/130 => Loss 31.103,  Loss1 0.792, Train_accy 80.10
2024-08-02 20:53:16,239 [foster.py] => SNet: Task 24, Epoch 73/130 => Loss 31.097,  Loss1 0.792, Train_accy 77.84
2024-08-02 20:53:20,470 [foster.py] => SNet: Task 24, Epoch 74/130 => Loss 31.098,  Loss1 0.792, Train_accy 78.77
2024-08-02 20:53:24,603 [foster.py] => SNet: Task 24, Epoch 75/130 => Loss 31.113,  Loss1 0.792, Train_accy 78.15
2024-08-02 20:53:30,030 [foster.py] => SNet: Task 24, Epoch 76/130 => Loss 31.098,  Loss1 0.792, Train_accy 79.11, Test_accy 60.11
2024-08-02 20:53:34,088 [foster.py] => SNet: Task 24, Epoch 77/130 => Loss 31.104,  Loss1 0.792, Train_accy 78.29
2024-08-02 20:53:38,160 [foster.py] => SNet: Task 24, Epoch 78/130 => Loss 31.068,  Loss1 0.793, Train_accy 78.46
2024-08-02 20:53:42,227 [foster.py] => SNet: Task 24, Epoch 79/130 => Loss 31.086,  Loss1 0.792, Train_accy 78.08
2024-08-02 20:53:46,296 [foster.py] => SNet: Task 24, Epoch 80/130 => Loss 31.104,  Loss1 0.793, Train_accy 80.14
2024-08-02 20:53:51,727 [foster.py] => SNet: Task 24, Epoch 81/130 => Loss 31.070,  Loss1 0.792, Train_accy 79.18, Test_accy 60.18
2024-08-02 20:53:55,859 [foster.py] => SNet: Task 24, Epoch 82/130 => Loss 31.124,  Loss1 0.792, Train_accy 79.01
2024-08-02 20:53:59,913 [foster.py] => SNet: Task 24, Epoch 83/130 => Loss 31.063,  Loss1 0.792, Train_accy 79.97
2024-08-02 20:54:04,013 [foster.py] => SNet: Task 24, Epoch 84/130 => Loss 31.106,  Loss1 0.792, Train_accy 79.49
2024-08-02 20:54:08,103 [foster.py] => SNet: Task 24, Epoch 85/130 => Loss 31.056,  Loss1 0.792, Train_accy 79.35
2024-08-02 20:54:13,528 [foster.py] => SNet: Task 24, Epoch 86/130 => Loss 31.129,  Loss1 0.791, Train_accy 78.63, Test_accy 60.42
2024-08-02 20:54:17,564 [foster.py] => SNet: Task 24, Epoch 87/130 => Loss 31.099,  Loss1 0.792, Train_accy 79.45
2024-08-02 20:54:21,598 [foster.py] => SNet: Task 24, Epoch 88/130 => Loss 31.069,  Loss1 0.792, Train_accy 78.80
2024-08-02 20:54:25,696 [foster.py] => SNet: Task 24, Epoch 89/130 => Loss 31.088,  Loss1 0.792, Train_accy 78.05
2024-08-02 20:54:29,855 [foster.py] => SNet: Task 24, Epoch 90/130 => Loss 31.138,  Loss1 0.792, Train_accy 78.46
2024-08-02 20:54:35,258 [foster.py] => SNet: Task 24, Epoch 91/130 => Loss 31.060,  Loss1 0.791, Train_accy 79.28, Test_accy 60.46
2024-08-02 20:54:39,329 [foster.py] => SNet: Task 24, Epoch 92/130 => Loss 31.132,  Loss1 0.792, Train_accy 77.98
2024-08-02 20:54:43,416 [foster.py] => SNet: Task 24, Epoch 93/130 => Loss 31.115,  Loss1 0.792, Train_accy 78.49
2024-08-02 20:54:47,504 [foster.py] => SNet: Task 24, Epoch 94/130 => Loss 31.101,  Loss1 0.792, Train_accy 79.28
2024-08-02 20:54:51,567 [foster.py] => SNet: Task 24, Epoch 95/130 => Loss 31.087,  Loss1 0.791, Train_accy 79.79
2024-08-02 20:54:57,010 [foster.py] => SNet: Task 24, Epoch 96/130 => Loss 31.108,  Loss1 0.792, Train_accy 78.97, Test_accy 60.35
2024-08-02 20:55:01,085 [foster.py] => SNet: Task 24, Epoch 97/130 => Loss 31.126,  Loss1 0.793, Train_accy 79.45
2024-08-02 20:55:05,210 [foster.py] => SNet: Task 24, Epoch 98/130 => Loss 31.093,  Loss1 0.792, Train_accy 78.70
2024-08-02 20:55:09,287 [foster.py] => SNet: Task 24, Epoch 99/130 => Loss 31.102,  Loss1 0.791, Train_accy 78.77
2024-08-02 20:55:13,362 [foster.py] => SNet: Task 24, Epoch 100/130 => Loss 31.100,  Loss1 0.792, Train_accy 78.29
2024-08-02 20:55:18,796 [foster.py] => SNet: Task 24, Epoch 101/130 => Loss 31.071,  Loss1 0.792, Train_accy 78.15, Test_accy 60.45
2024-08-02 20:55:22,869 [foster.py] => SNet: Task 24, Epoch 102/130 => Loss 31.122,  Loss1 0.792, Train_accy 80.17
2024-08-02 20:55:26,931 [foster.py] => SNet: Task 24, Epoch 103/130 => Loss 31.090,  Loss1 0.792, Train_accy 79.52
2024-08-02 20:55:30,997 [foster.py] => SNet: Task 24, Epoch 104/130 => Loss 31.080,  Loss1 0.792, Train_accy 79.49
2024-08-02 20:55:35,066 [foster.py] => SNet: Task 24, Epoch 105/130 => Loss 31.135,  Loss1 0.792, Train_accy 78.18
2024-08-02 20:55:40,467 [foster.py] => SNet: Task 24, Epoch 106/130 => Loss 31.079,  Loss1 0.792, Train_accy 78.73, Test_accy 60.34
2024-08-02 20:55:44,571 [foster.py] => SNet: Task 24, Epoch 107/130 => Loss 31.124,  Loss1 0.792, Train_accy 78.94
2024-08-02 20:55:48,689 [foster.py] => SNet: Task 24, Epoch 108/130 => Loss 31.105,  Loss1 0.792, Train_accy 78.25
2024-08-02 20:55:52,760 [foster.py] => SNet: Task 24, Epoch 109/130 => Loss 31.109,  Loss1 0.793, Train_accy 78.94
2024-08-02 20:55:56,835 [foster.py] => SNet: Task 24, Epoch 110/130 => Loss 31.083,  Loss1 0.792, Train_accy 79.35
2024-08-02 20:56:02,290 [foster.py] => SNet: Task 24, Epoch 111/130 => Loss 31.078,  Loss1 0.792, Train_accy 79.11, Test_accy 60.42
2024-08-02 20:56:06,355 [foster.py] => SNet: Task 24, Epoch 112/130 => Loss 31.101,  Loss1 0.792, Train_accy 79.45
2024-08-02 20:56:10,412 [foster.py] => SNet: Task 24, Epoch 113/130 => Loss 31.119,  Loss1 0.792, Train_accy 79.01
2024-08-02 20:56:14,484 [foster.py] => SNet: Task 24, Epoch 114/130 => Loss 31.119,  Loss1 0.792, Train_accy 77.53
2024-08-02 20:56:18,562 [foster.py] => SNet: Task 24, Epoch 115/130 => Loss 31.136,  Loss1 0.792, Train_accy 79.55
2024-08-02 20:56:23,976 [foster.py] => SNet: Task 24, Epoch 116/130 => Loss 31.073,  Loss1 0.792, Train_accy 79.32, Test_accy 60.30
2024-08-02 20:56:28,018 [foster.py] => SNet: Task 24, Epoch 117/130 => Loss 31.110,  Loss1 0.792, Train_accy 78.87
2024-08-02 20:56:32,082 [foster.py] => SNet: Task 24, Epoch 118/130 => Loss 31.060,  Loss1 0.792, Train_accy 79.11
2024-08-02 20:56:36,171 [foster.py] => SNet: Task 24, Epoch 119/130 => Loss 31.091,  Loss1 0.792, Train_accy 79.83
2024-08-02 20:56:40,221 [foster.py] => SNet: Task 24, Epoch 120/130 => Loss 31.124,  Loss1 0.792, Train_accy 78.08
2024-08-02 20:56:45,591 [foster.py] => SNet: Task 24, Epoch 121/130 => Loss 31.158,  Loss1 0.792, Train_accy 77.23, Test_accy 60.03
2024-08-02 20:56:49,656 [foster.py] => SNet: Task 24, Epoch 122/130 => Loss 31.101,  Loss1 0.792, Train_accy 79.21
2024-08-02 20:56:53,745 [foster.py] => SNet: Task 24, Epoch 123/130 => Loss 31.108,  Loss1 0.792, Train_accy 79.04
2024-08-02 20:56:57,850 [foster.py] => SNet: Task 24, Epoch 124/130 => Loss 31.118,  Loss1 0.792, Train_accy 78.70
2024-08-02 20:57:01,945 [foster.py] => SNet: Task 24, Epoch 125/130 => Loss 31.081,  Loss1 0.792, Train_accy 79.42
2024-08-02 20:57:07,330 [foster.py] => SNet: Task 24, Epoch 126/130 => Loss 31.100,  Loss1 0.792, Train_accy 78.01, Test_accy 60.35
2024-08-02 20:57:11,381 [foster.py] => SNet: Task 24, Epoch 127/130 => Loss 31.095,  Loss1 0.792, Train_accy 78.66
2024-08-02 20:57:15,446 [foster.py] => SNet: Task 24, Epoch 128/130 => Loss 31.098,  Loss1 0.792, Train_accy 78.87
2024-08-02 20:57:19,510 [foster.py] => SNet: Task 24, Epoch 129/130 => Loss 31.070,  Loss1 0.792, Train_accy 79.55
2024-08-02 20:57:23,596 [foster.py] => SNet: Task 24, Epoch 130/130 => Loss 31.111,  Loss1 0.792, Train_accy 78.97
2024-08-02 20:57:23,597 [foster.py] => do not weight align student!
2024-08-02 20:57:24,963 [foster.py] => darknet eval: 
2024-08-02 20:57:24,963 [foster.py] => CNN top1 curve: 60.31
2024-08-02 20:57:24,963 [foster.py] => CNN top5 curve: 84.88
2024-08-02 20:57:24,963 [foster.py] => CNN top1 平均值: 60.31
2024-08-02 20:57:24,969 [foster.py] => timees : 1359.055199623108
2024-08-02 20:57:24,970 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 20:57:54,770 [foster.py] => Exemplar size: 1960
2024-08-02 20:57:54,771 [trainer.py] => CNN: {'total': 60.71, '00-09': 66.1, '10-19': 50.5, '20-29': 66.2, '30-39': 58.1, '40-49': 64.8, '50-59': 48.4, '60-69': 58.4, '70-79': 58.2, '80-89': 68.7, '90-99': 69.5, 'old': 60.28, 'new': 81.5}
2024-08-02 20:57:54,771 [trainer.py] => NME: {'total': 54.94, '00-09': 52.6, '10-19': 39.5, '20-29': 59.3, '30-39': 49.9, '40-49': 56.6, '50-59': 42.1, '60-69': 59.1, '70-79': 61.3, '80-89': 69.9, '90-99': 60.12, 'old': 54.28, 'new': 86.5}
2024-08-02 20:57:54,771 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13, 62.75, 61.26, 60.76, 60.71]
2024-08-02 20:57:54,771 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99, 86.89, 85.94, 85.82, 85.39]
2024-08-02 20:57:54,771 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09, 57.52, 55.7, 54.34, 54.94]
2024-08-02 20:57:54,771 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79, 83.43, 81.69, 80.6, 80.78]

2024-08-02 20:57:54,771 [trainer.py] => CNN top1 平均值: 70.09
2024-08-02 20:57:54,774 [trainer.py] => All params: 1179800
2024-08-02 20:57:54,776 [trainer.py] => Trainable params: 596286
2024-08-02 20:57:54,837 [foster.py] => Learning on 98-100
2024-08-02 20:57:54,840 [foster.py] => All params: 1180318
2024-08-02 20:57:54,842 [foster.py] => Trainable params: 596674
2024-08-02 20:57:54,887 [foster.py] => per cls weights : [1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041 1.00914041
 1.00914041 1.00914041 0.55211999 0.55211999]
2024-08-02 20:57:57,945 [foster.py] => Task 25, Epoch 1/170 => Loss 5.255, Loss_clf 0.895, Loss_fe 1.681, Loss_kd 2.624, Train_accy 71.99
2024-08-02 20:58:03,173 [foster.py] => Task 25, Epoch 2/170 => Loss 3.933, Loss_clf 0.580, Loss_fe 0.704, Loss_kd 2.594, Train_accy 77.09, Test_accy 59.18
2024-08-02 20:58:08,418 [foster.py] => Task 25, Epoch 3/170 => Loss 3.810, Loss_clf 0.521, Loss_fe 0.625, Loss_kd 2.609, Train_accy 77.20, Test_accy 59.05
2024-08-02 20:58:13,631 [foster.py] => Task 25, Epoch 4/170 => Loss 3.720, Loss_clf 0.509, Loss_fe 0.560, Loss_kd 2.596, Train_accy 77.23, Test_accy 59.39
2024-08-02 20:58:18,858 [foster.py] => Task 25, Epoch 5/170 => Loss 3.613, Loss_clf 0.495, Loss_fe 0.514, Loss_kd 2.550, Train_accy 77.30, Test_accy 58.96
2024-08-02 20:58:21,832 [foster.py] => Task 25, Epoch 6/170 => Loss 3.542, Loss_clf 0.475, Loss_fe 0.453, Loss_kd 2.559, Train_accy 78.07
2024-08-02 20:58:27,042 [foster.py] => Task 25, Epoch 7/170 => Loss 3.572, Loss_clf 0.467, Loss_fe 0.439, Loss_kd 2.610, Train_accy 79.16, Test_accy 58.99
2024-08-02 20:58:32,325 [foster.py] => Task 25, Epoch 8/170 => Loss 3.537, Loss_clf 0.457, Loss_fe 0.441, Loss_kd 2.585, Train_accy 80.51, Test_accy 59.43
2024-08-02 20:58:37,562 [foster.py] => Task 25, Epoch 9/170 => Loss 3.560, Loss_clf 0.492, Loss_fe 0.432, Loss_kd 2.581, Train_accy 78.45, Test_accy 59.30
2024-08-02 20:58:42,760 [foster.py] => Task 25, Epoch 10/170 => Loss 3.585, Loss_clf 0.477, Loss_fe 0.455, Loss_kd 2.597, Train_accy 78.51, Test_accy 59.01
2024-08-02 20:58:45,743 [foster.py] => Task 25, Epoch 11/170 => Loss 3.489, Loss_clf 0.443, Loss_fe 0.414, Loss_kd 2.578, Train_accy 79.83
2024-08-02 20:58:50,936 [foster.py] => Task 25, Epoch 12/170 => Loss 3.540, Loss_clf 0.481, Loss_fe 0.413, Loss_kd 2.590, Train_accy 77.57, Test_accy 59.44
2024-08-02 20:58:56,190 [foster.py] => Task 25, Epoch 13/170 => Loss 3.560, Loss_clf 0.476, Loss_fe 0.420, Loss_kd 2.608, Train_accy 79.66, Test_accy 59.26
2024-08-02 20:59:01,385 [foster.py] => Task 25, Epoch 14/170 => Loss 3.501, Loss_clf 0.462, Loss_fe 0.399, Loss_kd 2.585, Train_accy 79.02, Test_accy 59.64
2024-08-02 20:59:06,621 [foster.py] => Task 25, Epoch 15/170 => Loss 3.483, Loss_clf 0.450, Loss_fe 0.409, Loss_kd 2.569, Train_accy 79.22, Test_accy 59.07
2024-08-02 20:59:09,656 [foster.py] => Task 25, Epoch 16/170 => Loss 3.415, Loss_clf 0.422, Loss_fe 0.350, Loss_kd 2.588, Train_accy 80.68
2024-08-02 20:59:14,939 [foster.py] => Task 25, Epoch 17/170 => Loss 3.421, Loss_clf 0.445, Loss_fe 0.350, Loss_kd 2.571, Train_accy 80.64, Test_accy 59.30
2024-08-02 20:59:20,180 [foster.py] => Task 25, Epoch 18/170 => Loss 3.489, Loss_clf 0.461, Loss_fe 0.381, Loss_kd 2.591, Train_accy 79.80, Test_accy 59.22
2024-08-02 20:59:25,408 [foster.py] => Task 25, Epoch 19/170 => Loss 3.476, Loss_clf 0.453, Loss_fe 0.375, Loss_kd 2.593, Train_accy 79.59, Test_accy 59.01
2024-08-02 20:59:30,763 [foster.py] => Task 25, Epoch 20/170 => Loss 3.437, Loss_clf 0.455, Loss_fe 0.358, Loss_kd 2.570, Train_accy 79.86, Test_accy 59.06
2024-08-02 20:59:33,763 [foster.py] => Task 25, Epoch 21/170 => Loss 3.431, Loss_clf 0.438, Loss_fe 0.347, Loss_kd 2.591, Train_accy 81.05
2024-08-02 20:59:38,986 [foster.py] => Task 25, Epoch 22/170 => Loss 3.532, Loss_clf 0.483, Loss_fe 0.423, Loss_kd 2.571, Train_accy 81.35, Test_accy 59.07
2024-08-02 20:59:44,200 [foster.py] => Task 25, Epoch 23/170 => Loss 3.509, Loss_clf 0.457, Loss_fe 0.426, Loss_kd 2.572, Train_accy 78.82, Test_accy 59.37
2024-08-02 20:59:49,538 [foster.py] => Task 25, Epoch 24/170 => Loss 3.395, Loss_clf 0.427, Loss_fe 0.351, Loss_kd 2.563, Train_accy 79.76, Test_accy 59.08
2024-08-02 20:59:54,948 [foster.py] => Task 25, Epoch 25/170 => Loss 3.423, Loss_clf 0.446, Loss_fe 0.345, Loss_kd 2.578, Train_accy 81.42, Test_accy 59.15
2024-08-02 20:59:57,946 [foster.py] => Task 25, Epoch 26/170 => Loss 3.424, Loss_clf 0.437, Loss_fe 0.340, Loss_kd 2.593, Train_accy 80.54
2024-08-02 21:00:03,255 [foster.py] => Task 25, Epoch 27/170 => Loss 3.379, Loss_clf 0.416, Loss_fe 0.290, Loss_kd 2.618, Train_accy 82.57, Test_accy 58.60
2024-08-02 21:00:08,475 [foster.py] => Task 25, Epoch 28/170 => Loss 3.354, Loss_clf 0.404, Loss_fe 0.315, Loss_kd 2.581, Train_accy 82.77, Test_accy 59.55
2024-08-02 21:00:13,716 [foster.py] => Task 25, Epoch 29/170 => Loss 3.410, Loss_clf 0.453, Loss_fe 0.325, Loss_kd 2.577, Train_accy 80.00, Test_accy 59.45
2024-08-02 21:00:18,959 [foster.py] => Task 25, Epoch 30/170 => Loss 3.451, Loss_clf 0.444, Loss_fe 0.345, Loss_kd 2.607, Train_accy 81.93, Test_accy 59.09
2024-08-02 21:00:21,961 [foster.py] => Task 25, Epoch 31/170 => Loss 3.377, Loss_clf 0.429, Loss_fe 0.302, Loss_kd 2.591, Train_accy 79.02
2024-08-02 21:00:27,256 [foster.py] => Task 25, Epoch 32/170 => Loss 3.328, Loss_clf 0.420, Loss_fe 0.296, Loss_kd 2.558, Train_accy 80.95, Test_accy 59.34
2024-08-02 21:00:32,527 [foster.py] => Task 25, Epoch 33/170 => Loss 3.355, Loss_clf 0.431, Loss_fe 0.280, Loss_kd 2.590, Train_accy 80.24, Test_accy 59.24
2024-08-02 21:00:37,766 [foster.py] => Task 25, Epoch 34/170 => Loss 3.308, Loss_clf 0.404, Loss_fe 0.284, Loss_kd 2.566, Train_accy 82.13, Test_accy 58.85
2024-08-02 21:00:42,971 [foster.py] => Task 25, Epoch 35/170 => Loss 3.346, Loss_clf 0.434, Loss_fe 0.288, Loss_kd 2.570, Train_accy 81.62, Test_accy 59.32
2024-08-02 21:00:46,002 [foster.py] => Task 25, Epoch 36/170 => Loss 3.312, Loss_clf 0.406, Loss_fe 0.270, Loss_kd 2.581, Train_accy 82.30
2024-08-02 21:00:51,246 [foster.py] => Task 25, Epoch 37/170 => Loss 3.404, Loss_clf 0.444, Loss_fe 0.311, Loss_kd 2.594, Train_accy 81.72, Test_accy 59.19
2024-08-02 21:00:56,440 [foster.py] => Task 25, Epoch 38/170 => Loss 3.286, Loss_clf 0.392, Loss_fe 0.295, Loss_kd 2.545, Train_accy 82.23, Test_accy 58.69
2024-08-02 21:01:01,669 [foster.py] => Task 25, Epoch 39/170 => Loss 3.341, Loss_clf 0.437, Loss_fe 0.284, Loss_kd 2.566, Train_accy 80.81, Test_accy 59.15
2024-08-02 21:01:06,939 [foster.py] => Task 25, Epoch 40/170 => Loss 3.305, Loss_clf 0.404, Loss_fe 0.281, Loss_kd 2.565, Train_accy 81.55, Test_accy 58.94
2024-08-02 21:01:09,914 [foster.py] => Task 25, Epoch 41/170 => Loss 3.307, Loss_clf 0.398, Loss_fe 0.292, Loss_kd 2.563, Train_accy 82.97
2024-08-02 21:01:15,161 [foster.py] => Task 25, Epoch 42/170 => Loss 3.379, Loss_clf 0.429, Loss_fe 0.281, Loss_kd 2.613, Train_accy 80.20, Test_accy 58.97
2024-08-02 21:01:20,379 [foster.py] => Task 25, Epoch 43/170 => Loss 3.293, Loss_clf 0.415, Loss_fe 0.249, Loss_kd 2.575, Train_accy 82.23, Test_accy 58.68
2024-08-02 21:01:25,599 [foster.py] => Task 25, Epoch 44/170 => Loss 3.320, Loss_clf 0.425, Loss_fe 0.264, Loss_kd 2.575, Train_accy 81.86, Test_accy 59.24
2024-08-02 21:01:30,832 [foster.py] => Task 25, Epoch 45/170 => Loss 3.337, Loss_clf 0.421, Loss_fe 0.275, Loss_kd 2.586, Train_accy 82.64, Test_accy 59.40
2024-08-02 21:01:33,938 [foster.py] => Task 25, Epoch 46/170 => Loss 3.305, Loss_clf 0.404, Loss_fe 0.253, Loss_kd 2.594, Train_accy 82.57
2024-08-02 21:01:39,148 [foster.py] => Task 25, Epoch 47/170 => Loss 3.360, Loss_clf 0.405, Loss_fe 0.279, Loss_kd 2.620, Train_accy 82.30, Test_accy 59.45
2024-08-02 21:01:44,375 [foster.py] => Task 25, Epoch 48/170 => Loss 3.344, Loss_clf 0.420, Loss_fe 0.306, Loss_kd 2.564, Train_accy 82.16, Test_accy 59.48
2024-08-02 21:01:49,672 [foster.py] => Task 25, Epoch 49/170 => Loss 3.400, Loss_clf 0.418, Loss_fe 0.313, Loss_kd 2.614, Train_accy 82.09, Test_accy 58.98
2024-08-02 21:01:54,869 [foster.py] => Task 25, Epoch 50/170 => Loss 3.361, Loss_clf 0.428, Loss_fe 0.292, Loss_kd 2.587, Train_accy 81.11, Test_accy 58.64
2024-08-02 21:01:57,910 [foster.py] => Task 25, Epoch 51/170 => Loss 3.374, Loss_clf 0.436, Loss_fe 0.274, Loss_kd 2.609, Train_accy 81.45
2024-08-02 21:02:03,132 [foster.py] => Task 25, Epoch 52/170 => Loss 3.316, Loss_clf 0.421, Loss_fe 0.253, Loss_kd 2.587, Train_accy 81.59, Test_accy 59.34
2024-08-02 21:02:08,368 [foster.py] => Task 25, Epoch 53/170 => Loss 3.310, Loss_clf 0.395, Loss_fe 0.259, Loss_kd 2.602, Train_accy 82.64, Test_accy 59.46
2024-08-02 21:02:13,590 [foster.py] => Task 25, Epoch 54/170 => Loss 3.230, Loss_clf 0.369, Loss_fe 0.232, Loss_kd 2.574, Train_accy 83.65, Test_accy 59.32
2024-08-02 21:02:18,817 [foster.py] => Task 25, Epoch 55/170 => Loss 3.265, Loss_clf 0.382, Loss_fe 0.260, Loss_kd 2.568, Train_accy 85.03, Test_accy 59.34
2024-08-02 21:02:21,828 [foster.py] => Task 25, Epoch 56/170 => Loss 3.313, Loss_clf 0.409, Loss_fe 0.282, Loss_kd 2.567, Train_accy 82.64
2024-08-02 21:02:27,222 [foster.py] => Task 25, Epoch 57/170 => Loss 3.323, Loss_clf 0.417, Loss_fe 0.279, Loss_kd 2.574, Train_accy 82.30, Test_accy 59.60
2024-08-02 21:02:32,493 [foster.py] => Task 25, Epoch 58/170 => Loss 3.356, Loss_clf 0.422, Loss_fe 0.281, Loss_kd 2.598, Train_accy 81.66, Test_accy 59.37
2024-08-02 21:02:37,751 [foster.py] => Task 25, Epoch 59/170 => Loss 3.294, Loss_clf 0.408, Loss_fe 0.246, Loss_kd 2.585, Train_accy 82.30, Test_accy 59.60
2024-08-02 21:02:42,994 [foster.py] => Task 25, Epoch 60/170 => Loss 3.311, Loss_clf 0.404, Loss_fe 0.246, Loss_kd 2.607, Train_accy 82.40, Test_accy 59.88
2024-08-02 21:02:45,969 [foster.py] => Task 25, Epoch 61/170 => Loss 3.268, Loss_clf 0.403, Loss_fe 0.230, Loss_kd 2.579, Train_accy 82.80
2024-08-02 21:02:51,244 [foster.py] => Task 25, Epoch 62/170 => Loss 3.310, Loss_clf 0.407, Loss_fe 0.254, Loss_kd 2.595, Train_accy 82.53, Test_accy 58.97
2024-08-02 21:02:56,460 [foster.py] => Task 25, Epoch 63/170 => Loss 3.329, Loss_clf 0.426, Loss_fe 0.244, Loss_kd 2.604, Train_accy 82.40, Test_accy 59.58
2024-08-02 21:03:01,747 [foster.py] => Task 25, Epoch 64/170 => Loss 3.332, Loss_clf 0.395, Loss_fe 0.275, Loss_kd 2.607, Train_accy 82.53, Test_accy 58.96
2024-08-02 21:03:06,992 [foster.py] => Task 25, Epoch 65/170 => Loss 3.304, Loss_clf 0.396, Loss_fe 0.259, Loss_kd 2.595, Train_accy 83.51, Test_accy 58.97
2024-08-02 21:03:10,005 [foster.py] => Task 25, Epoch 66/170 => Loss 3.272, Loss_clf 0.384, Loss_fe 0.252, Loss_kd 2.581, Train_accy 82.64
2024-08-02 21:03:15,231 [foster.py] => Task 25, Epoch 67/170 => Loss 3.281, Loss_clf 0.381, Loss_fe 0.273, Loss_kd 2.573, Train_accy 84.19, Test_accy 59.47
2024-08-02 21:03:20,453 [foster.py] => Task 25, Epoch 68/170 => Loss 3.260, Loss_clf 0.372, Loss_fe 0.267, Loss_kd 2.567, Train_accy 82.77, Test_accy 59.26
2024-08-02 21:03:25,874 [foster.py] => Task 25, Epoch 69/170 => Loss 3.281, Loss_clf 0.410, Loss_fe 0.250, Loss_kd 2.567, Train_accy 81.89, Test_accy 59.38
2024-08-02 21:03:31,140 [foster.py] => Task 25, Epoch 70/170 => Loss 3.372, Loss_clf 0.433, Loss_fe 0.290, Loss_kd 2.594, Train_accy 83.34, Test_accy 59.03
2024-08-02 21:03:34,122 [foster.py] => Task 25, Epoch 71/170 => Loss 3.354, Loss_clf 0.414, Loss_fe 0.286, Loss_kd 2.600, Train_accy 82.91
2024-08-02 21:03:39,328 [foster.py] => Task 25, Epoch 72/170 => Loss 3.277, Loss_clf 0.376, Loss_fe 0.264, Loss_kd 2.583, Train_accy 83.07, Test_accy 59.48
2024-08-02 21:03:44,539 [foster.py] => Task 25, Epoch 73/170 => Loss 3.186, Loss_clf 0.356, Loss_fe 0.205, Loss_kd 2.571, Train_accy 83.78, Test_accy 59.47
2024-08-02 21:03:49,763 [foster.py] => Task 25, Epoch 74/170 => Loss 3.245, Loss_clf 0.389, Loss_fe 0.221, Loss_kd 2.581, Train_accy 83.34, Test_accy 59.58
2024-08-02 21:03:55,022 [foster.py] => Task 25, Epoch 75/170 => Loss 3.226, Loss_clf 0.378, Loss_fe 0.207, Loss_kd 2.586, Train_accy 83.34, Test_accy 59.71
2024-08-02 21:03:58,187 [foster.py] => Task 25, Epoch 76/170 => Loss 3.273, Loss_clf 0.412, Loss_fe 0.208, Loss_kd 2.599, Train_accy 83.51
2024-08-02 21:04:03,558 [foster.py] => Task 25, Epoch 77/170 => Loss 3.308, Loss_clf 0.425, Loss_fe 0.201, Loss_kd 2.626, Train_accy 83.14, Test_accy 59.73
2024-08-02 21:04:08,935 [foster.py] => Task 25, Epoch 78/170 => Loss 3.206, Loss_clf 0.356, Loss_fe 0.207, Loss_kd 2.589, Train_accy 85.47, Test_accy 59.14
2024-08-02 21:04:14,146 [foster.py] => Task 25, Epoch 79/170 => Loss 3.297, Loss_clf 0.394, Loss_fe 0.226, Loss_kd 2.622, Train_accy 84.22, Test_accy 59.40
2024-08-02 21:04:19,412 [foster.py] => Task 25, Epoch 80/170 => Loss 3.183, Loss_clf 0.356, Loss_fe 0.188, Loss_kd 2.585, Train_accy 84.83, Test_accy 59.26
2024-08-02 21:04:22,396 [foster.py] => Task 25, Epoch 81/170 => Loss 3.165, Loss_clf 0.360, Loss_fe 0.188, Loss_kd 2.563, Train_accy 85.34
2024-08-02 21:04:27,696 [foster.py] => Task 25, Epoch 82/170 => Loss 3.239, Loss_clf 0.393, Loss_fe 0.183, Loss_kd 2.607, Train_accy 84.36, Test_accy 59.55
2024-08-02 21:04:32,919 [foster.py] => Task 25, Epoch 83/170 => Loss 3.231, Loss_clf 0.379, Loss_fe 0.204, Loss_kd 2.594, Train_accy 83.45, Test_accy 59.27
2024-08-02 21:04:38,105 [foster.py] => Task 25, Epoch 84/170 => Loss 3.194, Loss_clf 0.358, Loss_fe 0.183, Loss_kd 2.598, Train_accy 85.57, Test_accy 59.48
2024-08-02 21:04:43,430 [foster.py] => Task 25, Epoch 85/170 => Loss 3.253, Loss_clf 0.394, Loss_fe 0.232, Loss_kd 2.573, Train_accy 84.80, Test_accy 59.71
2024-08-02 21:04:46,520 [foster.py] => Task 25, Epoch 86/170 => Loss 3.273, Loss_clf 0.389, Loss_fe 0.270, Loss_kd 2.559, Train_accy 83.82
2024-08-02 21:04:51,769 [foster.py] => Task 25, Epoch 87/170 => Loss 3.217, Loss_clf 0.385, Loss_fe 0.210, Loss_kd 2.568, Train_accy 84.32, Test_accy 59.77
2024-08-02 21:04:57,012 [foster.py] => Task 25, Epoch 88/170 => Loss 3.142, Loss_clf 0.341, Loss_fe 0.174, Loss_kd 2.574, Train_accy 84.97, Test_accy 59.71
2024-08-02 21:05:02,206 [foster.py] => Task 25, Epoch 89/170 => Loss 3.230, Loss_clf 0.368, Loss_fe 0.208, Loss_kd 2.599, Train_accy 85.24, Test_accy 59.47
2024-08-02 21:05:07,453 [foster.py] => Task 25, Epoch 90/170 => Loss 3.279, Loss_clf 0.396, Loss_fe 0.234, Loss_kd 2.594, Train_accy 84.46, Test_accy 59.38
2024-08-02 21:05:10,473 [foster.py] => Task 25, Epoch 91/170 => Loss 3.246, Loss_clf 0.394, Loss_fe 0.218, Loss_kd 2.579, Train_accy 84.09
2024-08-02 21:05:15,739 [foster.py] => Task 25, Epoch 92/170 => Loss 3.283, Loss_clf 0.411, Loss_fe 0.215, Loss_kd 2.602, Train_accy 83.38, Test_accy 59.82
2024-08-02 21:05:20,966 [foster.py] => Task 25, Epoch 93/170 => Loss 3.217, Loss_clf 0.376, Loss_fe 0.209, Loss_kd 2.577, Train_accy 85.71, Test_accy 59.44
2024-08-02 21:05:26,239 [foster.py] => Task 25, Epoch 94/170 => Loss 3.265, Loss_clf 0.395, Loss_fe 0.209, Loss_kd 2.606, Train_accy 84.66, Test_accy 59.63
2024-08-02 21:05:31,451 [foster.py] => Task 25, Epoch 95/170 => Loss 3.215, Loss_clf 0.382, Loss_fe 0.172, Loss_kd 2.606, Train_accy 83.92, Test_accy 59.68
2024-08-02 21:05:34,449 [foster.py] => Task 25, Epoch 96/170 => Loss 3.258, Loss_clf 0.394, Loss_fe 0.202, Loss_kd 2.607, Train_accy 84.46
2024-08-02 21:05:39,725 [foster.py] => Task 25, Epoch 97/170 => Loss 3.153, Loss_clf 0.365, Loss_fe 0.157, Loss_kd 2.577, Train_accy 85.91, Test_accy 59.27
2024-08-02 21:05:44,924 [foster.py] => Task 25, Epoch 98/170 => Loss 3.158, Loss_clf 0.350, Loss_fe 0.158, Loss_kd 2.596, Train_accy 86.18, Test_accy 59.62
2024-08-02 21:05:50,175 [foster.py] => Task 25, Epoch 99/170 => Loss 3.238, Loss_clf 0.386, Loss_fe 0.176, Loss_kd 2.621, Train_accy 85.37, Test_accy 59.81
2024-08-02 21:05:55,521 [foster.py] => Task 25, Epoch 100/170 => Loss 3.219, Loss_clf 0.372, Loss_fe 0.196, Loss_kd 2.596, Train_accy 86.32, Test_accy 59.41
2024-08-02 21:05:58,497 [foster.py] => Task 25, Epoch 101/170 => Loss 3.180, Loss_clf 0.369, Loss_fe 0.184, Loss_kd 2.572, Train_accy 83.99
2024-08-02 21:06:03,709 [foster.py] => Task 25, Epoch 102/170 => Loss 3.248, Loss_clf 0.385, Loss_fe 0.195, Loss_kd 2.613, Train_accy 84.46, Test_accy 59.68
2024-08-02 21:06:09,007 [foster.py] => Task 25, Epoch 103/170 => Loss 3.158, Loss_clf 0.364, Loss_fe 0.152, Loss_kd 2.587, Train_accy 85.41, Test_accy 59.98
2024-08-02 21:06:14,357 [foster.py] => Task 25, Epoch 104/170 => Loss 3.147, Loss_clf 0.348, Loss_fe 0.147, Loss_kd 2.597, Train_accy 86.52, Test_accy 59.46
2024-08-02 21:06:19,655 [foster.py] => Task 25, Epoch 105/170 => Loss 3.163, Loss_clf 0.353, Loss_fe 0.158, Loss_kd 2.598, Train_accy 86.25, Test_accy 59.71
2024-08-02 21:06:22,714 [foster.py] => Task 25, Epoch 106/170 => Loss 3.162, Loss_clf 0.353, Loss_fe 0.158, Loss_kd 2.596, Train_accy 84.86
2024-08-02 21:06:27,971 [foster.py] => Task 25, Epoch 107/170 => Loss 3.166, Loss_clf 0.369, Loss_fe 0.158, Loss_kd 2.585, Train_accy 87.26, Test_accy 60.00
2024-08-02 21:06:33,181 [foster.py] => Task 25, Epoch 108/170 => Loss 3.083, Loss_clf 0.330, Loss_fe 0.148, Loss_kd 2.551, Train_accy 85.74, Test_accy 59.45
2024-08-02 21:06:38,474 [foster.py] => Task 25, Epoch 109/170 => Loss 3.120, Loss_clf 0.330, Loss_fe 0.151, Loss_kd 2.585, Train_accy 86.96, Test_accy 59.92
2024-08-02 21:06:43,660 [foster.py] => Task 25, Epoch 110/170 => Loss 3.127, Loss_clf 0.343, Loss_fe 0.152, Loss_kd 2.577, Train_accy 85.91, Test_accy 59.81
2024-08-02 21:06:46,775 [foster.py] => Task 25, Epoch 111/170 => Loss 3.119, Loss_clf 0.330, Loss_fe 0.147, Loss_kd 2.588, Train_accy 86.11
2024-08-02 21:06:52,188 [foster.py] => Task 25, Epoch 112/170 => Loss 3.173, Loss_clf 0.363, Loss_fe 0.153, Loss_kd 2.602, Train_accy 86.15, Test_accy 60.09
2024-08-02 21:06:57,604 [foster.py] => Task 25, Epoch 113/170 => Loss 3.124, Loss_clf 0.350, Loss_fe 0.140, Loss_kd 2.580, Train_accy 85.57, Test_accy 59.90
2024-08-02 21:07:02,845 [foster.py] => Task 25, Epoch 114/170 => Loss 3.174, Loss_clf 0.369, Loss_fe 0.155, Loss_kd 2.595, Train_accy 85.47, Test_accy 59.64
2024-08-02 21:07:08,111 [foster.py] => Task 25, Epoch 115/170 => Loss 3.187, Loss_clf 0.380, Loss_fe 0.180, Loss_kd 2.573, Train_accy 85.64, Test_accy 59.83
2024-08-02 21:07:11,091 [foster.py] => Task 25, Epoch 116/170 => Loss 3.133, Loss_clf 0.351, Loss_fe 0.133, Loss_kd 2.595, Train_accy 85.71
2024-08-02 21:07:16,313 [foster.py] => Task 25, Epoch 117/170 => Loss 3.153, Loss_clf 0.361, Loss_fe 0.136, Loss_kd 2.600, Train_accy 85.24, Test_accy 60.14
2024-08-02 21:07:21,519 [foster.py] => Task 25, Epoch 118/170 => Loss 3.129, Loss_clf 0.360, Loss_fe 0.149, Loss_kd 2.566, Train_accy 86.01, Test_accy 60.12
2024-08-02 21:07:26,960 [foster.py] => Task 25, Epoch 119/170 => Loss 3.124, Loss_clf 0.362, Loss_fe 0.130, Loss_kd 2.577, Train_accy 85.27, Test_accy 60.33
2024-08-02 21:07:32,286 [foster.py] => Task 25, Epoch 120/170 => Loss 3.070, Loss_clf 0.321, Loss_fe 0.122, Loss_kd 2.573, Train_accy 87.36, Test_accy 60.18
2024-08-02 21:07:35,284 [foster.py] => Task 25, Epoch 121/170 => Loss 3.086, Loss_clf 0.338, Loss_fe 0.145, Loss_kd 2.550, Train_accy 87.30
2024-08-02 21:07:40,515 [foster.py] => Task 25, Epoch 122/170 => Loss 3.151, Loss_clf 0.359, Loss_fe 0.138, Loss_kd 2.599, Train_accy 86.76, Test_accy 59.72
2024-08-02 21:07:45,913 [foster.py] => Task 25, Epoch 123/170 => Loss 3.156, Loss_clf 0.358, Loss_fe 0.152, Loss_kd 2.591, Train_accy 87.03, Test_accy 59.90
2024-08-02 21:07:51,188 [foster.py] => Task 25, Epoch 124/170 => Loss 3.083, Loss_clf 0.337, Loss_fe 0.135, Loss_kd 2.557, Train_accy 86.76, Test_accy 59.82
2024-08-02 21:07:56,418 [foster.py] => Task 25, Epoch 125/170 => Loss 3.162, Loss_clf 0.377, Loss_fe 0.138, Loss_kd 2.592, Train_accy 86.42, Test_accy 59.87
2024-08-02 21:07:59,420 [foster.py] => Task 25, Epoch 126/170 => Loss 3.102, Loss_clf 0.327, Loss_fe 0.138, Loss_kd 2.583, Train_accy 86.66
2024-08-02 21:08:04,637 [foster.py] => Task 25, Epoch 127/170 => Loss 3.171, Loss_clf 0.351, Loss_fe 0.161, Loss_kd 2.603, Train_accy 86.52, Test_accy 59.88
2024-08-02 21:08:09,856 [foster.py] => Task 25, Epoch 128/170 => Loss 3.127, Loss_clf 0.343, Loss_fe 0.125, Loss_kd 2.604, Train_accy 86.86, Test_accy 60.08
2024-08-02 21:08:15,061 [foster.py] => Task 25, Epoch 129/170 => Loss 3.135, Loss_clf 0.344, Loss_fe 0.139, Loss_kd 2.597, Train_accy 85.54, Test_accy 59.93
2024-08-02 21:08:20,271 [foster.py] => Task 25, Epoch 130/170 => Loss 3.090, Loss_clf 0.329, Loss_fe 0.124, Loss_kd 2.583, Train_accy 86.25, Test_accy 59.80
2024-08-02 21:08:23,429 [foster.py] => Task 25, Epoch 131/170 => Loss 3.016, Loss_clf 0.305, Loss_fe 0.111, Loss_kd 2.547, Train_accy 87.74
2024-08-02 21:08:28,708 [foster.py] => Task 25, Epoch 132/170 => Loss 3.182, Loss_clf 0.370, Loss_fe 0.127, Loss_kd 2.629, Train_accy 86.28, Test_accy 59.98
2024-08-02 21:08:33,922 [foster.py] => Task 25, Epoch 133/170 => Loss 3.157, Loss_clf 0.351, Loss_fe 0.137, Loss_kd 2.614, Train_accy 85.91, Test_accy 59.93
2024-08-02 21:08:39,150 [foster.py] => Task 25, Epoch 134/170 => Loss 3.147, Loss_clf 0.347, Loss_fe 0.147, Loss_kd 2.598, Train_accy 86.49, Test_accy 59.90
2024-08-02 21:08:44,369 [foster.py] => Task 25, Epoch 135/170 => Loss 3.135, Loss_clf 0.347, Loss_fe 0.121, Loss_kd 2.612, Train_accy 85.71, Test_accy 59.97
2024-08-02 21:08:47,365 [foster.py] => Task 25, Epoch 136/170 => Loss 3.078, Loss_clf 0.323, Loss_fe 0.136, Loss_kd 2.565, Train_accy 87.84
2024-08-02 21:08:52,654 [foster.py] => Task 25, Epoch 137/170 => Loss 3.098, Loss_clf 0.326, Loss_fe 0.142, Loss_kd 2.577, Train_accy 87.23, Test_accy 59.96
2024-08-02 21:08:57,863 [foster.py] => Task 25, Epoch 138/170 => Loss 3.128, Loss_clf 0.354, Loss_fe 0.130, Loss_kd 2.589, Train_accy 86.15, Test_accy 59.85
2024-08-02 21:09:03,087 [foster.py] => Task 25, Epoch 139/170 => Loss 3.110, Loss_clf 0.337, Loss_fe 0.131, Loss_kd 2.587, Train_accy 86.82, Test_accy 59.95
2024-08-02 21:09:08,362 [foster.py] => Task 25, Epoch 140/170 => Loss 3.083, Loss_clf 0.332, Loss_fe 0.120, Loss_kd 2.577, Train_accy 86.93, Test_accy 59.87
2024-08-02 21:09:11,344 [foster.py] => Task 25, Epoch 141/170 => Loss 3.136, Loss_clf 0.347, Loss_fe 0.136, Loss_kd 2.598, Train_accy 88.18
2024-08-02 21:09:16,600 [foster.py] => Task 25, Epoch 142/170 => Loss 3.091, Loss_clf 0.340, Loss_fe 0.124, Loss_kd 2.573, Train_accy 86.99, Test_accy 59.80
2024-08-02 21:09:21,803 [foster.py] => Task 25, Epoch 143/170 => Loss 3.131, Loss_clf 0.339, Loss_fe 0.129, Loss_kd 2.608, Train_accy 86.82, Test_accy 59.96
2024-08-02 21:09:27,026 [foster.py] => Task 25, Epoch 144/170 => Loss 3.088, Loss_clf 0.337, Loss_fe 0.115, Loss_kd 2.582, Train_accy 86.72, Test_accy 59.99
2024-08-02 21:09:32,227 [foster.py] => Task 25, Epoch 145/170 => Loss 3.087, Loss_clf 0.329, Loss_fe 0.112, Loss_kd 2.592, Train_accy 86.15, Test_accy 59.96
2024-08-02 21:09:35,220 [foster.py] => Task 25, Epoch 146/170 => Loss 3.060, Loss_clf 0.321, Loss_fe 0.113, Loss_kd 2.572, Train_accy 87.03
2024-08-02 21:09:40,438 [foster.py] => Task 25, Epoch 147/170 => Loss 3.097, Loss_clf 0.335, Loss_fe 0.121, Loss_kd 2.587, Train_accy 86.55, Test_accy 59.90
2024-08-02 21:09:45,623 [foster.py] => Task 25, Epoch 148/170 => Loss 3.026, Loss_clf 0.309, Loss_fe 0.102, Loss_kd 2.561, Train_accy 87.06, Test_accy 59.85
2024-08-02 21:09:50,956 [foster.py] => Task 25, Epoch 149/170 => Loss 3.142, Loss_clf 0.355, Loss_fe 0.135, Loss_kd 2.598, Train_accy 87.43, Test_accy 60.00
2024-08-02 21:09:56,208 [foster.py] => Task 25, Epoch 150/170 => Loss 3.127, Loss_clf 0.358, Loss_fe 0.119, Loss_kd 2.595, Train_accy 85.37, Test_accy 60.02
2024-08-02 21:09:59,207 [foster.py] => Task 25, Epoch 151/170 => Loss 3.097, Loss_clf 0.330, Loss_fe 0.105, Loss_kd 2.606, Train_accy 86.79
2024-08-02 21:10:04,457 [foster.py] => Task 25, Epoch 152/170 => Loss 3.046, Loss_clf 0.314, Loss_fe 0.092, Loss_kd 2.585, Train_accy 87.23, Test_accy 59.98
2024-08-02 21:10:09,665 [foster.py] => Task 25, Epoch 153/170 => Loss 3.060, Loss_clf 0.329, Loss_fe 0.110, Loss_kd 2.568, Train_accy 86.11, Test_accy 60.02
2024-08-02 21:10:14,843 [foster.py] => Task 25, Epoch 154/170 => Loss 3.065, Loss_clf 0.317, Loss_fe 0.098, Loss_kd 2.596, Train_accy 87.20, Test_accy 60.01
2024-08-02 21:10:20,102 [foster.py] => Task 25, Epoch 155/170 => Loss 3.051, Loss_clf 0.323, Loss_fe 0.105, Loss_kd 2.569, Train_accy 86.82, Test_accy 59.96
2024-08-02 21:10:23,142 [foster.py] => Task 25, Epoch 156/170 => Loss 3.075, Loss_clf 0.328, Loss_fe 0.101, Loss_kd 2.590, Train_accy 87.50
2024-08-02 21:10:28,368 [foster.py] => Task 25, Epoch 157/170 => Loss 3.046, Loss_clf 0.327, Loss_fe 0.097, Loss_kd 2.567, Train_accy 86.62, Test_accy 60.00
2024-08-02 21:10:33,577 [foster.py] => Task 25, Epoch 158/170 => Loss 3.047, Loss_clf 0.322, Loss_fe 0.092, Loss_kd 2.579, Train_accy 86.62, Test_accy 59.96
2024-08-02 21:10:38,816 [foster.py] => Task 25, Epoch 159/170 => Loss 3.133, Loss_clf 0.348, Loss_fe 0.122, Loss_kd 2.608, Train_accy 86.86, Test_accy 59.96
2024-08-02 21:10:44,085 [foster.py] => Task 25, Epoch 160/170 => Loss 3.105, Loss_clf 0.341, Loss_fe 0.100, Loss_kd 2.609, Train_accy 86.79, Test_accy 60.02
2024-08-02 21:10:47,079 [foster.py] => Task 25, Epoch 161/170 => Loss 3.064, Loss_clf 0.329, Loss_fe 0.122, Loss_kd 2.560, Train_accy 87.57
2024-08-02 21:10:52,318 [foster.py] => Task 25, Epoch 162/170 => Loss 3.136, Loss_clf 0.356, Loss_fe 0.115, Loss_kd 2.610, Train_accy 86.49, Test_accy 60.09
2024-08-02 21:10:57,566 [foster.py] => Task 25, Epoch 163/170 => Loss 3.099, Loss_clf 0.343, Loss_fe 0.101, Loss_kd 2.601, Train_accy 86.35, Test_accy 59.95
2024-08-02 21:11:02,821 [foster.py] => Task 25, Epoch 164/170 => Loss 3.079, Loss_clf 0.347, Loss_fe 0.107, Loss_kd 2.570, Train_accy 86.55, Test_accy 59.98
2024-08-02 21:11:08,022 [foster.py] => Task 25, Epoch 165/170 => Loss 3.091, Loss_clf 0.325, Loss_fe 0.129, Loss_kd 2.583, Train_accy 87.26, Test_accy 60.07
2024-08-02 21:11:11,013 [foster.py] => Task 25, Epoch 166/170 => Loss 3.090, Loss_clf 0.343, Loss_fe 0.104, Loss_kd 2.588, Train_accy 86.52
2024-08-02 21:11:16,284 [foster.py] => Task 25, Epoch 167/170 => Loss 3.088, Loss_clf 0.316, Loss_fe 0.114, Loss_kd 2.604, Train_accy 87.30, Test_accy 59.97
2024-08-02 21:11:21,514 [foster.py] => Task 25, Epoch 168/170 => Loss 3.096, Loss_clf 0.331, Loss_fe 0.114, Loss_kd 2.597, Train_accy 86.89, Test_accy 59.94
2024-08-02 21:11:26,741 [foster.py] => Task 25, Epoch 169/170 => Loss 3.066, Loss_clf 0.328, Loss_fe 0.108, Loss_kd 2.576, Train_accy 86.79, Test_accy 60.05
2024-08-02 21:11:31,966 [foster.py] => Task 25, Epoch 170/170 => Loss 3.124, Loss_clf 0.351, Loss_fe 0.125, Loss_kd 2.593, Train_accy 86.11, Test_accy 59.94
2024-08-02 21:11:31,969 [foster.py] => do not weight align teacher!
2024-08-02 21:11:31,971 [foster.py] => per cls weights : [1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094 1.01085094
 1.01085094 1.01085094 0.46830403 0.46830403]
2024-08-02 21:11:37,813 [foster.py] => SNet: Task 25, Epoch 1/130 => Loss 31.345,  Loss1 0.795, Train_accy 62.53, Test_accy 58.01
2024-08-02 21:11:42,017 [foster.py] => SNet: Task 25, Epoch 2/130 => Loss 31.280,  Loss1 0.794, Train_accy 68.99
2024-08-02 21:11:46,227 [foster.py] => SNet: Task 25, Epoch 3/130 => Loss 31.325,  Loss1 0.793, Train_accy 69.70
2024-08-02 21:11:50,412 [foster.py] => SNet: Task 25, Epoch 4/130 => Loss 31.273,  Loss1 0.794, Train_accy 70.98
2024-08-02 21:11:54,620 [foster.py] => SNet: Task 25, Epoch 5/130 => Loss 31.249,  Loss1 0.794, Train_accy 71.45
2024-08-02 21:12:00,177 [foster.py] => SNet: Task 25, Epoch 6/130 => Loss 31.266,  Loss1 0.794, Train_accy 71.11, Test_accy 58.14
2024-08-02 21:12:04,392 [foster.py] => SNet: Task 25, Epoch 7/130 => Loss 31.308,  Loss1 0.794, Train_accy 72.67
2024-08-02 21:12:08,565 [foster.py] => SNet: Task 25, Epoch 8/130 => Loss 31.243,  Loss1 0.795, Train_accy 71.62
2024-08-02 21:12:12,767 [foster.py] => SNet: Task 25, Epoch 9/130 => Loss 31.307,  Loss1 0.794, Train_accy 73.65
2024-08-02 21:12:16,959 [foster.py] => SNet: Task 25, Epoch 10/130 => Loss 31.276,  Loss1 0.794, Train_accy 72.43
2024-08-02 21:12:22,522 [foster.py] => SNet: Task 25, Epoch 11/130 => Loss 31.258,  Loss1 0.794, Train_accy 72.91, Test_accy 59.29
2024-08-02 21:12:26,748 [foster.py] => SNet: Task 25, Epoch 12/130 => Loss 31.231,  Loss1 0.794, Train_accy 74.53
2024-08-02 21:12:30,948 [foster.py] => SNet: Task 25, Epoch 13/130 => Loss 31.265,  Loss1 0.794, Train_accy 73.28
2024-08-02 21:12:35,143 [foster.py] => SNet: Task 25, Epoch 14/130 => Loss 31.283,  Loss1 0.795, Train_accy 74.66
2024-08-02 21:12:39,351 [foster.py] => SNet: Task 25, Epoch 15/130 => Loss 31.256,  Loss1 0.795, Train_accy 73.89
2024-08-02 21:12:44,945 [foster.py] => SNet: Task 25, Epoch 16/130 => Loss 31.293,  Loss1 0.795, Train_accy 73.61, Test_accy 58.76
2024-08-02 21:12:49,234 [foster.py] => SNet: Task 25, Epoch 17/130 => Loss 31.250,  Loss1 0.794, Train_accy 75.00
2024-08-02 21:12:53,420 [foster.py] => SNet: Task 25, Epoch 18/130 => Loss 31.267,  Loss1 0.793, Train_accy 72.94
2024-08-02 21:12:57,615 [foster.py] => SNet: Task 25, Epoch 19/130 => Loss 31.334,  Loss1 0.794, Train_accy 74.36
2024-08-02 21:13:01,828 [foster.py] => SNet: Task 25, Epoch 20/130 => Loss 31.294,  Loss1 0.793, Train_accy 73.48
2024-08-02 21:13:07,390 [foster.py] => SNet: Task 25, Epoch 21/130 => Loss 31.290,  Loss1 0.794, Train_accy 74.22, Test_accy 58.40
2024-08-02 21:13:11,585 [foster.py] => SNet: Task 25, Epoch 22/130 => Loss 31.271,  Loss1 0.795, Train_accy 75.71
2024-08-02 21:13:15,800 [foster.py] => SNet: Task 25, Epoch 23/130 => Loss 31.298,  Loss1 0.794, Train_accy 73.82
2024-08-02 21:13:19,993 [foster.py] => SNet: Task 25, Epoch 24/130 => Loss 31.281,  Loss1 0.795, Train_accy 75.37
2024-08-02 21:13:24,249 [foster.py] => SNet: Task 25, Epoch 25/130 => Loss 31.295,  Loss1 0.794, Train_accy 74.16
2024-08-02 21:13:29,804 [foster.py] => SNet: Task 25, Epoch 26/130 => Loss 31.347,  Loss1 0.794, Train_accy 75.51, Test_accy 58.06
2024-08-02 21:13:34,019 [foster.py] => SNet: Task 25, Epoch 27/130 => Loss 31.261,  Loss1 0.794, Train_accy 73.85
2024-08-02 21:13:38,219 [foster.py] => SNet: Task 25, Epoch 28/130 => Loss 31.268,  Loss1 0.794, Train_accy 75.84
2024-08-02 21:13:42,471 [foster.py] => SNet: Task 25, Epoch 29/130 => Loss 31.246,  Loss1 0.794, Train_accy 73.61
2024-08-02 21:13:46,699 [foster.py] => SNet: Task 25, Epoch 30/130 => Loss 31.267,  Loss1 0.794, Train_accy 76.39
2024-08-02 21:13:52,242 [foster.py] => SNet: Task 25, Epoch 31/130 => Loss 31.228,  Loss1 0.794, Train_accy 75.14, Test_accy 58.99
2024-08-02 21:13:56,417 [foster.py] => SNet: Task 25, Epoch 32/130 => Loss 31.253,  Loss1 0.794, Train_accy 75.07
2024-08-02 21:14:00,678 [foster.py] => SNet: Task 25, Epoch 33/130 => Loss 31.326,  Loss1 0.795, Train_accy 75.00
2024-08-02 21:14:04,882 [foster.py] => SNet: Task 25, Epoch 34/130 => Loss 31.320,  Loss1 0.794, Train_accy 75.98
2024-08-02 21:14:09,070 [foster.py] => SNet: Task 25, Epoch 35/130 => Loss 31.252,  Loss1 0.794, Train_accy 75.68
2024-08-02 21:14:14,639 [foster.py] => SNet: Task 25, Epoch 36/130 => Loss 31.261,  Loss1 0.795, Train_accy 74.70, Test_accy 59.46
2024-08-02 21:14:18,822 [foster.py] => SNet: Task 25, Epoch 37/130 => Loss 31.220,  Loss1 0.794, Train_accy 75.91
2024-08-02 21:14:22,988 [foster.py] => SNet: Task 25, Epoch 38/130 => Loss 31.289,  Loss1 0.794, Train_accy 76.66
2024-08-02 21:14:27,191 [foster.py] => SNet: Task 25, Epoch 39/130 => Loss 31.341,  Loss1 0.795, Train_accy 75.27
2024-08-02 21:14:31,368 [foster.py] => SNet: Task 25, Epoch 40/130 => Loss 31.266,  Loss1 0.794, Train_accy 75.17
2024-08-02 21:14:36,969 [foster.py] => SNet: Task 25, Epoch 41/130 => Loss 31.229,  Loss1 0.794, Train_accy 76.55, Test_accy 59.37
2024-08-02 21:14:41,173 [foster.py] => SNet: Task 25, Epoch 42/130 => Loss 31.244,  Loss1 0.795, Train_accy 76.93
2024-08-02 21:14:45,373 [foster.py] => SNet: Task 25, Epoch 43/130 => Loss 31.242,  Loss1 0.794, Train_accy 75.24
2024-08-02 21:14:49,546 [foster.py] => SNet: Task 25, Epoch 44/130 => Loss 31.273,  Loss1 0.794, Train_accy 75.54
2024-08-02 21:14:53,778 [foster.py] => SNet: Task 25, Epoch 45/130 => Loss 31.297,  Loss1 0.794, Train_accy 76.89
2024-08-02 21:14:59,422 [foster.py] => SNet: Task 25, Epoch 46/130 => Loss 31.241,  Loss1 0.794, Train_accy 76.86, Test_accy 59.89
2024-08-02 21:15:03,630 [foster.py] => SNet: Task 25, Epoch 47/130 => Loss 31.284,  Loss1 0.794, Train_accy 74.63
2024-08-02 21:15:07,882 [foster.py] => SNet: Task 25, Epoch 48/130 => Loss 31.326,  Loss1 0.794, Train_accy 75.54
2024-08-02 21:15:12,161 [foster.py] => SNet: Task 25, Epoch 49/130 => Loss 31.285,  Loss1 0.794, Train_accy 77.06
2024-08-02 21:15:16,386 [foster.py] => SNet: Task 25, Epoch 50/130 => Loss 31.224,  Loss1 0.795, Train_accy 75.37
2024-08-02 21:15:21,995 [foster.py] => SNet: Task 25, Epoch 51/130 => Loss 31.250,  Loss1 0.794, Train_accy 75.78, Test_accy 59.59
2024-08-02 21:15:26,222 [foster.py] => SNet: Task 25, Epoch 52/130 => Loss 31.275,  Loss1 0.795, Train_accy 75.64
2024-08-02 21:15:30,409 [foster.py] => SNet: Task 25, Epoch 53/130 => Loss 31.265,  Loss1 0.794, Train_accy 76.08
2024-08-02 21:15:34,593 [foster.py] => SNet: Task 25, Epoch 54/130 => Loss 31.267,  Loss1 0.795, Train_accy 76.35
2024-08-02 21:15:38,811 [foster.py] => SNet: Task 25, Epoch 55/130 => Loss 31.227,  Loss1 0.794, Train_accy 75.44
2024-08-02 21:15:44,367 [foster.py] => SNet: Task 25, Epoch 56/130 => Loss 31.189,  Loss1 0.795, Train_accy 76.11, Test_accy 59.53
2024-08-02 21:15:48,546 [foster.py] => SNet: Task 25, Epoch 57/130 => Loss 31.287,  Loss1 0.794, Train_accy 76.79
2024-08-02 21:15:52,746 [foster.py] => SNet: Task 25, Epoch 58/130 => Loss 31.258,  Loss1 0.794, Train_accy 75.51
2024-08-02 21:15:56,946 [foster.py] => SNet: Task 25, Epoch 59/130 => Loss 31.247,  Loss1 0.795, Train_accy 76.66
2024-08-02 21:16:01,152 [foster.py] => SNet: Task 25, Epoch 60/130 => Loss 31.223,  Loss1 0.794, Train_accy 77.06
2024-08-02 21:16:06,705 [foster.py] => SNet: Task 25, Epoch 61/130 => Loss 31.261,  Loss1 0.795, Train_accy 76.35, Test_accy 59.36
2024-08-02 21:16:10,921 [foster.py] => SNet: Task 25, Epoch 62/130 => Loss 31.288,  Loss1 0.794, Train_accy 75.78
2024-08-02 21:16:15,132 [foster.py] => SNet: Task 25, Epoch 63/130 => Loss 31.238,  Loss1 0.794, Train_accy 77.64
2024-08-02 21:16:19,330 [foster.py] => SNet: Task 25, Epoch 64/130 => Loss 31.264,  Loss1 0.794, Train_accy 77.97
2024-08-02 21:16:23,628 [foster.py] => SNet: Task 25, Epoch 65/130 => Loss 31.294,  Loss1 0.795, Train_accy 76.93
2024-08-02 21:16:29,229 [foster.py] => SNet: Task 25, Epoch 66/130 => Loss 31.269,  Loss1 0.794, Train_accy 76.62, Test_accy 59.51
2024-08-02 21:16:33,404 [foster.py] => SNet: Task 25, Epoch 67/130 => Loss 31.256,  Loss1 0.795, Train_accy 76.39
2024-08-02 21:16:37,583 [foster.py] => SNet: Task 25, Epoch 68/130 => Loss 31.305,  Loss1 0.794, Train_accy 77.70
2024-08-02 21:16:41,769 [foster.py] => SNet: Task 25, Epoch 69/130 => Loss 31.266,  Loss1 0.795, Train_accy 76.89
2024-08-02 21:16:45,941 [foster.py] => SNet: Task 25, Epoch 70/130 => Loss 31.259,  Loss1 0.795, Train_accy 77.26
2024-08-02 21:16:51,507 [foster.py] => SNet: Task 25, Epoch 71/130 => Loss 31.292,  Loss1 0.795, Train_accy 76.11, Test_accy 59.75
2024-08-02 21:16:55,728 [foster.py] => SNet: Task 25, Epoch 72/130 => Loss 31.271,  Loss1 0.794, Train_accy 76.96
2024-08-02 21:16:59,912 [foster.py] => SNet: Task 25, Epoch 73/130 => Loss 31.269,  Loss1 0.795, Train_accy 76.79
2024-08-02 21:17:04,112 [foster.py] => SNet: Task 25, Epoch 74/130 => Loss 31.184,  Loss1 0.794, Train_accy 76.79
2024-08-02 21:17:08,285 [foster.py] => SNet: Task 25, Epoch 75/130 => Loss 31.231,  Loss1 0.795, Train_accy 76.79
2024-08-02 21:17:13,873 [foster.py] => SNet: Task 25, Epoch 76/130 => Loss 31.244,  Loss1 0.794, Train_accy 76.45, Test_accy 59.30
2024-08-02 21:17:18,103 [foster.py] => SNet: Task 25, Epoch 77/130 => Loss 31.296,  Loss1 0.794, Train_accy 77.13
2024-08-02 21:17:22,312 [foster.py] => SNet: Task 25, Epoch 78/130 => Loss 31.236,  Loss1 0.795, Train_accy 77.26
2024-08-02 21:17:26,539 [foster.py] => SNet: Task 25, Epoch 79/130 => Loss 31.246,  Loss1 0.794, Train_accy 77.20
2024-08-02 21:17:30,707 [foster.py] => SNet: Task 25, Epoch 80/130 => Loss 31.247,  Loss1 0.794, Train_accy 76.15
2024-08-02 21:17:36,354 [foster.py] => SNet: Task 25, Epoch 81/130 => Loss 31.268,  Loss1 0.795, Train_accy 76.15, Test_accy 59.53
2024-08-02 21:17:40,538 [foster.py] => SNet: Task 25, Epoch 82/130 => Loss 31.258,  Loss1 0.794, Train_accy 77.23
2024-08-02 21:17:44,757 [foster.py] => SNet: Task 25, Epoch 83/130 => Loss 31.292,  Loss1 0.794, Train_accy 75.74
2024-08-02 21:17:48,961 [foster.py] => SNet: Task 25, Epoch 84/130 => Loss 31.264,  Loss1 0.795, Train_accy 76.35
2024-08-02 21:17:53,194 [foster.py] => SNet: Task 25, Epoch 85/130 => Loss 31.220,  Loss1 0.794, Train_accy 76.93
2024-08-02 21:17:58,779 [foster.py] => SNet: Task 25, Epoch 86/130 => Loss 31.261,  Loss1 0.794, Train_accy 76.35, Test_accy 59.48
2024-08-02 21:18:02,998 [foster.py] => SNet: Task 25, Epoch 87/130 => Loss 31.171,  Loss1 0.795, Train_accy 77.43
2024-08-02 21:18:07,218 [foster.py] => SNet: Task 25, Epoch 88/130 => Loss 31.269,  Loss1 0.794, Train_accy 76.89
2024-08-02 21:18:11,399 [foster.py] => SNet: Task 25, Epoch 89/130 => Loss 31.272,  Loss1 0.794, Train_accy 76.55
2024-08-02 21:18:15,602 [foster.py] => SNet: Task 25, Epoch 90/130 => Loss 31.197,  Loss1 0.795, Train_accy 76.66
2024-08-02 21:18:21,191 [foster.py] => SNet: Task 25, Epoch 91/130 => Loss 31.270,  Loss1 0.794, Train_accy 77.26, Test_accy 59.79
2024-08-02 21:18:25,415 [foster.py] => SNet: Task 25, Epoch 92/130 => Loss 31.277,  Loss1 0.794, Train_accy 76.62
2024-08-02 21:18:29,632 [foster.py] => SNet: Task 25, Epoch 93/130 => Loss 31.257,  Loss1 0.794, Train_accy 76.99
2024-08-02 21:18:33,863 [foster.py] => SNet: Task 25, Epoch 94/130 => Loss 31.264,  Loss1 0.795, Train_accy 77.70
2024-08-02 21:18:38,032 [foster.py] => SNet: Task 25, Epoch 95/130 => Loss 31.270,  Loss1 0.795, Train_accy 75.98
2024-08-02 21:18:43,598 [foster.py] => SNet: Task 25, Epoch 96/130 => Loss 31.257,  Loss1 0.795, Train_accy 76.59, Test_accy 59.64
2024-08-02 21:18:47,852 [foster.py] => SNet: Task 25, Epoch 97/130 => Loss 31.213,  Loss1 0.794, Train_accy 76.28
2024-08-02 21:18:52,070 [foster.py] => SNet: Task 25, Epoch 98/130 => Loss 31.213,  Loss1 0.795, Train_accy 77.30
2024-08-02 21:18:56,279 [foster.py] => SNet: Task 25, Epoch 99/130 => Loss 31.210,  Loss1 0.795, Train_accy 77.09
2024-08-02 21:19:00,434 [foster.py] => SNet: Task 25, Epoch 100/130 => Loss 31.228,  Loss1 0.794, Train_accy 77.74
2024-08-02 21:19:06,039 [foster.py] => SNet: Task 25, Epoch 101/130 => Loss 31.259,  Loss1 0.794, Train_accy 77.40, Test_accy 59.93
2024-08-02 21:19:10,222 [foster.py] => SNet: Task 25, Epoch 102/130 => Loss 31.213,  Loss1 0.794, Train_accy 77.09
2024-08-02 21:19:14,407 [foster.py] => SNet: Task 25, Epoch 103/130 => Loss 31.262,  Loss1 0.795, Train_accy 76.49
2024-08-02 21:19:18,648 [foster.py] => SNet: Task 25, Epoch 104/130 => Loss 31.227,  Loss1 0.794, Train_accy 77.06
2024-08-02 21:19:22,876 [foster.py] => SNet: Task 25, Epoch 105/130 => Loss 31.277,  Loss1 0.795, Train_accy 77.91
2024-08-02 21:19:28,447 [foster.py] => SNet: Task 25, Epoch 106/130 => Loss 31.212,  Loss1 0.795, Train_accy 76.76, Test_accy 59.71
2024-08-02 21:19:32,619 [foster.py] => SNet: Task 25, Epoch 107/130 => Loss 31.225,  Loss1 0.794, Train_accy 77.67
2024-08-02 21:19:36,830 [foster.py] => SNet: Task 25, Epoch 108/130 => Loss 31.231,  Loss1 0.795, Train_accy 77.87
2024-08-02 21:19:41,025 [foster.py] => SNet: Task 25, Epoch 109/130 => Loss 31.254,  Loss1 0.795, Train_accy 75.68
2024-08-02 21:19:45,282 [foster.py] => SNet: Task 25, Epoch 110/130 => Loss 31.210,  Loss1 0.795, Train_accy 77.97
2024-08-02 21:19:50,866 [foster.py] => SNet: Task 25, Epoch 111/130 => Loss 31.251,  Loss1 0.795, Train_accy 77.80, Test_accy 59.79
2024-08-02 21:19:55,085 [foster.py] => SNet: Task 25, Epoch 112/130 => Loss 31.187,  Loss1 0.795, Train_accy 77.23
2024-08-02 21:19:59,331 [foster.py] => SNet: Task 25, Epoch 113/130 => Loss 31.247,  Loss1 0.794, Train_accy 76.82
2024-08-02 21:20:03,574 [foster.py] => SNet: Task 25, Epoch 114/130 => Loss 31.250,  Loss1 0.795, Train_accy 76.05
2024-08-02 21:20:07,799 [foster.py] => SNet: Task 25, Epoch 115/130 => Loss 31.208,  Loss1 0.794, Train_accy 76.96
2024-08-02 21:20:13,334 [foster.py] => SNet: Task 25, Epoch 116/130 => Loss 31.273,  Loss1 0.794, Train_accy 77.06, Test_accy 59.95
2024-08-02 21:20:17,503 [foster.py] => SNet: Task 25, Epoch 117/130 => Loss 31.258,  Loss1 0.795, Train_accy 76.76
2024-08-02 21:20:21,709 [foster.py] => SNet: Task 25, Epoch 118/130 => Loss 31.269,  Loss1 0.795, Train_accy 76.96
2024-08-02 21:20:25,937 [foster.py] => SNet: Task 25, Epoch 119/130 => Loss 31.295,  Loss1 0.794, Train_accy 76.32
2024-08-02 21:20:30,110 [foster.py] => SNet: Task 25, Epoch 120/130 => Loss 31.257,  Loss1 0.794, Train_accy 77.09
2024-08-02 21:20:35,669 [foster.py] => SNet: Task 25, Epoch 121/130 => Loss 31.230,  Loss1 0.794, Train_accy 77.43, Test_accy 59.87
2024-08-02 21:20:39,903 [foster.py] => SNet: Task 25, Epoch 122/130 => Loss 31.216,  Loss1 0.795, Train_accy 77.33
2024-08-02 21:20:44,088 [foster.py] => SNet: Task 25, Epoch 123/130 => Loss 31.260,  Loss1 0.794, Train_accy 76.99
2024-08-02 21:20:48,294 [foster.py] => SNet: Task 25, Epoch 124/130 => Loss 31.267,  Loss1 0.795, Train_accy 76.82
2024-08-02 21:20:52,511 [foster.py] => SNet: Task 25, Epoch 125/130 => Loss 31.249,  Loss1 0.794, Train_accy 77.64
2024-08-02 21:20:58,082 [foster.py] => SNet: Task 25, Epoch 126/130 => Loss 31.242,  Loss1 0.794, Train_accy 76.55, Test_accy 59.90
2024-08-02 21:21:02,287 [foster.py] => SNet: Task 25, Epoch 127/130 => Loss 31.239,  Loss1 0.793, Train_accy 78.01
2024-08-02 21:21:06,499 [foster.py] => SNet: Task 25, Epoch 128/130 => Loss 31.202,  Loss1 0.794, Train_accy 77.30
2024-08-02 21:21:10,751 [foster.py] => SNet: Task 25, Epoch 129/130 => Loss 31.253,  Loss1 0.795, Train_accy 76.66
2024-08-02 21:21:14,954 [foster.py] => SNet: Task 25, Epoch 130/130 => Loss 31.259,  Loss1 0.795, Train_accy 77.03
2024-08-02 21:21:14,954 [foster.py] => do not weight align student!
2024-08-02 21:21:16,342 [foster.py] => darknet eval: 
2024-08-02 21:21:16,343 [foster.py] => CNN top1 curve: 60.01
2024-08-02 21:21:16,343 [foster.py] => CNN top5 curve: 84.51
2024-08-02 21:21:16,343 [foster.py] => CNN top1 平均值: 60.01
2024-08-02 21:21:16,347 [foster.py] => timees : 1401.479440689087
2024-08-02 21:21:16,348 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-08-02 21:21:46,732 [foster.py] => Exemplar size: 2000
2024-08-02 21:21:46,733 [trainer.py] => CNN: {'total': 59.94, '00-09': 66.0, '10-19': 48.2, '20-29': 64.9, '30-39': 56.5, '40-49': 64.0, '50-59': 46.8, '60-69': 58.0, '70-79': 56.1, '80-89': 67.7, '90-99': 71.2, 'old': 59.56, 'new': 78.5}
2024-08-02 21:21:46,733 [trainer.py] => NME: {'total': 53.53, '00-09': 51.2, '10-19': 37.2, '20-29': 55.9, '30-39': 47.0, '40-49': 54.5, '50-59': 41.5, '60-69': 58.0, '70-79': 59.5, '80-89': 69.8, '90-99': 60.7, 'old': 52.83, 'new': 88.0}
2024-08-02 21:21:46,733 [trainer.py] => CNN top1 curve: [81.66, 80.75, 79.35, 78.45, 77.29, 76.17, 75.56, 73.67, 73.08, 72.79, 71.43, 70.56, 69.85, 68.55, 67.21, 66.38, 65.95, 65.73, 64.95, 64.19, 63.13, 62.75, 61.26, 60.76, 60.71, 59.94]
2024-08-02 21:21:46,733 [trainer.py] => CNN top5 curve: [97.02, 96.81, 96.65, 96.46, 95.79, 95.27, 94.52, 93.83, 93.38, 92.9, 92.31, 91.96, 91.19, 90.66, 90.45, 89.56, 89.54, 89.1, 88.45, 88.03, 86.99, 86.89, 85.94, 85.82, 85.39, 84.87]
2024-08-02 21:21:46,733 [trainer.py] => NME top1 curve: [80.72, 77.73, 76.3, 74.91, 74.0, 72.02, 71.27, 69.28, 69.15, 68.26, 67.61, 66.04, 64.74, 63.17, 62.36, 60.9, 60.26, 59.67, 59.05, 58.08, 58.09, 57.52, 55.7, 54.34, 54.94, 53.53]
2024-08-02 21:21:46,733 [trainer.py] => NME top5 curve: [96.8, 95.31, 94.65, 94.54, 93.83, 92.9, 92.56, 91.67, 90.65, 89.69, 89.91, 89.31, 88.91, 87.8, 87.58, 86.4, 86.16, 85.65, 85.38, 84.42, 83.79, 83.43, 81.69, 80.6, 80.78, 79.9]

2024-08-02 21:21:46,733 [trainer.py] => CNN top1 平均值: 69.70
