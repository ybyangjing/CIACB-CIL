2024-08-07 12:41:15,505 [trainer.py] => config: ./configs/cifar/b0inc201.json
2024-08-07 12:41:15,508 [trainer.py] => prefix: cil
2024-08-07 12:41:15,508 [trainer.py] => dataset: cifar100
2024-08-07 12:41:15,509 [trainer.py] => memory_size: 2000
2024-08-07 12:41:15,509 [trainer.py] => memory_per_class: 20
2024-08-07 12:41:15,509 [trainer.py] => fixed_memory: False
2024-08-07 12:41:15,510 [trainer.py] => shuffle: True
2024-08-07 12:41:15,510 [trainer.py] => init_cls: 20
2024-08-07 12:41:15,510 [trainer.py] => increment: 20
2024-08-07 12:41:15,511 [trainer.py] => model_name: foster
2024-08-07 12:41:15,511 [trainer.py] => convnet_type: resnet32
2024-08-07 12:41:15,511 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-07 12:41:15,512 [trainer.py] => seed: 1993
2024-08-07 12:41:15,512 [trainer.py] => beta1: [0.97, 0.96, 0.95, 0.94]
2024-08-07 12:41:15,512 [trainer.py] => beta2: 0.975
2024-08-07 12:41:15,513 [trainer.py] => oofc: ft
2024-08-07 12:41:15,513 [trainer.py] => is_teacher_wa: False
2024-08-07 12:41:15,513 [trainer.py] => is_student_wa: False
2024-08-07 12:41:15,514 [trainer.py] => lambda_okd: 1
2024-08-07 12:41:15,514 [trainer.py] => wa_value: 1
2024-08-07 12:41:15,514 [trainer.py] => init_epochs: 200
2024-08-07 12:41:15,514 [trainer.py] => init_lr: 0.1
2024-08-07 12:41:15,515 [trainer.py] => init_weight_decay: 0.0005
2024-08-07 12:41:15,515 [trainer.py] => boosting_epochs: 170
2024-08-07 12:41:15,515 [trainer.py] => compression_epochs: 130
2024-08-07 12:41:15,515 [trainer.py] => lr: 0.1
2024-08-07 12:41:15,515 [trainer.py] => batch_size: 128
2024-08-07 12:41:15,516 [trainer.py] => weight_decay: 0.0005
2024-08-07 12:41:15,516 [trainer.py] => num_workers: 8
2024-08-07 12:41:15,516 [trainer.py] => T: 2
2024-08-07 12:41:17,780 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-07 12:41:17,900 [trainer.py] => All params: 0
2024-08-07 12:41:17,900 [trainer.py] => Trainable params: 0
2024-08-07 12:41:19,131 [foster.py] => Learning on 0-20
2024-08-07 12:41:19,133 [foster.py] => All params: 643874
2024-08-07 12:41:19,134 [foster.py] => Trainable params: 643874
2024-08-07 12:41:47,290 [foster.py] => Task 0, Epoch 1/200 => Loss 2.915, Train_accy 10.22, Test_accy 19.75
2024-08-07 12:41:55,037 [foster.py] => Task 0, Epoch 2/200 => Loss 2.725, Loss1 2.725,Train_accy 16.18
2024-08-07 12:42:02,782 [foster.py] => Task 0, Epoch 3/200 => Loss 2.618, Loss1 2.618,Train_accy 19.95
2024-08-07 12:42:10,533 [foster.py] => Task 0, Epoch 4/200 => Loss 2.544, Loss1 2.544,Train_accy 22.11
2024-08-07 12:42:18,309 [foster.py] => Task 0, Epoch 5/200 => Loss 2.477, Loss1 2.477,Train_accy 24.04
2024-08-07 12:42:27,157 [foster.py] => Task 0, Epoch 6/200 => Loss 2.417, Train_accy 26.21, Test_accy 35.95
2024-08-07 12:42:34,940 [foster.py] => Task 0, Epoch 7/200 => Loss 2.352, Loss1 2.352,Train_accy 28.33
2024-08-07 12:42:42,810 [foster.py] => Task 0, Epoch 8/200 => Loss 2.283, Loss1 2.283,Train_accy 29.35
2024-08-07 12:42:50,588 [foster.py] => Task 0, Epoch 9/200 => Loss 2.212, Loss1 2.212,Train_accy 31.82
2024-08-07 12:42:58,355 [foster.py] => Task 0, Epoch 10/200 => Loss 2.154, Loss1 2.154,Train_accy 33.94
2024-08-07 12:43:07,157 [foster.py] => Task 0, Epoch 11/200 => Loss 2.119, Train_accy 34.86, Test_accy 42.55
2024-08-07 12:43:14,916 [foster.py] => Task 0, Epoch 12/200 => Loss 2.059, Loss1 2.059,Train_accy 36.23
2024-08-07 12:43:23,253 [foster.py] => Task 0, Epoch 13/200 => Loss 2.020, Loss1 2.020,Train_accy 38.07
2024-08-07 12:43:31,040 [foster.py] => Task 0, Epoch 14/200 => Loss 1.932, Loss1 1.932,Train_accy 40.31
2024-08-07 12:43:38,806 [foster.py] => Task 0, Epoch 15/200 => Loss 1.917, Loss1 1.917,Train_accy 41.05
2024-08-07 12:43:47,631 [foster.py] => Task 0, Epoch 16/200 => Loss 1.867, Train_accy 41.65, Test_accy 45.30
2024-08-07 12:43:55,416 [foster.py] => Task 0, Epoch 17/200 => Loss 1.841, Loss1 1.841,Train_accy 43.56
2024-08-07 12:44:03,168 [foster.py] => Task 0, Epoch 18/200 => Loss 1.807, Loss1 1.807,Train_accy 44.14
2024-08-07 12:44:11,150 [foster.py] => Task 0, Epoch 19/200 => Loss 1.778, Loss1 1.778,Train_accy 44.88
2024-08-07 12:44:19,197 [foster.py] => Task 0, Epoch 20/200 => Loss 1.750, Loss1 1.750,Train_accy 45.59
2024-08-07 12:44:28,358 [foster.py] => Task 0, Epoch 21/200 => Loss 1.719, Train_accy 46.90, Test_accy 44.40
2024-08-07 12:44:36,350 [foster.py] => Task 0, Epoch 22/200 => Loss 1.684, Loss1 1.684,Train_accy 47.86
2024-08-07 12:44:44,410 [foster.py] => Task 0, Epoch 23/200 => Loss 1.679, Loss1 1.679,Train_accy 48.25
2024-08-07 12:44:52,398 [foster.py] => Task 0, Epoch 24/200 => Loss 1.610, Loss1 1.610,Train_accy 50.54
2024-08-07 12:45:00,461 [foster.py] => Task 0, Epoch 25/200 => Loss 1.635, Loss1 1.635,Train_accy 49.44
2024-08-07 12:45:09,564 [foster.py] => Task 0, Epoch 26/200 => Loss 1.646, Train_accy 49.22, Test_accy 53.00
2024-08-07 12:45:17,603 [foster.py] => Task 0, Epoch 27/200 => Loss 1.541, Loss1 1.541,Train_accy 51.92
2024-08-07 12:45:25,653 [foster.py] => Task 0, Epoch 28/200 => Loss 1.578, Loss1 1.578,Train_accy 51.03
2024-08-07 12:45:33,679 [foster.py] => Task 0, Epoch 29/200 => Loss 1.528, Loss1 1.528,Train_accy 52.71
2024-08-07 12:45:42,330 [foster.py] => Task 0, Epoch 30/200 => Loss 1.531, Loss1 1.531,Train_accy 52.50
2024-08-07 12:45:51,431 [foster.py] => Task 0, Epoch 31/200 => Loss 1.500, Train_accy 54.16, Test_accy 57.35
2024-08-07 12:45:59,443 [foster.py] => Task 0, Epoch 32/200 => Loss 1.484, Loss1 1.484,Train_accy 54.17
2024-08-07 12:46:07,498 [foster.py] => Task 0, Epoch 33/200 => Loss 1.482, Loss1 1.482,Train_accy 53.70
2024-08-07 12:46:15,543 [foster.py] => Task 0, Epoch 34/200 => Loss 1.451, Loss1 1.451,Train_accy 55.05
2024-08-07 12:46:23,612 [foster.py] => Task 0, Epoch 35/200 => Loss 1.462, Loss1 1.462,Train_accy 54.63
2024-08-07 12:46:32,743 [foster.py] => Task 0, Epoch 36/200 => Loss 1.438, Train_accy 55.51, Test_accy 62.30
2024-08-07 12:46:40,783 [foster.py] => Task 0, Epoch 37/200 => Loss 1.412, Loss1 1.412,Train_accy 56.01
2024-08-07 12:46:48,769 [foster.py] => Task 0, Epoch 38/200 => Loss 1.409, Loss1 1.409,Train_accy 56.14
2024-08-07 12:46:56,837 [foster.py] => Task 0, Epoch 39/200 => Loss 1.415, Loss1 1.415,Train_accy 56.23
2024-08-07 12:47:04,872 [foster.py] => Task 0, Epoch 40/200 => Loss 1.396, Loss1 1.396,Train_accy 56.59
2024-08-07 12:47:13,975 [foster.py] => Task 0, Epoch 41/200 => Loss 1.375, Train_accy 58.12, Test_accy 57.80
2024-08-07 12:47:22,029 [foster.py] => Task 0, Epoch 42/200 => Loss 1.363, Loss1 1.363,Train_accy 57.99
2024-08-07 12:47:30,120 [foster.py] => Task 0, Epoch 43/200 => Loss 1.369, Loss1 1.369,Train_accy 57.86
2024-08-07 12:47:38,182 [foster.py] => Task 0, Epoch 44/200 => Loss 1.318, Loss1 1.318,Train_accy 59.04
2024-08-07 12:47:46,315 [foster.py] => Task 0, Epoch 45/200 => Loss 1.347, Loss1 1.347,Train_accy 58.85
2024-08-07 12:47:55,469 [foster.py] => Task 0, Epoch 46/200 => Loss 1.346, Train_accy 58.51, Test_accy 62.40
2024-08-07 12:48:03,516 [foster.py] => Task 0, Epoch 47/200 => Loss 1.347, Loss1 1.347,Train_accy 57.81
2024-08-07 12:48:11,526 [foster.py] => Task 0, Epoch 48/200 => Loss 1.302, Loss1 1.302,Train_accy 60.08
2024-08-07 12:48:19,603 [foster.py] => Task 0, Epoch 49/200 => Loss 1.298, Loss1 1.298,Train_accy 59.58
2024-08-07 12:48:27,695 [foster.py] => Task 0, Epoch 50/200 => Loss 1.278, Loss1 1.278,Train_accy 60.61
2024-08-07 12:48:36,863 [foster.py] => Task 0, Epoch 51/200 => Loss 1.288, Train_accy 60.08, Test_accy 49.00
2024-08-07 12:48:44,954 [foster.py] => Task 0, Epoch 52/200 => Loss 1.275, Loss1 1.275,Train_accy 60.62
2024-08-07 12:48:53,051 [foster.py] => Task 0, Epoch 53/200 => Loss 1.271, Loss1 1.271,Train_accy 61.06
2024-08-07 12:49:01,145 [foster.py] => Task 0, Epoch 54/200 => Loss 1.291, Loss1 1.291,Train_accy 59.65
2024-08-07 12:49:09,402 [foster.py] => Task 0, Epoch 55/200 => Loss 1.261, Loss1 1.261,Train_accy 61.00
2024-08-07 12:49:18,707 [foster.py] => Task 0, Epoch 56/200 => Loss 1.281, Train_accy 60.41, Test_accy 61.50
2024-08-07 12:49:26,933 [foster.py] => Task 0, Epoch 57/200 => Loss 1.257, Loss1 1.257,Train_accy 61.53
2024-08-07 12:49:35,160 [foster.py] => Task 0, Epoch 58/200 => Loss 1.231, Loss1 1.231,Train_accy 62.05
2024-08-07 12:49:43,385 [foster.py] => Task 0, Epoch 59/200 => Loss 1.234, Loss1 1.234,Train_accy 61.45
2024-08-07 12:49:51,628 [foster.py] => Task 0, Epoch 60/200 => Loss 1.195, Loss1 1.195,Train_accy 62.65
2024-08-07 12:50:00,952 [foster.py] => Task 0, Epoch 61/200 => Loss 1.245, Train_accy 61.83, Test_accy 64.65
2024-08-07 12:50:09,175 [foster.py] => Task 0, Epoch 62/200 => Loss 1.221, Loss1 1.221,Train_accy 62.48
2024-08-07 12:50:17,439 [foster.py] => Task 0, Epoch 63/200 => Loss 1.190, Loss1 1.190,Train_accy 63.04
2024-08-07 12:50:25,652 [foster.py] => Task 0, Epoch 64/200 => Loss 1.202, Loss1 1.202,Train_accy 63.18
2024-08-07 12:50:33,604 [foster.py] => Task 0, Epoch 65/200 => Loss 1.177, Loss1 1.177,Train_accy 63.67
2024-08-07 12:50:42,476 [foster.py] => Task 0, Epoch 66/200 => Loss 1.215, Train_accy 62.76, Test_accy 62.45
2024-08-07 12:50:50,217 [foster.py] => Task 0, Epoch 67/200 => Loss 1.178, Loss1 1.178,Train_accy 63.45
2024-08-07 12:50:58,044 [foster.py] => Task 0, Epoch 68/200 => Loss 1.177, Loss1 1.177,Train_accy 63.54
2024-08-07 12:51:05,919 [foster.py] => Task 0, Epoch 69/200 => Loss 1.182, Loss1 1.182,Train_accy 63.66
2024-08-07 12:51:13,768 [foster.py] => Task 0, Epoch 70/200 => Loss 1.160, Loss1 1.160,Train_accy 63.54
2024-08-07 12:51:22,898 [foster.py] => Task 0, Epoch 71/200 => Loss 1.178, Train_accy 63.16, Test_accy 68.35
2024-08-07 12:51:30,839 [foster.py] => Task 0, Epoch 72/200 => Loss 1.129, Loss1 1.129,Train_accy 65.12
2024-08-07 12:51:38,823 [foster.py] => Task 0, Epoch 73/200 => Loss 1.149, Loss1 1.149,Train_accy 64.29
2024-08-07 12:51:46,834 [foster.py] => Task 0, Epoch 74/200 => Loss 1.126, Loss1 1.126,Train_accy 64.99
2024-08-07 12:51:54,782 [foster.py] => Task 0, Epoch 75/200 => Loss 1.154, Loss1 1.154,Train_accy 64.29
2024-08-07 12:52:03,865 [foster.py] => Task 0, Epoch 76/200 => Loss 1.113, Train_accy 65.43, Test_accy 69.75
2024-08-07 12:52:11,880 [foster.py] => Task 0, Epoch 77/200 => Loss 1.093, Loss1 1.093,Train_accy 66.53
2024-08-07 12:52:19,925 [foster.py] => Task 0, Epoch 78/200 => Loss 1.127, Loss1 1.127,Train_accy 65.94
2024-08-07 12:52:27,935 [foster.py] => Task 0, Epoch 79/200 => Loss 1.132, Loss1 1.132,Train_accy 65.51
2024-08-07 12:52:35,909 [foster.py] => Task 0, Epoch 80/200 => Loss 1.125, Loss1 1.125,Train_accy 65.63
2024-08-07 12:52:44,988 [foster.py] => Task 0, Epoch 81/200 => Loss 1.106, Train_accy 65.78, Test_accy 60.20
2024-08-07 12:52:52,961 [foster.py] => Task 0, Epoch 82/200 => Loss 1.085, Loss1 1.085,Train_accy 66.06
2024-08-07 12:53:00,973 [foster.py] => Task 0, Epoch 83/200 => Loss 1.083, Loss1 1.083,Train_accy 66.27
2024-08-07 12:53:08,962 [foster.py] => Task 0, Epoch 84/200 => Loss 1.095, Loss1 1.095,Train_accy 66.50
2024-08-07 12:53:16,943 [foster.py] => Task 0, Epoch 85/200 => Loss 1.054, Loss1 1.054,Train_accy 67.73
2024-08-07 12:53:26,025 [foster.py] => Task 0, Epoch 86/200 => Loss 1.092, Train_accy 66.46, Test_accy 69.00
2024-08-07 12:53:34,043 [foster.py] => Task 0, Epoch 87/200 => Loss 1.058, Loss1 1.058,Train_accy 67.14
2024-08-07 12:53:42,018 [foster.py] => Task 0, Epoch 88/200 => Loss 1.049, Loss1 1.049,Train_accy 67.47
2024-08-07 12:53:50,021 [foster.py] => Task 0, Epoch 89/200 => Loss 1.052, Loss1 1.052,Train_accy 67.23
2024-08-07 12:53:58,003 [foster.py] => Task 0, Epoch 90/200 => Loss 1.052, Loss1 1.052,Train_accy 67.66
2024-08-07 12:54:07,048 [foster.py] => Task 0, Epoch 91/200 => Loss 1.047, Train_accy 67.44, Test_accy 73.40
2024-08-07 12:54:15,023 [foster.py] => Task 0, Epoch 92/200 => Loss 1.055, Loss1 1.055,Train_accy 67.20
2024-08-07 12:54:23,045 [foster.py] => Task 0, Epoch 93/200 => Loss 1.002, Loss1 1.002,Train_accy 68.79
2024-08-07 12:54:31,078 [foster.py] => Task 0, Epoch 94/200 => Loss 1.038, Loss1 1.038,Train_accy 68.09
2024-08-07 12:54:39,042 [foster.py] => Task 0, Epoch 95/200 => Loss 1.002, Loss1 1.002,Train_accy 68.44
2024-08-07 12:54:48,160 [foster.py] => Task 0, Epoch 96/200 => Loss 0.998, Train_accy 68.77, Test_accy 73.95
2024-08-07 12:54:56,145 [foster.py] => Task 0, Epoch 97/200 => Loss 1.008, Loss1 1.008,Train_accy 68.44
2024-08-07 12:55:04,131 [foster.py] => Task 0, Epoch 98/200 => Loss 1.024, Loss1 1.024,Train_accy 67.98
2024-08-07 12:55:12,107 [foster.py] => Task 0, Epoch 99/200 => Loss 1.003, Loss1 1.003,Train_accy 69.57
2024-08-07 12:55:20,110 [foster.py] => Task 0, Epoch 100/200 => Loss 0.985, Loss1 0.985,Train_accy 69.56
2024-08-07 12:55:29,229 [foster.py] => Task 0, Epoch 101/200 => Loss 1.004, Train_accy 69.42, Test_accy 65.85
2024-08-07 12:55:37,222 [foster.py] => Task 0, Epoch 102/200 => Loss 0.978, Loss1 0.978,Train_accy 69.82
2024-08-07 12:55:45,824 [foster.py] => Task 0, Epoch 103/200 => Loss 0.973, Loss1 0.973,Train_accy 70.07
2024-08-07 12:55:53,802 [foster.py] => Task 0, Epoch 104/200 => Loss 0.953, Loss1 0.953,Train_accy 70.60
2024-08-07 12:56:01,785 [foster.py] => Task 0, Epoch 105/200 => Loss 0.956, Loss1 0.956,Train_accy 70.21
2024-08-07 12:56:10,902 [foster.py] => Task 0, Epoch 106/200 => Loss 0.958, Train_accy 70.62, Test_accy 73.95
2024-08-07 12:56:18,877 [foster.py] => Task 0, Epoch 107/200 => Loss 0.983, Loss1 0.983,Train_accy 69.00
2024-08-07 12:56:26,906 [foster.py] => Task 0, Epoch 108/200 => Loss 0.937, Loss1 0.937,Train_accy 70.76
2024-08-07 12:56:34,851 [foster.py] => Task 0, Epoch 109/200 => Loss 0.922, Loss1 0.922,Train_accy 71.14
2024-08-07 12:56:42,875 [foster.py] => Task 0, Epoch 110/200 => Loss 0.920, Loss1 0.920,Train_accy 71.80
2024-08-07 12:56:51,978 [foster.py] => Task 0, Epoch 111/200 => Loss 0.934, Train_accy 70.71, Test_accy 75.95
2024-08-07 12:56:59,971 [foster.py] => Task 0, Epoch 112/200 => Loss 0.904, Loss1 0.904,Train_accy 71.89
2024-08-07 12:57:08,010 [foster.py] => Task 0, Epoch 113/200 => Loss 0.941, Loss1 0.941,Train_accy 70.87
2024-08-07 12:57:16,041 [foster.py] => Task 0, Epoch 114/200 => Loss 0.925, Loss1 0.925,Train_accy 71.36
2024-08-07 12:57:24,023 [foster.py] => Task 0, Epoch 115/200 => Loss 0.916, Loss1 0.916,Train_accy 71.69
2024-08-07 12:57:33,104 [foster.py] => Task 0, Epoch 116/200 => Loss 0.899, Train_accy 71.92, Test_accy 68.95
2024-08-07 12:57:41,092 [foster.py] => Task 0, Epoch 117/200 => Loss 0.890, Loss1 0.890,Train_accy 71.77
2024-08-07 12:57:49,023 [foster.py] => Task 0, Epoch 118/200 => Loss 0.912, Loss1 0.912,Train_accy 71.61
2024-08-07 12:57:56,992 [foster.py] => Task 0, Epoch 119/200 => Loss 0.902, Loss1 0.902,Train_accy 72.40
2024-08-07 12:58:04,962 [foster.py] => Task 0, Epoch 120/200 => Loss 0.880, Loss1 0.880,Train_accy 72.53
2024-08-07 12:58:14,035 [foster.py] => Task 0, Epoch 121/200 => Loss 0.875, Train_accy 72.58, Test_accy 77.55
2024-08-07 12:58:22,003 [foster.py] => Task 0, Epoch 122/200 => Loss 0.845, Loss1 0.845,Train_accy 73.70
2024-08-07 12:58:29,965 [foster.py] => Task 0, Epoch 123/200 => Loss 0.847, Loss1 0.847,Train_accy 73.40
2024-08-07 12:58:37,918 [foster.py] => Task 0, Epoch 124/200 => Loss 0.846, Loss1 0.846,Train_accy 73.24
2024-08-07 12:58:45,899 [foster.py] => Task 0, Epoch 125/200 => Loss 0.850, Loss1 0.850,Train_accy 73.65
2024-08-07 12:58:54,969 [foster.py] => Task 0, Epoch 126/200 => Loss 0.841, Train_accy 73.90, Test_accy 77.00
2024-08-07 12:59:02,886 [foster.py] => Task 0, Epoch 127/200 => Loss 0.819, Loss1 0.819,Train_accy 74.52
2024-08-07 12:59:10,880 [foster.py] => Task 0, Epoch 128/200 => Loss 0.810, Loss1 0.810,Train_accy 74.66
2024-08-07 12:59:18,856 [foster.py] => Task 0, Epoch 129/200 => Loss 0.787, Loss1 0.787,Train_accy 75.22
2024-08-07 12:59:26,885 [foster.py] => Task 0, Epoch 130/200 => Loss 0.812, Loss1 0.812,Train_accy 75.08
2024-08-07 12:59:36,518 [foster.py] => Task 0, Epoch 131/200 => Loss 0.771, Train_accy 75.63, Test_accy 74.50
2024-08-07 12:59:44,481 [foster.py] => Task 0, Epoch 132/200 => Loss 0.773, Loss1 0.773,Train_accy 75.92
2024-08-07 12:59:52,464 [foster.py] => Task 0, Epoch 133/200 => Loss 0.811, Loss1 0.811,Train_accy 74.93
2024-08-07 13:00:00,422 [foster.py] => Task 0, Epoch 134/200 => Loss 0.768, Loss1 0.768,Train_accy 75.76
2024-08-07 13:00:08,451 [foster.py] => Task 0, Epoch 135/200 => Loss 0.757, Loss1 0.757,Train_accy 76.41
2024-08-07 13:00:17,531 [foster.py] => Task 0, Epoch 136/200 => Loss 0.764, Train_accy 76.07, Test_accy 80.45
2024-08-07 13:00:25,552 [foster.py] => Task 0, Epoch 137/200 => Loss 0.746, Loss1 0.746,Train_accy 76.68
2024-08-07 13:00:33,540 [foster.py] => Task 0, Epoch 138/200 => Loss 0.738, Loss1 0.738,Train_accy 76.93
2024-08-07 13:00:41,536 [foster.py] => Task 0, Epoch 139/200 => Loss 0.738, Loss1 0.738,Train_accy 77.17
2024-08-07 13:00:49,494 [foster.py] => Task 0, Epoch 140/200 => Loss 0.758, Loss1 0.758,Train_accy 77.09
2024-08-07 13:00:58,526 [foster.py] => Task 0, Epoch 141/200 => Loss 0.743, Train_accy 76.52, Test_accy 79.45
2024-08-07 13:01:06,502 [foster.py] => Task 0, Epoch 142/200 => Loss 0.730, Loss1 0.730,Train_accy 77.48
2024-08-07 13:01:14,496 [foster.py] => Task 0, Epoch 143/200 => Loss 0.726, Loss1 0.726,Train_accy 77.02
2024-08-07 13:01:22,509 [foster.py] => Task 0, Epoch 144/200 => Loss 0.698, Loss1 0.698,Train_accy 78.23
2024-08-07 13:01:30,481 [foster.py] => Task 0, Epoch 145/200 => Loss 0.715, Loss1 0.715,Train_accy 77.93
2024-08-07 13:01:39,607 [foster.py] => Task 0, Epoch 146/200 => Loss 0.703, Train_accy 77.79, Test_accy 81.95
2024-08-07 13:01:47,484 [foster.py] => Task 0, Epoch 147/200 => Loss 0.681, Loss1 0.681,Train_accy 78.71
2024-08-07 13:01:55,425 [foster.py] => Task 0, Epoch 148/200 => Loss 0.673, Loss1 0.673,Train_accy 79.19
2024-08-07 13:02:03,453 [foster.py] => Task 0, Epoch 149/200 => Loss 0.664, Loss1 0.664,Train_accy 79.15
2024-08-07 13:02:11,431 [foster.py] => Task 0, Epoch 150/200 => Loss 0.659, Loss1 0.659,Train_accy 79.51
2024-08-07 13:02:20,532 [foster.py] => Task 0, Epoch 151/200 => Loss 0.673, Train_accy 79.02, Test_accy 82.45
2024-08-07 13:02:28,494 [foster.py] => Task 0, Epoch 152/200 => Loss 0.654, Loss1 0.654,Train_accy 79.48
2024-08-07 13:02:36,455 [foster.py] => Task 0, Epoch 153/200 => Loss 0.629, Loss1 0.629,Train_accy 80.15
2024-08-07 13:02:44,392 [foster.py] => Task 0, Epoch 154/200 => Loss 0.632, Loss1 0.632,Train_accy 80.18
2024-08-07 13:02:52,367 [foster.py] => Task 0, Epoch 155/200 => Loss 0.628, Loss1 0.628,Train_accy 80.65
2024-08-07 13:03:01,394 [foster.py] => Task 0, Epoch 156/200 => Loss 0.602, Train_accy 81.18, Test_accy 83.80
2024-08-07 13:03:09,343 [foster.py] => Task 0, Epoch 157/200 => Loss 0.591, Loss1 0.591,Train_accy 81.67
2024-08-07 13:03:17,362 [foster.py] => Task 0, Epoch 158/200 => Loss 0.586, Loss1 0.586,Train_accy 81.71
2024-08-07 13:03:25,968 [foster.py] => Task 0, Epoch 159/200 => Loss 0.594, Loss1 0.594,Train_accy 81.15
2024-08-07 13:03:33,961 [foster.py] => Task 0, Epoch 160/200 => Loss 0.588, Loss1 0.588,Train_accy 81.68
2024-08-07 13:03:43,131 [foster.py] => Task 0, Epoch 161/200 => Loss 0.591, Train_accy 81.85, Test_accy 84.80
2024-08-07 13:03:51,122 [foster.py] => Task 0, Epoch 162/200 => Loss 0.551, Loss1 0.551,Train_accy 82.58
2024-08-07 13:03:59,109 [foster.py] => Task 0, Epoch 163/200 => Loss 0.561, Loss1 0.561,Train_accy 82.11
2024-08-07 13:04:07,122 [foster.py] => Task 0, Epoch 164/200 => Loss 0.570, Loss1 0.570,Train_accy 82.27
2024-08-07 13:04:15,104 [foster.py] => Task 0, Epoch 165/200 => Loss 0.566, Loss1 0.566,Train_accy 82.56
2024-08-07 13:04:24,161 [foster.py] => Task 0, Epoch 166/200 => Loss 0.538, Train_accy 83.00, Test_accy 85.70
2024-08-07 13:04:32,110 [foster.py] => Task 0, Epoch 167/200 => Loss 0.538, Loss1 0.538,Train_accy 83.36
2024-08-07 13:04:40,109 [foster.py] => Task 0, Epoch 168/200 => Loss 0.533, Loss1 0.533,Train_accy 83.61
2024-08-07 13:04:48,052 [foster.py] => Task 0, Epoch 169/200 => Loss 0.513, Loss1 0.513,Train_accy 83.97
2024-08-07 13:04:56,029 [foster.py] => Task 0, Epoch 170/200 => Loss 0.514, Loss1 0.514,Train_accy 83.90
2024-08-07 13:05:05,076 [foster.py] => Task 0, Epoch 171/200 => Loss 0.500, Train_accy 84.57, Test_accy 85.85
2024-08-07 13:05:13,016 [foster.py] => Task 0, Epoch 172/200 => Loss 0.512, Loss1 0.512,Train_accy 84.39
2024-08-07 13:05:20,996 [foster.py] => Task 0, Epoch 173/200 => Loss 0.502, Loss1 0.502,Train_accy 84.63
2024-08-07 13:05:28,976 [foster.py] => Task 0, Epoch 174/200 => Loss 0.489, Loss1 0.489,Train_accy 84.93
2024-08-07 13:05:36,961 [foster.py] => Task 0, Epoch 175/200 => Loss 0.476, Loss1 0.476,Train_accy 85.26
2024-08-07 13:05:46,055 [foster.py] => Task 0, Epoch 176/200 => Loss 0.497, Train_accy 84.92, Test_accy 86.55
2024-08-07 13:05:54,008 [foster.py] => Task 0, Epoch 177/200 => Loss 0.458, Loss1 0.458,Train_accy 85.58
2024-08-07 13:06:01,915 [foster.py] => Task 0, Epoch 178/200 => Loss 0.468, Loss1 0.468,Train_accy 85.37
2024-08-07 13:06:09,905 [foster.py] => Task 0, Epoch 179/200 => Loss 0.468, Loss1 0.468,Train_accy 85.55
2024-08-07 13:06:17,869 [foster.py] => Task 0, Epoch 180/200 => Loss 0.451, Loss1 0.451,Train_accy 86.04
2024-08-07 13:06:26,962 [foster.py] => Task 0, Epoch 181/200 => Loss 0.438, Train_accy 86.30, Test_accy 86.45
2024-08-07 13:06:34,952 [foster.py] => Task 0, Epoch 182/200 => Loss 0.444, Loss1 0.444,Train_accy 86.41
2024-08-07 13:06:42,927 [foster.py] => Task 0, Epoch 183/200 => Loss 0.443, Loss1 0.443,Train_accy 86.29
2024-08-07 13:06:50,859 [foster.py] => Task 0, Epoch 184/200 => Loss 0.423, Loss1 0.423,Train_accy 86.73
2024-08-07 13:06:58,837 [foster.py] => Task 0, Epoch 185/200 => Loss 0.437, Loss1 0.437,Train_accy 86.52
2024-08-07 13:07:07,976 [foster.py] => Task 0, Epoch 186/200 => Loss 0.448, Train_accy 86.35, Test_accy 87.45
2024-08-07 13:07:16,490 [foster.py] => Task 0, Epoch 187/200 => Loss 0.427, Loss1 0.427,Train_accy 86.82
2024-08-07 13:07:24,414 [foster.py] => Task 0, Epoch 188/200 => Loss 0.430, Loss1 0.430,Train_accy 86.76
2024-08-07 13:07:32,429 [foster.py] => Task 0, Epoch 189/200 => Loss 0.425, Loss1 0.425,Train_accy 86.86
2024-08-07 13:07:40,412 [foster.py] => Task 0, Epoch 190/200 => Loss 0.423, Loss1 0.423,Train_accy 87.23
2024-08-07 13:07:49,481 [foster.py] => Task 0, Epoch 191/200 => Loss 0.430, Train_accy 86.53, Test_accy 87.30
2024-08-07 13:07:57,492 [foster.py] => Task 0, Epoch 192/200 => Loss 0.412, Loss1 0.412,Train_accy 87.49
2024-08-07 13:08:05,481 [foster.py] => Task 0, Epoch 193/200 => Loss 0.399, Loss1 0.399,Train_accy 87.53
2024-08-07 13:08:13,486 [foster.py] => Task 0, Epoch 194/200 => Loss 0.420, Loss1 0.420,Train_accy 87.28
2024-08-07 13:08:21,496 [foster.py] => Task 0, Epoch 195/200 => Loss 0.406, Loss1 0.406,Train_accy 87.59
2024-08-07 13:08:30,543 [foster.py] => Task 0, Epoch 196/200 => Loss 0.408, Train_accy 87.53, Test_accy 87.05
2024-08-07 13:08:38,462 [foster.py] => Task 0, Epoch 197/200 => Loss 0.413, Loss1 0.413,Train_accy 87.37
2024-08-07 13:08:46,421 [foster.py] => Task 0, Epoch 198/200 => Loss 0.420, Loss1 0.420,Train_accy 87.07
2024-08-07 13:08:54,375 [foster.py] => Task 0, Epoch 199/200 => Loss 0.402, Loss1 0.402,Train_accy 87.26
2024-08-07 13:09:02,403 [foster.py] => Task 0, Epoch 200/200 => Loss 0.415, Loss1 0.415,Train_accy 87.46
2024-08-07 13:09:02,405 [foster.py] => training time: 1663.2522122859955
2024-08-07 13:09:02,406 [base.py] => Reducing exemplars...(100 per classes)
2024-08-07 13:09:02,406 [base.py] => Constructing exemplars...(100 per classes)
2024-08-07 13:09:22,784 [foster.py] => Exemplar size: 2000
2024-08-07 13:09:22,784 [trainer.py] => CNN: {'total': 87.15, '00-09': 90.6, '10-19': 83.7, 'old': 0, 'new': 87.15}
2024-08-07 13:09:22,784 [trainer.py] => NME: {'total': 87.2, '00-09': 91.1, '10-19': 83.3, 'old': 0, 'new': 87.2}
2024-08-07 13:09:22,784 [trainer.py] => CNN top1 curve: [87.15]
2024-08-07 13:09:22,784 [trainer.py] => CNN top5 curve: [98.3]
2024-08-07 13:09:22,785 [trainer.py] => NME top1 curve: [87.2]
2024-08-07 13:09:22,785 [trainer.py] => NME top5 curve: [98.45]

2024-08-07 13:09:22,785 [trainer.py] => CNN top1 平均值: 87.15
2024-08-07 13:09:22,786 [trainer.py] => All params: 643874
2024-08-07 13:09:22,787 [trainer.py] => Trainable params: 643874
2024-08-07 13:09:22,881 [foster.py] => Learning on 20-40
2024-08-07 13:09:22,884 [foster.py] => All params: 1291608
2024-08-07 13:09:22,886 [foster.py] => Trainable params: 649034
2024-08-07 13:09:22,991 [foster.py] => per cls weights : [1.07189088 1.07189088 1.07189088 1.07189088 1.07189088 1.07189088
 1.07189088 1.07189088 1.07189088 1.07189088 1.07189088 1.07189088
 1.07189088 1.07189088 1.07189088 1.07189088 1.07189088 1.07189088
 1.07189088 1.07189088 0.92810912 0.92810912 0.92810912 0.92810912
 0.92810912 0.92810912 0.92810912 0.92810912 0.92810912 0.92810912
 0.92810912 0.92810912 0.92810912 0.92810912 0.92810912 0.92810912
 0.92810912 0.92810912 0.92810912 0.92810912]
2024-08-07 13:09:35,590 [foster.py] => Task 1, Epoch 1/170 => Loss 6.673, Loss_clf 2.298, Loss_fe 2.491, Loss_kd 0.942, Train_accy 40.59
2024-08-07 13:09:49,289 [foster.py] => Task 1, Epoch 2/170 => Loss 5.801, Loss_clf 1.853, Loss_fe 2.085, Loss_kd 0.931, Train_accy 49.99, Test_accy 61.62
2024-08-07 13:10:03,027 [foster.py] => Task 1, Epoch 3/170 => Loss 5.607, Loss_clf 1.780, Loss_fe 1.958, Loss_kd 0.934, Train_accy 52.17, Test_accy 62.58
2024-08-07 13:10:16,583 [foster.py] => Task 1, Epoch 4/170 => Loss 5.399, Loss_clf 1.697, Loss_fe 1.836, Loss_kd 0.932, Train_accy 54.68, Test_accy 64.97
2024-08-07 13:10:30,157 [foster.py] => Task 1, Epoch 5/170 => Loss 5.281, Loss_clf 1.652, Loss_fe 1.770, Loss_kd 0.929, Train_accy 55.59, Test_accy 61.90
2024-08-07 13:10:42,248 [foster.py] => Task 1, Epoch 6/170 => Loss 5.153, Loss_clf 1.608, Loss_fe 1.692, Loss_kd 0.926, Train_accy 57.18
2024-08-07 13:10:56,436 [foster.py] => Task 1, Epoch 7/170 => Loss 5.079, Loss_clf 1.567, Loss_fe 1.658, Loss_kd 0.927, Train_accy 58.24, Test_accy 69.10
2024-08-07 13:11:10,514 [foster.py] => Task 1, Epoch 8/170 => Loss 4.993, Loss_clf 1.526, Loss_fe 1.610, Loss_kd 0.928, Train_accy 58.87, Test_accy 68.95
2024-08-07 13:11:24,296 [foster.py] => Task 1, Epoch 9/170 => Loss 4.968, Loss_clf 1.509, Loss_fe 1.596, Loss_kd 0.930, Train_accy 59.92, Test_accy 68.47
2024-08-07 13:11:37,909 [foster.py] => Task 1, Epoch 10/170 => Loss 4.955, Loss_clf 1.512, Loss_fe 1.574, Loss_kd 0.934, Train_accy 59.66, Test_accy 69.50
2024-08-07 13:11:49,678 [foster.py] => Task 1, Epoch 11/170 => Loss 4.848, Loss_clf 1.457, Loss_fe 1.531, Loss_kd 0.929, Train_accy 61.37
2024-08-07 13:12:03,114 [foster.py] => Task 1, Epoch 12/170 => Loss 4.792, Loss_clf 1.439, Loss_fe 1.491, Loss_kd 0.930, Train_accy 62.09, Test_accy 66.08
2024-08-07 13:12:16,856 [foster.py] => Task 1, Epoch 13/170 => Loss 4.758, Loss_clf 1.428, Loss_fe 1.470, Loss_kd 0.929, Train_accy 61.87, Test_accy 66.68
2024-08-07 13:12:30,441 [foster.py] => Task 1, Epoch 14/170 => Loss 4.715, Loss_clf 1.402, Loss_fe 1.455, Loss_kd 0.928, Train_accy 62.33, Test_accy 72.03
2024-08-07 13:12:44,033 [foster.py] => Task 1, Epoch 15/170 => Loss 4.678, Loss_clf 1.393, Loss_fe 1.424, Loss_kd 0.929, Train_accy 62.92, Test_accy 69.92
2024-08-07 13:12:56,226 [foster.py] => Task 1, Epoch 16/170 => Loss 4.675, Loss_clf 1.407, Loss_fe 1.417, Loss_kd 0.924, Train_accy 62.41
2024-08-07 13:13:10,191 [foster.py] => Task 1, Epoch 17/170 => Loss 4.629, Loss_clf 1.373, Loss_fe 1.392, Loss_kd 0.931, Train_accy 63.60, Test_accy 71.92
2024-08-07 13:13:24,046 [foster.py] => Task 1, Epoch 18/170 => Loss 4.597, Loss_clf 1.352, Loss_fe 1.382, Loss_kd 0.931, Train_accy 63.78, Test_accy 71.18
2024-08-07 13:13:37,529 [foster.py] => Task 1, Epoch 19/170 => Loss 4.569, Loss_clf 1.348, Loss_fe 1.360, Loss_kd 0.930, Train_accy 64.61, Test_accy 71.12
2024-08-07 13:13:51,088 [foster.py] => Task 1, Epoch 20/170 => Loss 4.515, Loss_clf 1.324, Loss_fe 1.335, Loss_kd 0.927, Train_accy 65.08, Test_accy 71.62
2024-08-07 13:14:03,138 [foster.py] => Task 1, Epoch 21/170 => Loss 4.585, Loss_clf 1.362, Loss_fe 1.365, Loss_kd 0.928, Train_accy 64.03
2024-08-07 13:14:16,692 [foster.py] => Task 1, Epoch 22/170 => Loss 4.487, Loss_clf 1.301, Loss_fe 1.319, Loss_kd 0.932, Train_accy 65.51, Test_accy 71.53
2024-08-07 13:14:30,231 [foster.py] => Task 1, Epoch 23/170 => Loss 4.439, Loss_clf 1.281, Loss_fe 1.301, Loss_kd 0.927, Train_accy 65.38, Test_accy 70.47
2024-08-07 13:14:43,698 [foster.py] => Task 1, Epoch 24/170 => Loss 4.487, Loss_clf 1.313, Loss_fe 1.308, Loss_kd 0.932, Train_accy 65.49, Test_accy 69.58
2024-08-07 13:14:57,318 [foster.py] => Task 1, Epoch 25/170 => Loss 4.445, Loss_clf 1.285, Loss_fe 1.299, Loss_kd 0.929, Train_accy 65.96, Test_accy 71.22
2024-08-07 13:15:09,329 [foster.py] => Task 1, Epoch 26/170 => Loss 4.414, Loss_clf 1.275, Loss_fe 1.279, Loss_kd 0.929, Train_accy 66.03
2024-08-07 13:15:22,831 [foster.py] => Task 1, Epoch 27/170 => Loss 4.417, Loss_clf 1.276, Loss_fe 1.285, Loss_kd 0.927, Train_accy 66.15, Test_accy 71.25
2024-08-07 13:15:36,475 [foster.py] => Task 1, Epoch 28/170 => Loss 4.391, Loss_clf 1.264, Loss_fe 1.266, Loss_kd 0.930, Train_accy 66.55, Test_accy 69.82
2024-08-07 13:15:49,955 [foster.py] => Task 1, Epoch 29/170 => Loss 4.317, Loss_clf 1.229, Loss_fe 1.230, Loss_kd 0.927, Train_accy 67.58, Test_accy 71.65
2024-08-07 13:16:03,378 [foster.py] => Task 1, Epoch 30/170 => Loss 4.334, Loss_clf 1.236, Loss_fe 1.237, Loss_kd 0.929, Train_accy 66.82, Test_accy 73.35
2024-08-07 13:16:15,378 [foster.py] => Task 1, Epoch 31/170 => Loss 4.371, Loss_clf 1.249, Loss_fe 1.258, Loss_kd 0.931, Train_accy 66.92
2024-08-07 13:16:29,007 [foster.py] => Task 1, Epoch 32/170 => Loss 4.313, Loss_clf 1.229, Loss_fe 1.235, Loss_kd 0.923, Train_accy 67.28, Test_accy 70.95
2024-08-07 13:16:42,772 [foster.py] => Task 1, Epoch 33/170 => Loss 4.276, Loss_clf 1.210, Loss_fe 1.205, Loss_kd 0.929, Train_accy 67.88, Test_accy 71.47
2024-08-07 13:16:56,332 [foster.py] => Task 1, Epoch 34/170 => Loss 4.274, Loss_clf 1.205, Loss_fe 1.211, Loss_kd 0.927, Train_accy 67.98, Test_accy 71.92
2024-08-07 13:17:10,020 [foster.py] => Task 1, Epoch 35/170 => Loss 4.211, Loss_clf 1.173, Loss_fe 1.183, Loss_kd 0.926, Train_accy 68.95, Test_accy 71.88
2024-08-07 13:17:21,979 [foster.py] => Task 1, Epoch 36/170 => Loss 4.227, Loss_clf 1.186, Loss_fe 1.180, Loss_kd 0.929, Train_accy 68.65
2024-08-07 13:17:35,719 [foster.py] => Task 1, Epoch 37/170 => Loss 4.207, Loss_clf 1.175, Loss_fe 1.183, Loss_kd 0.923, Train_accy 68.62, Test_accy 73.68
2024-08-07 13:17:49,516 [foster.py] => Task 1, Epoch 38/170 => Loss 4.239, Loss_clf 1.191, Loss_fe 1.178, Loss_kd 0.933, Train_accy 68.67, Test_accy 73.82
2024-08-07 13:18:03,142 [foster.py] => Task 1, Epoch 39/170 => Loss 4.231, Loss_clf 1.185, Loss_fe 1.180, Loss_kd 0.932, Train_accy 68.49, Test_accy 72.45
2024-08-07 13:18:16,624 [foster.py] => Task 1, Epoch 40/170 => Loss 4.184, Loss_clf 1.163, Loss_fe 1.161, Loss_kd 0.929, Train_accy 69.18, Test_accy 69.78
2024-08-07 13:18:28,723 [foster.py] => Task 1, Epoch 41/170 => Loss 4.206, Loss_clf 1.181, Loss_fe 1.161, Loss_kd 0.931, Train_accy 68.99
2024-08-07 13:18:42,176 [foster.py] => Task 1, Epoch 42/170 => Loss 4.163, Loss_clf 1.158, Loss_fe 1.149, Loss_kd 0.927, Train_accy 68.68, Test_accy 72.25
2024-08-07 13:18:55,734 [foster.py] => Task 1, Epoch 43/170 => Loss 4.179, Loss_clf 1.167, Loss_fe 1.152, Loss_kd 0.929, Train_accy 69.18, Test_accy 71.90
2024-08-07 13:19:09,326 [foster.py] => Task 1, Epoch 44/170 => Loss 4.157, Loss_clf 1.150, Loss_fe 1.149, Loss_kd 0.928, Train_accy 69.65, Test_accy 70.35
2024-08-07 13:19:22,952 [foster.py] => Task 1, Epoch 45/170 => Loss 4.134, Loss_clf 1.140, Loss_fe 1.139, Loss_kd 0.926, Train_accy 69.90, Test_accy 76.30
2024-08-07 13:19:34,754 [foster.py] => Task 1, Epoch 46/170 => Loss 4.104, Loss_clf 1.129, Loss_fe 1.116, Loss_kd 0.928, Train_accy 69.75
2024-08-07 13:19:48,329 [foster.py] => Task 1, Epoch 47/170 => Loss 4.107, Loss_clf 1.129, Loss_fe 1.121, Loss_kd 0.927, Train_accy 70.30, Test_accy 75.10
2024-08-07 13:20:01,836 [foster.py] => Task 1, Epoch 48/170 => Loss 4.094, Loss_clf 1.121, Loss_fe 1.120, Loss_kd 0.925, Train_accy 70.28, Test_accy 71.85
2024-08-07 13:20:15,578 [foster.py] => Task 1, Epoch 49/170 => Loss 4.106, Loss_clf 1.126, Loss_fe 1.117, Loss_kd 0.930, Train_accy 70.38, Test_accy 71.50
2024-08-07 13:20:29,444 [foster.py] => Task 1, Epoch 50/170 => Loss 4.071, Loss_clf 1.115, Loss_fe 1.099, Loss_kd 0.927, Train_accy 70.74, Test_accy 73.45
2024-08-07 13:20:41,453 [foster.py] => Task 1, Epoch 51/170 => Loss 4.080, Loss_clf 1.117, Loss_fe 1.100, Loss_kd 0.930, Train_accy 70.24
2024-08-07 13:20:55,199 [foster.py] => Task 1, Epoch 52/170 => Loss 4.046, Loss_clf 1.105, Loss_fe 1.092, Loss_kd 0.923, Train_accy 70.73, Test_accy 73.92
2024-08-07 13:21:08,920 [foster.py] => Task 1, Epoch 53/170 => Loss 4.085, Loss_clf 1.121, Loss_fe 1.097, Loss_kd 0.932, Train_accy 69.99, Test_accy 75.03
2024-08-07 13:21:22,610 [foster.py] => Task 1, Epoch 54/170 => Loss 4.080, Loss_clf 1.121, Loss_fe 1.097, Loss_kd 0.930, Train_accy 70.42, Test_accy 71.30
2024-08-07 13:21:36,129 [foster.py] => Task 1, Epoch 55/170 => Loss 4.045, Loss_clf 1.101, Loss_fe 1.088, Loss_kd 0.927, Train_accy 71.05, Test_accy 73.68
2024-08-07 13:21:48,261 [foster.py] => Task 1, Epoch 56/170 => Loss 4.017, Loss_clf 1.080, Loss_fe 1.072, Loss_kd 0.932, Train_accy 71.31
2024-08-07 13:22:02,163 [foster.py] => Task 1, Epoch 57/170 => Loss 4.026, Loss_clf 1.089, Loss_fe 1.076, Loss_kd 0.929, Train_accy 71.05, Test_accy 74.42
2024-08-07 13:22:15,784 [foster.py] => Task 1, Epoch 58/170 => Loss 4.003, Loss_clf 1.082, Loss_fe 1.060, Loss_kd 0.929, Train_accy 71.62, Test_accy 75.75
2024-08-07 13:22:29,556 [foster.py] => Task 1, Epoch 59/170 => Loss 3.970, Loss_clf 1.066, Loss_fe 1.050, Loss_kd 0.926, Train_accy 71.63, Test_accy 72.80
2024-08-07 13:22:43,045 [foster.py] => Task 1, Epoch 60/170 => Loss 4.022, Loss_clf 1.097, Loss_fe 1.065, Loss_kd 0.928, Train_accy 71.03, Test_accy 70.12
2024-08-07 13:22:55,147 [foster.py] => Task 1, Epoch 61/170 => Loss 3.940, Loss_clf 1.052, Loss_fe 1.034, Loss_kd 0.926, Train_accy 72.13
2024-08-07 13:23:08,753 [foster.py] => Task 1, Epoch 62/170 => Loss 3.992, Loss_clf 1.082, Loss_fe 1.052, Loss_kd 0.928, Train_accy 71.46, Test_accy 73.72
2024-08-07 13:23:22,385 [foster.py] => Task 1, Epoch 63/170 => Loss 3.917, Loss_clf 1.037, Loss_fe 1.027, Loss_kd 0.925, Train_accy 72.43, Test_accy 75.50
2024-08-07 13:23:35,893 [foster.py] => Task 1, Epoch 64/170 => Loss 4.017, Loss_clf 1.094, Loss_fe 1.054, Loss_kd 0.933, Train_accy 71.54, Test_accy 73.78
2024-08-07 13:23:49,292 [foster.py] => Task 1, Epoch 65/170 => Loss 3.896, Loss_clf 1.032, Loss_fe 1.007, Loss_kd 0.927, Train_accy 72.84, Test_accy 76.00
2024-08-07 13:24:01,454 [foster.py] => Task 1, Epoch 66/170 => Loss 3.934, Loss_clf 1.046, Loss_fe 1.025, Loss_kd 0.930, Train_accy 72.47
2024-08-07 13:24:15,015 [foster.py] => Task 1, Epoch 67/170 => Loss 3.892, Loss_clf 1.029, Loss_fe 1.011, Loss_kd 0.925, Train_accy 73.10, Test_accy 74.20
2024-08-07 13:24:28,481 [foster.py] => Task 1, Epoch 68/170 => Loss 3.926, Loss_clf 1.047, Loss_fe 1.015, Loss_kd 0.931, Train_accy 72.42, Test_accy 75.90
2024-08-07 13:24:42,079 [foster.py] => Task 1, Epoch 69/170 => Loss 3.900, Loss_clf 1.031, Loss_fe 1.010, Loss_kd 0.928, Train_accy 72.87, Test_accy 75.90
2024-08-07 13:24:55,512 [foster.py] => Task 1, Epoch 70/170 => Loss 3.880, Loss_clf 1.021, Loss_fe 1.001, Loss_kd 0.928, Train_accy 73.21, Test_accy 74.72
2024-08-07 13:25:07,290 [foster.py] => Task 1, Epoch 71/170 => Loss 3.846, Loss_clf 1.006, Loss_fe 0.989, Loss_kd 0.924, Train_accy 73.43
2024-08-07 13:25:20,784 [foster.py] => Task 1, Epoch 72/170 => Loss 3.838, Loss_clf 1.008, Loss_fe 0.975, Loss_kd 0.926, Train_accy 73.17, Test_accy 76.32
2024-08-07 13:25:34,373 [foster.py] => Task 1, Epoch 73/170 => Loss 3.855, Loss_clf 1.013, Loss_fe 0.984, Loss_kd 0.927, Train_accy 73.41, Test_accy 76.00
2024-08-07 13:25:47,803 [foster.py] => Task 1, Epoch 74/170 => Loss 3.848, Loss_clf 1.007, Loss_fe 0.977, Loss_kd 0.930, Train_accy 73.77, Test_accy 76.75
2024-08-07 13:26:01,474 [foster.py] => Task 1, Epoch 75/170 => Loss 3.802, Loss_clf 0.981, Loss_fe 0.963, Loss_kd 0.928, Train_accy 74.25, Test_accy 75.45
2024-08-07 13:26:13,388 [foster.py] => Task 1, Epoch 76/170 => Loss 3.734, Loss_clf 0.948, Loss_fe 0.928, Loss_kd 0.927, Train_accy 74.77
2024-08-07 13:26:26,846 [foster.py] => Task 1, Epoch 77/170 => Loss 3.850, Loss_clf 1.011, Loss_fe 0.975, Loss_kd 0.930, Train_accy 73.64, Test_accy 75.70
2024-08-07 13:26:40,381 [foster.py] => Task 1, Epoch 78/170 => Loss 3.806, Loss_clf 0.992, Loss_fe 0.958, Loss_kd 0.927, Train_accy 73.68, Test_accy 74.20
2024-08-07 13:26:54,017 [foster.py] => Task 1, Epoch 79/170 => Loss 3.755, Loss_clf 0.956, Loss_fe 0.937, Loss_kd 0.930, Train_accy 74.77, Test_accy 76.97
2024-08-07 13:27:07,635 [foster.py] => Task 1, Epoch 80/170 => Loss 3.752, Loss_clf 0.970, Loss_fe 0.928, Loss_kd 0.925, Train_accy 74.15, Test_accy 75.65
2024-08-07 13:27:19,443 [foster.py] => Task 1, Epoch 81/170 => Loss 3.729, Loss_clf 0.945, Loss_fe 0.923, Loss_kd 0.929, Train_accy 74.78
2024-08-07 13:27:33,191 [foster.py] => Task 1, Epoch 82/170 => Loss 3.720, Loss_clf 0.943, Loss_fe 0.919, Loss_kd 0.928, Train_accy 75.37, Test_accy 77.30
2024-08-07 13:27:46,927 [foster.py] => Task 1, Epoch 83/170 => Loss 3.760, Loss_clf 0.969, Loss_fe 0.926, Loss_kd 0.931, Train_accy 74.32, Test_accy 77.12
2024-08-07 13:28:00,749 [foster.py] => Task 1, Epoch 84/170 => Loss 3.733, Loss_clf 0.952, Loss_fe 0.921, Loss_kd 0.929, Train_accy 74.86, Test_accy 75.97
2024-08-07 13:28:14,441 [foster.py] => Task 1, Epoch 85/170 => Loss 3.696, Loss_clf 0.940, Loss_fe 0.895, Loss_kd 0.929, Train_accy 75.25, Test_accy 76.03
2024-08-07 13:28:26,415 [foster.py] => Task 1, Epoch 86/170 => Loss 3.734, Loss_clf 0.956, Loss_fe 0.921, Loss_kd 0.927, Train_accy 74.79
2024-08-07 13:28:40,161 [foster.py] => Task 1, Epoch 87/170 => Loss 3.664, Loss_clf 0.925, Loss_fe 0.891, Loss_kd 0.923, Train_accy 75.61, Test_accy 75.78
2024-08-07 13:28:53,649 [foster.py] => Task 1, Epoch 88/170 => Loss 3.722, Loss_clf 0.949, Loss_fe 0.912, Loss_kd 0.929, Train_accy 75.32, Test_accy 76.62
2024-08-07 13:29:07,056 [foster.py] => Task 1, Epoch 89/170 => Loss 3.635, Loss_clf 0.907, Loss_fe 0.872, Loss_kd 0.927, Train_accy 76.33, Test_accy 77.03
2024-08-07 13:29:20,499 [foster.py] => Task 1, Epoch 90/170 => Loss 3.666, Loss_clf 0.919, Loss_fe 0.886, Loss_kd 0.929, Train_accy 75.82, Test_accy 75.85
2024-08-07 13:29:32,377 [foster.py] => Task 1, Epoch 91/170 => Loss 3.640, Loss_clf 0.910, Loss_fe 0.875, Loss_kd 0.926, Train_accy 76.24
2024-08-07 13:29:45,708 [foster.py] => Task 1, Epoch 92/170 => Loss 3.640, Loss_clf 0.904, Loss_fe 0.874, Loss_kd 0.929, Train_accy 76.41, Test_accy 78.08
2024-08-07 13:29:59,297 [foster.py] => Task 1, Epoch 93/170 => Loss 3.615, Loss_clf 0.895, Loss_fe 0.862, Loss_kd 0.928, Train_accy 76.14, Test_accy 78.75
2024-08-07 13:30:12,898 [foster.py] => Task 1, Epoch 94/170 => Loss 3.581, Loss_clf 0.879, Loss_fe 0.843, Loss_kd 0.929, Train_accy 76.76, Test_accy 78.40
2024-08-07 13:30:26,571 [foster.py] => Task 1, Epoch 95/170 => Loss 3.572, Loss_clf 0.874, Loss_fe 0.844, Loss_kd 0.925, Train_accy 76.72, Test_accy 77.28
2024-08-07 13:30:38,515 [foster.py] => Task 1, Epoch 96/170 => Loss 3.580, Loss_clf 0.884, Loss_fe 0.840, Loss_kd 0.926, Train_accy 76.81
2024-08-07 13:30:52,098 [foster.py] => Task 1, Epoch 97/170 => Loss 3.510, Loss_clf 0.849, Loss_fe 0.805, Loss_kd 0.926, Train_accy 77.32, Test_accy 76.68
2024-08-07 13:31:05,671 [foster.py] => Task 1, Epoch 98/170 => Loss 3.573, Loss_clf 0.877, Loss_fe 0.838, Loss_kd 0.928, Train_accy 77.04, Test_accy 78.10
2024-08-07 13:31:19,347 [foster.py] => Task 1, Epoch 99/170 => Loss 3.527, Loss_clf 0.852, Loss_fe 0.821, Loss_kd 0.926, Train_accy 78.10, Test_accy 77.62
2024-08-07 13:31:33,261 [foster.py] => Task 1, Epoch 100/170 => Loss 3.525, Loss_clf 0.858, Loss_fe 0.812, Loss_kd 0.926, Train_accy 77.18, Test_accy 77.82
2024-08-07 13:31:45,192 [foster.py] => Task 1, Epoch 101/170 => Loss 3.528, Loss_clf 0.859, Loss_fe 0.811, Loss_kd 0.927, Train_accy 77.19
2024-08-07 13:31:59,123 [foster.py] => Task 1, Epoch 102/170 => Loss 3.458, Loss_clf 0.823, Loss_fe 0.787, Loss_kd 0.922, Train_accy 78.34, Test_accy 78.78
2024-08-07 13:32:12,849 [foster.py] => Task 1, Epoch 103/170 => Loss 3.482, Loss_clf 0.835, Loss_fe 0.794, Loss_kd 0.925, Train_accy 77.94, Test_accy 77.32
2024-08-07 13:32:26,240 [foster.py] => Task 1, Epoch 104/170 => Loss 3.484, Loss_clf 0.832, Loss_fe 0.791, Loss_kd 0.929, Train_accy 78.10, Test_accy 78.38
2024-08-07 13:32:39,739 [foster.py] => Task 1, Epoch 105/170 => Loss 3.463, Loss_clf 0.820, Loss_fe 0.779, Loss_kd 0.930, Train_accy 78.34, Test_accy 79.20
2024-08-07 13:32:51,425 [foster.py] => Task 1, Epoch 106/170 => Loss 3.439, Loss_clf 0.810, Loss_fe 0.774, Loss_kd 0.926, Train_accy 78.78
2024-08-07 13:33:05,331 [foster.py] => Task 1, Epoch 107/170 => Loss 3.428, Loss_clf 0.807, Loss_fe 0.767, Loss_kd 0.926, Train_accy 78.36, Test_accy 78.10
2024-08-07 13:33:19,022 [foster.py] => Task 1, Epoch 108/170 => Loss 3.425, Loss_clf 0.806, Loss_fe 0.761, Loss_kd 0.928, Train_accy 79.31, Test_accy 78.30
2024-08-07 13:33:32,800 [foster.py] => Task 1, Epoch 109/170 => Loss 3.399, Loss_clf 0.794, Loss_fe 0.751, Loss_kd 0.926, Train_accy 78.96, Test_accy 78.80
2024-08-07 13:33:46,304 [foster.py] => Task 1, Epoch 110/170 => Loss 3.353, Loss_clf 0.766, Loss_fe 0.726, Loss_kd 0.929, Train_accy 79.47, Test_accy 79.10
2024-08-07 13:33:58,406 [foster.py] => Task 1, Epoch 111/170 => Loss 3.357, Loss_clf 0.768, Loss_fe 0.728, Loss_kd 0.929, Train_accy 79.92
2024-08-07 13:34:11,972 [foster.py] => Task 1, Epoch 112/170 => Loss 3.390, Loss_clf 0.786, Loss_fe 0.749, Loss_kd 0.927, Train_accy 79.03, Test_accy 77.47
2024-08-07 13:34:25,331 [foster.py] => Task 1, Epoch 113/170 => Loss 3.365, Loss_clf 0.771, Loss_fe 0.733, Loss_kd 0.929, Train_accy 79.62, Test_accy 79.45
2024-08-07 13:34:38,942 [foster.py] => Task 1, Epoch 114/170 => Loss 3.366, Loss_clf 0.777, Loss_fe 0.730, Loss_kd 0.928, Train_accy 79.68, Test_accy 78.55
2024-08-07 13:34:52,422 [foster.py] => Task 1, Epoch 115/170 => Loss 3.284, Loss_clf 0.742, Loss_fe 0.698, Loss_kd 0.921, Train_accy 80.15, Test_accy 78.78
2024-08-07 13:35:04,141 [foster.py] => Task 1, Epoch 116/170 => Loss 3.307, Loss_clf 0.751, Loss_fe 0.702, Loss_kd 0.926, Train_accy 80.41
2024-08-07 13:35:17,609 [foster.py] => Task 1, Epoch 117/170 => Loss 3.297, Loss_clf 0.744, Loss_fe 0.698, Loss_kd 0.926, Train_accy 80.28, Test_accy 79.10
2024-08-07 13:35:31,253 [foster.py] => Task 1, Epoch 118/170 => Loss 3.270, Loss_clf 0.726, Loss_fe 0.686, Loss_kd 0.928, Train_accy 80.67, Test_accy 78.42
2024-08-07 13:35:44,742 [foster.py] => Task 1, Epoch 119/170 => Loss 3.311, Loss_clf 0.750, Loss_fe 0.697, Loss_kd 0.931, Train_accy 80.43, Test_accy 79.80
2024-08-07 13:35:58,251 [foster.py] => Task 1, Epoch 120/170 => Loss 3.282, Loss_clf 0.736, Loss_fe 0.685, Loss_kd 0.929, Train_accy 80.78, Test_accy 78.42
2024-08-07 13:36:10,094 [foster.py] => Task 1, Epoch 121/170 => Loss 3.246, Loss_clf 0.720, Loss_fe 0.668, Loss_kd 0.928, Train_accy 81.12
2024-08-07 13:36:23,593 [foster.py] => Task 1, Epoch 122/170 => Loss 3.199, Loss_clf 0.696, Loss_fe 0.653, Loss_kd 0.924, Train_accy 81.94, Test_accy 80.50
2024-08-07 13:36:36,916 [foster.py] => Task 1, Epoch 123/170 => Loss 3.236, Loss_clf 0.714, Loss_fe 0.662, Loss_kd 0.928, Train_accy 81.15, Test_accy 79.53
2024-08-07 13:36:50,484 [foster.py] => Task 1, Epoch 124/170 => Loss 3.160, Loss_clf 0.682, Loss_fe 0.627, Loss_kd 0.925, Train_accy 82.08, Test_accy 79.60
2024-08-07 13:37:03,925 [foster.py] => Task 1, Epoch 125/170 => Loss 3.165, Loss_clf 0.684, Loss_fe 0.627, Loss_kd 0.926, Train_accy 82.41, Test_accy 80.28
2024-08-07 13:37:15,702 [foster.py] => Task 1, Epoch 126/170 => Loss 3.186, Loss_clf 0.691, Loss_fe 0.639, Loss_kd 0.926, Train_accy 82.02
2024-08-07 13:37:29,035 [foster.py] => Task 1, Epoch 127/170 => Loss 3.148, Loss_clf 0.671, Loss_fe 0.622, Loss_kd 0.926, Train_accy 82.09, Test_accy 79.50
2024-08-07 13:37:42,757 [foster.py] => Task 1, Epoch 128/170 => Loss 3.183, Loss_clf 0.692, Loss_fe 0.629, Loss_kd 0.930, Train_accy 82.04, Test_accy 79.62
2024-08-07 13:37:56,232 [foster.py] => Task 1, Epoch 129/170 => Loss 3.115, Loss_clf 0.649, Loss_fe 0.611, Loss_kd 0.926, Train_accy 83.18, Test_accy 80.30
2024-08-07 13:38:09,789 [foster.py] => Task 1, Epoch 130/170 => Loss 3.121, Loss_clf 0.656, Loss_fe 0.604, Loss_kd 0.929, Train_accy 82.82, Test_accy 80.58
2024-08-07 13:38:21,436 [foster.py] => Task 1, Epoch 131/170 => Loss 3.114, Loss_clf 0.653, Loss_fe 0.600, Loss_kd 0.929, Train_accy 82.86
2024-08-07 13:38:34,990 [foster.py] => Task 1, Epoch 132/170 => Loss 3.108, Loss_clf 0.652, Loss_fe 0.600, Loss_kd 0.927, Train_accy 82.78, Test_accy 80.53
2024-08-07 13:38:48,335 [foster.py] => Task 1, Epoch 133/170 => Loss 3.064, Loss_clf 0.630, Loss_fe 0.582, Loss_kd 0.925, Train_accy 83.72, Test_accy 80.60
2024-08-07 13:39:01,726 [foster.py] => Task 1, Epoch 134/170 => Loss 3.089, Loss_clf 0.639, Loss_fe 0.584, Loss_kd 0.932, Train_accy 83.26, Test_accy 80.68
2024-08-07 13:39:15,587 [foster.py] => Task 1, Epoch 135/170 => Loss 3.067, Loss_clf 0.637, Loss_fe 0.574, Loss_kd 0.926, Train_accy 83.55, Test_accy 80.53
2024-08-07 13:39:27,397 [foster.py] => Task 1, Epoch 136/170 => Loss 3.049, Loss_clf 0.623, Loss_fe 0.570, Loss_kd 0.927, Train_accy 83.77
2024-08-07 13:39:40,874 [foster.py] => Task 1, Epoch 137/170 => Loss 3.068, Loss_clf 0.631, Loss_fe 0.576, Loss_kd 0.930, Train_accy 83.83, Test_accy 81.15
2024-08-07 13:39:54,406 [foster.py] => Task 1, Epoch 138/170 => Loss 3.045, Loss_clf 0.624, Loss_fe 0.566, Loss_kd 0.926, Train_accy 83.76, Test_accy 80.88
2024-08-07 13:40:08,030 [foster.py] => Task 1, Epoch 139/170 => Loss 3.026, Loss_clf 0.618, Loss_fe 0.554, Loss_kd 0.926, Train_accy 83.71, Test_accy 81.72
2024-08-07 13:40:21,554 [foster.py] => Task 1, Epoch 140/170 => Loss 2.994, Loss_clf 0.595, Loss_fe 0.536, Loss_kd 0.930, Train_accy 84.53, Test_accy 80.68
2024-08-07 13:40:33,415 [foster.py] => Task 1, Epoch 141/170 => Loss 3.003, Loss_clf 0.604, Loss_fe 0.543, Loss_kd 0.927, Train_accy 84.49
2024-08-07 13:40:46,948 [foster.py] => Task 1, Epoch 142/170 => Loss 2.970, Loss_clf 0.592, Loss_fe 0.527, Loss_kd 0.925, Train_accy 84.42, Test_accy 81.55
2024-08-07 13:41:00,398 [foster.py] => Task 1, Epoch 143/170 => Loss 2.959, Loss_clf 0.577, Loss_fe 0.522, Loss_kd 0.929, Train_accy 84.78, Test_accy 81.50
2024-08-07 13:41:14,234 [foster.py] => Task 1, Epoch 144/170 => Loss 2.914, Loss_clf 0.559, Loss_fe 0.504, Loss_kd 0.924, Train_accy 85.61, Test_accy 81.12
2024-08-07 13:41:28,123 [foster.py] => Task 1, Epoch 145/170 => Loss 2.973, Loss_clf 0.587, Loss_fe 0.525, Loss_kd 0.929, Train_accy 84.62, Test_accy 82.00
2024-08-07 13:41:40,033 [foster.py] => Task 1, Epoch 146/170 => Loss 2.951, Loss_clf 0.578, Loss_fe 0.519, Loss_kd 0.926, Train_accy 85.15
2024-08-07 13:41:53,442 [foster.py] => Task 1, Epoch 147/170 => Loss 2.929, Loss_clf 0.572, Loss_fe 0.504, Loss_kd 0.925, Train_accy 85.41, Test_accy 81.38
2024-08-07 13:42:06,868 [foster.py] => Task 1, Epoch 148/170 => Loss 2.901, Loss_clf 0.552, Loss_fe 0.495, Loss_kd 0.926, Train_accy 85.42, Test_accy 82.00
2024-08-07 13:42:20,657 [foster.py] => Task 1, Epoch 149/170 => Loss 2.933, Loss_clf 0.570, Loss_fe 0.503, Loss_kd 0.929, Train_accy 85.60, Test_accy 81.88
2024-08-07 13:42:34,174 [foster.py] => Task 1, Epoch 150/170 => Loss 2.889, Loss_clf 0.545, Loss_fe 0.492, Loss_kd 0.924, Train_accy 85.94, Test_accy 82.22
2024-08-07 13:42:46,260 [foster.py] => Task 1, Epoch 151/170 => Loss 2.883, Loss_clf 0.541, Loss_fe 0.485, Loss_kd 0.927, Train_accy 85.59
2024-08-07 13:42:59,684 [foster.py] => Task 1, Epoch 152/170 => Loss 2.901, Loss_clf 0.553, Loss_fe 0.484, Loss_kd 0.930, Train_accy 85.74, Test_accy 81.92
2024-08-07 13:43:13,060 [foster.py] => Task 1, Epoch 153/170 => Loss 2.873, Loss_clf 0.539, Loss_fe 0.478, Loss_kd 0.926, Train_accy 86.02, Test_accy 81.60
2024-08-07 13:43:26,627 [foster.py] => Task 1, Epoch 154/170 => Loss 2.867, Loss_clf 0.536, Loss_fe 0.475, Loss_kd 0.927, Train_accy 86.26, Test_accy 81.80
2024-08-07 13:43:40,090 [foster.py] => Task 1, Epoch 155/170 => Loss 2.839, Loss_clf 0.523, Loss_fe 0.466, Loss_kd 0.924, Train_accy 86.42, Test_accy 81.72
2024-08-07 13:43:51,870 [foster.py] => Task 1, Epoch 156/170 => Loss 2.854, Loss_clf 0.532, Loss_fe 0.467, Loss_kd 0.927, Train_accy 86.37
2024-08-07 13:44:05,659 [foster.py] => Task 1, Epoch 157/170 => Loss 2.862, Loss_clf 0.539, Loss_fe 0.467, Loss_kd 0.927, Train_accy 86.18, Test_accy 81.75
2024-08-07 13:44:19,140 [foster.py] => Task 1, Epoch 158/170 => Loss 2.844, Loss_clf 0.533, Loss_fe 0.461, Loss_kd 0.924, Train_accy 86.20, Test_accy 81.78
2024-08-07 13:44:32,441 [foster.py] => Task 1, Epoch 159/170 => Loss 2.826, Loss_clf 0.515, Loss_fe 0.455, Loss_kd 0.927, Train_accy 86.64, Test_accy 81.92
2024-08-07 13:44:45,921 [foster.py] => Task 1, Epoch 160/170 => Loss 2.838, Loss_clf 0.520, Loss_fe 0.461, Loss_kd 0.927, Train_accy 86.73, Test_accy 81.92
2024-08-07 13:44:57,712 [foster.py] => Task 1, Epoch 161/170 => Loss 2.843, Loss_clf 0.525, Loss_fe 0.456, Loss_kd 0.930, Train_accy 86.76
2024-08-07 13:45:11,079 [foster.py] => Task 1, Epoch 162/170 => Loss 2.835, Loss_clf 0.517, Loss_fe 0.460, Loss_kd 0.928, Train_accy 87.04, Test_accy 82.30
2024-08-07 13:45:24,572 [foster.py] => Task 1, Epoch 163/170 => Loss 2.815, Loss_clf 0.512, Loss_fe 0.448, Loss_kd 0.926, Train_accy 86.85, Test_accy 81.98
2024-08-07 13:45:37,968 [foster.py] => Task 1, Epoch 164/170 => Loss 2.845, Loss_clf 0.527, Loss_fe 0.463, Loss_kd 0.926, Train_accy 86.22, Test_accy 82.25
2024-08-07 13:45:51,380 [foster.py] => Task 1, Epoch 165/170 => Loss 2.791, Loss_clf 0.503, Loss_fe 0.444, Loss_kd 0.921, Train_accy 86.85, Test_accy 82.12
2024-08-07 13:46:03,454 [foster.py] => Task 1, Epoch 166/170 => Loss 2.828, Loss_clf 0.517, Loss_fe 0.454, Loss_kd 0.927, Train_accy 86.66
2024-08-07 13:46:17,109 [foster.py] => Task 1, Epoch 167/170 => Loss 2.820, Loss_clf 0.514, Loss_fe 0.448, Loss_kd 0.928, Train_accy 86.60, Test_accy 82.32
2024-08-07 13:46:30,869 [foster.py] => Task 1, Epoch 168/170 => Loss 2.809, Loss_clf 0.508, Loss_fe 0.447, Loss_kd 0.926, Train_accy 86.68, Test_accy 82.28
2024-08-07 13:46:44,330 [foster.py] => Task 1, Epoch 169/170 => Loss 2.836, Loss_clf 0.519, Loss_fe 0.455, Loss_kd 0.930, Train_accy 86.44, Test_accy 82.20
2024-08-07 13:46:58,053 [foster.py] => Task 1, Epoch 170/170 => Loss 2.834, Loss_clf 0.520, Loss_fe 0.456, Loss_kd 0.928, Train_accy 86.58, Test_accy 82.28
2024-08-07 13:46:58,057 [foster.py] => do not weight align teacher!
2024-08-07 13:46:58,058 [foster.py] => per cls weights : [1.05808572 1.05808572 1.05808572 1.05808572 1.05808572 1.05808572
 1.05808572 1.05808572 1.05808572 1.05808572 1.05808572 1.05808572
 1.05808572 1.05808572 1.05808572 1.05808572 1.05808572 1.05808572
 1.05808572 1.05808572 0.94191428 0.94191428 0.94191428 0.94191428
 0.94191428 0.94191428 0.94191428 0.94191428 0.94191428 0.94191428
 0.94191428 0.94191428 0.94191428 0.94191428 0.94191428 0.94191428
 0.94191428 0.94191428 0.94191428 0.94191428]
2024-08-07 13:47:17,056 [foster.py] => SNet: Task 1, Epoch 1/130 => Loss 25.326,  Loss1 0.633, Train_accy 32.47, Test_accy 50.90
2024-08-07 13:47:33,859 [foster.py] => SNet: Task 1, Epoch 2/130 => Loss 25.050,  Loss1 0.631, Train_accy 50.95
2024-08-07 13:47:50,684 [foster.py] => SNet: Task 1, Epoch 3/130 => Loss 24.979,  Loss1 0.631, Train_accy 55.29
2024-08-07 13:48:08,002 [foster.py] => SNet: Task 1, Epoch 4/130 => Loss 24.951,  Loss1 0.631, Train_accy 57.69
2024-08-07 13:48:24,703 [foster.py] => SNet: Task 1, Epoch 5/130 => Loss 24.926,  Loss1 0.631, Train_accy 60.04
2024-08-07 13:48:43,588 [foster.py] => SNet: Task 1, Epoch 6/130 => Loss 24.896,  Loss1 0.632, Train_accy 61.34, Test_accy 64.20
2024-08-07 13:49:00,544 [foster.py] => SNet: Task 1, Epoch 7/130 => Loss 24.880,  Loss1 0.632, Train_accy 62.78
2024-08-07 13:49:17,202 [foster.py] => SNet: Task 1, Epoch 8/130 => Loss 24.866,  Loss1 0.632, Train_accy 63.53
2024-08-07 13:49:33,910 [foster.py] => SNet: Task 1, Epoch 9/130 => Loss 24.860,  Loss1 0.632, Train_accy 65.53
2024-08-07 13:49:50,646 [foster.py] => SNet: Task 1, Epoch 10/130 => Loss 24.850,  Loss1 0.632, Train_accy 65.18
2024-08-07 13:50:08,951 [foster.py] => SNet: Task 1, Epoch 11/130 => Loss 24.832,  Loss1 0.632, Train_accy 66.23, Test_accy 69.03
2024-08-07 13:50:25,904 [foster.py] => SNet: Task 1, Epoch 12/130 => Loss 24.827,  Loss1 0.632, Train_accy 67.03
2024-08-07 13:50:42,631 [foster.py] => SNet: Task 1, Epoch 13/130 => Loss 24.810,  Loss1 0.632, Train_accy 68.42
2024-08-07 13:50:59,404 [foster.py] => SNet: Task 1, Epoch 14/130 => Loss 24.806,  Loss1 0.632, Train_accy 68.07
2024-08-07 13:51:16,122 [foster.py] => SNet: Task 1, Epoch 15/130 => Loss 24.819,  Loss1 0.632, Train_accy 68.66
2024-08-07 13:51:34,556 [foster.py] => SNet: Task 1, Epoch 16/130 => Loss 24.794,  Loss1 0.632, Train_accy 69.02, Test_accy 72.28
2024-08-07 13:51:51,374 [foster.py] => SNet: Task 1, Epoch 17/130 => Loss 24.801,  Loss1 0.632, Train_accy 70.31
2024-08-07 13:52:08,106 [foster.py] => SNet: Task 1, Epoch 18/130 => Loss 24.790,  Loss1 0.632, Train_accy 70.21
2024-08-07 13:52:24,803 [foster.py] => SNet: Task 1, Epoch 19/130 => Loss 24.761,  Loss1 0.632, Train_accy 70.67
2024-08-07 13:52:41,393 [foster.py] => SNet: Task 1, Epoch 20/130 => Loss 24.769,  Loss1 0.632, Train_accy 71.22
2024-08-07 13:52:59,749 [foster.py] => SNet: Task 1, Epoch 21/130 => Loss 24.767,  Loss1 0.632, Train_accy 71.63, Test_accy 72.12
2024-08-07 13:53:16,614 [foster.py] => SNet: Task 1, Epoch 22/130 => Loss 24.758,  Loss1 0.632, Train_accy 71.63
2024-08-07 13:53:33,473 [foster.py] => SNet: Task 1, Epoch 23/130 => Loss 24.760,  Loss1 0.632, Train_accy 71.95
2024-08-07 13:53:50,244 [foster.py] => SNet: Task 1, Epoch 24/130 => Loss 24.756,  Loss1 0.632, Train_accy 72.65
2024-08-07 13:54:07,350 [foster.py] => SNet: Task 1, Epoch 25/130 => Loss 24.754,  Loss1 0.632, Train_accy 72.56
2024-08-07 13:54:25,657 [foster.py] => SNet: Task 1, Epoch 26/130 => Loss 24.764,  Loss1 0.632, Train_accy 73.08, Test_accy 72.53
2024-08-07 13:54:42,497 [foster.py] => SNet: Task 1, Epoch 27/130 => Loss 24.740,  Loss1 0.632, Train_accy 73.27
2024-08-07 13:54:59,247 [foster.py] => SNet: Task 1, Epoch 28/130 => Loss 24.745,  Loss1 0.632, Train_accy 73.01
2024-08-07 13:55:16,382 [foster.py] => SNet: Task 1, Epoch 29/130 => Loss 24.738,  Loss1 0.632, Train_accy 73.44
2024-08-07 13:55:33,287 [foster.py] => SNet: Task 1, Epoch 30/130 => Loss 24.739,  Loss1 0.632, Train_accy 73.44
2024-08-07 13:55:51,484 [foster.py] => SNet: Task 1, Epoch 31/130 => Loss 24.744,  Loss1 0.632, Train_accy 74.14, Test_accy 75.53
2024-08-07 13:56:08,578 [foster.py] => SNet: Task 1, Epoch 32/130 => Loss 24.731,  Loss1 0.632, Train_accy 74.39
2024-08-07 13:56:25,268 [foster.py] => SNet: Task 1, Epoch 33/130 => Loss 24.728,  Loss1 0.632, Train_accy 74.68
2024-08-07 13:56:42,083 [foster.py] => SNet: Task 1, Epoch 34/130 => Loss 24.726,  Loss1 0.632, Train_accy 75.09
2024-08-07 13:56:58,862 [foster.py] => SNet: Task 1, Epoch 35/130 => Loss 24.729,  Loss1 0.632, Train_accy 74.85
2024-08-07 13:57:17,327 [foster.py] => SNet: Task 1, Epoch 36/130 => Loss 24.720,  Loss1 0.632, Train_accy 75.32, Test_accy 74.90
2024-08-07 13:57:34,148 [foster.py] => SNet: Task 1, Epoch 37/130 => Loss 24.718,  Loss1 0.632, Train_accy 75.48
2024-08-07 13:57:50,955 [foster.py] => SNet: Task 1, Epoch 38/130 => Loss 24.722,  Loss1 0.632, Train_accy 75.42
2024-08-07 13:58:07,779 [foster.py] => SNet: Task 1, Epoch 39/130 => Loss 24.716,  Loss1 0.632, Train_accy 76.38
2024-08-07 13:58:24,778 [foster.py] => SNet: Task 1, Epoch 40/130 => Loss 24.712,  Loss1 0.632, Train_accy 75.82
2024-08-07 13:58:42,903 [foster.py] => SNet: Task 1, Epoch 41/130 => Loss 24.712,  Loss1 0.632, Train_accy 75.97, Test_accy 76.22
2024-08-07 13:59:00,047 [foster.py] => SNet: Task 1, Epoch 42/130 => Loss 24.704,  Loss1 0.632, Train_accy 76.18
2024-08-07 13:59:17,034 [foster.py] => SNet: Task 1, Epoch 43/130 => Loss 24.714,  Loss1 0.632, Train_accy 76.92
2024-08-07 13:59:33,675 [foster.py] => SNet: Task 1, Epoch 44/130 => Loss 24.701,  Loss1 0.632, Train_accy 76.26
2024-08-07 13:59:50,686 [foster.py] => SNet: Task 1, Epoch 45/130 => Loss 24.709,  Loss1 0.632, Train_accy 76.71
2024-08-07 14:00:09,316 [foster.py] => SNet: Task 1, Epoch 46/130 => Loss 24.696,  Loss1 0.632, Train_accy 77.03, Test_accy 76.72
2024-08-07 14:00:26,061 [foster.py] => SNet: Task 1, Epoch 47/130 => Loss 24.697,  Loss1 0.632, Train_accy 77.41
2024-08-07 14:00:42,816 [foster.py] => SNet: Task 1, Epoch 48/130 => Loss 24.695,  Loss1 0.632, Train_accy 77.61
2024-08-07 14:00:59,531 [foster.py] => SNet: Task 1, Epoch 49/130 => Loss 24.685,  Loss1 0.632, Train_accy 77.56
2024-08-07 14:01:16,189 [foster.py] => SNet: Task 1, Epoch 50/130 => Loss 24.695,  Loss1 0.632, Train_accy 77.16
2024-08-07 14:01:34,296 [foster.py] => SNet: Task 1, Epoch 51/130 => Loss 24.700,  Loss1 0.632, Train_accy 77.59, Test_accy 77.03
2024-08-07 14:01:51,219 [foster.py] => SNet: Task 1, Epoch 52/130 => Loss 24.688,  Loss1 0.632, Train_accy 78.53
2024-08-07 14:02:07,890 [foster.py] => SNet: Task 1, Epoch 53/130 => Loss 24.684,  Loss1 0.632, Train_accy 78.34
2024-08-07 14:02:24,859 [foster.py] => SNet: Task 1, Epoch 54/130 => Loss 24.679,  Loss1 0.632, Train_accy 77.76
2024-08-07 14:02:41,810 [foster.py] => SNet: Task 1, Epoch 55/130 => Loss 24.692,  Loss1 0.632, Train_accy 78.02
2024-08-07 14:02:59,981 [foster.py] => SNet: Task 1, Epoch 56/130 => Loss 24.689,  Loss1 0.632, Train_accy 78.57, Test_accy 77.25
2024-08-07 14:03:16,745 [foster.py] => SNet: Task 1, Epoch 57/130 => Loss 24.678,  Loss1 0.632, Train_accy 78.53
2024-08-07 14:03:33,449 [foster.py] => SNet: Task 1, Epoch 58/130 => Loss 24.682,  Loss1 0.632, Train_accy 78.67
2024-08-07 14:03:50,474 [foster.py] => SNet: Task 1, Epoch 59/130 => Loss 24.674,  Loss1 0.632, Train_accy 78.62
2024-08-07 14:04:07,507 [foster.py] => SNet: Task 1, Epoch 60/130 => Loss 24.687,  Loss1 0.632, Train_accy 78.68
2024-08-07 14:04:25,882 [foster.py] => SNet: Task 1, Epoch 61/130 => Loss 24.692,  Loss1 0.632, Train_accy 78.43, Test_accy 77.50
2024-08-07 14:04:42,854 [foster.py] => SNet: Task 1, Epoch 62/130 => Loss 24.670,  Loss1 0.632, Train_accy 78.98
2024-08-07 14:04:59,629 [foster.py] => SNet: Task 1, Epoch 63/130 => Loss 24.678,  Loss1 0.632, Train_accy 79.02
2024-08-07 14:05:16,676 [foster.py] => SNet: Task 1, Epoch 64/130 => Loss 24.681,  Loss1 0.632, Train_accy 78.72
2024-08-07 14:05:33,350 [foster.py] => SNet: Task 1, Epoch 65/130 => Loss 24.672,  Loss1 0.632, Train_accy 79.28
2024-08-07 14:05:51,552 [foster.py] => SNet: Task 1, Epoch 66/130 => Loss 24.672,  Loss1 0.632, Train_accy 79.75, Test_accy 79.08
2024-08-07 14:06:08,310 [foster.py] => SNet: Task 1, Epoch 67/130 => Loss 24.674,  Loss1 0.632, Train_accy 79.82
2024-08-07 14:06:25,376 [foster.py] => SNet: Task 1, Epoch 68/130 => Loss 24.667,  Loss1 0.632, Train_accy 80.18
2024-08-07 14:06:42,262 [foster.py] => SNet: Task 1, Epoch 69/130 => Loss 24.667,  Loss1 0.632, Train_accy 79.80
2024-08-07 14:06:59,167 [foster.py] => SNet: Task 1, Epoch 70/130 => Loss 24.668,  Loss1 0.632, Train_accy 79.90
2024-08-07 14:07:17,255 [foster.py] => SNet: Task 1, Epoch 71/130 => Loss 24.669,  Loss1 0.632, Train_accy 79.54, Test_accy 79.32
2024-08-07 14:07:33,955 [foster.py] => SNet: Task 1, Epoch 72/130 => Loss 24.666,  Loss1 0.632, Train_accy 80.10
2024-08-07 14:07:50,777 [foster.py] => SNet: Task 1, Epoch 73/130 => Loss 24.657,  Loss1 0.632, Train_accy 79.71
2024-08-07 14:08:07,836 [foster.py] => SNet: Task 1, Epoch 74/130 => Loss 24.660,  Loss1 0.632, Train_accy 80.47
2024-08-07 14:08:24,700 [foster.py] => SNet: Task 1, Epoch 75/130 => Loss 24.664,  Loss1 0.632, Train_accy 80.28
2024-08-07 14:08:42,804 [foster.py] => SNet: Task 1, Epoch 76/130 => Loss 24.665,  Loss1 0.632, Train_accy 80.16, Test_accy 79.47
2024-08-07 14:08:59,630 [foster.py] => SNet: Task 1, Epoch 77/130 => Loss 24.676,  Loss1 0.632, Train_accy 80.41
2024-08-07 14:09:16,635 [foster.py] => SNet: Task 1, Epoch 78/130 => Loss 24.652,  Loss1 0.632, Train_accy 80.44
2024-08-07 14:09:33,243 [foster.py] => SNet: Task 1, Epoch 79/130 => Loss 24.655,  Loss1 0.632, Train_accy 80.63
2024-08-07 14:09:50,089 [foster.py] => SNet: Task 1, Epoch 80/130 => Loss 24.653,  Loss1 0.632, Train_accy 80.18
2024-08-07 14:10:08,577 [foster.py] => SNet: Task 1, Epoch 81/130 => Loss 24.662,  Loss1 0.632, Train_accy 80.39, Test_accy 79.68
2024-08-07 14:10:25,406 [foster.py] => SNet: Task 1, Epoch 82/130 => Loss 24.659,  Loss1 0.632, Train_accy 81.01
2024-08-07 14:10:42,577 [foster.py] => SNet: Task 1, Epoch 83/130 => Loss 24.641,  Loss1 0.632, Train_accy 80.91
2024-08-07 14:10:59,521 [foster.py] => SNet: Task 1, Epoch 84/130 => Loss 24.661,  Loss1 0.632, Train_accy 80.69
2024-08-07 14:11:16,211 [foster.py] => SNet: Task 1, Epoch 85/130 => Loss 24.655,  Loss1 0.632, Train_accy 80.67
2024-08-07 14:11:35,116 [foster.py] => SNet: Task 1, Epoch 86/130 => Loss 24.664,  Loss1 0.632, Train_accy 80.41, Test_accy 79.18
2024-08-07 14:11:51,817 [foster.py] => SNet: Task 1, Epoch 87/130 => Loss 24.649,  Loss1 0.632, Train_accy 80.63
2024-08-07 14:12:08,843 [foster.py] => SNet: Task 1, Epoch 88/130 => Loss 24.669,  Loss1 0.632, Train_accy 81.04
2024-08-07 14:12:25,741 [foster.py] => SNet: Task 1, Epoch 89/130 => Loss 24.653,  Loss1 0.632, Train_accy 80.96
2024-08-07 14:12:42,498 [foster.py] => SNet: Task 1, Epoch 90/130 => Loss 24.659,  Loss1 0.632, Train_accy 80.91
2024-08-07 14:13:00,867 [foster.py] => SNet: Task 1, Epoch 91/130 => Loss 24.656,  Loss1 0.632, Train_accy 81.38, Test_accy 79.62
2024-08-07 14:13:17,664 [foster.py] => SNet: Task 1, Epoch 92/130 => Loss 24.659,  Loss1 0.632, Train_accy 80.88
2024-08-07 14:13:34,401 [foster.py] => SNet: Task 1, Epoch 93/130 => Loss 24.649,  Loss1 0.632, Train_accy 81.47
2024-08-07 14:13:51,439 [foster.py] => SNet: Task 1, Epoch 94/130 => Loss 24.661,  Loss1 0.632, Train_accy 80.39
2024-08-07 14:14:08,538 [foster.py] => SNet: Task 1, Epoch 95/130 => Loss 24.658,  Loss1 0.632, Train_accy 81.27
2024-08-07 14:14:26,828 [foster.py] => SNet: Task 1, Epoch 96/130 => Loss 24.657,  Loss1 0.632, Train_accy 81.39, Test_accy 79.38
2024-08-07 14:14:43,629 [foster.py] => SNet: Task 1, Epoch 97/130 => Loss 24.646,  Loss1 0.632, Train_accy 81.39
2024-08-07 14:15:00,579 [foster.py] => SNet: Task 1, Epoch 98/130 => Loss 24.643,  Loss1 0.632, Train_accy 81.71
2024-08-07 14:15:17,752 [foster.py] => SNet: Task 1, Epoch 99/130 => Loss 24.653,  Loss1 0.632, Train_accy 81.59
2024-08-07 14:15:34,554 [foster.py] => SNet: Task 1, Epoch 100/130 => Loss 24.651,  Loss1 0.632, Train_accy 81.32
2024-08-07 14:15:53,000 [foster.py] => SNet: Task 1, Epoch 101/130 => Loss 24.645,  Loss1 0.632, Train_accy 81.96, Test_accy 79.45
2024-08-07 14:16:09,956 [foster.py] => SNet: Task 1, Epoch 102/130 => Loss 24.650,  Loss1 0.632, Train_accy 81.74
2024-08-07 14:16:27,006 [foster.py] => SNet: Task 1, Epoch 103/130 => Loss 24.660,  Loss1 0.632, Train_accy 80.97
2024-08-07 14:16:44,214 [foster.py] => SNet: Task 1, Epoch 104/130 => Loss 24.642,  Loss1 0.632, Train_accy 82.07
2024-08-07 14:17:01,050 [foster.py] => SNet: Task 1, Epoch 105/130 => Loss 24.652,  Loss1 0.632, Train_accy 81.41
2024-08-07 14:17:19,193 [foster.py] => SNet: Task 1, Epoch 106/130 => Loss 24.645,  Loss1 0.633, Train_accy 81.84, Test_accy 80.05
2024-08-07 14:17:35,971 [foster.py] => SNet: Task 1, Epoch 107/130 => Loss 24.646,  Loss1 0.632, Train_accy 82.25
2024-08-07 14:17:53,007 [foster.py] => SNet: Task 1, Epoch 108/130 => Loss 24.642,  Loss1 0.632, Train_accy 81.92
2024-08-07 14:18:09,992 [foster.py] => SNet: Task 1, Epoch 109/130 => Loss 24.643,  Loss1 0.632, Train_accy 81.83
2024-08-07 14:18:26,714 [foster.py] => SNet: Task 1, Epoch 110/130 => Loss 24.645,  Loss1 0.632, Train_accy 81.75
2024-08-07 14:18:44,940 [foster.py] => SNet: Task 1, Epoch 111/130 => Loss 24.652,  Loss1 0.632, Train_accy 81.63, Test_accy 79.88
2024-08-07 14:19:01,937 [foster.py] => SNet: Task 1, Epoch 112/130 => Loss 24.631,  Loss1 0.632, Train_accy 81.64
2024-08-07 14:19:18,925 [foster.py] => SNet: Task 1, Epoch 113/130 => Loss 24.643,  Loss1 0.632, Train_accy 82.05
2024-08-07 14:19:35,838 [foster.py] => SNet: Task 1, Epoch 114/130 => Loss 24.633,  Loss1 0.632, Train_accy 82.43
2024-08-07 14:19:52,991 [foster.py] => SNet: Task 1, Epoch 115/130 => Loss 24.640,  Loss1 0.632, Train_accy 81.98
2024-08-07 14:20:11,585 [foster.py] => SNet: Task 1, Epoch 116/130 => Loss 24.642,  Loss1 0.632, Train_accy 82.01, Test_accy 79.78
2024-08-07 14:20:28,356 [foster.py] => SNet: Task 1, Epoch 117/130 => Loss 24.651,  Loss1 0.632, Train_accy 81.48
2024-08-07 14:20:45,073 [foster.py] => SNet: Task 1, Epoch 118/130 => Loss 24.641,  Loss1 0.632, Train_accy 82.28
2024-08-07 14:21:02,028 [foster.py] => SNet: Task 1, Epoch 119/130 => Loss 24.658,  Loss1 0.632, Train_accy 82.02
2024-08-07 14:21:18,769 [foster.py] => SNet: Task 1, Epoch 120/130 => Loss 24.647,  Loss1 0.632, Train_accy 81.85
2024-08-07 14:21:37,215 [foster.py] => SNet: Task 1, Epoch 121/130 => Loss 24.659,  Loss1 0.632, Train_accy 81.65, Test_accy 79.82
2024-08-07 14:21:53,945 [foster.py] => SNet: Task 1, Epoch 122/130 => Loss 24.652,  Loss1 0.632, Train_accy 81.88
2024-08-07 14:22:10,829 [foster.py] => SNet: Task 1, Epoch 123/130 => Loss 24.642,  Loss1 0.632, Train_accy 81.95
2024-08-07 14:22:27,649 [foster.py] => SNet: Task 1, Epoch 124/130 => Loss 24.630,  Loss1 0.632, Train_accy 82.11
2024-08-07 14:22:44,370 [foster.py] => SNet: Task 1, Epoch 125/130 => Loss 24.650,  Loss1 0.632, Train_accy 82.48
2024-08-07 14:23:02,664 [foster.py] => SNet: Task 1, Epoch 126/130 => Loss 24.659,  Loss1 0.632, Train_accy 81.42, Test_accy 79.70
2024-08-07 14:23:19,352 [foster.py] => SNet: Task 1, Epoch 127/130 => Loss 24.648,  Loss1 0.632, Train_accy 82.25
2024-08-07 14:23:36,243 [foster.py] => SNet: Task 1, Epoch 128/130 => Loss 24.644,  Loss1 0.632, Train_accy 82.02
2024-08-07 14:23:53,251 [foster.py] => SNet: Task 1, Epoch 129/130 => Loss 24.642,  Loss1 0.632, Train_accy 81.67
2024-08-07 14:24:10,043 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 24.651,  Loss1 0.632, Train_accy 81.79
2024-08-07 14:24:10,043 [foster.py] => do not weight align student!
2024-08-07 14:24:11,558 [foster.py] => darknet eval: 
2024-08-07 14:24:11,558 [foster.py] => CNN top1 curve: 79.95
2024-08-07 14:24:11,558 [foster.py] => CNN top5 curve: 96.42
2024-08-07 14:24:11,559 [foster.py] => CNN top1 平均值: 79.95
2024-08-07 14:24:11,561 [foster.py] => timees : 4488.589014530182
2024-08-07 14:24:11,562 [base.py] => Reducing exemplars...(50 per classes)
2024-08-07 14:24:18,207 [base.py] => Constructing exemplars...(50 per classes)
2024-08-07 14:24:41,191 [foster.py] => Exemplar size: 2000
2024-08-07 14:24:41,191 [trainer.py] => CNN: {'total': 82.28, '00-09': 83.4, '10-19': 73.4, '20-29': 87.5, '30-39': 84.8, 'old': 78.4, 'new': 86.15}
2024-08-07 14:24:41,192 [trainer.py] => NME: {'total': 82.42, '00-09': 84.9, '10-19': 75.8, '20-29': 85.8, '30-39': 83.2, 'old': 80.35, 'new': 84.5}
2024-08-07 14:24:41,192 [trainer.py] => CNN top1 curve: [87.15, 82.28]
2024-08-07 14:24:41,192 [trainer.py] => CNN top5 curve: [98.3, 96.45]
2024-08-07 14:24:41,193 [trainer.py] => NME top1 curve: [87.2, 82.42]
2024-08-07 14:24:41,193 [trainer.py] => NME top5 curve: [98.45, 96.6]

2024-08-07 14:24:41,193 [trainer.py] => CNN top1 平均值: 84.72
2024-08-07 14:24:41,196 [trainer.py] => All params: 1291608
2024-08-07 14:24:41,199 [trainer.py] => Trainable params: 649034
2024-08-07 14:24:41,319 [foster.py] => Learning on 40-60
2024-08-07 14:24:41,323 [foster.py] => All params: 1296788
2024-08-07 14:24:41,326 [foster.py] => Trainable params: 652914
2024-08-07 14:24:41,432 [foster.py] => per cls weights : [1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858 1.07487858
 1.07487858 1.07487858 1.07487858 1.07487858 0.85024284 0.85024284
 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284
 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284
 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284 0.85024284]
2024-08-07 14:24:53,165 [foster.py] => Task 2, Epoch 1/170 => Loss 6.681, Loss_clf 2.273, Loss_fe 2.085, Loss_kd 1.547, Train_accy 45.12
2024-08-07 14:25:07,030 [foster.py] => Task 2, Epoch 2/170 => Loss 5.707, Loss_clf 1.704, Loss_fe 1.698, Loss_kd 1.535, Train_accy 52.98, Test_accy 65.32
2024-08-07 14:25:20,826 [foster.py] => Task 2, Epoch 3/170 => Loss 5.503, Loss_clf 1.598, Loss_fe 1.606, Loss_kd 1.531, Train_accy 55.85, Test_accy 67.90
2024-08-07 14:25:34,709 [foster.py] => Task 2, Epoch 4/170 => Loss 5.406, Loss_clf 1.552, Loss_fe 1.545, Loss_kd 1.537, Train_accy 57.23, Test_accy 63.35
2024-08-07 14:25:48,636 [foster.py] => Task 2, Epoch 5/170 => Loss 5.371, Loss_clf 1.554, Loss_fe 1.516, Loss_kd 1.532, Train_accy 57.31, Test_accy 67.70
2024-08-07 14:26:00,531 [foster.py] => Task 2, Epoch 6/170 => Loss 5.296, Loss_clf 1.530, Loss_fe 1.459, Loss_kd 1.536, Train_accy 58.32
2024-08-07 14:26:14,265 [foster.py] => Task 2, Epoch 7/170 => Loss 5.256, Loss_clf 1.516, Loss_fe 1.439, Loss_kd 1.533, Train_accy 58.49, Test_accy 66.38
2024-08-07 14:26:28,328 [foster.py] => Task 2, Epoch 8/170 => Loss 5.209, Loss_clf 1.477, Loss_fe 1.426, Loss_kd 1.535, Train_accy 59.47, Test_accy 69.47
2024-08-07 14:26:42,160 [foster.py] => Task 2, Epoch 9/170 => Loss 5.145, Loss_clf 1.476, Loss_fe 1.369, Loss_kd 1.532, Train_accy 60.03, Test_accy 68.75
2024-08-07 14:26:56,183 [foster.py] => Task 2, Epoch 10/170 => Loss 5.108, Loss_clf 1.447, Loss_fe 1.360, Loss_kd 1.532, Train_accy 60.33, Test_accy 69.30
2024-08-07 14:27:08,040 [foster.py] => Task 2, Epoch 11/170 => Loss 5.025, Loss_clf 1.398, Loss_fe 1.333, Loss_kd 1.528, Train_accy 61.00
2024-08-07 14:27:21,952 [foster.py] => Task 2, Epoch 12/170 => Loss 5.060, Loss_clf 1.418, Loss_fe 1.345, Loss_kd 1.530, Train_accy 60.82, Test_accy 68.42
2024-08-07 14:27:35,746 [foster.py] => Task 2, Epoch 13/170 => Loss 5.011, Loss_clf 1.395, Loss_fe 1.310, Loss_kd 1.535, Train_accy 61.22, Test_accy 69.57
2024-08-07 14:27:49,559 [foster.py] => Task 2, Epoch 14/170 => Loss 4.999, Loss_clf 1.409, Loss_fe 1.294, Loss_kd 1.528, Train_accy 61.56, Test_accy 66.75
2024-08-07 14:28:03,360 [foster.py] => Task 2, Epoch 15/170 => Loss 4.986, Loss_clf 1.381, Loss_fe 1.294, Loss_kd 1.539, Train_accy 61.76, Test_accy 70.12
2024-08-07 14:28:15,061 [foster.py] => Task 2, Epoch 16/170 => Loss 4.981, Loss_clf 1.380, Loss_fe 1.290, Loss_kd 1.538, Train_accy 62.02
2024-08-07 14:28:28,900 [foster.py] => Task 2, Epoch 17/170 => Loss 4.934, Loss_clf 1.357, Loss_fe 1.273, Loss_kd 1.534, Train_accy 62.28, Test_accy 69.50
2024-08-07 14:28:42,698 [foster.py] => Task 2, Epoch 18/170 => Loss 4.867, Loss_clf 1.322, Loss_fe 1.247, Loss_kd 1.530, Train_accy 63.88, Test_accy 69.52
2024-08-07 14:28:56,584 [foster.py] => Task 2, Epoch 19/170 => Loss 4.880, Loss_clf 1.326, Loss_fe 1.249, Loss_kd 1.535, Train_accy 63.18, Test_accy 69.50
2024-08-07 14:29:10,669 [foster.py] => Task 2, Epoch 20/170 => Loss 4.878, Loss_clf 1.333, Loss_fe 1.240, Loss_kd 1.535, Train_accy 62.97, Test_accy 69.38
2024-08-07 14:29:22,614 [foster.py] => Task 2, Epoch 21/170 => Loss 4.859, Loss_clf 1.329, Loss_fe 1.222, Loss_kd 1.537, Train_accy 62.92
2024-08-07 14:29:36,769 [foster.py] => Task 2, Epoch 22/170 => Loss 4.850, Loss_clf 1.318, Loss_fe 1.227, Loss_kd 1.535, Train_accy 63.98, Test_accy 70.13
2024-08-07 14:29:50,678 [foster.py] => Task 2, Epoch 23/170 => Loss 4.795, Loss_clf 1.286, Loss_fe 1.207, Loss_kd 1.533, Train_accy 64.67, Test_accy 68.43
2024-08-07 14:30:04,672 [foster.py] => Task 2, Epoch 24/170 => Loss 4.811, Loss_clf 1.314, Loss_fe 1.197, Loss_kd 1.531, Train_accy 64.28, Test_accy 71.13
2024-08-07 14:30:18,498 [foster.py] => Task 2, Epoch 25/170 => Loss 4.791, Loss_clf 1.284, Loss_fe 1.206, Loss_kd 1.532, Train_accy 64.87, Test_accy 71.40
2024-08-07 14:30:30,507 [foster.py] => Task 2, Epoch 26/170 => Loss 4.785, Loss_clf 1.301, Loss_fe 1.182, Loss_kd 1.532, Train_accy 64.28
2024-08-07 14:30:44,620 [foster.py] => Task 2, Epoch 27/170 => Loss 4.731, Loss_clf 1.264, Loss_fe 1.164, Loss_kd 1.534, Train_accy 64.66, Test_accy 70.78
2024-08-07 14:30:58,792 [foster.py] => Task 2, Epoch 28/170 => Loss 4.839, Loss_clf 1.336, Loss_fe 1.195, Loss_kd 1.537, Train_accy 63.99, Test_accy 69.73
2024-08-07 14:31:12,619 [foster.py] => Task 2, Epoch 29/170 => Loss 4.727, Loss_clf 1.268, Loss_fe 1.160, Loss_kd 1.531, Train_accy 65.14, Test_accy 69.10
2024-08-07 14:31:26,403 [foster.py] => Task 2, Epoch 30/170 => Loss 4.740, Loss_clf 1.273, Loss_fe 1.166, Loss_kd 1.531, Train_accy 65.28, Test_accy 70.52
2024-08-07 14:31:38,411 [foster.py] => Task 2, Epoch 31/170 => Loss 4.676, Loss_clf 1.232, Loss_fe 1.145, Loss_kd 1.531, Train_accy 65.92
2024-08-07 14:31:52,362 [foster.py] => Task 2, Epoch 32/170 => Loss 4.712, Loss_clf 1.255, Loss_fe 1.154, Loss_kd 1.533, Train_accy 64.88, Test_accy 70.90
2024-08-07 14:32:06,186 [foster.py] => Task 2, Epoch 33/170 => Loss 4.707, Loss_clf 1.247, Loss_fe 1.153, Loss_kd 1.536, Train_accy 65.68, Test_accy 71.58
2024-08-07 14:32:20,082 [foster.py] => Task 2, Epoch 34/170 => Loss 4.659, Loss_clf 1.226, Loss_fe 1.126, Loss_kd 1.536, Train_accy 66.25, Test_accy 70.63
2024-08-07 14:32:33,948 [foster.py] => Task 2, Epoch 35/170 => Loss 4.687, Loss_clf 1.251, Loss_fe 1.133, Loss_kd 1.533, Train_accy 65.29, Test_accy 71.68
2024-08-07 14:32:45,779 [foster.py] => Task 2, Epoch 36/170 => Loss 4.677, Loss_clf 1.244, Loss_fe 1.134, Loss_kd 1.531, Train_accy 65.58
2024-08-07 14:32:59,737 [foster.py] => Task 2, Epoch 37/170 => Loss 4.653, Loss_clf 1.231, Loss_fe 1.127, Loss_kd 1.528, Train_accy 65.97, Test_accy 69.68
2024-08-07 14:33:13,499 [foster.py] => Task 2, Epoch 38/170 => Loss 4.652, Loss_clf 1.227, Loss_fe 1.120, Loss_kd 1.534, Train_accy 65.72, Test_accy 69.97
2024-08-07 14:33:27,398 [foster.py] => Task 2, Epoch 39/170 => Loss 4.609, Loss_clf 1.209, Loss_fe 1.097, Loss_kd 1.533, Train_accy 66.95, Test_accy 71.40
2024-08-07 14:33:41,368 [foster.py] => Task 2, Epoch 40/170 => Loss 4.604, Loss_clf 1.202, Loss_fe 1.110, Loss_kd 1.526, Train_accy 66.59, Test_accy 71.38
2024-08-07 14:33:53,160 [foster.py] => Task 2, Epoch 41/170 => Loss 4.587, Loss_clf 1.196, Loss_fe 1.088, Loss_kd 1.532, Train_accy 66.99
2024-08-07 14:34:07,085 [foster.py] => Task 2, Epoch 42/170 => Loss 4.645, Loss_clf 1.225, Loss_fe 1.113, Loss_kd 1.536, Train_accy 65.73, Test_accy 71.67
2024-08-07 14:34:20,984 [foster.py] => Task 2, Epoch 43/170 => Loss 4.572, Loss_clf 1.203, Loss_fe 1.074, Loss_kd 1.528, Train_accy 66.96, Test_accy 71.40
2024-08-07 14:34:34,974 [foster.py] => Task 2, Epoch 44/170 => Loss 4.562, Loss_clf 1.182, Loss_fe 1.077, Loss_kd 1.533, Train_accy 67.42, Test_accy 70.65
2024-08-07 14:34:49,257 [foster.py] => Task 2, Epoch 45/170 => Loss 4.586, Loss_clf 1.200, Loss_fe 1.085, Loss_kd 1.532, Train_accy 66.38, Test_accy 71.27
2024-08-07 14:35:01,704 [foster.py] => Task 2, Epoch 46/170 => Loss 4.546, Loss_clf 1.180, Loss_fe 1.069, Loss_kd 1.529, Train_accy 66.92
2024-08-07 14:35:15,643 [foster.py] => Task 2, Epoch 47/170 => Loss 4.597, Loss_clf 1.200, Loss_fe 1.089, Loss_kd 1.536, Train_accy 66.53, Test_accy 72.32
2024-08-07 14:35:29,673 [foster.py] => Task 2, Epoch 48/170 => Loss 4.531, Loss_clf 1.156, Loss_fe 1.067, Loss_kd 1.536, Train_accy 68.04, Test_accy 72.33
2024-08-07 14:35:43,622 [foster.py] => Task 2, Epoch 49/170 => Loss 4.486, Loss_clf 1.138, Loss_fe 1.050, Loss_kd 1.530, Train_accy 68.18, Test_accy 72.73
2024-08-07 14:35:57,526 [foster.py] => Task 2, Epoch 50/170 => Loss 4.550, Loss_clf 1.183, Loss_fe 1.060, Loss_kd 1.536, Train_accy 67.37, Test_accy 71.92
2024-08-07 14:36:09,303 [foster.py] => Task 2, Epoch 51/170 => Loss 4.480, Loss_clf 1.141, Loss_fe 1.038, Loss_kd 1.531, Train_accy 67.60
2024-08-07 14:36:23,145 [foster.py] => Task 2, Epoch 52/170 => Loss 4.471, Loss_clf 1.129, Loss_fe 1.048, Loss_kd 1.527, Train_accy 67.92, Test_accy 70.95
2024-08-07 14:36:37,017 [foster.py] => Task 2, Epoch 53/170 => Loss 4.489, Loss_clf 1.158, Loss_fe 1.033, Loss_kd 1.530, Train_accy 67.66, Test_accy 69.38
2024-08-07 14:36:51,096 [foster.py] => Task 2, Epoch 54/170 => Loss 4.517, Loss_clf 1.163, Loss_fe 1.047, Loss_kd 1.535, Train_accy 67.64, Test_accy 72.52
2024-08-07 14:37:05,477 [foster.py] => Task 2, Epoch 55/170 => Loss 4.474, Loss_clf 1.141, Loss_fe 1.036, Loss_kd 1.529, Train_accy 68.04, Test_accy 73.42
2024-08-07 14:37:17,476 [foster.py] => Task 2, Epoch 56/170 => Loss 4.465, Loss_clf 1.122, Loss_fe 1.033, Loss_kd 1.538, Train_accy 68.61
2024-08-07 14:37:31,358 [foster.py] => Task 2, Epoch 57/170 => Loss 4.460, Loss_clf 1.119, Loss_fe 1.028, Loss_kd 1.539, Train_accy 69.09, Test_accy 72.87
2024-08-07 14:37:45,410 [foster.py] => Task 2, Epoch 58/170 => Loss 4.417, Loss_clf 1.095, Loss_fe 1.021, Loss_kd 1.532, Train_accy 69.67, Test_accy 72.07
2024-08-07 14:37:59,432 [foster.py] => Task 2, Epoch 59/170 => Loss 4.438, Loss_clf 1.128, Loss_fe 1.015, Loss_kd 1.528, Train_accy 68.96, Test_accy 71.32
2024-08-07 14:38:13,425 [foster.py] => Task 2, Epoch 60/170 => Loss 4.432, Loss_clf 1.114, Loss_fe 1.014, Loss_kd 1.534, Train_accy 68.54, Test_accy 72.67
2024-08-07 14:38:25,128 [foster.py] => Task 2, Epoch 61/170 => Loss 4.380, Loss_clf 1.088, Loss_fe 0.985, Loss_kd 1.535, Train_accy 69.83
2024-08-07 14:38:39,017 [foster.py] => Task 2, Epoch 62/170 => Loss 4.396, Loss_clf 1.101, Loss_fe 1.000, Loss_kd 1.528, Train_accy 68.63, Test_accy 72.32
2024-08-07 14:38:52,879 [foster.py] => Task 2, Epoch 63/170 => Loss 4.426, Loss_clf 1.114, Loss_fe 1.009, Loss_kd 1.533, Train_accy 68.57, Test_accy 72.43
2024-08-07 14:39:06,761 [foster.py] => Task 2, Epoch 64/170 => Loss 4.390, Loss_clf 1.105, Loss_fe 0.992, Loss_kd 1.526, Train_accy 68.82, Test_accy 73.22
2024-08-07 14:39:20,785 [foster.py] => Task 2, Epoch 65/170 => Loss 4.358, Loss_clf 1.092, Loss_fe 0.975, Loss_kd 1.525, Train_accy 69.62, Test_accy 71.28
2024-08-07 14:39:33,150 [foster.py] => Task 2, Epoch 66/170 => Loss 4.330, Loss_clf 1.064, Loss_fe 0.967, Loss_kd 1.530, Train_accy 70.08
2024-08-07 14:39:47,506 [foster.py] => Task 2, Epoch 67/170 => Loss 4.368, Loss_clf 1.082, Loss_fe 0.980, Loss_kd 1.536, Train_accy 69.38, Test_accy 71.10
2024-08-07 14:40:01,669 [foster.py] => Task 2, Epoch 68/170 => Loss 4.326, Loss_clf 1.062, Loss_fe 0.967, Loss_kd 1.529, Train_accy 70.06, Test_accy 72.92
2024-08-07 14:40:15,632 [foster.py] => Task 2, Epoch 69/170 => Loss 4.320, Loss_clf 1.055, Loss_fe 0.960, Loss_kd 1.534, Train_accy 70.21, Test_accy 72.40
2024-08-07 14:40:29,444 [foster.py] => Task 2, Epoch 70/170 => Loss 4.278, Loss_clf 1.033, Loss_fe 0.948, Loss_kd 1.529, Train_accy 70.77, Test_accy 73.35
2024-08-07 14:40:41,231 [foster.py] => Task 2, Epoch 71/170 => Loss 4.291, Loss_clf 1.052, Loss_fe 0.945, Loss_kd 1.527, Train_accy 70.89
2024-08-07 14:40:55,262 [foster.py] => Task 2, Epoch 72/170 => Loss 4.290, Loss_clf 1.050, Loss_fe 0.936, Loss_kd 1.534, Train_accy 71.02, Test_accy 72.75
2024-08-07 14:41:09,147 [foster.py] => Task 2, Epoch 73/170 => Loss 4.262, Loss_clf 1.034, Loss_fe 0.929, Loss_kd 1.530, Train_accy 70.75, Test_accy 73.03
2024-08-07 14:41:23,399 [foster.py] => Task 2, Epoch 74/170 => Loss 4.280, Loss_clf 1.039, Loss_fe 0.943, Loss_kd 1.529, Train_accy 70.97, Test_accy 72.62
2024-08-07 14:41:37,307 [foster.py] => Task 2, Epoch 75/170 => Loss 4.282, Loss_clf 1.046, Loss_fe 0.935, Loss_kd 1.532, Train_accy 70.62, Test_accy 73.03
2024-08-07 14:41:49,076 [foster.py] => Task 2, Epoch 76/170 => Loss 4.250, Loss_clf 1.032, Loss_fe 0.922, Loss_kd 1.528, Train_accy 70.68
2024-08-07 14:42:03,083 [foster.py] => Task 2, Epoch 77/170 => Loss 4.274, Loss_clf 1.044, Loss_fe 0.928, Loss_kd 1.533, Train_accy 70.88, Test_accy 72.92
2024-08-07 14:42:16,966 [foster.py] => Task 2, Epoch 78/170 => Loss 4.212, Loss_clf 1.004, Loss_fe 0.908, Loss_kd 1.531, Train_accy 71.42, Test_accy 73.50
2024-08-07 14:42:30,844 [foster.py] => Task 2, Epoch 79/170 => Loss 4.178, Loss_clf 0.989, Loss_fe 0.893, Loss_kd 1.529, Train_accy 72.28, Test_accy 73.97
2024-08-07 14:42:44,629 [foster.py] => Task 2, Epoch 80/170 => Loss 4.224, Loss_clf 1.014, Loss_fe 0.904, Loss_kd 1.535, Train_accy 71.30, Test_accy 71.97
2024-08-07 14:42:56,386 [foster.py] => Task 2, Epoch 81/170 => Loss 4.203, Loss_clf 1.004, Loss_fe 0.898, Loss_kd 1.532, Train_accy 71.72
2024-08-07 14:43:10,262 [foster.py] => Task 2, Epoch 82/170 => Loss 4.196, Loss_clf 1.001, Loss_fe 0.898, Loss_kd 1.529, Train_accy 71.84, Test_accy 72.65
2024-08-07 14:43:24,200 [foster.py] => Task 2, Epoch 83/170 => Loss 4.222, Loss_clf 1.016, Loss_fe 0.914, Loss_kd 1.526, Train_accy 71.30, Test_accy 73.72
2024-08-07 14:43:38,496 [foster.py] => Task 2, Epoch 84/170 => Loss 4.159, Loss_clf 0.978, Loss_fe 0.884, Loss_kd 1.529, Train_accy 72.36, Test_accy 73.87
2024-08-07 14:43:53,044 [foster.py] => Task 2, Epoch 85/170 => Loss 4.115, Loss_clf 0.956, Loss_fe 0.861, Loss_kd 1.530, Train_accy 72.49, Test_accy 74.25
2024-08-07 14:44:04,976 [foster.py] => Task 2, Epoch 86/170 => Loss 4.175, Loss_clf 0.994, Loss_fe 0.880, Loss_kd 1.532, Train_accy 72.31
2024-08-07 14:44:18,861 [foster.py] => Task 2, Epoch 87/170 => Loss 4.137, Loss_clf 0.974, Loss_fe 0.865, Loss_kd 1.529, Train_accy 72.67, Test_accy 73.85
2024-08-07 14:44:32,794 [foster.py] => Task 2, Epoch 88/170 => Loss 4.123, Loss_clf 0.963, Loss_fe 0.864, Loss_kd 1.528, Train_accy 72.80, Test_accy 72.67
2024-08-07 14:44:46,801 [foster.py] => Task 2, Epoch 89/170 => Loss 4.110, Loss_clf 0.958, Loss_fe 0.856, Loss_kd 1.529, Train_accy 72.95, Test_accy 73.38
2024-08-07 14:45:00,922 [foster.py] => Task 2, Epoch 90/170 => Loss 4.123, Loss_clf 0.961, Loss_fe 0.860, Loss_kd 1.532, Train_accy 72.97, Test_accy 74.65
2024-08-07 14:45:12,782 [foster.py] => Task 2, Epoch 91/170 => Loss 4.068, Loss_clf 0.939, Loss_fe 0.834, Loss_kd 1.527, Train_accy 73.33
2024-08-07 14:45:26,700 [foster.py] => Task 2, Epoch 92/170 => Loss 4.105, Loss_clf 0.952, Loss_fe 0.847, Loss_kd 1.535, Train_accy 72.89, Test_accy 74.33
2024-08-07 14:45:40,554 [foster.py] => Task 2, Epoch 93/170 => Loss 4.063, Loss_clf 0.939, Loss_fe 0.827, Loss_kd 1.530, Train_accy 73.28, Test_accy 73.53
2024-08-07 14:45:54,608 [foster.py] => Task 2, Epoch 94/170 => Loss 4.093, Loss_clf 0.945, Loss_fe 0.843, Loss_kd 1.534, Train_accy 73.03, Test_accy 72.38
2024-08-07 14:46:08,596 [foster.py] => Task 2, Epoch 95/170 => Loss 4.036, Loss_clf 0.920, Loss_fe 0.820, Loss_kd 1.528, Train_accy 74.00, Test_accy 74.93
2024-08-07 14:46:20,601 [foster.py] => Task 2, Epoch 96/170 => Loss 4.005, Loss_clf 0.908, Loss_fe 0.803, Loss_kd 1.527, Train_accy 74.03
2024-08-07 14:46:34,693 [foster.py] => Task 2, Epoch 97/170 => Loss 4.028, Loss_clf 0.918, Loss_fe 0.809, Loss_kd 1.532, Train_accy 74.43, Test_accy 74.13
2024-08-07 14:46:48,631 [foster.py] => Task 2, Epoch 98/170 => Loss 4.020, Loss_clf 0.917, Loss_fe 0.808, Loss_kd 1.528, Train_accy 73.88, Test_accy 74.47
2024-08-07 14:47:02,656 [foster.py] => Task 2, Epoch 99/170 => Loss 4.024, Loss_clf 0.914, Loss_fe 0.817, Loss_kd 1.526, Train_accy 74.58, Test_accy 74.03
2024-08-07 14:47:16,773 [foster.py] => Task 2, Epoch 100/170 => Loss 3.996, Loss_clf 0.903, Loss_fe 0.795, Loss_kd 1.529, Train_accy 73.96, Test_accy 74.70
2024-08-07 14:47:28,633 [foster.py] => Task 2, Epoch 101/170 => Loss 3.955, Loss_clf 0.882, Loss_fe 0.776, Loss_kd 1.529, Train_accy 75.28
2024-08-07 14:47:42,736 [foster.py] => Task 2, Epoch 102/170 => Loss 3.964, Loss_clf 0.884, Loss_fe 0.781, Loss_kd 1.530, Train_accy 75.15, Test_accy 74.97
2024-08-07 14:47:56,730 [foster.py] => Task 2, Epoch 103/170 => Loss 3.933, Loss_clf 0.866, Loss_fe 0.765, Loss_kd 1.533, Train_accy 74.90, Test_accy 73.85
2024-08-07 14:48:10,701 [foster.py] => Task 2, Epoch 104/170 => Loss 3.937, Loss_clf 0.871, Loss_fe 0.764, Loss_kd 1.532, Train_accy 75.44, Test_accy 74.75
2024-08-07 14:48:24,675 [foster.py] => Task 2, Epoch 105/170 => Loss 3.946, Loss_clf 0.879, Loss_fe 0.758, Loss_kd 1.537, Train_accy 75.31, Test_accy 75.37
2024-08-07 14:48:36,543 [foster.py] => Task 2, Epoch 106/170 => Loss 3.889, Loss_clf 0.848, Loss_fe 0.748, Loss_kd 1.526, Train_accy 75.78
2024-08-07 14:48:50,532 [foster.py] => Task 2, Epoch 107/170 => Loss 3.869, Loss_clf 0.838, Loss_fe 0.741, Loss_kd 1.524, Train_accy 76.11, Test_accy 74.85
2024-08-07 14:49:04,733 [foster.py] => Task 2, Epoch 108/170 => Loss 3.868, Loss_clf 0.833, Loss_fe 0.735, Loss_kd 1.531, Train_accy 76.72, Test_accy 75.12
2024-08-07 14:49:18,856 [foster.py] => Task 2, Epoch 109/170 => Loss 3.852, Loss_clf 0.831, Loss_fe 0.729, Loss_kd 1.526, Train_accy 76.16, Test_accy 74.65
2024-08-07 14:49:32,737 [foster.py] => Task 2, Epoch 110/170 => Loss 3.832, Loss_clf 0.820, Loss_fe 0.716, Loss_kd 1.529, Train_accy 76.60, Test_accy 75.28
2024-08-07 14:49:44,629 [foster.py] => Task 2, Epoch 111/170 => Loss 3.800, Loss_clf 0.808, Loss_fe 0.699, Loss_kd 1.526, Train_accy 77.10
2024-08-07 14:49:59,002 [foster.py] => Task 2, Epoch 112/170 => Loss 3.820, Loss_clf 0.817, Loss_fe 0.702, Loss_kd 1.531, Train_accy 77.07, Test_accy 74.22
2024-08-07 14:50:13,533 [foster.py] => Task 2, Epoch 113/170 => Loss 3.819, Loss_clf 0.815, Loss_fe 0.708, Loss_kd 1.529, Train_accy 76.93, Test_accy 75.42
2024-08-07 14:50:27,365 [foster.py] => Task 2, Epoch 114/170 => Loss 3.801, Loss_clf 0.801, Loss_fe 0.705, Loss_kd 1.528, Train_accy 77.12, Test_accy 74.47
2024-08-07 14:50:41,204 [foster.py] => Task 2, Epoch 115/170 => Loss 3.754, Loss_clf 0.782, Loss_fe 0.684, Loss_kd 1.523, Train_accy 77.49, Test_accy 74.95
2024-08-07 14:50:53,038 [foster.py] => Task 2, Epoch 116/170 => Loss 3.761, Loss_clf 0.785, Loss_fe 0.682, Loss_kd 1.527, Train_accy 77.57
2024-08-07 14:51:06,936 [foster.py] => Task 2, Epoch 117/170 => Loss 3.758, Loss_clf 0.782, Loss_fe 0.678, Loss_kd 1.530, Train_accy 77.68, Test_accy 75.25
2024-08-07 14:51:20,877 [foster.py] => Task 2, Epoch 118/170 => Loss 3.763, Loss_clf 0.785, Loss_fe 0.676, Loss_kd 1.533, Train_accy 77.78, Test_accy 75.38
2024-08-07 14:51:35,089 [foster.py] => Task 2, Epoch 119/170 => Loss 3.725, Loss_clf 0.764, Loss_fe 0.662, Loss_kd 1.531, Train_accy 78.28, Test_accy 75.68
2024-08-07 14:51:49,433 [foster.py] => Task 2, Epoch 120/170 => Loss 3.700, Loss_clf 0.755, Loss_fe 0.652, Loss_kd 1.526, Train_accy 78.53, Test_accy 75.07
2024-08-07 14:52:01,347 [foster.py] => Task 2, Epoch 121/170 => Loss 3.692, Loss_clf 0.754, Loss_fe 0.648, Loss_kd 1.525, Train_accy 78.45
2024-08-07 14:52:15,316 [foster.py] => Task 2, Epoch 122/170 => Loss 3.703, Loss_clf 0.756, Loss_fe 0.650, Loss_kd 1.529, Train_accy 78.85, Test_accy 75.87
2024-08-07 14:52:29,479 [foster.py] => Task 2, Epoch 123/170 => Loss 3.655, Loss_clf 0.735, Loss_fe 0.625, Loss_kd 1.528, Train_accy 79.47, Test_accy 74.82
2024-08-07 14:52:43,825 [foster.py] => Task 2, Epoch 124/170 => Loss 3.695, Loss_clf 0.753, Loss_fe 0.648, Loss_kd 1.527, Train_accy 78.96, Test_accy 75.40
2024-08-07 14:52:57,794 [foster.py] => Task 2, Epoch 125/170 => Loss 3.631, Loss_clf 0.726, Loss_fe 0.615, Loss_kd 1.524, Train_accy 79.52, Test_accy 76.12
2024-08-07 14:53:09,654 [foster.py] => Task 2, Epoch 126/170 => Loss 3.616, Loss_clf 0.708, Loss_fe 0.610, Loss_kd 1.530, Train_accy 80.17
2024-08-07 14:53:23,553 [foster.py] => Task 2, Epoch 127/170 => Loss 3.612, Loss_clf 0.709, Loss_fe 0.602, Loss_kd 1.532, Train_accy 79.86, Test_accy 76.12
2024-08-07 14:53:37,526 [foster.py] => Task 2, Epoch 128/170 => Loss 3.613, Loss_clf 0.718, Loss_fe 0.603, Loss_kd 1.526, Train_accy 79.75, Test_accy 76.17
2024-08-07 14:53:51,311 [foster.py] => Task 2, Epoch 129/170 => Loss 3.638, Loss_clf 0.725, Loss_fe 0.613, Loss_kd 1.531, Train_accy 79.59, Test_accy 76.40
2024-08-07 14:54:05,290 [foster.py] => Task 2, Epoch 130/170 => Loss 3.572, Loss_clf 0.698, Loss_fe 0.584, Loss_kd 1.525, Train_accy 80.40, Test_accy 76.40
2024-08-07 14:54:17,120 [foster.py] => Task 2, Epoch 131/170 => Loss 3.575, Loss_clf 0.693, Loss_fe 0.587, Loss_kd 1.528, Train_accy 80.42
2024-08-07 14:54:30,966 [foster.py] => Task 2, Epoch 132/170 => Loss 3.543, Loss_clf 0.679, Loss_fe 0.570, Loss_kd 1.527, Train_accy 80.61, Test_accy 76.32
2024-08-07 14:54:45,293 [foster.py] => Task 2, Epoch 133/170 => Loss 3.587, Loss_clf 0.701, Loss_fe 0.580, Loss_kd 1.535, Train_accy 80.54, Test_accy 75.98
2024-08-07 14:54:59,499 [foster.py] => Task 2, Epoch 134/170 => Loss 3.497, Loss_clf 0.657, Loss_fe 0.553, Loss_kd 1.523, Train_accy 81.40, Test_accy 76.00
2024-08-07 14:55:13,612 [foster.py] => Task 2, Epoch 135/170 => Loss 3.522, Loss_clf 0.668, Loss_fe 0.557, Loss_kd 1.529, Train_accy 81.27, Test_accy 76.07
2024-08-07 14:55:25,448 [foster.py] => Task 2, Epoch 136/170 => Loss 3.498, Loss_clf 0.659, Loss_fe 0.544, Loss_kd 1.528, Train_accy 81.42
2024-08-07 14:55:39,456 [foster.py] => Task 2, Epoch 137/170 => Loss 3.477, Loss_clf 0.643, Loss_fe 0.537, Loss_kd 1.529, Train_accy 82.07, Test_accy 76.33
2024-08-07 14:55:53,522 [foster.py] => Task 2, Epoch 138/170 => Loss 3.514, Loss_clf 0.662, Loss_fe 0.546, Loss_kd 1.536, Train_accy 81.17, Test_accy 76.43
2024-08-07 14:56:07,459 [foster.py] => Task 2, Epoch 139/170 => Loss 3.459, Loss_clf 0.632, Loss_fe 0.526, Loss_kd 1.532, Train_accy 81.98, Test_accy 76.08
2024-08-07 14:56:21,291 [foster.py] => Task 2, Epoch 140/170 => Loss 3.444, Loss_clf 0.629, Loss_fe 0.528, Loss_kd 1.523, Train_accy 82.12, Test_accy 76.95
2024-08-07 14:56:32,983 [foster.py] => Task 2, Epoch 141/170 => Loss 3.456, Loss_clf 0.640, Loss_fe 0.525, Loss_kd 1.525, Train_accy 81.71
2024-08-07 14:56:46,990 [foster.py] => Task 2, Epoch 142/170 => Loss 3.455, Loss_clf 0.641, Loss_fe 0.520, Loss_kd 1.528, Train_accy 82.22, Test_accy 77.08
2024-08-07 14:57:01,099 [foster.py] => Task 2, Epoch 143/170 => Loss 3.416, Loss_clf 0.618, Loss_fe 0.511, Loss_kd 1.523, Train_accy 82.42, Test_accy 76.95
2024-08-07 14:57:15,010 [foster.py] => Task 2, Epoch 144/170 => Loss 3.380, Loss_clf 0.598, Loss_fe 0.496, Loss_kd 1.522, Train_accy 83.02, Test_accy 77.08
2024-08-07 14:57:29,001 [foster.py] => Task 2, Epoch 145/170 => Loss 3.407, Loss_clf 0.617, Loss_fe 0.499, Loss_kd 1.525, Train_accy 82.98, Test_accy 77.25
2024-08-07 14:57:40,869 [foster.py] => Task 2, Epoch 146/170 => Loss 3.386, Loss_clf 0.603, Loss_fe 0.490, Loss_kd 1.527, Train_accy 82.95
2024-08-07 14:57:54,981 [foster.py] => Task 2, Epoch 147/170 => Loss 3.393, Loss_clf 0.602, Loss_fe 0.496, Loss_kd 1.527, Train_accy 83.02, Test_accy 77.10
2024-08-07 14:58:08,873 [foster.py] => Task 2, Epoch 148/170 => Loss 3.376, Loss_clf 0.595, Loss_fe 0.487, Loss_kd 1.527, Train_accy 83.04, Test_accy 77.17
2024-08-07 14:58:22,932 [foster.py] => Task 2, Epoch 149/170 => Loss 3.398, Loss_clf 0.616, Loss_fe 0.484, Loss_kd 1.530, Train_accy 83.02, Test_accy 76.83
2024-08-07 14:58:36,981 [foster.py] => Task 2, Epoch 150/170 => Loss 3.361, Loss_clf 0.588, Loss_fe 0.478, Loss_kd 1.528, Train_accy 83.54, Test_accy 77.00
2024-08-07 14:58:48,748 [foster.py] => Task 2, Epoch 151/170 => Loss 3.330, Loss_clf 0.577, Loss_fe 0.466, Loss_kd 1.523, Train_accy 83.95
2024-08-07 14:59:02,510 [foster.py] => Task 2, Epoch 152/170 => Loss 3.342, Loss_clf 0.577, Loss_fe 0.473, Loss_kd 1.526, Train_accy 83.32, Test_accy 77.25
2024-08-07 14:59:16,391 [foster.py] => Task 2, Epoch 153/170 => Loss 3.347, Loss_clf 0.589, Loss_fe 0.469, Loss_kd 1.524, Train_accy 83.25, Test_accy 76.97
2024-08-07 14:59:30,323 [foster.py] => Task 2, Epoch 154/170 => Loss 3.318, Loss_clf 0.571, Loss_fe 0.456, Loss_kd 1.525, Train_accy 83.90, Test_accy 77.08
2024-08-07 14:59:44,343 [foster.py] => Task 2, Epoch 155/170 => Loss 3.291, Loss_clf 0.555, Loss_fe 0.448, Loss_kd 1.522, Train_accy 84.35, Test_accy 77.12
2024-08-07 14:59:56,119 [foster.py] => Task 2, Epoch 156/170 => Loss 3.300, Loss_clf 0.555, Loss_fe 0.451, Loss_kd 1.527, Train_accy 84.40
2024-08-07 15:00:10,066 [foster.py] => Task 2, Epoch 157/170 => Loss 3.335, Loss_clf 0.576, Loss_fe 0.466, Loss_kd 1.526, Train_accy 83.77, Test_accy 77.05
2024-08-07 15:00:23,984 [foster.py] => Task 2, Epoch 158/170 => Loss 3.303, Loss_clf 0.565, Loss_fe 0.445, Loss_kd 1.527, Train_accy 84.05, Test_accy 77.28
2024-08-07 15:00:37,788 [foster.py] => Task 2, Epoch 159/170 => Loss 3.301, Loss_clf 0.565, Loss_fe 0.448, Loss_kd 1.524, Train_accy 83.93, Test_accy 77.42
2024-08-07 15:00:51,908 [foster.py] => Task 2, Epoch 160/170 => Loss 3.310, Loss_clf 0.565, Loss_fe 0.450, Loss_kd 1.528, Train_accy 84.48, Test_accy 77.20
2024-08-07 15:01:03,649 [foster.py] => Task 2, Epoch 161/170 => Loss 3.311, Loss_clf 0.572, Loss_fe 0.446, Loss_kd 1.527, Train_accy 84.09
2024-08-07 15:01:17,658 [foster.py] => Task 2, Epoch 162/170 => Loss 3.310, Loss_clf 0.564, Loss_fe 0.449, Loss_kd 1.529, Train_accy 84.33, Test_accy 77.23
2024-08-07 15:01:31,500 [foster.py] => Task 2, Epoch 163/170 => Loss 3.291, Loss_clf 0.559, Loss_fe 0.445, Loss_kd 1.522, Train_accy 84.12, Test_accy 77.22
2024-08-07 15:01:45,338 [foster.py] => Task 2, Epoch 164/170 => Loss 3.307, Loss_clf 0.565, Loss_fe 0.446, Loss_kd 1.529, Train_accy 84.21, Test_accy 77.30
2024-08-07 15:01:59,119 [foster.py] => Task 2, Epoch 165/170 => Loss 3.318, Loss_clf 0.570, Loss_fe 0.448, Loss_kd 1.531, Train_accy 84.28, Test_accy 77.33
2024-08-07 15:02:10,934 [foster.py] => Task 2, Epoch 166/170 => Loss 3.275, Loss_clf 0.548, Loss_fe 0.431, Loss_kd 1.529, Train_accy 84.92
2024-08-07 15:02:24,909 [foster.py] => Task 2, Epoch 167/170 => Loss 3.259, Loss_clf 0.540, Loss_fe 0.428, Loss_kd 1.525, Train_accy 85.04, Test_accy 77.23
2024-08-07 15:02:38,833 [foster.py] => Task 2, Epoch 168/170 => Loss 3.279, Loss_clf 0.551, Loss_fe 0.442, Loss_kd 1.522, Train_accy 84.28, Test_accy 77.15
2024-08-07 15:02:53,122 [foster.py] => Task 2, Epoch 169/170 => Loss 3.309, Loss_clf 0.563, Loss_fe 0.451, Loss_kd 1.528, Train_accy 84.06, Test_accy 77.32
2024-08-07 15:03:07,537 [foster.py] => Task 2, Epoch 170/170 => Loss 3.309, Loss_clf 0.565, Loss_fe 0.450, Loss_kd 1.527, Train_accy 84.12, Test_accy 77.25
2024-08-07 15:03:07,540 [foster.py] => do not weight align teacher!
2024-08-07 15:03:07,542 [foster.py] => per cls weights : [1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878 1.07988878
 1.07988878 1.07988878 1.07988878 1.07988878 0.84022245 0.84022245
 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245
 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245
 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245 0.84022245]
2024-08-07 15:03:26,918 [foster.py] => SNet: Task 2, Epoch 1/130 => Loss 28.067,  Loss1 0.697, Train_accy 37.42, Test_accy 61.15
2024-08-07 15:03:43,722 [foster.py] => SNet: Task 2, Epoch 2/130 => Loss 27.821,  Loss1 0.695, Train_accy 55.92
2024-08-07 15:04:00,687 [foster.py] => SNet: Task 2, Epoch 3/130 => Loss 27.752,  Loss1 0.695, Train_accy 60.38
2024-08-07 15:04:17,505 [foster.py] => SNet: Task 2, Epoch 4/130 => Loss 27.716,  Loss1 0.694, Train_accy 62.68
2024-08-07 15:04:34,441 [foster.py] => SNet: Task 2, Epoch 5/130 => Loss 27.724,  Loss1 0.695, Train_accy 63.66
2024-08-07 15:04:53,242 [foster.py] => SNet: Task 2, Epoch 6/130 => Loss 27.703,  Loss1 0.694, Train_accy 64.14, Test_accy 66.55
2024-08-07 15:05:10,416 [foster.py] => SNet: Task 2, Epoch 7/130 => Loss 27.689,  Loss1 0.694, Train_accy 65.79
2024-08-07 15:05:27,196 [foster.py] => SNet: Task 2, Epoch 8/130 => Loss 27.696,  Loss1 0.694, Train_accy 65.98
2024-08-07 15:05:43,996 [foster.py] => SNet: Task 2, Epoch 9/130 => Loss 27.681,  Loss1 0.694, Train_accy 67.12
2024-08-07 15:06:01,036 [foster.py] => SNet: Task 2, Epoch 10/130 => Loss 27.662,  Loss1 0.694, Train_accy 67.53
2024-08-07 15:06:19,902 [foster.py] => SNet: Task 2, Epoch 11/130 => Loss 27.671,  Loss1 0.694, Train_accy 68.19, Test_accy 68.70
2024-08-07 15:06:36,759 [foster.py] => SNet: Task 2, Epoch 12/130 => Loss 27.673,  Loss1 0.694, Train_accy 68.25
2024-08-07 15:06:53,679 [foster.py] => SNet: Task 2, Epoch 13/130 => Loss 27.669,  Loss1 0.694, Train_accy 68.23
2024-08-07 15:07:10,511 [foster.py] => SNet: Task 2, Epoch 14/130 => Loss 27.671,  Loss1 0.694, Train_accy 68.77
2024-08-07 15:07:27,620 [foster.py] => SNet: Task 2, Epoch 15/130 => Loss 27.649,  Loss1 0.694, Train_accy 69.03
2024-08-07 15:07:46,203 [foster.py] => SNet: Task 2, Epoch 16/130 => Loss 27.654,  Loss1 0.694, Train_accy 69.66, Test_accy 68.62
2024-08-07 15:08:03,168 [foster.py] => SNet: Task 2, Epoch 17/130 => Loss 27.633,  Loss1 0.694, Train_accy 70.70
2024-08-07 15:08:19,929 [foster.py] => SNet: Task 2, Epoch 18/130 => Loss 27.648,  Loss1 0.694, Train_accy 70.09
2024-08-07 15:08:37,001 [foster.py] => SNet: Task 2, Epoch 19/130 => Loss 27.645,  Loss1 0.694, Train_accy 70.42
2024-08-07 15:08:53,847 [foster.py] => SNet: Task 2, Epoch 20/130 => Loss 27.659,  Loss1 0.694, Train_accy 70.66
2024-08-07 15:09:12,600 [foster.py] => SNet: Task 2, Epoch 21/130 => Loss 27.643,  Loss1 0.694, Train_accy 70.92, Test_accy 70.78
2024-08-07 15:09:29,725 [foster.py] => SNet: Task 2, Epoch 22/130 => Loss 27.622,  Loss1 0.694, Train_accy 71.30
2024-08-07 15:09:46,707 [foster.py] => SNet: Task 2, Epoch 23/130 => Loss 27.635,  Loss1 0.694, Train_accy 71.61
2024-08-07 15:10:03,603 [foster.py] => SNet: Task 2, Epoch 24/130 => Loss 27.644,  Loss1 0.694, Train_accy 70.58
2024-08-07 15:10:20,574 [foster.py] => SNet: Task 2, Epoch 25/130 => Loss 27.635,  Loss1 0.694, Train_accy 72.08
2024-08-07 15:10:39,485 [foster.py] => SNet: Task 2, Epoch 26/130 => Loss 27.619,  Loss1 0.694, Train_accy 71.62, Test_accy 71.35
2024-08-07 15:10:56,610 [foster.py] => SNet: Task 2, Epoch 27/130 => Loss 27.620,  Loss1 0.694, Train_accy 72.39
2024-08-07 15:11:13,364 [foster.py] => SNet: Task 2, Epoch 28/130 => Loss 27.619,  Loss1 0.694, Train_accy 72.77
2024-08-07 15:11:30,110 [foster.py] => SNet: Task 2, Epoch 29/130 => Loss 27.617,  Loss1 0.694, Train_accy 72.72
2024-08-07 15:11:47,075 [foster.py] => SNet: Task 2, Epoch 30/130 => Loss 27.627,  Loss1 0.694, Train_accy 72.78
2024-08-07 15:12:05,822 [foster.py] => SNet: Task 2, Epoch 31/130 => Loss 27.623,  Loss1 0.694, Train_accy 72.38, Test_accy 72.05
2024-08-07 15:12:23,052 [foster.py] => SNet: Task 2, Epoch 32/130 => Loss 27.622,  Loss1 0.694, Train_accy 72.56
2024-08-07 15:12:40,430 [foster.py] => SNet: Task 2, Epoch 33/130 => Loss 27.615,  Loss1 0.694, Train_accy 73.72
2024-08-07 15:12:57,677 [foster.py] => SNet: Task 2, Epoch 34/130 => Loss 27.592,  Loss1 0.694, Train_accy 72.97
2024-08-07 15:13:14,819 [foster.py] => SNet: Task 2, Epoch 35/130 => Loss 27.627,  Loss1 0.694, Train_accy 72.63
2024-08-07 15:13:33,495 [foster.py] => SNet: Task 2, Epoch 36/130 => Loss 27.614,  Loss1 0.694, Train_accy 74.15, Test_accy 72.15
2024-08-07 15:13:50,224 [foster.py] => SNet: Task 2, Epoch 37/130 => Loss 27.603,  Loss1 0.694, Train_accy 73.66
2024-08-07 15:14:07,016 [foster.py] => SNet: Task 2, Epoch 38/130 => Loss 27.606,  Loss1 0.694, Train_accy 73.79
2024-08-07 15:14:23,942 [foster.py] => SNet: Task 2, Epoch 39/130 => Loss 27.623,  Loss1 0.694, Train_accy 73.34
2024-08-07 15:14:40,698 [foster.py] => SNet: Task 2, Epoch 40/130 => Loss 27.595,  Loss1 0.694, Train_accy 74.05
2024-08-07 15:14:59,280 [foster.py] => SNet: Task 2, Epoch 41/130 => Loss 27.603,  Loss1 0.694, Train_accy 74.39, Test_accy 72.20
2024-08-07 15:15:16,457 [foster.py] => SNet: Task 2, Epoch 42/130 => Loss 27.599,  Loss1 0.694, Train_accy 74.26
2024-08-07 15:15:33,470 [foster.py] => SNet: Task 2, Epoch 43/130 => Loss 27.593,  Loss1 0.694, Train_accy 74.59
2024-08-07 15:15:50,410 [foster.py] => SNet: Task 2, Epoch 44/130 => Loss 27.593,  Loss1 0.694, Train_accy 74.44
2024-08-07 15:16:07,457 [foster.py] => SNet: Task 2, Epoch 45/130 => Loss 27.603,  Loss1 0.694, Train_accy 74.86
2024-08-07 15:16:26,348 [foster.py] => SNet: Task 2, Epoch 46/130 => Loss 27.601,  Loss1 0.694, Train_accy 74.42, Test_accy 72.82
2024-08-07 15:16:43,209 [foster.py] => SNet: Task 2, Epoch 47/130 => Loss 27.599,  Loss1 0.694, Train_accy 74.87
2024-08-07 15:17:00,149 [foster.py] => SNet: Task 2, Epoch 48/130 => Loss 27.584,  Loss1 0.694, Train_accy 75.26
2024-08-07 15:17:17,035 [foster.py] => SNet: Task 2, Epoch 49/130 => Loss 27.581,  Loss1 0.694, Train_accy 74.56
2024-08-07 15:17:33,889 [foster.py] => SNet: Task 2, Epoch 50/130 => Loss 27.588,  Loss1 0.694, Train_accy 75.22
2024-08-07 15:17:52,623 [foster.py] => SNet: Task 2, Epoch 51/130 => Loss 27.593,  Loss1 0.694, Train_accy 75.16, Test_accy 73.72
2024-08-07 15:18:09,453 [foster.py] => SNet: Task 2, Epoch 52/130 => Loss 27.591,  Loss1 0.694, Train_accy 75.57
2024-08-07 15:18:26,374 [foster.py] => SNet: Task 2, Epoch 53/130 => Loss 27.584,  Loss1 0.694, Train_accy 75.20
2024-08-07 15:18:43,059 [foster.py] => SNet: Task 2, Epoch 54/130 => Loss 27.592,  Loss1 0.694, Train_accy 75.38
2024-08-07 15:18:59,761 [foster.py] => SNet: Task 2, Epoch 55/130 => Loss 27.601,  Loss1 0.694, Train_accy 74.75
2024-08-07 15:19:18,473 [foster.py] => SNet: Task 2, Epoch 56/130 => Loss 27.604,  Loss1 0.694, Train_accy 75.12, Test_accy 73.93
2024-08-07 15:19:35,534 [foster.py] => SNet: Task 2, Epoch 57/130 => Loss 27.583,  Loss1 0.694, Train_accy 75.68
2024-08-07 15:19:52,501 [foster.py] => SNet: Task 2, Epoch 58/130 => Loss 27.575,  Loss1 0.694, Train_accy 75.87
2024-08-07 15:20:09,521 [foster.py] => SNet: Task 2, Epoch 59/130 => Loss 27.584,  Loss1 0.694, Train_accy 76.30
2024-08-07 15:20:26,300 [foster.py] => SNet: Task 2, Epoch 60/130 => Loss 27.587,  Loss1 0.694, Train_accy 75.73
2024-08-07 15:20:44,821 [foster.py] => SNet: Task 2, Epoch 61/130 => Loss 27.587,  Loss1 0.694, Train_accy 76.45, Test_accy 73.55
2024-08-07 15:21:01,855 [foster.py] => SNet: Task 2, Epoch 62/130 => Loss 27.600,  Loss1 0.694, Train_accy 75.45
2024-08-07 15:21:18,670 [foster.py] => SNet: Task 2, Epoch 63/130 => Loss 27.585,  Loss1 0.694, Train_accy 75.60
2024-08-07 15:21:35,293 [foster.py] => SNet: Task 2, Epoch 64/130 => Loss 27.574,  Loss1 0.694, Train_accy 76.62
2024-08-07 15:21:52,194 [foster.py] => SNet: Task 2, Epoch 65/130 => Loss 27.577,  Loss1 0.694, Train_accy 76.74
2024-08-07 15:22:11,164 [foster.py] => SNet: Task 2, Epoch 66/130 => Loss 27.587,  Loss1 0.694, Train_accy 76.38, Test_accy 74.03
2024-08-07 15:22:28,010 [foster.py] => SNet: Task 2, Epoch 67/130 => Loss 27.585,  Loss1 0.694, Train_accy 76.56
2024-08-07 15:22:44,862 [foster.py] => SNet: Task 2, Epoch 68/130 => Loss 27.580,  Loss1 0.694, Train_accy 76.96
2024-08-07 15:23:01,563 [foster.py] => SNet: Task 2, Epoch 69/130 => Loss 27.574,  Loss1 0.694, Train_accy 77.11
2024-08-07 15:23:18,324 [foster.py] => SNet: Task 2, Epoch 70/130 => Loss 27.581,  Loss1 0.694, Train_accy 76.52
2024-08-07 15:23:37,257 [foster.py] => SNet: Task 2, Epoch 71/130 => Loss 27.591,  Loss1 0.694, Train_accy 76.04, Test_accy 73.90
2024-08-07 15:23:54,067 [foster.py] => SNet: Task 2, Epoch 72/130 => Loss 27.584,  Loss1 0.694, Train_accy 76.53
2024-08-07 15:24:11,043 [foster.py] => SNet: Task 2, Epoch 73/130 => Loss 27.562,  Loss1 0.694, Train_accy 76.99
2024-08-07 15:24:27,710 [foster.py] => SNet: Task 2, Epoch 74/130 => Loss 27.576,  Loss1 0.694, Train_accy 76.65
2024-08-07 15:24:44,523 [foster.py] => SNet: Task 2, Epoch 75/130 => Loss 27.571,  Loss1 0.694, Train_accy 77.22
2024-08-07 15:25:03,173 [foster.py] => SNet: Task 2, Epoch 76/130 => Loss 27.579,  Loss1 0.694, Train_accy 77.03, Test_accy 74.07
2024-08-07 15:25:20,207 [foster.py] => SNet: Task 2, Epoch 77/130 => Loss 27.571,  Loss1 0.694, Train_accy 76.70
2024-08-07 15:25:37,149 [foster.py] => SNet: Task 2, Epoch 78/130 => Loss 27.578,  Loss1 0.694, Train_accy 77.29
2024-08-07 15:25:54,184 [foster.py] => SNet: Task 2, Epoch 79/130 => Loss 27.560,  Loss1 0.694, Train_accy 77.28
2024-08-07 15:26:10,983 [foster.py] => SNet: Task 2, Epoch 80/130 => Loss 27.564,  Loss1 0.694, Train_accy 77.42
2024-08-07 15:26:29,807 [foster.py] => SNet: Task 2, Epoch 81/130 => Loss 27.577,  Loss1 0.693, Train_accy 77.19, Test_accy 74.85
2024-08-07 15:26:46,757 [foster.py] => SNet: Task 2, Epoch 82/130 => Loss 27.566,  Loss1 0.694, Train_accy 77.35
2024-08-07 15:27:03,831 [foster.py] => SNet: Task 2, Epoch 83/130 => Loss 27.561,  Loss1 0.694, Train_accy 77.46
2024-08-07 15:27:20,738 [foster.py] => SNet: Task 2, Epoch 84/130 => Loss 27.577,  Loss1 0.694, Train_accy 77.07
2024-08-07 15:27:37,509 [foster.py] => SNet: Task 2, Epoch 85/130 => Loss 27.572,  Loss1 0.694, Train_accy 77.58
2024-08-07 15:27:56,047 [foster.py] => SNet: Task 2, Epoch 86/130 => Loss 27.566,  Loss1 0.694, Train_accy 77.33, Test_accy 74.93
2024-08-07 15:28:13,147 [foster.py] => SNet: Task 2, Epoch 87/130 => Loss 27.580,  Loss1 0.694, Train_accy 76.90
2024-08-07 15:28:30,141 [foster.py] => SNet: Task 2, Epoch 88/130 => Loss 27.568,  Loss1 0.694, Train_accy 77.49
2024-08-07 15:28:46,928 [foster.py] => SNet: Task 2, Epoch 89/130 => Loss 27.565,  Loss1 0.693, Train_accy 77.52
2024-08-07 15:29:03,903 [foster.py] => SNet: Task 2, Epoch 90/130 => Loss 27.565,  Loss1 0.694, Train_accy 77.53
2024-08-07 15:29:22,503 [foster.py] => SNet: Task 2, Epoch 91/130 => Loss 27.550,  Loss1 0.694, Train_accy 77.52, Test_accy 74.68
2024-08-07 15:29:39,406 [foster.py] => SNet: Task 2, Epoch 92/130 => Loss 27.571,  Loss1 0.694, Train_accy 77.43
2024-08-07 15:29:56,583 [foster.py] => SNet: Task 2, Epoch 93/130 => Loss 27.574,  Loss1 0.694, Train_accy 77.49
2024-08-07 15:30:13,400 [foster.py] => SNet: Task 2, Epoch 94/130 => Loss 27.581,  Loss1 0.694, Train_accy 77.10
2024-08-07 15:30:30,183 [foster.py] => SNet: Task 2, Epoch 95/130 => Loss 27.582,  Loss1 0.694, Train_accy 77.76
2024-08-07 15:30:48,981 [foster.py] => SNet: Task 2, Epoch 96/130 => Loss 27.560,  Loss1 0.694, Train_accy 77.95, Test_accy 75.17
2024-08-07 15:31:06,465 [foster.py] => SNet: Task 2, Epoch 97/130 => Loss 27.550,  Loss1 0.694, Train_accy 77.97
2024-08-07 15:31:23,327 [foster.py] => SNet: Task 2, Epoch 98/130 => Loss 27.560,  Loss1 0.694, Train_accy 77.42
2024-08-07 15:31:40,196 [foster.py] => SNet: Task 2, Epoch 99/130 => Loss 27.559,  Loss1 0.694, Train_accy 78.36
2024-08-07 15:31:57,411 [foster.py] => SNet: Task 2, Epoch 100/130 => Loss 27.558,  Loss1 0.694, Train_accy 78.34
2024-08-07 15:32:16,232 [foster.py] => SNet: Task 2, Epoch 101/130 => Loss 27.569,  Loss1 0.694, Train_accy 78.01, Test_accy 74.85
2024-08-07 15:32:33,436 [foster.py] => SNet: Task 2, Epoch 102/130 => Loss 27.570,  Loss1 0.694, Train_accy 77.71
2024-08-07 15:32:50,591 [foster.py] => SNet: Task 2, Epoch 103/130 => Loss 27.573,  Loss1 0.694, Train_accy 77.66
2024-08-07 15:33:07,502 [foster.py] => SNet: Task 2, Epoch 104/130 => Loss 27.549,  Loss1 0.694, Train_accy 78.22
2024-08-07 15:33:24,658 [foster.py] => SNet: Task 2, Epoch 105/130 => Loss 27.567,  Loss1 0.694, Train_accy 77.81
2024-08-07 15:33:43,687 [foster.py] => SNet: Task 2, Epoch 106/130 => Loss 27.558,  Loss1 0.693, Train_accy 78.51, Test_accy 75.00
2024-08-07 15:34:00,604 [foster.py] => SNet: Task 2, Epoch 107/130 => Loss 27.559,  Loss1 0.693, Train_accy 78.12
2024-08-07 15:34:17,394 [foster.py] => SNet: Task 2, Epoch 108/130 => Loss 27.570,  Loss1 0.694, Train_accy 77.87
2024-08-07 15:34:34,292 [foster.py] => SNet: Task 2, Epoch 109/130 => Loss 27.553,  Loss1 0.694, Train_accy 77.78
2024-08-07 15:34:51,041 [foster.py] => SNet: Task 2, Epoch 110/130 => Loss 27.559,  Loss1 0.694, Train_accy 77.80
2024-08-07 15:35:09,938 [foster.py] => SNet: Task 2, Epoch 111/130 => Loss 27.562,  Loss1 0.694, Train_accy 78.28, Test_accy 75.08
2024-08-07 15:35:26,961 [foster.py] => SNet: Task 2, Epoch 112/130 => Loss 27.567,  Loss1 0.694, Train_accy 77.97
2024-08-07 15:35:43,650 [foster.py] => SNet: Task 2, Epoch 113/130 => Loss 27.566,  Loss1 0.694, Train_accy 78.13
2024-08-07 15:36:00,618 [foster.py] => SNet: Task 2, Epoch 114/130 => Loss 27.571,  Loss1 0.694, Train_accy 78.13
2024-08-07 15:36:17,602 [foster.py] => SNet: Task 2, Epoch 115/130 => Loss 27.570,  Loss1 0.694, Train_accy 78.69
2024-08-07 15:36:36,340 [foster.py] => SNet: Task 2, Epoch 116/130 => Loss 27.563,  Loss1 0.694, Train_accy 78.27, Test_accy 75.07
2024-08-07 15:36:53,690 [foster.py] => SNet: Task 2, Epoch 117/130 => Loss 27.566,  Loss1 0.694, Train_accy 77.62
2024-08-07 15:37:10,473 [foster.py] => SNet: Task 2, Epoch 118/130 => Loss 27.564,  Loss1 0.694, Train_accy 77.93
2024-08-07 15:37:27,674 [foster.py] => SNet: Task 2, Epoch 119/130 => Loss 27.553,  Loss1 0.694, Train_accy 78.18
2024-08-07 15:37:44,598 [foster.py] => SNet: Task 2, Epoch 120/130 => Loss 27.561,  Loss1 0.693, Train_accy 78.58
2024-08-07 15:38:03,420 [foster.py] => SNet: Task 2, Epoch 121/130 => Loss 27.563,  Loss1 0.694, Train_accy 77.98, Test_accy 75.15
2024-08-07 15:38:20,172 [foster.py] => SNet: Task 2, Epoch 122/130 => Loss 27.548,  Loss1 0.694, Train_accy 77.92
2024-08-07 15:38:37,238 [foster.py] => SNet: Task 2, Epoch 123/130 => Loss 27.564,  Loss1 0.694, Train_accy 78.42
2024-08-07 15:38:54,186 [foster.py] => SNet: Task 2, Epoch 124/130 => Loss 27.561,  Loss1 0.694, Train_accy 78.82
2024-08-07 15:39:11,358 [foster.py] => SNet: Task 2, Epoch 125/130 => Loss 27.558,  Loss1 0.694, Train_accy 78.45
2024-08-07 15:39:30,115 [foster.py] => SNet: Task 2, Epoch 126/130 => Loss 27.557,  Loss1 0.693, Train_accy 78.59, Test_accy 75.15
2024-08-07 15:39:46,987 [foster.py] => SNet: Task 2, Epoch 127/130 => Loss 27.563,  Loss1 0.694, Train_accy 78.61
2024-08-07 15:40:03,877 [foster.py] => SNet: Task 2, Epoch 128/130 => Loss 27.562,  Loss1 0.694, Train_accy 78.02
2024-08-07 15:40:20,926 [foster.py] => SNet: Task 2, Epoch 129/130 => Loss 27.548,  Loss1 0.693, Train_accy 77.97
2024-08-07 15:40:38,033 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 27.538,  Loss1 0.694, Train_accy 78.62
2024-08-07 15:40:38,034 [foster.py] => do not weight align student!
2024-08-07 15:40:39,923 [foster.py] => darknet eval: 
2024-08-07 15:40:39,923 [foster.py] => CNN top1 curve: 75.1
2024-08-07 15:40:39,923 [foster.py] => CNN top5 curve: 94.15
2024-08-07 15:40:39,924 [foster.py] => CNN top1 平均值: 75.10
2024-08-07 15:40:39,927 [foster.py] => timees : 4558.513232469559
2024-08-07 15:40:39,928 [base.py] => Reducing exemplars...(33 per classes)
2024-08-07 15:40:53,158 [base.py] => Constructing exemplars...(33 per classes)
2024-08-07 15:41:17,429 [foster.py] => Exemplar size: 1980
2024-08-07 15:41:17,429 [trainer.py] => CNN: {'total': 77.25, '00-09': 77.9, '10-19': 65.6, '20-29': 81.3, '30-39': 76.2, '40-49': 81.9, '50-59': 80.6, 'old': 75.25, 'new': 81.25}
2024-08-07 15:41:17,429 [trainer.py] => NME: {'total': 75.68, '00-09': 77.2, '10-19': 68.2, '20-29': 77.6, '30-39': 71.4, '40-49': 81.5, '50-59': 78.2, 'old': 73.6, 'new': 79.85}
2024-08-07 15:41:17,429 [trainer.py] => CNN top1 curve: [87.15, 82.28, 77.25]
2024-08-07 15:41:17,429 [trainer.py] => CNN top5 curve: [98.3, 96.45, 94.98]
2024-08-07 15:41:17,429 [trainer.py] => NME top1 curve: [87.2, 82.42, 75.68]
2024-08-07 15:41:17,429 [trainer.py] => NME top5 curve: [98.45, 96.6, 94.38]

2024-08-07 15:41:17,429 [trainer.py] => CNN top1 平均值: 82.23
2024-08-07 15:41:17,432 [trainer.py] => All params: 1296788
2024-08-07 15:41:17,434 [trainer.py] => Trainable params: 652914
2024-08-07 15:41:17,497 [foster.py] => Learning on 60-80
2024-08-07 15:41:17,500 [foster.py] => All params: 1301968
2024-08-07 15:41:17,502 [foster.py] => Trainable params: 656794
2024-08-07 15:41:17,608 [foster.py] => per cls weights : [1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576 1.06900576
 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273
 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273
 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273 0.79298273
 0.79298273 0.79298273]
2024-08-07 15:41:29,576 [foster.py] => Task 3, Epoch 1/170 => Loss 7.251, Loss_clf 2.578, Loss_fe 2.086, Loss_kd 1.938, Train_accy 42.15
2024-08-07 15:41:43,773 [foster.py] => Task 3, Epoch 2/170 => Loss 6.023, Loss_clf 1.835, Loss_fe 1.644, Loss_kd 1.906, Train_accy 49.83, Test_accy 62.94
2024-08-07 15:41:58,073 [foster.py] => Task 3, Epoch 3/170 => Loss 5.834, Loss_clf 1.713, Loss_fe 1.562, Loss_kd 1.917, Train_accy 52.57, Test_accy 62.21
2024-08-07 15:42:12,344 [foster.py] => Task 3, Epoch 4/170 => Loss 5.726, Loss_clf 1.682, Loss_fe 1.492, Loss_kd 1.911, Train_accy 52.85, Test_accy 62.25
2024-08-07 15:42:26,857 [foster.py] => Task 3, Epoch 5/170 => Loss 5.705, Loss_clf 1.684, Loss_fe 1.472, Loss_kd 1.910, Train_accy 54.42, Test_accy 65.38
2024-08-07 15:42:38,779 [foster.py] => Task 3, Epoch 6/170 => Loss 5.679, Loss_clf 1.669, Loss_fe 1.456, Loss_kd 1.912, Train_accy 54.69
2024-08-07 15:42:53,068 [foster.py] => Task 3, Epoch 7/170 => Loss 5.555, Loss_clf 1.596, Loss_fe 1.405, Loss_kd 1.912, Train_accy 55.63, Test_accy 66.62
2024-08-07 15:43:07,353 [foster.py] => Task 3, Epoch 8/170 => Loss 5.539, Loss_clf 1.595, Loss_fe 1.393, Loss_kd 1.910, Train_accy 55.60, Test_accy 65.51
2024-08-07 15:43:21,725 [foster.py] => Task 3, Epoch 9/170 => Loss 5.481, Loss_clf 1.565, Loss_fe 1.366, Loss_kd 1.909, Train_accy 56.19, Test_accy 64.20
2024-08-07 15:43:36,088 [foster.py] => Task 3, Epoch 10/170 => Loss 5.464, Loss_clf 1.554, Loss_fe 1.355, Loss_kd 1.913, Train_accy 56.37, Test_accy 65.00
2024-08-07 15:43:47,825 [foster.py] => Task 3, Epoch 11/170 => Loss 5.358, Loss_clf 1.480, Loss_fe 1.324, Loss_kd 1.913, Train_accy 57.55
2024-08-07 15:44:02,125 [foster.py] => Task 3, Epoch 12/170 => Loss 5.358, Loss_clf 1.488, Loss_fe 1.323, Loss_kd 1.908, Train_accy 57.57, Test_accy 64.86
2024-08-07 15:44:16,642 [foster.py] => Task 3, Epoch 13/170 => Loss 5.475, Loss_clf 1.593, Loss_fe 1.328, Loss_kd 1.913, Train_accy 56.35, Test_accy 66.34
2024-08-07 15:44:30,907 [foster.py] => Task 3, Epoch 14/170 => Loss 5.414, Loss_clf 1.563, Loss_fe 1.298, Loss_kd 1.912, Train_accy 57.20, Test_accy 66.09
2024-08-07 15:44:45,349 [foster.py] => Task 3, Epoch 15/170 => Loss 5.445, Loss_clf 1.588, Loss_fe 1.298, Loss_kd 1.916, Train_accy 57.11, Test_accy 66.68
2024-08-07 15:44:57,287 [foster.py] => Task 3, Epoch 16/170 => Loss 5.397, Loss_clf 1.540, Loss_fe 1.289, Loss_kd 1.923, Train_accy 57.56
2024-08-07 15:45:12,188 [foster.py] => Task 3, Epoch 17/170 => Loss 5.262, Loss_clf 1.440, Loss_fe 1.262, Loss_kd 1.918, Train_accy 59.02, Test_accy 66.01
2024-08-07 15:45:26,599 [foster.py] => Task 3, Epoch 18/170 => Loss 5.264, Loss_clf 1.469, Loss_fe 1.240, Loss_kd 1.913, Train_accy 58.81, Test_accy 66.31
2024-08-07 15:45:41,027 [foster.py] => Task 3, Epoch 19/170 => Loss 5.304, Loss_clf 1.502, Loss_fe 1.249, Loss_kd 1.912, Train_accy 57.90, Test_accy 66.97
2024-08-07 15:45:55,333 [foster.py] => Task 3, Epoch 20/170 => Loss 5.278, Loss_clf 1.470, Loss_fe 1.254, Loss_kd 1.913, Train_accy 58.80, Test_accy 65.89
2024-08-07 15:46:07,285 [foster.py] => Task 3, Epoch 21/170 => Loss 5.161, Loss_clf 1.393, Loss_fe 1.220, Loss_kd 1.908, Train_accy 59.54
2024-08-07 15:46:21,702 [foster.py] => Task 3, Epoch 22/170 => Loss 5.241, Loss_clf 1.456, Loss_fe 1.228, Loss_kd 1.914, Train_accy 59.03, Test_accy 67.47
2024-08-07 15:46:35,882 [foster.py] => Task 3, Epoch 23/170 => Loss 5.087, Loss_clf 1.339, Loss_fe 1.192, Loss_kd 1.914, Train_accy 60.91, Test_accy 64.19
2024-08-07 15:46:50,146 [foster.py] => Task 3, Epoch 24/170 => Loss 5.148, Loss_clf 1.403, Loss_fe 1.195, Loss_kd 1.909, Train_accy 59.28, Test_accy 64.82
2024-08-07 15:47:04,434 [foster.py] => Task 3, Epoch 25/170 => Loss 5.187, Loss_clf 1.431, Loss_fe 1.209, Loss_kd 1.907, Train_accy 58.78, Test_accy 67.20
2024-08-07 15:47:16,355 [foster.py] => Task 3, Epoch 26/170 => Loss 5.098, Loss_clf 1.373, Loss_fe 1.180, Loss_kd 1.906, Train_accy 60.17
2024-08-07 15:47:30,597 [foster.py] => Task 3, Epoch 27/170 => Loss 5.092, Loss_clf 1.353, Loss_fe 1.182, Loss_kd 1.914, Train_accy 60.90, Test_accy 65.18
2024-08-07 15:47:44,919 [foster.py] => Task 3, Epoch 28/170 => Loss 5.128, Loss_clf 1.399, Loss_fe 1.178, Loss_kd 1.910, Train_accy 60.06, Test_accy 67.64
2024-08-07 15:47:59,115 [foster.py] => Task 3, Epoch 29/170 => Loss 5.136, Loss_clf 1.416, Loss_fe 1.166, Loss_kd 1.913, Train_accy 60.46, Test_accy 67.26
2024-08-07 15:48:13,342 [foster.py] => Task 3, Epoch 30/170 => Loss 5.108, Loss_clf 1.381, Loss_fe 1.164, Loss_kd 1.919, Train_accy 60.72, Test_accy 66.20
2024-08-07 15:48:25,007 [foster.py] => Task 3, Epoch 31/170 => Loss 5.108, Loss_clf 1.389, Loss_fe 1.169, Loss_kd 1.910, Train_accy 60.18
2024-08-07 15:48:39,375 [foster.py] => Task 3, Epoch 32/170 => Loss 5.045, Loss_clf 1.357, Loss_fe 1.138, Loss_kd 1.910, Train_accy 61.44, Test_accy 67.14
2024-08-07 15:48:53,979 [foster.py] => Task 3, Epoch 33/170 => Loss 5.053, Loss_clf 1.352, Loss_fe 1.149, Loss_kd 1.911, Train_accy 61.59, Test_accy 66.30
2024-08-07 15:49:08,530 [foster.py] => Task 3, Epoch 34/170 => Loss 5.059, Loss_clf 1.368, Loss_fe 1.147, Loss_kd 1.905, Train_accy 60.76, Test_accy 66.14
2024-08-07 15:49:22,794 [foster.py] => Task 3, Epoch 35/170 => Loss 5.071, Loss_clf 1.381, Loss_fe 1.140, Loss_kd 1.910, Train_accy 60.73, Test_accy 63.56
2024-08-07 15:49:34,553 [foster.py] => Task 3, Epoch 36/170 => Loss 5.102, Loss_clf 1.394, Loss_fe 1.159, Loss_kd 1.909, Train_accy 60.38
2024-08-07 15:49:48,824 [foster.py] => Task 3, Epoch 37/170 => Loss 5.020, Loss_clf 1.347, Loss_fe 1.118, Loss_kd 1.913, Train_accy 61.13, Test_accy 65.91
2024-08-07 15:50:03,101 [foster.py] => Task 3, Epoch 38/170 => Loss 4.984, Loss_clf 1.310, Loss_fe 1.127, Loss_kd 1.907, Train_accy 61.14, Test_accy 66.69
2024-08-07 15:50:17,294 [foster.py] => Task 3, Epoch 39/170 => Loss 5.012, Loss_clf 1.357, Loss_fe 1.108, Loss_kd 1.907, Train_accy 61.22, Test_accy 67.58
2024-08-07 15:50:31,948 [foster.py] => Task 3, Epoch 40/170 => Loss 5.020, Loss_clf 1.356, Loss_fe 1.118, Loss_kd 1.906, Train_accy 61.52, Test_accy 65.70
2024-08-07 15:50:43,873 [foster.py] => Task 3, Epoch 41/170 => Loss 4.971, Loss_clf 1.314, Loss_fe 1.104, Loss_kd 1.912, Train_accy 62.30
2024-08-07 15:50:58,240 [foster.py] => Task 3, Epoch 42/170 => Loss 5.029, Loss_clf 1.357, Loss_fe 1.105, Loss_kd 1.922, Train_accy 61.57, Test_accy 65.70
2024-08-07 15:51:12,509 [foster.py] => Task 3, Epoch 43/170 => Loss 5.028, Loss_clf 1.372, Loss_fe 1.103, Loss_kd 1.912, Train_accy 61.33, Test_accy 67.36
2024-08-07 15:51:26,774 [foster.py] => Task 3, Epoch 44/170 => Loss 4.970, Loss_clf 1.325, Loss_fe 1.095, Loss_kd 1.910, Train_accy 61.93, Test_accy 69.59
2024-08-07 15:51:41,056 [foster.py] => Task 3, Epoch 45/170 => Loss 4.919, Loss_clf 1.289, Loss_fe 1.083, Loss_kd 1.907, Train_accy 62.42, Test_accy 68.45
2024-08-07 15:51:52,826 [foster.py] => Task 3, Epoch 46/170 => Loss 4.886, Loss_clf 1.260, Loss_fe 1.072, Loss_kd 1.913, Train_accy 63.06
2024-08-07 15:52:07,061 [foster.py] => Task 3, Epoch 47/170 => Loss 4.857, Loss_clf 1.244, Loss_fe 1.069, Loss_kd 1.905, Train_accy 62.95, Test_accy 68.84
2024-08-07 15:52:21,361 [foster.py] => Task 3, Epoch 48/170 => Loss 4.872, Loss_clf 1.263, Loss_fe 1.065, Loss_kd 1.905, Train_accy 63.16, Test_accy 68.78
2024-08-07 15:52:35,887 [foster.py] => Task 3, Epoch 49/170 => Loss 4.889, Loss_clf 1.254, Loss_fe 1.084, Loss_kd 1.910, Train_accy 62.68, Test_accy 66.29
2024-08-07 15:52:50,083 [foster.py] => Task 3, Epoch 50/170 => Loss 4.848, Loss_clf 1.252, Loss_fe 1.047, Loss_kd 1.908, Train_accy 63.80, Test_accy 68.51
2024-08-07 15:53:01,829 [foster.py] => Task 3, Epoch 51/170 => Loss 4.806, Loss_clf 1.209, Loss_fe 1.045, Loss_kd 1.911, Train_accy 63.51
2024-08-07 15:53:16,133 [foster.py] => Task 3, Epoch 52/170 => Loss 4.832, Loss_clf 1.234, Loss_fe 1.048, Loss_kd 1.910, Train_accy 63.84, Test_accy 68.01
2024-08-07 15:53:30,505 [foster.py] => Task 3, Epoch 53/170 => Loss 4.802, Loss_clf 1.218, Loss_fe 1.041, Loss_kd 1.905, Train_accy 63.41, Test_accy 67.50
2024-08-07 15:53:44,830 [foster.py] => Task 3, Epoch 54/170 => Loss 4.858, Loss_clf 1.267, Loss_fe 1.037, Loss_kd 1.913, Train_accy 63.16, Test_accy 67.44
2024-08-07 15:53:59,076 [foster.py] => Task 3, Epoch 55/170 => Loss 4.824, Loss_clf 1.229, Loss_fe 1.043, Loss_kd 1.911, Train_accy 62.84, Test_accy 68.03
2024-08-07 15:54:10,776 [foster.py] => Task 3, Epoch 56/170 => Loss 4.817, Loss_clf 1.240, Loss_fe 1.029, Loss_kd 1.908, Train_accy 63.44
2024-08-07 15:54:25,035 [foster.py] => Task 3, Epoch 57/170 => Loss 4.845, Loss_clf 1.248, Loss_fe 1.046, Loss_kd 1.910, Train_accy 63.17, Test_accy 67.80
2024-08-07 15:54:39,417 [foster.py] => Task 3, Epoch 58/170 => Loss 4.791, Loss_clf 1.226, Loss_fe 1.016, Loss_kd 1.908, Train_accy 63.27, Test_accy 66.76
2024-08-07 15:54:53,739 [foster.py] => Task 3, Epoch 59/170 => Loss 4.842, Loss_clf 1.253, Loss_fe 1.038, Loss_kd 1.911, Train_accy 63.81, Test_accy 69.54
2024-08-07 15:55:08,184 [foster.py] => Task 3, Epoch 60/170 => Loss 4.719, Loss_clf 1.171, Loss_fe 0.998, Loss_kd 1.909, Train_accy 64.99, Test_accy 68.46
2024-08-07 15:55:20,003 [foster.py] => Task 3, Epoch 61/170 => Loss 4.796, Loss_clf 1.230, Loss_fe 1.014, Loss_kd 1.911, Train_accy 63.17
2024-08-07 15:55:34,272 [foster.py] => Task 3, Epoch 62/170 => Loss 4.754, Loss_clf 1.197, Loss_fe 1.014, Loss_kd 1.904, Train_accy 63.37, Test_accy 67.85
2024-08-07 15:55:48,655 [foster.py] => Task 3, Epoch 63/170 => Loss 4.736, Loss_clf 1.187, Loss_fe 1.004, Loss_kd 1.906, Train_accy 64.82, Test_accy 67.88
2024-08-07 15:56:02,903 [foster.py] => Task 3, Epoch 64/170 => Loss 4.736, Loss_clf 1.191, Loss_fe 0.994, Loss_kd 1.910, Train_accy 63.86, Test_accy 66.81
2024-08-07 15:56:17,255 [foster.py] => Task 3, Epoch 65/170 => Loss 4.673, Loss_clf 1.152, Loss_fe 0.985, Loss_kd 1.899, Train_accy 64.82, Test_accy 68.86
2024-08-07 15:56:29,154 [foster.py] => Task 3, Epoch 66/170 => Loss 4.715, Loss_clf 1.178, Loss_fe 0.987, Loss_kd 1.910, Train_accy 64.63
2024-08-07 15:56:43,528 [foster.py] => Task 3, Epoch 67/170 => Loss 4.690, Loss_clf 1.160, Loss_fe 0.983, Loss_kd 1.907, Train_accy 64.42, Test_accy 68.59
2024-08-07 15:56:57,913 [foster.py] => Task 3, Epoch 68/170 => Loss 4.628, Loss_clf 1.116, Loss_fe 0.963, Loss_kd 1.909, Train_accy 66.00, Test_accy 68.30
2024-08-07 15:57:12,150 [foster.py] => Task 3, Epoch 69/170 => Loss 4.635, Loss_clf 1.141, Loss_fe 0.950, Loss_kd 1.905, Train_accy 65.16, Test_accy 67.94
2024-08-07 15:57:26,487 [foster.py] => Task 3, Epoch 70/170 => Loss 4.633, Loss_clf 1.139, Loss_fe 0.956, Loss_kd 1.900, Train_accy 65.43, Test_accy 66.55
2024-08-07 15:57:38,197 [foster.py] => Task 3, Epoch 71/170 => Loss 4.651, Loss_clf 1.138, Loss_fe 0.965, Loss_kd 1.909, Train_accy 65.73
2024-08-07 15:57:52,409 [foster.py] => Task 3, Epoch 72/170 => Loss 4.662, Loss_clf 1.157, Loss_fe 0.955, Loss_kd 1.909, Train_accy 65.90, Test_accy 66.81
2024-08-07 15:58:06,617 [foster.py] => Task 3, Epoch 73/170 => Loss 4.701, Loss_clf 1.178, Loss_fe 0.960, Loss_kd 1.919, Train_accy 65.08, Test_accy 69.39
2024-08-07 15:58:20,945 [foster.py] => Task 3, Epoch 74/170 => Loss 4.595, Loss_clf 1.111, Loss_fe 0.932, Loss_kd 1.911, Train_accy 66.22, Test_accy 68.68
2024-08-07 15:58:35,215 [foster.py] => Task 3, Epoch 75/170 => Loss 4.616, Loss_clf 1.122, Loss_fe 0.945, Loss_kd 1.908, Train_accy 66.07, Test_accy 68.20
2024-08-07 15:58:46,921 [foster.py] => Task 3, Epoch 76/170 => Loss 4.539, Loss_clf 1.085, Loss_fe 0.920, Loss_kd 1.898, Train_accy 66.83
2024-08-07 15:59:01,080 [foster.py] => Task 3, Epoch 77/170 => Loss 4.593, Loss_clf 1.108, Loss_fe 0.937, Loss_kd 1.908, Train_accy 66.18, Test_accy 68.58
2024-08-07 15:59:15,773 [foster.py] => Task 3, Epoch 78/170 => Loss 4.599, Loss_clf 1.106, Loss_fe 0.942, Loss_kd 1.909, Train_accy 66.15, Test_accy 69.30
2024-08-07 15:59:30,554 [foster.py] => Task 3, Epoch 79/170 => Loss 4.546, Loss_clf 1.093, Loss_fe 0.915, Loss_kd 1.901, Train_accy 66.34, Test_accy 69.81
2024-08-07 15:59:44,927 [foster.py] => Task 3, Epoch 80/170 => Loss 4.508, Loss_clf 1.061, Loss_fe 0.905, Loss_kd 1.904, Train_accy 67.33, Test_accy 68.84
2024-08-07 15:59:56,788 [foster.py] => Task 3, Epoch 81/170 => Loss 4.498, Loss_clf 1.061, Loss_fe 0.893, Loss_kd 1.905, Train_accy 67.22
2024-08-07 16:00:11,178 [foster.py] => Task 3, Epoch 82/170 => Loss 4.507, Loss_clf 1.067, Loss_fe 0.901, Loss_kd 1.901, Train_accy 67.00, Test_accy 69.88
2024-08-07 16:00:25,696 [foster.py] => Task 3, Epoch 83/170 => Loss 4.496, Loss_clf 1.060, Loss_fe 0.886, Loss_kd 1.910, Train_accy 67.16, Test_accy 69.22
2024-08-07 16:00:40,141 [foster.py] => Task 3, Epoch 84/170 => Loss 4.495, Loss_clf 1.057, Loss_fe 0.892, Loss_kd 1.906, Train_accy 67.60, Test_accy 69.12
2024-08-07 16:00:54,544 [foster.py] => Task 3, Epoch 85/170 => Loss 4.542, Loss_clf 1.082, Loss_fe 0.910, Loss_kd 1.909, Train_accy 66.78, Test_accy 69.78
2024-08-07 16:01:06,434 [foster.py] => Task 3, Epoch 86/170 => Loss 4.487, Loss_clf 1.047, Loss_fe 0.889, Loss_kd 1.910, Train_accy 67.63
2024-08-07 16:01:21,093 [foster.py] => Task 3, Epoch 87/170 => Loss 4.453, Loss_clf 1.030, Loss_fe 0.867, Loss_kd 1.914, Train_accy 67.63, Test_accy 69.38
2024-08-07 16:01:35,307 [foster.py] => Task 3, Epoch 88/170 => Loss 4.430, Loss_clf 1.019, Loss_fe 0.864, Loss_kd 1.907, Train_accy 68.31, Test_accy 69.60
2024-08-07 16:01:49,593 [foster.py] => Task 3, Epoch 89/170 => Loss 4.412, Loss_clf 1.012, Loss_fe 0.852, Loss_kd 1.908, Train_accy 68.37, Test_accy 69.49
2024-08-07 16:02:03,936 [foster.py] => Task 3, Epoch 90/170 => Loss 4.403, Loss_clf 1.008, Loss_fe 0.852, Loss_kd 1.904, Train_accy 68.64, Test_accy 70.36
2024-08-07 16:02:15,695 [foster.py] => Task 3, Epoch 91/170 => Loss 4.373, Loss_clf 0.992, Loss_fe 0.826, Loss_kd 1.914, Train_accy 69.52
2024-08-07 16:02:29,944 [foster.py] => Task 3, Epoch 92/170 => Loss 4.385, Loss_clf 0.996, Loss_fe 0.843, Loss_kd 1.907, Train_accy 68.51, Test_accy 69.20
2024-08-07 16:02:44,276 [foster.py] => Task 3, Epoch 93/170 => Loss 4.387, Loss_clf 1.012, Loss_fe 0.833, Loss_kd 1.903, Train_accy 68.44, Test_accy 70.35
2024-08-07 16:02:58,614 [foster.py] => Task 3, Epoch 94/170 => Loss 4.381, Loss_clf 0.993, Loss_fe 0.841, Loss_kd 1.908, Train_accy 69.04, Test_accy 69.72
2024-08-07 16:03:13,437 [foster.py] => Task 3, Epoch 95/170 => Loss 4.308, Loss_clf 0.964, Loss_fe 0.808, Loss_kd 1.900, Train_accy 69.48, Test_accy 70.20
2024-08-07 16:03:25,312 [foster.py] => Task 3, Epoch 96/170 => Loss 4.275, Loss_clf 0.937, Loss_fe 0.801, Loss_kd 1.899, Train_accy 70.09
2024-08-07 16:03:39,601 [foster.py] => Task 3, Epoch 97/170 => Loss 4.312, Loss_clf 0.965, Loss_fe 0.807, Loss_kd 1.902, Train_accy 69.20, Test_accy 69.00
2024-08-07 16:03:53,843 [foster.py] => Task 3, Epoch 98/170 => Loss 4.274, Loss_clf 0.938, Loss_fe 0.798, Loss_kd 1.900, Train_accy 69.87, Test_accy 69.85
2024-08-07 16:04:08,171 [foster.py] => Task 3, Epoch 99/170 => Loss 4.308, Loss_clf 0.962, Loss_fe 0.796, Loss_kd 1.910, Train_accy 69.87, Test_accy 69.11
2024-08-07 16:04:22,456 [foster.py] => Task 3, Epoch 100/170 => Loss 4.253, Loss_clf 0.926, Loss_fe 0.784, Loss_kd 1.904, Train_accy 70.53, Test_accy 69.65
2024-08-07 16:04:34,447 [foster.py] => Task 3, Epoch 101/170 => Loss 4.271, Loss_clf 0.946, Loss_fe 0.787, Loss_kd 1.901, Train_accy 70.08
2024-08-07 16:04:48,697 [foster.py] => Task 3, Epoch 102/170 => Loss 4.209, Loss_clf 0.911, Loss_fe 0.761, Loss_kd 1.900, Train_accy 70.53, Test_accy 68.81
2024-08-07 16:05:03,181 [foster.py] => Task 3, Epoch 103/170 => Loss 4.165, Loss_clf 0.884, Loss_fe 0.741, Loss_kd 1.903, Train_accy 71.49, Test_accy 70.49
2024-08-07 16:05:17,496 [foster.py] => Task 3, Epoch 104/170 => Loss 4.192, Loss_clf 0.905, Loss_fe 0.747, Loss_kd 1.902, Train_accy 71.70, Test_accy 70.28
2024-08-07 16:05:31,923 [foster.py] => Task 3, Epoch 105/170 => Loss 4.190, Loss_clf 0.904, Loss_fe 0.748, Loss_kd 1.901, Train_accy 71.15, Test_accy 70.89
2024-08-07 16:05:43,728 [foster.py] => Task 3, Epoch 106/170 => Loss 4.165, Loss_clf 0.888, Loss_fe 0.742, Loss_kd 1.898, Train_accy 71.59
2024-08-07 16:05:57,991 [foster.py] => Task 3, Epoch 107/170 => Loss 4.230, Loss_clf 0.917, Loss_fe 0.770, Loss_kd 1.904, Train_accy 70.87, Test_accy 71.03
2024-08-07 16:06:12,256 [foster.py] => Task 3, Epoch 108/170 => Loss 4.135, Loss_clf 0.866, Loss_fe 0.729, Loss_kd 1.902, Train_accy 72.59, Test_accy 70.41
2024-08-07 16:06:26,648 [foster.py] => Task 3, Epoch 109/170 => Loss 4.189, Loss_clf 0.890, Loss_fe 0.747, Loss_kd 1.911, Train_accy 71.67, Test_accy 70.66
2024-08-07 16:06:41,115 [foster.py] => Task 3, Epoch 110/170 => Loss 4.120, Loss_clf 0.866, Loss_fe 0.715, Loss_kd 1.901, Train_accy 72.70, Test_accy 70.35
2024-08-07 16:06:53,255 [foster.py] => Task 3, Epoch 111/170 => Loss 4.156, Loss_clf 0.884, Loss_fe 0.727, Loss_kd 1.905, Train_accy 71.19
2024-08-07 16:07:07,919 [foster.py] => Task 3, Epoch 112/170 => Loss 4.092, Loss_clf 0.844, Loss_fe 0.700, Loss_kd 1.908, Train_accy 72.87, Test_accy 70.41
2024-08-07 16:07:22,264 [foster.py] => Task 3, Epoch 113/170 => Loss 4.081, Loss_clf 0.840, Loss_fe 0.699, Loss_kd 1.904, Train_accy 72.98, Test_accy 70.47
2024-08-07 16:07:36,522 [foster.py] => Task 3, Epoch 114/170 => Loss 4.112, Loss_clf 0.855, Loss_fe 0.706, Loss_kd 1.910, Train_accy 72.50, Test_accy 69.89
2024-08-07 16:07:50,886 [foster.py] => Task 3, Epoch 115/170 => Loss 4.017, Loss_clf 0.808, Loss_fe 0.673, Loss_kd 1.898, Train_accy 73.62, Test_accy 70.85
2024-08-07 16:08:02,866 [foster.py] => Task 3, Epoch 116/170 => Loss 4.015, Loss_clf 0.815, Loss_fe 0.667, Loss_kd 1.897, Train_accy 74.15
2024-08-07 16:08:17,196 [foster.py] => Task 3, Epoch 117/170 => Loss 3.990, Loss_clf 0.801, Loss_fe 0.660, Loss_kd 1.894, Train_accy 74.18, Test_accy 70.68
2024-08-07 16:08:31,418 [foster.py] => Task 3, Epoch 118/170 => Loss 3.996, Loss_clf 0.800, Loss_fe 0.657, Loss_kd 1.900, Train_accy 74.64, Test_accy 70.15
2024-08-07 16:08:45,762 [foster.py] => Task 3, Epoch 119/170 => Loss 3.950, Loss_clf 0.788, Loss_fe 0.637, Loss_kd 1.891, Train_accy 74.61, Test_accy 71.06
2024-08-07 16:09:00,263 [foster.py] => Task 3, Epoch 120/170 => Loss 4.018, Loss_clf 0.812, Loss_fe 0.663, Loss_kd 1.904, Train_accy 74.45, Test_accy 71.49
2024-08-07 16:09:12,142 [foster.py] => Task 3, Epoch 121/170 => Loss 3.960, Loss_clf 0.779, Loss_fe 0.641, Loss_kd 1.902, Train_accy 75.03
2024-08-07 16:09:26,547 [foster.py] => Task 3, Epoch 122/170 => Loss 4.007, Loss_clf 0.805, Loss_fe 0.664, Loss_kd 1.901, Train_accy 74.19, Test_accy 71.28
2024-08-07 16:09:41,043 [foster.py] => Task 3, Epoch 123/170 => Loss 3.933, Loss_clf 0.763, Loss_fe 0.626, Loss_kd 1.905, Train_accy 75.23, Test_accy 70.86
2024-08-07 16:09:55,256 [foster.py] => Task 3, Epoch 124/170 => Loss 3.868, Loss_clf 0.740, Loss_fe 0.590, Loss_kd 1.900, Train_accy 75.52, Test_accy 71.59
2024-08-07 16:10:09,658 [foster.py] => Task 3, Epoch 125/170 => Loss 3.923, Loss_clf 0.764, Loss_fe 0.620, Loss_kd 1.901, Train_accy 75.33, Test_accy 71.32
2024-08-07 16:10:21,366 [foster.py] => Task 3, Epoch 126/170 => Loss 3.868, Loss_clf 0.729, Loss_fe 0.594, Loss_kd 1.905, Train_accy 76.74
2024-08-07 16:10:35,743 [foster.py] => Task 3, Epoch 127/170 => Loss 3.857, Loss_clf 0.730, Loss_fe 0.589, Loss_kd 1.900, Train_accy 76.29, Test_accy 70.84
2024-08-07 16:10:50,072 [foster.py] => Task 3, Epoch 128/170 => Loss 3.875, Loss_clf 0.738, Loss_fe 0.596, Loss_kd 1.903, Train_accy 75.92, Test_accy 71.78
2024-08-07 16:11:04,792 [foster.py] => Task 3, Epoch 129/170 => Loss 3.837, Loss_clf 0.717, Loss_fe 0.579, Loss_kd 1.903, Train_accy 76.74, Test_accy 71.28
2024-08-07 16:11:19,773 [foster.py] => Task 3, Epoch 130/170 => Loss 3.798, Loss_clf 0.698, Loss_fe 0.568, Loss_kd 1.896, Train_accy 77.02, Test_accy 71.61
2024-08-07 16:11:31,688 [foster.py] => Task 3, Epoch 131/170 => Loss 3.805, Loss_clf 0.703, Loss_fe 0.563, Loss_kd 1.901, Train_accy 77.13
2024-08-07 16:11:45,955 [foster.py] => Task 3, Epoch 132/170 => Loss 3.842, Loss_clf 0.723, Loss_fe 0.573, Loss_kd 1.907, Train_accy 76.54, Test_accy 71.60
2024-08-07 16:12:00,293 [foster.py] => Task 3, Epoch 133/170 => Loss 3.788, Loss_clf 0.695, Loss_fe 0.555, Loss_kd 1.901, Train_accy 77.12, Test_accy 71.86
2024-08-07 16:12:14,620 [foster.py] => Task 3, Epoch 134/170 => Loss 3.791, Loss_clf 0.695, Loss_fe 0.550, Loss_kd 1.907, Train_accy 77.34, Test_accy 71.55
2024-08-07 16:12:28,906 [foster.py] => Task 3, Epoch 135/170 => Loss 3.791, Loss_clf 0.705, Loss_fe 0.550, Loss_kd 1.900, Train_accy 77.58, Test_accy 71.88
2024-08-07 16:12:40,842 [foster.py] => Task 3, Epoch 136/170 => Loss 3.753, Loss_clf 0.678, Loss_fe 0.536, Loss_kd 1.901, Train_accy 78.24
2024-08-07 16:12:55,239 [foster.py] => Task 3, Epoch 137/170 => Loss 3.722, Loss_clf 0.665, Loss_fe 0.524, Loss_kd 1.897, Train_accy 78.16, Test_accy 71.94
2024-08-07 16:13:09,523 [foster.py] => Task 3, Epoch 138/170 => Loss 3.705, Loss_clf 0.652, Loss_fe 0.518, Loss_kd 1.898, Train_accy 78.46, Test_accy 72.08
2024-08-07 16:13:23,782 [foster.py] => Task 3, Epoch 139/170 => Loss 3.722, Loss_clf 0.661, Loss_fe 0.523, Loss_kd 1.901, Train_accy 78.37, Test_accy 72.08
2024-08-07 16:13:38,081 [foster.py] => Task 3, Epoch 140/170 => Loss 3.693, Loss_clf 0.647, Loss_fe 0.508, Loss_kd 1.900, Train_accy 78.98, Test_accy 72.28
2024-08-07 16:13:49,822 [foster.py] => Task 3, Epoch 141/170 => Loss 3.719, Loss_clf 0.658, Loss_fe 0.517, Loss_kd 1.905, Train_accy 78.65
2024-08-07 16:14:04,116 [foster.py] => Task 3, Epoch 142/170 => Loss 3.641, Loss_clf 0.623, Loss_fe 0.491, Loss_kd 1.893, Train_accy 79.69, Test_accy 72.03
2024-08-07 16:14:18,366 [foster.py] => Task 3, Epoch 143/170 => Loss 3.660, Loss_clf 0.631, Loss_fe 0.486, Loss_kd 1.905, Train_accy 79.67, Test_accy 72.19
2024-08-07 16:14:32,921 [foster.py] => Task 3, Epoch 144/170 => Loss 3.648, Loss_clf 0.620, Loss_fe 0.487, Loss_kd 1.903, Train_accy 79.32, Test_accy 72.04
2024-08-07 16:14:47,277 [foster.py] => Task 3, Epoch 145/170 => Loss 3.627, Loss_clf 0.610, Loss_fe 0.476, Loss_kd 1.902, Train_accy 80.30, Test_accy 72.30
2024-08-07 16:14:59,238 [foster.py] => Task 3, Epoch 146/170 => Loss 3.676, Loss_clf 0.640, Loss_fe 0.490, Loss_kd 1.907, Train_accy 79.61
2024-08-07 16:15:13,530 [foster.py] => Task 3, Epoch 147/170 => Loss 3.641, Loss_clf 0.626, Loss_fe 0.480, Loss_kd 1.899, Train_accy 79.89, Test_accy 72.41
2024-08-07 16:15:27,883 [foster.py] => Task 3, Epoch 148/170 => Loss 3.611, Loss_clf 0.607, Loss_fe 0.464, Loss_kd 1.902, Train_accy 80.43, Test_accy 72.34
2024-08-07 16:15:42,109 [foster.py] => Task 3, Epoch 149/170 => Loss 3.604, Loss_clf 0.605, Loss_fe 0.471, Loss_kd 1.893, Train_accy 80.02, Test_accy 72.35
2024-08-07 16:15:56,521 [foster.py] => Task 3, Epoch 150/170 => Loss 3.638, Loss_clf 0.621, Loss_fe 0.474, Loss_kd 1.905, Train_accy 79.63, Test_accy 72.40
2024-08-07 16:16:08,159 [foster.py] => Task 3, Epoch 151/170 => Loss 3.642, Loss_clf 0.629, Loss_fe 0.475, Loss_kd 1.901, Train_accy 80.26
2024-08-07 16:16:22,656 [foster.py] => Task 3, Epoch 152/170 => Loss 3.568, Loss_clf 0.583, Loss_fe 0.451, Loss_kd 1.898, Train_accy 80.60, Test_accy 72.76
2024-08-07 16:16:36,972 [foster.py] => Task 3, Epoch 153/170 => Loss 3.616, Loss_clf 0.608, Loss_fe 0.462, Loss_kd 1.907, Train_accy 80.47, Test_accy 72.50
2024-08-07 16:16:51,118 [foster.py] => Task 3, Epoch 154/170 => Loss 3.595, Loss_clf 0.601, Loss_fe 0.457, Loss_kd 1.901, Train_accy 80.53, Test_accy 72.53
2024-08-07 16:17:05,450 [foster.py] => Task 3, Epoch 155/170 => Loss 3.562, Loss_clf 0.581, Loss_fe 0.444, Loss_kd 1.900, Train_accy 81.25, Test_accy 72.56
2024-08-07 16:17:17,210 [foster.py] => Task 3, Epoch 156/170 => Loss 3.593, Loss_clf 0.596, Loss_fe 0.451, Loss_kd 1.907, Train_accy 80.53
2024-08-07 16:17:31,765 [foster.py] => Task 3, Epoch 157/170 => Loss 3.566, Loss_clf 0.583, Loss_fe 0.445, Loss_kd 1.901, Train_accy 81.17, Test_accy 72.66
2024-08-07 16:17:45,999 [foster.py] => Task 3, Epoch 158/170 => Loss 3.514, Loss_clf 0.559, Loss_fe 0.422, Loss_kd 1.897, Train_accy 81.35, Test_accy 72.54
2024-08-07 16:18:00,233 [foster.py] => Task 3, Epoch 159/170 => Loss 3.608, Loss_clf 0.609, Loss_fe 0.445, Loss_kd 1.913, Train_accy 80.30, Test_accy 72.51
2024-08-07 16:18:14,579 [foster.py] => Task 3, Epoch 160/170 => Loss 3.516, Loss_clf 0.560, Loss_fe 0.414, Loss_kd 1.904, Train_accy 81.19, Test_accy 72.62
2024-08-07 16:18:26,431 [foster.py] => Task 3, Epoch 161/170 => Loss 3.554, Loss_clf 0.578, Loss_fe 0.437, Loss_kd 1.901, Train_accy 80.83
2024-08-07 16:18:40,842 [foster.py] => Task 3, Epoch 162/170 => Loss 3.565, Loss_clf 0.587, Loss_fe 0.439, Loss_kd 1.902, Train_accy 81.34, Test_accy 72.82
2024-08-07 16:18:55,249 [foster.py] => Task 3, Epoch 163/170 => Loss 3.539, Loss_clf 0.574, Loss_fe 0.430, Loss_kd 1.899, Train_accy 81.29, Test_accy 72.68
2024-08-07 16:19:09,557 [foster.py] => Task 3, Epoch 164/170 => Loss 3.555, Loss_clf 0.574, Loss_fe 0.433, Loss_kd 1.907, Train_accy 81.62, Test_accy 72.47
2024-08-07 16:19:24,016 [foster.py] => Task 3, Epoch 165/170 => Loss 3.585, Loss_clf 0.595, Loss_fe 0.449, Loss_kd 1.903, Train_accy 80.94, Test_accy 72.59
2024-08-07 16:19:35,777 [foster.py] => Task 3, Epoch 166/170 => Loss 3.538, Loss_clf 0.567, Loss_fe 0.427, Loss_kd 1.905, Train_accy 81.45
2024-08-07 16:19:50,201 [foster.py] => Task 3, Epoch 167/170 => Loss 3.547, Loss_clf 0.580, Loss_fe 0.429, Loss_kd 1.900, Train_accy 81.38, Test_accy 72.56
2024-08-07 16:20:04,949 [foster.py] => Task 3, Epoch 168/170 => Loss 3.549, Loss_clf 0.580, Loss_fe 0.433, Loss_kd 1.900, Train_accy 81.31, Test_accy 72.65
2024-08-07 16:20:19,281 [foster.py] => Task 3, Epoch 169/170 => Loss 3.501, Loss_clf 0.551, Loss_fe 0.418, Loss_kd 1.896, Train_accy 81.97, Test_accy 72.70
2024-08-07 16:20:33,694 [foster.py] => Task 3, Epoch 170/170 => Loss 3.545, Loss_clf 0.577, Loss_fe 0.431, Loss_kd 1.900, Train_accy 81.34, Test_accy 72.65
2024-08-07 16:20:33,698 [foster.py] => do not weight align teacher!
2024-08-07 16:20:33,702 [foster.py] => per cls weights : [1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077 1.09411077
 0.7176677  0.7176677  0.7176677  0.7176677  0.7176677  0.7176677
 0.7176677  0.7176677  0.7176677  0.7176677  0.7176677  0.7176677
 0.7176677  0.7176677  0.7176677  0.7176677  0.7176677  0.7176677
 0.7176677  0.7176677 ]
2024-08-07 16:20:53,204 [foster.py] => SNet: Task 3, Epoch 1/130 => Loss 30.097,  Loss1 0.757, Train_accy 32.38, Test_accy 60.91
2024-08-07 16:21:10,116 [foster.py] => SNet: Task 3, Epoch 2/130 => Loss 29.858,  Loss1 0.758, Train_accy 49.95
2024-08-07 16:21:27,079 [foster.py] => SNet: Task 3, Epoch 3/130 => Loss 29.820,  Loss1 0.758, Train_accy 54.17
2024-08-07 16:21:44,223 [foster.py] => SNet: Task 3, Epoch 4/130 => Loss 29.804,  Loss1 0.758, Train_accy 55.83
2024-08-07 16:22:01,527 [foster.py] => SNet: Task 3, Epoch 5/130 => Loss 29.789,  Loss1 0.758, Train_accy 57.74
2024-08-07 16:22:20,558 [foster.py] => SNet: Task 3, Epoch 6/130 => Loss 29.775,  Loss1 0.758, Train_accy 58.41, Test_accy 65.71
2024-08-07 16:22:37,542 [foster.py] => SNet: Task 3, Epoch 7/130 => Loss 29.767,  Loss1 0.757, Train_accy 59.48
2024-08-07 16:22:54,828 [foster.py] => SNet: Task 3, Epoch 8/130 => Loss 29.766,  Loss1 0.758, Train_accy 59.84
2024-08-07 16:23:11,920 [foster.py] => SNet: Task 3, Epoch 9/130 => Loss 29.748,  Loss1 0.758, Train_accy 60.86
2024-08-07 16:23:28,794 [foster.py] => SNet: Task 3, Epoch 10/130 => Loss 29.741,  Loss1 0.758, Train_accy 61.88
2024-08-07 16:23:48,004 [foster.py] => SNet: Task 3, Epoch 11/130 => Loss 29.751,  Loss1 0.758, Train_accy 61.19, Test_accy 66.03
2024-08-07 16:24:04,935 [foster.py] => SNet: Task 3, Epoch 12/130 => Loss 29.751,  Loss1 0.758, Train_accy 62.80
2024-08-07 16:24:22,033 [foster.py] => SNet: Task 3, Epoch 13/130 => Loss 29.752,  Loss1 0.758, Train_accy 63.09
2024-08-07 16:24:39,254 [foster.py] => SNet: Task 3, Epoch 14/130 => Loss 29.743,  Loss1 0.758, Train_accy 64.00
2024-08-07 16:24:56,358 [foster.py] => SNet: Task 3, Epoch 15/130 => Loss 29.740,  Loss1 0.758, Train_accy 63.22
2024-08-07 16:25:15,764 [foster.py] => SNet: Task 3, Epoch 16/130 => Loss 29.743,  Loss1 0.758, Train_accy 63.95, Test_accy 66.55
2024-08-07 16:25:32,745 [foster.py] => SNet: Task 3, Epoch 17/130 => Loss 29.729,  Loss1 0.758, Train_accy 64.42
2024-08-07 16:25:49,642 [foster.py] => SNet: Task 3, Epoch 18/130 => Loss 29.729,  Loss1 0.758, Train_accy 64.47
2024-08-07 16:26:06,727 [foster.py] => SNet: Task 3, Epoch 19/130 => Loss 29.749,  Loss1 0.758, Train_accy 64.35
2024-08-07 16:26:23,746 [foster.py] => SNet: Task 3, Epoch 20/130 => Loss 29.735,  Loss1 0.758, Train_accy 64.39
2024-08-07 16:26:43,408 [foster.py] => SNet: Task 3, Epoch 21/130 => Loss 29.727,  Loss1 0.758, Train_accy 64.77, Test_accy 66.96
2024-08-07 16:27:00,308 [foster.py] => SNet: Task 3, Epoch 22/130 => Loss 29.738,  Loss1 0.758, Train_accy 65.21
2024-08-07 16:27:17,137 [foster.py] => SNet: Task 3, Epoch 23/130 => Loss 29.716,  Loss1 0.758, Train_accy 65.58
2024-08-07 16:27:34,201 [foster.py] => SNet: Task 3, Epoch 24/130 => Loss 29.722,  Loss1 0.758, Train_accy 65.51
2024-08-07 16:27:51,059 [foster.py] => SNet: Task 3, Epoch 25/130 => Loss 29.714,  Loss1 0.758, Train_accy 65.48
2024-08-07 16:28:10,091 [foster.py] => SNet: Task 3, Epoch 26/130 => Loss 29.716,  Loss1 0.758, Train_accy 65.85, Test_accy 67.31
2024-08-07 16:28:26,990 [foster.py] => SNet: Task 3, Epoch 27/130 => Loss 29.723,  Loss1 0.758, Train_accy 65.64
2024-08-07 16:28:44,588 [foster.py] => SNet: Task 3, Epoch 28/130 => Loss 29.713,  Loss1 0.758, Train_accy 65.79
2024-08-07 16:29:01,555 [foster.py] => SNet: Task 3, Epoch 29/130 => Loss 29.708,  Loss1 0.758, Train_accy 66.47
2024-08-07 16:29:18,597 [foster.py] => SNet: Task 3, Epoch 30/130 => Loss 29.713,  Loss1 0.758, Train_accy 66.24
2024-08-07 16:29:37,771 [foster.py] => SNet: Task 3, Epoch 31/130 => Loss 29.714,  Loss1 0.758, Train_accy 66.66, Test_accy 67.03
2024-08-07 16:29:54,902 [foster.py] => SNet: Task 3, Epoch 32/130 => Loss 29.714,  Loss1 0.758, Train_accy 66.05
2024-08-07 16:30:12,058 [foster.py] => SNet: Task 3, Epoch 33/130 => Loss 29.712,  Loss1 0.758, Train_accy 66.83
2024-08-07 16:30:28,872 [foster.py] => SNet: Task 3, Epoch 34/130 => Loss 29.704,  Loss1 0.758, Train_accy 67.71
2024-08-07 16:30:45,883 [foster.py] => SNet: Task 3, Epoch 35/130 => Loss 29.700,  Loss1 0.758, Train_accy 66.89
2024-08-07 16:31:05,253 [foster.py] => SNet: Task 3, Epoch 36/130 => Loss 29.696,  Loss1 0.758, Train_accy 67.09, Test_accy 68.30
2024-08-07 16:31:22,176 [foster.py] => SNet: Task 3, Epoch 37/130 => Loss 29.694,  Loss1 0.758, Train_accy 67.21
2024-08-07 16:31:39,308 [foster.py] => SNet: Task 3, Epoch 38/130 => Loss 29.712,  Loss1 0.758, Train_accy 67.55
2024-08-07 16:31:56,369 [foster.py] => SNet: Task 3, Epoch 39/130 => Loss 29.686,  Loss1 0.758, Train_accy 67.91
2024-08-07 16:32:13,243 [foster.py] => SNet: Task 3, Epoch 40/130 => Loss 29.704,  Loss1 0.758, Train_accy 68.00
2024-08-07 16:32:32,298 [foster.py] => SNet: Task 3, Epoch 41/130 => Loss 29.691,  Loss1 0.758, Train_accy 68.22, Test_accy 68.51
2024-08-07 16:32:49,180 [foster.py] => SNet: Task 3, Epoch 42/130 => Loss 29.705,  Loss1 0.758, Train_accy 67.90
2024-08-07 16:33:06,041 [foster.py] => SNet: Task 3, Epoch 43/130 => Loss 29.687,  Loss1 0.758, Train_accy 68.23
2024-08-07 16:33:23,150 [foster.py] => SNet: Task 3, Epoch 44/130 => Loss 29.707,  Loss1 0.758, Train_accy 68.01
2024-08-07 16:33:40,190 [foster.py] => SNet: Task 3, Epoch 45/130 => Loss 29.688,  Loss1 0.758, Train_accy 68.24
2024-08-07 16:33:59,556 [foster.py] => SNet: Task 3, Epoch 46/130 => Loss 29.692,  Loss1 0.758, Train_accy 68.31, Test_accy 68.47
2024-08-07 16:34:16,600 [foster.py] => SNet: Task 3, Epoch 47/130 => Loss 29.695,  Loss1 0.758, Train_accy 68.01
2024-08-07 16:34:33,998 [foster.py] => SNet: Task 3, Epoch 48/130 => Loss 29.683,  Loss1 0.758, Train_accy 68.07
2024-08-07 16:34:50,968 [foster.py] => SNet: Task 3, Epoch 49/130 => Loss 29.678,  Loss1 0.758, Train_accy 68.20
2024-08-07 16:35:07,958 [foster.py] => SNet: Task 3, Epoch 50/130 => Loss 29.684,  Loss1 0.758, Train_accy 68.95
2024-08-07 16:35:27,286 [foster.py] => SNet: Task 3, Epoch 51/130 => Loss 29.685,  Loss1 0.758, Train_accy 68.78, Test_accy 68.94
2024-08-07 16:35:44,597 [foster.py] => SNet: Task 3, Epoch 52/130 => Loss 29.721,  Loss1 0.758, Train_accy 68.24
2024-08-07 16:36:01,836 [foster.py] => SNet: Task 3, Epoch 53/130 => Loss 29.679,  Loss1 0.758, Train_accy 69.82
2024-08-07 16:36:18,834 [foster.py] => SNet: Task 3, Epoch 54/130 => Loss 29.695,  Loss1 0.758, Train_accy 69.38
2024-08-07 16:36:35,610 [foster.py] => SNet: Task 3, Epoch 55/130 => Loss 29.690,  Loss1 0.757, Train_accy 69.16
2024-08-07 16:36:54,849 [foster.py] => SNet: Task 3, Epoch 56/130 => Loss 29.709,  Loss1 0.758, Train_accy 68.83, Test_accy 68.76
2024-08-07 16:37:11,753 [foster.py] => SNet: Task 3, Epoch 57/130 => Loss 29.679,  Loss1 0.758, Train_accy 69.22
2024-08-07 16:37:28,693 [foster.py] => SNet: Task 3, Epoch 58/130 => Loss 29.693,  Loss1 0.758, Train_accy 69.00
2024-08-07 16:37:45,598 [foster.py] => SNet: Task 3, Epoch 59/130 => Loss 29.683,  Loss1 0.758, Train_accy 69.03
2024-08-07 16:38:02,458 [foster.py] => SNet: Task 3, Epoch 60/130 => Loss 29.692,  Loss1 0.758, Train_accy 69.27
2024-08-07 16:38:21,610 [foster.py] => SNet: Task 3, Epoch 61/130 => Loss 29.673,  Loss1 0.758, Train_accy 69.57, Test_accy 69.56
2024-08-07 16:38:38,633 [foster.py] => SNet: Task 3, Epoch 62/130 => Loss 29.687,  Loss1 0.758, Train_accy 69.34
2024-08-07 16:38:55,529 [foster.py] => SNet: Task 3, Epoch 63/130 => Loss 29.686,  Loss1 0.758, Train_accy 69.92
2024-08-07 16:39:12,439 [foster.py] => SNet: Task 3, Epoch 64/130 => Loss 29.691,  Loss1 0.758, Train_accy 69.60
2024-08-07 16:39:29,454 [foster.py] => SNet: Task 3, Epoch 65/130 => Loss 29.683,  Loss1 0.758, Train_accy 69.27
2024-08-07 16:39:48,867 [foster.py] => SNet: Task 3, Epoch 66/130 => Loss 29.672,  Loss1 0.758, Train_accy 70.23, Test_accy 68.82
2024-08-07 16:40:05,838 [foster.py] => SNet: Task 3, Epoch 67/130 => Loss 29.687,  Loss1 0.758, Train_accy 69.93
2024-08-07 16:40:23,003 [foster.py] => SNet: Task 3, Epoch 68/130 => Loss 29.684,  Loss1 0.758, Train_accy 70.01
2024-08-07 16:40:39,845 [foster.py] => SNet: Task 3, Epoch 69/130 => Loss 29.669,  Loss1 0.758, Train_accy 70.32
2024-08-07 16:40:56,877 [foster.py] => SNet: Task 3, Epoch 70/130 => Loss 29.686,  Loss1 0.758, Train_accy 69.31
2024-08-07 16:41:16,306 [foster.py] => SNet: Task 3, Epoch 71/130 => Loss 29.683,  Loss1 0.758, Train_accy 69.90, Test_accy 69.56
2024-08-07 16:41:33,267 [foster.py] => SNet: Task 3, Epoch 72/130 => Loss 29.664,  Loss1 0.758, Train_accy 70.41
2024-08-07 16:41:50,141 [foster.py] => SNet: Task 3, Epoch 73/130 => Loss 29.678,  Loss1 0.758, Train_accy 69.84
2024-08-07 16:42:07,138 [foster.py] => SNet: Task 3, Epoch 74/130 => Loss 29.677,  Loss1 0.758, Train_accy 69.73
2024-08-07 16:42:24,108 [foster.py] => SNet: Task 3, Epoch 75/130 => Loss 29.696,  Loss1 0.758, Train_accy 70.25
2024-08-07 16:42:43,247 [foster.py] => SNet: Task 3, Epoch 76/130 => Loss 29.681,  Loss1 0.758, Train_accy 70.08, Test_accy 69.19
2024-08-07 16:43:00,321 [foster.py] => SNet: Task 3, Epoch 77/130 => Loss 29.674,  Loss1 0.758, Train_accy 69.91
2024-08-07 16:43:17,212 [foster.py] => SNet: Task 3, Epoch 78/130 => Loss 29.655,  Loss1 0.758, Train_accy 70.83
2024-08-07 16:43:34,189 [foster.py] => SNet: Task 3, Epoch 79/130 => Loss 29.679,  Loss1 0.758, Train_accy 70.41
2024-08-07 16:43:51,115 [foster.py] => SNet: Task 3, Epoch 80/130 => Loss 29.667,  Loss1 0.758, Train_accy 70.61
2024-08-07 16:44:10,342 [foster.py] => SNet: Task 3, Epoch 81/130 => Loss 29.678,  Loss1 0.758, Train_accy 70.29, Test_accy 69.76
2024-08-07 16:44:27,546 [foster.py] => SNet: Task 3, Epoch 82/130 => Loss 29.677,  Loss1 0.758, Train_accy 70.65
2024-08-07 16:44:44,645 [foster.py] => SNet: Task 3, Epoch 83/130 => Loss 29.664,  Loss1 0.758, Train_accy 70.85
2024-08-07 16:45:01,642 [foster.py] => SNet: Task 3, Epoch 84/130 => Loss 29.676,  Loss1 0.758, Train_accy 70.20
2024-08-07 16:45:18,702 [foster.py] => SNet: Task 3, Epoch 85/130 => Loss 29.666,  Loss1 0.758, Train_accy 70.68
2024-08-07 16:45:37,919 [foster.py] => SNet: Task 3, Epoch 86/130 => Loss 29.656,  Loss1 0.758, Train_accy 71.19, Test_accy 70.00
2024-08-07 16:45:54,922 [foster.py] => SNet: Task 3, Epoch 87/130 => Loss 29.675,  Loss1 0.758, Train_accy 70.06
2024-08-07 16:46:11,674 [foster.py] => SNet: Task 3, Epoch 88/130 => Loss 29.672,  Loss1 0.758, Train_accy 70.61
2024-08-07 16:46:28,490 [foster.py] => SNet: Task 3, Epoch 89/130 => Loss 29.663,  Loss1 0.758, Train_accy 71.42
2024-08-07 16:46:45,374 [foster.py] => SNet: Task 3, Epoch 90/130 => Loss 29.671,  Loss1 0.758, Train_accy 70.33
2024-08-07 16:47:04,577 [foster.py] => SNet: Task 3, Epoch 91/130 => Loss 29.661,  Loss1 0.758, Train_accy 70.88, Test_accy 70.03
2024-08-07 16:47:21,610 [foster.py] => SNet: Task 3, Epoch 92/130 => Loss 29.648,  Loss1 0.758, Train_accy 70.33
2024-08-07 16:47:38,827 [foster.py] => SNet: Task 3, Epoch 93/130 => Loss 29.651,  Loss1 0.758, Train_accy 71.44
2024-08-07 16:47:56,031 [foster.py] => SNet: Task 3, Epoch 94/130 => Loss 29.688,  Loss1 0.758, Train_accy 71.13
2024-08-07 16:48:13,027 [foster.py] => SNet: Task 3, Epoch 95/130 => Loss 29.675,  Loss1 0.758, Train_accy 71.25
2024-08-07 16:48:32,466 [foster.py] => SNet: Task 3, Epoch 96/130 => Loss 29.667,  Loss1 0.758, Train_accy 70.89, Test_accy 69.81
2024-08-07 16:48:49,340 [foster.py] => SNet: Task 3, Epoch 97/130 => Loss 29.653,  Loss1 0.758, Train_accy 71.52
2024-08-07 16:49:06,145 [foster.py] => SNet: Task 3, Epoch 98/130 => Loss 29.652,  Loss1 0.758, Train_accy 71.28
2024-08-07 16:49:23,070 [foster.py] => SNet: Task 3, Epoch 99/130 => Loss 29.674,  Loss1 0.758, Train_accy 70.55
2024-08-07 16:49:40,341 [foster.py] => SNet: Task 3, Epoch 100/130 => Loss 29.666,  Loss1 0.758, Train_accy 71.39
2024-08-07 16:49:59,961 [foster.py] => SNet: Task 3, Epoch 101/130 => Loss 29.657,  Loss1 0.758, Train_accy 71.34, Test_accy 70.19
2024-08-07 16:50:17,266 [foster.py] => SNet: Task 3, Epoch 102/130 => Loss 29.676,  Loss1 0.758, Train_accy 71.43
2024-08-07 16:50:34,061 [foster.py] => SNet: Task 3, Epoch 103/130 => Loss 29.684,  Loss1 0.758, Train_accy 70.82
2024-08-07 16:50:51,262 [foster.py] => SNet: Task 3, Epoch 104/130 => Loss 29.671,  Loss1 0.758, Train_accy 71.45
2024-08-07 16:51:08,248 [foster.py] => SNet: Task 3, Epoch 105/130 => Loss 29.664,  Loss1 0.758, Train_accy 71.28
2024-08-07 16:51:27,634 [foster.py] => SNet: Task 3, Epoch 106/130 => Loss 29.670,  Loss1 0.758, Train_accy 71.24, Test_accy 70.06
2024-08-07 16:51:44,818 [foster.py] => SNet: Task 3, Epoch 107/130 => Loss 29.675,  Loss1 0.758, Train_accy 71.22
2024-08-07 16:52:02,260 [foster.py] => SNet: Task 3, Epoch 108/130 => Loss 29.671,  Loss1 0.758, Train_accy 71.26
2024-08-07 16:52:19,407 [foster.py] => SNet: Task 3, Epoch 109/130 => Loss 29.667,  Loss1 0.758, Train_accy 71.28
2024-08-07 16:52:36,223 [foster.py] => SNet: Task 3, Epoch 110/130 => Loss 29.664,  Loss1 0.758, Train_accy 71.54
2024-08-07 16:52:55,536 [foster.py] => SNet: Task 3, Epoch 111/130 => Loss 29.678,  Loss1 0.758, Train_accy 70.83, Test_accy 69.92
2024-08-07 16:53:12,454 [foster.py] => SNet: Task 3, Epoch 112/130 => Loss 29.647,  Loss1 0.758, Train_accy 70.85
2024-08-07 16:53:29,688 [foster.py] => SNet: Task 3, Epoch 113/130 => Loss 29.663,  Loss1 0.758, Train_accy 71.51
2024-08-07 16:53:46,611 [foster.py] => SNet: Task 3, Epoch 114/130 => Loss 29.679,  Loss1 0.758, Train_accy 70.85
2024-08-07 16:54:03,695 [foster.py] => SNet: Task 3, Epoch 115/130 => Loss 29.674,  Loss1 0.758, Train_accy 70.82
2024-08-07 16:54:22,815 [foster.py] => SNet: Task 3, Epoch 116/130 => Loss 29.657,  Loss1 0.758, Train_accy 71.27, Test_accy 69.97
2024-08-07 16:54:39,660 [foster.py] => SNet: Task 3, Epoch 117/130 => Loss 29.673,  Loss1 0.758, Train_accy 70.82
2024-08-07 16:54:56,842 [foster.py] => SNet: Task 3, Epoch 118/130 => Loss 29.666,  Loss1 0.758, Train_accy 71.99
2024-08-07 16:55:13,900 [foster.py] => SNet: Task 3, Epoch 119/130 => Loss 29.670,  Loss1 0.758, Train_accy 71.51
2024-08-07 16:55:30,804 [foster.py] => SNet: Task 3, Epoch 120/130 => Loss 29.651,  Loss1 0.758, Train_accy 71.65
2024-08-07 16:55:49,872 [foster.py] => SNet: Task 3, Epoch 121/130 => Loss 29.673,  Loss1 0.758, Train_accy 70.69, Test_accy 70.21
2024-08-07 16:56:06,853 [foster.py] => SNet: Task 3, Epoch 122/130 => Loss 29.650,  Loss1 0.758, Train_accy 71.42
2024-08-07 16:56:24,164 [foster.py] => SNet: Task 3, Epoch 123/130 => Loss 29.661,  Loss1 0.758, Train_accy 71.30
2024-08-07 16:56:40,931 [foster.py] => SNet: Task 3, Epoch 124/130 => Loss 29.665,  Loss1 0.758, Train_accy 71.55
2024-08-07 16:56:57,978 [foster.py] => SNet: Task 3, Epoch 125/130 => Loss 29.655,  Loss1 0.758, Train_accy 72.05
2024-08-07 16:57:17,300 [foster.py] => SNet: Task 3, Epoch 126/130 => Loss 29.666,  Loss1 0.758, Train_accy 71.57, Test_accy 70.19
2024-08-07 16:57:34,320 [foster.py] => SNet: Task 3, Epoch 127/130 => Loss 29.663,  Loss1 0.758, Train_accy 71.30
2024-08-07 16:57:51,413 [foster.py] => SNet: Task 3, Epoch 128/130 => Loss 29.667,  Loss1 0.758, Train_accy 70.99
2024-08-07 16:58:08,636 [foster.py] => SNet: Task 3, Epoch 129/130 => Loss 29.654,  Loss1 0.758, Train_accy 71.54
2024-08-07 16:58:25,783 [foster.py] => SNet: Task 3, Epoch 130/130 => Loss 29.660,  Loss1 0.758, Train_accy 71.34
2024-08-07 16:58:25,783 [foster.py] => do not weight align student!
2024-08-07 16:58:28,108 [foster.py] => darknet eval: 
2024-08-07 16:58:28,108 [foster.py] => CNN top1 curve: 70.2
2024-08-07 16:58:28,108 [foster.py] => CNN top5 curve: 92.64
2024-08-07 16:58:28,108 [foster.py] => CNN top1 平均值: 70.20
2024-08-07 16:58:28,111 [foster.py] => timees : 4630.521792411804
2024-08-07 16:58:28,112 [base.py] => Reducing exemplars...(25 per classes)
2024-08-07 16:58:48,441 [base.py] => Constructing exemplars...(25 per classes)
2024-08-07 16:59:13,705 [foster.py] => Exemplar size: 2000
2024-08-07 16:59:13,706 [trainer.py] => CNN: {'total': 72.65, '00-09': 74.5, '10-19': 61.3, '20-29': 74.1, '30-39': 71.0, '40-49': 78.2, '50-59': 71.7, '60-69': 80.2, '70-79': 70.2, 'old': 71.8, 'new': 75.2}
2024-08-07 16:59:13,706 [trainer.py] => NME: {'total': 69.74, '00-09': 72.9, '10-19': 61.6, '20-29': 72.1, '30-39': 65.4, '40-49': 70.7, '50-59': 63.9, '60-69': 78.9, '70-79': 72.4, 'old': 67.77, 'new': 75.65}
2024-08-07 16:59:13,706 [trainer.py] => CNN top1 curve: [87.15, 82.28, 77.25, 72.65]
2024-08-07 16:59:13,706 [trainer.py] => CNN top5 curve: [98.3, 96.45, 94.98, 93.45]
2024-08-07 16:59:13,706 [trainer.py] => NME top1 curve: [87.2, 82.42, 75.68, 69.74]
2024-08-07 16:59:13,706 [trainer.py] => NME top5 curve: [98.45, 96.6, 94.38, 91.92]

2024-08-07 16:59:13,706 [trainer.py] => CNN top1 平均值: 79.83
2024-08-07 16:59:13,709 [trainer.py] => All params: 1301968
2024-08-07 16:59:13,711 [trainer.py] => Trainable params: 656794
2024-08-07 16:59:13,773 [foster.py] => Learning on 80-100
2024-08-07 16:59:13,777 [foster.py] => All params: 1307148
2024-08-07 16:59:13,779 [foster.py] => Trainable params: 660674
2024-08-07 16:59:13,887 [foster.py] => per cls weights : [1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  1.0603248  1.0603248  1.0603248  1.0603248
 1.0603248  1.0603248  0.75870082 0.75870082 0.75870082 0.75870082
 0.75870082 0.75870082 0.75870082 0.75870082 0.75870082 0.75870082
 0.75870082 0.75870082 0.75870082 0.75870082 0.75870082 0.75870082
 0.75870082 0.75870082 0.75870082 0.75870082]
2024-08-07 16:59:25,645 [foster.py] => Task 4, Epoch 1/170 => Loss 7.957, Loss_clf 2.859, Loss_fe 2.128, Loss_kd 2.372, Train_accy 42.12
2024-08-07 16:59:40,372 [foster.py] => Task 4, Epoch 2/170 => Loss 6.637, Loss_clf 2.023, Loss_fe 1.688, Loss_kd 2.338, Train_accy 49.94, Test_accy 61.22
2024-08-07 16:59:55,043 [foster.py] => Task 4, Epoch 3/170 => Loss 6.488, Loss_clf 1.932, Loss_fe 1.627, Loss_kd 2.340, Train_accy 51.59, Test_accy 60.92
2024-08-07 17:00:10,111 [foster.py] => Task 4, Epoch 4/170 => Loss 6.292, Loss_clf 1.829, Loss_fe 1.536, Loss_kd 2.339, Train_accy 53.70, Test_accy 61.85
2024-08-07 17:00:25,122 [foster.py] => Task 4, Epoch 5/170 => Loss 6.231, Loss_clf 1.795, Loss_fe 1.501, Loss_kd 2.345, Train_accy 53.88, Test_accy 59.45
2024-08-07 17:00:36,977 [foster.py] => Task 4, Epoch 6/170 => Loss 6.178, Loss_clf 1.769, Loss_fe 1.472, Loss_kd 2.346, Train_accy 54.88
2024-08-07 17:00:51,642 [foster.py] => Task 4, Epoch 7/170 => Loss 6.101, Loss_clf 1.727, Loss_fe 1.443, Loss_kd 2.341, Train_accy 55.68, Test_accy 63.71
2024-08-07 17:01:06,430 [foster.py] => Task 4, Epoch 8/170 => Loss 6.061, Loss_clf 1.698, Loss_fe 1.422, Loss_kd 2.350, Train_accy 55.75, Test_accy 62.54
2024-08-07 17:01:21,191 [foster.py] => Task 4, Epoch 9/170 => Loss 6.015, Loss_clf 1.684, Loss_fe 1.400, Loss_kd 2.341, Train_accy 56.49, Test_accy 63.12
2024-08-07 17:01:35,831 [foster.py] => Task 4, Epoch 10/170 => Loss 6.009, Loss_clf 1.676, Loss_fe 1.397, Loss_kd 2.345, Train_accy 56.71, Test_accy 62.33
2024-08-07 17:01:47,603 [foster.py] => Task 4, Epoch 11/170 => Loss 6.024, Loss_clf 1.707, Loss_fe 1.385, Loss_kd 2.343, Train_accy 56.59
2024-08-07 17:02:02,756 [foster.py] => Task 4, Epoch 12/170 => Loss 5.945, Loss_clf 1.650, Loss_fe 1.355, Loss_kd 2.348, Train_accy 57.08, Test_accy 61.68
2024-08-07 17:02:17,711 [foster.py] => Task 4, Epoch 13/170 => Loss 5.866, Loss_clf 1.597, Loss_fe 1.335, Loss_kd 2.344, Train_accy 57.98, Test_accy 61.96
2024-08-07 17:02:32,479 [foster.py] => Task 4, Epoch 14/170 => Loss 5.918, Loss_clf 1.638, Loss_fe 1.340, Loss_kd 2.348, Train_accy 57.39, Test_accy 62.27
2024-08-07 17:02:47,206 [foster.py] => Task 4, Epoch 15/170 => Loss 5.802, Loss_clf 1.582, Loss_fe 1.297, Loss_kd 2.335, Train_accy 57.77, Test_accy 62.32
2024-08-07 17:02:58,999 [foster.py] => Task 4, Epoch 16/170 => Loss 5.880, Loss_clf 1.639, Loss_fe 1.309, Loss_kd 2.342, Train_accy 57.90
2024-08-07 17:03:13,738 [foster.py] => Task 4, Epoch 17/170 => Loss 5.823, Loss_clf 1.593, Loss_fe 1.291, Loss_kd 2.348, Train_accy 58.68, Test_accy 64.11
2024-08-07 17:03:28,432 [foster.py] => Task 4, Epoch 18/170 => Loss 5.743, Loss_clf 1.530, Loss_fe 1.291, Loss_kd 2.333, Train_accy 58.21, Test_accy 63.81
2024-08-07 17:03:43,284 [foster.py] => Task 4, Epoch 19/170 => Loss 5.851, Loss_clf 1.618, Loss_fe 1.297, Loss_kd 2.345, Train_accy 57.61, Test_accy 63.87
2024-08-07 17:03:58,073 [foster.py] => Task 4, Epoch 20/170 => Loss 5.746, Loss_clf 1.549, Loss_fe 1.264, Loss_kd 2.343, Train_accy 58.29, Test_accy 61.00
2024-08-07 17:04:10,011 [foster.py] => Task 4, Epoch 21/170 => Loss 5.693, Loss_clf 1.505, Loss_fe 1.260, Loss_kd 2.338, Train_accy 59.43
2024-08-07 17:04:24,797 [foster.py] => Task 4, Epoch 22/170 => Loss 5.714, Loss_clf 1.532, Loss_fe 1.250, Loss_kd 2.342, Train_accy 59.27, Test_accy 63.09
2024-08-07 17:04:39,627 [foster.py] => Task 4, Epoch 23/170 => Loss 5.765, Loss_clf 1.564, Loss_fe 1.266, Loss_kd 2.344, Train_accy 58.45, Test_accy 62.69
2024-08-07 17:04:54,426 [foster.py] => Task 4, Epoch 24/170 => Loss 5.706, Loss_clf 1.529, Loss_fe 1.249, Loss_kd 2.339, Train_accy 58.76, Test_accy 62.14
2024-08-07 17:05:09,231 [foster.py] => Task 4, Epoch 25/170 => Loss 5.670, Loss_clf 1.490, Loss_fe 1.234, Loss_kd 2.353, Train_accy 59.82, Test_accy 62.38
2024-08-07 17:05:21,019 [foster.py] => Task 4, Epoch 26/170 => Loss 5.666, Loss_clf 1.515, Loss_fe 1.221, Loss_kd 2.341, Train_accy 59.44
2024-08-07 17:05:35,793 [foster.py] => Task 4, Epoch 27/170 => Loss 5.635, Loss_clf 1.496, Loss_fe 1.211, Loss_kd 2.339, Train_accy 60.15, Test_accy 63.75
2024-08-07 17:05:50,488 [foster.py] => Task 4, Epoch 28/170 => Loss 5.718, Loss_clf 1.546, Loss_fe 1.232, Loss_kd 2.348, Train_accy 59.06, Test_accy 63.49
2024-08-07 17:06:05,143 [foster.py] => Task 4, Epoch 29/170 => Loss 5.690, Loss_clf 1.534, Loss_fe 1.218, Loss_kd 2.347, Train_accy 58.96, Test_accy 63.71
2024-08-07 17:06:19,934 [foster.py] => Task 4, Epoch 30/170 => Loss 5.663, Loss_clf 1.518, Loss_fe 1.214, Loss_kd 2.341, Train_accy 59.44, Test_accy 63.90
2024-08-07 17:06:31,811 [foster.py] => Task 4, Epoch 31/170 => Loss 5.569, Loss_clf 1.438, Loss_fe 1.199, Loss_kd 2.342, Train_accy 60.60
2024-08-07 17:06:46,734 [foster.py] => Task 4, Epoch 32/170 => Loss 5.608, Loss_clf 1.511, Loss_fe 1.169, Loss_kd 2.339, Train_accy 59.63, Test_accy 62.51
2024-08-07 17:07:01,645 [foster.py] => Task 4, Epoch 33/170 => Loss 5.606, Loss_clf 1.476, Loss_fe 1.190, Loss_kd 2.349, Train_accy 60.18, Test_accy 62.88
2024-08-07 17:07:16,422 [foster.py] => Task 4, Epoch 34/170 => Loss 5.602, Loss_clf 1.497, Loss_fe 1.169, Loss_kd 2.346, Train_accy 60.76, Test_accy 63.89
2024-08-07 17:07:31,152 [foster.py] => Task 4, Epoch 35/170 => Loss 5.586, Loss_clf 1.468, Loss_fe 1.187, Loss_kd 2.342, Train_accy 60.39, Test_accy 63.30
2024-08-07 17:07:43,070 [foster.py] => Task 4, Epoch 36/170 => Loss 5.548, Loss_clf 1.429, Loss_fe 1.173, Loss_kd 2.353, Train_accy 60.69
2024-08-07 17:07:57,872 [foster.py] => Task 4, Epoch 37/170 => Loss 5.526, Loss_clf 1.435, Loss_fe 1.159, Loss_kd 2.342, Train_accy 61.28, Test_accy 65.08
2024-08-07 17:08:12,561 [foster.py] => Task 4, Epoch 38/170 => Loss 5.511, Loss_clf 1.424, Loss_fe 1.157, Loss_kd 2.340, Train_accy 60.98, Test_accy 64.08
2024-08-07 17:08:27,557 [foster.py] => Task 4, Epoch 39/170 => Loss 5.514, Loss_clf 1.424, Loss_fe 1.154, Loss_kd 2.345, Train_accy 60.84, Test_accy 63.80
2024-08-07 17:08:42,342 [foster.py] => Task 4, Epoch 40/170 => Loss 5.536, Loss_clf 1.449, Loss_fe 1.154, Loss_kd 2.342, Train_accy 60.63, Test_accy 63.96
2024-08-07 17:08:54,284 [foster.py] => Task 4, Epoch 41/170 => Loss 5.540, Loss_clf 1.439, Loss_fe 1.153, Loss_kd 2.354, Train_accy 61.18
2024-08-07 17:09:09,093 [foster.py] => Task 4, Epoch 42/170 => Loss 5.420, Loss_clf 1.365, Loss_fe 1.124, Loss_kd 2.342, Train_accy 61.95, Test_accy 64.47
2024-08-07 17:09:24,191 [foster.py] => Task 4, Epoch 43/170 => Loss 5.424, Loss_clf 1.368, Loss_fe 1.124, Loss_kd 2.342, Train_accy 62.11, Test_accy 63.92
2024-08-07 17:09:39,311 [foster.py] => Task 4, Epoch 44/170 => Loss 5.416, Loss_clf 1.368, Loss_fe 1.116, Loss_kd 2.342, Train_accy 61.85, Test_accy 65.83
2024-08-07 17:09:53,966 [foster.py] => Task 4, Epoch 45/170 => Loss 5.386, Loss_clf 1.357, Loss_fe 1.100, Loss_kd 2.339, Train_accy 61.71, Test_accy 65.74
2024-08-07 17:10:05,858 [foster.py] => Task 4, Epoch 46/170 => Loss 5.424, Loss_clf 1.371, Loss_fe 1.117, Loss_kd 2.345, Train_accy 61.45
2024-08-07 17:10:20,636 [foster.py] => Task 4, Epoch 47/170 => Loss 5.400, Loss_clf 1.342, Loss_fe 1.124, Loss_kd 2.343, Train_accy 62.32, Test_accy 64.97
2024-08-07 17:10:35,324 [foster.py] => Task 4, Epoch 48/170 => Loss 5.428, Loss_clf 1.375, Loss_fe 1.109, Loss_kd 2.351, Train_accy 61.41, Test_accy 64.92
2024-08-07 17:10:50,091 [foster.py] => Task 4, Epoch 49/170 => Loss 5.383, Loss_clf 1.350, Loss_fe 1.110, Loss_kd 2.334, Train_accy 61.70, Test_accy 64.17
2024-08-07 17:11:04,916 [foster.py] => Task 4, Epoch 50/170 => Loss 5.397, Loss_clf 1.352, Loss_fe 1.104, Loss_kd 2.349, Train_accy 62.31, Test_accy 63.38
2024-08-07 17:11:16,615 [foster.py] => Task 4, Epoch 51/170 => Loss 5.377, Loss_clf 1.367, Loss_fe 1.081, Loss_kd 2.340, Train_accy 61.97
2024-08-07 17:11:31,404 [foster.py] => Task 4, Epoch 52/170 => Loss 5.394, Loss_clf 1.373, Loss_fe 1.093, Loss_kd 2.339, Train_accy 62.52, Test_accy 64.91
2024-08-07 17:11:46,862 [foster.py] => Task 4, Epoch 53/170 => Loss 5.388, Loss_clf 1.363, Loss_fe 1.093, Loss_kd 2.342, Train_accy 61.69, Test_accy 63.84
2024-08-07 17:12:01,545 [foster.py] => Task 4, Epoch 54/170 => Loss 5.312, Loss_clf 1.317, Loss_fe 1.065, Loss_kd 2.341, Train_accy 62.51, Test_accy 64.71
2024-08-07 17:12:16,406 [foster.py] => Task 4, Epoch 55/170 => Loss 5.240, Loss_clf 1.267, Loss_fe 1.045, Loss_kd 2.339, Train_accy 64.18, Test_accy 65.99
2024-08-07 17:12:28,246 [foster.py] => Task 4, Epoch 56/170 => Loss 5.329, Loss_clf 1.320, Loss_fe 1.070, Loss_kd 2.347, Train_accy 62.33
2024-08-07 17:12:42,941 [foster.py] => Task 4, Epoch 57/170 => Loss 5.332, Loss_clf 1.323, Loss_fe 1.079, Loss_kd 2.340, Train_accy 62.75, Test_accy 65.91
2024-08-07 17:12:57,700 [foster.py] => Task 4, Epoch 58/170 => Loss 5.400, Loss_clf 1.379, Loss_fe 1.078, Loss_kd 2.351, Train_accy 61.88, Test_accy 64.33
2024-08-07 17:13:12,627 [foster.py] => Task 4, Epoch 59/170 => Loss 5.231, Loss_clf 1.268, Loss_fe 1.034, Loss_kd 2.339, Train_accy 63.68, Test_accy 65.72
2024-08-07 17:13:27,304 [foster.py] => Task 4, Epoch 60/170 => Loss 5.271, Loss_clf 1.301, Loss_fe 1.044, Loss_kd 2.337, Train_accy 62.75, Test_accy 64.66
2024-08-07 17:13:39,167 [foster.py] => Task 4, Epoch 61/170 => Loss 5.207, Loss_clf 1.255, Loss_fe 1.027, Loss_kd 2.336, Train_accy 63.98
2024-08-07 17:13:53,922 [foster.py] => Task 4, Epoch 62/170 => Loss 5.269, Loss_clf 1.296, Loss_fe 1.040, Loss_kd 2.343, Train_accy 63.78, Test_accy 65.04
2024-08-07 17:14:08,655 [foster.py] => Task 4, Epoch 63/170 => Loss 5.203, Loss_clf 1.253, Loss_fe 1.023, Loss_kd 2.337, Train_accy 64.32, Test_accy 65.49
2024-08-07 17:14:23,304 [foster.py] => Task 4, Epoch 64/170 => Loss 5.216, Loss_clf 1.266, Loss_fe 1.018, Loss_kd 2.341, Train_accy 63.10, Test_accy 65.05
2024-08-07 17:14:38,162 [foster.py] => Task 4, Epoch 65/170 => Loss 5.181, Loss_clf 1.237, Loss_fe 1.015, Loss_kd 2.339, Train_accy 64.23, Test_accy 65.27
2024-08-07 17:14:50,063 [foster.py] => Task 4, Epoch 66/170 => Loss 5.132, Loss_clf 1.214, Loss_fe 0.989, Loss_kd 2.339, Train_accy 64.22
2024-08-07 17:15:04,907 [foster.py] => Task 4, Epoch 67/170 => Loss 5.163, Loss_clf 1.218, Loss_fe 1.012, Loss_kd 2.343, Train_accy 64.51, Test_accy 65.52
2024-08-07 17:15:19,645 [foster.py] => Task 4, Epoch 68/170 => Loss 5.144, Loss_clf 1.215, Loss_fe 0.999, Loss_kd 2.340, Train_accy 65.04, Test_accy 65.88
2024-08-07 17:15:34,533 [foster.py] => Task 4, Epoch 69/170 => Loss 5.121, Loss_clf 1.209, Loss_fe 0.986, Loss_kd 2.338, Train_accy 65.43, Test_accy 65.39
2024-08-07 17:15:49,152 [foster.py] => Task 4, Epoch 70/170 => Loss 5.153, Loss_clf 1.226, Loss_fe 1.000, Loss_kd 2.337, Train_accy 64.78, Test_accy 66.46
2024-08-07 17:16:00,849 [foster.py] => Task 4, Epoch 71/170 => Loss 5.107, Loss_clf 1.196, Loss_fe 0.989, Loss_kd 2.334, Train_accy 64.45
2024-08-07 17:16:15,494 [foster.py] => Task 4, Epoch 72/170 => Loss 5.043, Loss_clf 1.160, Loss_fe 0.962, Loss_kd 2.334, Train_accy 65.53, Test_accy 64.85
2024-08-07 17:16:30,294 [foster.py] => Task 4, Epoch 73/170 => Loss 5.077, Loss_clf 1.188, Loss_fe 0.969, Loss_kd 2.333, Train_accy 64.91, Test_accy 65.13
2024-08-07 17:16:45,301 [foster.py] => Task 4, Epoch 74/170 => Loss 5.156, Loss_clf 1.226, Loss_fe 0.995, Loss_kd 2.344, Train_accy 64.54, Test_accy 64.75
2024-08-07 17:17:00,055 [foster.py] => Task 4, Epoch 75/170 => Loss 5.097, Loss_clf 1.196, Loss_fe 0.970, Loss_kd 2.341, Train_accy 65.72, Test_accy 65.56
2024-08-07 17:17:11,774 [foster.py] => Task 4, Epoch 76/170 => Loss 5.072, Loss_clf 1.186, Loss_fe 0.960, Loss_kd 2.337, Train_accy 65.49
2024-08-07 17:17:26,425 [foster.py] => Task 4, Epoch 77/170 => Loss 4.998, Loss_clf 1.145, Loss_fe 0.934, Loss_kd 2.332, Train_accy 66.46, Test_accy 65.71
2024-08-07 17:17:41,280 [foster.py] => Task 4, Epoch 78/170 => Loss 5.024, Loss_clf 1.156, Loss_fe 0.943, Loss_kd 2.336, Train_accy 65.72, Test_accy 65.58
2024-08-07 17:17:56,185 [foster.py] => Task 4, Epoch 79/170 => Loss 5.039, Loss_clf 1.162, Loss_fe 0.946, Loss_kd 2.341, Train_accy 65.86, Test_accy 65.49
2024-08-07 17:18:10,984 [foster.py] => Task 4, Epoch 80/170 => Loss 5.013, Loss_clf 1.137, Loss_fe 0.948, Loss_kd 2.339, Train_accy 66.32, Test_accy 66.98
2024-08-07 17:18:22,888 [foster.py] => Task 4, Epoch 81/170 => Loss 4.943, Loss_clf 1.111, Loss_fe 0.911, Loss_kd 2.333, Train_accy 66.77
2024-08-07 17:18:37,651 [foster.py] => Task 4, Epoch 82/170 => Loss 4.958, Loss_clf 1.109, Loss_fe 0.920, Loss_kd 2.340, Train_accy 66.82, Test_accy 64.91
2024-08-07 17:18:52,563 [foster.py] => Task 4, Epoch 83/170 => Loss 4.957, Loss_clf 1.122, Loss_fe 0.909, Loss_kd 2.338, Train_accy 66.62, Test_accy 66.68
2024-08-07 17:19:07,306 [foster.py] => Task 4, Epoch 84/170 => Loss 4.925, Loss_clf 1.105, Loss_fe 0.904, Loss_kd 2.330, Train_accy 67.20, Test_accy 66.13
2024-08-07 17:19:22,057 [foster.py] => Task 4, Epoch 85/170 => Loss 4.934, Loss_clf 1.111, Loss_fe 0.904, Loss_kd 2.332, Train_accy 67.34, Test_accy 65.55
2024-08-07 17:19:33,867 [foster.py] => Task 4, Epoch 86/170 => Loss 4.940, Loss_clf 1.117, Loss_fe 0.905, Loss_kd 2.331, Train_accy 66.76
2024-08-07 17:19:48,739 [foster.py] => Task 4, Epoch 87/170 => Loss 4.860, Loss_clf 1.072, Loss_fe 0.874, Loss_kd 2.328, Train_accy 68.20, Test_accy 66.85
2024-08-07 17:20:03,631 [foster.py] => Task 4, Epoch 88/170 => Loss 4.917, Loss_clf 1.097, Loss_fe 0.889, Loss_kd 2.342, Train_accy 67.82, Test_accy 64.78
2024-08-07 17:20:18,372 [foster.py] => Task 4, Epoch 89/170 => Loss 4.867, Loss_clf 1.063, Loss_fe 0.887, Loss_kd 2.331, Train_accy 67.53, Test_accy 66.61
2024-08-07 17:20:33,231 [foster.py] => Task 4, Epoch 90/170 => Loss 4.861, Loss_clf 1.060, Loss_fe 0.871, Loss_kd 2.340, Train_accy 67.51, Test_accy 66.24
2024-08-07 17:20:45,267 [foster.py] => Task 4, Epoch 91/170 => Loss 4.834, Loss_clf 1.055, Loss_fe 0.859, Loss_kd 2.332, Train_accy 68.72
2024-08-07 17:20:59,876 [foster.py] => Task 4, Epoch 92/170 => Loss 4.846, Loss_clf 1.056, Loss_fe 0.869, Loss_kd 2.334, Train_accy 67.91, Test_accy 66.68
2024-08-07 17:21:14,570 [foster.py] => Task 4, Epoch 93/170 => Loss 4.798, Loss_clf 1.029, Loss_fe 0.847, Loss_kd 2.334, Train_accy 69.04, Test_accy 66.49
2024-08-07 17:21:29,248 [foster.py] => Task 4, Epoch 94/170 => Loss 4.805, Loss_clf 1.032, Loss_fe 0.841, Loss_kd 2.342, Train_accy 68.51, Test_accy 66.33
2024-08-07 17:21:44,041 [foster.py] => Task 4, Epoch 95/170 => Loss 4.802, Loss_clf 1.042, Loss_fe 0.842, Loss_kd 2.331, Train_accy 68.62, Test_accy 65.66
2024-08-07 17:21:55,935 [foster.py] => Task 4, Epoch 96/170 => Loss 4.775, Loss_clf 1.016, Loss_fe 0.833, Loss_kd 2.337, Train_accy 68.98
2024-08-07 17:22:10,725 [foster.py] => Task 4, Epoch 97/170 => Loss 4.781, Loss_clf 1.011, Loss_fe 0.836, Loss_kd 2.343, Train_accy 68.68, Test_accy 66.80
2024-08-07 17:22:25,490 [foster.py] => Task 4, Epoch 98/170 => Loss 4.717, Loss_clf 0.989, Loss_fe 0.806, Loss_kd 2.334, Train_accy 69.12, Test_accy 67.07
2024-08-07 17:22:40,520 [foster.py] => Task 4, Epoch 99/170 => Loss 4.717, Loss_clf 0.992, Loss_fe 0.802, Loss_kd 2.335, Train_accy 69.61, Test_accy 67.08
2024-08-07 17:22:55,423 [foster.py] => Task 4, Epoch 100/170 => Loss 4.702, Loss_clf 0.969, Loss_fe 0.808, Loss_kd 2.336, Train_accy 70.35, Test_accy 66.71
2024-08-07 17:23:07,196 [foster.py] => Task 4, Epoch 101/170 => Loss 4.713, Loss_clf 0.984, Loss_fe 0.807, Loss_kd 2.334, Train_accy 69.86
2024-08-07 17:23:21,920 [foster.py] => Task 4, Epoch 102/170 => Loss 4.676, Loss_clf 0.963, Loss_fe 0.793, Loss_kd 2.332, Train_accy 69.95, Test_accy 67.17
2024-08-07 17:23:36,848 [foster.py] => Task 4, Epoch 103/170 => Loss 4.704, Loss_clf 0.975, Loss_fe 0.801, Loss_kd 2.339, Train_accy 70.32, Test_accy 66.81
2024-08-07 17:23:51,565 [foster.py] => Task 4, Epoch 104/170 => Loss 4.611, Loss_clf 0.932, Loss_fe 0.759, Loss_kd 2.333, Train_accy 70.78, Test_accy 65.92
2024-08-07 17:24:06,353 [foster.py] => Task 4, Epoch 105/170 => Loss 4.618, Loss_clf 0.927, Loss_fe 0.773, Loss_kd 2.330, Train_accy 71.50, Test_accy 67.37
2024-08-07 17:24:18,264 [foster.py] => Task 4, Epoch 106/170 => Loss 4.641, Loss_clf 0.953, Loss_fe 0.768, Loss_kd 2.332, Train_accy 70.47
2024-08-07 17:24:33,320 [foster.py] => Task 4, Epoch 107/170 => Loss 4.688, Loss_clf 0.973, Loss_fe 0.785, Loss_kd 2.340, Train_accy 70.12, Test_accy 67.41
2024-08-07 17:24:48,145 [foster.py] => Task 4, Epoch 108/170 => Loss 4.581, Loss_clf 0.921, Loss_fe 0.740, Loss_kd 2.332, Train_accy 71.10, Test_accy 67.64
2024-08-07 17:25:02,948 [foster.py] => Task 4, Epoch 109/170 => Loss 4.593, Loss_clf 0.924, Loss_fe 0.744, Loss_kd 2.337, Train_accy 71.28, Test_accy 67.11
2024-08-07 17:25:17,776 [foster.py] => Task 4, Epoch 110/170 => Loss 4.589, Loss_clf 0.916, Loss_fe 0.747, Loss_kd 2.337, Train_accy 71.44, Test_accy 67.15
2024-08-07 17:25:29,502 [foster.py] => Task 4, Epoch 111/170 => Loss 4.550, Loss_clf 0.894, Loss_fe 0.732, Loss_kd 2.335, Train_accy 72.28
2024-08-07 17:25:44,149 [foster.py] => Task 4, Epoch 112/170 => Loss 4.517, Loss_clf 0.886, Loss_fe 0.717, Loss_kd 2.328, Train_accy 72.27, Test_accy 67.57
2024-08-07 17:25:59,272 [foster.py] => Task 4, Epoch 113/170 => Loss 4.525, Loss_clf 0.884, Loss_fe 0.710, Loss_kd 2.341, Train_accy 72.32, Test_accy 67.89
2024-08-07 17:26:14,251 [foster.py] => Task 4, Epoch 114/170 => Loss 4.517, Loss_clf 0.883, Loss_fe 0.719, Loss_kd 2.329, Train_accy 72.26, Test_accy 67.66
2024-08-07 17:26:28,941 [foster.py] => Task 4, Epoch 115/170 => Loss 4.551, Loss_clf 0.910, Loss_fe 0.728, Loss_kd 2.327, Train_accy 72.08, Test_accy 67.03
2024-08-07 17:26:40,592 [foster.py] => Task 4, Epoch 116/170 => Loss 4.456, Loss_clf 0.858, Loss_fe 0.682, Loss_kd 2.330, Train_accy 73.44
2024-08-07 17:26:55,372 [foster.py] => Task 4, Epoch 117/170 => Loss 4.494, Loss_clf 0.869, Loss_fe 0.700, Loss_kd 2.337, Train_accy 73.05, Test_accy 67.29
2024-08-07 17:27:10,153 [foster.py] => Task 4, Epoch 118/170 => Loss 4.467, Loss_clf 0.855, Loss_fe 0.687, Loss_kd 2.336, Train_accy 73.42, Test_accy 67.66
2024-08-07 17:27:24,839 [foster.py] => Task 4, Epoch 119/170 => Loss 4.464, Loss_clf 0.860, Loss_fe 0.681, Loss_kd 2.335, Train_accy 73.52, Test_accy 67.25
2024-08-07 17:27:39,458 [foster.py] => Task 4, Epoch 120/170 => Loss 4.416, Loss_clf 0.827, Loss_fe 0.667, Loss_kd 2.334, Train_accy 74.25, Test_accy 67.36
2024-08-07 17:27:51,369 [foster.py] => Task 4, Epoch 121/170 => Loss 4.401, Loss_clf 0.826, Loss_fe 0.656, Loss_kd 2.332, Train_accy 73.90
2024-08-07 17:28:06,110 [foster.py] => Task 4, Epoch 122/170 => Loss 4.449, Loss_clf 0.852, Loss_fe 0.670, Loss_kd 2.338, Train_accy 73.62, Test_accy 67.53
2024-08-07 17:28:20,844 [foster.py] => Task 4, Epoch 123/170 => Loss 4.365, Loss_clf 0.802, Loss_fe 0.643, Loss_kd 2.332, Train_accy 74.34, Test_accy 67.57
2024-08-07 17:28:35,639 [foster.py] => Task 4, Epoch 124/170 => Loss 4.384, Loss_clf 0.815, Loss_fe 0.648, Loss_kd 2.334, Train_accy 74.78, Test_accy 68.12
2024-08-07 17:28:50,522 [foster.py] => Task 4, Epoch 125/170 => Loss 4.352, Loss_clf 0.795, Loss_fe 0.634, Loss_kd 2.335, Train_accy 75.67, Test_accy 68.10
2024-08-07 17:29:03,382 [foster.py] => Task 4, Epoch 126/170 => Loss 4.349, Loss_clf 0.798, Loss_fe 0.629, Loss_kd 2.335, Train_accy 74.68
2024-08-07 17:29:18,667 [foster.py] => Task 4, Epoch 127/170 => Loss 4.304, Loss_clf 0.775, Loss_fe 0.617, Loss_kd 2.326, Train_accy 75.28, Test_accy 68.42
2024-08-07 17:29:33,711 [foster.py] => Task 4, Epoch 128/170 => Loss 4.340, Loss_clf 0.791, Loss_fe 0.624, Loss_kd 2.336, Train_accy 75.14, Test_accy 68.21
2024-08-07 17:29:48,422 [foster.py] => Task 4, Epoch 129/170 => Loss 4.253, Loss_clf 0.748, Loss_fe 0.592, Loss_kd 2.327, Train_accy 76.05, Test_accy 68.02
2024-08-07 17:30:03,121 [foster.py] => Task 4, Epoch 130/170 => Loss 4.295, Loss_clf 0.775, Loss_fe 0.607, Loss_kd 2.326, Train_accy 75.55, Test_accy 68.13
2024-08-07 17:30:15,011 [foster.py] => Task 4, Epoch 131/170 => Loss 4.286, Loss_clf 0.767, Loss_fe 0.605, Loss_kd 2.328, Train_accy 75.88
2024-08-07 17:30:29,954 [foster.py] => Task 4, Epoch 132/170 => Loss 4.282, Loss_clf 0.759, Loss_fe 0.596, Loss_kd 2.338, Train_accy 76.48, Test_accy 67.82
2024-08-07 17:30:44,730 [foster.py] => Task 4, Epoch 133/170 => Loss 4.224, Loss_clf 0.734, Loss_fe 0.571, Loss_kd 2.332, Train_accy 77.01, Test_accy 68.53
2024-08-07 17:30:59,531 [foster.py] => Task 4, Epoch 134/170 => Loss 4.237, Loss_clf 0.747, Loss_fe 0.575, Loss_kd 2.328, Train_accy 76.54, Test_accy 68.42
2024-08-07 17:31:14,180 [foster.py] => Task 4, Epoch 135/170 => Loss 4.232, Loss_clf 0.733, Loss_fe 0.576, Loss_kd 2.335, Train_accy 77.38, Test_accy 68.52
2024-08-07 17:31:25,963 [foster.py] => Task 4, Epoch 136/170 => Loss 4.163, Loss_clf 0.708, Loss_fe 0.549, Loss_kd 2.322, Train_accy 77.38
2024-08-07 17:31:40,867 [foster.py] => Task 4, Epoch 137/170 => Loss 4.197, Loss_clf 0.715, Loss_fe 0.562, Loss_kd 2.332, Train_accy 77.34, Test_accy 68.20
2024-08-07 17:31:55,782 [foster.py] => Task 4, Epoch 138/170 => Loss 4.184, Loss_clf 0.715, Loss_fe 0.550, Loss_kd 2.331, Train_accy 77.52, Test_accy 68.31
2024-08-07 17:32:10,482 [foster.py] => Task 4, Epoch 139/170 => Loss 4.167, Loss_clf 0.705, Loss_fe 0.543, Loss_kd 2.332, Train_accy 77.91, Test_accy 68.25
2024-08-07 17:32:25,384 [foster.py] => Task 4, Epoch 140/170 => Loss 4.147, Loss_clf 0.693, Loss_fe 0.530, Loss_kd 2.336, Train_accy 78.16, Test_accy 68.29
2024-08-07 17:32:37,287 [foster.py] => Task 4, Epoch 141/170 => Loss 4.158, Loss_clf 0.698, Loss_fe 0.528, Loss_kd 2.342, Train_accy 77.82
2024-08-07 17:32:52,030 [foster.py] => Task 4, Epoch 142/170 => Loss 4.146, Loss_clf 0.695, Loss_fe 0.530, Loss_kd 2.333, Train_accy 78.04, Test_accy 68.61
2024-08-07 17:33:06,824 [foster.py] => Task 4, Epoch 143/170 => Loss 4.103, Loss_clf 0.675, Loss_fe 0.511, Loss_kd 2.331, Train_accy 78.21, Test_accy 68.74
2024-08-07 17:33:21,677 [foster.py] => Task 4, Epoch 144/170 => Loss 4.070, Loss_clf 0.653, Loss_fe 0.496, Loss_kd 2.334, Train_accy 79.39, Test_accy 68.64
2024-08-07 17:33:36,385 [foster.py] => Task 4, Epoch 145/170 => Loss 4.110, Loss_clf 0.672, Loss_fe 0.514, Loss_kd 2.336, Train_accy 78.41, Test_accy 68.41
2024-08-07 17:33:48,269 [foster.py] => Task 4, Epoch 146/170 => Loss 4.087, Loss_clf 0.665, Loss_fe 0.500, Loss_kd 2.334, Train_accy 79.01
2024-08-07 17:34:02,910 [foster.py] => Task 4, Epoch 147/170 => Loss 4.081, Loss_clf 0.661, Loss_fe 0.499, Loss_kd 2.333, Train_accy 79.02, Test_accy 68.48
2024-08-07 17:34:17,938 [foster.py] => Task 4, Epoch 148/170 => Loss 4.047, Loss_clf 0.644, Loss_fe 0.483, Loss_kd 2.332, Train_accy 79.53, Test_accy 68.83
2024-08-07 17:34:33,051 [foster.py] => Task 4, Epoch 149/170 => Loss 4.030, Loss_clf 0.633, Loss_fe 0.480, Loss_kd 2.330, Train_accy 79.97, Test_accy 68.66
2024-08-07 17:34:47,814 [foster.py] => Task 4, Epoch 150/170 => Loss 4.037, Loss_clf 0.638, Loss_fe 0.479, Loss_kd 2.333, Train_accy 80.01, Test_accy 68.77
2024-08-07 17:34:59,538 [foster.py] => Task 4, Epoch 151/170 => Loss 4.030, Loss_clf 0.630, Loss_fe 0.475, Loss_kd 2.336, Train_accy 79.75
2024-08-07 17:35:14,260 [foster.py] => Task 4, Epoch 152/170 => Loss 4.045, Loss_clf 0.645, Loss_fe 0.478, Loss_kd 2.334, Train_accy 79.53, Test_accy 68.75
2024-08-07 17:35:29,083 [foster.py] => Task 4, Epoch 153/170 => Loss 4.011, Loss_clf 0.634, Loss_fe 0.460, Loss_kd 2.330, Train_accy 79.55, Test_accy 68.83
2024-08-07 17:35:43,749 [foster.py] => Task 4, Epoch 154/170 => Loss 4.011, Loss_clf 0.635, Loss_fe 0.461, Loss_kd 2.328, Train_accy 79.95, Test_accy 68.83
2024-08-07 17:35:58,541 [foster.py] => Task 4, Epoch 155/170 => Loss 3.985, Loss_clf 0.617, Loss_fe 0.455, Loss_kd 2.327, Train_accy 79.98, Test_accy 68.84
2024-08-07 17:36:10,384 [foster.py] => Task 4, Epoch 156/170 => Loss 4.014, Loss_clf 0.629, Loss_fe 0.463, Loss_kd 2.334, Train_accy 80.28
2024-08-07 17:36:25,452 [foster.py] => Task 4, Epoch 157/170 => Loss 3.972, Loss_clf 0.609, Loss_fe 0.448, Loss_kd 2.329, Train_accy 80.63, Test_accy 69.15
2024-08-07 17:36:40,744 [foster.py] => Task 4, Epoch 158/170 => Loss 3.997, Loss_clf 0.621, Loss_fe 0.455, Loss_kd 2.333, Train_accy 80.68, Test_accy 69.14
2024-08-07 17:36:55,768 [foster.py] => Task 4, Epoch 159/170 => Loss 3.992, Loss_clf 0.621, Loss_fe 0.455, Loss_kd 2.329, Train_accy 80.00, Test_accy 68.98
2024-08-07 17:37:10,700 [foster.py] => Task 4, Epoch 160/170 => Loss 3.978, Loss_clf 0.612, Loss_fe 0.445, Loss_kd 2.333, Train_accy 80.68, Test_accy 69.12
2024-08-07 17:37:22,492 [foster.py] => Task 4, Epoch 161/170 => Loss 3.951, Loss_clf 0.596, Loss_fe 0.441, Loss_kd 2.328, Train_accy 80.92
2024-08-07 17:37:37,167 [foster.py] => Task 4, Epoch 162/170 => Loss 3.941, Loss_clf 0.590, Loss_fe 0.430, Loss_kd 2.334, Train_accy 81.42, Test_accy 68.98
2024-08-07 17:37:51,889 [foster.py] => Task 4, Epoch 163/170 => Loss 3.988, Loss_clf 0.616, Loss_fe 0.455, Loss_kd 2.330, Train_accy 80.62, Test_accy 69.10
2024-08-07 17:38:06,814 [foster.py] => Task 4, Epoch 164/170 => Loss 3.969, Loss_clf 0.612, Loss_fe 0.444, Loss_kd 2.327, Train_accy 81.03, Test_accy 69.01
2024-08-07 17:38:21,515 [foster.py] => Task 4, Epoch 165/170 => Loss 3.952, Loss_clf 0.598, Loss_fe 0.433, Loss_kd 2.333, Train_accy 81.22, Test_accy 68.94
2024-08-07 17:38:33,595 [foster.py] => Task 4, Epoch 166/170 => Loss 3.977, Loss_clf 0.615, Loss_fe 0.448, Loss_kd 2.328, Train_accy 80.33
2024-08-07 17:38:48,418 [foster.py] => Task 4, Epoch 167/170 => Loss 3.973, Loss_clf 0.611, Loss_fe 0.437, Loss_kd 2.337, Train_accy 80.69, Test_accy 68.91
2024-08-07 17:39:03,163 [foster.py] => Task 4, Epoch 168/170 => Loss 3.949, Loss_clf 0.598, Loss_fe 0.439, Loss_kd 2.327, Train_accy 80.78, Test_accy 68.94
2024-08-07 17:39:18,053 [foster.py] => Task 4, Epoch 169/170 => Loss 3.947, Loss_clf 0.594, Loss_fe 0.433, Loss_kd 2.333, Train_accy 81.17, Test_accy 68.83
2024-08-07 17:39:32,727 [foster.py] => Task 4, Epoch 170/170 => Loss 3.976, Loss_clf 0.606, Loss_fe 0.453, Loss_kd 2.330, Train_accy 81.03, Test_accy 68.91
2024-08-07 17:39:32,730 [foster.py] => do not weight align teacher!
2024-08-07 17:39:32,733 [foster.py] => per cls weights : [1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989 1.09553989
 1.09553989 1.09553989 0.61784045 0.61784045 0.61784045 0.61784045
 0.61784045 0.61784045 0.61784045 0.61784045 0.61784045 0.61784045
 0.61784045 0.61784045 0.61784045 0.61784045 0.61784045 0.61784045
 0.61784045 0.61784045 0.61784045 0.61784045]
2024-08-07 17:39:52,663 [foster.py] => SNet: Task 4, Epoch 1/130 => Loss 31.801,  Loss1 0.795, Train_accy 27.10, Test_accy 59.89
2024-08-07 17:40:09,587 [foster.py] => SNet: Task 4, Epoch 2/130 => Loss 31.645,  Loss1 0.795, Train_accy 45.86
2024-08-07 17:40:26,420 [foster.py] => SNet: Task 4, Epoch 3/130 => Loss 31.597,  Loss1 0.794, Train_accy 50.86
2024-08-07 17:40:43,660 [foster.py] => SNet: Task 4, Epoch 4/130 => Loss 31.580,  Loss1 0.794, Train_accy 52.95
2024-08-07 17:41:00,517 [foster.py] => SNet: Task 4, Epoch 5/130 => Loss 31.555,  Loss1 0.794, Train_accy 55.17
2024-08-07 17:41:20,163 [foster.py] => SNet: Task 4, Epoch 6/130 => Loss 31.562,  Loss1 0.794, Train_accy 55.98, Test_accy 63.34
2024-08-07 17:41:37,257 [foster.py] => SNet: Task 4, Epoch 7/130 => Loss 31.547,  Loss1 0.795, Train_accy 56.73
2024-08-07 17:41:54,868 [foster.py] => SNet: Task 4, Epoch 8/130 => Loss 31.538,  Loss1 0.795, Train_accy 58.27
2024-08-07 17:42:12,038 [foster.py] => SNet: Task 4, Epoch 9/130 => Loss 31.533,  Loss1 0.795, Train_accy 58.23
2024-08-07 17:42:28,846 [foster.py] => SNet: Task 4, Epoch 10/130 => Loss 31.555,  Loss1 0.794, Train_accy 58.85
2024-08-07 17:42:48,664 [foster.py] => SNet: Task 4, Epoch 11/130 => Loss 31.547,  Loss1 0.795, Train_accy 58.66, Test_accy 63.72
2024-08-07 17:43:05,448 [foster.py] => SNet: Task 4, Epoch 12/130 => Loss 31.544,  Loss1 0.794, Train_accy 59.54
2024-08-07 17:43:22,332 [foster.py] => SNet: Task 4, Epoch 13/130 => Loss 31.536,  Loss1 0.794, Train_accy 60.32
2024-08-07 17:43:39,206 [foster.py] => SNet: Task 4, Epoch 14/130 => Loss 31.531,  Loss1 0.795, Train_accy 60.76
2024-08-07 17:43:56,200 [foster.py] => SNet: Task 4, Epoch 15/130 => Loss 31.531,  Loss1 0.794, Train_accy 61.06
2024-08-07 17:44:15,878 [foster.py] => SNet: Task 4, Epoch 16/130 => Loss 31.525,  Loss1 0.794, Train_accy 60.97, Test_accy 64.71
2024-08-07 17:44:33,139 [foster.py] => SNet: Task 4, Epoch 17/130 => Loss 31.525,  Loss1 0.795, Train_accy 60.71
2024-08-07 17:44:50,238 [foster.py] => SNet: Task 4, Epoch 18/130 => Loss 31.536,  Loss1 0.794, Train_accy 61.89
2024-08-07 17:45:07,125 [foster.py] => SNet: Task 4, Epoch 19/130 => Loss 31.508,  Loss1 0.794, Train_accy 61.59
2024-08-07 17:45:24,165 [foster.py] => SNet: Task 4, Epoch 20/130 => Loss 31.515,  Loss1 0.794, Train_accy 61.68
2024-08-07 17:45:43,782 [foster.py] => SNet: Task 4, Epoch 21/130 => Loss 31.514,  Loss1 0.794, Train_accy 61.48, Test_accy 64.35
2024-08-07 17:46:01,162 [foster.py] => SNet: Task 4, Epoch 22/130 => Loss 31.497,  Loss1 0.795, Train_accy 62.72
2024-08-07 17:46:18,079 [foster.py] => SNet: Task 4, Epoch 23/130 => Loss 31.508,  Loss1 0.794, Train_accy 62.08
2024-08-07 17:46:35,199 [foster.py] => SNet: Task 4, Epoch 24/130 => Loss 31.517,  Loss1 0.794, Train_accy 61.98
2024-08-07 17:46:52,124 [foster.py] => SNet: Task 4, Epoch 25/130 => Loss 31.498,  Loss1 0.794, Train_accy 63.15
2024-08-07 17:47:11,827 [foster.py] => SNet: Task 4, Epoch 26/130 => Loss 31.505,  Loss1 0.794, Train_accy 62.78, Test_accy 65.60
2024-08-07 17:47:28,940 [foster.py] => SNet: Task 4, Epoch 27/130 => Loss 31.530,  Loss1 0.794, Train_accy 63.08
2024-08-07 17:47:45,786 [foster.py] => SNet: Task 4, Epoch 28/130 => Loss 31.514,  Loss1 0.794, Train_accy 63.10
2024-08-07 17:48:02,865 [foster.py] => SNet: Task 4, Epoch 29/130 => Loss 31.510,  Loss1 0.794, Train_accy 63.06
2024-08-07 17:48:20,032 [foster.py] => SNet: Task 4, Epoch 30/130 => Loss 31.488,  Loss1 0.795, Train_accy 63.49
2024-08-07 17:48:39,757 [foster.py] => SNet: Task 4, Epoch 31/130 => Loss 31.506,  Loss1 0.795, Train_accy 63.22, Test_accy 65.03
2024-08-07 17:48:56,556 [foster.py] => SNet: Task 4, Epoch 32/130 => Loss 31.517,  Loss1 0.794, Train_accy 63.32
2024-08-07 17:49:13,403 [foster.py] => SNet: Task 4, Epoch 33/130 => Loss 31.518,  Loss1 0.794, Train_accy 63.94
2024-08-07 17:49:30,218 [foster.py] => SNet: Task 4, Epoch 34/130 => Loss 31.509,  Loss1 0.795, Train_accy 63.47
2024-08-07 17:49:47,237 [foster.py] => SNet: Task 4, Epoch 35/130 => Loss 31.511,  Loss1 0.794, Train_accy 63.42
2024-08-07 17:50:06,954 [foster.py] => SNet: Task 4, Epoch 36/130 => Loss 31.494,  Loss1 0.794, Train_accy 64.68, Test_accy 65.22
2024-08-07 17:50:24,008 [foster.py] => SNet: Task 4, Epoch 37/130 => Loss 31.497,  Loss1 0.794, Train_accy 63.98
2024-08-07 17:50:40,874 [foster.py] => SNet: Task 4, Epoch 38/130 => Loss 31.494,  Loss1 0.795, Train_accy 63.72
2024-08-07 17:50:57,685 [foster.py] => SNet: Task 4, Epoch 39/130 => Loss 31.502,  Loss1 0.795, Train_accy 64.17
2024-08-07 17:51:14,933 [foster.py] => SNet: Task 4, Epoch 40/130 => Loss 31.497,  Loss1 0.794, Train_accy 64.54
2024-08-07 17:51:34,743 [foster.py] => SNet: Task 4, Epoch 41/130 => Loss 31.494,  Loss1 0.794, Train_accy 64.98, Test_accy 65.44
2024-08-07 17:51:51,563 [foster.py] => SNet: Task 4, Epoch 42/130 => Loss 31.496,  Loss1 0.795, Train_accy 65.40
2024-08-07 17:52:08,480 [foster.py] => SNet: Task 4, Epoch 43/130 => Loss 31.497,  Loss1 0.794, Train_accy 65.58
2024-08-07 17:52:25,316 [foster.py] => SNet: Task 4, Epoch 44/130 => Loss 31.485,  Loss1 0.795, Train_accy 64.99
2024-08-07 17:52:42,470 [foster.py] => SNet: Task 4, Epoch 45/130 => Loss 31.494,  Loss1 0.794, Train_accy 65.04
2024-08-07 17:53:01,932 [foster.py] => SNet: Task 4, Epoch 46/130 => Loss 31.489,  Loss1 0.794, Train_accy 65.14, Test_accy 65.52
2024-08-07 17:53:18,838 [foster.py] => SNet: Task 4, Epoch 47/130 => Loss 31.500,  Loss1 0.794, Train_accy 65.35
2024-08-07 17:53:35,779 [foster.py] => SNet: Task 4, Epoch 48/130 => Loss 31.480,  Loss1 0.794, Train_accy 65.58
2024-08-07 17:53:52,825 [foster.py] => SNet: Task 4, Epoch 49/130 => Loss 31.486,  Loss1 0.794, Train_accy 64.98
2024-08-07 17:54:09,990 [foster.py] => SNet: Task 4, Epoch 50/130 => Loss 31.497,  Loss1 0.795, Train_accy 65.11
2024-08-07 17:54:29,515 [foster.py] => SNet: Task 4, Epoch 51/130 => Loss 31.492,  Loss1 0.794, Train_accy 65.40, Test_accy 66.11
2024-08-07 17:54:46,399 [foster.py] => SNet: Task 4, Epoch 52/130 => Loss 31.500,  Loss1 0.794, Train_accy 65.28
2024-08-07 17:55:03,690 [foster.py] => SNet: Task 4, Epoch 53/130 => Loss 31.494,  Loss1 0.794, Train_accy 64.68
2024-08-07 17:55:20,678 [foster.py] => SNet: Task 4, Epoch 54/130 => Loss 31.497,  Loss1 0.795, Train_accy 64.94
2024-08-07 17:55:37,586 [foster.py] => SNet: Task 4, Epoch 55/130 => Loss 31.485,  Loss1 0.794, Train_accy 65.86
2024-08-07 17:55:57,225 [foster.py] => SNet: Task 4, Epoch 56/130 => Loss 31.476,  Loss1 0.794, Train_accy 65.78, Test_accy 65.92
2024-08-07 17:56:14,154 [foster.py] => SNet: Task 4, Epoch 57/130 => Loss 31.489,  Loss1 0.795, Train_accy 66.37
2024-08-07 17:56:30,944 [foster.py] => SNet: Task 4, Epoch 58/130 => Loss 31.497,  Loss1 0.794, Train_accy 66.12
2024-08-07 17:56:48,242 [foster.py] => SNet: Task 4, Epoch 59/130 => Loss 31.466,  Loss1 0.794, Train_accy 65.93
2024-08-07 17:57:05,136 [foster.py] => SNet: Task 4, Epoch 60/130 => Loss 31.495,  Loss1 0.794, Train_accy 66.04
2024-08-07 17:57:24,660 [foster.py] => SNet: Task 4, Epoch 61/130 => Loss 31.481,  Loss1 0.794, Train_accy 65.64, Test_accy 66.12
2024-08-07 17:57:41,770 [foster.py] => SNet: Task 4, Epoch 62/130 => Loss 31.461,  Loss1 0.794, Train_accy 65.91
2024-08-07 17:57:58,671 [foster.py] => SNet: Task 4, Epoch 63/130 => Loss 31.482,  Loss1 0.794, Train_accy 66.53
2024-08-07 17:58:15,801 [foster.py] => SNet: Task 4, Epoch 64/130 => Loss 31.488,  Loss1 0.794, Train_accy 66.03
2024-08-07 17:58:32,599 [foster.py] => SNet: Task 4, Epoch 65/130 => Loss 31.487,  Loss1 0.795, Train_accy 65.88
2024-08-07 17:58:52,107 [foster.py] => SNet: Task 4, Epoch 66/130 => Loss 31.485,  Loss1 0.794, Train_accy 66.36, Test_accy 66.13
2024-08-07 17:59:09,138 [foster.py] => SNet: Task 4, Epoch 67/130 => Loss 31.468,  Loss1 0.794, Train_accy 66.31
2024-08-07 17:59:26,399 [foster.py] => SNet: Task 4, Epoch 68/130 => Loss 31.480,  Loss1 0.794, Train_accy 66.57
2024-08-07 17:59:43,648 [foster.py] => SNet: Task 4, Epoch 69/130 => Loss 31.474,  Loss1 0.794, Train_accy 66.92
2024-08-07 18:00:00,471 [foster.py] => SNet: Task 4, Epoch 70/130 => Loss 31.462,  Loss1 0.794, Train_accy 66.28
2024-08-07 18:00:20,000 [foster.py] => SNet: Task 4, Epoch 71/130 => Loss 31.474,  Loss1 0.794, Train_accy 66.18, Test_accy 66.50
2024-08-07 18:00:37,534 [foster.py] => SNet: Task 4, Epoch 72/130 => Loss 31.474,  Loss1 0.794, Train_accy 66.44
2024-08-07 18:00:54,855 [foster.py] => SNet: Task 4, Epoch 73/130 => Loss 31.492,  Loss1 0.794, Train_accy 66.28
2024-08-07 18:01:11,505 [foster.py] => SNet: Task 4, Epoch 74/130 => Loss 31.468,  Loss1 0.794, Train_accy 66.62
2024-08-07 18:01:28,463 [foster.py] => SNet: Task 4, Epoch 75/130 => Loss 31.479,  Loss1 0.795, Train_accy 66.82
2024-08-07 18:01:47,791 [foster.py] => SNet: Task 4, Epoch 76/130 => Loss 31.476,  Loss1 0.794, Train_accy 66.61, Test_accy 66.57
2024-08-07 18:02:04,379 [foster.py] => SNet: Task 4, Epoch 77/130 => Loss 31.486,  Loss1 0.794, Train_accy 66.22
2024-08-07 18:02:21,102 [foster.py] => SNet: Task 4, Epoch 78/130 => Loss 31.457,  Loss1 0.795, Train_accy 67.40
2024-08-07 18:02:37,626 [foster.py] => SNet: Task 4, Epoch 79/130 => Loss 31.469,  Loss1 0.794, Train_accy 66.92
2024-08-07 18:02:54,572 [foster.py] => SNet: Task 4, Epoch 80/130 => Loss 31.492,  Loss1 0.794, Train_accy 66.72
2024-08-07 18:03:13,976 [foster.py] => SNet: Task 4, Epoch 81/130 => Loss 31.459,  Loss1 0.795, Train_accy 67.76, Test_accy 66.55
2024-08-07 18:03:30,554 [foster.py] => SNet: Task 4, Epoch 82/130 => Loss 31.467,  Loss1 0.794, Train_accy 66.73
2024-08-07 18:03:47,473 [foster.py] => SNet: Task 4, Epoch 83/130 => Loss 31.481,  Loss1 0.794, Train_accy 67.28
2024-08-07 18:04:04,174 [foster.py] => SNet: Task 4, Epoch 84/130 => Loss 31.475,  Loss1 0.794, Train_accy 66.23
2024-08-07 18:04:20,790 [foster.py] => SNet: Task 4, Epoch 85/130 => Loss 31.472,  Loss1 0.794, Train_accy 66.63
2024-08-07 18:04:40,174 [foster.py] => SNet: Task 4, Epoch 86/130 => Loss 31.470,  Loss1 0.794, Train_accy 67.29, Test_accy 66.75
2024-08-07 18:04:57,108 [foster.py] => SNet: Task 4, Epoch 87/130 => Loss 31.481,  Loss1 0.794, Train_accy 66.93
2024-08-07 18:05:14,254 [foster.py] => SNet: Task 4, Epoch 88/130 => Loss 31.470,  Loss1 0.794, Train_accy 67.12
2024-08-07 18:05:31,151 [foster.py] => SNet: Task 4, Epoch 89/130 => Loss 31.455,  Loss1 0.794, Train_accy 67.58
2024-08-07 18:05:47,998 [foster.py] => SNet: Task 4, Epoch 90/130 => Loss 31.464,  Loss1 0.794, Train_accy 67.20
2024-08-07 18:06:07,133 [foster.py] => SNet: Task 4, Epoch 91/130 => Loss 31.479,  Loss1 0.795, Train_accy 67.03, Test_accy 66.75
2024-08-07 18:06:23,918 [foster.py] => SNet: Task 4, Epoch 92/130 => Loss 31.461,  Loss1 0.794, Train_accy 67.65
2024-08-07 18:06:40,986 [foster.py] => SNet: Task 4, Epoch 93/130 => Loss 31.464,  Loss1 0.794, Train_accy 66.68
2024-08-07 18:06:57,566 [foster.py] => SNet: Task 4, Epoch 94/130 => Loss 31.461,  Loss1 0.794, Train_accy 66.79
2024-08-07 18:07:14,110 [foster.py] => SNet: Task 4, Epoch 95/130 => Loss 31.481,  Loss1 0.794, Train_accy 66.86
2024-08-07 18:07:33,245 [foster.py] => SNet: Task 4, Epoch 96/130 => Loss 31.473,  Loss1 0.795, Train_accy 66.95, Test_accy 66.88
2024-08-07 18:07:50,024 [foster.py] => SNet: Task 4, Epoch 97/130 => Loss 31.468,  Loss1 0.794, Train_accy 67.18
2024-08-07 18:08:06,689 [foster.py] => SNet: Task 4, Epoch 98/130 => Loss 31.483,  Loss1 0.794, Train_accy 67.80
2024-08-07 18:08:23,456 [foster.py] => SNet: Task 4, Epoch 99/130 => Loss 31.469,  Loss1 0.794, Train_accy 67.36
2024-08-07 18:08:40,069 [foster.py] => SNet: Task 4, Epoch 100/130 => Loss 31.465,  Loss1 0.794, Train_accy 66.98
2024-08-07 18:08:59,376 [foster.py] => SNet: Task 4, Epoch 101/130 => Loss 31.454,  Loss1 0.794, Train_accy 67.38, Test_accy 66.76
2024-08-07 18:09:16,095 [foster.py] => SNet: Task 4, Epoch 102/130 => Loss 31.466,  Loss1 0.794, Train_accy 67.12
2024-08-07 18:09:32,881 [foster.py] => SNet: Task 4, Epoch 103/130 => Loss 31.456,  Loss1 0.794, Train_accy 67.36
2024-08-07 18:09:49,420 [foster.py] => SNet: Task 4, Epoch 104/130 => Loss 31.459,  Loss1 0.794, Train_accy 67.06
2024-08-07 18:10:06,027 [foster.py] => SNet: Task 4, Epoch 105/130 => Loss 31.467,  Loss1 0.794, Train_accy 67.97
2024-08-07 18:10:25,194 [foster.py] => SNet: Task 4, Epoch 106/130 => Loss 31.475,  Loss1 0.794, Train_accy 66.56, Test_accy 66.79
2024-08-07 18:10:41,972 [foster.py] => SNet: Task 4, Epoch 107/130 => Loss 31.461,  Loss1 0.794, Train_accy 67.63
2024-08-07 18:10:58,678 [foster.py] => SNet: Task 4, Epoch 108/130 => Loss 31.464,  Loss1 0.795, Train_accy 67.68
2024-08-07 18:11:15,449 [foster.py] => SNet: Task 4, Epoch 109/130 => Loss 31.461,  Loss1 0.794, Train_accy 67.48
2024-08-07 18:11:32,626 [foster.py] => SNet: Task 4, Epoch 110/130 => Loss 31.469,  Loss1 0.794, Train_accy 67.53
2024-08-07 18:11:52,180 [foster.py] => SNet: Task 4, Epoch 111/130 => Loss 31.453,  Loss1 0.794, Train_accy 67.41, Test_accy 66.77
2024-08-07 18:12:09,154 [foster.py] => SNet: Task 4, Epoch 112/130 => Loss 31.465,  Loss1 0.795, Train_accy 67.82
2024-08-07 18:12:25,965 [foster.py] => SNet: Task 4, Epoch 113/130 => Loss 31.463,  Loss1 0.794, Train_accy 67.42
2024-08-07 18:12:42,702 [foster.py] => SNet: Task 4, Epoch 114/130 => Loss 31.456,  Loss1 0.794, Train_accy 67.00
2024-08-07 18:12:59,532 [foster.py] => SNet: Task 4, Epoch 115/130 => Loss 31.466,  Loss1 0.794, Train_accy 67.55
2024-08-07 18:13:18,717 [foster.py] => SNet: Task 4, Epoch 116/130 => Loss 31.466,  Loss1 0.794, Train_accy 66.88, Test_accy 67.17
2024-08-07 18:13:35,456 [foster.py] => SNet: Task 4, Epoch 117/130 => Loss 31.470,  Loss1 0.794, Train_accy 67.38
2024-08-07 18:13:52,089 [foster.py] => SNet: Task 4, Epoch 118/130 => Loss 31.471,  Loss1 0.794, Train_accy 67.26
2024-08-07 18:14:08,872 [foster.py] => SNet: Task 4, Epoch 119/130 => Loss 31.456,  Loss1 0.795, Train_accy 67.57
2024-08-07 18:14:25,594 [foster.py] => SNet: Task 4, Epoch 120/130 => Loss 31.449,  Loss1 0.794, Train_accy 67.19
2024-08-07 18:14:44,852 [foster.py] => SNet: Task 4, Epoch 121/130 => Loss 31.471,  Loss1 0.795, Train_accy 67.48, Test_accy 66.82
2024-08-07 18:15:01,779 [foster.py] => SNet: Task 4, Epoch 122/130 => Loss 31.457,  Loss1 0.794, Train_accy 67.22
2024-08-07 18:15:18,689 [foster.py] => SNet: Task 4, Epoch 123/130 => Loss 31.452,  Loss1 0.794, Train_accy 67.35
2024-08-07 18:15:35,439 [foster.py] => SNet: Task 4, Epoch 124/130 => Loss 31.463,  Loss1 0.794, Train_accy 67.10
2024-08-07 18:15:52,042 [foster.py] => SNet: Task 4, Epoch 125/130 => Loss 31.473,  Loss1 0.794, Train_accy 66.92
2024-08-07 18:16:11,440 [foster.py] => SNet: Task 4, Epoch 126/130 => Loss 31.470,  Loss1 0.794, Train_accy 67.50, Test_accy 66.73
2024-08-07 18:16:28,121 [foster.py] => SNet: Task 4, Epoch 127/130 => Loss 31.462,  Loss1 0.795, Train_accy 67.18
2024-08-07 18:16:45,064 [foster.py] => SNet: Task 4, Epoch 128/130 => Loss 31.480,  Loss1 0.794, Train_accy 67.65
2024-08-07 18:17:02,039 [foster.py] => SNet: Task 4, Epoch 129/130 => Loss 31.474,  Loss1 0.794, Train_accy 67.12
2024-08-07 18:17:18,674 [foster.py] => SNet: Task 4, Epoch 130/130 => Loss 31.470,  Loss1 0.794, Train_accy 67.39
2024-08-07 18:17:18,676 [foster.py] => do not weight align student!
2024-08-07 18:17:21,322 [foster.py] => darknet eval: 
2024-08-07 18:17:21,322 [foster.py] => CNN top1 curve: 66.85
2024-08-07 18:17:21,323 [foster.py] => CNN top5 curve: 91.0
2024-08-07 18:17:21,324 [foster.py] => CNN top1 平均值: 66.85
2024-08-07 18:17:21,327 [foster.py] => timees : 4687.459175109863
2024-08-07 18:17:21,328 [base.py] => Reducing exemplars...(20 per classes)
2024-08-07 18:17:47,767 [base.py] => Constructing exemplars...(20 per classes)
2024-08-07 18:18:13,683 [foster.py] => Exemplar size: 2000
2024-08-07 18:18:13,683 [trainer.py] => CNN: {'total': 68.91, '00-09': 71.2, '10-19': 56.3, '20-29': 70.9, '30-39': 66.1, '40-49': 70.9, '50-59': 65.6, '60-69': 74.7, '70-79': 64.8, '80-89': 72.4, '90-99': 76.2, 'old': 67.56, 'new': 74.3}
2024-08-07 18:18:13,684 [trainer.py] => NME: {'total': 64.56, '00-09': 67.1, '10-19': 53.3, '20-29': 66.6, '30-39': 60.3, '40-49': 66.6, '50-59': 61.4, '60-69': 64.4, '70-79': 61.5, '80-89': 71.8, '90-99': 72.6, 'old': 62.65, 'new': 72.2}
2024-08-07 18:18:13,684 [trainer.py] => CNN top1 curve: [87.15, 82.28, 77.25, 72.65, 68.91]
2024-08-07 18:18:13,684 [trainer.py] => CNN top5 curve: [98.3, 96.45, 94.98, 93.45, 91.67]
2024-08-07 18:18:13,685 [trainer.py] => NME top1 curve: [87.2, 82.42, 75.68, 69.74, 64.56]
2024-08-07 18:18:13,685 [trainer.py] => NME top5 curve: [98.45, 96.6, 94.38, 91.92, 89.9]

2024-08-07 18:18:13,685 [trainer.py] => CNN top1 平均值: 77.65