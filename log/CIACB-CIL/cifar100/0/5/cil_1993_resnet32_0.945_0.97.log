2024-08-31 12:28:18,518 [trainer.py] => config: ./configs/cifar/b0inc5.json
2024-08-31 12:28:18,519 [trainer.py] => prefix: cil
2024-08-31 12:28:18,520 [trainer.py] => dataset: cifar100
2024-08-31 12:28:18,520 [trainer.py] => memory_size: 2000
2024-08-31 12:28:18,520 [trainer.py] => memory_per_class: 20
2024-08-31 12:28:18,521 [trainer.py] => fixed_memory: False
2024-08-31 12:28:18,521 [trainer.py] => shuffle: True
2024-08-31 12:28:18,521 [trainer.py] => init_cls: 5
2024-08-31 12:28:18,522 [trainer.py] => increment: 5
2024-08-31 12:28:18,522 [trainer.py] => model_name: foster
2024-08-31 12:28:18,522 [trainer.py] => convnet_type: resnet32
2024-08-31 12:28:18,523 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-31 12:28:18,527 [trainer.py] => seed: 1993
2024-08-31 12:28:18,527 [trainer.py] => beta1: 0.945
2024-08-31 12:28:18,527 [trainer.py] => beta2: 0.97
2024-08-31 12:28:18,528 [trainer.py] => oofc: ft
2024-08-31 12:28:18,528 [trainer.py] => is_teacher_wa: False
2024-08-31 12:28:18,528 [trainer.py] => is_student_wa: False
2024-08-31 12:28:18,528 [trainer.py] => lambda_okd: 1
2024-08-31 12:28:18,528 [trainer.py] => wa_value: 1
2024-08-31 12:28:18,528 [trainer.py] => init_epochs: 200
2024-08-31 12:28:18,528 [trainer.py] => init_lr: 0.1
2024-08-31 12:28:18,528 [trainer.py] => init_weight_decay: 0.0005
2024-08-31 12:28:18,528 [trainer.py] => boosting_epochs: 170
2024-08-31 12:28:18,528 [trainer.py] => compression_epochs: 130
2024-08-31 12:28:18,528 [trainer.py] => lr: 0.1
2024-08-31 12:28:18,528 [trainer.py] => batch_size: 128
2024-08-31 12:28:18,528 [trainer.py] => weight_decay: 0.0005
2024-08-31 12:28:18,528 [trainer.py] => num_workers: 8
2024-08-31 12:28:18,528 [trainer.py] => T: 2
2024-08-31 12:28:20,938 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-31 12:28:21,044 [trainer.py] => All params: 0
2024-08-31 12:28:21,045 [trainer.py] => Trainable params: 0
2024-08-31 12:28:22,030 [foster.py] => Learning on 0-5
2024-08-31 12:28:22,031 [foster.py] => All params: 641924
2024-08-31 12:28:22,033 [foster.py] => Trainable params: 641924
2024-08-31 12:28:29,059 [foster.py] => Task 0, Epoch 1/200 => Loss 1.557, Train_accy 27.76, Test_accy 29.40
2024-08-31 12:28:31,550 [foster.py] => Task 0, Epoch 2/200 => Loss 1.369, Loss1 1.369,Train_accy 39.08
2024-08-31 12:28:34,103 [foster.py] => Task 0, Epoch 3/200 => Loss 1.301, Loss1 1.301,Train_accy 45.36
2024-08-31 12:28:36,636 [foster.py] => Task 0, Epoch 4/200 => Loss 1.203, Loss1 1.203,Train_accy 50.08
2024-08-31 12:28:39,125 [foster.py] => Task 0, Epoch 5/200 => Loss 1.099, Loss1 1.099,Train_accy 54.76
2024-08-31 12:28:42,426 [foster.py] => Task 0, Epoch 6/200 => Loss 1.048, Train_accy 56.96, Test_accy 70.20
2024-08-31 12:28:44,962 [foster.py] => Task 0, Epoch 7/200 => Loss 0.993, Loss1 0.993,Train_accy 58.96
2024-08-31 12:28:47,500 [foster.py] => Task 0, Epoch 8/200 => Loss 1.007, Loss1 1.007,Train_accy 59.24
2024-08-31 12:28:50,076 [foster.py] => Task 0, Epoch 9/200 => Loss 0.931, Loss1 0.931,Train_accy 62.84
2024-08-31 12:28:52,628 [foster.py] => Task 0, Epoch 10/200 => Loss 0.907, Loss1 0.907,Train_accy 63.92
2024-08-31 12:28:55,847 [foster.py] => Task 0, Epoch 11/200 => Loss 0.848, Train_accy 66.52, Test_accy 77.20
2024-08-31 12:28:58,355 [foster.py] => Task 0, Epoch 12/200 => Loss 0.832, Loss1 0.832,Train_accy 67.44
2024-08-31 12:29:00,903 [foster.py] => Task 0, Epoch 13/200 => Loss 0.865, Loss1 0.865,Train_accy 66.72
2024-08-31 12:29:03,427 [foster.py] => Task 0, Epoch 14/200 => Loss 0.802, Loss1 0.802,Train_accy 69.52
2024-08-31 12:29:06,014 [foster.py] => Task 0, Epoch 15/200 => Loss 0.811, Loss1 0.811,Train_accy 69.00
2024-08-31 12:29:09,215 [foster.py] => Task 0, Epoch 16/200 => Loss 0.781, Train_accy 70.32, Test_accy 75.80
2024-08-31 12:29:11,747 [foster.py] => Task 0, Epoch 17/200 => Loss 0.798, Loss1 0.798,Train_accy 70.12
2024-08-31 12:29:14,282 [foster.py] => Task 0, Epoch 18/200 => Loss 0.762, Loss1 0.762,Train_accy 71.92
2024-08-31 12:29:16,804 [foster.py] => Task 0, Epoch 19/200 => Loss 0.725, Loss1 0.725,Train_accy 72.96
2024-08-31 12:29:19,310 [foster.py] => Task 0, Epoch 20/200 => Loss 0.670, Loss1 0.670,Train_accy 75.48
2024-08-31 12:29:23,097 [foster.py] => Task 0, Epoch 21/200 => Loss 0.695, Train_accy 73.56, Test_accy 84.20
2024-08-31 12:29:25,609 [foster.py] => Task 0, Epoch 22/200 => Loss 0.741, Loss1 0.741,Train_accy 71.48
2024-08-31 12:29:28,139 [foster.py] => Task 0, Epoch 23/200 => Loss 0.680, Loss1 0.680,Train_accy 73.88
2024-08-31 12:29:30,656 [foster.py] => Task 0, Epoch 24/200 => Loss 0.668, Loss1 0.668,Train_accy 74.12
2024-08-31 12:29:33,214 [foster.py] => Task 0, Epoch 25/200 => Loss 0.690, Loss1 0.690,Train_accy 74.88
2024-08-31 12:29:36,463 [foster.py] => Task 0, Epoch 26/200 => Loss 0.630, Train_accy 76.40, Test_accy 84.80
2024-08-31 12:29:38,972 [foster.py] => Task 0, Epoch 27/200 => Loss 0.625, Loss1 0.625,Train_accy 76.04
2024-08-31 12:29:41,507 [foster.py] => Task 0, Epoch 28/200 => Loss 0.593, Loss1 0.593,Train_accy 78.32
2024-08-31 12:29:44,019 [foster.py] => Task 0, Epoch 29/200 => Loss 0.627, Loss1 0.627,Train_accy 77.68
2024-08-31 12:29:46,590 [foster.py] => Task 0, Epoch 30/200 => Loss 0.580, Loss1 0.580,Train_accy 77.16
2024-08-31 12:29:49,915 [foster.py] => Task 0, Epoch 31/200 => Loss 0.555, Train_accy 79.40, Test_accy 86.60
2024-08-31 12:29:52,439 [foster.py] => Task 0, Epoch 32/200 => Loss 0.571, Loss1 0.571,Train_accy 79.44
2024-08-31 12:29:55,026 [foster.py] => Task 0, Epoch 33/200 => Loss 0.571, Loss1 0.571,Train_accy 78.72
2024-08-31 12:29:57,540 [foster.py] => Task 0, Epoch 34/200 => Loss 0.526, Loss1 0.526,Train_accy 80.60
2024-08-31 12:30:00,060 [foster.py] => Task 0, Epoch 35/200 => Loss 0.534, Loss1 0.534,Train_accy 80.04
2024-08-31 12:30:03,306 [foster.py] => Task 0, Epoch 36/200 => Loss 0.514, Train_accy 81.40, Test_accy 89.60
2024-08-31 12:30:05,819 [foster.py] => Task 0, Epoch 37/200 => Loss 0.526, Loss1 0.526,Train_accy 80.68
2024-08-31 12:30:08,383 [foster.py] => Task 0, Epoch 38/200 => Loss 0.511, Loss1 0.511,Train_accy 80.76
2024-08-31 12:30:10,887 [foster.py] => Task 0, Epoch 39/200 => Loss 0.518, Loss1 0.518,Train_accy 80.40
2024-08-31 12:30:13,398 [foster.py] => Task 0, Epoch 40/200 => Loss 0.519, Loss1 0.519,Train_accy 81.16
2024-08-31 12:30:16,611 [foster.py] => Task 0, Epoch 41/200 => Loss 0.478, Train_accy 82.92, Test_accy 92.20
2024-08-31 12:30:19,212 [foster.py] => Task 0, Epoch 42/200 => Loss 0.486, Loss1 0.486,Train_accy 82.24
2024-08-31 12:30:21,778 [foster.py] => Task 0, Epoch 43/200 => Loss 0.434, Loss1 0.434,Train_accy 83.84
2024-08-31 12:30:24,306 [foster.py] => Task 0, Epoch 44/200 => Loss 0.465, Loss1 0.465,Train_accy 82.92
2024-08-31 12:30:26,823 [foster.py] => Task 0, Epoch 45/200 => Loss 0.458, Loss1 0.458,Train_accy 83.96
2024-08-31 12:30:30,069 [foster.py] => Task 0, Epoch 46/200 => Loss 0.422, Train_accy 84.72, Test_accy 90.40
2024-08-31 12:30:32,589 [foster.py] => Task 0, Epoch 47/200 => Loss 0.439, Loss1 0.439,Train_accy 84.36
2024-08-31 12:30:35,108 [foster.py] => Task 0, Epoch 48/200 => Loss 0.457, Loss1 0.457,Train_accy 84.16
2024-08-31 12:30:37,622 [foster.py] => Task 0, Epoch 49/200 => Loss 0.411, Loss1 0.411,Train_accy 85.00
2024-08-31 12:30:40,171 [foster.py] => Task 0, Epoch 50/200 => Loss 0.437, Loss1 0.437,Train_accy 84.52
2024-08-31 12:30:43,411 [foster.py] => Task 0, Epoch 51/200 => Loss 0.430, Train_accy 84.60, Test_accy 91.00
2024-08-31 12:30:45,938 [foster.py] => Task 0, Epoch 52/200 => Loss 0.396, Loss1 0.396,Train_accy 85.36
2024-08-31 12:30:48,452 [foster.py] => Task 0, Epoch 53/200 => Loss 0.379, Loss1 0.379,Train_accy 87.00
2024-08-31 12:30:50,973 [foster.py] => Task 0, Epoch 54/200 => Loss 0.407, Loss1 0.407,Train_accy 85.12
2024-08-31 12:30:53,557 [foster.py] => Task 0, Epoch 55/200 => Loss 0.421, Loss1 0.421,Train_accy 84.20
2024-08-31 12:30:56,801 [foster.py] => Task 0, Epoch 56/200 => Loss 0.433, Train_accy 84.32, Test_accy 93.20
2024-08-31 12:30:59,363 [foster.py] => Task 0, Epoch 57/200 => Loss 0.413, Loss1 0.413,Train_accy 85.16
2024-08-31 12:31:01,899 [foster.py] => Task 0, Epoch 58/200 => Loss 0.398, Loss1 0.398,Train_accy 86.04
2024-08-31 12:31:04,442 [foster.py] => Task 0, Epoch 59/200 => Loss 0.346, Loss1 0.346,Train_accy 87.36
2024-08-31 12:31:06,991 [foster.py] => Task 0, Epoch 60/200 => Loss 0.360, Loss1 0.360,Train_accy 87.76
2024-08-31 12:31:10,237 [foster.py] => Task 0, Epoch 61/200 => Loss 0.346, Train_accy 87.88, Test_accy 87.80
2024-08-31 12:31:12,754 [foster.py] => Task 0, Epoch 62/200 => Loss 0.340, Loss1 0.340,Train_accy 87.88
2024-08-31 12:31:15,293 [foster.py] => Task 0, Epoch 63/200 => Loss 0.340, Loss1 0.340,Train_accy 87.68
2024-08-31 12:31:17,797 [foster.py] => Task 0, Epoch 64/200 => Loss 0.369, Loss1 0.369,Train_accy 86.96
2024-08-31 12:31:20,318 [foster.py] => Task 0, Epoch 65/200 => Loss 0.371, Loss1 0.371,Train_accy 85.92
2024-08-31 12:31:23,558 [foster.py] => Task 0, Epoch 66/200 => Loss 0.372, Train_accy 86.96, Test_accy 94.60
2024-08-31 12:31:26,093 [foster.py] => Task 0, Epoch 67/200 => Loss 0.316, Loss1 0.316,Train_accy 88.20
2024-08-31 12:31:28,653 [foster.py] => Task 0, Epoch 68/200 => Loss 0.305, Loss1 0.305,Train_accy 88.28
2024-08-31 12:31:31,220 [foster.py] => Task 0, Epoch 69/200 => Loss 0.369, Loss1 0.369,Train_accy 86.32
2024-08-31 12:31:33,726 [foster.py] => Task 0, Epoch 70/200 => Loss 0.327, Loss1 0.327,Train_accy 88.28
2024-08-31 12:31:36,963 [foster.py] => Task 0, Epoch 71/200 => Loss 0.309, Train_accy 88.36, Test_accy 95.80
2024-08-31 12:31:39,497 [foster.py] => Task 0, Epoch 72/200 => Loss 0.317, Loss1 0.317,Train_accy 88.36
2024-08-31 12:31:42,088 [foster.py] => Task 0, Epoch 73/200 => Loss 0.316, Loss1 0.316,Train_accy 88.36
2024-08-31 12:31:44,616 [foster.py] => Task 0, Epoch 74/200 => Loss 0.322, Loss1 0.322,Train_accy 88.32
2024-08-31 12:31:47,134 [foster.py] => Task 0, Epoch 75/200 => Loss 0.348, Loss1 0.348,Train_accy 87.76
2024-08-31 12:31:50,427 [foster.py] => Task 0, Epoch 76/200 => Loss 0.321, Train_accy 88.20, Test_accy 90.40
2024-08-31 12:31:53,000 [foster.py] => Task 0, Epoch 77/200 => Loss 0.320, Loss1 0.320,Train_accy 88.64
2024-08-31 12:31:55,506 [foster.py] => Task 0, Epoch 78/200 => Loss 0.307, Loss1 0.307,Train_accy 88.84
2024-08-31 12:31:58,067 [foster.py] => Task 0, Epoch 79/200 => Loss 0.291, Loss1 0.291,Train_accy 89.84
2024-08-31 12:32:00,663 [foster.py] => Task 0, Epoch 80/200 => Loss 0.301, Loss1 0.301,Train_accy 89.40
2024-08-31 12:32:03,931 [foster.py] => Task 0, Epoch 81/200 => Loss 0.290, Train_accy 89.84, Test_accy 95.00
2024-08-31 12:32:06,433 [foster.py] => Task 0, Epoch 82/200 => Loss 0.283, Loss1 0.283,Train_accy 90.08
2024-08-31 12:32:08,960 [foster.py] => Task 0, Epoch 83/200 => Loss 0.296, Loss1 0.296,Train_accy 89.08
2024-08-31 12:32:11,482 [foster.py] => Task 0, Epoch 84/200 => Loss 0.294, Loss1 0.294,Train_accy 89.80
2024-08-31 12:32:13,991 [foster.py] => Task 0, Epoch 85/200 => Loss 0.299, Loss1 0.299,Train_accy 89.32
2024-08-31 12:32:17,200 [foster.py] => Task 0, Epoch 86/200 => Loss 0.285, Train_accy 89.32, Test_accy 88.20
2024-08-31 12:32:19,721 [foster.py] => Task 0, Epoch 87/200 => Loss 0.297, Loss1 0.297,Train_accy 89.84
2024-08-31 12:32:22,257 [foster.py] => Task 0, Epoch 88/200 => Loss 0.291, Loss1 0.291,Train_accy 88.92
2024-08-31 12:32:24,764 [foster.py] => Task 0, Epoch 89/200 => Loss 0.287, Loss1 0.287,Train_accy 89.52
2024-08-31 12:32:27,319 [foster.py] => Task 0, Epoch 90/200 => Loss 0.293, Loss1 0.293,Train_accy 89.52
2024-08-31 12:32:30,572 [foster.py] => Task 0, Epoch 91/200 => Loss 0.290, Train_accy 90.04, Test_accy 94.00
2024-08-31 12:32:33,164 [foster.py] => Task 0, Epoch 92/200 => Loss 0.272, Loss1 0.272,Train_accy 90.32
2024-08-31 12:32:35,728 [foster.py] => Task 0, Epoch 93/200 => Loss 0.263, Loss1 0.263,Train_accy 90.76
2024-08-31 12:32:38,266 [foster.py] => Task 0, Epoch 94/200 => Loss 0.263, Loss1 0.263,Train_accy 90.52
2024-08-31 12:32:40,783 [foster.py] => Task 0, Epoch 95/200 => Loss 0.253, Loss1 0.253,Train_accy 91.32
2024-08-31 12:32:44,005 [foster.py] => Task 0, Epoch 96/200 => Loss 0.247, Train_accy 91.24, Test_accy 96.20
2024-08-31 12:32:46,563 [foster.py] => Task 0, Epoch 97/200 => Loss 0.245, Loss1 0.245,Train_accy 91.20
2024-08-31 12:32:49,149 [foster.py] => Task 0, Epoch 98/200 => Loss 0.261, Loss1 0.261,Train_accy 90.32
2024-08-31 12:32:51,662 [foster.py] => Task 0, Epoch 99/200 => Loss 0.249, Loss1 0.249,Train_accy 91.40
2024-08-31 12:32:54,191 [foster.py] => Task 0, Epoch 100/200 => Loss 0.241, Loss1 0.241,Train_accy 91.60
2024-08-31 12:32:57,438 [foster.py] => Task 0, Epoch 101/200 => Loss 0.251, Train_accy 90.64, Test_accy 96.40
2024-08-31 12:33:00,025 [foster.py] => Task 0, Epoch 102/200 => Loss 0.255, Loss1 0.255,Train_accy 90.72
2024-08-31 12:33:02,532 [foster.py] => Task 0, Epoch 103/200 => Loss 0.247, Loss1 0.247,Train_accy 91.04
2024-08-31 12:33:05,073 [foster.py] => Task 0, Epoch 104/200 => Loss 0.223, Loss1 0.223,Train_accy 91.72
2024-08-31 12:33:07,601 [foster.py] => Task 0, Epoch 105/200 => Loss 0.245, Loss1 0.245,Train_accy 91.76
2024-08-31 12:33:10,854 [foster.py] => Task 0, Epoch 106/200 => Loss 0.233, Train_accy 91.56, Test_accy 97.40
2024-08-31 12:33:13,426 [foster.py] => Task 0, Epoch 107/200 => Loss 0.226, Loss1 0.226,Train_accy 91.80
2024-08-31 12:33:15,980 [foster.py] => Task 0, Epoch 108/200 => Loss 0.207, Loss1 0.207,Train_accy 92.72
2024-08-31 12:33:18,524 [foster.py] => Task 0, Epoch 109/200 => Loss 0.220, Loss1 0.220,Train_accy 92.24
2024-08-31 12:33:21,047 [foster.py] => Task 0, Epoch 110/200 => Loss 0.246, Loss1 0.246,Train_accy 90.88
2024-08-31 12:33:24,340 [foster.py] => Task 0, Epoch 111/200 => Loss 0.215, Train_accy 92.68, Test_accy 96.60
2024-08-31 12:33:26,858 [foster.py] => Task 0, Epoch 112/200 => Loss 0.219, Loss1 0.219,Train_accy 91.92
2024-08-31 12:33:29,396 [foster.py] => Task 0, Epoch 113/200 => Loss 0.194, Loss1 0.194,Train_accy 93.56
2024-08-31 12:33:31,929 [foster.py] => Task 0, Epoch 114/200 => Loss 0.222, Loss1 0.222,Train_accy 91.96
2024-08-31 12:33:34,466 [foster.py] => Task 0, Epoch 115/200 => Loss 0.199, Loss1 0.199,Train_accy 93.00
2024-08-31 12:33:37,750 [foster.py] => Task 0, Epoch 116/200 => Loss 0.215, Train_accy 92.64, Test_accy 96.60
2024-08-31 12:33:40,326 [foster.py] => Task 0, Epoch 117/200 => Loss 0.207, Loss1 0.207,Train_accy 92.20
2024-08-31 12:33:42,916 [foster.py] => Task 0, Epoch 118/200 => Loss 0.217, Loss1 0.217,Train_accy 92.68
2024-08-31 12:33:45,462 [foster.py] => Task 0, Epoch 119/200 => Loss 0.197, Loss1 0.197,Train_accy 92.68
2024-08-31 12:33:47,971 [foster.py] => Task 0, Epoch 120/200 => Loss 0.181, Loss1 0.181,Train_accy 93.24
2024-08-31 12:33:51,189 [foster.py] => Task 0, Epoch 121/200 => Loss 0.202, Train_accy 92.68, Test_accy 97.20
2024-08-31 12:33:53,761 [foster.py] => Task 0, Epoch 122/200 => Loss 0.204, Loss1 0.204,Train_accy 92.84
2024-08-31 12:33:56,275 [foster.py] => Task 0, Epoch 123/200 => Loss 0.183, Loss1 0.183,Train_accy 93.40
2024-08-31 12:33:58,833 [foster.py] => Task 0, Epoch 124/200 => Loss 0.204, Loss1 0.204,Train_accy 92.88
2024-08-31 12:34:01,354 [foster.py] => Task 0, Epoch 125/200 => Loss 0.172, Loss1 0.172,Train_accy 93.92
2024-08-31 12:34:04,572 [foster.py] => Task 0, Epoch 126/200 => Loss 0.198, Train_accy 92.96, Test_accy 95.40
2024-08-31 12:34:07,091 [foster.py] => Task 0, Epoch 127/200 => Loss 0.189, Loss1 0.189,Train_accy 93.40
2024-08-31 12:34:09,633 [foster.py] => Task 0, Epoch 128/200 => Loss 0.186, Loss1 0.186,Train_accy 93.36
2024-08-31 12:34:12,148 [foster.py] => Task 0, Epoch 129/200 => Loss 0.196, Loss1 0.196,Train_accy 93.04
2024-08-31 12:34:14,705 [foster.py] => Task 0, Epoch 130/200 => Loss 0.179, Loss1 0.179,Train_accy 93.88
2024-08-31 12:34:18,027 [foster.py] => Task 0, Epoch 131/200 => Loss 0.218, Train_accy 92.12, Test_accy 97.40
2024-08-31 12:34:20,552 [foster.py] => Task 0, Epoch 132/200 => Loss 0.158, Loss1 0.158,Train_accy 94.12
2024-08-31 12:34:23,066 [foster.py] => Task 0, Epoch 133/200 => Loss 0.174, Loss1 0.174,Train_accy 93.44
2024-08-31 12:34:25,594 [foster.py] => Task 0, Epoch 134/200 => Loss 0.172, Loss1 0.172,Train_accy 93.32
2024-08-31 12:34:28,190 [foster.py] => Task 0, Epoch 135/200 => Loss 0.184, Loss1 0.184,Train_accy 93.68
2024-08-31 12:34:31,414 [foster.py] => Task 0, Epoch 136/200 => Loss 0.165, Train_accy 94.12, Test_accy 97.40
2024-08-31 12:34:33,960 [foster.py] => Task 0, Epoch 137/200 => Loss 0.174, Loss1 0.174,Train_accy 93.88
2024-08-31 12:34:36,476 [foster.py] => Task 0, Epoch 138/200 => Loss 0.166, Loss1 0.166,Train_accy 93.96
2024-08-31 12:34:38,974 [foster.py] => Task 0, Epoch 139/200 => Loss 0.161, Loss1 0.161,Train_accy 94.20
2024-08-31 12:34:41,497 [foster.py] => Task 0, Epoch 140/200 => Loss 0.173, Loss1 0.173,Train_accy 93.60
2024-08-31 12:34:44,774 [foster.py] => Task 0, Epoch 141/200 => Loss 0.155, Train_accy 94.60, Test_accy 98.80
2024-08-31 12:34:47,385 [foster.py] => Task 0, Epoch 142/200 => Loss 0.146, Loss1 0.146,Train_accy 95.00
2024-08-31 12:34:49,890 [foster.py] => Task 0, Epoch 143/200 => Loss 0.150, Loss1 0.150,Train_accy 94.64
2024-08-31 12:34:52,393 [foster.py] => Task 0, Epoch 144/200 => Loss 0.167, Loss1 0.167,Train_accy 94.32
2024-08-31 12:34:54,968 [foster.py] => Task 0, Epoch 145/200 => Loss 0.159, Loss1 0.159,Train_accy 94.72
2024-08-31 12:34:58,197 [foster.py] => Task 0, Epoch 146/200 => Loss 0.141, Train_accy 95.08, Test_accy 98.00
2024-08-31 12:35:00,730 [foster.py] => Task 0, Epoch 147/200 => Loss 0.145, Loss1 0.145,Train_accy 94.52
2024-08-31 12:35:03,307 [foster.py] => Task 0, Epoch 148/200 => Loss 0.160, Loss1 0.160,Train_accy 94.20
2024-08-31 12:35:05,817 [foster.py] => Task 0, Epoch 149/200 => Loss 0.147, Loss1 0.147,Train_accy 94.96
2024-08-31 12:35:08,346 [foster.py] => Task 0, Epoch 150/200 => Loss 0.148, Loss1 0.148,Train_accy 94.56
2024-08-31 12:35:11,598 [foster.py] => Task 0, Epoch 151/200 => Loss 0.161, Train_accy 94.04, Test_accy 97.20
2024-08-31 12:35:14,123 [foster.py] => Task 0, Epoch 152/200 => Loss 0.148, Loss1 0.148,Train_accy 94.96
2024-08-31 12:35:16,652 [foster.py] => Task 0, Epoch 153/200 => Loss 0.146, Loss1 0.146,Train_accy 94.96
2024-08-31 12:35:19,157 [foster.py] => Task 0, Epoch 154/200 => Loss 0.143, Loss1 0.143,Train_accy 95.12
2024-08-31 12:35:21,683 [foster.py] => Task 0, Epoch 155/200 => Loss 0.143, Loss1 0.143,Train_accy 95.08
2024-08-31 12:35:24,917 [foster.py] => Task 0, Epoch 156/200 => Loss 0.152, Train_accy 95.00, Test_accy 98.60
2024-08-31 12:35:27,436 [foster.py] => Task 0, Epoch 157/200 => Loss 0.144, Loss1 0.144,Train_accy 95.08
2024-08-31 12:35:29,946 [foster.py] => Task 0, Epoch 158/200 => Loss 0.154, Loss1 0.154,Train_accy 94.80
2024-08-31 12:35:32,543 [foster.py] => Task 0, Epoch 159/200 => Loss 0.128, Loss1 0.128,Train_accy 95.44
2024-08-31 12:35:35,036 [foster.py] => Task 0, Epoch 160/200 => Loss 0.123, Loss1 0.123,Train_accy 96.52
2024-08-31 12:35:38,255 [foster.py] => Task 0, Epoch 161/200 => Loss 0.113, Train_accy 95.80, Test_accy 98.60
2024-08-31 12:35:40,819 [foster.py] => Task 0, Epoch 162/200 => Loss 0.126, Loss1 0.126,Train_accy 95.72
2024-08-31 12:35:43,350 [foster.py] => Task 0, Epoch 163/200 => Loss 0.120, Loss1 0.120,Train_accy 95.92
2024-08-31 12:35:45,862 [foster.py] => Task 0, Epoch 164/200 => Loss 0.134, Loss1 0.134,Train_accy 95.00
2024-08-31 12:35:48,394 [foster.py] => Task 0, Epoch 165/200 => Loss 0.137, Loss1 0.137,Train_accy 95.04
2024-08-31 12:35:51,664 [foster.py] => Task 0, Epoch 166/200 => Loss 0.112, Train_accy 96.16, Test_accy 98.80
2024-08-31 12:35:54,180 [foster.py] => Task 0, Epoch 167/200 => Loss 0.123, Loss1 0.123,Train_accy 95.40
2024-08-31 12:35:56,701 [foster.py] => Task 0, Epoch 168/200 => Loss 0.130, Loss1 0.130,Train_accy 95.48
2024-08-31 12:35:59,270 [foster.py] => Task 0, Epoch 169/200 => Loss 0.127, Loss1 0.127,Train_accy 95.32
2024-08-31 12:36:01,787 [foster.py] => Task 0, Epoch 170/200 => Loss 0.112, Loss1 0.112,Train_accy 96.16
2024-08-31 12:36:05,020 [foster.py] => Task 0, Epoch 171/200 => Loss 0.131, Train_accy 95.24, Test_accy 99.00
2024-08-31 12:36:07,618 [foster.py] => Task 0, Epoch 172/200 => Loss 0.118, Loss1 0.118,Train_accy 96.32
2024-08-31 12:36:10,150 [foster.py] => Task 0, Epoch 173/200 => Loss 0.115, Loss1 0.115,Train_accy 95.92
2024-08-31 12:36:12,683 [foster.py] => Task 0, Epoch 174/200 => Loss 0.123, Loss1 0.123,Train_accy 95.40
2024-08-31 12:36:15,201 [foster.py] => Task 0, Epoch 175/200 => Loss 0.103, Loss1 0.103,Train_accy 96.52
2024-08-31 12:36:18,442 [foster.py] => Task 0, Epoch 176/200 => Loss 0.116, Train_accy 95.96, Test_accy 99.00
2024-08-31 12:36:21,006 [foster.py] => Task 0, Epoch 177/200 => Loss 0.124, Loss1 0.124,Train_accy 95.44
2024-08-31 12:36:23,520 [foster.py] => Task 0, Epoch 178/200 => Loss 0.111, Loss1 0.111,Train_accy 96.36
2024-08-31 12:36:26,061 [foster.py] => Task 0, Epoch 179/200 => Loss 0.102, Loss1 0.102,Train_accy 96.12
2024-08-31 12:36:28,600 [foster.py] => Task 0, Epoch 180/200 => Loss 0.125, Loss1 0.125,Train_accy 95.12
2024-08-31 12:36:31,868 [foster.py] => Task 0, Epoch 181/200 => Loss 0.114, Train_accy 95.68, Test_accy 98.60
2024-08-31 12:36:34,383 [foster.py] => Task 0, Epoch 182/200 => Loss 0.111, Loss1 0.111,Train_accy 96.04
2024-08-31 12:36:36,987 [foster.py] => Task 0, Epoch 183/200 => Loss 0.122, Loss1 0.122,Train_accy 95.60
2024-08-31 12:36:39,521 [foster.py] => Task 0, Epoch 184/200 => Loss 0.113, Loss1 0.113,Train_accy 95.72
2024-08-31 12:36:42,035 [foster.py] => Task 0, Epoch 185/200 => Loss 0.115, Loss1 0.115,Train_accy 96.12
2024-08-31 12:36:45,312 [foster.py] => Task 0, Epoch 186/200 => Loss 0.110, Train_accy 96.12, Test_accy 98.80
2024-08-31 12:36:47,815 [foster.py] => Task 0, Epoch 187/200 => Loss 0.092, Loss1 0.092,Train_accy 96.64
2024-08-31 12:36:50,378 [foster.py] => Task 0, Epoch 188/200 => Loss 0.122, Loss1 0.122,Train_accy 95.64
2024-08-31 12:36:52,898 [foster.py] => Task 0, Epoch 189/200 => Loss 0.103, Loss1 0.103,Train_accy 96.48
2024-08-31 12:36:55,453 [foster.py] => Task 0, Epoch 190/200 => Loss 0.110, Loss1 0.110,Train_accy 96.04
2024-08-31 12:36:58,730 [foster.py] => Task 0, Epoch 191/200 => Loss 0.110, Train_accy 96.32, Test_accy 98.80
2024-08-31 12:37:01,251 [foster.py] => Task 0, Epoch 192/200 => Loss 0.106, Loss1 0.106,Train_accy 96.44
2024-08-31 12:37:03,777 [foster.py] => Task 0, Epoch 193/200 => Loss 0.121, Loss1 0.121,Train_accy 95.40
2024-08-31 12:37:06,356 [foster.py] => Task 0, Epoch 194/200 => Loss 0.102, Loss1 0.102,Train_accy 96.24
2024-08-31 12:37:08,909 [foster.py] => Task 0, Epoch 195/200 => Loss 0.096, Loss1 0.096,Train_accy 96.72
2024-08-31 12:37:12,158 [foster.py] => Task 0, Epoch 196/200 => Loss 0.093, Train_accy 96.76, Test_accy 98.60
2024-08-31 12:37:14,693 [foster.py] => Task 0, Epoch 197/200 => Loss 0.111, Loss1 0.111,Train_accy 95.80
2024-08-31 12:37:17,226 [foster.py] => Task 0, Epoch 198/200 => Loss 0.107, Loss1 0.107,Train_accy 96.24
2024-08-31 12:37:19,751 [foster.py] => Task 0, Epoch 199/200 => Loss 0.126, Loss1 0.126,Train_accy 95.44
2024-08-31 12:37:22,349 [foster.py] => Task 0, Epoch 200/200 => Loss 0.105, Loss1 0.105,Train_accy 95.96
2024-08-31 12:37:22,352 [foster.py] => training time: 540.314747095108
2024-08-31 12:37:22,354 [base.py] => Reducing exemplars...(400 per classes)
2024-08-31 12:37:22,354 [base.py] => Constructing exemplars...(400 per classes)
2024-08-31 12:37:29,715 [foster.py] => Exemplar size: 2000
2024-08-31 12:37:29,715 [trainer.py] => CNN: {'total': 98.8, '00-09': 98.8, 'old': 0, 'new': 98.8}
2024-08-31 12:37:29,715 [trainer.py] => NME: {'total': 99.0, '00-09': 99.0, 'old': 0, 'new': 99.0}
2024-08-31 12:37:29,715 [trainer.py] => CNN top1 curve: [98.8]
2024-08-31 12:37:29,715 [trainer.py] => CNN top5 curve: [100.0]
2024-08-31 12:37:29,716 [trainer.py] => NME top1 curve: [99.0]
2024-08-31 12:37:29,716 [trainer.py] => NME top5 curve: [100.0]

2024-08-31 12:37:29,716 [trainer.py] => CNN top1 平均值: 98.80
2024-08-31 12:37:29,718 [trainer.py] => All params: 641924
2024-08-31 12:37:29,719 [trainer.py] => Trainable params: 641924
2024-08-31 12:37:29,894 [foster.py] => Learning on 5-10
2024-08-31 12:37:29,897 [foster.py] => All params: 1284813
2024-08-31 12:37:29,899 [foster.py] => Trainable params: 643214
2024-08-31 12:37:29,942 [foster.py] => per cls weights : [1.04761905 1.04761905 1.04761905 1.04761905 1.04761905 0.95238095
 0.95238095 0.95238095 0.95238095 0.95238095]
2024-08-31 12:37:35,698 [foster.py] => Task 1, Epoch 1/170 => Loss 3.832, Loss_clf 1.251, Loss_fe 1.753, Loss_kd 0.413, Train_accy 56.22
2024-08-31 12:37:42,116 [foster.py] => Task 1, Epoch 2/170 => Loss 3.474, Loss_clf 1.001, Loss_fe 1.647, Loss_kd 0.412, Train_accy 63.20, Test_accy 70.80
2024-08-31 12:37:48,421 [foster.py] => Task 1, Epoch 3/170 => Loss 3.396, Loss_clf 0.983, Loss_fe 1.585, Loss_kd 0.413, Train_accy 64.13, Test_accy 76.90
2024-08-31 12:37:54,814 [foster.py] => Task 1, Epoch 4/170 => Loss 3.154, Loss_clf 0.927, Loss_fe 1.407, Loss_kd 0.410, Train_accy 66.13, Test_accy 70.60
2024-08-31 12:38:01,196 [foster.py] => Task 1, Epoch 5/170 => Loss 3.112, Loss_clf 0.899, Loss_fe 1.389, Loss_kd 0.411, Train_accy 68.02, Test_accy 71.50
2024-08-31 12:38:06,627 [foster.py] => Task 1, Epoch 6/170 => Loss 3.004, Loss_clf 0.870, Loss_fe 1.316, Loss_kd 0.408, Train_accy 68.69
2024-08-31 12:38:12,992 [foster.py] => Task 1, Epoch 7/170 => Loss 2.998, Loss_clf 0.880, Loss_fe 1.298, Loss_kd 0.410, Train_accy 68.33, Test_accy 77.20
2024-08-31 12:38:19,359 [foster.py] => Task 1, Epoch 8/170 => Loss 2.901, Loss_clf 0.841, Loss_fe 1.244, Loss_kd 0.408, Train_accy 70.02, Test_accy 78.90
2024-08-31 12:38:25,855 [foster.py] => Task 1, Epoch 9/170 => Loss 2.824, Loss_clf 0.804, Loss_fe 1.199, Loss_kd 0.410, Train_accy 71.89, Test_accy 78.40
2024-08-31 12:38:32,220 [foster.py] => Task 1, Epoch 10/170 => Loss 2.810, Loss_clf 0.802, Loss_fe 1.189, Loss_kd 0.409, Train_accy 71.20, Test_accy 74.10
2024-08-31 12:38:37,631 [foster.py] => Task 1, Epoch 11/170 => Loss 2.790, Loss_clf 0.812, Loss_fe 1.160, Loss_kd 0.409, Train_accy 70.89
2024-08-31 12:38:43,972 [foster.py] => Task 1, Epoch 12/170 => Loss 2.748, Loss_clf 0.798, Loss_fe 1.130, Loss_kd 0.410, Train_accy 71.40, Test_accy 80.70
2024-08-31 12:38:50,309 [foster.py] => Task 1, Epoch 13/170 => Loss 2.683, Loss_clf 0.770, Loss_fe 1.092, Loss_kd 0.410, Train_accy 72.51, Test_accy 74.70
2024-08-31 12:38:56,870 [foster.py] => Task 1, Epoch 14/170 => Loss 2.708, Loss_clf 0.786, Loss_fe 1.100, Loss_kd 0.410, Train_accy 72.44, Test_accy 65.30
2024-08-31 12:39:03,191 [foster.py] => Task 1, Epoch 15/170 => Loss 2.670, Loss_clf 0.775, Loss_fe 1.076, Loss_kd 0.409, Train_accy 73.58, Test_accy 75.10
2024-08-31 12:39:08,654 [foster.py] => Task 1, Epoch 16/170 => Loss 2.658, Loss_clf 0.775, Loss_fe 1.060, Loss_kd 0.411, Train_accy 72.36
2024-08-31 12:39:15,133 [foster.py] => Task 1, Epoch 17/170 => Loss 2.675, Loss_clf 0.767, Loss_fe 1.084, Loss_kd 0.411, Train_accy 73.27, Test_accy 73.30
2024-08-31 12:39:21,595 [foster.py] => Task 1, Epoch 18/170 => Loss 2.559, Loss_clf 0.721, Loss_fe 1.021, Loss_kd 0.408, Train_accy 74.36, Test_accy 73.60
2024-08-31 12:39:28,203 [foster.py] => Task 1, Epoch 19/170 => Loss 2.559, Loss_clf 0.733, Loss_fe 1.011, Loss_kd 0.407, Train_accy 74.51, Test_accy 64.50
2024-08-31 12:39:34,905 [foster.py] => Task 1, Epoch 20/170 => Loss 2.578, Loss_clf 0.740, Loss_fe 1.017, Loss_kd 0.410, Train_accy 74.87, Test_accy 81.30
2024-08-31 12:39:40,287 [foster.py] => Task 1, Epoch 21/170 => Loss 2.559, Loss_clf 0.737, Loss_fe 1.014, Loss_kd 0.403, Train_accy 74.02
2024-08-31 12:39:46,767 [foster.py] => Task 1, Epoch 22/170 => Loss 2.563, Loss_clf 0.725, Loss_fe 1.016, Loss_kd 0.410, Train_accy 75.20, Test_accy 73.00
2024-08-31 12:39:53,111 [foster.py] => Task 1, Epoch 23/170 => Loss 2.537, Loss_clf 0.716, Loss_fe 1.004, Loss_kd 0.408, Train_accy 74.53, Test_accy 68.60
2024-08-31 12:39:59,473 [foster.py] => Task 1, Epoch 24/170 => Loss 2.548, Loss_clf 0.727, Loss_fe 0.996, Loss_kd 0.411, Train_accy 75.24, Test_accy 74.80
2024-08-31 12:40:05,844 [foster.py] => Task 1, Epoch 25/170 => Loss 2.439, Loss_clf 0.691, Loss_fe 0.934, Loss_kd 0.406, Train_accy 76.22, Test_accy 83.40
2024-08-31 12:40:11,334 [foster.py] => Task 1, Epoch 26/170 => Loss 2.396, Loss_clf 0.665, Loss_fe 0.917, Loss_kd 0.407, Train_accy 76.93
2024-08-31 12:40:17,750 [foster.py] => Task 1, Epoch 27/170 => Loss 2.431, Loss_clf 0.701, Loss_fe 0.920, Loss_kd 0.404, Train_accy 75.80, Test_accy 83.90
2024-08-31 12:40:24,148 [foster.py] => Task 1, Epoch 28/170 => Loss 2.436, Loss_clf 0.685, Loss_fe 0.929, Loss_kd 0.410, Train_accy 77.07, Test_accy 81.50
2024-08-31 12:40:30,621 [foster.py] => Task 1, Epoch 29/170 => Loss 2.451, Loss_clf 0.701, Loss_fe 0.932, Loss_kd 0.408, Train_accy 75.78, Test_accy 85.10
2024-08-31 12:40:37,134 [foster.py] => Task 1, Epoch 30/170 => Loss 2.385, Loss_clf 0.672, Loss_fe 0.892, Loss_kd 0.410, Train_accy 77.00, Test_accy 81.20
2024-08-31 12:40:42,572 [foster.py] => Task 1, Epoch 31/170 => Loss 2.440, Loss_clf 0.684, Loss_fe 0.940, Loss_kd 0.408, Train_accy 76.82
2024-08-31 12:40:49,020 [foster.py] => Task 1, Epoch 32/170 => Loss 2.471, Loss_clf 0.686, Loss_fe 0.964, Loss_kd 0.409, Train_accy 76.18, Test_accy 82.30
2024-08-31 12:40:55,368 [foster.py] => Task 1, Epoch 33/170 => Loss 2.424, Loss_clf 0.683, Loss_fe 0.913, Loss_kd 0.413, Train_accy 76.84, Test_accy 81.90
2024-08-31 12:41:01,782 [foster.py] => Task 1, Epoch 34/170 => Loss 2.319, Loss_clf 0.643, Loss_fe 0.861, Loss_kd 0.407, Train_accy 77.98, Test_accy 83.70
2024-08-31 12:41:08,140 [foster.py] => Task 1, Epoch 35/170 => Loss 2.369, Loss_clf 0.669, Loss_fe 0.884, Loss_kd 0.407, Train_accy 76.78, Test_accy 79.90
2024-08-31 12:41:13,565 [foster.py] => Task 1, Epoch 36/170 => Loss 2.272, Loss_clf 0.624, Loss_fe 0.831, Loss_kd 0.408, Train_accy 78.33
2024-08-31 12:41:20,022 [foster.py] => Task 1, Epoch 37/170 => Loss 2.362, Loss_clf 0.653, Loss_fe 0.888, Loss_kd 0.410, Train_accy 77.84, Test_accy 79.60
2024-08-31 12:41:26,461 [foster.py] => Task 1, Epoch 38/170 => Loss 2.320, Loss_clf 0.652, Loss_fe 0.854, Loss_kd 0.406, Train_accy 77.98, Test_accy 82.90
2024-08-31 12:41:32,822 [foster.py] => Task 1, Epoch 39/170 => Loss 2.377, Loss_clf 0.665, Loss_fe 0.887, Loss_kd 0.412, Train_accy 77.04, Test_accy 55.70
2024-08-31 12:41:39,203 [foster.py] => Task 1, Epoch 40/170 => Loss 2.387, Loss_clf 0.671, Loss_fe 0.902, Loss_kd 0.406, Train_accy 77.60, Test_accy 81.40
2024-08-31 12:41:44,598 [foster.py] => Task 1, Epoch 41/170 => Loss 2.254, Loss_clf 0.628, Loss_fe 0.810, Loss_kd 0.408, Train_accy 78.76
2024-08-31 12:41:51,067 [foster.py] => Task 1, Epoch 42/170 => Loss 2.304, Loss_clf 0.648, Loss_fe 0.835, Loss_kd 0.410, Train_accy 78.13, Test_accy 77.50
2024-08-31 12:41:57,498 [foster.py] => Task 1, Epoch 43/170 => Loss 2.257, Loss_clf 0.620, Loss_fe 0.815, Loss_kd 0.410, Train_accy 80.27, Test_accy 85.80
2024-08-31 12:42:03,853 [foster.py] => Task 1, Epoch 44/170 => Loss 2.308, Loss_clf 0.650, Loss_fe 0.840, Loss_kd 0.408, Train_accy 77.96, Test_accy 76.00
2024-08-31 12:42:10,249 [foster.py] => Task 1, Epoch 45/170 => Loss 2.323, Loss_clf 0.651, Loss_fe 0.847, Loss_kd 0.412, Train_accy 77.69, Test_accy 77.30
2024-08-31 12:42:15,677 [foster.py] => Task 1, Epoch 46/170 => Loss 2.221, Loss_clf 0.607, Loss_fe 0.786, Loss_kd 0.414, Train_accy 78.78
2024-08-31 12:42:22,060 [foster.py] => Task 1, Epoch 47/170 => Loss 2.336, Loss_clf 0.658, Loss_fe 0.855, Loss_kd 0.411, Train_accy 77.69, Test_accy 79.40
2024-08-31 12:42:28,562 [foster.py] => Task 1, Epoch 48/170 => Loss 2.205, Loss_clf 0.603, Loss_fe 0.781, Loss_kd 0.410, Train_accy 78.82, Test_accy 76.10
2024-08-31 12:42:34,994 [foster.py] => Task 1, Epoch 49/170 => Loss 2.230, Loss_clf 0.613, Loss_fe 0.797, Loss_kd 0.409, Train_accy 79.27, Test_accy 83.20
2024-08-31 12:42:41,409 [foster.py] => Task 1, Epoch 50/170 => Loss 2.180, Loss_clf 0.596, Loss_fe 0.766, Loss_kd 0.409, Train_accy 79.69, Test_accy 80.50
2024-08-31 12:42:46,869 [foster.py] => Task 1, Epoch 51/170 => Loss 2.217, Loss_clf 0.609, Loss_fe 0.792, Loss_kd 0.407, Train_accy 79.16
2024-08-31 12:42:53,254 [foster.py] => Task 1, Epoch 52/170 => Loss 2.165, Loss_clf 0.588, Loss_fe 0.760, Loss_kd 0.408, Train_accy 79.91, Test_accy 77.30
2024-08-31 12:42:59,659 [foster.py] => Task 1, Epoch 53/170 => Loss 2.290, Loss_clf 0.647, Loss_fe 0.823, Loss_kd 0.409, Train_accy 78.09, Test_accy 80.50
2024-08-31 12:43:06,194 [foster.py] => Task 1, Epoch 54/170 => Loss 2.152, Loss_clf 0.585, Loss_fe 0.751, Loss_kd 0.407, Train_accy 79.58, Test_accy 80.30
2024-08-31 12:43:12,612 [foster.py] => Task 1, Epoch 55/170 => Loss 2.262, Loss_clf 0.627, Loss_fe 0.816, Loss_kd 0.409, Train_accy 78.71, Test_accy 82.20
2024-08-31 12:43:18,022 [foster.py] => Task 1, Epoch 56/170 => Loss 2.206, Loss_clf 0.605, Loss_fe 0.787, Loss_kd 0.406, Train_accy 79.64
2024-08-31 12:43:24,378 [foster.py] => Task 1, Epoch 57/170 => Loss 2.193, Loss_clf 0.598, Loss_fe 0.777, Loss_kd 0.408, Train_accy 79.44, Test_accy 82.10
2024-08-31 12:43:30,808 [foster.py] => Task 1, Epoch 58/170 => Loss 2.115, Loss_clf 0.568, Loss_fe 0.731, Loss_kd 0.407, Train_accy 81.53, Test_accy 89.00
2024-08-31 12:43:37,238 [foster.py] => Task 1, Epoch 59/170 => Loss 2.178, Loss_clf 0.593, Loss_fe 0.766, Loss_kd 0.408, Train_accy 79.71, Test_accy 82.10
2024-08-31 12:43:43,669 [foster.py] => Task 1, Epoch 60/170 => Loss 2.164, Loss_clf 0.595, Loss_fe 0.751, Loss_kd 0.408, Train_accy 80.51, Test_accy 85.00
2024-08-31 12:43:49,166 [foster.py] => Task 1, Epoch 61/170 => Loss 2.097, Loss_clf 0.558, Loss_fe 0.723, Loss_kd 0.407, Train_accy 80.78
2024-08-31 12:43:55,572 [foster.py] => Task 1, Epoch 62/170 => Loss 2.133, Loss_clf 0.579, Loss_fe 0.731, Loss_kd 0.410, Train_accy 80.09, Test_accy 86.60
2024-08-31 12:44:02,020 [foster.py] => Task 1, Epoch 63/170 => Loss 2.105, Loss_clf 0.568, Loss_fe 0.717, Loss_kd 0.409, Train_accy 81.00, Test_accy 85.50
2024-08-31 12:44:08,370 [foster.py] => Task 1, Epoch 64/170 => Loss 2.230, Loss_clf 0.611, Loss_fe 0.797, Loss_kd 0.410, Train_accy 79.24, Test_accy 59.10
2024-08-31 12:44:14,743 [foster.py] => Task 1, Epoch 65/170 => Loss 2.087, Loss_clf 0.559, Loss_fe 0.716, Loss_kd 0.405, Train_accy 80.69, Test_accy 86.30
2024-08-31 12:44:20,177 [foster.py] => Task 1, Epoch 66/170 => Loss 2.092, Loss_clf 0.557, Loss_fe 0.722, Loss_kd 0.406, Train_accy 80.96
2024-08-31 12:44:26,654 [foster.py] => Task 1, Epoch 67/170 => Loss 2.047, Loss_clf 0.551, Loss_fe 0.681, Loss_kd 0.406, Train_accy 81.40, Test_accy 86.30
2024-08-31 12:44:33,054 [foster.py] => Task 1, Epoch 68/170 => Loss 2.075, Loss_clf 0.561, Loss_fe 0.699, Loss_kd 0.407, Train_accy 81.00, Test_accy 82.30
2024-08-31 12:44:39,673 [foster.py] => Task 1, Epoch 69/170 => Loss 2.043, Loss_clf 0.535, Loss_fe 0.695, Loss_kd 0.406, Train_accy 82.04, Test_accy 84.20
2024-08-31 12:44:46,169 [foster.py] => Task 1, Epoch 70/170 => Loss 2.169, Loss_clf 0.585, Loss_fe 0.772, Loss_kd 0.406, Train_accy 80.11, Test_accy 86.10
2024-08-31 12:44:51,607 [foster.py] => Task 1, Epoch 71/170 => Loss 2.048, Loss_clf 0.535, Loss_fe 0.701, Loss_kd 0.405, Train_accy 81.98
2024-08-31 12:44:57,989 [foster.py] => Task 1, Epoch 72/170 => Loss 2.099, Loss_clf 0.565, Loss_fe 0.704, Loss_kd 0.414, Train_accy 80.51, Test_accy 88.20
2024-08-31 12:45:04,377 [foster.py] => Task 1, Epoch 73/170 => Loss 2.067, Loss_clf 0.564, Loss_fe 0.675, Loss_kd 0.413, Train_accy 81.00, Test_accy 85.90
2024-08-31 12:45:10,855 [foster.py] => Task 1, Epoch 74/170 => Loss 1.982, Loss_clf 0.521, Loss_fe 0.651, Loss_kd 0.404, Train_accy 82.58, Test_accy 86.00
2024-08-31 12:45:17,229 [foster.py] => Task 1, Epoch 75/170 => Loss 2.051, Loss_clf 0.540, Loss_fe 0.685, Loss_kd 0.412, Train_accy 81.24, Test_accy 64.30
2024-08-31 12:45:22,715 [foster.py] => Task 1, Epoch 76/170 => Loss 2.097, Loss_clf 0.569, Loss_fe 0.704, Loss_kd 0.411, Train_accy 81.04
2024-08-31 12:45:29,200 [foster.py] => Task 1, Epoch 77/170 => Loss 1.991, Loss_clf 0.508, Loss_fe 0.667, Loss_kd 0.408, Train_accy 82.38, Test_accy 83.90
2024-08-31 12:45:35,612 [foster.py] => Task 1, Epoch 78/170 => Loss 1.991, Loss_clf 0.518, Loss_fe 0.657, Loss_kd 0.407, Train_accy 82.96, Test_accy 84.60
2024-08-31 12:45:42,018 [foster.py] => Task 1, Epoch 79/170 => Loss 2.042, Loss_clf 0.552, Loss_fe 0.674, Loss_kd 0.407, Train_accy 81.49, Test_accy 87.10
2024-08-31 12:45:48,356 [foster.py] => Task 1, Epoch 80/170 => Loss 2.047, Loss_clf 0.532, Loss_fe 0.695, Loss_kd 0.409, Train_accy 82.07, Test_accy 84.10
2024-08-31 12:45:53,685 [foster.py] => Task 1, Epoch 81/170 => Loss 1.913, Loss_clf 0.483, Loss_fe 0.610, Loss_kd 0.410, Train_accy 83.53
2024-08-31 12:45:59,997 [foster.py] => Task 1, Epoch 82/170 => Loss 1.991, Loss_clf 0.525, Loss_fe 0.649, Loss_kd 0.408, Train_accy 82.42, Test_accy 85.70
2024-08-31 12:46:06,375 [foster.py] => Task 1, Epoch 83/170 => Loss 2.082, Loss_clf 0.562, Loss_fe 0.698, Loss_kd 0.411, Train_accy 81.27, Test_accy 87.00
2024-08-31 12:46:12,766 [foster.py] => Task 1, Epoch 84/170 => Loss 1.994, Loss_clf 0.539, Loss_fe 0.640, Loss_kd 0.407, Train_accy 81.67, Test_accy 88.10
2024-08-31 12:46:19,184 [foster.py] => Task 1, Epoch 85/170 => Loss 1.960, Loss_clf 0.508, Loss_fe 0.632, Loss_kd 0.409, Train_accy 82.91, Test_accy 84.90
2024-08-31 12:46:24,561 [foster.py] => Task 1, Epoch 86/170 => Loss 1.988, Loss_clf 0.513, Loss_fe 0.656, Loss_kd 0.409, Train_accy 82.64
2024-08-31 12:46:30,975 [foster.py] => Task 1, Epoch 87/170 => Loss 1.917, Loss_clf 0.490, Loss_fe 0.622, Loss_kd 0.402, Train_accy 83.60, Test_accy 85.40
2024-08-31 12:46:37,332 [foster.py] => Task 1, Epoch 88/170 => Loss 2.013, Loss_clf 0.543, Loss_fe 0.646, Loss_kd 0.411, Train_accy 82.04, Test_accy 89.70
2024-08-31 12:46:43,663 [foster.py] => Task 1, Epoch 89/170 => Loss 1.954, Loss_clf 0.509, Loss_fe 0.629, Loss_kd 0.408, Train_accy 82.47, Test_accy 89.40
2024-08-31 12:46:50,026 [foster.py] => Task 1, Epoch 90/170 => Loss 1.925, Loss_clf 0.497, Loss_fe 0.610, Loss_kd 0.408, Train_accy 83.18, Test_accy 84.70
2024-08-31 12:46:55,453 [foster.py] => Task 1, Epoch 91/170 => Loss 1.899, Loss_clf 0.483, Loss_fe 0.603, Loss_kd 0.406, Train_accy 83.22
2024-08-31 12:47:01,856 [foster.py] => Task 1, Epoch 92/170 => Loss 1.875, Loss_clf 0.469, Loss_fe 0.592, Loss_kd 0.406, Train_accy 84.36, Test_accy 85.10
2024-08-31 12:47:08,327 [foster.py] => Task 1, Epoch 93/170 => Loss 1.898, Loss_clf 0.488, Loss_fe 0.601, Loss_kd 0.404, Train_accy 83.69, Test_accy 87.40
2024-08-31 12:47:14,817 [foster.py] => Task 1, Epoch 94/170 => Loss 1.935, Loss_clf 0.493, Loss_fe 0.625, Loss_kd 0.408, Train_accy 83.49, Test_accy 83.70
2024-08-31 12:47:21,266 [foster.py] => Task 1, Epoch 95/170 => Loss 1.937, Loss_clf 0.510, Loss_fe 0.607, Loss_kd 0.409, Train_accy 82.93, Test_accy 86.90
2024-08-31 12:47:26,721 [foster.py] => Task 1, Epoch 96/170 => Loss 1.986, Loss_clf 0.524, Loss_fe 0.646, Loss_kd 0.407, Train_accy 82.27
2024-08-31 12:47:33,152 [foster.py] => Task 1, Epoch 97/170 => Loss 1.936, Loss_clf 0.504, Loss_fe 0.610, Loss_kd 0.410, Train_accy 83.16, Test_accy 85.80
2024-08-31 12:47:39,617 [foster.py] => Task 1, Epoch 98/170 => Loss 1.875, Loss_clf 0.479, Loss_fe 0.580, Loss_kd 0.407, Train_accy 84.11, Test_accy 90.50
2024-08-31 12:47:46,004 [foster.py] => Task 1, Epoch 99/170 => Loss 1.845, Loss_clf 0.474, Loss_fe 0.558, Loss_kd 0.406, Train_accy 84.20, Test_accy 88.00
2024-08-31 12:47:52,431 [foster.py] => Task 1, Epoch 100/170 => Loss 1.875, Loss_clf 0.482, Loss_fe 0.567, Loss_kd 0.412, Train_accy 84.13, Test_accy 90.00
2024-08-31 12:47:57,788 [foster.py] => Task 1, Epoch 101/170 => Loss 1.872, Loss_clf 0.477, Loss_fe 0.580, Loss_kd 0.407, Train_accy 83.96
2024-08-31 12:48:04,253 [foster.py] => Task 1, Epoch 102/170 => Loss 1.834, Loss_clf 0.463, Loss_fe 0.559, Loss_kd 0.405, Train_accy 83.96, Test_accy 87.50
2024-08-31 12:48:10,714 [foster.py] => Task 1, Epoch 103/170 => Loss 1.850, Loss_clf 0.463, Loss_fe 0.560, Loss_kd 0.412, Train_accy 84.56, Test_accy 90.10
2024-08-31 12:48:17,133 [foster.py] => Task 1, Epoch 104/170 => Loss 1.834, Loss_clf 0.462, Loss_fe 0.551, Loss_kd 0.410, Train_accy 85.07, Test_accy 88.60
2024-08-31 12:48:23,605 [foster.py] => Task 1, Epoch 105/170 => Loss 1.818, Loss_clf 0.456, Loss_fe 0.542, Loss_kd 0.409, Train_accy 84.56, Test_accy 87.80
2024-08-31 12:48:28,970 [foster.py] => Task 1, Epoch 106/170 => Loss 1.765, Loss_clf 0.426, Loss_fe 0.523, Loss_kd 0.407, Train_accy 85.78
2024-08-31 12:48:35,320 [foster.py] => Task 1, Epoch 107/170 => Loss 1.802, Loss_clf 0.445, Loss_fe 0.541, Loss_kd 0.407, Train_accy 85.13, Test_accy 91.50
2024-08-31 12:48:41,714 [foster.py] => Task 1, Epoch 108/170 => Loss 1.844, Loss_clf 0.470, Loss_fe 0.556, Loss_kd 0.408, Train_accy 84.67, Test_accy 86.50
2024-08-31 12:48:48,106 [foster.py] => Task 1, Epoch 109/170 => Loss 1.764, Loss_clf 0.439, Loss_fe 0.508, Loss_kd 0.408, Train_accy 85.67, Test_accy 90.10
2024-08-31 12:48:54,662 [foster.py] => Task 1, Epoch 110/170 => Loss 1.763, Loss_clf 0.436, Loss_fe 0.512, Loss_kd 0.407, Train_accy 84.80, Test_accy 89.10
2024-08-31 12:49:00,041 [foster.py] => Task 1, Epoch 111/170 => Loss 1.790, Loss_clf 0.449, Loss_fe 0.523, Loss_kd 0.409, Train_accy 84.76
2024-08-31 12:49:06,486 [foster.py] => Task 1, Epoch 112/170 => Loss 1.793, Loss_clf 0.442, Loss_fe 0.533, Loss_kd 0.409, Train_accy 85.47, Test_accy 85.40
2024-08-31 12:49:12,966 [foster.py] => Task 1, Epoch 113/170 => Loss 1.773, Loss_clf 0.442, Loss_fe 0.527, Loss_kd 0.401, Train_accy 86.02, Test_accy 90.40
2024-08-31 12:49:19,386 [foster.py] => Task 1, Epoch 114/170 => Loss 1.717, Loss_clf 0.418, Loss_fe 0.483, Loss_kd 0.407, Train_accy 86.04, Test_accy 90.90
2024-08-31 12:49:25,716 [foster.py] => Task 1, Epoch 115/170 => Loss 1.697, Loss_clf 0.409, Loss_fe 0.470, Loss_kd 0.409, Train_accy 85.93, Test_accy 91.70
2024-08-31 12:49:31,151 [foster.py] => Task 1, Epoch 116/170 => Loss 1.666, Loss_clf 0.395, Loss_fe 0.458, Loss_kd 0.406, Train_accy 86.67
2024-08-31 12:49:37,508 [foster.py] => Task 1, Epoch 117/170 => Loss 1.715, Loss_clf 0.410, Loss_fe 0.485, Loss_kd 0.409, Train_accy 86.24, Test_accy 90.90
2024-08-31 12:49:43,901 [foster.py] => Task 1, Epoch 118/170 => Loss 1.673, Loss_clf 0.404, Loss_fe 0.456, Loss_kd 0.406, Train_accy 86.49, Test_accy 90.70
2024-08-31 12:49:50,318 [foster.py] => Task 1, Epoch 119/170 => Loss 1.667, Loss_clf 0.387, Loss_fe 0.453, Loss_kd 0.413, Train_accy 86.82, Test_accy 90.70
2024-08-31 12:49:56,649 [foster.py] => Task 1, Epoch 120/170 => Loss 1.627, Loss_clf 0.379, Loss_fe 0.436, Loss_kd 0.406, Train_accy 87.33, Test_accy 92.40
2024-08-31 12:50:02,183 [foster.py] => Task 1, Epoch 121/170 => Loss 1.637, Loss_clf 0.387, Loss_fe 0.438, Loss_kd 0.405, Train_accy 87.09
2024-08-31 12:50:08,565 [foster.py] => Task 1, Epoch 122/170 => Loss 1.651, Loss_clf 0.385, Loss_fe 0.444, Loss_kd 0.410, Train_accy 87.02, Test_accy 90.50
2024-08-31 12:50:15,043 [foster.py] => Task 1, Epoch 123/170 => Loss 1.668, Loss_clf 0.395, Loss_fe 0.447, Loss_kd 0.413, Train_accy 86.93, Test_accy 90.70
2024-08-31 12:50:21,438 [foster.py] => Task 1, Epoch 124/170 => Loss 1.595, Loss_clf 0.372, Loss_fe 0.407, Loss_kd 0.408, Train_accy 87.80, Test_accy 92.20
2024-08-31 12:50:27,773 [foster.py] => Task 1, Epoch 125/170 => Loss 1.650, Loss_clf 0.389, Loss_fe 0.445, Loss_kd 0.407, Train_accy 87.13, Test_accy 90.80
2024-08-31 12:50:33,297 [foster.py] => Task 1, Epoch 126/170 => Loss 1.625, Loss_clf 0.377, Loss_fe 0.432, Loss_kd 0.408, Train_accy 87.44
2024-08-31 12:50:39,805 [foster.py] => Task 1, Epoch 127/170 => Loss 1.578, Loss_clf 0.367, Loss_fe 0.398, Loss_kd 0.406, Train_accy 87.84, Test_accy 92.00
2024-08-31 12:50:46,154 [foster.py] => Task 1, Epoch 128/170 => Loss 1.557, Loss_clf 0.348, Loss_fe 0.394, Loss_kd 0.407, Train_accy 88.67, Test_accy 90.70
2024-08-31 12:50:52,527 [foster.py] => Task 1, Epoch 129/170 => Loss 1.634, Loss_clf 0.382, Loss_fe 0.432, Loss_kd 0.410, Train_accy 87.73, Test_accy 89.90
2024-08-31 12:50:58,913 [foster.py] => Task 1, Epoch 130/170 => Loss 1.538, Loss_clf 0.340, Loss_fe 0.383, Loss_kd 0.406, Train_accy 88.84, Test_accy 92.40
2024-08-31 12:51:04,372 [foster.py] => Task 1, Epoch 131/170 => Loss 1.514, Loss_clf 0.331, Loss_fe 0.369, Loss_kd 0.406, Train_accy 88.49
2024-08-31 12:51:10,695 [foster.py] => Task 1, Epoch 132/170 => Loss 1.492, Loss_clf 0.322, Loss_fe 0.351, Loss_kd 0.409, Train_accy 89.89, Test_accy 91.50
2024-08-31 12:51:17,099 [foster.py] => Task 1, Epoch 133/170 => Loss 1.567, Loss_clf 0.353, Loss_fe 0.393, Loss_kd 0.410, Train_accy 88.36, Test_accy 90.30
2024-08-31 12:51:23,501 [foster.py] => Task 1, Epoch 134/170 => Loss 1.545, Loss_clf 0.337, Loss_fe 0.385, Loss_kd 0.411, Train_accy 89.00, Test_accy 92.30
2024-08-31 12:51:29,901 [foster.py] => Task 1, Epoch 135/170 => Loss 1.540, Loss_clf 0.344, Loss_fe 0.370, Loss_kd 0.413, Train_accy 88.53, Test_accy 91.30
2024-08-31 12:51:35,312 [foster.py] => Task 1, Epoch 136/170 => Loss 1.527, Loss_clf 0.337, Loss_fe 0.371, Loss_kd 0.409, Train_accy 88.96
2024-08-31 12:51:41,671 [foster.py] => Task 1, Epoch 137/170 => Loss 1.493, Loss_clf 0.322, Loss_fe 0.351, Loss_kd 0.410, Train_accy 89.09, Test_accy 92.80
2024-08-31 12:51:48,032 [foster.py] => Task 1, Epoch 138/170 => Loss 1.479, Loss_clf 0.319, Loss_fe 0.347, Loss_kd 0.406, Train_accy 89.38, Test_accy 91.70
2024-08-31 12:51:54,411 [foster.py] => Task 1, Epoch 139/170 => Loss 1.501, Loss_clf 0.326, Loss_fe 0.356, Loss_kd 0.408, Train_accy 89.29, Test_accy 92.00
2024-08-31 12:52:00,871 [foster.py] => Task 1, Epoch 140/170 => Loss 1.480, Loss_clf 0.313, Loss_fe 0.343, Loss_kd 0.411, Train_accy 90.38, Test_accy 93.20
2024-08-31 12:52:06,290 [foster.py] => Task 1, Epoch 141/170 => Loss 1.501, Loss_clf 0.321, Loss_fe 0.364, Loss_kd 0.407, Train_accy 89.56
2024-08-31 12:52:12,655 [foster.py] => Task 1, Epoch 142/170 => Loss 1.492, Loss_clf 0.328, Loss_fe 0.350, Loss_kd 0.407, Train_accy 89.51, Test_accy 91.90
2024-08-31 12:52:19,083 [foster.py] => Task 1, Epoch 143/170 => Loss 1.454, Loss_clf 0.310, Loss_fe 0.332, Loss_kd 0.405, Train_accy 89.96, Test_accy 91.90
2024-08-31 12:52:25,445 [foster.py] => Task 1, Epoch 144/170 => Loss 1.478, Loss_clf 0.314, Loss_fe 0.342, Loss_kd 0.410, Train_accy 90.00, Test_accy 92.90
2024-08-31 12:52:31,875 [foster.py] => Task 1, Epoch 145/170 => Loss 1.494, Loss_clf 0.314, Loss_fe 0.363, Loss_kd 0.408, Train_accy 89.49, Test_accy 92.20
2024-08-31 12:52:37,308 [foster.py] => Task 1, Epoch 146/170 => Loss 1.422, Loss_clf 0.300, Loss_fe 0.308, Loss_kd 0.406, Train_accy 89.82
2024-08-31 12:52:43,655 [foster.py] => Task 1, Epoch 147/170 => Loss 1.392, Loss_clf 0.273, Loss_fe 0.297, Loss_kd 0.410, Train_accy 90.69, Test_accy 93.00
2024-08-31 12:52:50,078 [foster.py] => Task 1, Epoch 148/170 => Loss 1.418, Loss_clf 0.291, Loss_fe 0.308, Loss_kd 0.409, Train_accy 90.20, Test_accy 93.60
2024-08-31 12:52:56,500 [foster.py] => Task 1, Epoch 149/170 => Loss 1.364, Loss_clf 0.270, Loss_fe 0.285, Loss_kd 0.404, Train_accy 91.00, Test_accy 93.70
2024-08-31 12:53:02,938 [foster.py] => Task 1, Epoch 150/170 => Loss 1.401, Loss_clf 0.283, Loss_fe 0.297, Loss_kd 0.409, Train_accy 90.96, Test_accy 93.80
2024-08-31 12:53:08,319 [foster.py] => Task 1, Epoch 151/170 => Loss 1.368, Loss_clf 0.268, Loss_fe 0.286, Loss_kd 0.406, Train_accy 91.33
2024-08-31 12:53:14,681 [foster.py] => Task 1, Epoch 152/170 => Loss 1.375, Loss_clf 0.271, Loss_fe 0.287, Loss_kd 0.408, Train_accy 91.18, Test_accy 93.00
2024-08-31 12:53:21,162 [foster.py] => Task 1, Epoch 153/170 => Loss 1.364, Loss_clf 0.267, Loss_fe 0.284, Loss_kd 0.406, Train_accy 90.87, Test_accy 93.40
2024-08-31 12:53:27,636 [foster.py] => Task 1, Epoch 154/170 => Loss 1.387, Loss_clf 0.278, Loss_fe 0.293, Loss_kd 0.407, Train_accy 91.02, Test_accy 93.50
2024-08-31 12:53:34,449 [foster.py] => Task 1, Epoch 155/170 => Loss 1.371, Loss_clf 0.274, Loss_fe 0.282, Loss_kd 0.406, Train_accy 91.09, Test_accy 93.70
2024-08-31 12:53:39,872 [foster.py] => Task 1, Epoch 156/170 => Loss 1.358, Loss_clf 0.265, Loss_fe 0.273, Loss_kd 0.409, Train_accy 90.93
2024-08-31 12:53:46,261 [foster.py] => Task 1, Epoch 157/170 => Loss 1.325, Loss_clf 0.247, Loss_fe 0.256, Loss_kd 0.410, Train_accy 92.20, Test_accy 93.50
2024-08-31 12:53:52,637 [foster.py] => Task 1, Epoch 158/170 => Loss 1.379, Loss_clf 0.271, Loss_fe 0.294, Loss_kd 0.406, Train_accy 90.76, Test_accy 94.20
2024-08-31 12:53:59,106 [foster.py] => Task 1, Epoch 159/170 => Loss 1.352, Loss_clf 0.263, Loss_fe 0.271, Loss_kd 0.408, Train_accy 91.47, Test_accy 93.60
2024-08-31 12:54:05,579 [foster.py] => Task 1, Epoch 160/170 => Loss 1.293, Loss_clf 0.233, Loss_fe 0.249, Loss_kd 0.405, Train_accy 91.96, Test_accy 93.60
2024-08-31 12:54:10,946 [foster.py] => Task 1, Epoch 161/170 => Loss 1.347, Loss_clf 0.261, Loss_fe 0.262, Loss_kd 0.411, Train_accy 91.64
2024-08-31 12:54:17,300 [foster.py] => Task 1, Epoch 162/170 => Loss 1.341, Loss_clf 0.252, Loss_fe 0.269, Loss_kd 0.409, Train_accy 92.31, Test_accy 93.90
2024-08-31 12:54:23,731 [foster.py] => Task 1, Epoch 163/170 => Loss 1.335, Loss_clf 0.260, Loss_fe 0.258, Loss_kd 0.408, Train_accy 91.58, Test_accy 93.90
2024-08-31 12:54:30,172 [foster.py] => Task 1, Epoch 164/170 => Loss 1.344, Loss_clf 0.258, Loss_fe 0.267, Loss_kd 0.409, Train_accy 91.87, Test_accy 93.90
2024-08-31 12:54:36,571 [foster.py] => Task 1, Epoch 165/170 => Loss 1.380, Loss_clf 0.276, Loss_fe 0.284, Loss_kd 0.410, Train_accy 91.02, Test_accy 93.80
2024-08-31 12:54:42,024 [foster.py] => Task 1, Epoch 166/170 => Loss 1.295, Loss_clf 0.239, Loss_fe 0.243, Loss_kd 0.406, Train_accy 91.98
2024-08-31 12:54:48,511 [foster.py] => Task 1, Epoch 167/170 => Loss 1.329, Loss_clf 0.253, Loss_fe 0.257, Loss_kd 0.409, Train_accy 92.07, Test_accy 93.90
2024-08-31 12:54:54,971 [foster.py] => Task 1, Epoch 168/170 => Loss 1.341, Loss_clf 0.262, Loss_fe 0.265, Loss_kd 0.406, Train_accy 91.42, Test_accy 93.70
2024-08-31 12:55:01,387 [foster.py] => Task 1, Epoch 169/170 => Loss 1.313, Loss_clf 0.246, Loss_fe 0.254, Loss_kd 0.406, Train_accy 91.98, Test_accy 93.90
2024-08-31 12:55:07,787 [foster.py] => Task 1, Epoch 170/170 => Loss 1.306, Loss_clf 0.239, Loss_fe 0.251, Loss_kd 0.408, Train_accy 92.31, Test_accy 93.90
2024-08-31 12:55:07,791 [foster.py] => do not weight align teacher!
2024-08-31 12:55:07,792 [foster.py] => per cls weights : [1.04762148 1.04762148 1.04762148 1.04762148 1.04762148 0.95237852
 0.95237852 0.95237852 0.95237852 0.95237852]
2024-08-31 12:55:16,551 [foster.py] => SNet: Task 1, Epoch 1/130 => Loss 15.564,  Loss1 0.391, Train_accy 48.76, Test_accy 47.80
2024-08-31 12:55:23,840 [foster.py] => SNet: Task 1, Epoch 2/130 => Loss 15.582,  Loss1 0.391, Train_accy 54.53
2024-08-31 12:55:31,322 [foster.py] => SNet: Task 1, Epoch 3/130 => Loss 15.526,  Loss1 0.390, Train_accy 58.07
2024-08-31 12:55:38,827 [foster.py] => SNet: Task 1, Epoch 4/130 => Loss 15.459,  Loss1 0.390, Train_accy 62.02
2024-08-31 12:55:46,116 [foster.py] => SNet: Task 1, Epoch 5/130 => Loss 15.422,  Loss1 0.390, Train_accy 65.02
2024-08-31 12:55:54,178 [foster.py] => SNet: Task 1, Epoch 6/130 => Loss 15.396,  Loss1 0.390, Train_accy 67.58, Test_accy 72.90
2024-08-31 12:56:01,782 [foster.py] => SNet: Task 1, Epoch 7/130 => Loss 15.379,  Loss1 0.390, Train_accy 68.27
2024-08-31 12:56:09,266 [foster.py] => SNet: Task 1, Epoch 8/130 => Loss 15.324,  Loss1 0.390, Train_accy 70.82
2024-08-31 12:56:16,457 [foster.py] => SNet: Task 1, Epoch 9/130 => Loss 15.328,  Loss1 0.390, Train_accy 72.09
2024-08-31 12:56:23,660 [foster.py] => SNet: Task 1, Epoch 10/130 => Loss 15.310,  Loss1 0.390, Train_accy 73.22
2024-08-31 12:56:31,816 [foster.py] => SNet: Task 1, Epoch 11/130 => Loss 15.288,  Loss1 0.390, Train_accy 74.62, Test_accy 79.80
2024-08-31 12:56:39,089 [foster.py] => SNet: Task 1, Epoch 12/130 => Loss 15.295,  Loss1 0.389, Train_accy 74.56
2024-08-31 12:56:46,312 [foster.py] => SNet: Task 1, Epoch 13/130 => Loss 15.264,  Loss1 0.390, Train_accy 77.04
2024-08-31 12:56:53,813 [foster.py] => SNet: Task 1, Epoch 14/130 => Loss 15.274,  Loss1 0.390, Train_accy 76.51
2024-08-31 12:57:01,293 [foster.py] => SNet: Task 1, Epoch 15/130 => Loss 15.255,  Loss1 0.390, Train_accy 77.07
2024-08-31 12:57:09,478 [foster.py] => SNet: Task 1, Epoch 16/130 => Loss 15.242,  Loss1 0.390, Train_accy 78.49, Test_accy 85.30
2024-08-31 12:57:16,716 [foster.py] => SNet: Task 1, Epoch 17/130 => Loss 15.247,  Loss1 0.390, Train_accy 77.64
2024-08-31 12:57:24,011 [foster.py] => SNet: Task 1, Epoch 18/130 => Loss 15.257,  Loss1 0.390, Train_accy 77.22
2024-08-31 12:57:31,188 [foster.py] => SNet: Task 1, Epoch 19/130 => Loss 15.255,  Loss1 0.390, Train_accy 78.73
2024-08-31 12:57:38,364 [foster.py] => SNet: Task 1, Epoch 20/130 => Loss 15.238,  Loss1 0.390, Train_accy 78.82
2024-08-31 12:57:46,714 [foster.py] => SNet: Task 1, Epoch 21/130 => Loss 15.258,  Loss1 0.390, Train_accy 79.09, Test_accy 88.60
2024-08-31 12:57:54,008 [foster.py] => SNet: Task 1, Epoch 22/130 => Loss 15.206,  Loss1 0.389, Train_accy 80.02
2024-08-31 12:58:01,294 [foster.py] => SNet: Task 1, Epoch 23/130 => Loss 15.230,  Loss1 0.390, Train_accy 80.22
2024-08-31 12:58:08,563 [foster.py] => SNet: Task 1, Epoch 24/130 => Loss 15.222,  Loss1 0.390, Train_accy 80.36
2024-08-31 12:58:15,771 [foster.py] => SNet: Task 1, Epoch 25/130 => Loss 15.222,  Loss1 0.390, Train_accy 80.98
2024-08-31 12:58:23,889 [foster.py] => SNet: Task 1, Epoch 26/130 => Loss 15.214,  Loss1 0.390, Train_accy 82.13, Test_accy 88.90
2024-08-31 12:58:31,243 [foster.py] => SNet: Task 1, Epoch 27/130 => Loss 15.205,  Loss1 0.390, Train_accy 80.93
2024-08-31 12:58:38,614 [foster.py] => SNet: Task 1, Epoch 28/130 => Loss 15.203,  Loss1 0.390, Train_accy 82.11
2024-08-31 12:58:46,112 [foster.py] => SNet: Task 1, Epoch 29/130 => Loss 15.197,  Loss1 0.390, Train_accy 82.49
2024-08-31 12:58:53,529 [foster.py] => SNet: Task 1, Epoch 30/130 => Loss 15.200,  Loss1 0.390, Train_accy 82.11
2024-08-31 12:59:01,937 [foster.py] => SNet: Task 1, Epoch 31/130 => Loss 15.194,  Loss1 0.389, Train_accy 82.13, Test_accy 88.20
2024-08-31 12:59:09,176 [foster.py] => SNet: Task 1, Epoch 32/130 => Loss 15.187,  Loss1 0.390, Train_accy 83.80
2024-08-31 12:59:16,365 [foster.py] => SNet: Task 1, Epoch 33/130 => Loss 15.209,  Loss1 0.389, Train_accy 81.89
2024-08-31 12:59:23,631 [foster.py] => SNet: Task 1, Epoch 34/130 => Loss 15.177,  Loss1 0.389, Train_accy 83.84
2024-08-31 12:59:31,053 [foster.py] => SNet: Task 1, Epoch 35/130 => Loss 15.184,  Loss1 0.390, Train_accy 83.44
2024-08-31 12:59:39,297 [foster.py] => SNet: Task 1, Epoch 36/130 => Loss 15.164,  Loss1 0.390, Train_accy 84.07, Test_accy 88.60
2024-08-31 12:59:46,509 [foster.py] => SNet: Task 1, Epoch 37/130 => Loss 15.178,  Loss1 0.390, Train_accy 84.02
2024-08-31 12:59:53,795 [foster.py] => SNet: Task 1, Epoch 38/130 => Loss 15.203,  Loss1 0.389, Train_accy 82.40
2024-08-31 13:00:01,273 [foster.py] => SNet: Task 1, Epoch 39/130 => Loss 15.171,  Loss1 0.390, Train_accy 85.20
2024-08-31 13:00:08,852 [foster.py] => SNet: Task 1, Epoch 40/130 => Loss 15.196,  Loss1 0.390, Train_accy 83.96
2024-08-31 13:00:17,083 [foster.py] => SNet: Task 1, Epoch 41/130 => Loss 15.191,  Loss1 0.389, Train_accy 84.13, Test_accy 91.00
2024-08-31 13:00:24,580 [foster.py] => SNet: Task 1, Epoch 42/130 => Loss 15.171,  Loss1 0.390, Train_accy 84.44
2024-08-31 13:00:31,803 [foster.py] => SNet: Task 1, Epoch 43/130 => Loss 15.172,  Loss1 0.389, Train_accy 84.38
2024-08-31 13:00:39,113 [foster.py] => SNet: Task 1, Epoch 44/130 => Loss 15.155,  Loss1 0.390, Train_accy 85.04
2024-08-31 13:00:46,300 [foster.py] => SNet: Task 1, Epoch 45/130 => Loss 15.159,  Loss1 0.389, Train_accy 84.89
2024-08-31 13:00:54,885 [foster.py] => SNet: Task 1, Epoch 46/130 => Loss 15.145,  Loss1 0.390, Train_accy 85.27, Test_accy 92.20
2024-08-31 13:01:02,141 [foster.py] => SNet: Task 1, Epoch 47/130 => Loss 15.164,  Loss1 0.390, Train_accy 85.44
2024-08-31 13:01:09,382 [foster.py] => SNet: Task 1, Epoch 48/130 => Loss 15.168,  Loss1 0.389, Train_accy 85.27
2024-08-31 13:01:16,785 [foster.py] => SNet: Task 1, Epoch 49/130 => Loss 15.153,  Loss1 0.389, Train_accy 85.87
2024-08-31 13:01:23,998 [foster.py] => SNet: Task 1, Epoch 50/130 => Loss 15.151,  Loss1 0.390, Train_accy 86.58
2024-08-31 13:01:32,278 [foster.py] => SNet: Task 1, Epoch 51/130 => Loss 15.154,  Loss1 0.390, Train_accy 86.36, Test_accy 91.10
2024-08-31 13:01:39,629 [foster.py] => SNet: Task 1, Epoch 52/130 => Loss 15.176,  Loss1 0.390, Train_accy 86.44
2024-08-31 13:01:47,219 [foster.py] => SNet: Task 1, Epoch 53/130 => Loss 15.146,  Loss1 0.390, Train_accy 86.51
2024-08-31 13:01:54,836 [foster.py] => SNet: Task 1, Epoch 54/130 => Loss 15.153,  Loss1 0.389, Train_accy 86.24
2024-08-31 13:02:02,093 [foster.py] => SNet: Task 1, Epoch 55/130 => Loss 15.171,  Loss1 0.390, Train_accy 86.36
2024-08-31 13:02:10,258 [foster.py] => SNet: Task 1, Epoch 56/130 => Loss 15.152,  Loss1 0.390, Train_accy 86.71, Test_accy 91.30
2024-08-31 13:02:17,908 [foster.py] => SNet: Task 1, Epoch 57/130 => Loss 15.138,  Loss1 0.390, Train_accy 86.49
2024-08-31 13:02:25,133 [foster.py] => SNet: Task 1, Epoch 58/130 => Loss 15.156,  Loss1 0.390, Train_accy 85.89
2024-08-31 13:02:32,405 [foster.py] => SNet: Task 1, Epoch 59/130 => Loss 15.164,  Loss1 0.390, Train_accy 86.73
2024-08-31 13:02:39,887 [foster.py] => SNet: Task 1, Epoch 60/130 => Loss 15.137,  Loss1 0.389, Train_accy 88.07
2024-08-31 13:02:48,047 [foster.py] => SNet: Task 1, Epoch 61/130 => Loss 15.139,  Loss1 0.389, Train_accy 87.60, Test_accy 92.00
2024-08-31 13:02:55,297 [foster.py] => SNet: Task 1, Epoch 62/130 => Loss 15.154,  Loss1 0.390, Train_accy 87.91
2024-08-31 13:03:02,540 [foster.py] => SNet: Task 1, Epoch 63/130 => Loss 15.141,  Loss1 0.389, Train_accy 86.98
2024-08-31 13:03:09,859 [foster.py] => SNet: Task 1, Epoch 64/130 => Loss 15.149,  Loss1 0.390, Train_accy 87.09
2024-08-31 13:03:17,099 [foster.py] => SNet: Task 1, Epoch 65/130 => Loss 15.158,  Loss1 0.389, Train_accy 87.18
2024-08-31 13:03:25,519 [foster.py] => SNet: Task 1, Epoch 66/130 => Loss 15.151,  Loss1 0.389, Train_accy 86.80, Test_accy 93.40
2024-08-31 13:03:33,021 [foster.py] => SNet: Task 1, Epoch 67/130 => Loss 15.144,  Loss1 0.389, Train_accy 87.33
2024-08-31 13:03:40,514 [foster.py] => SNet: Task 1, Epoch 68/130 => Loss 15.155,  Loss1 0.390, Train_accy 87.16
2024-08-31 13:03:48,053 [foster.py] => SNet: Task 1, Epoch 69/130 => Loss 15.158,  Loss1 0.389, Train_accy 87.62
2024-08-31 13:03:55,263 [foster.py] => SNet: Task 1, Epoch 70/130 => Loss 15.132,  Loss1 0.389, Train_accy 87.71
2024-08-31 13:04:03,697 [foster.py] => SNet: Task 1, Epoch 71/130 => Loss 15.131,  Loss1 0.390, Train_accy 88.49, Test_accy 92.10
2024-08-31 13:04:10,987 [foster.py] => SNet: Task 1, Epoch 72/130 => Loss 15.133,  Loss1 0.390, Train_accy 87.91
2024-08-31 13:04:18,543 [foster.py] => SNet: Task 1, Epoch 73/130 => Loss 15.151,  Loss1 0.390, Train_accy 87.67
2024-08-31 13:04:26,161 [foster.py] => SNet: Task 1, Epoch 74/130 => Loss 15.157,  Loss1 0.390, Train_accy 87.78
2024-08-31 13:04:33,446 [foster.py] => SNet: Task 1, Epoch 75/130 => Loss 15.156,  Loss1 0.389, Train_accy 87.71
2024-08-31 13:04:41,635 [foster.py] => SNet: Task 1, Epoch 76/130 => Loss 15.151,  Loss1 0.390, Train_accy 88.04, Test_accy 92.60
2024-08-31 13:04:48,822 [foster.py] => SNet: Task 1, Epoch 77/130 => Loss 15.153,  Loss1 0.390, Train_accy 88.27
2024-08-31 13:04:56,119 [foster.py] => SNet: Task 1, Epoch 78/130 => Loss 15.148,  Loss1 0.389, Train_accy 88.80
2024-08-31 13:05:03,575 [foster.py] => SNet: Task 1, Epoch 79/130 => Loss 15.149,  Loss1 0.390, Train_accy 88.38
2024-08-31 13:05:10,925 [foster.py] => SNet: Task 1, Epoch 80/130 => Loss 15.141,  Loss1 0.389, Train_accy 88.38
2024-08-31 13:05:18,966 [foster.py] => SNet: Task 1, Epoch 81/130 => Loss 15.147,  Loss1 0.389, Train_accy 88.89, Test_accy 92.40
2024-08-31 13:05:26,285 [foster.py] => SNet: Task 1, Epoch 82/130 => Loss 15.136,  Loss1 0.390, Train_accy 88.29
2024-08-31 13:05:33,469 [foster.py] => SNet: Task 1, Epoch 83/130 => Loss 15.138,  Loss1 0.390, Train_accy 89.02
2024-08-31 13:05:40,747 [foster.py] => SNet: Task 1, Epoch 84/130 => Loss 15.122,  Loss1 0.389, Train_accy 88.98
2024-08-31 13:05:48,255 [foster.py] => SNet: Task 1, Epoch 85/130 => Loss 15.136,  Loss1 0.389, Train_accy 88.09
2024-08-31 13:05:56,751 [foster.py] => SNet: Task 1, Epoch 86/130 => Loss 15.132,  Loss1 0.390, Train_accy 88.96, Test_accy 92.70
2024-08-31 13:06:03,983 [foster.py] => SNet: Task 1, Epoch 87/130 => Loss 15.143,  Loss1 0.390, Train_accy 88.40
2024-08-31 13:06:11,218 [foster.py] => SNet: Task 1, Epoch 88/130 => Loss 15.147,  Loss1 0.389, Train_accy 88.98
2024-08-31 13:06:18,378 [foster.py] => SNet: Task 1, Epoch 89/130 => Loss 15.144,  Loss1 0.390, Train_accy 88.47
2024-08-31 13:06:25,535 [foster.py] => SNet: Task 1, Epoch 90/130 => Loss 15.143,  Loss1 0.389, Train_accy 88.91
2024-08-31 13:06:33,617 [foster.py] => SNet: Task 1, Epoch 91/130 => Loss 15.144,  Loss1 0.390, Train_accy 87.60, Test_accy 93.10
2024-08-31 13:06:41,084 [foster.py] => SNet: Task 1, Epoch 92/130 => Loss 15.144,  Loss1 0.390, Train_accy 88.69
2024-08-31 13:06:48,483 [foster.py] => SNet: Task 1, Epoch 93/130 => Loss 15.139,  Loss1 0.390, Train_accy 88.62
2024-08-31 13:06:55,828 [foster.py] => SNet: Task 1, Epoch 94/130 => Loss 15.138,  Loss1 0.389, Train_accy 88.80
2024-08-31 13:07:03,324 [foster.py] => SNet: Task 1, Epoch 95/130 => Loss 15.126,  Loss1 0.389, Train_accy 88.96
2024-08-31 13:07:11,634 [foster.py] => SNet: Task 1, Epoch 96/130 => Loss 15.131,  Loss1 0.390, Train_accy 88.91, Test_accy 92.90
2024-08-31 13:07:18,855 [foster.py] => SNet: Task 1, Epoch 97/130 => Loss 15.145,  Loss1 0.390, Train_accy 89.11
2024-08-31 13:07:26,248 [foster.py] => SNet: Task 1, Epoch 98/130 => Loss 15.140,  Loss1 0.390, Train_accy 89.11
2024-08-31 13:07:33,598 [foster.py] => SNet: Task 1, Epoch 99/130 => Loss 15.105,  Loss1 0.390, Train_accy 89.93
2024-08-31 13:07:40,920 [foster.py] => SNet: Task 1, Epoch 100/130 => Loss 15.127,  Loss1 0.389, Train_accy 89.24
2024-08-31 13:07:49,169 [foster.py] => SNet: Task 1, Epoch 101/130 => Loss 15.133,  Loss1 0.390, Train_accy 88.84, Test_accy 93.20
2024-08-31 13:07:56,430 [foster.py] => SNet: Task 1, Epoch 102/130 => Loss 15.142,  Loss1 0.390, Train_accy 89.16
2024-08-31 13:08:03,943 [foster.py] => SNet: Task 1, Epoch 103/130 => Loss 15.123,  Loss1 0.390, Train_accy 89.13
2024-08-31 13:08:11,276 [foster.py] => SNet: Task 1, Epoch 104/130 => Loss 15.141,  Loss1 0.389, Train_accy 88.51
2024-08-31 13:08:18,531 [foster.py] => SNet: Task 1, Epoch 105/130 => Loss 15.123,  Loss1 0.390, Train_accy 89.53
2024-08-31 13:08:26,572 [foster.py] => SNet: Task 1, Epoch 106/130 => Loss 15.126,  Loss1 0.389, Train_accy 89.24, Test_accy 92.90
2024-08-31 13:08:33,836 [foster.py] => SNet: Task 1, Epoch 107/130 => Loss 15.126,  Loss1 0.390, Train_accy 89.36
2024-08-31 13:08:41,318 [foster.py] => SNet: Task 1, Epoch 108/130 => Loss 15.125,  Loss1 0.389, Train_accy 89.53
2024-08-31 13:08:48,684 [foster.py] => SNet: Task 1, Epoch 109/130 => Loss 15.121,  Loss1 0.389, Train_accy 90.09
2024-08-31 13:08:56,052 [foster.py] => SNet: Task 1, Epoch 110/130 => Loss 15.135,  Loss1 0.389, Train_accy 89.44
2024-08-31 13:09:04,218 [foster.py] => SNet: Task 1, Epoch 111/130 => Loss 15.128,  Loss1 0.389, Train_accy 89.47, Test_accy 93.20
2024-08-31 13:09:11,653 [foster.py] => SNet: Task 1, Epoch 112/130 => Loss 15.120,  Loss1 0.389, Train_accy 89.91
2024-08-31 13:09:19,311 [foster.py] => SNet: Task 1, Epoch 113/130 => Loss 15.133,  Loss1 0.389, Train_accy 89.69
2024-08-31 13:09:26,611 [foster.py] => SNet: Task 1, Epoch 114/130 => Loss 15.134,  Loss1 0.390, Train_accy 89.58
2024-08-31 13:09:34,022 [foster.py] => SNet: Task 1, Epoch 115/130 => Loss 15.120,  Loss1 0.389, Train_accy 89.62
2024-08-31 13:09:42,067 [foster.py] => SNet: Task 1, Epoch 116/130 => Loss 15.137,  Loss1 0.390, Train_accy 89.40, Test_accy 93.30
2024-08-31 13:09:49,274 [foster.py] => SNet: Task 1, Epoch 117/130 => Loss 15.126,  Loss1 0.390, Train_accy 89.44
2024-08-31 13:09:56,442 [foster.py] => SNet: Task 1, Epoch 118/130 => Loss 15.121,  Loss1 0.390, Train_accy 89.49
2024-08-31 13:10:03,794 [foster.py] => SNet: Task 1, Epoch 119/130 => Loss 15.135,  Loss1 0.390, Train_accy 89.07
2024-08-31 13:10:11,282 [foster.py] => SNet: Task 1, Epoch 120/130 => Loss 15.130,  Loss1 0.390, Train_accy 89.64
2024-08-31 13:10:19,339 [foster.py] => SNet: Task 1, Epoch 121/130 => Loss 15.128,  Loss1 0.389, Train_accy 89.89, Test_accy 92.80
2024-08-31 13:10:27,266 [foster.py] => SNet: Task 1, Epoch 122/130 => Loss 15.130,  Loss1 0.389, Train_accy 89.71
2024-08-31 13:10:34,626 [foster.py] => SNet: Task 1, Epoch 123/130 => Loss 15.137,  Loss1 0.389, Train_accy 88.56
2024-08-31 13:10:42,045 [foster.py] => SNet: Task 1, Epoch 124/130 => Loss 15.132,  Loss1 0.389, Train_accy 89.47
2024-08-31 13:10:49,233 [foster.py] => SNet: Task 1, Epoch 125/130 => Loss 15.141,  Loss1 0.390, Train_accy 89.22
2024-08-31 13:10:57,716 [foster.py] => SNet: Task 1, Epoch 126/130 => Loss 15.106,  Loss1 0.389, Train_accy 89.56, Test_accy 93.60
2024-08-31 13:11:05,215 [foster.py] => SNet: Task 1, Epoch 127/130 => Loss 15.135,  Loss1 0.390, Train_accy 89.80
2024-08-31 13:11:12,523 [foster.py] => SNet: Task 1, Epoch 128/130 => Loss 15.126,  Loss1 0.390, Train_accy 89.80
2024-08-31 13:11:19,802 [foster.py] => SNet: Task 1, Epoch 129/130 => Loss 15.128,  Loss1 0.390, Train_accy 89.18
2024-08-31 13:11:26,963 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 15.107,  Loss1 0.389, Train_accy 89.82
2024-08-31 13:11:26,964 [foster.py] => do not weight align student!
2024-08-31 13:11:27,886 [foster.py] => darknet eval: 
2024-08-31 13:11:27,886 [foster.py] => CNN top1 curve: 93.0
2024-08-31 13:11:27,887 [foster.py] => CNN top5 curve: 99.7
2024-08-31 13:11:27,887 [foster.py] => CNN top1 平均值: 93.00
2024-08-31 13:11:27,889 [foster.py] => timees : 2037.9655265808105
2024-08-31 13:11:27,890 [base.py] => Reducing exemplars...(200 per classes)
2024-08-31 13:11:30,231 [base.py] => Constructing exemplars...(200 per classes)
2024-08-31 13:11:38,192 [foster.py] => Exemplar size: 2000
2024-08-31 13:11:38,192 [trainer.py] => CNN: {'total': 93.9, '00-09': 93.9, 'old': 96.6, 'new': 91.2}
2024-08-31 13:11:38,192 [trainer.py] => NME: {'total': 94.1, '00-09': 94.1, 'old': 97.0, 'new': 91.2}
2024-08-31 13:11:38,192 [trainer.py] => CNN top1 curve: [98.8, 93.9]
2024-08-31 13:11:38,192 [trainer.py] => CNN top5 curve: [100.0, 99.8]
2024-08-31 13:11:38,192 [trainer.py] => NME top1 curve: [99.0, 94.1]
2024-08-31 13:11:38,192 [trainer.py] => NME top5 curve: [100.0, 99.7]

2024-08-31 13:11:38,192 [trainer.py] => CNN top1 平均值: 96.35
2024-08-31 13:11:38,196 [trainer.py] => All params: 1284813
2024-08-31 13:11:38,199 [trainer.py] => Trainable params: 643214
2024-08-31 13:11:38,261 [foster.py] => Learning on 10-15
2024-08-31 13:11:38,265 [foster.py] => All params: 1286108
2024-08-31 13:11:38,267 [foster.py] => Trainable params: 644184
2024-08-31 13:11:38,307 [foster.py] => per cls weights : [1.03125393 1.03125393 1.03125393 1.03125393 1.03125393 1.03125393
 1.03125393 1.03125393 1.03125393 1.03125393 0.93749214 0.93749214
 0.93749214 0.93749214 0.93749214]
2024-08-31 13:11:43,694 [foster.py] => Task 2, Epoch 1/170 => Loss 4.355, Loss_clf 1.403, Loss_fe 1.724, Loss_kd 0.818, Train_accy 54.53
2024-08-31 13:11:50,319 [foster.py] => Task 2, Epoch 2/170 => Loss 3.974, Loss_clf 1.128, Loss_fe 1.635, Loss_kd 0.806, Train_accy 61.07, Test_accy 74.27
2024-08-31 13:11:56,891 [foster.py] => Task 2, Epoch 3/170 => Loss 3.747, Loss_clf 1.023, Loss_fe 1.511, Loss_kd 0.808, Train_accy 64.64, Test_accy 77.67
2024-08-31 13:12:03,564 [foster.py] => Task 2, Epoch 4/170 => Loss 3.604, Loss_clf 0.975, Loss_fe 1.412, Loss_kd 0.810, Train_accy 66.64, Test_accy 74.00
2024-08-31 13:12:10,171 [foster.py] => Task 2, Epoch 5/170 => Loss 3.658, Loss_clf 0.988, Loss_fe 1.451, Loss_kd 0.811, Train_accy 66.62, Test_accy 74.13
2024-08-31 13:12:15,509 [foster.py] => Task 2, Epoch 6/170 => Loss 3.602, Loss_clf 0.965, Loss_fe 1.428, Loss_kd 0.804, Train_accy 66.80
2024-08-31 13:12:21,967 [foster.py] => Task 2, Epoch 7/170 => Loss 3.656, Loss_clf 1.016, Loss_fe 1.415, Loss_kd 0.814, Train_accy 66.09, Test_accy 74.13
2024-08-31 13:12:28,529 [foster.py] => Task 2, Epoch 8/170 => Loss 3.517, Loss_clf 0.941, Loss_fe 1.370, Loss_kd 0.802, Train_accy 68.38, Test_accy 74.40
2024-08-31 13:12:35,109 [foster.py] => Task 2, Epoch 9/170 => Loss 3.507, Loss_clf 0.938, Loss_fe 1.358, Loss_kd 0.806, Train_accy 68.20, Test_accy 75.53
2024-08-31 13:12:41,837 [foster.py] => Task 2, Epoch 10/170 => Loss 3.553, Loss_clf 0.942, Loss_fe 1.404, Loss_kd 0.803, Train_accy 66.89, Test_accy 76.93
2024-08-31 13:12:47,215 [foster.py] => Task 2, Epoch 11/170 => Loss 3.482, Loss_clf 0.934, Loss_fe 1.335, Loss_kd 0.807, Train_accy 68.02
2024-08-31 13:12:53,741 [foster.py] => Task 2, Epoch 12/170 => Loss 3.431, Loss_clf 0.891, Loss_fe 1.331, Loss_kd 0.805, Train_accy 69.20, Test_accy 78.80
2024-08-31 13:13:00,345 [foster.py] => Task 2, Epoch 13/170 => Loss 3.361, Loss_clf 0.885, Loss_fe 1.265, Loss_kd 0.806, Train_accy 69.33, Test_accy 78.20
2024-08-31 13:13:06,945 [foster.py] => Task 2, Epoch 14/170 => Loss 3.466, Loss_clf 0.916, Loss_fe 1.342, Loss_kd 0.804, Train_accy 68.27, Test_accy 74.53
2024-08-31 13:13:13,614 [foster.py] => Task 2, Epoch 15/170 => Loss 3.441, Loss_clf 0.909, Loss_fe 1.324, Loss_kd 0.803, Train_accy 69.11, Test_accy 78.20
2024-08-31 13:13:19,062 [foster.py] => Task 2, Epoch 16/170 => Loss 3.451, Loss_clf 0.927, Loss_fe 1.310, Loss_kd 0.808, Train_accy 68.76
2024-08-31 13:13:25,727 [foster.py] => Task 2, Epoch 17/170 => Loss 3.368, Loss_clf 0.885, Loss_fe 1.265, Loss_kd 0.810, Train_accy 69.87, Test_accy 77.67
2024-08-31 13:13:32,384 [foster.py] => Task 2, Epoch 18/170 => Loss 3.354, Loss_clf 0.882, Loss_fe 1.261, Loss_kd 0.806, Train_accy 69.89, Test_accy 77.13
2024-08-31 13:13:39,019 [foster.py] => Task 2, Epoch 19/170 => Loss 3.344, Loss_clf 0.888, Loss_fe 1.238, Loss_kd 0.810, Train_accy 70.40, Test_accy 77.60
2024-08-31 13:13:45,616 [foster.py] => Task 2, Epoch 20/170 => Loss 3.336, Loss_clf 0.893, Loss_fe 1.235, Loss_kd 0.804, Train_accy 69.87, Test_accy 74.53
2024-08-31 13:13:51,012 [foster.py] => Task 2, Epoch 21/170 => Loss 3.319, Loss_clf 0.884, Loss_fe 1.226, Loss_kd 0.805, Train_accy 70.38
2024-08-31 13:13:57,627 [foster.py] => Task 2, Epoch 22/170 => Loss 3.319, Loss_clf 0.881, Loss_fe 1.219, Loss_kd 0.811, Train_accy 70.47, Test_accy 78.60
2024-08-31 13:14:04,216 [foster.py] => Task 2, Epoch 23/170 => Loss 3.307, Loss_clf 0.857, Loss_fe 1.226, Loss_kd 0.815, Train_accy 70.84, Test_accy 77.67
2024-08-31 13:14:10,829 [foster.py] => Task 2, Epoch 24/170 => Loss 3.331, Loss_clf 0.889, Loss_fe 1.222, Loss_kd 0.812, Train_accy 70.20, Test_accy 76.60
2024-08-31 13:14:17,559 [foster.py] => Task 2, Epoch 25/170 => Loss 3.344, Loss_clf 0.901, Loss_fe 1.235, Loss_kd 0.804, Train_accy 68.91, Test_accy 70.27
2024-08-31 13:14:23,013 [foster.py] => Task 2, Epoch 26/170 => Loss 3.310, Loss_clf 0.878, Loss_fe 1.218, Loss_kd 0.808, Train_accy 69.80
2024-08-31 13:14:29,671 [foster.py] => Task 2, Epoch 27/170 => Loss 3.245, Loss_clf 0.855, Loss_fe 1.176, Loss_kd 0.808, Train_accy 71.29, Test_accy 78.87
2024-08-31 13:14:36,511 [foster.py] => Task 2, Epoch 28/170 => Loss 3.290, Loss_clf 0.882, Loss_fe 1.195, Loss_kd 0.807, Train_accy 70.38, Test_accy 79.13
2024-08-31 13:14:43,269 [foster.py] => Task 2, Epoch 29/170 => Loss 3.268, Loss_clf 0.862, Loss_fe 1.196, Loss_kd 0.805, Train_accy 70.47, Test_accy 79.67
2024-08-31 13:14:49,868 [foster.py] => Task 2, Epoch 30/170 => Loss 3.237, Loss_clf 0.845, Loss_fe 1.187, Loss_kd 0.802, Train_accy 71.67, Test_accy 79.33
2024-08-31 13:14:55,360 [foster.py] => Task 2, Epoch 31/170 => Loss 3.201, Loss_clf 0.818, Loss_fe 1.166, Loss_kd 0.809, Train_accy 70.89
2024-08-31 13:15:01,940 [foster.py] => Task 2, Epoch 32/170 => Loss 3.163, Loss_clf 0.827, Loss_fe 1.127, Loss_kd 0.804, Train_accy 72.04, Test_accy 77.80
2024-08-31 13:15:08,489 [foster.py] => Task 2, Epoch 33/170 => Loss 3.281, Loss_clf 0.887, Loss_fe 1.185, Loss_kd 0.804, Train_accy 69.84, Test_accy 76.80
2024-08-31 13:15:15,105 [foster.py] => Task 2, Epoch 34/170 => Loss 3.278, Loss_clf 0.880, Loss_fe 1.188, Loss_kd 0.805, Train_accy 70.93, Test_accy 81.93
2024-08-31 13:15:21,721 [foster.py] => Task 2, Epoch 35/170 => Loss 3.118, Loss_clf 0.819, Loss_fe 1.103, Loss_kd 0.796, Train_accy 72.09, Test_accy 78.60
2024-08-31 13:15:27,130 [foster.py] => Task 2, Epoch 36/170 => Loss 3.128, Loss_clf 0.815, Loss_fe 1.102, Loss_kd 0.806, Train_accy 72.53
2024-08-31 13:15:33,720 [foster.py] => Task 2, Epoch 37/170 => Loss 3.109, Loss_clf 0.790, Loss_fe 1.108, Loss_kd 0.806, Train_accy 73.13, Test_accy 80.20
2024-08-31 13:15:40,303 [foster.py] => Task 2, Epoch 38/170 => Loss 3.132, Loss_clf 0.806, Loss_fe 1.115, Loss_kd 0.806, Train_accy 72.67, Test_accy 69.27
2024-08-31 13:15:46,974 [foster.py] => Task 2, Epoch 39/170 => Loss 3.216, Loss_clf 0.856, Loss_fe 1.140, Loss_kd 0.812, Train_accy 71.16, Test_accy 77.20
2024-08-31 13:15:53,497 [foster.py] => Task 2, Epoch 40/170 => Loss 3.112, Loss_clf 0.794, Loss_fe 1.109, Loss_kd 0.805, Train_accy 73.38, Test_accy 74.93
2024-08-31 13:15:58,891 [foster.py] => Task 2, Epoch 41/170 => Loss 3.195, Loss_clf 0.830, Loss_fe 1.146, Loss_kd 0.811, Train_accy 71.80
2024-08-31 13:16:05,518 [foster.py] => Task 2, Epoch 42/170 => Loss 3.140, Loss_clf 0.815, Loss_fe 1.120, Loss_kd 0.802, Train_accy 72.33, Test_accy 76.53
2024-08-31 13:16:12,074 [foster.py] => Task 2, Epoch 43/170 => Loss 3.183, Loss_clf 0.826, Loss_fe 1.149, Loss_kd 0.804, Train_accy 72.13, Test_accy 81.93
2024-08-31 13:16:18,658 [foster.py] => Task 2, Epoch 44/170 => Loss 3.183, Loss_clf 0.837, Loss_fe 1.122, Loss_kd 0.815, Train_accy 71.20, Test_accy 76.13
2024-08-31 13:16:25,298 [foster.py] => Task 2, Epoch 45/170 => Loss 3.167, Loss_clf 0.828, Loss_fe 1.131, Loss_kd 0.803, Train_accy 71.44, Test_accy 80.67
2024-08-31 13:16:30,768 [foster.py] => Task 2, Epoch 46/170 => Loss 3.106, Loss_clf 0.813, Loss_fe 1.074, Loss_kd 0.811, Train_accy 72.20
2024-08-31 13:16:37,410 [foster.py] => Task 2, Epoch 47/170 => Loss 3.220, Loss_clf 0.875, Loss_fe 1.125, Loss_kd 0.812, Train_accy 70.89, Test_accy 80.47
2024-08-31 13:16:44,074 [foster.py] => Task 2, Epoch 48/170 => Loss 3.105, Loss_clf 0.805, Loss_fe 1.098, Loss_kd 0.800, Train_accy 72.67, Test_accy 82.20
2024-08-31 13:16:50,704 [foster.py] => Task 2, Epoch 49/170 => Loss 3.106, Loss_clf 0.810, Loss_fe 1.089, Loss_kd 0.804, Train_accy 72.78, Test_accy 82.13
2024-08-31 13:16:57,281 [foster.py] => Task 2, Epoch 50/170 => Loss 3.109, Loss_clf 0.810, Loss_fe 1.088, Loss_kd 0.806, Train_accy 72.44, Test_accy 77.40
2024-08-31 13:17:02,716 [foster.py] => Task 2, Epoch 51/170 => Loss 3.108, Loss_clf 0.802, Loss_fe 1.088, Loss_kd 0.810, Train_accy 72.36
2024-08-31 13:17:09,321 [foster.py] => Task 2, Epoch 52/170 => Loss 3.160, Loss_clf 0.828, Loss_fe 1.118, Loss_kd 0.808, Train_accy 71.69, Test_accy 79.47
2024-08-31 13:17:15,958 [foster.py] => Task 2, Epoch 53/170 => Loss 3.107, Loss_clf 0.823, Loss_fe 1.073, Loss_kd 0.806, Train_accy 71.93, Test_accy 80.27
2024-08-31 13:17:22,574 [foster.py] => Task 2, Epoch 54/170 => Loss 3.031, Loss_clf 0.775, Loss_fe 1.034, Loss_kd 0.812, Train_accy 73.89, Test_accy 82.33
2024-08-31 13:17:29,186 [foster.py] => Task 2, Epoch 55/170 => Loss 3.089, Loss_clf 0.803, Loss_fe 1.069, Loss_kd 0.810, Train_accy 72.91, Test_accy 80.67
2024-08-31 13:17:34,650 [foster.py] => Task 2, Epoch 56/170 => Loss 3.098, Loss_clf 0.802, Loss_fe 1.079, Loss_kd 0.810, Train_accy 73.00
2024-08-31 13:17:41,209 [foster.py] => Task 2, Epoch 57/170 => Loss 3.055, Loss_clf 0.788, Loss_fe 1.056, Loss_kd 0.806, Train_accy 73.93, Test_accy 74.13
2024-08-31 13:17:47,848 [foster.py] => Task 2, Epoch 58/170 => Loss 3.123, Loss_clf 0.802, Loss_fe 1.111, Loss_kd 0.805, Train_accy 72.51, Test_accy 74.13
2024-08-31 13:17:54,464 [foster.py] => Task 2, Epoch 59/170 => Loss 3.083, Loss_clf 0.805, Loss_fe 1.063, Loss_kd 0.808, Train_accy 73.24, Test_accy 77.47
2024-08-31 13:18:01,038 [foster.py] => Task 2, Epoch 60/170 => Loss 3.091, Loss_clf 0.826, Loss_fe 1.046, Loss_kd 0.811, Train_accy 72.38, Test_accy 76.80
2024-08-31 13:18:06,497 [foster.py] => Task 2, Epoch 61/170 => Loss 2.972, Loss_clf 0.760, Loss_fe 1.003, Loss_kd 0.805, Train_accy 74.36
2024-08-31 13:18:13,109 [foster.py] => Task 2, Epoch 62/170 => Loss 3.010, Loss_clf 0.775, Loss_fe 1.022, Loss_kd 0.807, Train_accy 74.02, Test_accy 75.80
2024-08-31 13:18:19,767 [foster.py] => Task 2, Epoch 63/170 => Loss 2.934, Loss_clf 0.752, Loss_fe 0.980, Loss_kd 0.801, Train_accy 74.73, Test_accy 80.80
2024-08-31 13:18:26,343 [foster.py] => Task 2, Epoch 64/170 => Loss 2.993, Loss_clf 0.760, Loss_fe 1.021, Loss_kd 0.807, Train_accy 74.84, Test_accy 79.87
2024-08-31 13:18:32,910 [foster.py] => Task 2, Epoch 65/170 => Loss 3.050, Loss_clf 0.791, Loss_fe 1.041, Loss_kd 0.811, Train_accy 72.22, Test_accy 80.40
2024-08-31 13:18:38,418 [foster.py] => Task 2, Epoch 66/170 => Loss 2.934, Loss_clf 0.722, Loss_fe 1.014, Loss_kd 0.798, Train_accy 75.38
2024-08-31 13:18:45,058 [foster.py] => Task 2, Epoch 67/170 => Loss 2.922, Loss_clf 0.731, Loss_fe 0.981, Loss_kd 0.805, Train_accy 75.56, Test_accy 81.13
2024-08-31 13:18:51,739 [foster.py] => Task 2, Epoch 68/170 => Loss 2.878, Loss_clf 0.716, Loss_fe 0.956, Loss_kd 0.803, Train_accy 75.49, Test_accy 83.33
2024-08-31 13:18:58,430 [foster.py] => Task 2, Epoch 69/170 => Loss 2.956, Loss_clf 0.764, Loss_fe 0.972, Loss_kd 0.812, Train_accy 75.22, Test_accy 83.33
2024-08-31 13:19:05,034 [foster.py] => Task 2, Epoch 70/170 => Loss 3.000, Loss_clf 0.768, Loss_fe 1.018, Loss_kd 0.808, Train_accy 74.36, Test_accy 81.53
2024-08-31 13:19:10,422 [foster.py] => Task 2, Epoch 71/170 => Loss 2.882, Loss_clf 0.716, Loss_fe 0.958, Loss_kd 0.804, Train_accy 76.11
2024-08-31 13:19:16,975 [foster.py] => Task 2, Epoch 72/170 => Loss 2.865, Loss_clf 0.718, Loss_fe 0.935, Loss_kd 0.807, Train_accy 75.53, Test_accy 82.60
2024-08-31 13:19:23,494 [foster.py] => Task 2, Epoch 73/170 => Loss 2.877, Loss_clf 0.727, Loss_fe 0.946, Loss_kd 0.801, Train_accy 75.36, Test_accy 81.47
2024-08-31 13:19:30,110 [foster.py] => Task 2, Epoch 74/170 => Loss 2.917, Loss_clf 0.754, Loss_fe 0.951, Loss_kd 0.807, Train_accy 74.96, Test_accy 80.60
2024-08-31 13:19:36,797 [foster.py] => Task 2, Epoch 75/170 => Loss 2.966, Loss_clf 0.748, Loss_fe 1.006, Loss_kd 0.807, Train_accy 74.33, Test_accy 80.80
2024-08-31 13:19:42,281 [foster.py] => Task 2, Epoch 76/170 => Loss 2.879, Loss_clf 0.720, Loss_fe 0.942, Loss_kd 0.810, Train_accy 76.18
2024-08-31 13:19:48,871 [foster.py] => Task 2, Epoch 77/170 => Loss 2.797, Loss_clf 0.691, Loss_fe 0.905, Loss_kd 0.799, Train_accy 76.36, Test_accy 80.93
2024-08-31 13:19:55,368 [foster.py] => Task 2, Epoch 78/170 => Loss 2.858, Loss_clf 0.718, Loss_fe 0.929, Loss_kd 0.805, Train_accy 76.27, Test_accy 83.73
2024-08-31 13:20:02,028 [foster.py] => Task 2, Epoch 79/170 => Loss 2.845, Loss_clf 0.714, Loss_fe 0.920, Loss_kd 0.806, Train_accy 75.98, Test_accy 83.93
2024-08-31 13:20:08,593 [foster.py] => Task 2, Epoch 80/170 => Loss 2.823, Loss_clf 0.706, Loss_fe 0.901, Loss_kd 0.809, Train_accy 76.60, Test_accy 84.93
2024-08-31 13:20:14,166 [foster.py] => Task 2, Epoch 81/170 => Loss 2.873, Loss_clf 0.729, Loss_fe 0.934, Loss_kd 0.805, Train_accy 75.87
2024-08-31 13:20:20,953 [foster.py] => Task 2, Epoch 82/170 => Loss 2.895, Loss_clf 0.732, Loss_fe 0.952, Loss_kd 0.806, Train_accy 75.49, Test_accy 82.07
2024-08-31 13:20:27,530 [foster.py] => Task 2, Epoch 83/170 => Loss 2.814, Loss_clf 0.708, Loss_fe 0.891, Loss_kd 0.809, Train_accy 76.36, Test_accy 83.47
2024-08-31 13:20:34,185 [foster.py] => Task 2, Epoch 84/170 => Loss 2.766, Loss_clf 0.691, Loss_fe 0.872, Loss_kd 0.801, Train_accy 76.69, Test_accy 81.27
2024-08-31 13:20:40,837 [foster.py] => Task 2, Epoch 85/170 => Loss 2.826, Loss_clf 0.724, Loss_fe 0.889, Loss_kd 0.807, Train_accy 75.71, Test_accy 81.87
2024-08-31 13:20:46,251 [foster.py] => Task 2, Epoch 86/170 => Loss 2.769, Loss_clf 0.698, Loss_fe 0.857, Loss_kd 0.808, Train_accy 76.60
2024-08-31 13:20:52,817 [foster.py] => Task 2, Epoch 87/170 => Loss 2.835, Loss_clf 0.721, Loss_fe 0.903, Loss_kd 0.806, Train_accy 76.64, Test_accy 82.33
2024-08-31 13:20:59,488 [foster.py] => Task 2, Epoch 88/170 => Loss 2.839, Loss_clf 0.721, Loss_fe 0.903, Loss_kd 0.809, Train_accy 75.84, Test_accy 82.07
2024-08-31 13:21:06,067 [foster.py] => Task 2, Epoch 89/170 => Loss 2.766, Loss_clf 0.691, Loss_fe 0.868, Loss_kd 0.803, Train_accy 77.42, Test_accy 82.67
2024-08-31 13:21:12,676 [foster.py] => Task 2, Epoch 90/170 => Loss 2.745, Loss_clf 0.675, Loss_fe 0.857, Loss_kd 0.807, Train_accy 77.18, Test_accy 80.67
2024-08-31 13:21:18,189 [foster.py] => Task 2, Epoch 91/170 => Loss 2.721, Loss_clf 0.660, Loss_fe 0.845, Loss_kd 0.809, Train_accy 77.84
2024-08-31 13:21:24,876 [foster.py] => Task 2, Epoch 92/170 => Loss 2.742, Loss_clf 0.689, Loss_fe 0.850, Loss_kd 0.800, Train_accy 77.24, Test_accy 80.13
2024-08-31 13:21:31,559 [foster.py] => Task 2, Epoch 93/170 => Loss 2.716, Loss_clf 0.656, Loss_fe 0.847, Loss_kd 0.807, Train_accy 77.82, Test_accy 82.20
2024-08-31 13:21:38,156 [foster.py] => Task 2, Epoch 94/170 => Loss 2.710, Loss_clf 0.670, Loss_fe 0.826, Loss_kd 0.807, Train_accy 77.93, Test_accy 80.73
2024-08-31 13:21:44,822 [foster.py] => Task 2, Epoch 95/170 => Loss 2.742, Loss_clf 0.679, Loss_fe 0.846, Loss_kd 0.809, Train_accy 78.02, Test_accy 82.20
2024-08-31 13:21:50,371 [foster.py] => Task 2, Epoch 96/170 => Loss 2.672, Loss_clf 0.657, Loss_fe 0.807, Loss_kd 0.804, Train_accy 78.42
2024-08-31 13:21:57,052 [foster.py] => Task 2, Epoch 97/170 => Loss 2.762, Loss_clf 0.692, Loss_fe 0.853, Loss_kd 0.810, Train_accy 75.80, Test_accy 83.20
2024-08-31 13:22:03,666 [foster.py] => Task 2, Epoch 98/170 => Loss 2.728, Loss_clf 0.674, Loss_fe 0.828, Loss_kd 0.816, Train_accy 77.56, Test_accy 83.40
2024-08-31 13:22:10,518 [foster.py] => Task 2, Epoch 99/170 => Loss 2.696, Loss_clf 0.666, Loss_fe 0.821, Loss_kd 0.805, Train_accy 77.82, Test_accy 81.73
2024-08-31 13:22:17,368 [foster.py] => Task 2, Epoch 100/170 => Loss 2.737, Loss_clf 0.694, Loss_fe 0.827, Loss_kd 0.808, Train_accy 76.71, Test_accy 84.33
2024-08-31 13:22:23,022 [foster.py] => Task 2, Epoch 101/170 => Loss 2.654, Loss_clf 0.644, Loss_fe 0.797, Loss_kd 0.807, Train_accy 78.38
2024-08-31 13:22:29,808 [foster.py] => Task 2, Epoch 102/170 => Loss 2.636, Loss_clf 0.638, Loss_fe 0.787, Loss_kd 0.806, Train_accy 78.69, Test_accy 83.80
2024-08-31 13:22:36,375 [foster.py] => Task 2, Epoch 103/170 => Loss 2.646, Loss_clf 0.648, Loss_fe 0.790, Loss_kd 0.804, Train_accy 78.60, Test_accy 84.20
2024-08-31 13:22:42,902 [foster.py] => Task 2, Epoch 104/170 => Loss 2.670, Loss_clf 0.655, Loss_fe 0.798, Loss_kd 0.810, Train_accy 78.40, Test_accy 83.27
2024-08-31 13:22:49,520 [foster.py] => Task 2, Epoch 105/170 => Loss 2.662, Loss_clf 0.649, Loss_fe 0.795, Loss_kd 0.810, Train_accy 79.24, Test_accy 84.87
2024-08-31 13:22:54,935 [foster.py] => Task 2, Epoch 106/170 => Loss 2.471, Loss_clf 0.565, Loss_fe 0.694, Loss_kd 0.807, Train_accy 81.04
2024-08-31 13:23:01,548 [foster.py] => Task 2, Epoch 107/170 => Loss 2.586, Loss_clf 0.614, Loss_fe 0.760, Loss_kd 0.806, Train_accy 79.40, Test_accy 83.00
2024-08-31 13:23:08,234 [foster.py] => Task 2, Epoch 108/170 => Loss 2.545, Loss_clf 0.601, Loss_fe 0.729, Loss_kd 0.809, Train_accy 80.89, Test_accy 84.20
2024-08-31 13:23:14,936 [foster.py] => Task 2, Epoch 109/170 => Loss 2.603, Loss_clf 0.628, Loss_fe 0.751, Loss_kd 0.814, Train_accy 79.80, Test_accy 83.33
2024-08-31 13:23:21,484 [foster.py] => Task 2, Epoch 110/170 => Loss 2.591, Loss_clf 0.632, Loss_fe 0.739, Loss_kd 0.812, Train_accy 79.44, Test_accy 81.67
2024-08-31 13:23:27,008 [foster.py] => Task 2, Epoch 111/170 => Loss 2.577, Loss_clf 0.621, Loss_fe 0.754, Loss_kd 0.800, Train_accy 79.49
2024-08-31 13:23:33,719 [foster.py] => Task 2, Epoch 112/170 => Loss 2.566, Loss_clf 0.609, Loss_fe 0.735, Loss_kd 0.812, Train_accy 80.02, Test_accy 85.20
2024-08-31 13:23:40,339 [foster.py] => Task 2, Epoch 113/170 => Loss 2.553, Loss_clf 0.601, Loss_fe 0.733, Loss_kd 0.812, Train_accy 80.09, Test_accy 85.80
2024-08-31 13:23:47,036 [foster.py] => Task 2, Epoch 114/170 => Loss 2.517, Loss_clf 0.595, Loss_fe 0.704, Loss_kd 0.810, Train_accy 80.04, Test_accy 84.13
2024-08-31 13:23:53,648 [foster.py] => Task 2, Epoch 115/170 => Loss 2.479, Loss_clf 0.587, Loss_fe 0.693, Loss_kd 0.798, Train_accy 80.53, Test_accy 84.60
2024-08-31 13:23:59,113 [foster.py] => Task 2, Epoch 116/170 => Loss 2.490, Loss_clf 0.580, Loss_fe 0.687, Loss_kd 0.814, Train_accy 80.69
2024-08-31 13:24:05,795 [foster.py] => Task 2, Epoch 117/170 => Loss 2.413, Loss_clf 0.554, Loss_fe 0.657, Loss_kd 0.800, Train_accy 81.02, Test_accy 86.27
2024-08-31 13:24:12,395 [foster.py] => Task 2, Epoch 118/170 => Loss 2.429, Loss_clf 0.556, Loss_fe 0.661, Loss_kd 0.806, Train_accy 82.02, Test_accy 83.13
2024-08-31 13:24:19,103 [foster.py] => Task 2, Epoch 119/170 => Loss 2.494, Loss_clf 0.585, Loss_fe 0.684, Loss_kd 0.815, Train_accy 80.22, Test_accy 85.00
2024-08-31 13:24:25,668 [foster.py] => Task 2, Epoch 120/170 => Loss 2.395, Loss_clf 0.552, Loss_fe 0.635, Loss_kd 0.804, Train_accy 82.71, Test_accy 85.47
2024-08-31 13:24:31,101 [foster.py] => Task 2, Epoch 121/170 => Loss 2.358, Loss_clf 0.528, Loss_fe 0.612, Loss_kd 0.811, Train_accy 82.82
2024-08-31 13:24:37,718 [foster.py] => Task 2, Epoch 122/170 => Loss 2.481, Loss_clf 0.586, Loss_fe 0.679, Loss_kd 0.809, Train_accy 81.09, Test_accy 85.27
2024-08-31 13:24:44,297 [foster.py] => Task 2, Epoch 123/170 => Loss 2.424, Loss_clf 0.568, Loss_fe 0.642, Loss_kd 0.808, Train_accy 81.98, Test_accy 85.80
2024-08-31 13:24:50,829 [foster.py] => Task 2, Epoch 124/170 => Loss 2.385, Loss_clf 0.544, Loss_fe 0.623, Loss_kd 0.810, Train_accy 81.98, Test_accy 86.47
2024-08-31 13:24:57,473 [foster.py] => Task 2, Epoch 125/170 => Loss 2.316, Loss_clf 0.511, Loss_fe 0.592, Loss_kd 0.808, Train_accy 83.18, Test_accy 84.13
2024-08-31 13:25:02,917 [foster.py] => Task 2, Epoch 126/170 => Loss 2.323, Loss_clf 0.517, Loss_fe 0.597, Loss_kd 0.804, Train_accy 83.31
2024-08-31 13:25:09,575 [foster.py] => Task 2, Epoch 127/170 => Loss 2.277, Loss_clf 0.511, Loss_fe 0.557, Loss_kd 0.805, Train_accy 83.47, Test_accy 87.33
2024-08-31 13:25:16,155 [foster.py] => Task 2, Epoch 128/170 => Loss 2.299, Loss_clf 0.510, Loss_fe 0.577, Loss_kd 0.806, Train_accy 83.00, Test_accy 85.93
2024-08-31 13:25:22,742 [foster.py] => Task 2, Epoch 129/170 => Loss 2.268, Loss_clf 0.500, Loss_fe 0.555, Loss_kd 0.807, Train_accy 83.36, Test_accy 86.20
2024-08-31 13:25:29,374 [foster.py] => Task 2, Epoch 130/170 => Loss 2.302, Loss_clf 0.516, Loss_fe 0.578, Loss_kd 0.804, Train_accy 83.60, Test_accy 85.60
2024-08-31 13:25:34,815 [foster.py] => Task 2, Epoch 131/170 => Loss 2.295, Loss_clf 0.516, Loss_fe 0.567, Loss_kd 0.807, Train_accy 83.82
2024-08-31 13:25:41,418 [foster.py] => Task 2, Epoch 132/170 => Loss 2.310, Loss_clf 0.518, Loss_fe 0.587, Loss_kd 0.802, Train_accy 82.87, Test_accy 86.93
2024-08-31 13:25:48,036 [foster.py] => Task 2, Epoch 133/170 => Loss 2.187, Loss_clf 0.476, Loss_fe 0.514, Loss_kd 0.797, Train_accy 84.22, Test_accy 85.80
2024-08-31 13:25:54,680 [foster.py] => Task 2, Epoch 134/170 => Loss 2.194, Loss_clf 0.473, Loss_fe 0.508, Loss_kd 0.808, Train_accy 84.91, Test_accy 86.07
2024-08-31 13:26:01,306 [foster.py] => Task 2, Epoch 135/170 => Loss 2.227, Loss_clf 0.486, Loss_fe 0.529, Loss_kd 0.807, Train_accy 84.96, Test_accy 86.87
2024-08-31 13:26:07,011 [foster.py] => Task 2, Epoch 136/170 => Loss 2.235, Loss_clf 0.482, Loss_fe 0.538, Loss_kd 0.808, Train_accy 84.27
2024-08-31 13:26:13,719 [foster.py] => Task 2, Epoch 137/170 => Loss 2.217, Loss_clf 0.488, Loss_fe 0.517, Loss_kd 0.807, Train_accy 84.42, Test_accy 87.00
2024-08-31 13:26:20,346 [foster.py] => Task 2, Epoch 138/170 => Loss 2.217, Loss_clf 0.482, Loss_fe 0.520, Loss_kd 0.809, Train_accy 84.96, Test_accy 86.40
2024-08-31 13:26:26,959 [foster.py] => Task 2, Epoch 139/170 => Loss 2.173, Loss_clf 0.465, Loss_fe 0.503, Loss_kd 0.802, Train_accy 84.87, Test_accy 86.80
2024-08-31 13:26:33,546 [foster.py] => Task 2, Epoch 140/170 => Loss 2.132, Loss_clf 0.444, Loss_fe 0.475, Loss_kd 0.807, Train_accy 85.58, Test_accy 86.53
2024-08-31 13:26:38,950 [foster.py] => Task 2, Epoch 141/170 => Loss 2.131, Loss_clf 0.445, Loss_fe 0.482, Loss_kd 0.802, Train_accy 85.33
2024-08-31 13:26:45,747 [foster.py] => Task 2, Epoch 142/170 => Loss 2.105, Loss_clf 0.434, Loss_fe 0.462, Loss_kd 0.804, Train_accy 86.69, Test_accy 87.80
2024-08-31 13:26:52,351 [foster.py] => Task 2, Epoch 143/170 => Loss 2.158, Loss_clf 0.466, Loss_fe 0.485, Loss_kd 0.804, Train_accy 84.82, Test_accy 85.93
2024-08-31 13:26:59,014 [foster.py] => Task 2, Epoch 144/170 => Loss 2.118, Loss_clf 0.444, Loss_fe 0.459, Loss_kd 0.809, Train_accy 85.76, Test_accy 87.60
2024-08-31 13:27:05,548 [foster.py] => Task 2, Epoch 145/170 => Loss 2.106, Loss_clf 0.433, Loss_fe 0.448, Loss_kd 0.815, Train_accy 86.44, Test_accy 87.80
2024-08-31 13:27:10,956 [foster.py] => Task 2, Epoch 146/170 => Loss 2.070, Loss_clf 0.426, Loss_fe 0.427, Loss_kd 0.810, Train_accy 86.44
2024-08-31 13:27:17,752 [foster.py] => Task 2, Epoch 147/170 => Loss 2.075, Loss_clf 0.423, Loss_fe 0.431, Loss_kd 0.813, Train_accy 86.60, Test_accy 88.07
2024-08-31 13:27:24,470 [foster.py] => Task 2, Epoch 148/170 => Loss 2.053, Loss_clf 0.409, Loss_fe 0.425, Loss_kd 0.812, Train_accy 86.89, Test_accy 87.13
2024-08-31 13:27:31,071 [foster.py] => Task 2, Epoch 149/170 => Loss 2.062, Loss_clf 0.418, Loss_fe 0.436, Loss_kd 0.804, Train_accy 86.20, Test_accy 88.33
2024-08-31 13:27:37,723 [foster.py] => Task 2, Epoch 150/170 => Loss 2.003, Loss_clf 0.395, Loss_fe 0.400, Loss_kd 0.804, Train_accy 87.51, Test_accy 87.93
2024-08-31 13:27:43,119 [foster.py] => Task 2, Epoch 151/170 => Loss 2.045, Loss_clf 0.413, Loss_fe 0.420, Loss_kd 0.807, Train_accy 86.49
2024-08-31 13:27:49,690 [foster.py] => Task 2, Epoch 152/170 => Loss 2.013, Loss_clf 0.397, Loss_fe 0.407, Loss_kd 0.804, Train_accy 87.51, Test_accy 88.27
2024-08-31 13:27:56,281 [foster.py] => Task 2, Epoch 153/170 => Loss 2.045, Loss_clf 0.418, Loss_fe 0.414, Loss_kd 0.807, Train_accy 86.82, Test_accy 88.53
2024-08-31 13:28:02,914 [foster.py] => Task 2, Epoch 154/170 => Loss 1.974, Loss_clf 0.381, Loss_fe 0.379, Loss_kd 0.808, Train_accy 88.00, Test_accy 88.40
2024-08-31 13:28:09,598 [foster.py] => Task 2, Epoch 155/170 => Loss 1.969, Loss_clf 0.373, Loss_fe 0.381, Loss_kd 0.809, Train_accy 87.80, Test_accy 88.60
2024-08-31 13:28:15,094 [foster.py] => Task 2, Epoch 156/170 => Loss 1.967, Loss_clf 0.382, Loss_fe 0.386, Loss_kd 0.798, Train_accy 88.04
2024-08-31 13:28:21,696 [foster.py] => Task 2, Epoch 157/170 => Loss 2.032, Loss_clf 0.407, Loss_fe 0.405, Loss_kd 0.812, Train_accy 87.42, Test_accy 88.20
2024-08-31 13:28:28,394 [foster.py] => Task 2, Epoch 158/170 => Loss 2.020, Loss_clf 0.400, Loss_fe 0.404, Loss_kd 0.809, Train_accy 87.29, Test_accy 88.53
2024-08-31 13:28:34,958 [foster.py] => Task 2, Epoch 159/170 => Loss 1.982, Loss_clf 0.388, Loss_fe 0.379, Loss_kd 0.809, Train_accy 87.73, Test_accy 88.73
2024-08-31 13:28:41,572 [foster.py] => Task 2, Epoch 160/170 => Loss 2.040, Loss_clf 0.411, Loss_fe 0.407, Loss_kd 0.814, Train_accy 87.42, Test_accy 88.53
2024-08-31 13:28:46,919 [foster.py] => Task 2, Epoch 161/170 => Loss 1.932, Loss_clf 0.364, Loss_fe 0.366, Loss_kd 0.800, Train_accy 88.47
2024-08-31 13:28:53,508 [foster.py] => Task 2, Epoch 162/170 => Loss 1.983, Loss_clf 0.382, Loss_fe 0.383, Loss_kd 0.811, Train_accy 87.69, Test_accy 88.60
2024-08-31 13:29:00,106 [foster.py] => Task 2, Epoch 163/170 => Loss 1.957, Loss_clf 0.377, Loss_fe 0.371, Loss_kd 0.805, Train_accy 88.16, Test_accy 88.27
2024-08-31 13:29:06,724 [foster.py] => Task 2, Epoch 164/170 => Loss 1.980, Loss_clf 0.390, Loss_fe 0.381, Loss_kd 0.805, Train_accy 88.04, Test_accy 88.47
2024-08-31 13:29:13,402 [foster.py] => Task 2, Epoch 165/170 => Loss 1.950, Loss_clf 0.376, Loss_fe 0.366, Loss_kd 0.805, Train_accy 88.36, Test_accy 88.20
2024-08-31 13:29:18,857 [foster.py] => Task 2, Epoch 166/170 => Loss 2.019, Loss_clf 0.401, Loss_fe 0.398, Loss_kd 0.812, Train_accy 87.58
2024-08-31 13:29:25,498 [foster.py] => Task 2, Epoch 167/170 => Loss 1.953, Loss_clf 0.375, Loss_fe 0.369, Loss_kd 0.805, Train_accy 88.27, Test_accy 88.47
2024-08-31 13:29:32,155 [foster.py] => Task 2, Epoch 168/170 => Loss 2.006, Loss_clf 0.394, Loss_fe 0.394, Loss_kd 0.810, Train_accy 87.89, Test_accy 88.40
2024-08-31 13:29:38,780 [foster.py] => Task 2, Epoch 169/170 => Loss 1.953, Loss_clf 0.371, Loss_fe 0.376, Loss_kd 0.803, Train_accy 88.16, Test_accy 88.20
2024-08-31 13:29:45,389 [foster.py] => Task 2, Epoch 170/170 => Loss 1.980, Loss_clf 0.386, Loss_fe 0.380, Loss_kd 0.808, Train_accy 88.29, Test_accy 88.60
2024-08-31 13:29:45,393 [foster.py] => do not weight align teacher!
2024-08-31 13:29:45,395 [foster.py] => per cls weights : [1.03197916 1.03197916 1.03197916 1.03197916 1.03197916 1.03197916
 1.03197916 1.03197916 1.03197916 1.03197916 0.93604169 0.93604169
 0.93604169 0.93604169 0.93604169]
2024-08-31 13:29:53,858 [foster.py] => SNet: Task 2, Epoch 1/130 => Loss 18.398,  Loss1 0.461, Train_accy 48.18, Test_accy 66.73
2024-08-31 13:30:01,088 [foster.py] => SNet: Task 2, Epoch 2/130 => Loss 18.290,  Loss1 0.460, Train_accy 57.71
2024-08-31 13:30:08,852 [foster.py] => SNet: Task 2, Epoch 3/130 => Loss 18.240,  Loss1 0.460, Train_accy 62.87
2024-08-31 13:30:16,446 [foster.py] => SNet: Task 2, Epoch 4/130 => Loss 18.199,  Loss1 0.460, Train_accy 64.40
2024-08-31 13:30:23,801 [foster.py] => SNet: Task 2, Epoch 5/130 => Loss 18.174,  Loss1 0.460, Train_accy 66.33
2024-08-31 13:30:32,324 [foster.py] => SNet: Task 2, Epoch 6/130 => Loss 18.171,  Loss1 0.460, Train_accy 68.62, Test_accy 75.60
2024-08-31 13:30:39,718 [foster.py] => SNet: Task 2, Epoch 7/130 => Loss 18.190,  Loss1 0.460, Train_accy 68.07
2024-08-31 13:30:47,249 [foster.py] => SNet: Task 2, Epoch 8/130 => Loss 18.166,  Loss1 0.460, Train_accy 69.89
2024-08-31 13:30:54,487 [foster.py] => SNet: Task 2, Epoch 9/130 => Loss 18.129,  Loss1 0.460, Train_accy 71.33
2024-08-31 13:31:01,735 [foster.py] => SNet: Task 2, Epoch 10/130 => Loss 18.148,  Loss1 0.460, Train_accy 71.20
2024-08-31 13:31:10,153 [foster.py] => SNet: Task 2, Epoch 11/130 => Loss 18.128,  Loss1 0.460, Train_accy 70.67, Test_accy 78.27
2024-08-31 13:31:17,471 [foster.py] => SNet: Task 2, Epoch 12/130 => Loss 18.133,  Loss1 0.460, Train_accy 71.07
2024-08-31 13:31:24,695 [foster.py] => SNet: Task 2, Epoch 13/130 => Loss 18.126,  Loss1 0.460, Train_accy 72.98
2024-08-31 13:31:32,063 [foster.py] => SNet: Task 2, Epoch 14/130 => Loss 18.124,  Loss1 0.460, Train_accy 72.24
2024-08-31 13:31:39,385 [foster.py] => SNet: Task 2, Epoch 15/130 => Loss 18.097,  Loss1 0.460, Train_accy 73.96
2024-08-31 13:31:47,635 [foster.py] => SNet: Task 2, Epoch 16/130 => Loss 18.114,  Loss1 0.460, Train_accy 73.22, Test_accy 78.67
2024-08-31 13:31:55,024 [foster.py] => SNet: Task 2, Epoch 17/130 => Loss 18.123,  Loss1 0.460, Train_accy 73.93
2024-08-31 13:32:02,513 [foster.py] => SNet: Task 2, Epoch 18/130 => Loss 18.124,  Loss1 0.460, Train_accy 74.20
2024-08-31 13:32:10,348 [foster.py] => SNet: Task 2, Epoch 19/130 => Loss 18.096,  Loss1 0.460, Train_accy 74.42
2024-08-31 13:32:17,676 [foster.py] => SNet: Task 2, Epoch 20/130 => Loss 18.075,  Loss1 0.459, Train_accy 76.47
2024-08-31 13:32:26,202 [foster.py] => SNet: Task 2, Epoch 21/130 => Loss 18.092,  Loss1 0.459, Train_accy 75.02, Test_accy 82.20
2024-08-31 13:32:33,408 [foster.py] => SNet: Task 2, Epoch 22/130 => Loss 18.115,  Loss1 0.459, Train_accy 75.82
2024-08-31 13:32:40,670 [foster.py] => SNet: Task 2, Epoch 23/130 => Loss 18.080,  Loss1 0.460, Train_accy 75.56
2024-08-31 13:32:47,953 [foster.py] => SNet: Task 2, Epoch 24/130 => Loss 18.089,  Loss1 0.459, Train_accy 76.31
2024-08-31 13:32:55,483 [foster.py] => SNet: Task 2, Epoch 25/130 => Loss 18.094,  Loss1 0.460, Train_accy 75.78
2024-08-31 13:33:03,890 [foster.py] => SNet: Task 2, Epoch 26/130 => Loss 18.097,  Loss1 0.459, Train_accy 76.76, Test_accy 81.27
2024-08-31 13:33:11,120 [foster.py] => SNet: Task 2, Epoch 27/130 => Loss 18.079,  Loss1 0.459, Train_accy 76.69
2024-08-31 13:33:19,046 [foster.py] => SNet: Task 2, Epoch 28/130 => Loss 18.071,  Loss1 0.459, Train_accy 77.09
2024-08-31 13:33:26,311 [foster.py] => SNet: Task 2, Epoch 29/130 => Loss 18.074,  Loss1 0.459, Train_accy 78.16
2024-08-31 13:33:33,518 [foster.py] => SNet: Task 2, Epoch 30/130 => Loss 18.076,  Loss1 0.459, Train_accy 77.56
2024-08-31 13:33:42,127 [foster.py] => SNet: Task 2, Epoch 31/130 => Loss 18.086,  Loss1 0.460, Train_accy 78.40, Test_accy 83.87
2024-08-31 13:33:49,784 [foster.py] => SNet: Task 2, Epoch 32/130 => Loss 18.090,  Loss1 0.459, Train_accy 77.29
2024-08-31 13:33:57,016 [foster.py] => SNet: Task 2, Epoch 33/130 => Loss 18.053,  Loss1 0.459, Train_accy 78.80
2024-08-31 13:34:04,355 [foster.py] => SNet: Task 2, Epoch 34/130 => Loss 18.058,  Loss1 0.459, Train_accy 78.44
2024-08-31 13:34:11,661 [foster.py] => SNet: Task 2, Epoch 35/130 => Loss 18.047,  Loss1 0.459, Train_accy 78.31
2024-08-31 13:34:19,968 [foster.py] => SNet: Task 2, Epoch 36/130 => Loss 18.067,  Loss1 0.459, Train_accy 78.87, Test_accy 83.67
2024-08-31 13:34:27,470 [foster.py] => SNet: Task 2, Epoch 37/130 => Loss 18.049,  Loss1 0.459, Train_accy 78.24
2024-08-31 13:34:34,762 [foster.py] => SNet: Task 2, Epoch 38/130 => Loss 18.051,  Loss1 0.459, Train_accy 79.42
2024-08-31 13:34:42,276 [foster.py] => SNet: Task 2, Epoch 39/130 => Loss 18.088,  Loss1 0.459, Train_accy 77.93
2024-08-31 13:34:49,543 [foster.py] => SNet: Task 2, Epoch 40/130 => Loss 18.068,  Loss1 0.459, Train_accy 78.02
2024-08-31 13:34:57,880 [foster.py] => SNet: Task 2, Epoch 41/130 => Loss 18.047,  Loss1 0.459, Train_accy 79.40, Test_accy 82.87
2024-08-31 13:35:05,130 [foster.py] => SNet: Task 2, Epoch 42/130 => Loss 18.064,  Loss1 0.459, Train_accy 79.13
2024-08-31 13:35:12,412 [foster.py] => SNet: Task 2, Epoch 43/130 => Loss 18.052,  Loss1 0.459, Train_accy 79.49
2024-08-31 13:35:19,672 [foster.py] => SNet: Task 2, Epoch 44/130 => Loss 18.060,  Loss1 0.459, Train_accy 80.51
2024-08-31 13:35:27,140 [foster.py] => SNet: Task 2, Epoch 45/130 => Loss 18.071,  Loss1 0.459, Train_accy 79.44
2024-08-31 13:35:35,542 [foster.py] => SNet: Task 2, Epoch 46/130 => Loss 18.049,  Loss1 0.459, Train_accy 79.78, Test_accy 84.53
2024-08-31 13:35:42,810 [foster.py] => SNet: Task 2, Epoch 47/130 => Loss 18.045,  Loss1 0.459, Train_accy 78.93
2024-08-31 13:35:50,307 [foster.py] => SNet: Task 2, Epoch 48/130 => Loss 18.032,  Loss1 0.459, Train_accy 79.89
2024-08-31 13:35:57,559 [foster.py] => SNet: Task 2, Epoch 49/130 => Loss 18.035,  Loss1 0.459, Train_accy 79.76
2024-08-31 13:36:04,968 [foster.py] => SNet: Task 2, Epoch 50/130 => Loss 18.047,  Loss1 0.459, Train_accy 79.62
2024-08-31 13:36:13,261 [foster.py] => SNet: Task 2, Epoch 51/130 => Loss 18.061,  Loss1 0.459, Train_accy 81.13, Test_accy 84.53
2024-08-31 13:36:20,756 [foster.py] => SNet: Task 2, Epoch 52/130 => Loss 18.026,  Loss1 0.459, Train_accy 80.82
2024-08-31 13:36:28,209 [foster.py] => SNet: Task 2, Epoch 53/130 => Loss 18.036,  Loss1 0.459, Train_accy 81.31
2024-08-31 13:36:35,638 [foster.py] => SNet: Task 2, Epoch 54/130 => Loss 18.028,  Loss1 0.459, Train_accy 82.04
2024-08-31 13:36:42,879 [foster.py] => SNet: Task 2, Epoch 55/130 => Loss 18.033,  Loss1 0.459, Train_accy 81.60
2024-08-31 13:36:51,154 [foster.py] => SNet: Task 2, Epoch 56/130 => Loss 18.015,  Loss1 0.459, Train_accy 81.87, Test_accy 84.00
2024-08-31 13:36:58,360 [foster.py] => SNet: Task 2, Epoch 57/130 => Loss 18.053,  Loss1 0.459, Train_accy 81.29
2024-08-31 13:37:05,664 [foster.py] => SNet: Task 2, Epoch 58/130 => Loss 18.037,  Loss1 0.459, Train_accy 81.96
2024-08-31 13:37:12,898 [foster.py] => SNet: Task 2, Epoch 59/130 => Loss 18.026,  Loss1 0.459, Train_accy 81.64
2024-08-31 13:37:20,294 [foster.py] => SNet: Task 2, Epoch 60/130 => Loss 18.016,  Loss1 0.459, Train_accy 80.49
2024-08-31 13:37:28,787 [foster.py] => SNet: Task 2, Epoch 61/130 => Loss 18.011,  Loss1 0.459, Train_accy 81.51, Test_accy 84.47
2024-08-31 13:37:36,020 [foster.py] => SNet: Task 2, Epoch 62/130 => Loss 17.999,  Loss1 0.459, Train_accy 82.36
2024-08-31 13:37:43,430 [foster.py] => SNet: Task 2, Epoch 63/130 => Loss 18.023,  Loss1 0.459, Train_accy 82.00
2024-08-31 13:37:50,902 [foster.py] => SNet: Task 2, Epoch 64/130 => Loss 18.029,  Loss1 0.459, Train_accy 82.09
2024-08-31 13:37:58,296 [foster.py] => SNet: Task 2, Epoch 65/130 => Loss 18.020,  Loss1 0.459, Train_accy 82.29
2024-08-31 13:38:06,640 [foster.py] => SNet: Task 2, Epoch 66/130 => Loss 18.028,  Loss1 0.459, Train_accy 82.96, Test_accy 85.60
2024-08-31 13:38:14,175 [foster.py] => SNet: Task 2, Epoch 67/130 => Loss 18.003,  Loss1 0.459, Train_accy 82.89
2024-08-31 13:38:21,396 [foster.py] => SNet: Task 2, Epoch 68/130 => Loss 18.025,  Loss1 0.459, Train_accy 82.49
2024-08-31 13:38:28,589 [foster.py] => SNet: Task 2, Epoch 69/130 => Loss 18.045,  Loss1 0.459, Train_accy 82.36
2024-08-31 13:38:35,985 [foster.py] => SNet: Task 2, Epoch 70/130 => Loss 18.000,  Loss1 0.459, Train_accy 83.78
2024-08-31 13:38:44,247 [foster.py] => SNet: Task 2, Epoch 71/130 => Loss 18.024,  Loss1 0.459, Train_accy 82.93, Test_accy 85.47
2024-08-31 13:38:51,616 [foster.py] => SNet: Task 2, Epoch 72/130 => Loss 18.015,  Loss1 0.459, Train_accy 82.58
2024-08-31 13:38:58,843 [foster.py] => SNet: Task 2, Epoch 73/130 => Loss 18.029,  Loss1 0.459, Train_accy 82.02
2024-08-31 13:39:06,084 [foster.py] => SNet: Task 2, Epoch 74/130 => Loss 18.024,  Loss1 0.459, Train_accy 82.44
2024-08-31 13:39:13,589 [foster.py] => SNet: Task 2, Epoch 75/130 => Loss 18.002,  Loss1 0.459, Train_accy 83.20
2024-08-31 13:39:21,902 [foster.py] => SNet: Task 2, Epoch 76/130 => Loss 18.022,  Loss1 0.459, Train_accy 83.18, Test_accy 85.87
2024-08-31 13:39:29,767 [foster.py] => SNet: Task 2, Epoch 77/130 => Loss 18.015,  Loss1 0.459, Train_accy 83.73
2024-08-31 13:39:36,956 [foster.py] => SNet: Task 2, Epoch 78/130 => Loss 18.019,  Loss1 0.459, Train_accy 83.47
2024-08-31 13:39:44,154 [foster.py] => SNet: Task 2, Epoch 79/130 => Loss 18.004,  Loss1 0.459, Train_accy 83.42
2024-08-31 13:39:51,775 [foster.py] => SNet: Task 2, Epoch 80/130 => Loss 18.016,  Loss1 0.459, Train_accy 82.78
2024-08-31 13:40:00,109 [foster.py] => SNet: Task 2, Epoch 81/130 => Loss 18.020,  Loss1 0.459, Train_accy 83.47, Test_accy 86.53
2024-08-31 13:40:07,298 [foster.py] => SNet: Task 2, Epoch 82/130 => Loss 17.999,  Loss1 0.459, Train_accy 84.11
2024-08-31 13:40:14,547 [foster.py] => SNet: Task 2, Epoch 83/130 => Loss 18.005,  Loss1 0.459, Train_accy 83.44
2024-08-31 13:40:21,906 [foster.py] => SNet: Task 2, Epoch 84/130 => Loss 17.989,  Loss1 0.459, Train_accy 83.42
2024-08-31 13:40:29,260 [foster.py] => SNet: Task 2, Epoch 85/130 => Loss 18.018,  Loss1 0.459, Train_accy 83.24
2024-08-31 13:40:37,828 [foster.py] => SNet: Task 2, Epoch 86/130 => Loss 18.010,  Loss1 0.459, Train_accy 83.80, Test_accy 85.80
2024-08-31 13:40:45,153 [foster.py] => SNet: Task 2, Epoch 87/130 => Loss 18.003,  Loss1 0.459, Train_accy 83.53
2024-08-31 13:40:52,596 [foster.py] => SNet: Task 2, Epoch 88/130 => Loss 18.010,  Loss1 0.459, Train_accy 83.87
2024-08-31 13:40:59,894 [foster.py] => SNet: Task 2, Epoch 89/130 => Loss 17.985,  Loss1 0.459, Train_accy 84.98
2024-08-31 13:41:07,103 [foster.py] => SNet: Task 2, Epoch 90/130 => Loss 17.999,  Loss1 0.459, Train_accy 84.33
2024-08-31 13:41:15,337 [foster.py] => SNet: Task 2, Epoch 91/130 => Loss 18.016,  Loss1 0.459, Train_accy 83.53, Test_accy 86.47
2024-08-31 13:41:22,824 [foster.py] => SNet: Task 2, Epoch 92/130 => Loss 17.995,  Loss1 0.459, Train_accy 84.02
2024-08-31 13:41:30,562 [foster.py] => SNet: Task 2, Epoch 93/130 => Loss 17.990,  Loss1 0.459, Train_accy 84.51
2024-08-31 13:41:37,847 [foster.py] => SNet: Task 2, Epoch 94/130 => Loss 18.005,  Loss1 0.459, Train_accy 83.87
2024-08-31 13:41:45,045 [foster.py] => SNet: Task 2, Epoch 95/130 => Loss 17.998,  Loss1 0.459, Train_accy 84.04
2024-08-31 13:41:53,331 [foster.py] => SNet: Task 2, Epoch 96/130 => Loss 17.986,  Loss1 0.459, Train_accy 83.93, Test_accy 86.40
2024-08-31 13:42:00,810 [foster.py] => SNet: Task 2, Epoch 97/130 => Loss 18.022,  Loss1 0.459, Train_accy 84.69
2024-08-31 13:42:08,249 [foster.py] => SNet: Task 2, Epoch 98/130 => Loss 18.013,  Loss1 0.459, Train_accy 85.36
2024-08-31 13:42:15,532 [foster.py] => SNet: Task 2, Epoch 99/130 => Loss 18.009,  Loss1 0.459, Train_accy 84.47
2024-08-31 13:42:22,891 [foster.py] => SNet: Task 2, Epoch 100/130 => Loss 17.998,  Loss1 0.459, Train_accy 83.51
2024-08-31 13:42:31,684 [foster.py] => SNet: Task 2, Epoch 101/130 => Loss 17.987,  Loss1 0.459, Train_accy 85.22, Test_accy 86.07
2024-08-31 13:42:39,253 [foster.py] => SNet: Task 2, Epoch 102/130 => Loss 18.017,  Loss1 0.459, Train_accy 84.78
2024-08-31 13:42:46,441 [foster.py] => SNet: Task 2, Epoch 103/130 => Loss 18.004,  Loss1 0.459, Train_accy 83.80
2024-08-31 13:42:53,901 [foster.py] => SNet: Task 2, Epoch 104/130 => Loss 18.015,  Loss1 0.459, Train_accy 83.89
2024-08-31 13:43:01,494 [foster.py] => SNet: Task 2, Epoch 105/130 => Loss 18.005,  Loss1 0.459, Train_accy 84.51
2024-08-31 13:43:10,073 [foster.py] => SNet: Task 2, Epoch 106/130 => Loss 17.996,  Loss1 0.459, Train_accy 84.36, Test_accy 85.93
2024-08-31 13:43:17,565 [foster.py] => SNet: Task 2, Epoch 107/130 => Loss 17.995,  Loss1 0.459, Train_accy 84.87
2024-08-31 13:43:25,047 [foster.py] => SNet: Task 2, Epoch 108/130 => Loss 18.019,  Loss1 0.459, Train_accy 84.44
2024-08-31 13:43:32,311 [foster.py] => SNet: Task 2, Epoch 109/130 => Loss 18.019,  Loss1 0.459, Train_accy 84.16
2024-08-31 13:43:39,895 [foster.py] => SNet: Task 2, Epoch 110/130 => Loss 18.005,  Loss1 0.459, Train_accy 84.84
2024-08-31 13:43:48,357 [foster.py] => SNet: Task 2, Epoch 111/130 => Loss 18.009,  Loss1 0.459, Train_accy 84.44, Test_accy 86.27
2024-08-31 13:43:55,752 [foster.py] => SNet: Task 2, Epoch 112/130 => Loss 18.000,  Loss1 0.459, Train_accy 84.76
2024-08-31 13:44:03,372 [foster.py] => SNet: Task 2, Epoch 113/130 => Loss 17.987,  Loss1 0.459, Train_accy 84.31
2024-08-31 13:44:10,614 [foster.py] => SNet: Task 2, Epoch 114/130 => Loss 18.003,  Loss1 0.459, Train_accy 84.44
2024-08-31 13:44:17,930 [foster.py] => SNet: Task 2, Epoch 115/130 => Loss 18.005,  Loss1 0.459, Train_accy 84.93
2024-08-31 13:44:26,295 [foster.py] => SNet: Task 2, Epoch 116/130 => Loss 18.013,  Loss1 0.459, Train_accy 84.98, Test_accy 85.53
2024-08-31 13:44:33,798 [foster.py] => SNet: Task 2, Epoch 117/130 => Loss 17.990,  Loss1 0.459, Train_accy 84.96
2024-08-31 13:44:41,288 [foster.py] => SNet: Task 2, Epoch 118/130 => Loss 18.011,  Loss1 0.459, Train_accy 85.51
2024-08-31 13:44:48,718 [foster.py] => SNet: Task 2, Epoch 119/130 => Loss 17.972,  Loss1 0.459, Train_accy 85.38
2024-08-31 13:44:55,978 [foster.py] => SNet: Task 2, Epoch 120/130 => Loss 17.997,  Loss1 0.459, Train_accy 84.64
2024-08-31 13:45:04,333 [foster.py] => SNet: Task 2, Epoch 121/130 => Loss 17.980,  Loss1 0.459, Train_accy 85.20, Test_accy 86.27
2024-08-31 13:45:11,650 [foster.py] => SNet: Task 2, Epoch 122/130 => Loss 17.972,  Loss1 0.459, Train_accy 84.84
2024-08-31 13:45:18,932 [foster.py] => SNet: Task 2, Epoch 123/130 => Loss 18.011,  Loss1 0.459, Train_accy 84.71
2024-08-31 13:45:26,388 [foster.py] => SNet: Task 2, Epoch 124/130 => Loss 17.992,  Loss1 0.459, Train_accy 84.33
2024-08-31 13:45:33,880 [foster.py] => SNet: Task 2, Epoch 125/130 => Loss 18.009,  Loss1 0.459, Train_accy 84.44
2024-08-31 13:45:42,102 [foster.py] => SNet: Task 2, Epoch 126/130 => Loss 18.003,  Loss1 0.459, Train_accy 84.11, Test_accy 86.00
2024-08-31 13:45:49,328 [foster.py] => SNet: Task 2, Epoch 127/130 => Loss 17.992,  Loss1 0.459, Train_accy 85.02
2024-08-31 13:45:56,805 [foster.py] => SNet: Task 2, Epoch 128/130 => Loss 17.990,  Loss1 0.459, Train_accy 84.49
2024-08-31 13:46:04,267 [foster.py] => SNet: Task 2, Epoch 129/130 => Loss 17.977,  Loss1 0.459, Train_accy 84.38
2024-08-31 13:46:11,743 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 18.010,  Loss1 0.459, Train_accy 84.78
2024-08-31 13:46:11,743 [foster.py] => do not weight align student!
2024-08-31 13:46:12,770 [foster.py] => darknet eval: 
2024-08-31 13:46:12,770 [foster.py] => CNN top1 curve: 86.93
2024-08-31 13:46:12,770 [foster.py] => CNN top5 curve: 99.07
2024-08-31 13:46:12,770 [foster.py] => CNN top1 平均值: 86.93
2024-08-31 13:46:12,776 [foster.py] => timees : 2074.487058401108
2024-08-31 13:46:12,778 [base.py] => Reducing exemplars...(133 per classes)
2024-08-31 13:46:17,153 [base.py] => Constructing exemplars...(133 per classes)
2024-08-31 13:46:25,185 [foster.py] => Exemplar size: 1995
2024-08-31 13:46:25,185 [trainer.py] => CNN: {'total': 88.6, '00-09': 89.2, '10-19': 87.4, 'old': 89.2, 'new': 87.4}
2024-08-31 13:46:25,185 [trainer.py] => NME: {'total': 88.67, '00-09': 89.7, '10-19': 86.6, 'old': 89.7, 'new': 86.6}
2024-08-31 13:46:25,185 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6]
2024-08-31 13:46:25,185 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13]
2024-08-31 13:46:25,185 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67]
2024-08-31 13:46:25,185 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87]

2024-08-31 13:46:25,186 [trainer.py] => CNN top1 平均值: 93.77
2024-08-31 13:46:25,188 [trainer.py] => All params: 1286108
2024-08-31 13:46:25,190 [trainer.py] => Trainable params: 644184
2024-08-31 13:46:25,253 [foster.py] => Learning on 15-20
2024-08-31 13:46:25,256 [foster.py] => All params: 1287403
2024-08-31 13:46:25,258 [foster.py] => Trainable params: 645154
2024-08-31 13:46:25,299 [foster.py] => per cls weights : [1.02338434 1.02338434 1.02338434 1.02338434 1.02338434 1.02338434
 1.02338434 1.02338434 1.02338434 1.02338434 1.02338434 1.02338434
 1.02338434 1.02338434 1.02338434 0.92984697 0.92984697 0.92984697
 0.92984697 0.92984697]
2024-08-31 13:46:30,825 [foster.py] => Task 3, Epoch 1/170 => Loss 4.747, Loss_clf 1.520, Loss_fe 1.739, Loss_kd 1.114, Train_accy 53.19
2024-08-31 13:46:37,628 [foster.py] => Task 3, Epoch 2/170 => Loss 4.380, Loss_clf 1.219, Loss_fe 1.665, Loss_kd 1.120, Train_accy 58.11, Test_accy 71.90
2024-08-31 13:46:44,339 [foster.py] => Task 3, Epoch 3/170 => Loss 4.092, Loss_clf 1.132, Loss_fe 1.493, Loss_kd 1.098, Train_accy 62.20, Test_accy 73.60
2024-08-31 13:46:51,059 [foster.py] => Task 3, Epoch 4/170 => Loss 4.010, Loss_clf 1.117, Loss_fe 1.411, Loss_kd 1.110, Train_accy 62.85, Test_accy 68.05
2024-08-31 13:46:57,949 [foster.py] => Task 3, Epoch 5/170 => Loss 4.075, Loss_clf 1.101, Loss_fe 1.492, Loss_kd 1.110, Train_accy 63.31, Test_accy 74.35
2024-08-31 13:47:03,578 [foster.py] => Task 3, Epoch 6/170 => Loss 3.988, Loss_clf 1.087, Loss_fe 1.417, Loss_kd 1.111, Train_accy 64.16
2024-08-31 13:47:10,414 [foster.py] => Task 3, Epoch 7/170 => Loss 4.014, Loss_clf 1.091, Loss_fe 1.441, Loss_kd 1.109, Train_accy 63.11, Test_accy 70.25
2024-08-31 13:47:17,172 [foster.py] => Task 3, Epoch 8/170 => Loss 3.940, Loss_clf 1.077, Loss_fe 1.390, Loss_kd 1.102, Train_accy 64.74, Test_accy 72.60
2024-08-31 13:47:23,928 [foster.py] => Task 3, Epoch 9/170 => Loss 3.819, Loss_clf 1.036, Loss_fe 1.314, Loss_kd 1.100, Train_accy 66.14, Test_accy 74.60
2024-08-31 13:47:30,636 [foster.py] => Task 3, Epoch 10/170 => Loss 3.820, Loss_clf 1.033, Loss_fe 1.313, Loss_kd 1.103, Train_accy 66.10, Test_accy 68.95
2024-08-31 13:47:36,028 [foster.py] => Task 3, Epoch 11/170 => Loss 3.902, Loss_clf 1.069, Loss_fe 1.355, Loss_kd 1.106, Train_accy 65.01
2024-08-31 13:47:42,768 [foster.py] => Task 3, Epoch 12/170 => Loss 3.895, Loss_clf 1.055, Loss_fe 1.348, Loss_kd 1.117, Train_accy 66.07, Test_accy 70.85
2024-08-31 13:47:49,485 [foster.py] => Task 3, Epoch 13/170 => Loss 3.845, Loss_clf 1.037, Loss_fe 1.332, Loss_kd 1.105, Train_accy 66.03, Test_accy 74.25
2024-08-31 13:47:56,215 [foster.py] => Task 3, Epoch 14/170 => Loss 3.813, Loss_clf 1.027, Loss_fe 1.308, Loss_kd 1.106, Train_accy 66.45, Test_accy 70.30
2024-08-31 13:48:02,962 [foster.py] => Task 3, Epoch 15/170 => Loss 3.829, Loss_clf 1.027, Loss_fe 1.318, Loss_kd 1.111, Train_accy 66.23, Test_accy 74.35
2024-08-31 13:48:08,384 [foster.py] => Task 3, Epoch 16/170 => Loss 3.798, Loss_clf 1.010, Loss_fe 1.293, Loss_kd 1.119, Train_accy 66.43
2024-08-31 13:48:15,207 [foster.py] => Task 3, Epoch 17/170 => Loss 3.842, Loss_clf 1.026, Loss_fe 1.323, Loss_kd 1.117, Train_accy 66.34, Test_accy 75.55
2024-08-31 13:48:21,979 [foster.py] => Task 3, Epoch 18/170 => Loss 3.771, Loss_clf 0.989, Loss_fe 1.290, Loss_kd 1.117, Train_accy 67.50, Test_accy 75.60
2024-08-31 13:48:28,761 [foster.py] => Task 3, Epoch 19/170 => Loss 3.801, Loss_clf 0.998, Loss_fe 1.329, Loss_kd 1.104, Train_accy 66.47, Test_accy 71.55
2024-08-31 13:48:35,536 [foster.py] => Task 3, Epoch 20/170 => Loss 3.659, Loss_clf 0.947, Loss_fe 1.256, Loss_kd 1.090, Train_accy 68.48, Test_accy 71.05
2024-08-31 13:48:40,972 [foster.py] => Task 3, Epoch 21/170 => Loss 3.709, Loss_clf 0.990, Loss_fe 1.238, Loss_kd 1.109, Train_accy 66.96
2024-08-31 13:48:47,701 [foster.py] => Task 3, Epoch 22/170 => Loss 3.749, Loss_clf 1.008, Loss_fe 1.270, Loss_kd 1.101, Train_accy 67.68, Test_accy 66.10
2024-08-31 13:48:54,512 [foster.py] => Task 3, Epoch 23/170 => Loss 3.789, Loss_clf 1.050, Loss_fe 1.257, Loss_kd 1.110, Train_accy 66.07, Test_accy 71.55
2024-08-31 13:49:01,257 [foster.py] => Task 3, Epoch 24/170 => Loss 3.754, Loss_clf 0.994, Loss_fe 1.276, Loss_kd 1.111, Train_accy 67.61, Test_accy 71.15
2024-08-31 13:49:07,951 [foster.py] => Task 3, Epoch 25/170 => Loss 3.722, Loss_clf 0.991, Loss_fe 1.247, Loss_kd 1.111, Train_accy 66.83, Test_accy 75.20
2024-08-31 13:49:13,359 [foster.py] => Task 3, Epoch 26/170 => Loss 3.697, Loss_clf 0.984, Loss_fe 1.230, Loss_kd 1.110, Train_accy 68.34
2024-08-31 13:49:20,009 [foster.py] => Task 3, Epoch 27/170 => Loss 3.780, Loss_clf 0.998, Loss_fe 1.306, Loss_kd 1.105, Train_accy 68.43, Test_accy 76.30
2024-08-31 13:49:26,838 [foster.py] => Task 3, Epoch 28/170 => Loss 3.822, Loss_clf 1.016, Loss_fe 1.317, Loss_kd 1.115, Train_accy 65.74, Test_accy 76.75
2024-08-31 13:49:33,607 [foster.py] => Task 3, Epoch 29/170 => Loss 3.616, Loss_clf 0.949, Loss_fe 1.186, Loss_kd 1.108, Train_accy 69.52, Test_accy 70.60
2024-08-31 13:49:40,377 [foster.py] => Task 3, Epoch 30/170 => Loss 3.658, Loss_clf 0.967, Loss_fe 1.226, Loss_kd 1.097, Train_accy 67.50, Test_accy 75.25
2024-08-31 13:49:45,859 [foster.py] => Task 3, Epoch 31/170 => Loss 3.666, Loss_clf 0.944, Loss_fe 1.226, Loss_kd 1.120, Train_accy 69.05
2024-08-31 13:49:52,624 [foster.py] => Task 3, Epoch 32/170 => Loss 3.730, Loss_clf 0.999, Loss_fe 1.247, Loss_kd 1.112, Train_accy 67.92, Test_accy 75.85
2024-08-31 13:49:59,412 [foster.py] => Task 3, Epoch 33/170 => Loss 3.642, Loss_clf 0.962, Loss_fe 1.207, Loss_kd 1.103, Train_accy 68.12, Test_accy 76.15
2024-08-31 13:50:06,179 [foster.py] => Task 3, Epoch 34/170 => Loss 3.641, Loss_clf 0.948, Loss_fe 1.206, Loss_kd 1.113, Train_accy 69.01, Test_accy 75.90
2024-08-31 13:50:13,026 [foster.py] => Task 3, Epoch 35/170 => Loss 3.660, Loss_clf 0.959, Loss_fe 1.208, Loss_kd 1.118, Train_accy 68.97, Test_accy 76.60
2024-08-31 13:50:18,575 [foster.py] => Task 3, Epoch 36/170 => Loss 3.719, Loss_clf 0.971, Loss_fe 1.259, Loss_kd 1.114, Train_accy 68.21
2024-08-31 13:50:25,264 [foster.py] => Task 3, Epoch 37/170 => Loss 3.658, Loss_clf 0.984, Loss_fe 1.185, Loss_kd 1.115, Train_accy 68.63, Test_accy 75.20
2024-08-31 13:50:32,031 [foster.py] => Task 3, Epoch 38/170 => Loss 3.581, Loss_clf 0.943, Loss_fe 1.162, Loss_kd 1.105, Train_accy 69.70, Test_accy 65.50
2024-08-31 13:50:38,709 [foster.py] => Task 3, Epoch 39/170 => Loss 3.721, Loss_clf 0.990, Loss_fe 1.250, Loss_kd 1.108, Train_accy 67.25, Test_accy 76.05
2024-08-31 13:50:45,451 [foster.py] => Task 3, Epoch 40/170 => Loss 3.597, Loss_clf 0.934, Loss_fe 1.173, Loss_kd 1.115, Train_accy 69.41, Test_accy 73.70
2024-08-31 13:50:50,909 [foster.py] => Task 3, Epoch 41/170 => Loss 3.557, Loss_clf 0.922, Loss_fe 1.155, Loss_kd 1.108, Train_accy 70.59
2024-08-31 13:50:57,683 [foster.py] => Task 3, Epoch 42/170 => Loss 3.619, Loss_clf 0.958, Loss_fe 1.178, Loss_kd 1.110, Train_accy 69.28, Test_accy 68.25
2024-08-31 13:51:04,539 [foster.py] => Task 3, Epoch 43/170 => Loss 3.781, Loss_clf 1.024, Loss_fe 1.264, Loss_kd 1.118, Train_accy 67.59, Test_accy 74.35
2024-08-31 13:51:11,247 [foster.py] => Task 3, Epoch 44/170 => Loss 3.645, Loss_clf 0.959, Loss_fe 1.216, Loss_kd 1.101, Train_accy 68.48, Test_accy 77.80
2024-08-31 13:51:17,990 [foster.py] => Task 3, Epoch 45/170 => Loss 3.483, Loss_clf 0.868, Loss_fe 1.155, Loss_kd 1.093, Train_accy 71.77, Test_accy 77.50
2024-08-31 13:51:23,487 [foster.py] => Task 3, Epoch 46/170 => Loss 3.534, Loss_clf 0.930, Loss_fe 1.127, Loss_kd 1.106, Train_accy 70.37
2024-08-31 13:51:30,317 [foster.py] => Task 3, Epoch 47/170 => Loss 3.661, Loss_clf 0.995, Loss_fe 1.178, Loss_kd 1.114, Train_accy 68.03, Test_accy 72.70
2024-08-31 13:51:37,098 [foster.py] => Task 3, Epoch 48/170 => Loss 3.560, Loss_clf 0.932, Loss_fe 1.163, Loss_kd 1.097, Train_accy 70.75, Test_accy 77.35
2024-08-31 13:51:43,980 [foster.py] => Task 3, Epoch 49/170 => Loss 3.666, Loss_clf 0.974, Loss_fe 1.209, Loss_kd 1.110, Train_accy 67.63, Test_accy 78.70
2024-08-31 13:51:50,789 [foster.py] => Task 3, Epoch 50/170 => Loss 3.592, Loss_clf 0.958, Loss_fe 1.149, Loss_kd 1.112, Train_accy 69.90, Test_accy 77.20
2024-08-31 13:51:56,268 [foster.py] => Task 3, Epoch 51/170 => Loss 3.569, Loss_clf 0.923, Loss_fe 1.154, Loss_kd 1.117, Train_accy 70.28
2024-08-31 13:52:03,175 [foster.py] => Task 3, Epoch 52/170 => Loss 3.525, Loss_clf 0.899, Loss_fe 1.142, Loss_kd 1.110, Train_accy 70.81, Test_accy 75.85
2024-08-31 13:52:10,082 [foster.py] => Task 3, Epoch 53/170 => Loss 3.529, Loss_clf 0.922, Loss_fe 1.131, Loss_kd 1.105, Train_accy 70.95, Test_accy 77.15
2024-08-31 13:52:16,839 [foster.py] => Task 3, Epoch 54/170 => Loss 3.621, Loss_clf 0.956, Loss_fe 1.170, Loss_kd 1.119, Train_accy 68.70, Test_accy 74.25
2024-08-31 13:52:23,707 [foster.py] => Task 3, Epoch 55/170 => Loss 3.494, Loss_clf 0.911, Loss_fe 1.112, Loss_kd 1.101, Train_accy 71.23, Test_accy 76.70
2024-08-31 13:52:29,214 [foster.py] => Task 3, Epoch 56/170 => Loss 3.464, Loss_clf 0.895, Loss_fe 1.103, Loss_kd 1.098, Train_accy 70.28
2024-08-31 13:52:36,017 [foster.py] => Task 3, Epoch 57/170 => Loss 3.597, Loss_clf 0.963, Loss_fe 1.141, Loss_kd 1.118, Train_accy 69.28, Test_accy 78.85
2024-08-31 13:52:42,821 [foster.py] => Task 3, Epoch 58/170 => Loss 3.497, Loss_clf 0.887, Loss_fe 1.120, Loss_kd 1.115, Train_accy 72.06, Test_accy 72.50
2024-08-31 13:52:49,523 [foster.py] => Task 3, Epoch 59/170 => Loss 3.468, Loss_clf 0.897, Loss_fe 1.095, Loss_kd 1.105, Train_accy 71.79, Test_accy 79.80
2024-08-31 13:52:56,319 [foster.py] => Task 3, Epoch 60/170 => Loss 3.492, Loss_clf 0.906, Loss_fe 1.120, Loss_kd 1.098, Train_accy 71.06, Test_accy 75.95
2024-08-31 13:53:01,854 [foster.py] => Task 3, Epoch 61/170 => Loss 3.503, Loss_clf 0.917, Loss_fe 1.099, Loss_kd 1.113, Train_accy 70.72
2024-08-31 13:53:08,665 [foster.py] => Task 3, Epoch 62/170 => Loss 3.533, Loss_clf 0.933, Loss_fe 1.102, Loss_kd 1.122, Train_accy 71.19, Test_accy 74.30
2024-08-31 13:53:15,444 [foster.py] => Task 3, Epoch 63/170 => Loss 3.599, Loss_clf 0.953, Loss_fe 1.156, Loss_kd 1.115, Train_accy 69.57, Test_accy 77.75
2024-08-31 13:53:22,365 [foster.py] => Task 3, Epoch 64/170 => Loss 3.474, Loss_clf 0.892, Loss_fe 1.098, Loss_kd 1.110, Train_accy 71.01, Test_accy 73.30
2024-08-31 13:53:29,079 [foster.py] => Task 3, Epoch 65/170 => Loss 3.481, Loss_clf 0.882, Loss_fe 1.110, Loss_kd 1.114, Train_accy 71.35, Test_accy 76.20
2024-08-31 13:53:34,565 [foster.py] => Task 3, Epoch 66/170 => Loss 3.491, Loss_clf 0.900, Loss_fe 1.117, Loss_kd 1.103, Train_accy 71.01
2024-08-31 13:53:41,433 [foster.py] => Task 3, Epoch 67/170 => Loss 3.461, Loss_clf 0.898, Loss_fe 1.081, Loss_kd 1.109, Train_accy 71.26, Test_accy 77.10
2024-08-31 13:53:48,220 [foster.py] => Task 3, Epoch 68/170 => Loss 3.414, Loss_clf 0.863, Loss_fe 1.073, Loss_kd 1.107, Train_accy 71.86, Test_accy 77.30
2024-08-31 13:53:54,900 [foster.py] => Task 3, Epoch 69/170 => Loss 3.376, Loss_clf 0.860, Loss_fe 1.038, Loss_kd 1.106, Train_accy 73.17, Test_accy 74.20
2024-08-31 13:54:01,720 [foster.py] => Task 3, Epoch 70/170 => Loss 3.373, Loss_clf 0.834, Loss_fe 1.064, Loss_kd 1.104, Train_accy 72.70, Test_accy 79.70
2024-08-31 13:54:07,187 [foster.py] => Task 3, Epoch 71/170 => Loss 3.366, Loss_clf 0.847, Loss_fe 1.045, Loss_kd 1.103, Train_accy 72.84
2024-08-31 13:54:13,940 [foster.py] => Task 3, Epoch 72/170 => Loss 3.352, Loss_clf 0.845, Loss_fe 1.020, Loss_kd 1.113, Train_accy 73.06, Test_accy 78.85
2024-08-31 13:54:20,667 [foster.py] => Task 3, Epoch 73/170 => Loss 3.440, Loss_clf 0.870, Loss_fe 1.095, Loss_kd 1.104, Train_accy 72.28, Test_accy 77.15
2024-08-31 13:54:27,460 [foster.py] => Task 3, Epoch 74/170 => Loss 3.393, Loss_clf 0.855, Loss_fe 1.065, Loss_kd 1.103, Train_accy 72.24, Test_accy 75.15
2024-08-31 13:54:34,216 [foster.py] => Task 3, Epoch 75/170 => Loss 3.457, Loss_clf 0.879, Loss_fe 1.090, Loss_kd 1.113, Train_accy 72.04, Test_accy 78.40
2024-08-31 13:54:39,677 [foster.py] => Task 3, Epoch 76/170 => Loss 3.323, Loss_clf 0.835, Loss_fe 1.018, Loss_kd 1.101, Train_accy 73.41
2024-08-31 13:54:46,441 [foster.py] => Task 3, Epoch 77/170 => Loss 3.416, Loss_clf 0.899, Loss_fe 1.045, Loss_kd 1.102, Train_accy 71.90, Test_accy 69.80
2024-08-31 13:54:53,097 [foster.py] => Task 3, Epoch 78/170 => Loss 3.290, Loss_clf 0.830, Loss_fe 0.986, Loss_kd 1.103, Train_accy 73.24, Test_accy 78.50
2024-08-31 13:54:59,869 [foster.py] => Task 3, Epoch 79/170 => Loss 3.280, Loss_clf 0.829, Loss_fe 0.969, Loss_kd 1.110, Train_accy 73.62, Test_accy 77.80
2024-08-31 13:55:06,520 [foster.py] => Task 3, Epoch 80/170 => Loss 3.312, Loss_clf 0.840, Loss_fe 0.991, Loss_kd 1.108, Train_accy 72.97, Test_accy 78.05
2024-08-31 13:55:11,957 [foster.py] => Task 3, Epoch 81/170 => Loss 3.347, Loss_clf 0.858, Loss_fe 0.997, Loss_kd 1.117, Train_accy 72.53
2024-08-31 13:55:18,714 [foster.py] => Task 3, Epoch 82/170 => Loss 3.321, Loss_clf 0.847, Loss_fe 0.990, Loss_kd 1.112, Train_accy 72.77, Test_accy 78.80
2024-08-31 13:55:25,571 [foster.py] => Task 3, Epoch 83/170 => Loss 3.200, Loss_clf 0.785, Loss_fe 0.944, Loss_kd 1.101, Train_accy 74.59, Test_accy 79.15
2024-08-31 13:55:32,518 [foster.py] => Task 3, Epoch 84/170 => Loss 3.235, Loss_clf 0.789, Loss_fe 0.968, Loss_kd 1.107, Train_accy 74.44, Test_accy 77.30
2024-08-31 13:55:39,280 [foster.py] => Task 3, Epoch 85/170 => Loss 3.337, Loss_clf 0.852, Loss_fe 1.009, Loss_kd 1.105, Train_accy 73.15, Test_accy 75.05
2024-08-31 13:55:44,738 [foster.py] => Task 3, Epoch 86/170 => Loss 3.322, Loss_clf 0.853, Loss_fe 0.992, Loss_kd 1.105, Train_accy 73.15
2024-08-31 13:55:51,670 [foster.py] => Task 3, Epoch 87/170 => Loss 3.186, Loss_clf 0.802, Loss_fe 0.919, Loss_kd 1.096, Train_accy 74.97, Test_accy 78.10
2024-08-31 13:55:58,534 [foster.py] => Task 3, Epoch 88/170 => Loss 3.250, Loss_clf 0.823, Loss_fe 0.933, Loss_kd 1.118, Train_accy 74.10, Test_accy 77.25
2024-08-31 13:56:05,400 [foster.py] => Task 3, Epoch 89/170 => Loss 3.174, Loss_clf 0.768, Loss_fe 0.931, Loss_kd 1.104, Train_accy 76.40, Test_accy 78.30
2024-08-31 13:56:12,094 [foster.py] => Task 3, Epoch 90/170 => Loss 3.302, Loss_clf 0.826, Loss_fe 0.993, Loss_kd 1.111, Train_accy 73.75, Test_accy 79.20
2024-08-31 13:56:17,607 [foster.py] => Task 3, Epoch 91/170 => Loss 3.234, Loss_clf 0.807, Loss_fe 0.931, Loss_kd 1.120, Train_accy 74.44
2024-08-31 13:56:24,371 [foster.py] => Task 3, Epoch 92/170 => Loss 3.170, Loss_clf 0.769, Loss_fe 0.927, Loss_kd 1.103, Train_accy 74.99, Test_accy 79.15
2024-08-31 13:56:31,266 [foster.py] => Task 3, Epoch 93/170 => Loss 3.178, Loss_clf 0.793, Loss_fe 0.904, Loss_kd 1.109, Train_accy 75.19, Test_accy 73.70
2024-08-31 13:56:38,019 [foster.py] => Task 3, Epoch 94/170 => Loss 3.271, Loss_clf 0.814, Loss_fe 0.972, Loss_kd 1.112, Train_accy 73.79, Test_accy 80.80
2024-08-31 13:56:44,838 [foster.py] => Task 3, Epoch 95/170 => Loss 3.196, Loss_clf 0.784, Loss_fe 0.924, Loss_kd 1.114, Train_accy 75.22, Test_accy 78.75
2024-08-31 13:56:50,346 [foster.py] => Task 3, Epoch 96/170 => Loss 3.215, Loss_clf 0.786, Loss_fe 0.937, Loss_kd 1.117, Train_accy 75.22
2024-08-31 13:56:57,091 [foster.py] => Task 3, Epoch 97/170 => Loss 3.132, Loss_clf 0.762, Loss_fe 0.896, Loss_kd 1.104, Train_accy 76.28, Test_accy 80.10
2024-08-31 13:57:04,076 [foster.py] => Task 3, Epoch 98/170 => Loss 3.120, Loss_clf 0.749, Loss_fe 0.897, Loss_kd 1.103, Train_accy 75.62, Test_accy 79.20
2024-08-31 13:57:10,926 [foster.py] => Task 3, Epoch 99/170 => Loss 3.169, Loss_clf 0.785, Loss_fe 0.899, Loss_kd 1.112, Train_accy 75.26, Test_accy 78.40
2024-08-31 13:57:17,621 [foster.py] => Task 3, Epoch 100/170 => Loss 3.098, Loss_clf 0.744, Loss_fe 0.877, Loss_kd 1.106, Train_accy 76.02, Test_accy 77.30
2024-08-31 13:57:23,063 [foster.py] => Task 3, Epoch 101/170 => Loss 3.165, Loss_clf 0.782, Loss_fe 0.907, Loss_kd 1.105, Train_accy 75.84
2024-08-31 13:57:29,902 [foster.py] => Task 3, Epoch 102/170 => Loss 3.157, Loss_clf 0.777, Loss_fe 0.904, Loss_kd 1.105, Train_accy 75.17, Test_accy 76.60
2024-08-31 13:57:36,817 [foster.py] => Task 3, Epoch 103/170 => Loss 3.110, Loss_clf 0.758, Loss_fe 0.876, Loss_kd 1.105, Train_accy 76.42, Test_accy 78.00
2024-08-31 13:57:43,663 [foster.py] => Task 3, Epoch 104/170 => Loss 3.080, Loss_clf 0.741, Loss_fe 0.856, Loss_kd 1.110, Train_accy 76.44, Test_accy 80.30
2024-08-31 13:57:50,381 [foster.py] => Task 3, Epoch 105/170 => Loss 3.015, Loss_clf 0.709, Loss_fe 0.826, Loss_kd 1.108, Train_accy 77.66, Test_accy 75.05
2024-08-31 13:57:55,870 [foster.py] => Task 3, Epoch 106/170 => Loss 3.069, Loss_clf 0.747, Loss_fe 0.843, Loss_kd 1.108, Train_accy 77.24
2024-08-31 13:58:02,641 [foster.py] => Task 3, Epoch 107/170 => Loss 3.008, Loss_clf 0.704, Loss_fe 0.839, Loss_kd 1.097, Train_accy 77.33, Test_accy 80.05
2024-08-31 13:58:09,384 [foster.py] => Task 3, Epoch 108/170 => Loss 3.010, Loss_clf 0.707, Loss_fe 0.825, Loss_kd 1.106, Train_accy 77.75, Test_accy 79.00
2024-08-31 13:58:16,189 [foster.py] => Task 3, Epoch 109/170 => Loss 3.070, Loss_clf 0.753, Loss_fe 0.830, Loss_kd 1.113, Train_accy 76.33, Test_accy 76.80
2024-08-31 13:58:22,940 [foster.py] => Task 3, Epoch 110/170 => Loss 3.003, Loss_clf 0.711, Loss_fe 0.811, Loss_kd 1.109, Train_accy 77.78, Test_accy 80.60
2024-08-31 13:58:28,339 [foster.py] => Task 3, Epoch 111/170 => Loss 2.993, Loss_clf 0.702, Loss_fe 0.807, Loss_kd 1.111, Train_accy 78.06
2024-08-31 13:58:35,121 [foster.py] => Task 3, Epoch 112/170 => Loss 2.958, Loss_clf 0.678, Loss_fe 0.800, Loss_kd 1.108, Train_accy 78.15, Test_accy 79.85
2024-08-31 13:58:41,963 [foster.py] => Task 3, Epoch 113/170 => Loss 2.906, Loss_clf 0.666, Loss_fe 0.770, Loss_kd 1.101, Train_accy 79.22, Test_accy 80.20
2024-08-31 13:58:48,893 [foster.py] => Task 3, Epoch 114/170 => Loss 2.912, Loss_clf 0.663, Loss_fe 0.767, Loss_kd 1.109, Train_accy 78.60, Test_accy 81.35
2024-08-31 13:58:55,879 [foster.py] => Task 3, Epoch 115/170 => Loss 2.928, Loss_clf 0.670, Loss_fe 0.774, Loss_kd 1.111, Train_accy 79.76, Test_accy 81.80
2024-08-31 13:59:01,488 [foster.py] => Task 3, Epoch 116/170 => Loss 2.955, Loss_clf 0.698, Loss_fe 0.779, Loss_kd 1.106, Train_accy 78.44
2024-08-31 13:59:08,197 [foster.py] => Task 3, Epoch 117/170 => Loss 2.938, Loss_clf 0.691, Loss_fe 0.769, Loss_kd 1.107, Train_accy 77.71, Test_accy 80.90
2024-08-31 13:59:15,040 [foster.py] => Task 3, Epoch 118/170 => Loss 2.854, Loss_clf 0.651, Loss_fe 0.721, Loss_kd 1.110, Train_accy 79.67, Test_accy 79.30
2024-08-31 13:59:21,921 [foster.py] => Task 3, Epoch 119/170 => Loss 2.921, Loss_clf 0.681, Loss_fe 0.768, Loss_kd 1.102, Train_accy 78.67, Test_accy 80.45
2024-08-31 13:59:28,690 [foster.py] => Task 3, Epoch 120/170 => Loss 2.868, Loss_clf 0.663, Loss_fe 0.733, Loss_kd 1.102, Train_accy 79.76, Test_accy 81.95
2024-08-31 13:59:34,135 [foster.py] => Task 3, Epoch 121/170 => Loss 2.903, Loss_clf 0.673, Loss_fe 0.756, Loss_kd 1.104, Train_accy 79.02
2024-08-31 13:59:40,918 [foster.py] => Task 3, Epoch 122/170 => Loss 2.836, Loss_clf 0.656, Loss_fe 0.707, Loss_kd 1.103, Train_accy 79.49, Test_accy 81.80
2024-08-31 13:59:47,708 [foster.py] => Task 3, Epoch 123/170 => Loss 2.784, Loss_clf 0.626, Loss_fe 0.684, Loss_kd 1.103, Train_accy 80.58, Test_accy 80.95
2024-08-31 13:59:54,466 [foster.py] => Task 3, Epoch 124/170 => Loss 2.739, Loss_clf 0.612, Loss_fe 0.660, Loss_kd 1.098, Train_accy 81.11, Test_accy 79.20
2024-08-31 14:00:01,185 [foster.py] => Task 3, Epoch 125/170 => Loss 2.784, Loss_clf 0.620, Loss_fe 0.676, Loss_kd 1.114, Train_accy 80.27, Test_accy 82.15
2024-08-31 14:00:06,627 [foster.py] => Task 3, Epoch 126/170 => Loss 2.804, Loss_clf 0.633, Loss_fe 0.696, Loss_kd 1.105, Train_accy 79.93
2024-08-31 14:00:13,409 [foster.py] => Task 3, Epoch 127/170 => Loss 2.772, Loss_clf 0.620, Loss_fe 0.677, Loss_kd 1.104, Train_accy 80.76, Test_accy 82.80
2024-08-31 14:00:20,272 [foster.py] => Task 3, Epoch 128/170 => Loss 2.750, Loss_clf 0.622, Loss_fe 0.658, Loss_kd 1.100, Train_accy 80.85, Test_accy 82.30
2024-08-31 14:00:27,178 [foster.py] => Task 3, Epoch 129/170 => Loss 2.738, Loss_clf 0.606, Loss_fe 0.654, Loss_kd 1.107, Train_accy 80.29, Test_accy 81.00
2024-08-31 14:00:34,000 [foster.py] => Task 3, Epoch 130/170 => Loss 2.738, Loss_clf 0.605, Loss_fe 0.642, Loss_kd 1.116, Train_accy 81.25, Test_accy 81.60
2024-08-31 14:00:39,478 [foster.py] => Task 3, Epoch 131/170 => Loss 2.742, Loss_clf 0.616, Loss_fe 0.654, Loss_kd 1.102, Train_accy 81.05
2024-08-31 14:00:46,331 [foster.py] => Task 3, Epoch 132/170 => Loss 2.704, Loss_clf 0.597, Loss_fe 0.645, Loss_kd 1.095, Train_accy 81.09, Test_accy 81.55
2024-08-31 14:00:53,088 [foster.py] => Task 3, Epoch 133/170 => Loss 2.677, Loss_clf 0.573, Loss_fe 0.623, Loss_kd 1.109, Train_accy 82.69, Test_accy 81.95
2024-08-31 14:00:59,858 [foster.py] => Task 3, Epoch 134/170 => Loss 2.715, Loss_clf 0.603, Loss_fe 0.633, Loss_kd 1.108, Train_accy 81.36, Test_accy 81.95
2024-08-31 14:01:06,548 [foster.py] => Task 3, Epoch 135/170 => Loss 2.643, Loss_clf 0.568, Loss_fe 0.597, Loss_kd 1.107, Train_accy 81.87, Test_accy 82.30
2024-08-31 14:01:11,976 [foster.py] => Task 3, Epoch 136/170 => Loss 2.623, Loss_clf 0.561, Loss_fe 0.590, Loss_kd 1.102, Train_accy 82.96
2024-08-31 14:01:18,804 [foster.py] => Task 3, Epoch 137/170 => Loss 2.612, Loss_clf 0.564, Loss_fe 0.589, Loss_kd 1.092, Train_accy 81.96, Test_accy 80.80
2024-08-31 14:01:25,500 [foster.py] => Task 3, Epoch 138/170 => Loss 2.610, Loss_clf 0.561, Loss_fe 0.571, Loss_kd 1.107, Train_accy 82.91, Test_accy 82.30
2024-08-31 14:01:32,236 [foster.py] => Task 3, Epoch 139/170 => Loss 2.637, Loss_clf 0.564, Loss_fe 0.587, Loss_kd 1.113, Train_accy 82.18, Test_accy 82.15
2024-08-31 14:01:39,039 [foster.py] => Task 3, Epoch 140/170 => Loss 2.600, Loss_clf 0.556, Loss_fe 0.575, Loss_kd 1.100, Train_accy 82.67, Test_accy 82.30
2024-08-31 14:01:44,493 [foster.py] => Task 3, Epoch 141/170 => Loss 2.560, Loss_clf 0.535, Loss_fe 0.548, Loss_kd 1.106, Train_accy 83.34
2024-08-31 14:01:51,409 [foster.py] => Task 3, Epoch 142/170 => Loss 2.504, Loss_clf 0.518, Loss_fe 0.516, Loss_kd 1.100, Train_accy 84.09, Test_accy 83.05
2024-08-31 14:01:58,203 [foster.py] => Task 3, Epoch 143/170 => Loss 2.509, Loss_clf 0.521, Loss_fe 0.515, Loss_kd 1.103, Train_accy 83.76, Test_accy 82.00
2024-08-31 14:02:04,963 [foster.py] => Task 3, Epoch 144/170 => Loss 2.479, Loss_clf 0.504, Loss_fe 0.507, Loss_kd 1.099, Train_accy 84.40, Test_accy 82.80
2024-08-31 14:02:11,709 [foster.py] => Task 3, Epoch 145/170 => Loss 2.516, Loss_clf 0.519, Loss_fe 0.514, Loss_kd 1.110, Train_accy 83.83, Test_accy 82.95
2024-08-31 14:02:17,207 [foster.py] => Task 3, Epoch 146/170 => Loss 2.587, Loss_clf 0.549, Loss_fe 0.531, Loss_kd 1.128, Train_accy 83.34
2024-08-31 14:02:24,099 [foster.py] => Task 3, Epoch 147/170 => Loss 2.534, Loss_clf 0.534, Loss_fe 0.530, Loss_kd 1.101, Train_accy 84.00, Test_accy 82.90
2024-08-31 14:02:30,865 [foster.py] => Task 3, Epoch 148/170 => Loss 2.482, Loss_clf 0.505, Loss_fe 0.504, Loss_kd 1.103, Train_accy 83.83, Test_accy 82.60
2024-08-31 14:02:37,635 [foster.py] => Task 3, Epoch 149/170 => Loss 2.509, Loss_clf 0.513, Loss_fe 0.518, Loss_kd 1.107, Train_accy 84.12, Test_accy 82.70
2024-08-31 14:02:44,471 [foster.py] => Task 3, Epoch 150/170 => Loss 2.448, Loss_clf 0.489, Loss_fe 0.480, Loss_kd 1.108, Train_accy 84.78, Test_accy 83.55
2024-08-31 14:02:49,911 [foster.py] => Task 3, Epoch 151/170 => Loss 2.539, Loss_clf 0.547, Loss_fe 0.514, Loss_kd 1.106, Train_accy 83.40
2024-08-31 14:02:56,740 [foster.py] => Task 3, Epoch 152/170 => Loss 2.449, Loss_clf 0.494, Loss_fe 0.484, Loss_kd 1.102, Train_accy 84.98, Test_accy 83.55
2024-08-31 14:03:03,569 [foster.py] => Task 3, Epoch 153/170 => Loss 2.445, Loss_clf 0.491, Loss_fe 0.478, Loss_kd 1.105, Train_accy 85.56, Test_accy 83.20
2024-08-31 14:03:10,305 [foster.py] => Task 3, Epoch 154/170 => Loss 2.408, Loss_clf 0.474, Loss_fe 0.463, Loss_kd 1.101, Train_accy 85.54, Test_accy 83.50
2024-08-31 14:03:17,095 [foster.py] => Task 3, Epoch 155/170 => Loss 2.450, Loss_clf 0.502, Loss_fe 0.473, Loss_kd 1.105, Train_accy 84.43, Test_accy 83.60
2024-08-31 14:03:22,621 [foster.py] => Task 3, Epoch 156/170 => Loss 2.489, Loss_clf 0.509, Loss_fe 0.498, Loss_kd 1.110, Train_accy 84.32
2024-08-31 14:03:29,389 [foster.py] => Task 3, Epoch 157/170 => Loss 2.435, Loss_clf 0.494, Loss_fe 0.457, Loss_kd 1.111, Train_accy 84.63, Test_accy 83.10
2024-08-31 14:03:36,080 [foster.py] => Task 3, Epoch 158/170 => Loss 2.384, Loss_clf 0.474, Loss_fe 0.448, Loss_kd 1.094, Train_accy 85.92, Test_accy 82.95
2024-08-31 14:03:42,780 [foster.py] => Task 3, Epoch 159/170 => Loss 2.415, Loss_clf 0.482, Loss_fe 0.451, Loss_kd 1.109, Train_accy 85.54, Test_accy 83.20
2024-08-31 14:03:49,594 [foster.py] => Task 3, Epoch 160/170 => Loss 2.425, Loss_clf 0.484, Loss_fe 0.454, Loss_kd 1.113, Train_accy 85.05, Test_accy 83.05
2024-08-31 14:03:55,021 [foster.py] => Task 3, Epoch 161/170 => Loss 2.461, Loss_clf 0.501, Loss_fe 0.480, Loss_kd 1.108, Train_accy 84.63
2024-08-31 14:04:01,768 [foster.py] => Task 3, Epoch 162/170 => Loss 2.375, Loss_clf 0.457, Loss_fe 0.442, Loss_kd 1.105, Train_accy 85.85, Test_accy 83.50
2024-08-31 14:04:08,587 [foster.py] => Task 3, Epoch 163/170 => Loss 2.385, Loss_clf 0.469, Loss_fe 0.445, Loss_kd 1.101, Train_accy 85.74, Test_accy 83.35
2024-08-31 14:04:15,438 [foster.py] => Task 3, Epoch 164/170 => Loss 2.378, Loss_clf 0.456, Loss_fe 0.447, Loss_kd 1.105, Train_accy 86.23, Test_accy 83.45
2024-08-31 14:04:22,187 [foster.py] => Task 3, Epoch 165/170 => Loss 2.341, Loss_clf 0.446, Loss_fe 0.431, Loss_kd 1.096, Train_accy 86.94, Test_accy 83.55
2024-08-31 14:04:27,578 [foster.py] => Task 3, Epoch 166/170 => Loss 2.343, Loss_clf 0.448, Loss_fe 0.414, Loss_kd 1.109, Train_accy 85.96
2024-08-31 14:04:34,297 [foster.py] => Task 3, Epoch 167/170 => Loss 2.378, Loss_clf 0.470, Loss_fe 0.433, Loss_kd 1.105, Train_accy 86.05, Test_accy 83.15
2024-08-31 14:04:41,043 [foster.py] => Task 3, Epoch 168/170 => Loss 2.384, Loss_clf 0.477, Loss_fe 0.432, Loss_kd 1.104, Train_accy 85.78, Test_accy 83.40
2024-08-31 14:04:47,930 [foster.py] => Task 3, Epoch 169/170 => Loss 2.389, Loss_clf 0.477, Loss_fe 0.429, Loss_kd 1.110, Train_accy 85.34, Test_accy 83.25
2024-08-31 14:04:54,632 [foster.py] => Task 3, Epoch 170/170 => Loss 2.412, Loss_clf 0.486, Loss_fe 0.442, Loss_kd 1.111, Train_accy 84.78, Test_accy 83.40
2024-08-31 14:04:54,633 [foster.py] => do not weight align teacher!
2024-08-31 14:04:54,634 [foster.py] => per cls weights : [1.02741408 1.02741408 1.02741408 1.02741408 1.02741408 1.02741408
 1.02741408 1.02741408 1.02741408 1.02741408 1.02741408 1.02741408
 1.02741408 1.02741408 1.02741408 0.91775777 0.91775777 0.91775777
 0.91775777 0.91775777]
2024-08-31 14:05:03,453 [foster.py] => SNet: Task 3, Epoch 1/130 => Loss 20.437,  Loss1 0.520, Train_accy 45.61, Test_accy 65.95
2024-08-31 14:05:11,116 [foster.py] => SNet: Task 3, Epoch 2/130 => Loss 20.285,  Loss1 0.520, Train_accy 58.69
2024-08-31 14:05:18,353 [foster.py] => SNet: Task 3, Epoch 3/130 => Loss 20.242,  Loss1 0.521, Train_accy 62.58
2024-08-31 14:05:26,097 [foster.py] => SNet: Task 3, Epoch 4/130 => Loss 20.266,  Loss1 0.520, Train_accy 62.96
2024-08-31 14:05:33,618 [foster.py] => SNet: Task 3, Epoch 5/130 => Loss 20.230,  Loss1 0.520, Train_accy 64.45
2024-08-31 14:05:42,321 [foster.py] => SNet: Task 3, Epoch 6/130 => Loss 20.201,  Loss1 0.521, Train_accy 64.16, Test_accy 72.45
2024-08-31 14:05:49,901 [foster.py] => SNet: Task 3, Epoch 7/130 => Loss 20.195,  Loss1 0.521, Train_accy 67.03
2024-08-31 14:05:57,347 [foster.py] => SNet: Task 3, Epoch 8/130 => Loss 20.199,  Loss1 0.521, Train_accy 65.78
2024-08-31 14:06:04,651 [foster.py] => SNet: Task 3, Epoch 9/130 => Loss 20.180,  Loss1 0.521, Train_accy 67.90
2024-08-31 14:06:11,871 [foster.py] => SNet: Task 3, Epoch 10/130 => Loss 20.162,  Loss1 0.521, Train_accy 69.99
2024-08-31 14:06:20,251 [foster.py] => SNet: Task 3, Epoch 11/130 => Loss 20.137,  Loss1 0.522, Train_accy 69.88, Test_accy 68.80
2024-08-31 14:06:27,476 [foster.py] => SNet: Task 3, Epoch 12/130 => Loss 20.162,  Loss1 0.521, Train_accy 69.86
2024-08-31 14:06:34,858 [foster.py] => SNet: Task 3, Epoch 13/130 => Loss 20.173,  Loss1 0.521, Train_accy 69.83
2024-08-31 14:06:42,177 [foster.py] => SNet: Task 3, Epoch 14/130 => Loss 20.181,  Loss1 0.521, Train_accy 69.28
2024-08-31 14:06:49,442 [foster.py] => SNet: Task 3, Epoch 15/130 => Loss 20.171,  Loss1 0.522, Train_accy 71.79
2024-08-31 14:06:58,115 [foster.py] => SNet: Task 3, Epoch 16/130 => Loss 20.161,  Loss1 0.521, Train_accy 72.61, Test_accy 73.05
2024-08-31 14:07:05,354 [foster.py] => SNet: Task 3, Epoch 17/130 => Loss 20.179,  Loss1 0.521, Train_accy 70.23
2024-08-31 14:07:12,838 [foster.py] => SNet: Task 3, Epoch 18/130 => Loss 20.172,  Loss1 0.521, Train_accy 71.06
2024-08-31 14:07:20,405 [foster.py] => SNet: Task 3, Epoch 19/130 => Loss 20.139,  Loss1 0.522, Train_accy 73.41
2024-08-31 14:07:27,819 [foster.py] => SNet: Task 3, Epoch 20/130 => Loss 20.136,  Loss1 0.522, Train_accy 72.21
2024-08-31 14:07:36,412 [foster.py] => SNet: Task 3, Epoch 21/130 => Loss 20.128,  Loss1 0.522, Train_accy 73.93, Test_accy 78.25
2024-08-31 14:07:43,789 [foster.py] => SNet: Task 3, Epoch 22/130 => Loss 20.119,  Loss1 0.522, Train_accy 74.33
2024-08-31 14:07:51,221 [foster.py] => SNet: Task 3, Epoch 23/130 => Loss 20.134,  Loss1 0.522, Train_accy 74.33
2024-08-31 14:07:58,461 [foster.py] => SNet: Task 3, Epoch 24/130 => Loss 20.099,  Loss1 0.522, Train_accy 74.64
2024-08-31 14:08:05,747 [foster.py] => SNet: Task 3, Epoch 25/130 => Loss 20.113,  Loss1 0.522, Train_accy 74.71
2024-08-31 14:08:14,374 [foster.py] => SNet: Task 3, Epoch 26/130 => Loss 20.152,  Loss1 0.522, Train_accy 74.02, Test_accy 78.00
2024-08-31 14:08:21,695 [foster.py] => SNet: Task 3, Epoch 27/130 => Loss 20.139,  Loss1 0.522, Train_accy 74.06
2024-08-31 14:08:29,243 [foster.py] => SNet: Task 3, Epoch 28/130 => Loss 20.106,  Loss1 0.522, Train_accy 74.46
2024-08-31 14:08:36,625 [foster.py] => SNet: Task 3, Epoch 29/130 => Loss 20.130,  Loss1 0.522, Train_accy 75.42
2024-08-31 14:08:43,867 [foster.py] => SNet: Task 3, Epoch 30/130 => Loss 20.110,  Loss1 0.522, Train_accy 74.77
2024-08-31 14:08:52,609 [foster.py] => SNet: Task 3, Epoch 31/130 => Loss 20.134,  Loss1 0.522, Train_accy 75.26, Test_accy 78.10
2024-08-31 14:09:00,228 [foster.py] => SNet: Task 3, Epoch 32/130 => Loss 20.116,  Loss1 0.522, Train_accy 76.26
2024-08-31 14:09:07,508 [foster.py] => SNet: Task 3, Epoch 33/130 => Loss 20.113,  Loss1 0.522, Train_accy 77.09
2024-08-31 14:09:15,002 [foster.py] => SNet: Task 3, Epoch 34/130 => Loss 20.107,  Loss1 0.522, Train_accy 75.77
2024-08-31 14:09:22,270 [foster.py] => SNet: Task 3, Epoch 35/130 => Loss 20.110,  Loss1 0.522, Train_accy 77.04
2024-08-31 14:09:30,891 [foster.py] => SNet: Task 3, Epoch 36/130 => Loss 20.125,  Loss1 0.523, Train_accy 76.66, Test_accy 76.50
2024-08-31 14:09:38,410 [foster.py] => SNet: Task 3, Epoch 37/130 => Loss 20.131,  Loss1 0.522, Train_accy 75.13
2024-08-31 14:09:45,883 [foster.py] => SNet: Task 3, Epoch 38/130 => Loss 20.099,  Loss1 0.522, Train_accy 76.40
2024-08-31 14:09:53,145 [foster.py] => SNet: Task 3, Epoch 39/130 => Loss 20.106,  Loss1 0.522, Train_accy 76.71
2024-08-31 14:10:00,449 [foster.py] => SNet: Task 3, Epoch 40/130 => Loss 20.098,  Loss1 0.522, Train_accy 77.31
2024-08-31 14:10:09,006 [foster.py] => SNet: Task 3, Epoch 41/130 => Loss 20.082,  Loss1 0.523, Train_accy 77.73, Test_accy 79.05
2024-08-31 14:10:16,356 [foster.py] => SNet: Task 3, Epoch 42/130 => Loss 20.087,  Loss1 0.522, Train_accy 77.29
2024-08-31 14:10:23,828 [foster.py] => SNet: Task 3, Epoch 43/130 => Loss 20.105,  Loss1 0.522, Train_accy 77.89
2024-08-31 14:10:31,181 [foster.py] => SNet: Task 3, Epoch 44/130 => Loss 20.076,  Loss1 0.522, Train_accy 76.64
2024-08-31 14:10:38,548 [foster.py] => SNet: Task 3, Epoch 45/130 => Loss 20.096,  Loss1 0.522, Train_accy 77.53
2024-08-31 14:10:46,888 [foster.py] => SNet: Task 3, Epoch 46/130 => Loss 20.083,  Loss1 0.523, Train_accy 77.37, Test_accy 78.40
2024-08-31 14:10:54,211 [foster.py] => SNet: Task 3, Epoch 47/130 => Loss 20.101,  Loss1 0.522, Train_accy 78.22
2024-08-31 14:11:01,835 [foster.py] => SNet: Task 3, Epoch 48/130 => Loss 20.093,  Loss1 0.522, Train_accy 77.89
2024-08-31 14:11:09,422 [foster.py] => SNet: Task 3, Epoch 49/130 => Loss 20.106,  Loss1 0.522, Train_accy 78.11
2024-08-31 14:11:16,664 [foster.py] => SNet: Task 3, Epoch 50/130 => Loss 20.077,  Loss1 0.522, Train_accy 78.55
2024-08-31 14:11:25,068 [foster.py] => SNet: Task 3, Epoch 51/130 => Loss 20.069,  Loss1 0.522, Train_accy 79.13, Test_accy 80.10
2024-08-31 14:11:32,612 [foster.py] => SNet: Task 3, Epoch 52/130 => Loss 20.091,  Loss1 0.523, Train_accy 77.49
2024-08-31 14:11:40,125 [foster.py] => SNet: Task 3, Epoch 53/130 => Loss 20.085,  Loss1 0.522, Train_accy 78.91
2024-08-31 14:11:47,457 [foster.py] => SNet: Task 3, Epoch 54/130 => Loss 20.079,  Loss1 0.522, Train_accy 78.49
2024-08-31 14:11:55,286 [foster.py] => SNet: Task 3, Epoch 55/130 => Loss 20.068,  Loss1 0.522, Train_accy 79.15
2024-08-31 14:12:03,915 [foster.py] => SNet: Task 3, Epoch 56/130 => Loss 20.063,  Loss1 0.523, Train_accy 80.11, Test_accy 80.30
2024-08-31 14:12:11,426 [foster.py] => SNet: Task 3, Epoch 57/130 => Loss 20.057,  Loss1 0.522, Train_accy 79.56
2024-08-31 14:12:19,182 [foster.py] => SNet: Task 3, Epoch 58/130 => Loss 20.071,  Loss1 0.522, Train_accy 79.15
2024-08-31 14:12:26,838 [foster.py] => SNet: Task 3, Epoch 59/130 => Loss 20.080,  Loss1 0.522, Train_accy 78.98
2024-08-31 14:12:34,077 [foster.py] => SNet: Task 3, Epoch 60/130 => Loss 20.064,  Loss1 0.522, Train_accy 80.38
2024-08-31 14:12:42,438 [foster.py] => SNet: Task 3, Epoch 61/130 => Loss 20.069,  Loss1 0.522, Train_accy 79.51, Test_accy 79.80
2024-08-31 14:12:49,735 [foster.py] => SNet: Task 3, Epoch 62/130 => Loss 20.078,  Loss1 0.522, Train_accy 79.31
2024-08-31 14:12:57,045 [foster.py] => SNet: Task 3, Epoch 63/130 => Loss 20.057,  Loss1 0.523, Train_accy 81.25
2024-08-31 14:13:04,624 [foster.py] => SNet: Task 3, Epoch 64/130 => Loss 20.061,  Loss1 0.522, Train_accy 79.29
2024-08-31 14:13:12,102 [foster.py] => SNet: Task 3, Epoch 65/130 => Loss 20.061,  Loss1 0.523, Train_accy 79.69
2024-08-31 14:13:20,501 [foster.py] => SNet: Task 3, Epoch 66/130 => Loss 20.067,  Loss1 0.522, Train_accy 80.53, Test_accy 80.60
2024-08-31 14:13:27,982 [foster.py] => SNet: Task 3, Epoch 67/130 => Loss 20.066,  Loss1 0.523, Train_accy 80.29
2024-08-31 14:13:35,289 [foster.py] => SNet: Task 3, Epoch 68/130 => Loss 20.077,  Loss1 0.522, Train_accy 79.56
2024-08-31 14:13:42,765 [foster.py] => SNet: Task 3, Epoch 69/130 => Loss 20.036,  Loss1 0.523, Train_accy 80.58
2024-08-31 14:13:50,091 [foster.py] => SNet: Task 3, Epoch 70/130 => Loss 20.057,  Loss1 0.523, Train_accy 79.91
2024-08-31 14:13:58,415 [foster.py] => SNet: Task 3, Epoch 71/130 => Loss 20.053,  Loss1 0.523, Train_accy 80.82, Test_accy 81.40
2024-08-31 14:14:05,763 [foster.py] => SNet: Task 3, Epoch 72/130 => Loss 20.079,  Loss1 0.523, Train_accy 80.36
2024-08-31 14:14:13,213 [foster.py] => SNet: Task 3, Epoch 73/130 => Loss 20.056,  Loss1 0.522, Train_accy 80.96
2024-08-31 14:14:20,508 [foster.py] => SNet: Task 3, Epoch 74/130 => Loss 20.066,  Loss1 0.522, Train_accy 80.38
2024-08-31 14:14:28,016 [foster.py] => SNet: Task 3, Epoch 75/130 => Loss 20.080,  Loss1 0.523, Train_accy 80.78
2024-08-31 14:14:36,860 [foster.py] => SNet: Task 3, Epoch 76/130 => Loss 20.043,  Loss1 0.522, Train_accy 80.93, Test_accy 81.35
2024-08-31 14:14:44,157 [foster.py] => SNet: Task 3, Epoch 77/130 => Loss 20.072,  Loss1 0.523, Train_accy 80.96
2024-08-31 14:14:51,639 [foster.py] => SNet: Task 3, Epoch 78/130 => Loss 20.032,  Loss1 0.523, Train_accy 81.25
2024-08-31 14:14:58,991 [foster.py] => SNet: Task 3, Epoch 79/130 => Loss 20.056,  Loss1 0.523, Train_accy 80.44
2024-08-31 14:15:06,260 [foster.py] => SNet: Task 3, Epoch 80/130 => Loss 20.026,  Loss1 0.523, Train_accy 81.54
2024-08-31 14:15:14,775 [foster.py] => SNet: Task 3, Epoch 81/130 => Loss 20.057,  Loss1 0.523, Train_accy 81.20, Test_accy 81.20
2024-08-31 14:15:22,089 [foster.py] => SNet: Task 3, Epoch 82/130 => Loss 20.063,  Loss1 0.523, Train_accy 81.27
2024-08-31 14:15:29,339 [foster.py] => SNet: Task 3, Epoch 83/130 => Loss 20.067,  Loss1 0.523, Train_accy 81.07
2024-08-31 14:15:36,848 [foster.py] => SNet: Task 3, Epoch 84/130 => Loss 20.059,  Loss1 0.523, Train_accy 82.16
2024-08-31 14:15:44,397 [foster.py] => SNet: Task 3, Epoch 85/130 => Loss 20.062,  Loss1 0.522, Train_accy 81.98
2024-08-31 14:15:52,954 [foster.py] => SNet: Task 3, Epoch 86/130 => Loss 20.058,  Loss1 0.522, Train_accy 81.91, Test_accy 81.95
2024-08-31 14:16:00,553 [foster.py] => SNet: Task 3, Epoch 87/130 => Loss 20.067,  Loss1 0.523, Train_accy 81.27
2024-08-31 14:16:07,878 [foster.py] => SNet: Task 3, Epoch 88/130 => Loss 20.055,  Loss1 0.523, Train_accy 81.45
2024-08-31 14:16:15,505 [foster.py] => SNet: Task 3, Epoch 89/130 => Loss 20.053,  Loss1 0.523, Train_accy 81.40
2024-08-31 14:16:22,838 [foster.py] => SNet: Task 3, Epoch 90/130 => Loss 20.068,  Loss1 0.523, Train_accy 80.78
2024-08-31 14:16:31,285 [foster.py] => SNet: Task 3, Epoch 91/130 => Loss 20.043,  Loss1 0.522, Train_accy 83.20, Test_accy 81.65
2024-08-31 14:16:39,060 [foster.py] => SNet: Task 3, Epoch 92/130 => Loss 20.049,  Loss1 0.523, Train_accy 81.51
2024-08-31 14:16:46,529 [foster.py] => SNet: Task 3, Epoch 93/130 => Loss 20.068,  Loss1 0.523, Train_accy 81.25
2024-08-31 14:16:53,867 [foster.py] => SNet: Task 3, Epoch 94/130 => Loss 20.044,  Loss1 0.522, Train_accy 81.31
2024-08-31 14:17:01,173 [foster.py] => SNet: Task 3, Epoch 95/130 => Loss 20.034,  Loss1 0.523, Train_accy 81.89
2024-08-31 14:17:09,597 [foster.py] => SNet: Task 3, Epoch 96/130 => Loss 20.046,  Loss1 0.523, Train_accy 81.76, Test_accy 81.90
2024-08-31 14:17:16,937 [foster.py] => SNet: Task 3, Epoch 97/130 => Loss 20.041,  Loss1 0.523, Train_accy 82.18
2024-08-31 14:17:24,751 [foster.py] => SNet: Task 3, Epoch 98/130 => Loss 20.067,  Loss1 0.523, Train_accy 82.49
2024-08-31 14:17:32,336 [foster.py] => SNet: Task 3, Epoch 99/130 => Loss 20.050,  Loss1 0.523, Train_accy 82.67
2024-08-31 14:17:39,973 [foster.py] => SNet: Task 3, Epoch 100/130 => Loss 20.056,  Loss1 0.523, Train_accy 81.58
2024-08-31 14:17:48,589 [foster.py] => SNet: Task 3, Epoch 101/130 => Loss 20.033,  Loss1 0.523, Train_accy 82.63, Test_accy 81.40
2024-08-31 14:17:55,918 [foster.py] => SNet: Task 3, Epoch 102/130 => Loss 20.067,  Loss1 0.523, Train_accy 81.22
2024-08-31 14:18:03,193 [foster.py] => SNet: Task 3, Epoch 103/130 => Loss 20.090,  Loss1 0.522, Train_accy 81.65
2024-08-31 14:18:10,488 [foster.py] => SNet: Task 3, Epoch 104/130 => Loss 20.091,  Loss1 0.523, Train_accy 81.29
2024-08-31 14:18:18,037 [foster.py] => SNet: Task 3, Epoch 105/130 => Loss 20.051,  Loss1 0.523, Train_accy 82.67
2024-08-31 14:18:26,493 [foster.py] => SNet: Task 3, Epoch 106/130 => Loss 20.039,  Loss1 0.523, Train_accy 82.42, Test_accy 82.30
2024-08-31 14:18:33,697 [foster.py] => SNet: Task 3, Epoch 107/130 => Loss 20.043,  Loss1 0.523, Train_accy 83.76
2024-08-31 14:18:40,949 [foster.py] => SNet: Task 3, Epoch 108/130 => Loss 20.077,  Loss1 0.523, Train_accy 82.25
2024-08-31 14:18:48,277 [foster.py] => SNet: Task 3, Epoch 109/130 => Loss 20.033,  Loss1 0.523, Train_accy 82.25
2024-08-31 14:18:55,899 [foster.py] => SNet: Task 3, Epoch 110/130 => Loss 20.043,  Loss1 0.523, Train_accy 81.82
2024-08-31 14:19:04,309 [foster.py] => SNet: Task 3, Epoch 111/130 => Loss 20.048,  Loss1 0.523, Train_accy 82.07, Test_accy 82.05
2024-08-31 14:19:11,650 [foster.py] => SNet: Task 3, Epoch 112/130 => Loss 20.061,  Loss1 0.522, Train_accy 82.58
2024-08-31 14:19:19,063 [foster.py] => SNet: Task 3, Epoch 113/130 => Loss 20.028,  Loss1 0.523, Train_accy 82.54
2024-08-31 14:19:26,408 [foster.py] => SNet: Task 3, Epoch 114/130 => Loss 20.067,  Loss1 0.523, Train_accy 81.85
2024-08-31 14:19:33,925 [foster.py] => SNet: Task 3, Epoch 115/130 => Loss 20.014,  Loss1 0.523, Train_accy 83.03
2024-08-31 14:19:42,363 [foster.py] => SNet: Task 3, Epoch 116/130 => Loss 20.034,  Loss1 0.523, Train_accy 82.76, Test_accy 82.15
2024-08-31 14:19:49,596 [foster.py] => SNet: Task 3, Epoch 117/130 => Loss 20.043,  Loss1 0.523, Train_accy 82.94
2024-08-31 14:19:56,803 [foster.py] => SNet: Task 3, Epoch 118/130 => Loss 20.039,  Loss1 0.522, Train_accy 82.49
2024-08-31 14:20:04,224 [foster.py] => SNet: Task 3, Epoch 119/130 => Loss 20.046,  Loss1 0.523, Train_accy 82.69
2024-08-31 14:20:11,753 [foster.py] => SNet: Task 3, Epoch 120/130 => Loss 20.068,  Loss1 0.522, Train_accy 82.85
2024-08-31 14:20:20,422 [foster.py] => SNet: Task 3, Epoch 121/130 => Loss 20.064,  Loss1 0.523, Train_accy 82.14, Test_accy 81.90
2024-08-31 14:20:27,883 [foster.py] => SNet: Task 3, Epoch 122/130 => Loss 20.044,  Loss1 0.523, Train_accy 82.34
2024-08-31 14:20:35,196 [foster.py] => SNet: Task 3, Epoch 123/130 => Loss 20.053,  Loss1 0.523, Train_accy 82.80
2024-08-31 14:20:42,646 [foster.py] => SNet: Task 3, Epoch 124/130 => Loss 20.055,  Loss1 0.523, Train_accy 82.22
2024-08-31 14:20:49,860 [foster.py] => SNet: Task 3, Epoch 125/130 => Loss 20.065,  Loss1 0.523, Train_accy 82.47
2024-08-31 14:20:58,235 [foster.py] => SNet: Task 3, Epoch 126/130 => Loss 20.038,  Loss1 0.523, Train_accy 82.65, Test_accy 82.60
2024-08-31 14:21:05,664 [foster.py] => SNet: Task 3, Epoch 127/130 => Loss 20.052,  Loss1 0.523, Train_accy 82.91
2024-08-31 14:21:12,920 [foster.py] => SNet: Task 3, Epoch 128/130 => Loss 20.032,  Loss1 0.523, Train_accy 82.74
2024-08-31 14:21:20,490 [foster.py] => SNet: Task 3, Epoch 129/130 => Loss 20.058,  Loss1 0.523, Train_accy 81.96
2024-08-31 14:21:27,846 [foster.py] => SNet: Task 3, Epoch 130/130 => Loss 20.044,  Loss1 0.523, Train_accy 82.18
2024-08-31 14:21:27,846 [foster.py] => do not weight align student!
2024-08-31 14:21:28,991 [foster.py] => darknet eval: 
2024-08-31 14:21:28,992 [foster.py] => CNN top1 curve: 82.4
2024-08-31 14:21:28,992 [foster.py] => CNN top5 curve: 97.8
2024-08-31 14:21:28,992 [foster.py] => CNN top1 平均值: 82.40
2024-08-31 14:21:28,998 [foster.py] => timees : 2103.717432498932
2024-08-31 14:21:28,999 [base.py] => Reducing exemplars...(100 per classes)
2024-08-31 14:21:34,918 [base.py] => Constructing exemplars...(100 per classes)
2024-08-31 14:21:43,040 [foster.py] => Exemplar size: 2000
2024-08-31 14:21:43,041 [trainer.py] => CNN: {'total': 83.4, '00-09': 85.9, '10-19': 80.9, 'old': 82.8, 'new': 85.2}
2024-08-31 14:21:43,041 [trainer.py] => NME: {'total': 81.85, '00-09': 84.5, '10-19': 79.2, 'old': 81.8, 'new': 82.0}
2024-08-31 14:21:43,041 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4]
2024-08-31 14:21:43,041 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35]
2024-08-31 14:21:43,041 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85]
2024-08-31 14:21:43,041 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2]

2024-08-31 14:21:43,041 [trainer.py] => CNN top1 平均值: 91.17
2024-08-31 14:21:43,044 [trainer.py] => All params: 1287403
2024-08-31 14:21:43,046 [trainer.py] => Trainable params: 645154
2024-08-31 14:21:43,109 [foster.py] => Learning on 20-25
2024-08-31 14:21:43,113 [foster.py] => All params: 1288698
2024-08-31 14:21:43,115 [foster.py] => Trainable params: 646124
2024-08-31 14:21:43,157 [foster.py] => per cls weights : [1.01917775 1.01917775 1.01917775 1.01917775 1.01917775 1.01917775
 1.01917775 1.01917775 1.01917775 1.01917775 1.01917775 1.01917775
 1.01917775 1.01917775 1.01917775 1.01917775 1.01917775 1.01917775
 1.01917775 1.01917775 0.92328901 0.92328901 0.92328901 0.92328901
 0.92328901]
2024-08-31 14:21:48,644 [foster.py] => Task 4, Epoch 1/170 => Loss 4.751, Loss_clf 1.419, Loss_fe 1.610, Loss_kd 1.375, Train_accy 57.16
2024-08-31 14:21:55,568 [foster.py] => Task 4, Epoch 2/170 => Loss 3.955, Loss_clf 0.994, Loss_fe 1.273, Loss_kd 1.347, Train_accy 68.27, Test_accy 72.84
2024-08-31 14:22:02,419 [foster.py] => Task 4, Epoch 3/170 => Loss 3.878, Loss_clf 0.956, Loss_fe 1.242, Loss_kd 1.341, Train_accy 68.76, Test_accy 71.96
2024-08-31 14:22:09,265 [foster.py] => Task 4, Epoch 4/170 => Loss 3.887, Loss_clf 0.966, Loss_fe 1.223, Loss_kd 1.356, Train_accy 68.64, Test_accy 73.16
2024-08-31 14:22:16,166 [foster.py] => Task 4, Epoch 5/170 => Loss 3.737, Loss_clf 0.900, Loss_fe 1.142, Loss_kd 1.354, Train_accy 70.91, Test_accy 71.40
2024-08-31 14:22:21,543 [foster.py] => Task 4, Epoch 6/170 => Loss 3.817, Loss_clf 0.932, Loss_fe 1.191, Loss_kd 1.352, Train_accy 70.11
2024-08-31 14:22:28,420 [foster.py] => Task 4, Epoch 7/170 => Loss 3.770, Loss_clf 0.912, Loss_fe 1.177, Loss_kd 1.342, Train_accy 70.69, Test_accy 75.16
2024-08-31 14:22:35,315 [foster.py] => Task 4, Epoch 8/170 => Loss 3.709, Loss_clf 0.893, Loss_fe 1.131, Loss_kd 1.345, Train_accy 71.04, Test_accy 76.92
2024-08-31 14:22:42,187 [foster.py] => Task 4, Epoch 9/170 => Loss 3.647, Loss_clf 0.870, Loss_fe 1.092, Loss_kd 1.345, Train_accy 72.78, Test_accy 74.52
2024-08-31 14:22:49,110 [foster.py] => Task 4, Epoch 10/170 => Loss 3.685, Loss_clf 0.899, Loss_fe 1.083, Loss_kd 1.359, Train_accy 72.18, Test_accy 78.00
2024-08-31 14:22:54,566 [foster.py] => Task 4, Epoch 11/170 => Loss 3.705, Loss_clf 0.901, Loss_fe 1.120, Loss_kd 1.345, Train_accy 71.64
2024-08-31 14:23:01,527 [foster.py] => Task 4, Epoch 12/170 => Loss 3.696, Loss_clf 0.881, Loss_fe 1.104, Loss_kd 1.366, Train_accy 73.00, Test_accy 72.32
2024-08-31 14:23:08,314 [foster.py] => Task 4, Epoch 13/170 => Loss 3.617, Loss_clf 0.847, Loss_fe 1.102, Loss_kd 1.331, Train_accy 73.47, Test_accy 76.64
2024-08-31 14:23:15,225 [foster.py] => Task 4, Epoch 14/170 => Loss 3.666, Loss_clf 0.889, Loss_fe 1.085, Loss_kd 1.351, Train_accy 71.96, Test_accy 77.84
2024-08-31 14:23:22,119 [foster.py] => Task 4, Epoch 15/170 => Loss 3.658, Loss_clf 0.867, Loss_fe 1.104, Loss_kd 1.347, Train_accy 72.69, Test_accy 72.92
2024-08-31 14:23:27,578 [foster.py] => Task 4, Epoch 16/170 => Loss 3.724, Loss_clf 0.884, Loss_fe 1.155, Loss_kd 1.345, Train_accy 71.80
2024-08-31 14:23:34,455 [foster.py] => Task 4, Epoch 17/170 => Loss 3.652, Loss_clf 0.870, Loss_fe 1.100, Loss_kd 1.343, Train_accy 72.56, Test_accy 77.04
2024-08-31 14:23:41,366 [foster.py] => Task 4, Epoch 18/170 => Loss 3.640, Loss_clf 0.863, Loss_fe 1.107, Loss_kd 1.333, Train_accy 72.69, Test_accy 72.24
2024-08-31 14:23:48,376 [foster.py] => Task 4, Epoch 19/170 => Loss 3.661, Loss_clf 0.874, Loss_fe 1.116, Loss_kd 1.334, Train_accy 71.58, Test_accy 76.16
2024-08-31 14:23:55,303 [foster.py] => Task 4, Epoch 20/170 => Loss 3.563, Loss_clf 0.842, Loss_fe 1.043, Loss_kd 1.340, Train_accy 73.71, Test_accy 75.44
2024-08-31 14:24:00,768 [foster.py] => Task 4, Epoch 21/170 => Loss 3.591, Loss_clf 0.860, Loss_fe 1.046, Loss_kd 1.345, Train_accy 73.09
2024-08-31 14:24:07,702 [foster.py] => Task 4, Epoch 22/170 => Loss 3.595, Loss_clf 0.855, Loss_fe 1.064, Loss_kd 1.338, Train_accy 72.22, Test_accy 76.40
2024-08-31 14:24:14,535 [foster.py] => Task 4, Epoch 23/170 => Loss 3.619, Loss_clf 0.862, Loss_fe 1.063, Loss_kd 1.352, Train_accy 73.49, Test_accy 74.88
2024-08-31 14:24:21,449 [foster.py] => Task 4, Epoch 24/170 => Loss 3.727, Loss_clf 0.893, Loss_fe 1.148, Loss_kd 1.345, Train_accy 71.16, Test_accy 75.48
2024-08-31 14:24:28,300 [foster.py] => Task 4, Epoch 25/170 => Loss 3.492, Loss_clf 0.794, Loss_fe 1.020, Loss_kd 1.340, Train_accy 74.91, Test_accy 74.48
2024-08-31 14:24:33,742 [foster.py] => Task 4, Epoch 26/170 => Loss 3.580, Loss_clf 0.828, Loss_fe 1.069, Loss_kd 1.344, Train_accy 73.80
2024-08-31 14:24:40,626 [foster.py] => Task 4, Epoch 27/170 => Loss 3.614, Loss_clf 0.855, Loss_fe 1.073, Loss_kd 1.346, Train_accy 73.29, Test_accy 75.16
2024-08-31 14:24:47,638 [foster.py] => Task 4, Epoch 28/170 => Loss 3.614, Loss_clf 0.850, Loss_fe 1.072, Loss_kd 1.351, Train_accy 73.69, Test_accy 78.28
2024-08-31 14:24:54,560 [foster.py] => Task 4, Epoch 29/170 => Loss 3.528, Loss_clf 0.825, Loss_fe 1.041, Loss_kd 1.328, Train_accy 73.56, Test_accy 75.44
2024-08-31 14:25:01,447 [foster.py] => Task 4, Epoch 30/170 => Loss 3.648, Loss_clf 0.876, Loss_fe 1.090, Loss_kd 1.343, Train_accy 72.07, Test_accy 77.16
2024-08-31 14:25:06,867 [foster.py] => Task 4, Epoch 31/170 => Loss 3.465, Loss_clf 0.805, Loss_fe 1.003, Loss_kd 1.324, Train_accy 74.89
2024-08-31 14:25:13,723 [foster.py] => Task 4, Epoch 32/170 => Loss 3.517, Loss_clf 0.834, Loss_fe 0.994, Loss_kd 1.348, Train_accy 73.49, Test_accy 78.52
2024-08-31 14:25:20,592 [foster.py] => Task 4, Epoch 33/170 => Loss 3.536, Loss_clf 0.826, Loss_fe 1.029, Loss_kd 1.342, Train_accy 74.24, Test_accy 75.56
2024-08-31 14:25:27,559 [foster.py] => Task 4, Epoch 34/170 => Loss 3.497, Loss_clf 0.802, Loss_fe 1.026, Loss_kd 1.332, Train_accy 74.31, Test_accy 77.52
2024-08-31 14:25:34,375 [foster.py] => Task 4, Epoch 35/170 => Loss 3.457, Loss_clf 0.799, Loss_fe 0.963, Loss_kd 1.353, Train_accy 76.02, Test_accy 74.32
2024-08-31 14:25:39,814 [foster.py] => Task 4, Epoch 36/170 => Loss 3.422, Loss_clf 0.779, Loss_fe 0.959, Loss_kd 1.344, Train_accy 75.82
2024-08-31 14:25:46,778 [foster.py] => Task 4, Epoch 37/170 => Loss 3.556, Loss_clf 0.861, Loss_fe 0.997, Loss_kd 1.355, Train_accy 73.24, Test_accy 78.28
2024-08-31 14:25:53,650 [foster.py] => Task 4, Epoch 38/170 => Loss 3.575, Loss_clf 0.852, Loss_fe 1.048, Loss_kd 1.338, Train_accy 73.96, Test_accy 71.92
2024-08-31 14:26:00,516 [foster.py] => Task 4, Epoch 39/170 => Loss 3.547, Loss_clf 0.832, Loss_fe 1.027, Loss_kd 1.348, Train_accy 73.58, Test_accy 77.48
2024-08-31 14:26:07,320 [foster.py] => Task 4, Epoch 40/170 => Loss 3.566, Loss_clf 0.836, Loss_fe 1.036, Loss_kd 1.352, Train_accy 74.07, Test_accy 79.92
2024-08-31 14:26:12,834 [foster.py] => Task 4, Epoch 41/170 => Loss 3.417, Loss_clf 0.779, Loss_fe 0.959, Loss_kd 1.341, Train_accy 75.58
2024-08-31 14:26:19,945 [foster.py] => Task 4, Epoch 42/170 => Loss 3.531, Loss_clf 0.822, Loss_fe 1.029, Loss_kd 1.342, Train_accy 74.00, Test_accy 73.20
2024-08-31 14:26:26,902 [foster.py] => Task 4, Epoch 43/170 => Loss 3.410, Loss_clf 0.788, Loss_fe 0.947, Loss_kd 1.338, Train_accy 76.13, Test_accy 77.32
2024-08-31 14:26:33,839 [foster.py] => Task 4, Epoch 44/170 => Loss 3.497, Loss_clf 0.818, Loss_fe 0.991, Loss_kd 1.348, Train_accy 74.44, Test_accy 78.60
2024-08-31 14:26:40,703 [foster.py] => Task 4, Epoch 45/170 => Loss 3.399, Loss_clf 0.771, Loss_fe 0.937, Loss_kd 1.350, Train_accy 75.40, Test_accy 76.92
2024-08-31 14:26:46,117 [foster.py] => Task 4, Epoch 46/170 => Loss 3.405, Loss_clf 0.773, Loss_fe 0.945, Loss_kd 1.347, Train_accy 75.93
2024-08-31 14:26:52,960 [foster.py] => Task 4, Epoch 47/170 => Loss 3.426, Loss_clf 0.793, Loss_fe 0.942, Loss_kd 1.350, Train_accy 75.53, Test_accy 78.24
2024-08-31 14:26:59,840 [foster.py] => Task 4, Epoch 48/170 => Loss 3.450, Loss_clf 0.797, Loss_fe 0.960, Loss_kd 1.352, Train_accy 75.58, Test_accy 78.08
2024-08-31 14:27:06,684 [foster.py] => Task 4, Epoch 49/170 => Loss 3.373, Loss_clf 0.795, Loss_fe 0.903, Loss_kd 1.337, Train_accy 74.60, Test_accy 79.40
2024-08-31 14:27:13,583 [foster.py] => Task 4, Epoch 50/170 => Loss 3.383, Loss_clf 0.749, Loss_fe 0.953, Loss_kd 1.342, Train_accy 77.11, Test_accy 74.44
2024-08-31 14:27:19,089 [foster.py] => Task 4, Epoch 51/170 => Loss 3.363, Loss_clf 0.745, Loss_fe 0.938, Loss_kd 1.342, Train_accy 77.29
2024-08-31 14:27:25,966 [foster.py] => Task 4, Epoch 52/170 => Loss 3.429, Loss_clf 0.788, Loss_fe 0.966, Loss_kd 1.337, Train_accy 74.47, Test_accy 77.72
2024-08-31 14:27:32,913 [foster.py] => Task 4, Epoch 53/170 => Loss 3.355, Loss_clf 0.761, Loss_fe 0.916, Loss_kd 1.340, Train_accy 76.13, Test_accy 76.72
2024-08-31 14:27:39,788 [foster.py] => Task 4, Epoch 54/170 => Loss 3.431, Loss_clf 0.803, Loss_fe 0.944, Loss_kd 1.345, Train_accy 75.98, Test_accy 77.20
2024-08-31 14:27:46,676 [foster.py] => Task 4, Epoch 55/170 => Loss 3.434, Loss_clf 0.781, Loss_fe 0.978, Loss_kd 1.337, Train_accy 74.67, Test_accy 76.44
2024-08-31 14:27:52,110 [foster.py] => Task 4, Epoch 56/170 => Loss 3.535, Loss_clf 0.835, Loss_fe 1.022, Loss_kd 1.340, Train_accy 74.56
2024-08-31 14:27:58,925 [foster.py] => Task 4, Epoch 57/170 => Loss 3.458, Loss_clf 0.810, Loss_fe 0.972, Loss_kd 1.337, Train_accy 75.36, Test_accy 76.20
2024-08-31 14:28:05,725 [foster.py] => Task 4, Epoch 58/170 => Loss 3.377, Loss_clf 0.772, Loss_fe 0.918, Loss_kd 1.347, Train_accy 75.93, Test_accy 77.40
2024-08-31 14:28:12,567 [foster.py] => Task 4, Epoch 59/170 => Loss 3.404, Loss_clf 0.774, Loss_fe 0.933, Loss_kd 1.354, Train_accy 75.98, Test_accy 78.28
2024-08-31 14:28:19,431 [foster.py] => Task 4, Epoch 60/170 => Loss 3.320, Loss_clf 0.741, Loss_fe 0.888, Loss_kd 1.350, Train_accy 77.04, Test_accy 71.76
2024-08-31 14:28:24,920 [foster.py] => Task 4, Epoch 61/170 => Loss 3.320, Loss_clf 0.755, Loss_fe 0.879, Loss_kd 1.346, Train_accy 77.16
2024-08-31 14:28:31,896 [foster.py] => Task 4, Epoch 62/170 => Loss 3.416, Loss_clf 0.803, Loss_fe 0.924, Loss_kd 1.348, Train_accy 75.40, Test_accy 77.40
2024-08-31 14:28:38,796 [foster.py] => Task 4, Epoch 63/170 => Loss 3.317, Loss_clf 0.727, Loss_fe 0.917, Loss_kd 1.335, Train_accy 76.78, Test_accy 78.04
2024-08-31 14:28:45,659 [foster.py] => Task 4, Epoch 64/170 => Loss 3.404, Loss_clf 0.778, Loss_fe 0.944, Loss_kd 1.343, Train_accy 75.38, Test_accy 78.24
2024-08-31 14:28:52,625 [foster.py] => Task 4, Epoch 65/170 => Loss 3.349, Loss_clf 0.759, Loss_fe 0.905, Loss_kd 1.345, Train_accy 76.44, Test_accy 77.52
2024-08-31 14:28:58,042 [foster.py] => Task 4, Epoch 66/170 => Loss 3.353, Loss_clf 0.768, Loss_fe 0.903, Loss_kd 1.343, Train_accy 76.58
2024-08-31 14:29:04,931 [foster.py] => Task 4, Epoch 67/170 => Loss 3.221, Loss_clf 0.695, Loss_fe 0.856, Loss_kd 1.333, Train_accy 77.82, Test_accy 77.60
2024-08-31 14:29:11,755 [foster.py] => Task 4, Epoch 68/170 => Loss 3.269, Loss_clf 0.740, Loss_fe 0.854, Loss_kd 1.337, Train_accy 76.96, Test_accy 75.56
2024-08-31 14:29:18,721 [foster.py] => Task 4, Epoch 69/170 => Loss 3.290, Loss_clf 0.744, Loss_fe 0.878, Loss_kd 1.332, Train_accy 76.27, Test_accy 79.48
2024-08-31 14:29:25,573 [foster.py] => Task 4, Epoch 70/170 => Loss 3.273, Loss_clf 0.734, Loss_fe 0.855, Loss_kd 1.345, Train_accy 77.31, Test_accy 79.44
2024-08-31 14:29:31,023 [foster.py] => Task 4, Epoch 71/170 => Loss 3.270, Loss_clf 0.721, Loss_fe 0.869, Loss_kd 1.341, Train_accy 77.73
2024-08-31 14:29:37,999 [foster.py] => Task 4, Epoch 72/170 => Loss 3.352, Loss_clf 0.758, Loss_fe 0.904, Loss_kd 1.349, Train_accy 76.07, Test_accy 76.32
2024-08-31 14:29:44,828 [foster.py] => Task 4, Epoch 73/170 => Loss 3.298, Loss_clf 0.759, Loss_fe 0.851, Loss_kd 1.348, Train_accy 76.89, Test_accy 75.04
2024-08-31 14:29:51,679 [foster.py] => Task 4, Epoch 74/170 => Loss 3.263, Loss_clf 0.706, Loss_fe 0.875, Loss_kd 1.344, Train_accy 77.91, Test_accy 78.56
2024-08-31 14:29:58,565 [foster.py] => Task 4, Epoch 75/170 => Loss 3.246, Loss_clf 0.716, Loss_fe 0.854, Loss_kd 1.339, Train_accy 77.96, Test_accy 77.64
2024-08-31 14:30:04,071 [foster.py] => Task 4, Epoch 76/170 => Loss 3.301, Loss_clf 0.749, Loss_fe 0.879, Loss_kd 1.336, Train_accy 76.69
2024-08-31 14:30:11,027 [foster.py] => Task 4, Epoch 77/170 => Loss 3.185, Loss_clf 0.690, Loss_fe 0.801, Loss_kd 1.352, Train_accy 78.00, Test_accy 78.16
2024-08-31 14:30:18,061 [foster.py] => Task 4, Epoch 78/170 => Loss 3.249, Loss_clf 0.728, Loss_fe 0.838, Loss_kd 1.343, Train_accy 77.78, Test_accy 79.00
2024-08-31 14:30:25,076 [foster.py] => Task 4, Epoch 79/170 => Loss 3.202, Loss_clf 0.692, Loss_fe 0.826, Loss_kd 1.345, Train_accy 78.64, Test_accy 79.76
2024-08-31 14:30:31,947 [foster.py] => Task 4, Epoch 80/170 => Loss 3.241, Loss_clf 0.713, Loss_fe 0.839, Loss_kd 1.349, Train_accy 77.87, Test_accy 77.48
2024-08-31 14:30:37,292 [foster.py] => Task 4, Epoch 81/170 => Loss 3.187, Loss_clf 0.676, Loss_fe 0.824, Loss_kd 1.347, Train_accy 79.02
2024-08-31 14:30:44,254 [foster.py] => Task 4, Epoch 82/170 => Loss 3.194, Loss_clf 0.693, Loss_fe 0.825, Loss_kd 1.338, Train_accy 77.96, Test_accy 78.72
2024-08-31 14:30:51,127 [foster.py] => Task 4, Epoch 83/170 => Loss 3.135, Loss_clf 0.672, Loss_fe 0.796, Loss_kd 1.330, Train_accy 79.02, Test_accy 77.88
2024-08-31 14:30:58,088 [foster.py] => Task 4, Epoch 84/170 => Loss 3.138, Loss_clf 0.674, Loss_fe 0.775, Loss_kd 1.348, Train_accy 78.80, Test_accy 80.56
2024-08-31 14:31:04,989 [foster.py] => Task 4, Epoch 85/170 => Loss 3.163, Loss_clf 0.678, Loss_fe 0.805, Loss_kd 1.342, Train_accy 78.56, Test_accy 75.04
2024-08-31 14:31:10,436 [foster.py] => Task 4, Epoch 86/170 => Loss 3.259, Loss_clf 0.741, Loss_fe 0.834, Loss_kd 1.345, Train_accy 76.98
2024-08-31 14:31:17,289 [foster.py] => Task 4, Epoch 87/170 => Loss 3.175, Loss_clf 0.702, Loss_fe 0.796, Loss_kd 1.339, Train_accy 78.38, Test_accy 77.72
2024-08-31 14:31:24,272 [foster.py] => Task 4, Epoch 88/170 => Loss 3.156, Loss_clf 0.684, Loss_fe 0.793, Loss_kd 1.341, Train_accy 78.73, Test_accy 77.72
2024-08-31 14:31:31,136 [foster.py] => Task 4, Epoch 89/170 => Loss 3.103, Loss_clf 0.663, Loss_fe 0.771, Loss_kd 1.332, Train_accy 80.00, Test_accy 80.28
2024-08-31 14:31:37,984 [foster.py] => Task 4, Epoch 90/170 => Loss 3.186, Loss_clf 0.718, Loss_fe 0.785, Loss_kd 1.344, Train_accy 78.20, Test_accy 78.76
2024-08-31 14:31:43,567 [foster.py] => Task 4, Epoch 91/170 => Loss 3.149, Loss_clf 0.678, Loss_fe 0.777, Loss_kd 1.353, Train_accy 79.24
2024-08-31 14:31:50,459 [foster.py] => Task 4, Epoch 92/170 => Loss 3.120, Loss_clf 0.657, Loss_fe 0.780, Loss_kd 1.344, Train_accy 80.29, Test_accy 77.48
2024-08-31 14:31:57,307 [foster.py] => Task 4, Epoch 93/170 => Loss 3.095, Loss_clf 0.661, Loss_fe 0.754, Loss_kd 1.341, Train_accy 79.22, Test_accy 79.04
2024-08-31 14:32:04,286 [foster.py] => Task 4, Epoch 94/170 => Loss 3.090, Loss_clf 0.657, Loss_fe 0.759, Loss_kd 1.336, Train_accy 80.04, Test_accy 79.28
2024-08-31 14:32:11,144 [foster.py] => Task 4, Epoch 95/170 => Loss 3.117, Loss_clf 0.678, Loss_fe 0.741, Loss_kd 1.356, Train_accy 79.31, Test_accy 80.60
2024-08-31 14:32:16,691 [foster.py] => Task 4, Epoch 96/170 => Loss 3.079, Loss_clf 0.666, Loss_fe 0.730, Loss_kd 1.345, Train_accy 79.58
2024-08-31 14:32:23,652 [foster.py] => Task 4, Epoch 97/170 => Loss 3.066, Loss_clf 0.646, Loss_fe 0.749, Loss_kd 1.334, Train_accy 79.87, Test_accy 78.60
2024-08-31 14:32:30,547 [foster.py] => Task 4, Epoch 98/170 => Loss 3.015, Loss_clf 0.625, Loss_fe 0.710, Loss_kd 1.341, Train_accy 80.62, Test_accy 77.60
2024-08-31 14:32:37,499 [foster.py] => Task 4, Epoch 99/170 => Loss 3.034, Loss_clf 0.642, Loss_fe 0.715, Loss_kd 1.340, Train_accy 79.49, Test_accy 80.36
2024-08-31 14:32:44,401 [foster.py] => Task 4, Epoch 100/170 => Loss 3.071, Loss_clf 0.658, Loss_fe 0.737, Loss_kd 1.338, Train_accy 79.40, Test_accy 79.64
2024-08-31 14:32:49,919 [foster.py] => Task 4, Epoch 101/170 => Loss 2.992, Loss_clf 0.632, Loss_fe 0.676, Loss_kd 1.345, Train_accy 81.44
2024-08-31 14:32:56,794 [foster.py] => Task 4, Epoch 102/170 => Loss 2.985, Loss_clf 0.626, Loss_fe 0.678, Loss_kd 1.343, Train_accy 80.60, Test_accy 78.84
2024-08-31 14:33:03,712 [foster.py] => Task 4, Epoch 103/170 => Loss 3.059, Loss_clf 0.649, Loss_fe 0.722, Loss_kd 1.347, Train_accy 80.31, Test_accy 80.48
2024-08-31 14:33:10,551 [foster.py] => Task 4, Epoch 104/170 => Loss 3.004, Loss_clf 0.625, Loss_fe 0.690, Loss_kd 1.349, Train_accy 82.22, Test_accy 79.60
2024-08-31 14:33:17,684 [foster.py] => Task 4, Epoch 105/170 => Loss 2.975, Loss_clf 0.627, Loss_fe 0.682, Loss_kd 1.330, Train_accy 80.67, Test_accy 80.68
2024-08-31 14:33:23,192 [foster.py] => Task 4, Epoch 106/170 => Loss 2.939, Loss_clf 0.607, Loss_fe 0.662, Loss_kd 1.333, Train_accy 81.29
2024-08-31 14:33:30,160 [foster.py] => Task 4, Epoch 107/170 => Loss 2.987, Loss_clf 0.629, Loss_fe 0.678, Loss_kd 1.342, Train_accy 80.93, Test_accy 79.52
2024-08-31 14:33:37,040 [foster.py] => Task 4, Epoch 108/170 => Loss 2.981, Loss_clf 0.630, Loss_fe 0.668, Loss_kd 1.344, Train_accy 80.36, Test_accy 80.84
2024-08-31 14:33:44,010 [foster.py] => Task 4, Epoch 109/170 => Loss 2.927, Loss_clf 0.605, Loss_fe 0.642, Loss_kd 1.342, Train_accy 81.40, Test_accy 79.44
2024-08-31 14:33:50,916 [foster.py] => Task 4, Epoch 110/170 => Loss 2.905, Loss_clf 0.589, Loss_fe 0.642, Loss_kd 1.337, Train_accy 82.22, Test_accy 79.32
2024-08-31 14:33:56,337 [foster.py] => Task 4, Epoch 111/170 => Loss 2.886, Loss_clf 0.583, Loss_fe 0.629, Loss_kd 1.336, Train_accy 82.04
2024-08-31 14:34:03,127 [foster.py] => Task 4, Epoch 112/170 => Loss 2.853, Loss_clf 0.576, Loss_fe 0.612, Loss_kd 1.330, Train_accy 82.76, Test_accy 80.36
2024-08-31 14:34:09,999 [foster.py] => Task 4, Epoch 113/170 => Loss 2.865, Loss_clf 0.585, Loss_fe 0.614, Loss_kd 1.330, Train_accy 82.00, Test_accy 79.80
2024-08-31 14:34:16,925 [foster.py] => Task 4, Epoch 114/170 => Loss 2.940, Loss_clf 0.610, Loss_fe 0.653, Loss_kd 1.339, Train_accy 81.64, Test_accy 80.48
2024-08-31 14:34:23,840 [foster.py] => Task 4, Epoch 115/170 => Loss 2.918, Loss_clf 0.614, Loss_fe 0.629, Loss_kd 1.337, Train_accy 81.64, Test_accy 81.08
2024-08-31 14:34:29,315 [foster.py] => Task 4, Epoch 116/170 => Loss 2.892, Loss_clf 0.589, Loss_fe 0.626, Loss_kd 1.339, Train_accy 82.51
2024-08-31 14:34:36,190 [foster.py] => Task 4, Epoch 117/170 => Loss 2.872, Loss_clf 0.589, Loss_fe 0.610, Loss_kd 1.336, Train_accy 82.13, Test_accy 80.88
2024-08-31 14:34:43,087 [foster.py] => Task 4, Epoch 118/170 => Loss 2.878, Loss_clf 0.597, Loss_fe 0.592, Loss_kd 1.349, Train_accy 82.02, Test_accy 80.76
2024-08-31 14:34:49,998 [foster.py] => Task 4, Epoch 119/170 => Loss 2.867, Loss_clf 0.582, Loss_fe 0.598, Loss_kd 1.347, Train_accy 81.87, Test_accy 80.04
2024-08-31 14:34:56,937 [foster.py] => Task 4, Epoch 120/170 => Loss 2.888, Loss_clf 0.598, Loss_fe 0.603, Loss_kd 1.347, Train_accy 81.62, Test_accy 79.36
2024-08-31 14:35:02,346 [foster.py] => Task 4, Epoch 121/170 => Loss 2.774, Loss_clf 0.548, Loss_fe 0.560, Loss_kd 1.330, Train_accy 83.80
2024-08-31 14:35:09,360 [foster.py] => Task 4, Epoch 122/170 => Loss 2.769, Loss_clf 0.554, Loss_fe 0.562, Loss_kd 1.320, Train_accy 83.16, Test_accy 78.52
2024-08-31 14:35:16,257 [foster.py] => Task 4, Epoch 123/170 => Loss 2.788, Loss_clf 0.560, Loss_fe 0.561, Loss_kd 1.332, Train_accy 83.80, Test_accy 80.72
2024-08-31 14:35:23,128 [foster.py] => Task 4, Epoch 124/170 => Loss 2.761, Loss_clf 0.554, Loss_fe 0.538, Loss_kd 1.332, Train_accy 83.18, Test_accy 81.00
2024-08-31 14:35:30,079 [foster.py] => Task 4, Epoch 125/170 => Loss 2.782, Loss_clf 0.556, Loss_fe 0.545, Loss_kd 1.343, Train_accy 83.20, Test_accy 80.92
2024-08-31 14:35:35,482 [foster.py] => Task 4, Epoch 126/170 => Loss 2.725, Loss_clf 0.534, Loss_fe 0.526, Loss_kd 1.330, Train_accy 84.31
2024-08-31 14:35:42,351 [foster.py] => Task 4, Epoch 127/170 => Loss 2.773, Loss_clf 0.553, Loss_fe 0.523, Loss_kd 1.355, Train_accy 83.47, Test_accy 82.24
2024-08-31 14:35:49,397 [foster.py] => Task 4, Epoch 128/170 => Loss 2.687, Loss_clf 0.526, Loss_fe 0.496, Loss_kd 1.330, Train_accy 84.42, Test_accy 81.68
2024-08-31 14:35:56,308 [foster.py] => Task 4, Epoch 129/170 => Loss 2.634, Loss_clf 0.491, Loss_fe 0.471, Loss_kd 1.336, Train_accy 85.87, Test_accy 80.92
2024-08-31 14:36:03,222 [foster.py] => Task 4, Epoch 130/170 => Loss 2.715, Loss_clf 0.517, Loss_fe 0.508, Loss_kd 1.349, Train_accy 83.56, Test_accy 81.76
2024-08-31 14:36:08,622 [foster.py] => Task 4, Epoch 131/170 => Loss 2.657, Loss_clf 0.499, Loss_fe 0.485, Loss_kd 1.337, Train_accy 85.11
2024-08-31 14:36:15,551 [foster.py] => Task 4, Epoch 132/170 => Loss 2.676, Loss_clf 0.506, Loss_fe 0.479, Loss_kd 1.350, Train_accy 84.87, Test_accy 81.64
2024-08-31 14:36:22,395 [foster.py] => Task 4, Epoch 133/170 => Loss 2.738, Loss_clf 0.549, Loss_fe 0.501, Loss_kd 1.348, Train_accy 84.67, Test_accy 82.08
2024-08-31 14:36:29,338 [foster.py] => Task 4, Epoch 134/170 => Loss 2.732, Loss_clf 0.535, Loss_fe 0.515, Loss_kd 1.343, Train_accy 84.20, Test_accy 81.28
2024-08-31 14:36:36,202 [foster.py] => Task 4, Epoch 135/170 => Loss 2.673, Loss_clf 0.508, Loss_fe 0.485, Loss_kd 1.341, Train_accy 84.40, Test_accy 82.00
2024-08-31 14:36:41,673 [foster.py] => Task 4, Epoch 136/170 => Loss 2.684, Loss_clf 0.517, Loss_fe 0.487, Loss_kd 1.341, Train_accy 84.47
2024-08-31 14:36:48,672 [foster.py] => Task 4, Epoch 137/170 => Loss 2.577, Loss_clf 0.471, Loss_fe 0.437, Loss_kd 1.334, Train_accy 85.76, Test_accy 81.84
2024-08-31 14:36:55,534 [foster.py] => Task 4, Epoch 138/170 => Loss 2.613, Loss_clf 0.493, Loss_fe 0.438, Loss_kd 1.343, Train_accy 85.82, Test_accy 81.92
2024-08-31 14:37:02,384 [foster.py] => Task 4, Epoch 139/170 => Loss 2.634, Loss_clf 0.499, Loss_fe 0.455, Loss_kd 1.342, Train_accy 84.71, Test_accy 81.36
2024-08-31 14:37:09,262 [foster.py] => Task 4, Epoch 140/170 => Loss 2.612, Loss_clf 0.479, Loss_fe 0.457, Loss_kd 1.339, Train_accy 85.42, Test_accy 81.92
2024-08-31 14:37:14,695 [foster.py] => Task 4, Epoch 141/170 => Loss 2.542, Loss_clf 0.462, Loss_fe 0.410, Loss_kd 1.333, Train_accy 86.56
2024-08-31 14:37:21,639 [foster.py] => Task 4, Epoch 142/170 => Loss 2.574, Loss_clf 0.491, Loss_fe 0.418, Loss_kd 1.330, Train_accy 86.02, Test_accy 82.40
2024-08-31 14:37:28,587 [foster.py] => Task 4, Epoch 143/170 => Loss 2.552, Loss_clf 0.459, Loss_fe 0.417, Loss_kd 1.338, Train_accy 86.20, Test_accy 82.00
2024-08-31 14:37:35,468 [foster.py] => Task 4, Epoch 144/170 => Loss 2.584, Loss_clf 0.481, Loss_fe 0.416, Loss_kd 1.347, Train_accy 85.93, Test_accy 81.96
2024-08-31 14:37:42,569 [foster.py] => Task 4, Epoch 145/170 => Loss 2.535, Loss_clf 0.459, Loss_fe 0.391, Loss_kd 1.345, Train_accy 86.24, Test_accy 82.20
2024-08-31 14:37:48,224 [foster.py] => Task 4, Epoch 146/170 => Loss 2.548, Loss_clf 0.457, Loss_fe 0.418, Loss_kd 1.337, Train_accy 86.40
2024-08-31 14:37:55,435 [foster.py] => Task 4, Epoch 147/170 => Loss 2.527, Loss_clf 0.451, Loss_fe 0.402, Loss_kd 1.336, Train_accy 86.40, Test_accy 82.24
2024-08-31 14:38:02,446 [foster.py] => Task 4, Epoch 148/170 => Loss 2.498, Loss_clf 0.447, Loss_fe 0.383, Loss_kd 1.332, Train_accy 86.24, Test_accy 82.32
2024-08-31 14:38:09,356 [foster.py] => Task 4, Epoch 149/170 => Loss 2.473, Loss_clf 0.435, Loss_fe 0.368, Loss_kd 1.333, Train_accy 86.73, Test_accy 81.92
2024-08-31 14:38:16,207 [foster.py] => Task 4, Epoch 150/170 => Loss 2.504, Loss_clf 0.450, Loss_fe 0.387, Loss_kd 1.331, Train_accy 86.60, Test_accy 82.64
2024-08-31 14:38:21,709 [foster.py] => Task 4, Epoch 151/170 => Loss 2.474, Loss_clf 0.432, Loss_fe 0.368, Loss_kd 1.337, Train_accy 87.07
2024-08-31 14:38:28,721 [foster.py] => Task 4, Epoch 152/170 => Loss 2.475, Loss_clf 0.441, Loss_fe 0.359, Loss_kd 1.338, Train_accy 87.40, Test_accy 82.80
2024-08-31 14:38:35,644 [foster.py] => Task 4, Epoch 153/170 => Loss 2.535, Loss_clf 0.462, Loss_fe 0.385, Loss_kd 1.349, Train_accy 86.47, Test_accy 82.72
2024-08-31 14:38:42,517 [foster.py] => Task 4, Epoch 154/170 => Loss 2.494, Loss_clf 0.454, Loss_fe 0.374, Loss_kd 1.331, Train_accy 87.07, Test_accy 82.72
2024-08-31 14:38:49,472 [foster.py] => Task 4, Epoch 155/170 => Loss 2.505, Loss_clf 0.454, Loss_fe 0.369, Loss_kd 1.343, Train_accy 86.22, Test_accy 82.28
2024-08-31 14:38:54,966 [foster.py] => Task 4, Epoch 156/170 => Loss 2.496, Loss_clf 0.453, Loss_fe 0.366, Loss_kd 1.339, Train_accy 86.89
2024-08-31 14:39:01,877 [foster.py] => Task 4, Epoch 157/170 => Loss 2.477, Loss_clf 0.445, Loss_fe 0.350, Loss_kd 1.343, Train_accy 86.82, Test_accy 82.80
2024-08-31 14:39:08,731 [foster.py] => Task 4, Epoch 158/170 => Loss 2.458, Loss_clf 0.432, Loss_fe 0.335, Loss_kd 1.351, Train_accy 86.82, Test_accy 82.48
2024-08-31 14:39:15,706 [foster.py] => Task 4, Epoch 159/170 => Loss 2.479, Loss_clf 0.435, Loss_fe 0.366, Loss_kd 1.340, Train_accy 87.04, Test_accy 82.64
2024-08-31 14:39:22,627 [foster.py] => Task 4, Epoch 160/170 => Loss 2.488, Loss_clf 0.449, Loss_fe 0.356, Loss_kd 1.344, Train_accy 87.22, Test_accy 83.04
2024-08-31 14:39:28,063 [foster.py] => Task 4, Epoch 161/170 => Loss 2.457, Loss_clf 0.437, Loss_fe 0.348, Loss_kd 1.335, Train_accy 86.80
2024-08-31 14:39:35,059 [foster.py] => Task 4, Epoch 162/170 => Loss 2.439, Loss_clf 0.428, Loss_fe 0.348, Loss_kd 1.328, Train_accy 87.51, Test_accy 82.84
2024-08-31 14:39:41,998 [foster.py] => Task 4, Epoch 163/170 => Loss 2.439, Loss_clf 0.428, Loss_fe 0.332, Loss_kd 1.342, Train_accy 87.87, Test_accy 83.08
2024-08-31 14:39:48,935 [foster.py] => Task 4, Epoch 164/170 => Loss 2.431, Loss_clf 0.412, Loss_fe 0.341, Loss_kd 1.341, Train_accy 87.58, Test_accy 83.20
2024-08-31 14:39:55,803 [foster.py] => Task 4, Epoch 165/170 => Loss 2.443, Loss_clf 0.425, Loss_fe 0.338, Loss_kd 1.342, Train_accy 87.51, Test_accy 82.84
2024-08-31 14:40:01,266 [foster.py] => Task 4, Epoch 166/170 => Loss 2.488, Loss_clf 0.451, Loss_fe 0.355, Loss_kd 1.344, Train_accy 86.96
2024-08-31 14:40:08,197 [foster.py] => Task 4, Epoch 167/170 => Loss 2.484, Loss_clf 0.443, Loss_fe 0.355, Loss_kd 1.346, Train_accy 86.56, Test_accy 83.00
2024-08-31 14:40:15,118 [foster.py] => Task 4, Epoch 168/170 => Loss 2.457, Loss_clf 0.432, Loss_fe 0.339, Loss_kd 1.346, Train_accy 87.18, Test_accy 82.96
2024-08-31 14:40:22,116 [foster.py] => Task 4, Epoch 169/170 => Loss 2.411, Loss_clf 0.420, Loss_fe 0.328, Loss_kd 1.328, Train_accy 86.84, Test_accy 83.00
2024-08-31 14:40:29,004 [foster.py] => Task 4, Epoch 170/170 => Loss 2.465, Loss_clf 0.441, Loss_fe 0.341, Loss_kd 1.344, Train_accy 86.80, Test_accy 83.20
2024-08-31 14:40:29,006 [foster.py] => do not weight align teacher!
2024-08-31 14:40:29,008 [foster.py] => per cls weights : [1.02756725 1.02756725 1.02756725 1.02756725 1.02756725 1.02756725
 1.02756725 1.02756725 1.02756725 1.02756725 1.02756725 1.02756725
 1.02756725 1.02756725 1.02756725 1.02756725 1.02756725 1.02756725
 1.02756725 1.02756725 0.88973099 0.88973099 0.88973099 0.88973099
 0.88973099]
2024-08-31 14:40:37,894 [foster.py] => SNet: Task 4, Epoch 1/130 => Loss 21.943,  Loss1 0.546, Train_accy 47.09, Test_accy 65.24
2024-08-31 14:40:45,154 [foster.py] => SNet: Task 4, Epoch 2/130 => Loss 21.729,  Loss1 0.544, Train_accy 63.84
2024-08-31 14:40:52,544 [foster.py] => SNet: Task 4, Epoch 3/130 => Loss 21.661,  Loss1 0.543, Train_accy 68.02
2024-08-31 14:40:59,879 [foster.py] => SNet: Task 4, Epoch 4/130 => Loss 21.650,  Loss1 0.543, Train_accy 70.96
2024-08-31 14:41:07,135 [foster.py] => SNet: Task 4, Epoch 5/130 => Loss 21.637,  Loss1 0.543, Train_accy 71.98
2024-08-31 14:41:15,728 [foster.py] => SNet: Task 4, Epoch 6/130 => Loss 21.646,  Loss1 0.543, Train_accy 73.38, Test_accy 72.24
2024-08-31 14:41:23,210 [foster.py] => SNet: Task 4, Epoch 7/130 => Loss 21.673,  Loss1 0.543, Train_accy 72.93
2024-08-31 14:41:30,482 [foster.py] => SNet: Task 4, Epoch 8/130 => Loss 21.603,  Loss1 0.543, Train_accy 74.78
2024-08-31 14:41:38,040 [foster.py] => SNet: Task 4, Epoch 9/130 => Loss 21.609,  Loss1 0.542, Train_accy 74.82
2024-08-31 14:41:45,470 [foster.py] => SNet: Task 4, Epoch 10/130 => Loss 21.585,  Loss1 0.543, Train_accy 75.40
2024-08-31 14:41:54,285 [foster.py] => SNet: Task 4, Epoch 11/130 => Loss 21.623,  Loss1 0.543, Train_accy 76.40, Test_accy 73.84
2024-08-31 14:42:01,729 [foster.py] => SNet: Task 4, Epoch 12/130 => Loss 21.610,  Loss1 0.543, Train_accy 76.44
2024-08-31 14:42:09,052 [foster.py] => SNet: Task 4, Epoch 13/130 => Loss 21.611,  Loss1 0.543, Train_accy 76.38
2024-08-31 14:42:16,328 [foster.py] => SNet: Task 4, Epoch 14/130 => Loss 21.618,  Loss1 0.543, Train_accy 77.49
2024-08-31 14:42:23,658 [foster.py] => SNet: Task 4, Epoch 15/130 => Loss 21.587,  Loss1 0.543, Train_accy 77.29
2024-08-31 14:42:32,350 [foster.py] => SNet: Task 4, Epoch 16/130 => Loss 21.590,  Loss1 0.543, Train_accy 76.51, Test_accy 77.48
2024-08-31 14:42:39,781 [foster.py] => SNet: Task 4, Epoch 17/130 => Loss 21.577,  Loss1 0.543, Train_accy 77.49
2024-08-31 14:42:47,113 [foster.py] => SNet: Task 4, Epoch 18/130 => Loss 21.566,  Loss1 0.543, Train_accy 77.84
2024-08-31 14:42:54,421 [foster.py] => SNet: Task 4, Epoch 19/130 => Loss 21.581,  Loss1 0.542, Train_accy 78.91
2024-08-31 14:43:02,117 [foster.py] => SNet: Task 4, Epoch 20/130 => Loss 21.556,  Loss1 0.543, Train_accy 79.11
2024-08-31 14:43:11,005 [foster.py] => SNet: Task 4, Epoch 21/130 => Loss 21.595,  Loss1 0.543, Train_accy 78.78, Test_accy 76.24
2024-08-31 14:43:18,529 [foster.py] => SNet: Task 4, Epoch 22/130 => Loss 21.563,  Loss1 0.543, Train_accy 78.29
2024-08-31 14:43:25,802 [foster.py] => SNet: Task 4, Epoch 23/130 => Loss 21.567,  Loss1 0.543, Train_accy 78.93
2024-08-31 14:43:33,133 [foster.py] => SNet: Task 4, Epoch 24/130 => Loss 21.556,  Loss1 0.543, Train_accy 79.02
2024-08-31 14:43:40,554 [foster.py] => SNet: Task 4, Epoch 25/130 => Loss 21.585,  Loss1 0.543, Train_accy 79.24
2024-08-31 14:43:49,399 [foster.py] => SNet: Task 4, Epoch 26/130 => Loss 21.540,  Loss1 0.543, Train_accy 78.93, Test_accy 78.48
2024-08-31 14:43:56,662 [foster.py] => SNet: Task 4, Epoch 27/130 => Loss 21.567,  Loss1 0.543, Train_accy 79.64
2024-08-31 14:44:04,284 [foster.py] => SNet: Task 4, Epoch 28/130 => Loss 21.540,  Loss1 0.543, Train_accy 79.93
2024-08-31 14:44:11,730 [foster.py] => SNet: Task 4, Epoch 29/130 => Loss 21.557,  Loss1 0.543, Train_accy 80.02
2024-08-31 14:44:19,449 [foster.py] => SNet: Task 4, Epoch 30/130 => Loss 21.546,  Loss1 0.543, Train_accy 80.53
2024-08-31 14:44:27,944 [foster.py] => SNet: Task 4, Epoch 31/130 => Loss 21.550,  Loss1 0.543, Train_accy 81.02, Test_accy 79.32
2024-08-31 14:44:35,270 [foster.py] => SNet: Task 4, Epoch 32/130 => Loss 21.556,  Loss1 0.543, Train_accy 80.67
2024-08-31 14:44:42,522 [foster.py] => SNet: Task 4, Epoch 33/130 => Loss 21.545,  Loss1 0.543, Train_accy 81.38
2024-08-31 14:44:49,927 [foster.py] => SNet: Task 4, Epoch 34/130 => Loss 21.554,  Loss1 0.543, Train_accy 80.71
2024-08-31 14:44:57,195 [foster.py] => SNet: Task 4, Epoch 35/130 => Loss 21.558,  Loss1 0.543, Train_accy 80.78
2024-08-31 14:45:05,676 [foster.py] => SNet: Task 4, Epoch 36/130 => Loss 21.576,  Loss1 0.543, Train_accy 80.51, Test_accy 77.96
2024-08-31 14:45:13,374 [foster.py] => SNet: Task 4, Epoch 37/130 => Loss 21.545,  Loss1 0.542, Train_accy 80.98
2024-08-31 14:45:20,894 [foster.py] => SNet: Task 4, Epoch 38/130 => Loss 21.555,  Loss1 0.543, Train_accy 82.07
2024-08-31 14:45:28,803 [foster.py] => SNet: Task 4, Epoch 39/130 => Loss 21.549,  Loss1 0.543, Train_accy 81.29
2024-08-31 14:45:36,118 [foster.py] => SNet: Task 4, Epoch 40/130 => Loss 21.537,  Loss1 0.542, Train_accy 82.18
2024-08-31 14:45:44,844 [foster.py] => SNet: Task 4, Epoch 41/130 => Loss 21.564,  Loss1 0.542, Train_accy 81.62, Test_accy 78.48
2024-08-31 14:45:52,083 [foster.py] => SNet: Task 4, Epoch 42/130 => Loss 21.572,  Loss1 0.543, Train_accy 80.80
2024-08-31 14:45:59,338 [foster.py] => SNet: Task 4, Epoch 43/130 => Loss 21.542,  Loss1 0.542, Train_accy 82.22
2024-08-31 14:46:06,651 [foster.py] => SNet: Task 4, Epoch 44/130 => Loss 21.550,  Loss1 0.543, Train_accy 81.64
2024-08-31 14:46:14,058 [foster.py] => SNet: Task 4, Epoch 45/130 => Loss 21.527,  Loss1 0.543, Train_accy 81.76
2024-08-31 14:46:22,866 [foster.py] => SNet: Task 4, Epoch 46/130 => Loss 21.525,  Loss1 0.542, Train_accy 82.87, Test_accy 79.44
2024-08-31 14:46:30,400 [foster.py] => SNet: Task 4, Epoch 47/130 => Loss 21.525,  Loss1 0.542, Train_accy 82.16
2024-08-31 14:46:38,306 [foster.py] => SNet: Task 4, Epoch 48/130 => Loss 21.545,  Loss1 0.542, Train_accy 81.82
2024-08-31 14:46:45,937 [foster.py] => SNet: Task 4, Epoch 49/130 => Loss 21.520,  Loss1 0.542, Train_accy 82.56
2024-08-31 14:46:53,436 [foster.py] => SNet: Task 4, Epoch 50/130 => Loss 21.545,  Loss1 0.543, Train_accy 82.00
2024-08-31 14:47:02,233 [foster.py] => SNet: Task 4, Epoch 51/130 => Loss 21.523,  Loss1 0.543, Train_accy 82.40, Test_accy 79.44
2024-08-31 14:47:09,576 [foster.py] => SNet: Task 4, Epoch 52/130 => Loss 21.553,  Loss1 0.543, Train_accy 81.98
2024-08-31 14:47:17,286 [foster.py] => SNet: Task 4, Epoch 53/130 => Loss 21.534,  Loss1 0.542, Train_accy 82.64
2024-08-31 14:47:24,759 [foster.py] => SNet: Task 4, Epoch 54/130 => Loss 21.519,  Loss1 0.543, Train_accy 82.00
2024-08-31 14:47:32,092 [foster.py] => SNet: Task 4, Epoch 55/130 => Loss 21.544,  Loss1 0.543, Train_accy 82.71
2024-08-31 14:47:40,735 [foster.py] => SNet: Task 4, Epoch 56/130 => Loss 21.528,  Loss1 0.542, Train_accy 82.78, Test_accy 79.60
2024-08-31 14:47:48,031 [foster.py] => SNet: Task 4, Epoch 57/130 => Loss 21.521,  Loss1 0.543, Train_accy 80.98
2024-08-31 14:47:55,518 [foster.py] => SNet: Task 4, Epoch 58/130 => Loss 21.550,  Loss1 0.542, Train_accy 82.42
2024-08-31 14:48:02,946 [foster.py] => SNet: Task 4, Epoch 59/130 => Loss 21.524,  Loss1 0.543, Train_accy 83.64
2024-08-31 14:48:10,388 [foster.py] => SNet: Task 4, Epoch 60/130 => Loss 21.551,  Loss1 0.543, Train_accy 82.07
2024-08-31 14:48:18,926 [foster.py] => SNet: Task 4, Epoch 61/130 => Loss 21.534,  Loss1 0.543, Train_accy 82.78, Test_accy 79.20
2024-08-31 14:48:26,199 [foster.py] => SNet: Task 4, Epoch 62/130 => Loss 21.533,  Loss1 0.543, Train_accy 83.00
2024-08-31 14:48:33,738 [foster.py] => SNet: Task 4, Epoch 63/130 => Loss 21.569,  Loss1 0.543, Train_accy 82.78
2024-08-31 14:48:41,049 [foster.py] => SNet: Task 4, Epoch 64/130 => Loss 21.516,  Loss1 0.543, Train_accy 83.64
2024-08-31 14:48:48,340 [foster.py] => SNet: Task 4, Epoch 65/130 => Loss 21.517,  Loss1 0.542, Train_accy 83.29
2024-08-31 14:48:56,920 [foster.py] => SNet: Task 4, Epoch 66/130 => Loss 21.513,  Loss1 0.542, Train_accy 84.00, Test_accy 80.44
2024-08-31 14:49:04,687 [foster.py] => SNet: Task 4, Epoch 67/130 => Loss 21.524,  Loss1 0.543, Train_accy 83.62
2024-08-31 14:49:12,184 [foster.py] => SNet: Task 4, Epoch 68/130 => Loss 21.515,  Loss1 0.543, Train_accy 83.11
2024-08-31 14:49:19,466 [foster.py] => SNet: Task 4, Epoch 69/130 => Loss 21.516,  Loss1 0.543, Train_accy 84.04
2024-08-31 14:49:26,837 [foster.py] => SNet: Task 4, Epoch 70/130 => Loss 21.542,  Loss1 0.543, Train_accy 82.38
2024-08-31 14:49:35,712 [foster.py] => SNet: Task 4, Epoch 71/130 => Loss 21.501,  Loss1 0.543, Train_accy 83.62, Test_accy 79.80
2024-08-31 14:49:43,393 [foster.py] => SNet: Task 4, Epoch 72/130 => Loss 21.513,  Loss1 0.543, Train_accy 83.91
2024-08-31 14:49:50,853 [foster.py] => SNet: Task 4, Epoch 73/130 => Loss 21.501,  Loss1 0.542, Train_accy 84.58
2024-08-31 14:49:58,310 [foster.py] => SNet: Task 4, Epoch 74/130 => Loss 21.510,  Loss1 0.543, Train_accy 82.96
2024-08-31 14:50:05,601 [foster.py] => SNet: Task 4, Epoch 75/130 => Loss 21.523,  Loss1 0.543, Train_accy 83.40
2024-08-31 14:50:14,108 [foster.py] => SNet: Task 4, Epoch 76/130 => Loss 21.521,  Loss1 0.543, Train_accy 83.16, Test_accy 80.24
2024-08-31 14:50:21,537 [foster.py] => SNet: Task 4, Epoch 77/130 => Loss 21.509,  Loss1 0.542, Train_accy 83.33
2024-08-31 14:50:29,077 [foster.py] => SNet: Task 4, Epoch 78/130 => Loss 21.520,  Loss1 0.543, Train_accy 83.11
2024-08-31 14:50:36,346 [foster.py] => SNet: Task 4, Epoch 79/130 => Loss 21.528,  Loss1 0.543, Train_accy 83.42
2024-08-31 14:50:43,839 [foster.py] => SNet: Task 4, Epoch 80/130 => Loss 21.532,  Loss1 0.543, Train_accy 84.33
2024-08-31 14:50:52,365 [foster.py] => SNet: Task 4, Epoch 81/130 => Loss 21.512,  Loss1 0.543, Train_accy 83.84, Test_accy 80.56
2024-08-31 14:50:59,982 [foster.py] => SNet: Task 4, Epoch 82/130 => Loss 21.521,  Loss1 0.543, Train_accy 84.96
2024-08-31 14:51:07,330 [foster.py] => SNet: Task 4, Epoch 83/130 => Loss 21.492,  Loss1 0.542, Train_accy 83.93
2024-08-31 14:51:14,877 [foster.py] => SNet: Task 4, Epoch 84/130 => Loss 21.520,  Loss1 0.543, Train_accy 84.87
2024-08-31 14:51:22,168 [foster.py] => SNet: Task 4, Epoch 85/130 => Loss 21.517,  Loss1 0.543, Train_accy 83.62
2024-08-31 14:51:30,791 [foster.py] => SNet: Task 4, Epoch 86/130 => Loss 21.494,  Loss1 0.543, Train_accy 84.58, Test_accy 80.88
2024-08-31 14:51:38,070 [foster.py] => SNet: Task 4, Epoch 87/130 => Loss 21.506,  Loss1 0.543, Train_accy 84.56
2024-08-31 14:51:45,741 [foster.py] => SNet: Task 4, Epoch 88/130 => Loss 21.507,  Loss1 0.543, Train_accy 84.82
2024-08-31 14:51:53,130 [foster.py] => SNet: Task 4, Epoch 89/130 => Loss 21.508,  Loss1 0.543, Train_accy 83.91
2024-08-31 14:52:00,552 [foster.py] => SNet: Task 4, Epoch 90/130 => Loss 21.519,  Loss1 0.542, Train_accy 83.73
2024-08-31 14:52:09,038 [foster.py] => SNet: Task 4, Epoch 91/130 => Loss 21.497,  Loss1 0.542, Train_accy 85.16, Test_accy 81.44
2024-08-31 14:52:16,308 [foster.py] => SNet: Task 4, Epoch 92/130 => Loss 21.522,  Loss1 0.543, Train_accy 83.96
2024-08-31 14:52:23,845 [foster.py] => SNet: Task 4, Epoch 93/130 => Loss 21.477,  Loss1 0.543, Train_accy 84.18
2024-08-31 14:52:31,444 [foster.py] => SNet: Task 4, Epoch 94/130 => Loss 21.499,  Loss1 0.543, Train_accy 84.53
2024-08-31 14:52:38,878 [foster.py] => SNet: Task 4, Epoch 95/130 => Loss 21.519,  Loss1 0.543, Train_accy 84.22
2024-08-31 14:52:47,445 [foster.py] => SNet: Task 4, Epoch 96/130 => Loss 21.501,  Loss1 0.543, Train_accy 84.89, Test_accy 80.64
2024-08-31 14:52:54,939 [foster.py] => SNet: Task 4, Epoch 97/130 => Loss 21.504,  Loss1 0.543, Train_accy 84.44
2024-08-31 14:53:02,193 [foster.py] => SNet: Task 4, Epoch 98/130 => Loss 21.527,  Loss1 0.542, Train_accy 83.62
2024-08-31 14:53:09,501 [foster.py] => SNet: Task 4, Epoch 99/130 => Loss 21.500,  Loss1 0.543, Train_accy 84.73
2024-08-31 14:53:17,053 [foster.py] => SNet: Task 4, Epoch 100/130 => Loss 21.504,  Loss1 0.542, Train_accy 84.62
2024-08-31 14:53:25,519 [foster.py] => SNet: Task 4, Epoch 101/130 => Loss 21.502,  Loss1 0.543, Train_accy 84.24, Test_accy 80.84
2024-08-31 14:53:32,890 [foster.py] => SNet: Task 4, Epoch 102/130 => Loss 21.512,  Loss1 0.543, Train_accy 83.53
2024-08-31 14:53:40,117 [foster.py] => SNet: Task 4, Epoch 103/130 => Loss 21.506,  Loss1 0.543, Train_accy 84.07
2024-08-31 14:53:47,359 [foster.py] => SNet: Task 4, Epoch 104/130 => Loss 21.486,  Loss1 0.542, Train_accy 83.76
2024-08-31 14:53:54,802 [foster.py] => SNet: Task 4, Epoch 105/130 => Loss 21.517,  Loss1 0.543, Train_accy 83.96
2024-08-31 14:54:03,430 [foster.py] => SNet: Task 4, Epoch 106/130 => Loss 21.522,  Loss1 0.543, Train_accy 83.47, Test_accy 80.88
2024-08-31 14:54:10,917 [foster.py] => SNet: Task 4, Epoch 107/130 => Loss 21.515,  Loss1 0.542, Train_accy 83.80
2024-08-31 14:54:18,263 [foster.py] => SNet: Task 4, Epoch 108/130 => Loss 21.512,  Loss1 0.542, Train_accy 84.89
2024-08-31 14:54:25,585 [foster.py] => SNet: Task 4, Epoch 109/130 => Loss 21.514,  Loss1 0.542, Train_accy 84.53
2024-08-31 14:54:32,813 [foster.py] => SNet: Task 4, Epoch 110/130 => Loss 21.512,  Loss1 0.542, Train_accy 84.33
2024-08-31 14:54:41,592 [foster.py] => SNet: Task 4, Epoch 111/130 => Loss 21.506,  Loss1 0.543, Train_accy 84.44, Test_accy 81.48
2024-08-31 14:54:49,079 [foster.py] => SNet: Task 4, Epoch 112/130 => Loss 21.493,  Loss1 0.543, Train_accy 85.00
2024-08-31 14:54:56,581 [foster.py] => SNet: Task 4, Epoch 113/130 => Loss 21.516,  Loss1 0.543, Train_accy 84.18
2024-08-31 14:55:03,855 [foster.py] => SNet: Task 4, Epoch 114/130 => Loss 21.524,  Loss1 0.543, Train_accy 84.98
2024-08-31 14:55:11,205 [foster.py] => SNet: Task 4, Epoch 115/130 => Loss 21.513,  Loss1 0.543, Train_accy 84.53
2024-08-31 14:55:19,662 [foster.py] => SNet: Task 4, Epoch 116/130 => Loss 21.525,  Loss1 0.542, Train_accy 83.89, Test_accy 81.20
2024-08-31 14:55:27,015 [foster.py] => SNet: Task 4, Epoch 117/130 => Loss 21.494,  Loss1 0.543, Train_accy 84.24
2024-08-31 14:55:34,673 [foster.py] => SNet: Task 4, Epoch 118/130 => Loss 21.507,  Loss1 0.543, Train_accy 84.93
2024-08-31 14:55:41,899 [foster.py] => SNet: Task 4, Epoch 119/130 => Loss 21.526,  Loss1 0.543, Train_accy 84.36
2024-08-31 14:55:49,146 [foster.py] => SNet: Task 4, Epoch 120/130 => Loss 21.538,  Loss1 0.543, Train_accy 84.58
2024-08-31 14:55:57,660 [foster.py] => SNet: Task 4, Epoch 121/130 => Loss 21.513,  Loss1 0.543, Train_accy 85.20, Test_accy 81.08
2024-08-31 14:56:04,913 [foster.py] => SNet: Task 4, Epoch 122/130 => Loss 21.488,  Loss1 0.542, Train_accy 85.04
2024-08-31 14:56:12,283 [foster.py] => SNet: Task 4, Epoch 123/130 => Loss 21.509,  Loss1 0.543, Train_accy 84.42
2024-08-31 14:56:19,567 [foster.py] => SNet: Task 4, Epoch 124/130 => Loss 21.521,  Loss1 0.543, Train_accy 84.02
2024-08-31 14:56:27,173 [foster.py] => SNet: Task 4, Epoch 125/130 => Loss 21.512,  Loss1 0.543, Train_accy 83.91
2024-08-31 14:56:35,921 [foster.py] => SNet: Task 4, Epoch 126/130 => Loss 21.485,  Loss1 0.543, Train_accy 85.04, Test_accy 81.60
2024-08-31 14:56:43,499 [foster.py] => SNet: Task 4, Epoch 127/130 => Loss 21.518,  Loss1 0.542, Train_accy 84.18
2024-08-31 14:56:50,993 [foster.py] => SNet: Task 4, Epoch 128/130 => Loss 21.502,  Loss1 0.543, Train_accy 84.24
2024-08-31 14:56:58,254 [foster.py] => SNet: Task 4, Epoch 129/130 => Loss 21.510,  Loss1 0.543, Train_accy 84.49
2024-08-31 14:57:05,815 [foster.py] => SNet: Task 4, Epoch 130/130 => Loss 21.533,  Loss1 0.543, Train_accy 85.07
2024-08-31 14:57:05,816 [foster.py] => do not weight align student!
2024-08-31 14:57:07,020 [foster.py] => darknet eval: 
2024-08-31 14:57:07,020 [foster.py] => CNN top1 curve: 81.48
2024-08-31 14:57:07,020 [foster.py] => CNN top5 curve: 97.0
2024-08-31 14:57:07,020 [foster.py] => CNN top1 平均值: 81.48
2024-08-31 14:57:07,023 [foster.py] => timees : 2123.884856700897
2024-08-31 14:57:07,024 [base.py] => Reducing exemplars...(80 per classes)
2024-08-31 14:57:14,666 [base.py] => Constructing exemplars...(80 per classes)
2024-08-31 14:57:22,975 [foster.py] => Exemplar size: 2000
2024-08-31 14:57:22,975 [trainer.py] => CNN: {'total': 83.2, '00-09': 84.2, '10-19': 77.7, '20-29': 92.2, 'old': 80.95, 'new': 92.2}
2024-08-31 14:57:22,975 [trainer.py] => NME: {'total': 80.12, '00-09': 82.2, '10-19': 73.3, '20-29': 89.6, 'old': 77.75, 'new': 89.6}
2024-08-31 14:57:22,975 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2]
2024-08-31 14:57:22,976 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16]
2024-08-31 14:57:22,976 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12]
2024-08-31 14:57:22,976 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68]

2024-08-31 14:57:22,976 [trainer.py] => CNN top1 平均值: 89.58
2024-08-31 14:57:22,978 [trainer.py] => All params: 1288698
2024-08-31 14:57:22,981 [trainer.py] => Trainable params: 646124
2024-08-31 14:57:23,044 [foster.py] => Learning on 25-30
2024-08-31 14:57:23,047 [foster.py] => All params: 1289993
2024-08-31 14:57:23,049 [foster.py] => Trainable params: 647094
2024-08-31 14:57:23,094 [foster.py] => per cls weights : [1.0170789  1.0170789  1.0170789  1.0170789  1.0170789  1.0170789
 1.0170789  1.0170789  1.0170789  1.0170789  1.0170789  1.0170789
 1.0170789  1.0170789  1.0170789  1.0170789  1.0170789  1.0170789
 1.0170789  1.0170789  1.0170789  1.0170789  1.0170789  1.0170789
 1.0170789  0.91460551 0.91460551 0.91460551 0.91460551 0.91460551]
2024-08-31 14:57:28,592 [foster.py] => Task 5, Epoch 1/170 => Loss 4.808, Loss_clf 1.336, Loss_fe 1.656, Loss_kd 1.510, Train_accy 61.44
2024-08-31 14:57:35,695 [foster.py] => Task 5, Epoch 2/170 => Loss 3.898, Loss_clf 0.912, Loss_fe 1.190, Loss_kd 1.492, Train_accy 71.69, Test_accy 72.83
2024-08-31 14:57:42,850 [foster.py] => Task 5, Epoch 3/170 => Loss 3.809, Loss_clf 0.880, Loss_fe 1.115, Loss_kd 1.508, Train_accy 72.16, Test_accy 70.00
2024-08-31 14:57:49,957 [foster.py] => Task 5, Epoch 4/170 => Loss 3.743, Loss_clf 0.858, Loss_fe 1.088, Loss_kd 1.493, Train_accy 73.40, Test_accy 74.53
2024-08-31 14:57:57,107 [foster.py] => Task 5, Epoch 5/170 => Loss 3.776, Loss_clf 0.916, Loss_fe 1.057, Loss_kd 1.499, Train_accy 71.64, Test_accy 72.20
2024-08-31 14:58:02,581 [foster.py] => Task 5, Epoch 6/170 => Loss 3.714, Loss_clf 0.875, Loss_fe 1.030, Loss_kd 1.504, Train_accy 72.27
2024-08-31 14:58:09,589 [foster.py] => Task 5, Epoch 7/170 => Loss 3.575, Loss_clf 0.817, Loss_fe 0.959, Loss_kd 1.496, Train_accy 75.53, Test_accy 70.70
2024-08-31 14:58:16,548 [foster.py] => Task 5, Epoch 8/170 => Loss 3.653, Loss_clf 0.848, Loss_fe 1.006, Loss_kd 1.496, Train_accy 73.96, Test_accy 73.47
2024-08-31 14:58:23,558 [foster.py] => Task 5, Epoch 9/170 => Loss 3.658, Loss_clf 0.868, Loss_fe 1.001, Loss_kd 1.487, Train_accy 72.91, Test_accy 75.53
2024-08-31 14:58:30,678 [foster.py] => Task 5, Epoch 10/170 => Loss 3.604, Loss_clf 0.825, Loss_fe 0.977, Loss_kd 1.498, Train_accy 74.24, Test_accy 75.13
2024-08-31 14:58:36,150 [foster.py] => Task 5, Epoch 11/170 => Loss 3.653, Loss_clf 0.854, Loss_fe 1.003, Loss_kd 1.494, Train_accy 72.93
2024-08-31 14:58:43,236 [foster.py] => Task 5, Epoch 12/170 => Loss 3.585, Loss_clf 0.838, Loss_fe 0.952, Loss_kd 1.492, Train_accy 73.78, Test_accy 73.93
2024-08-31 14:58:50,199 [foster.py] => Task 5, Epoch 13/170 => Loss 3.603, Loss_clf 0.836, Loss_fe 0.976, Loss_kd 1.489, Train_accy 73.44, Test_accy 77.07
2024-08-31 14:58:57,234 [foster.py] => Task 5, Epoch 14/170 => Loss 3.600, Loss_clf 0.818, Loss_fe 0.979, Loss_kd 1.499, Train_accy 74.87, Test_accy 76.27
2024-08-31 14:59:04,340 [foster.py] => Task 5, Epoch 15/170 => Loss 3.638, Loss_clf 0.853, Loss_fe 0.990, Loss_kd 1.493, Train_accy 73.16, Test_accy 75.77
2024-08-31 14:59:09,766 [foster.py] => Task 5, Epoch 16/170 => Loss 3.575, Loss_clf 0.819, Loss_fe 0.960, Loss_kd 1.494, Train_accy 74.29
2024-08-31 14:59:16,793 [foster.py] => Task 5, Epoch 17/170 => Loss 3.646, Loss_clf 0.851, Loss_fe 0.993, Loss_kd 1.498, Train_accy 73.78, Test_accy 76.07
2024-08-31 14:59:23,786 [foster.py] => Task 5, Epoch 18/170 => Loss 3.617, Loss_clf 0.843, Loss_fe 0.976, Loss_kd 1.495, Train_accy 74.16, Test_accy 72.53
2024-08-31 14:59:30,918 [foster.py] => Task 5, Epoch 19/170 => Loss 3.575, Loss_clf 0.807, Loss_fe 0.979, Loss_kd 1.488, Train_accy 75.20, Test_accy 72.37
2024-08-31 14:59:37,978 [foster.py] => Task 5, Epoch 20/170 => Loss 3.583, Loss_clf 0.799, Loss_fe 0.980, Loss_kd 1.500, Train_accy 75.02, Test_accy 66.37
2024-08-31 14:59:43,362 [foster.py] => Task 5, Epoch 21/170 => Loss 3.625, Loss_clf 0.850, Loss_fe 0.974, Loss_kd 1.498, Train_accy 74.11
2024-08-31 14:59:50,444 [foster.py] => Task 5, Epoch 22/170 => Loss 3.675, Loss_clf 0.847, Loss_fe 1.000, Loss_kd 1.520, Train_accy 73.84, Test_accy 76.93
2024-08-31 14:59:57,523 [foster.py] => Task 5, Epoch 23/170 => Loss 3.554, Loss_clf 0.800, Loss_fe 0.948, Loss_kd 1.502, Train_accy 75.36, Test_accy 75.07
2024-08-31 15:00:04,566 [foster.py] => Task 5, Epoch 24/170 => Loss 3.588, Loss_clf 0.830, Loss_fe 0.958, Loss_kd 1.498, Train_accy 74.29, Test_accy 74.37
2024-08-31 15:00:11,599 [foster.py] => Task 5, Epoch 25/170 => Loss 3.509, Loss_clf 0.787, Loss_fe 0.937, Loss_kd 1.485, Train_accy 75.80, Test_accy 75.60
2024-08-31 15:00:17,034 [foster.py] => Task 5, Epoch 26/170 => Loss 3.528, Loss_clf 0.795, Loss_fe 0.946, Loss_kd 1.487, Train_accy 74.98
2024-08-31 15:00:24,031 [foster.py] => Task 5, Epoch 27/170 => Loss 3.562, Loss_clf 0.819, Loss_fe 0.958, Loss_kd 1.485, Train_accy 74.53, Test_accy 70.80
2024-08-31 15:00:31,014 [foster.py] => Task 5, Epoch 28/170 => Loss 3.625, Loss_clf 0.837, Loss_fe 0.997, Loss_kd 1.490, Train_accy 74.76, Test_accy 74.87
2024-08-31 15:00:38,075 [foster.py] => Task 5, Epoch 29/170 => Loss 3.606, Loss_clf 0.814, Loss_fe 0.998, Loss_kd 1.493, Train_accy 74.36, Test_accy 75.77
2024-08-31 15:00:45,235 [foster.py] => Task 5, Epoch 30/170 => Loss 3.556, Loss_clf 0.829, Loss_fe 0.937, Loss_kd 1.488, Train_accy 74.09, Test_accy 75.80
2024-08-31 15:00:50,711 [foster.py] => Task 5, Epoch 31/170 => Loss 3.555, Loss_clf 0.802, Loss_fe 0.972, Loss_kd 1.481, Train_accy 74.73
2024-08-31 15:00:57,759 [foster.py] => Task 5, Epoch 32/170 => Loss 3.574, Loss_clf 0.817, Loss_fe 0.953, Loss_kd 1.500, Train_accy 74.53, Test_accy 75.30
2024-08-31 15:01:04,735 [foster.py] => Task 5, Epoch 33/170 => Loss 3.652, Loss_clf 0.827, Loss_fe 1.011, Loss_kd 1.509, Train_accy 74.56, Test_accy 76.20
2024-08-31 15:01:11,720 [foster.py] => Task 5, Epoch 34/170 => Loss 3.538, Loss_clf 0.799, Loss_fe 0.947, Loss_kd 1.490, Train_accy 75.22, Test_accy 75.00
2024-08-31 15:01:18,725 [foster.py] => Task 5, Epoch 35/170 => Loss 3.558, Loss_clf 0.826, Loss_fe 0.925, Loss_kd 1.503, Train_accy 74.82, Test_accy 73.30
2024-08-31 15:01:24,150 [foster.py] => Task 5, Epoch 36/170 => Loss 3.545, Loss_clf 0.809, Loss_fe 0.935, Loss_kd 1.498, Train_accy 75.31
2024-08-31 15:01:31,092 [foster.py] => Task 5, Epoch 37/170 => Loss 3.561, Loss_clf 0.812, Loss_fe 0.927, Loss_kd 1.515, Train_accy 74.82, Test_accy 76.07
2024-08-31 15:01:38,239 [foster.py] => Task 5, Epoch 38/170 => Loss 3.519, Loss_clf 0.806, Loss_fe 0.899, Loss_kd 1.509, Train_accy 75.02, Test_accy 75.20
2024-08-31 15:01:45,256 [foster.py] => Task 5, Epoch 39/170 => Loss 3.478, Loss_clf 0.784, Loss_fe 0.894, Loss_kd 1.497, Train_accy 74.98, Test_accy 74.27
2024-08-31 15:01:52,255 [foster.py] => Task 5, Epoch 40/170 => Loss 3.514, Loss_clf 0.770, Loss_fe 0.956, Loss_kd 1.487, Train_accy 75.93, Test_accy 75.70
2024-08-31 15:01:57,739 [foster.py] => Task 5, Epoch 41/170 => Loss 3.581, Loss_clf 0.828, Loss_fe 0.953, Loss_kd 1.498, Train_accy 74.38
2024-08-31 15:02:04,795 [foster.py] => Task 5, Epoch 42/170 => Loss 3.545, Loss_clf 0.827, Loss_fe 0.919, Loss_kd 1.496, Train_accy 74.96, Test_accy 68.80
2024-08-31 15:02:11,853 [foster.py] => Task 5, Epoch 43/170 => Loss 3.604, Loss_clf 0.844, Loss_fe 0.953, Loss_kd 1.503, Train_accy 74.29, Test_accy 74.33
2024-08-31 15:02:18,860 [foster.py] => Task 5, Epoch 44/170 => Loss 3.566, Loss_clf 0.826, Loss_fe 0.943, Loss_kd 1.494, Train_accy 74.64, Test_accy 74.83
2024-08-31 15:02:25,817 [foster.py] => Task 5, Epoch 45/170 => Loss 3.529, Loss_clf 0.829, Loss_fe 0.899, Loss_kd 1.498, Train_accy 74.16, Test_accy 73.33
2024-08-31 15:02:31,386 [foster.py] => Task 5, Epoch 46/170 => Loss 3.529, Loss_clf 0.820, Loss_fe 0.921, Loss_kd 1.487, Train_accy 75.16
2024-08-31 15:02:38,400 [foster.py] => Task 5, Epoch 47/170 => Loss 3.563, Loss_clf 0.811, Loss_fe 0.945, Loss_kd 1.503, Train_accy 74.87, Test_accy 73.83
2024-08-31 15:02:45,391 [foster.py] => Task 5, Epoch 48/170 => Loss 3.456, Loss_clf 0.796, Loss_fe 0.880, Loss_kd 1.481, Train_accy 75.91, Test_accy 73.43
2024-08-31 15:02:52,439 [foster.py] => Task 5, Epoch 49/170 => Loss 3.491, Loss_clf 0.792, Loss_fe 0.897, Loss_kd 1.499, Train_accy 75.22, Test_accy 75.70
2024-08-31 15:02:59,546 [foster.py] => Task 5, Epoch 50/170 => Loss 3.512, Loss_clf 0.793, Loss_fe 0.897, Loss_kd 1.516, Train_accy 75.27, Test_accy 75.40
2024-08-31 15:03:05,028 [foster.py] => Task 5, Epoch 51/170 => Loss 3.459, Loss_clf 0.774, Loss_fe 0.885, Loss_kd 1.498, Train_accy 76.49
2024-08-31 15:03:12,032 [foster.py] => Task 5, Epoch 52/170 => Loss 3.444, Loss_clf 0.780, Loss_fe 0.884, Loss_kd 1.481, Train_accy 76.24, Test_accy 77.40
2024-08-31 15:03:19,010 [foster.py] => Task 5, Epoch 53/170 => Loss 3.515, Loss_clf 0.784, Loss_fe 0.923, Loss_kd 1.504, Train_accy 75.62, Test_accy 76.73
2024-08-31 15:03:26,096 [foster.py] => Task 5, Epoch 54/170 => Loss 3.476, Loss_clf 0.762, Loss_fe 0.919, Loss_kd 1.494, Train_accy 76.36, Test_accy 75.80
2024-08-31 15:03:33,114 [foster.py] => Task 5, Epoch 55/170 => Loss 3.466, Loss_clf 0.780, Loss_fe 0.874, Loss_kd 1.507, Train_accy 75.98, Test_accy 75.00
2024-08-31 15:03:38,581 [foster.py] => Task 5, Epoch 56/170 => Loss 3.433, Loss_clf 0.774, Loss_fe 0.859, Loss_kd 1.497, Train_accy 75.51
2024-08-31 15:03:45,584 [foster.py] => Task 5, Epoch 57/170 => Loss 3.446, Loss_clf 0.783, Loss_fe 0.864, Loss_kd 1.496, Train_accy 76.33, Test_accy 76.40
2024-08-31 15:03:52,615 [foster.py] => Task 5, Epoch 58/170 => Loss 3.392, Loss_clf 0.743, Loss_fe 0.857, Loss_kd 1.490, Train_accy 76.69, Test_accy 70.90
2024-08-31 15:03:59,570 [foster.py] => Task 5, Epoch 59/170 => Loss 3.426, Loss_clf 0.768, Loss_fe 0.856, Loss_kd 1.498, Train_accy 76.20, Test_accy 75.93
2024-08-31 15:04:06,683 [foster.py] => Task 5, Epoch 60/170 => Loss 3.473, Loss_clf 0.789, Loss_fe 0.893, Loss_kd 1.490, Train_accy 75.27, Test_accy 74.17
2024-08-31 15:04:12,170 [foster.py] => Task 5, Epoch 61/170 => Loss 3.370, Loss_clf 0.756, Loss_fe 0.824, Loss_kd 1.489, Train_accy 76.67
2024-08-31 15:04:19,351 [foster.py] => Task 5, Epoch 62/170 => Loss 3.491, Loss_clf 0.808, Loss_fe 0.869, Loss_kd 1.509, Train_accy 74.76, Test_accy 68.57
2024-08-31 15:04:26,443 [foster.py] => Task 5, Epoch 63/170 => Loss 3.435, Loss_clf 0.768, Loss_fe 0.866, Loss_kd 1.497, Train_accy 76.53, Test_accy 73.83
2024-08-31 15:04:33,738 [foster.py] => Task 5, Epoch 64/170 => Loss 3.386, Loss_clf 0.753, Loss_fe 0.835, Loss_kd 1.495, Train_accy 75.71, Test_accy 75.30
2024-08-31 15:04:41,093 [foster.py] => Task 5, Epoch 65/170 => Loss 3.343, Loss_clf 0.723, Loss_fe 0.829, Loss_kd 1.489, Train_accy 78.09, Test_accy 75.37
2024-08-31 15:04:46,777 [foster.py] => Task 5, Epoch 66/170 => Loss 3.469, Loss_clf 0.776, Loss_fe 0.891, Loss_kd 1.499, Train_accy 76.18
2024-08-31 15:04:53,842 [foster.py] => Task 5, Epoch 67/170 => Loss 3.459, Loss_clf 0.780, Loss_fe 0.865, Loss_kd 1.509, Train_accy 76.20, Test_accy 76.27
2024-08-31 15:05:00,805 [foster.py] => Task 5, Epoch 68/170 => Loss 3.281, Loss_clf 0.712, Loss_fe 0.786, Loss_kd 1.483, Train_accy 78.02, Test_accy 76.07
2024-08-31 15:05:07,848 [foster.py] => Task 5, Epoch 69/170 => Loss 3.387, Loss_clf 0.753, Loss_fe 0.833, Loss_kd 1.498, Train_accy 76.27, Test_accy 75.43
2024-08-31 15:05:14,894 [foster.py] => Task 5, Epoch 70/170 => Loss 3.395, Loss_clf 0.756, Loss_fe 0.836, Loss_kd 1.499, Train_accy 76.80, Test_accy 76.97
2024-08-31 15:05:20,329 [foster.py] => Task 5, Epoch 71/170 => Loss 3.304, Loss_clf 0.712, Loss_fe 0.794, Loss_kd 1.496, Train_accy 77.09
2024-08-31 15:05:27,337 [foster.py] => Task 5, Epoch 72/170 => Loss 3.303, Loss_clf 0.714, Loss_fe 0.801, Loss_kd 1.488, Train_accy 78.09, Test_accy 77.03
2024-08-31 15:05:34,429 [foster.py] => Task 5, Epoch 73/170 => Loss 3.331, Loss_clf 0.728, Loss_fe 0.803, Loss_kd 1.497, Train_accy 77.62, Test_accy 75.53
2024-08-31 15:05:41,493 [foster.py] => Task 5, Epoch 74/170 => Loss 3.320, Loss_clf 0.721, Loss_fe 0.790, Loss_kd 1.504, Train_accy 77.98, Test_accy 76.43
2024-08-31 15:05:48,591 [foster.py] => Task 5, Epoch 75/170 => Loss 3.361, Loss_clf 0.729, Loss_fe 0.834, Loss_kd 1.496, Train_accy 77.87, Test_accy 75.43
2024-08-31 15:05:54,115 [foster.py] => Task 5, Epoch 76/170 => Loss 3.349, Loss_clf 0.733, Loss_fe 0.817, Loss_kd 1.496, Train_accy 77.40
2024-08-31 15:06:01,147 [foster.py] => Task 5, Epoch 77/170 => Loss 3.335, Loss_clf 0.753, Loss_fe 0.773, Loss_kd 1.505, Train_accy 76.91, Test_accy 75.33
2024-08-31 15:06:08,238 [foster.py] => Task 5, Epoch 78/170 => Loss 3.265, Loss_clf 0.695, Loss_fe 0.778, Loss_kd 1.490, Train_accy 78.56, Test_accy 76.10
2024-08-31 15:06:15,212 [foster.py] => Task 5, Epoch 79/170 => Loss 3.316, Loss_clf 0.743, Loss_fe 0.783, Loss_kd 1.489, Train_accy 77.42, Test_accy 78.60
2024-08-31 15:06:22,286 [foster.py] => Task 5, Epoch 80/170 => Loss 3.320, Loss_clf 0.729, Loss_fe 0.789, Loss_kd 1.498, Train_accy 76.69, Test_accy 76.80
2024-08-31 15:06:27,714 [foster.py] => Task 5, Epoch 81/170 => Loss 3.284, Loss_clf 0.716, Loss_fe 0.773, Loss_kd 1.493, Train_accy 78.11
2024-08-31 15:06:34,771 [foster.py] => Task 5, Epoch 82/170 => Loss 3.207, Loss_clf 0.686, Loss_fe 0.731, Loss_kd 1.489, Train_accy 78.27, Test_accy 77.70
2024-08-31 15:06:41,750 [foster.py] => Task 5, Epoch 83/170 => Loss 3.244, Loss_clf 0.718, Loss_fe 0.735, Loss_kd 1.490, Train_accy 78.04, Test_accy 78.03
2024-08-31 15:06:48,776 [foster.py] => Task 5, Epoch 84/170 => Loss 3.215, Loss_clf 0.688, Loss_fe 0.740, Loss_kd 1.486, Train_accy 78.82, Test_accy 77.90
2024-08-31 15:06:55,786 [foster.py] => Task 5, Epoch 85/170 => Loss 3.212, Loss_clf 0.680, Loss_fe 0.739, Loss_kd 1.491, Train_accy 79.04, Test_accy 77.67
2024-08-31 15:07:01,262 [foster.py] => Task 5, Epoch 86/170 => Loss 3.319, Loss_clf 0.742, Loss_fe 0.773, Loss_kd 1.501, Train_accy 77.62
2024-08-31 15:07:08,260 [foster.py] => Task 5, Epoch 87/170 => Loss 3.270, Loss_clf 0.712, Loss_fe 0.755, Loss_kd 1.499, Train_accy 77.44, Test_accy 75.67
2024-08-31 15:07:15,291 [foster.py] => Task 5, Epoch 88/170 => Loss 3.171, Loss_clf 0.677, Loss_fe 0.711, Loss_kd 1.484, Train_accy 79.11, Test_accy 76.63
2024-08-31 15:07:22,367 [foster.py] => Task 5, Epoch 89/170 => Loss 3.207, Loss_clf 0.694, Loss_fe 0.724, Loss_kd 1.488, Train_accy 78.47, Test_accy 76.00
2024-08-31 15:07:29,391 [foster.py] => Task 5, Epoch 90/170 => Loss 3.172, Loss_clf 0.670, Loss_fe 0.707, Loss_kd 1.493, Train_accy 78.96, Test_accy 75.60
2024-08-31 15:07:34,833 [foster.py] => Task 5, Epoch 91/170 => Loss 3.202, Loss_clf 0.693, Loss_fe 0.718, Loss_kd 1.489, Train_accy 78.60
2024-08-31 15:07:41,878 [foster.py] => Task 5, Epoch 92/170 => Loss 3.216, Loss_clf 0.721, Loss_fe 0.696, Loss_kd 1.496, Train_accy 78.53, Test_accy 76.90
2024-08-31 15:07:48,853 [foster.py] => Task 5, Epoch 93/170 => Loss 3.153, Loss_clf 0.665, Loss_fe 0.693, Loss_kd 1.493, Train_accy 80.16, Test_accy 78.57
2024-08-31 15:07:55,868 [foster.py] => Task 5, Epoch 94/170 => Loss 3.199, Loss_clf 0.686, Loss_fe 0.713, Loss_kd 1.497, Train_accy 79.20, Test_accy 76.83
2024-08-31 15:08:02,866 [foster.py] => Task 5, Epoch 95/170 => Loss 3.204, Loss_clf 0.689, Loss_fe 0.717, Loss_kd 1.496, Train_accy 78.91, Test_accy 69.77
2024-08-31 15:08:08,337 [foster.py] => Task 5, Epoch 96/170 => Loss 3.225, Loss_clf 0.691, Loss_fe 0.728, Loss_kd 1.502, Train_accy 78.51
2024-08-31 15:08:15,477 [foster.py] => Task 5, Epoch 97/170 => Loss 3.156, Loss_clf 0.658, Loss_fe 0.715, Loss_kd 1.483, Train_accy 79.67, Test_accy 78.37
2024-08-31 15:08:22,451 [foster.py] => Task 5, Epoch 98/170 => Loss 3.159, Loss_clf 0.676, Loss_fe 0.691, Loss_kd 1.490, Train_accy 78.69, Test_accy 76.97
2024-08-31 15:08:29,505 [foster.py] => Task 5, Epoch 99/170 => Loss 3.094, Loss_clf 0.659, Loss_fe 0.647, Loss_kd 1.487, Train_accy 79.51, Test_accy 77.43
2024-08-31 15:08:36,524 [foster.py] => Task 5, Epoch 100/170 => Loss 3.123, Loss_clf 0.657, Loss_fe 0.669, Loss_kd 1.495, Train_accy 80.09, Test_accy 73.67
2024-08-31 15:08:42,073 [foster.py] => Task 5, Epoch 101/170 => Loss 3.178, Loss_clf 0.683, Loss_fe 0.710, Loss_kd 1.484, Train_accy 79.09
2024-08-31 15:08:49,175 [foster.py] => Task 5, Epoch 102/170 => Loss 3.100, Loss_clf 0.648, Loss_fe 0.667, Loss_kd 1.485, Train_accy 80.02, Test_accy 77.50
2024-08-31 15:08:56,170 [foster.py] => Task 5, Epoch 103/170 => Loss 3.091, Loss_clf 0.654, Loss_fe 0.640, Loss_kd 1.495, Train_accy 80.38, Test_accy 78.47
2024-08-31 15:09:03,303 [foster.py] => Task 5, Epoch 104/170 => Loss 3.099, Loss_clf 0.656, Loss_fe 0.638, Loss_kd 1.501, Train_accy 80.22, Test_accy 77.93
2024-08-31 15:09:10,385 [foster.py] => Task 5, Epoch 105/170 => Loss 3.098, Loss_clf 0.650, Loss_fe 0.647, Loss_kd 1.497, Train_accy 80.60, Test_accy 76.73
2024-08-31 15:09:15,993 [foster.py] => Task 5, Epoch 106/170 => Loss 3.086, Loss_clf 0.648, Loss_fe 0.651, Loss_kd 1.487, Train_accy 80.40
2024-08-31 15:09:23,085 [foster.py] => Task 5, Epoch 107/170 => Loss 3.140, Loss_clf 0.679, Loss_fe 0.656, Loss_kd 1.502, Train_accy 79.73, Test_accy 78.90
2024-08-31 15:09:30,232 [foster.py] => Task 5, Epoch 108/170 => Loss 3.051, Loss_clf 0.630, Loss_fe 0.634, Loss_kd 1.487, Train_accy 81.11, Test_accy 78.40
2024-08-31 15:09:37,246 [foster.py] => Task 5, Epoch 109/170 => Loss 3.003, Loss_clf 0.604, Loss_fe 0.600, Loss_kd 1.496, Train_accy 81.20, Test_accy 77.80
2024-08-31 15:09:44,254 [foster.py] => Task 5, Epoch 110/170 => Loss 2.992, Loss_clf 0.618, Loss_fe 0.589, Loss_kd 1.485, Train_accy 81.42, Test_accy 78.07
2024-08-31 15:09:49,692 [foster.py] => Task 5, Epoch 111/170 => Loss 3.034, Loss_clf 0.629, Loss_fe 0.615, Loss_kd 1.489, Train_accy 80.53
2024-08-31 15:09:56,775 [foster.py] => Task 5, Epoch 112/170 => Loss 3.023, Loss_clf 0.611, Loss_fe 0.611, Loss_kd 1.498, Train_accy 81.67, Test_accy 77.33
2024-08-31 15:10:04,017 [foster.py] => Task 5, Epoch 113/170 => Loss 3.091, Loss_clf 0.650, Loss_fe 0.640, Loss_kd 1.497, Train_accy 79.82, Test_accy 77.70
2024-08-31 15:10:11,123 [foster.py] => Task 5, Epoch 114/170 => Loss 3.018, Loss_clf 0.627, Loss_fe 0.595, Loss_kd 1.494, Train_accy 81.11, Test_accy 78.27
2024-08-31 15:10:18,231 [foster.py] => Task 5, Epoch 115/170 => Loss 3.088, Loss_clf 0.650, Loss_fe 0.642, Loss_kd 1.493, Train_accy 79.96, Test_accy 77.50
2024-08-31 15:10:23,708 [foster.py] => Task 5, Epoch 116/170 => Loss 3.028, Loss_clf 0.623, Loss_fe 0.596, Loss_kd 1.505, Train_accy 81.64
2024-08-31 15:10:30,718 [foster.py] => Task 5, Epoch 117/170 => Loss 3.023, Loss_clf 0.630, Loss_fe 0.596, Loss_kd 1.494, Train_accy 81.67, Test_accy 75.50
2024-08-31 15:10:37,746 [foster.py] => Task 5, Epoch 118/170 => Loss 3.037, Loss_clf 0.613, Loss_fe 0.627, Loss_kd 1.495, Train_accy 81.87, Test_accy 79.37
2024-08-31 15:10:44,833 [foster.py] => Task 5, Epoch 119/170 => Loss 2.994, Loss_clf 0.616, Loss_fe 0.585, Loss_kd 1.492, Train_accy 80.98, Test_accy 78.20
2024-08-31 15:10:51,811 [foster.py] => Task 5, Epoch 120/170 => Loss 2.928, Loss_clf 0.590, Loss_fe 0.556, Loss_kd 1.482, Train_accy 82.20, Test_accy 77.23
2024-08-31 15:10:57,271 [foster.py] => Task 5, Epoch 121/170 => Loss 2.969, Loss_clf 0.611, Loss_fe 0.551, Loss_kd 1.502, Train_accy 81.47
2024-08-31 15:11:04,229 [foster.py] => Task 5, Epoch 122/170 => Loss 2.955, Loss_clf 0.612, Loss_fe 0.550, Loss_kd 1.492, Train_accy 81.58, Test_accy 78.47
2024-08-31 15:11:11,220 [foster.py] => Task 5, Epoch 123/170 => Loss 2.908, Loss_clf 0.586, Loss_fe 0.546, Loss_kd 1.477, Train_accy 82.38, Test_accy 78.83
2024-08-31 15:11:18,214 [foster.py] => Task 5, Epoch 124/170 => Loss 2.849, Loss_clf 0.561, Loss_fe 0.508, Loss_kd 1.480, Train_accy 83.18, Test_accy 78.77
2024-08-31 15:11:25,240 [foster.py] => Task 5, Epoch 125/170 => Loss 2.902, Loss_clf 0.585, Loss_fe 0.523, Loss_kd 1.493, Train_accy 82.11, Test_accy 77.33
2024-08-31 15:11:30,684 [foster.py] => Task 5, Epoch 126/170 => Loss 2.860, Loss_clf 0.556, Loss_fe 0.513, Loss_kd 1.490, Train_accy 83.53
2024-08-31 15:11:37,652 [foster.py] => Task 5, Epoch 127/170 => Loss 2.871, Loss_clf 0.567, Loss_fe 0.496, Loss_kd 1.505, Train_accy 83.00, Test_accy 78.53
2024-08-31 15:11:44,686 [foster.py] => Task 5, Epoch 128/170 => Loss 2.818, Loss_clf 0.552, Loss_fe 0.488, Loss_kd 1.478, Train_accy 83.62, Test_accy 79.13
2024-08-31 15:11:51,848 [foster.py] => Task 5, Epoch 129/170 => Loss 2.821, Loss_clf 0.544, Loss_fe 0.498, Loss_kd 1.479, Train_accy 83.40, Test_accy 78.77
2024-08-31 15:11:58,849 [foster.py] => Task 5, Epoch 130/170 => Loss 2.802, Loss_clf 0.540, Loss_fe 0.479, Loss_kd 1.483, Train_accy 83.51, Test_accy 79.00
2024-08-31 15:12:04,291 [foster.py] => Task 5, Epoch 131/170 => Loss 2.820, Loss_clf 0.550, Loss_fe 0.474, Loss_kd 1.494, Train_accy 83.58
2024-08-31 15:12:11,287 [foster.py] => Task 5, Epoch 132/170 => Loss 2.807, Loss_clf 0.540, Loss_fe 0.469, Loss_kd 1.496, Train_accy 84.16, Test_accy 78.60
2024-08-31 15:12:18,312 [foster.py] => Task 5, Epoch 133/170 => Loss 2.853, Loss_clf 0.568, Loss_fe 0.489, Loss_kd 1.495, Train_accy 82.98, Test_accy 78.97
2024-08-31 15:12:25,393 [foster.py] => Task 5, Epoch 134/170 => Loss 2.736, Loss_clf 0.517, Loss_fe 0.437, Loss_kd 1.482, Train_accy 84.49, Test_accy 78.63
2024-08-31 15:12:32,511 [foster.py] => Task 5, Epoch 135/170 => Loss 2.767, Loss_clf 0.518, Loss_fe 0.452, Loss_kd 1.495, Train_accy 84.64, Test_accy 78.03
2024-08-31 15:12:37,968 [foster.py] => Task 5, Epoch 136/170 => Loss 2.807, Loss_clf 0.545, Loss_fe 0.461, Loss_kd 1.498, Train_accy 83.84
2024-08-31 15:12:44,961 [foster.py] => Task 5, Epoch 137/170 => Loss 2.777, Loss_clf 0.532, Loss_fe 0.449, Loss_kd 1.495, Train_accy 84.02, Test_accy 79.23
2024-08-31 15:12:52,036 [foster.py] => Task 5, Epoch 138/170 => Loss 2.811, Loss_clf 0.560, Loss_fe 0.453, Loss_kd 1.496, Train_accy 83.38, Test_accy 79.27
2024-08-31 15:12:59,156 [foster.py] => Task 5, Epoch 139/170 => Loss 2.726, Loss_clf 0.513, Loss_fe 0.421, Loss_kd 1.491, Train_accy 85.44, Test_accy 79.50
2024-08-31 15:13:06,293 [foster.py] => Task 5, Epoch 140/170 => Loss 2.714, Loss_clf 0.512, Loss_fe 0.417, Loss_kd 1.485, Train_accy 84.69, Test_accy 79.37
2024-08-31 15:13:11,686 [foster.py] => Task 5, Epoch 141/170 => Loss 2.709, Loss_clf 0.504, Loss_fe 0.408, Loss_kd 1.495, Train_accy 84.96
2024-08-31 15:13:18,780 [foster.py] => Task 5, Epoch 142/170 => Loss 2.680, Loss_clf 0.507, Loss_fe 0.391, Loss_kd 1.483, Train_accy 84.71, Test_accy 77.97
2024-08-31 15:13:25,788 [foster.py] => Task 5, Epoch 143/170 => Loss 2.694, Loss_clf 0.498, Loss_fe 0.404, Loss_kd 1.490, Train_accy 85.56, Test_accy 79.23
2024-08-31 15:13:32,840 [foster.py] => Task 5, Epoch 144/170 => Loss 2.726, Loss_clf 0.530, Loss_fe 0.406, Loss_kd 1.488, Train_accy 85.16, Test_accy 79.03
2024-08-31 15:13:39,837 [foster.py] => Task 5, Epoch 145/170 => Loss 2.651, Loss_clf 0.487, Loss_fe 0.374, Loss_kd 1.489, Train_accy 85.44, Test_accy 79.07
2024-08-31 15:13:45,402 [foster.py] => Task 5, Epoch 146/170 => Loss 2.685, Loss_clf 0.506, Loss_fe 0.395, Loss_kd 1.485, Train_accy 85.27
2024-08-31 15:13:52,385 [foster.py] => Task 5, Epoch 147/170 => Loss 2.675, Loss_clf 0.486, Loss_fe 0.378, Loss_kd 1.507, Train_accy 85.62, Test_accy 79.10
2024-08-31 15:13:59,458 [foster.py] => Task 5, Epoch 148/170 => Loss 2.678, Loss_clf 0.498, Loss_fe 0.396, Loss_kd 1.485, Train_accy 85.62, Test_accy 79.67
2024-08-31 15:14:06,580 [foster.py] => Task 5, Epoch 149/170 => Loss 2.632, Loss_clf 0.481, Loss_fe 0.369, Loss_kd 1.483, Train_accy 85.84, Test_accy 78.77
2024-08-31 15:14:13,593 [foster.py] => Task 5, Epoch 150/170 => Loss 2.643, Loss_clf 0.494, Loss_fe 0.361, Loss_kd 1.487, Train_accy 85.51, Test_accy 79.90
2024-08-31 15:14:19,006 [foster.py] => Task 5, Epoch 151/170 => Loss 2.624, Loss_clf 0.467, Loss_fe 0.364, Loss_kd 1.492, Train_accy 86.22
2024-08-31 15:14:26,020 [foster.py] => Task 5, Epoch 152/170 => Loss 2.617, Loss_clf 0.461, Loss_fe 0.352, Loss_kd 1.500, Train_accy 86.16, Test_accy 79.30
2024-08-31 15:14:33,120 [foster.py] => Task 5, Epoch 153/170 => Loss 2.650, Loss_clf 0.493, Loss_fe 0.363, Loss_kd 1.492, Train_accy 84.87, Test_accy 79.27
2024-08-31 15:14:40,254 [foster.py] => Task 5, Epoch 154/170 => Loss 2.580, Loss_clf 0.461, Loss_fe 0.329, Loss_kd 1.489, Train_accy 86.67, Test_accy 79.60
2024-08-31 15:14:47,319 [foster.py] => Task 5, Epoch 155/170 => Loss 2.588, Loss_clf 0.460, Loss_fe 0.338, Loss_kd 1.489, Train_accy 86.56, Test_accy 79.97
2024-08-31 15:14:52,831 [foster.py] => Task 5, Epoch 156/170 => Loss 2.630, Loss_clf 0.483, Loss_fe 0.340, Loss_kd 1.503, Train_accy 85.84
2024-08-31 15:14:59,847 [foster.py] => Task 5, Epoch 157/170 => Loss 2.600, Loss_clf 0.459, Loss_fe 0.339, Loss_kd 1.499, Train_accy 86.56, Test_accy 79.77
2024-08-31 15:15:06,884 [foster.py] => Task 5, Epoch 158/170 => Loss 2.599, Loss_clf 0.463, Loss_fe 0.333, Loss_kd 1.500, Train_accy 86.78, Test_accy 79.77
2024-08-31 15:15:13,820 [foster.py] => Task 5, Epoch 159/170 => Loss 2.616, Loss_clf 0.475, Loss_fe 0.342, Loss_kd 1.497, Train_accy 86.31, Test_accy 79.77
2024-08-31 15:15:20,830 [foster.py] => Task 5, Epoch 160/170 => Loss 2.583, Loss_clf 0.465, Loss_fe 0.328, Loss_kd 1.489, Train_accy 86.80, Test_accy 79.63
2024-08-31 15:15:26,207 [foster.py] => Task 5, Epoch 161/170 => Loss 2.562, Loss_clf 0.455, Loss_fe 0.325, Loss_kd 1.483, Train_accy 87.09
2024-08-31 15:15:33,261 [foster.py] => Task 5, Epoch 162/170 => Loss 2.587, Loss_clf 0.461, Loss_fe 0.329, Loss_kd 1.495, Train_accy 86.64, Test_accy 79.90
2024-08-31 15:15:40,274 [foster.py] => Task 5, Epoch 163/170 => Loss 2.594, Loss_clf 0.457, Loss_fe 0.347, Loss_kd 1.489, Train_accy 86.58, Test_accy 79.90
2024-08-31 15:15:47,326 [foster.py] => Task 5, Epoch 164/170 => Loss 2.588, Loss_clf 0.462, Loss_fe 0.324, Loss_kd 1.499, Train_accy 86.93, Test_accy 79.90
2024-08-31 15:15:54,350 [foster.py] => Task 5, Epoch 165/170 => Loss 2.570, Loss_clf 0.451, Loss_fe 0.319, Loss_kd 1.497, Train_accy 87.04, Test_accy 79.87
2024-08-31 15:15:59,839 [foster.py] => Task 5, Epoch 166/170 => Loss 2.584, Loss_clf 0.463, Loss_fe 0.336, Loss_kd 1.484, Train_accy 86.38
2024-08-31 15:16:06,884 [foster.py] => Task 5, Epoch 167/170 => Loss 2.555, Loss_clf 0.446, Loss_fe 0.320, Loss_kd 1.489, Train_accy 87.02, Test_accy 79.73
2024-08-31 15:16:13,852 [foster.py] => Task 5, Epoch 168/170 => Loss 2.562, Loss_clf 0.447, Loss_fe 0.323, Loss_kd 1.491, Train_accy 87.47, Test_accy 79.90
2024-08-31 15:16:20,948 [foster.py] => Task 5, Epoch 169/170 => Loss 2.602, Loss_clf 0.477, Loss_fe 0.326, Loss_kd 1.496, Train_accy 86.49, Test_accy 80.10
2024-08-31 15:16:28,011 [foster.py] => Task 5, Epoch 170/170 => Loss 2.535, Loss_clf 0.437, Loss_fe 0.306, Loss_kd 1.490, Train_accy 87.47, Test_accy 79.87
2024-08-31 15:16:28,014 [foster.py] => do not weight align teacher!
2024-08-31 15:16:28,016 [foster.py] => per cls weights : [1.02923102 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102
 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102
 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102
 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102 1.02923102
 1.02923102 0.85384488 0.85384488 0.85384488 0.85384488 0.85384488]
2024-08-31 15:16:37,215 [foster.py] => SNet: Task 5, Epoch 1/130 => Loss 23.139,  Loss1 0.584, Train_accy 54.87, Test_accy 69.37
2024-08-31 15:16:44,736 [foster.py] => SNet: Task 5, Epoch 2/130 => Loss 22.935,  Loss1 0.588, Train_accy 70.44
2024-08-31 15:16:52,116 [foster.py] => SNet: Task 5, Epoch 3/130 => Loss 22.904,  Loss1 0.588, Train_accy 71.69
2024-08-31 15:16:59,552 [foster.py] => SNet: Task 5, Epoch 4/130 => Loss 22.890,  Loss1 0.588, Train_accy 73.04
2024-08-31 15:17:07,072 [foster.py] => SNet: Task 5, Epoch 5/130 => Loss 22.903,  Loss1 0.588, Train_accy 73.38
2024-08-31 15:17:15,975 [foster.py] => SNet: Task 5, Epoch 6/130 => Loss 22.880,  Loss1 0.588, Train_accy 74.16, Test_accy 71.97
2024-08-31 15:17:23,518 [foster.py] => SNet: Task 5, Epoch 7/130 => Loss 22.876,  Loss1 0.589, Train_accy 75.58
2024-08-31 15:17:30,966 [foster.py] => SNet: Task 5, Epoch 8/130 => Loss 22.886,  Loss1 0.588, Train_accy 74.27
2024-08-31 15:17:38,234 [foster.py] => SNet: Task 5, Epoch 9/130 => Loss 22.858,  Loss1 0.589, Train_accy 76.40
2024-08-31 15:17:45,805 [foster.py] => SNet: Task 5, Epoch 10/130 => Loss 22.844,  Loss1 0.589, Train_accy 75.91
2024-08-31 15:17:54,414 [foster.py] => SNet: Task 5, Epoch 11/130 => Loss 22.893,  Loss1 0.588, Train_accy 75.51, Test_accy 73.30
2024-08-31 15:18:01,927 [foster.py] => SNet: Task 5, Epoch 12/130 => Loss 22.848,  Loss1 0.588, Train_accy 75.24
2024-08-31 15:18:09,182 [foster.py] => SNet: Task 5, Epoch 13/130 => Loss 22.858,  Loss1 0.589, Train_accy 76.93
2024-08-31 15:18:16,470 [foster.py] => SNet: Task 5, Epoch 14/130 => Loss 22.852,  Loss1 0.589, Train_accy 77.22
2024-08-31 15:18:23,792 [foster.py] => SNet: Task 5, Epoch 15/130 => Loss 22.840,  Loss1 0.588, Train_accy 76.87
2024-08-31 15:18:32,379 [foster.py] => SNet: Task 5, Epoch 16/130 => Loss 22.814,  Loss1 0.588, Train_accy 77.56, Test_accy 74.93
2024-08-31 15:18:39,676 [foster.py] => SNet: Task 5, Epoch 17/130 => Loss 22.833,  Loss1 0.588, Train_accy 77.49
2024-08-31 15:18:47,010 [foster.py] => SNet: Task 5, Epoch 18/130 => Loss 22.830,  Loss1 0.588, Train_accy 78.29
2024-08-31 15:18:54,396 [foster.py] => SNet: Task 5, Epoch 19/130 => Loss 22.839,  Loss1 0.588, Train_accy 77.13
2024-08-31 15:19:01,743 [foster.py] => SNet: Task 5, Epoch 20/130 => Loss 22.842,  Loss1 0.589, Train_accy 77.64
2024-08-31 15:19:10,605 [foster.py] => SNet: Task 5, Epoch 21/130 => Loss 22.874,  Loss1 0.588, Train_accy 77.91, Test_accy 75.47
2024-08-31 15:19:17,961 [foster.py] => SNet: Task 5, Epoch 22/130 => Loss 22.811,  Loss1 0.588, Train_accy 79.02
2024-08-31 15:19:25,351 [foster.py] => SNet: Task 5, Epoch 23/130 => Loss 22.833,  Loss1 0.589, Train_accy 78.73
2024-08-31 15:19:32,674 [foster.py] => SNet: Task 5, Epoch 24/130 => Loss 22.825,  Loss1 0.589, Train_accy 78.93
2024-08-31 15:19:40,236 [foster.py] => SNet: Task 5, Epoch 25/130 => Loss 22.810,  Loss1 0.588, Train_accy 80.22
2024-08-31 15:19:48,812 [foster.py] => SNet: Task 5, Epoch 26/130 => Loss 22.822,  Loss1 0.588, Train_accy 79.20, Test_accy 77.20
2024-08-31 15:19:56,158 [foster.py] => SNet: Task 5, Epoch 27/130 => Loss 22.815,  Loss1 0.589, Train_accy 79.78
2024-08-31 15:20:03,535 [foster.py] => SNet: Task 5, Epoch 28/130 => Loss 22.814,  Loss1 0.589, Train_accy 79.76
2024-08-31 15:20:10,855 [foster.py] => SNet: Task 5, Epoch 29/130 => Loss 22.821,  Loss1 0.589, Train_accy 79.53
2024-08-31 15:20:18,402 [foster.py] => SNet: Task 5, Epoch 30/130 => Loss 22.853,  Loss1 0.589, Train_accy 79.38
2024-08-31 15:20:26,957 [foster.py] => SNet: Task 5, Epoch 31/130 => Loss 22.804,  Loss1 0.589, Train_accy 79.80, Test_accy 75.73
2024-08-31 15:20:34,197 [foster.py] => SNet: Task 5, Epoch 32/130 => Loss 22.783,  Loss1 0.589, Train_accy 79.67
2024-08-31 15:20:41,459 [foster.py] => SNet: Task 5, Epoch 33/130 => Loss 22.807,  Loss1 0.589, Train_accy 80.09
2024-08-31 15:20:48,821 [foster.py] => SNet: Task 5, Epoch 34/130 => Loss 22.827,  Loss1 0.588, Train_accy 79.69
2024-08-31 15:20:56,315 [foster.py] => SNet: Task 5, Epoch 35/130 => Loss 22.841,  Loss1 0.588, Train_accy 80.13
2024-08-31 15:21:04,846 [foster.py] => SNet: Task 5, Epoch 36/130 => Loss 22.828,  Loss1 0.589, Train_accy 79.60, Test_accy 76.83
2024-08-31 15:21:12,121 [foster.py] => SNet: Task 5, Epoch 37/130 => Loss 22.789,  Loss1 0.589, Train_accy 80.96
2024-08-31 15:21:19,341 [foster.py] => SNet: Task 5, Epoch 38/130 => Loss 22.805,  Loss1 0.589, Train_accy 80.31
2024-08-31 15:21:26,816 [foster.py] => SNet: Task 5, Epoch 39/130 => Loss 22.810,  Loss1 0.589, Train_accy 80.51
2024-08-31 15:21:34,191 [foster.py] => SNet: Task 5, Epoch 40/130 => Loss 22.809,  Loss1 0.589, Train_accy 80.27
2024-08-31 15:21:43,244 [foster.py] => SNet: Task 5, Epoch 41/130 => Loss 22.795,  Loss1 0.589, Train_accy 79.64, Test_accy 75.80
2024-08-31 15:21:50,831 [foster.py] => SNet: Task 5, Epoch 42/130 => Loss 22.802,  Loss1 0.588, Train_accy 80.69
2024-08-31 15:21:58,239 [foster.py] => SNet: Task 5, Epoch 43/130 => Loss 22.824,  Loss1 0.589, Train_accy 81.22
2024-08-31 15:22:05,506 [foster.py] => SNet: Task 5, Epoch 44/130 => Loss 22.806,  Loss1 0.589, Train_accy 81.16
2024-08-31 15:22:13,042 [foster.py] => SNet: Task 5, Epoch 45/130 => Loss 22.801,  Loss1 0.588, Train_accy 81.36
2024-08-31 15:22:21,880 [foster.py] => SNet: Task 5, Epoch 46/130 => Loss 22.819,  Loss1 0.589, Train_accy 81.62, Test_accy 77.10
2024-08-31 15:22:29,174 [foster.py] => SNet: Task 5, Epoch 47/130 => Loss 22.797,  Loss1 0.589, Train_accy 80.44
2024-08-31 15:22:36,703 [foster.py] => SNet: Task 5, Epoch 48/130 => Loss 22.791,  Loss1 0.589, Train_accy 81.67
2024-08-31 15:22:44,186 [foster.py] => SNet: Task 5, Epoch 49/130 => Loss 22.818,  Loss1 0.589, Train_accy 81.11
2024-08-31 15:22:51,881 [foster.py] => SNet: Task 5, Epoch 50/130 => Loss 22.808,  Loss1 0.589, Train_accy 81.44
2024-08-31 15:23:00,692 [foster.py] => SNet: Task 5, Epoch 51/130 => Loss 22.790,  Loss1 0.589, Train_accy 81.00, Test_accy 77.37
2024-08-31 15:23:08,039 [foster.py] => SNet: Task 5, Epoch 52/130 => Loss 22.786,  Loss1 0.589, Train_accy 82.09
2024-08-31 15:23:15,428 [foster.py] => SNet: Task 5, Epoch 53/130 => Loss 22.786,  Loss1 0.589, Train_accy 81.42
2024-08-31 15:23:22,701 [foster.py] => SNet: Task 5, Epoch 54/130 => Loss 22.809,  Loss1 0.589, Train_accy 81.84
2024-08-31 15:23:30,014 [foster.py] => SNet: Task 5, Epoch 55/130 => Loss 22.806,  Loss1 0.589, Train_accy 81.91
2024-08-31 15:23:38,621 [foster.py] => SNet: Task 5, Epoch 56/130 => Loss 22.799,  Loss1 0.589, Train_accy 81.62, Test_accy 77.97
2024-08-31 15:23:45,860 [foster.py] => SNet: Task 5, Epoch 57/130 => Loss 22.799,  Loss1 0.589, Train_accy 81.56
2024-08-31 15:23:53,273 [foster.py] => SNet: Task 5, Epoch 58/130 => Loss 22.804,  Loss1 0.589, Train_accy 82.09
2024-08-31 15:24:00,779 [foster.py] => SNet: Task 5, Epoch 59/130 => Loss 22.811,  Loss1 0.589, Train_accy 82.51
2024-08-31 15:24:08,054 [foster.py] => SNet: Task 5, Epoch 60/130 => Loss 22.782,  Loss1 0.589, Train_accy 82.47
2024-08-31 15:24:16,868 [foster.py] => SNet: Task 5, Epoch 61/130 => Loss 22.779,  Loss1 0.589, Train_accy 83.29, Test_accy 77.30
2024-08-31 15:24:24,165 [foster.py] => SNet: Task 5, Epoch 62/130 => Loss 22.793,  Loss1 0.589, Train_accy 81.42
2024-08-31 15:24:31,390 [foster.py] => SNet: Task 5, Epoch 63/130 => Loss 22.811,  Loss1 0.589, Train_accy 82.47
2024-08-31 15:24:38,896 [foster.py] => SNet: Task 5, Epoch 64/130 => Loss 22.789,  Loss1 0.589, Train_accy 82.56
2024-08-31 15:24:46,263 [foster.py] => SNet: Task 5, Epoch 65/130 => Loss 22.807,  Loss1 0.589, Train_accy 82.42
2024-08-31 15:24:54,843 [foster.py] => SNet: Task 5, Epoch 66/130 => Loss 22.771,  Loss1 0.589, Train_accy 82.42, Test_accy 76.60
2024-08-31 15:25:02,116 [foster.py] => SNet: Task 5, Epoch 67/130 => Loss 22.816,  Loss1 0.589, Train_accy 82.16
2024-08-31 15:25:09,536 [foster.py] => SNet: Task 5, Epoch 68/130 => Loss 22.801,  Loss1 0.589, Train_accy 82.18
2024-08-31 15:25:16,822 [foster.py] => SNet: Task 5, Epoch 69/130 => Loss 22.813,  Loss1 0.589, Train_accy 82.38
2024-08-31 15:25:24,282 [foster.py] => SNet: Task 5, Epoch 70/130 => Loss 22.784,  Loss1 0.589, Train_accy 82.13
2024-08-31 15:25:32,930 [foster.py] => SNet: Task 5, Epoch 71/130 => Loss 22.778,  Loss1 0.589, Train_accy 82.29, Test_accy 77.73
2024-08-31 15:25:40,280 [foster.py] => SNet: Task 5, Epoch 72/130 => Loss 22.771,  Loss1 0.589, Train_accy 83.00
2024-08-31 15:25:47,523 [foster.py] => SNet: Task 5, Epoch 73/130 => Loss 22.788,  Loss1 0.589, Train_accy 82.93
2024-08-31 15:25:55,028 [foster.py] => SNet: Task 5, Epoch 74/130 => Loss 22.784,  Loss1 0.589, Train_accy 82.80
2024-08-31 15:26:02,311 [foster.py] => SNet: Task 5, Epoch 75/130 => Loss 22.785,  Loss1 0.589, Train_accy 82.47
2024-08-31 15:26:11,375 [foster.py] => SNet: Task 5, Epoch 76/130 => Loss 22.801,  Loss1 0.589, Train_accy 82.64, Test_accy 78.63
2024-08-31 15:26:19,178 [foster.py] => SNet: Task 5, Epoch 77/130 => Loss 22.801,  Loss1 0.589, Train_accy 83.38
2024-08-31 15:26:26,546 [foster.py] => SNet: Task 5, Epoch 78/130 => Loss 22.809,  Loss1 0.589, Train_accy 82.60
2024-08-31 15:26:33,918 [foster.py] => SNet: Task 5, Epoch 79/130 => Loss 22.763,  Loss1 0.589, Train_accy 83.18
2024-08-31 15:26:41,459 [foster.py] => SNet: Task 5, Epoch 80/130 => Loss 22.776,  Loss1 0.589, Train_accy 83.09
2024-08-31 15:26:50,310 [foster.py] => SNet: Task 5, Epoch 81/130 => Loss 22.777,  Loss1 0.589, Train_accy 83.69, Test_accy 78.37
2024-08-31 15:26:57,611 [foster.py] => SNet: Task 5, Epoch 82/130 => Loss 22.799,  Loss1 0.589, Train_accy 83.44
2024-08-31 15:27:04,896 [foster.py] => SNet: Task 5, Epoch 83/130 => Loss 22.795,  Loss1 0.589, Train_accy 83.62
2024-08-31 15:27:12,253 [foster.py] => SNet: Task 5, Epoch 84/130 => Loss 22.769,  Loss1 0.589, Train_accy 83.29
2024-08-31 15:27:19,552 [foster.py] => SNet: Task 5, Epoch 85/130 => Loss 22.756,  Loss1 0.589, Train_accy 83.18
2024-08-31 15:27:28,479 [foster.py] => SNet: Task 5, Epoch 86/130 => Loss 22.769,  Loss1 0.589, Train_accy 83.53, Test_accy 78.20
2024-08-31 15:27:35,806 [foster.py] => SNet: Task 5, Epoch 87/130 => Loss 22.793,  Loss1 0.589, Train_accy 83.73
2024-08-31 15:27:43,257 [foster.py] => SNet: Task 5, Epoch 88/130 => Loss 22.793,  Loss1 0.588, Train_accy 83.00
2024-08-31 15:27:50,504 [foster.py] => SNet: Task 5, Epoch 89/130 => Loss 22.770,  Loss1 0.589, Train_accy 83.91
2024-08-31 15:27:58,067 [foster.py] => SNet: Task 5, Epoch 90/130 => Loss 22.789,  Loss1 0.589, Train_accy 82.87
2024-08-31 15:28:06,897 [foster.py] => SNet: Task 5, Epoch 91/130 => Loss 22.794,  Loss1 0.589, Train_accy 83.53, Test_accy 77.83
2024-08-31 15:28:14,203 [foster.py] => SNet: Task 5, Epoch 92/130 => Loss 22.791,  Loss1 0.589, Train_accy 83.44
2024-08-31 15:28:21,495 [foster.py] => SNet: Task 5, Epoch 93/130 => Loss 22.782,  Loss1 0.589, Train_accy 83.69
2024-08-31 15:28:28,883 [foster.py] => SNet: Task 5, Epoch 94/130 => Loss 22.793,  Loss1 0.589, Train_accy 83.67
2024-08-31 15:28:36,298 [foster.py] => SNet: Task 5, Epoch 95/130 => Loss 22.788,  Loss1 0.589, Train_accy 83.49
2024-08-31 15:28:44,849 [foster.py] => SNet: Task 5, Epoch 96/130 => Loss 22.762,  Loss1 0.589, Train_accy 82.84, Test_accy 77.80
2024-08-31 15:28:52,163 [foster.py] => SNet: Task 5, Epoch 97/130 => Loss 22.761,  Loss1 0.589, Train_accy 84.13
2024-08-31 15:28:59,702 [foster.py] => SNet: Task 5, Epoch 98/130 => Loss 22.772,  Loss1 0.590, Train_accy 83.67
2024-08-31 15:29:06,901 [foster.py] => SNet: Task 5, Epoch 99/130 => Loss 22.773,  Loss1 0.589, Train_accy 84.00
2024-08-31 15:29:14,221 [foster.py] => SNet: Task 5, Epoch 100/130 => Loss 22.784,  Loss1 0.589, Train_accy 83.98
2024-08-31 15:29:23,093 [foster.py] => SNet: Task 5, Epoch 101/130 => Loss 22.772,  Loss1 0.589, Train_accy 83.44, Test_accy 77.97
2024-08-31 15:29:30,372 [foster.py] => SNet: Task 5, Epoch 102/130 => Loss 22.791,  Loss1 0.589, Train_accy 83.56
2024-08-31 15:29:37,907 [foster.py] => SNet: Task 5, Epoch 103/130 => Loss 22.777,  Loss1 0.589, Train_accy 83.22
2024-08-31 15:29:45,256 [foster.py] => SNet: Task 5, Epoch 104/130 => Loss 22.778,  Loss1 0.589, Train_accy 83.69
2024-08-31 15:29:52,642 [foster.py] => SNet: Task 5, Epoch 105/130 => Loss 22.797,  Loss1 0.589, Train_accy 83.93
2024-08-31 15:30:01,288 [foster.py] => SNet: Task 5, Epoch 106/130 => Loss 22.801,  Loss1 0.589, Train_accy 83.29, Test_accy 78.47
2024-08-31 15:30:08,919 [foster.py] => SNet: Task 5, Epoch 107/130 => Loss 22.755,  Loss1 0.589, Train_accy 83.49
2024-08-31 15:30:16,333 [foster.py] => SNet: Task 5, Epoch 108/130 => Loss 22.806,  Loss1 0.589, Train_accy 82.73
2024-08-31 15:30:23,624 [foster.py] => SNet: Task 5, Epoch 109/130 => Loss 22.781,  Loss1 0.590, Train_accy 83.60
2024-08-31 15:30:30,980 [foster.py] => SNet: Task 5, Epoch 110/130 => Loss 22.812,  Loss1 0.589, Train_accy 83.76
2024-08-31 15:30:39,643 [foster.py] => SNet: Task 5, Epoch 111/130 => Loss 22.780,  Loss1 0.589, Train_accy 84.00, Test_accy 78.73
2024-08-31 15:30:47,112 [foster.py] => SNet: Task 5, Epoch 112/130 => Loss 22.788,  Loss1 0.589, Train_accy 82.76
2024-08-31 15:30:54,631 [foster.py] => SNet: Task 5, Epoch 113/130 => Loss 22.749,  Loss1 0.589, Train_accy 84.87
2024-08-31 15:31:02,456 [foster.py] => SNet: Task 5, Epoch 114/130 => Loss 22.795,  Loss1 0.589, Train_accy 83.58
2024-08-31 15:31:09,694 [foster.py] => SNet: Task 5, Epoch 115/130 => Loss 22.766,  Loss1 0.589, Train_accy 83.93
2024-08-31 15:31:18,722 [foster.py] => SNet: Task 5, Epoch 116/130 => Loss 22.795,  Loss1 0.589, Train_accy 82.82, Test_accy 78.40
2024-08-31 15:31:26,108 [foster.py] => SNet: Task 5, Epoch 117/130 => Loss 22.757,  Loss1 0.589, Train_accy 84.67
2024-08-31 15:31:33,694 [foster.py] => SNet: Task 5, Epoch 118/130 => Loss 22.782,  Loss1 0.589, Train_accy 83.69
2024-08-31 15:31:41,000 [foster.py] => SNet: Task 5, Epoch 119/130 => Loss 22.746,  Loss1 0.589, Train_accy 84.29
2024-08-31 15:31:48,544 [foster.py] => SNet: Task 5, Epoch 120/130 => Loss 22.784,  Loss1 0.589, Train_accy 83.78
2024-08-31 15:31:57,150 [foster.py] => SNet: Task 5, Epoch 121/130 => Loss 22.757,  Loss1 0.589, Train_accy 83.47, Test_accy 78.93
2024-08-31 15:32:04,644 [foster.py] => SNet: Task 5, Epoch 122/130 => Loss 22.777,  Loss1 0.589, Train_accy 84.00
2024-08-31 15:32:11,892 [foster.py] => SNet: Task 5, Epoch 123/130 => Loss 22.775,  Loss1 0.589, Train_accy 83.44
2024-08-31 15:32:19,464 [foster.py] => SNet: Task 5, Epoch 124/130 => Loss 22.790,  Loss1 0.589, Train_accy 82.69
2024-08-31 15:32:26,948 [foster.py] => SNet: Task 5, Epoch 125/130 => Loss 22.756,  Loss1 0.589, Train_accy 84.53
2024-08-31 15:32:36,198 [foster.py] => SNet: Task 5, Epoch 126/130 => Loss 22.780,  Loss1 0.589, Train_accy 82.91, Test_accy 78.43
2024-08-31 15:32:43,714 [foster.py] => SNet: Task 5, Epoch 127/130 => Loss 22.783,  Loss1 0.589, Train_accy 82.76
2024-08-31 15:32:51,228 [foster.py] => SNet: Task 5, Epoch 128/130 => Loss 22.778,  Loss1 0.589, Train_accy 84.36
2024-08-31 15:32:58,647 [foster.py] => SNet: Task 5, Epoch 129/130 => Loss 22.782,  Loss1 0.589, Train_accy 83.87
2024-08-31 15:33:05,969 [foster.py] => SNet: Task 5, Epoch 130/130 => Loss 22.753,  Loss1 0.589, Train_accy 83.71
2024-08-31 15:33:05,970 [foster.py] => do not weight align student!
2024-08-31 15:33:07,306 [foster.py] => darknet eval: 
2024-08-31 15:33:07,306 [foster.py] => CNN top1 curve: 78.37
2024-08-31 15:33:07,306 [foster.py] => CNN top5 curve: 96.27
2024-08-31 15:33:07,307 [foster.py] => CNN top1 平均值: 78.37
2024-08-31 15:33:07,312 [foster.py] => timees : 2144.2368726730347
2024-08-31 15:33:07,312 [base.py] => Reducing exemplars...(66 per classes)
2024-08-31 15:33:16,851 [base.py] => Constructing exemplars...(66 per classes)
2024-08-31 15:33:25,389 [foster.py] => Exemplar size: 1980
2024-08-31 15:33:25,390 [trainer.py] => CNN: {'total': 79.87, '00-09': 81.7, '10-19': 71.2, '20-29': 86.7, 'old': 78.2, 'new': 88.2}
2024-08-31 15:33:25,390 [trainer.py] => NME: {'total': 78.27, '00-09': 80.9, '10-19': 72.4, '20-29': 81.5, 'old': 77.2, 'new': 83.6}
2024-08-31 15:33:25,390 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87]
2024-08-31 15:33:25,390 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4]
2024-08-31 15:33:25,390 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27]
2024-08-31 15:33:25,390 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87]

2024-08-31 15:33:25,390 [trainer.py] => CNN top1 平均值: 87.96
2024-08-31 15:33:25,393 [trainer.py] => All params: 1289993
2024-08-31 15:33:25,395 [trainer.py] => Trainable params: 647094
2024-08-31 15:33:25,458 [foster.py] => Learning on 30-35
2024-08-31 15:33:25,462 [foster.py] => All params: 1291288
2024-08-31 15:33:25,464 [foster.py] => Trainable params: 648064
2024-08-31 15:33:25,510 [foster.py] => per cls weights : [1.01635481 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481
 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481
 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481
 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481
 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481 1.01635481
 0.90187114 0.90187114 0.90187114 0.90187114 0.90187114]
2024-08-31 15:33:30,950 [foster.py] => Task 6, Epoch 1/170 => Loss 5.192, Loss_clf 1.616, Loss_fe 1.606, Loss_kd 1.684, Train_accy 53.62
2024-08-31 15:33:38,002 [foster.py] => Task 6, Epoch 2/170 => Loss 4.210, Loss_clf 1.035, Loss_fe 1.222, Loss_kd 1.669, Train_accy 65.85, Test_accy 70.54
2024-08-31 15:33:45,042 [foster.py] => Task 6, Epoch 3/170 => Loss 4.089, Loss_clf 1.042, Loss_fe 1.112, Loss_kd 1.654, Train_accy 67.72, Test_accy 71.09
2024-08-31 15:33:52,040 [foster.py] => Task 6, Epoch 4/170 => Loss 4.048, Loss_clf 1.007, Loss_fe 1.090, Loss_kd 1.668, Train_accy 68.06, Test_accy 72.40
2024-08-31 15:33:59,091 [foster.py] => Task 6, Epoch 5/170 => Loss 4.033, Loss_clf 1.028, Loss_fe 1.069, Loss_kd 1.655, Train_accy 66.81, Test_accy 72.06
2024-08-31 15:34:04,500 [foster.py] => Task 6, Epoch 6/170 => Loss 4.013, Loss_clf 1.035, Loss_fe 1.045, Loss_kd 1.652, Train_accy 67.81
2024-08-31 15:34:11,479 [foster.py] => Task 6, Epoch 7/170 => Loss 4.042, Loss_clf 1.043, Loss_fe 1.053, Loss_kd 1.665, Train_accy 66.16, Test_accy 71.71
2024-08-31 15:34:18,566 [foster.py] => Task 6, Epoch 8/170 => Loss 3.977, Loss_clf 1.004, Loss_fe 1.031, Loss_kd 1.661, Train_accy 67.95, Test_accy 71.83
2024-08-31 15:34:25,577 [foster.py] => Task 6, Epoch 9/170 => Loss 3.916, Loss_clf 0.963, Loss_fe 1.015, Loss_kd 1.658, Train_accy 69.55, Test_accy 67.97
2024-08-31 15:34:32,584 [foster.py] => Task 6, Epoch 10/170 => Loss 3.904, Loss_clf 0.954, Loss_fe 1.011, Loss_kd 1.658, Train_accy 69.82, Test_accy 73.63
2024-08-31 15:34:37,932 [foster.py] => Task 6, Epoch 11/170 => Loss 3.878, Loss_clf 0.929, Loss_fe 1.010, Loss_kd 1.658, Train_accy 69.26
2024-08-31 15:34:44,931 [foster.py] => Task 6, Epoch 12/170 => Loss 3.914, Loss_clf 0.970, Loss_fe 1.000, Loss_kd 1.662, Train_accy 69.35, Test_accy 73.09
2024-08-31 15:34:52,080 [foster.py] => Task 6, Epoch 13/170 => Loss 3.828, Loss_clf 0.903, Loss_fe 0.979, Loss_kd 1.664, Train_accy 71.36, Test_accy 69.77
2024-08-31 15:34:59,184 [foster.py] => Task 6, Epoch 14/170 => Loss 3.903, Loss_clf 0.971, Loss_fe 0.997, Loss_kd 1.655, Train_accy 69.02, Test_accy 71.34
2024-08-31 15:35:06,272 [foster.py] => Task 6, Epoch 15/170 => Loss 3.889, Loss_clf 0.952, Loss_fe 1.005, Loss_kd 1.651, Train_accy 69.80, Test_accy 72.86
2024-08-31 15:35:11,584 [foster.py] => Task 6, Epoch 16/170 => Loss 3.877, Loss_clf 0.948, Loss_fe 0.988, Loss_kd 1.660, Train_accy 69.22
2024-08-31 15:35:18,643 [foster.py] => Task 6, Epoch 17/170 => Loss 3.899, Loss_clf 0.944, Loss_fe 1.021, Loss_kd 1.654, Train_accy 70.16, Test_accy 64.91
2024-08-31 15:35:25,658 [foster.py] => Task 6, Epoch 18/170 => Loss 3.880, Loss_clf 0.934, Loss_fe 1.005, Loss_kd 1.660, Train_accy 70.00, Test_accy 74.74
2024-08-31 15:35:32,747 [foster.py] => Task 6, Epoch 19/170 => Loss 3.875, Loss_clf 0.931, Loss_fe 1.005, Loss_kd 1.658, Train_accy 69.84, Test_accy 72.94
2024-08-31 15:35:39,818 [foster.py] => Task 6, Epoch 20/170 => Loss 3.894, Loss_clf 0.933, Loss_fe 1.017, Loss_kd 1.663, Train_accy 69.55, Test_accy 75.20
2024-08-31 15:35:45,129 [foster.py] => Task 6, Epoch 21/170 => Loss 3.805, Loss_clf 0.931, Loss_fe 0.946, Loss_kd 1.649, Train_accy 69.84
2024-08-31 15:35:52,128 [foster.py] => Task 6, Epoch 22/170 => Loss 3.876, Loss_clf 0.957, Loss_fe 0.988, Loss_kd 1.652, Train_accy 69.69, Test_accy 72.71
2024-08-31 15:35:59,166 [foster.py] => Task 6, Epoch 23/170 => Loss 3.812, Loss_clf 0.921, Loss_fe 0.967, Loss_kd 1.645, Train_accy 70.69, Test_accy 71.97
2024-08-31 15:36:06,163 [foster.py] => Task 6, Epoch 24/170 => Loss 3.824, Loss_clf 0.919, Loss_fe 0.973, Loss_kd 1.652, Train_accy 70.20, Test_accy 70.69
2024-08-31 15:36:13,137 [foster.py] => Task 6, Epoch 25/170 => Loss 3.888, Loss_clf 0.975, Loss_fe 0.964, Loss_kd 1.666, Train_accy 69.31, Test_accy 74.09
2024-08-31 15:36:18,538 [foster.py] => Task 6, Epoch 26/170 => Loss 3.850, Loss_clf 0.919, Loss_fe 0.983, Loss_kd 1.667, Train_accy 70.98
2024-08-31 15:36:25,515 [foster.py] => Task 6, Epoch 27/170 => Loss 3.767, Loss_clf 0.880, Loss_fe 0.945, Loss_kd 1.660, Train_accy 71.65, Test_accy 70.94
2024-08-31 15:36:32,609 [foster.py] => Task 6, Epoch 28/170 => Loss 3.752, Loss_clf 0.883, Loss_fe 0.931, Loss_kd 1.658, Train_accy 72.21, Test_accy 70.97
2024-08-31 15:36:39,710 [foster.py] => Task 6, Epoch 29/170 => Loss 3.747, Loss_clf 0.876, Loss_fe 0.946, Loss_kd 1.646, Train_accy 71.12, Test_accy 71.97
2024-08-31 15:36:46,655 [foster.py] => Task 6, Epoch 30/170 => Loss 3.827, Loss_clf 0.937, Loss_fe 0.966, Loss_kd 1.646, Train_accy 69.35, Test_accy 61.43
2024-08-31 15:36:51,925 [foster.py] => Task 6, Epoch 31/170 => Loss 3.956, Loss_clf 1.047, Loss_fe 0.981, Loss_kd 1.649, Train_accy 69.73
2024-08-31 15:36:59,057 [foster.py] => Task 6, Epoch 32/170 => Loss 3.823, Loss_clf 0.912, Loss_fe 0.973, Loss_kd 1.658, Train_accy 70.80, Test_accy 72.17
2024-08-31 15:37:06,062 [foster.py] => Task 6, Epoch 33/170 => Loss 3.843, Loss_clf 0.928, Loss_fe 0.985, Loss_kd 1.651, Train_accy 71.16, Test_accy 74.00
2024-08-31 15:37:13,064 [foster.py] => Task 6, Epoch 34/170 => Loss 3.793, Loss_clf 0.892, Loss_fe 0.961, Loss_kd 1.660, Train_accy 72.37, Test_accy 73.69
2024-08-31 15:37:20,064 [foster.py] => Task 6, Epoch 35/170 => Loss 3.748, Loss_clf 0.872, Loss_fe 0.937, Loss_kd 1.659, Train_accy 71.36, Test_accy 73.06
2024-08-31 15:37:25,466 [foster.py] => Task 6, Epoch 36/170 => Loss 3.813, Loss_clf 0.915, Loss_fe 0.938, Loss_kd 1.676, Train_accy 70.92
2024-08-31 15:37:32,545 [foster.py] => Task 6, Epoch 37/170 => Loss 3.789, Loss_clf 0.930, Loss_fe 0.940, Loss_kd 1.641, Train_accy 70.13, Test_accy 74.66
2024-08-31 15:37:39,574 [foster.py] => Task 6, Epoch 38/170 => Loss 3.783, Loss_clf 0.906, Loss_fe 0.940, Loss_kd 1.656, Train_accy 70.69, Test_accy 68.97
2024-08-31 15:37:46,696 [foster.py] => Task 6, Epoch 39/170 => Loss 3.786, Loss_clf 0.921, Loss_fe 0.934, Loss_kd 1.651, Train_accy 71.14, Test_accy 70.91
2024-08-31 15:37:53,787 [foster.py] => Task 6, Epoch 40/170 => Loss 3.681, Loss_clf 0.849, Loss_fe 0.898, Loss_kd 1.654, Train_accy 73.73, Test_accy 74.86
2024-08-31 15:37:59,251 [foster.py] => Task 6, Epoch 41/170 => Loss 3.761, Loss_clf 0.875, Loss_fe 0.945, Loss_kd 1.660, Train_accy 71.45
2024-08-31 15:38:06,369 [foster.py] => Task 6, Epoch 42/170 => Loss 3.748, Loss_clf 0.876, Loss_fe 0.932, Loss_kd 1.659, Train_accy 71.54, Test_accy 69.97
2024-08-31 15:38:13,424 [foster.py] => Task 6, Epoch 43/170 => Loss 3.811, Loss_clf 0.941, Loss_fe 0.933, Loss_kd 1.657, Train_accy 70.78, Test_accy 72.49
2024-08-31 15:38:20,501 [foster.py] => Task 6, Epoch 44/170 => Loss 3.729, Loss_clf 0.862, Loss_fe 0.926, Loss_kd 1.660, Train_accy 71.88, Test_accy 73.60
2024-08-31 15:38:27,536 [foster.py] => Task 6, Epoch 45/170 => Loss 3.710, Loss_clf 0.880, Loss_fe 0.890, Loss_kd 1.660, Train_accy 71.85, Test_accy 69.31
2024-08-31 15:38:32,885 [foster.py] => Task 6, Epoch 46/170 => Loss 3.750, Loss_clf 0.903, Loss_fe 0.922, Loss_kd 1.647, Train_accy 71.12
2024-08-31 15:38:39,804 [foster.py] => Task 6, Epoch 47/170 => Loss 3.750, Loss_clf 0.875, Loss_fe 0.928, Loss_kd 1.666, Train_accy 71.18, Test_accy 73.54
2024-08-31 15:38:46,799 [foster.py] => Task 6, Epoch 48/170 => Loss 3.744, Loss_clf 0.889, Loss_fe 0.920, Loss_kd 1.654, Train_accy 71.67, Test_accy 75.31
2024-08-31 15:38:53,782 [foster.py] => Task 6, Epoch 49/170 => Loss 3.689, Loss_clf 0.883, Loss_fe 0.891, Loss_kd 1.639, Train_accy 71.72, Test_accy 70.31
2024-08-31 15:39:00,838 [foster.py] => Task 6, Epoch 50/170 => Loss 3.796, Loss_clf 0.930, Loss_fe 0.929, Loss_kd 1.657, Train_accy 71.43, Test_accy 67.69
2024-08-31 15:39:06,234 [foster.py] => Task 6, Epoch 51/170 => Loss 3.730, Loss_clf 0.877, Loss_fe 0.928, Loss_kd 1.646, Train_accy 71.27
2024-08-31 15:39:13,252 [foster.py] => Task 6, Epoch 52/170 => Loss 3.654, Loss_clf 0.837, Loss_fe 0.882, Loss_kd 1.656, Train_accy 72.99, Test_accy 72.31
2024-08-31 15:39:20,278 [foster.py] => Task 6, Epoch 53/170 => Loss 3.654, Loss_clf 0.828, Loss_fe 0.887, Loss_kd 1.659, Train_accy 73.97, Test_accy 73.63
2024-08-31 15:39:27,312 [foster.py] => Task 6, Epoch 54/170 => Loss 3.598, Loss_clf 0.803, Loss_fe 0.857, Loss_kd 1.658, Train_accy 73.82, Test_accy 74.77
2024-08-31 15:39:34,517 [foster.py] => Task 6, Epoch 55/170 => Loss 3.634, Loss_clf 0.831, Loss_fe 0.875, Loss_kd 1.649, Train_accy 73.39, Test_accy 72.11
2024-08-31 15:39:39,876 [foster.py] => Task 6, Epoch 56/170 => Loss 3.658, Loss_clf 0.840, Loss_fe 0.890, Loss_kd 1.650, Train_accy 73.39
2024-08-31 15:39:46,954 [foster.py] => Task 6, Epoch 57/170 => Loss 3.664, Loss_clf 0.846, Loss_fe 0.870, Loss_kd 1.666, Train_accy 73.62, Test_accy 73.94
2024-08-31 15:39:53,947 [foster.py] => Task 6, Epoch 58/170 => Loss 3.629, Loss_clf 0.835, Loss_fe 0.864, Loss_kd 1.652, Train_accy 73.44, Test_accy 73.51
2024-08-31 15:40:01,004 [foster.py] => Task 6, Epoch 59/170 => Loss 3.597, Loss_clf 0.807, Loss_fe 0.840, Loss_kd 1.668, Train_accy 75.54, Test_accy 74.06
2024-08-31 15:40:07,996 [foster.py] => Task 6, Epoch 60/170 => Loss 3.613, Loss_clf 0.819, Loss_fe 0.872, Loss_kd 1.645, Train_accy 74.55, Test_accy 74.40
2024-08-31 15:40:13,449 [foster.py] => Task 6, Epoch 61/170 => Loss 3.515, Loss_clf 0.777, Loss_fe 0.813, Loss_kd 1.647, Train_accy 75.45
2024-08-31 15:40:20,422 [foster.py] => Task 6, Epoch 62/170 => Loss 3.687, Loss_clf 0.892, Loss_fe 0.868, Loss_kd 1.648, Train_accy 72.08, Test_accy 72.57
2024-08-31 15:40:27,447 [foster.py] => Task 6, Epoch 63/170 => Loss 3.626, Loss_clf 0.834, Loss_fe 0.862, Loss_kd 1.651, Train_accy 73.50, Test_accy 70.40
2024-08-31 15:40:34,533 [foster.py] => Task 6, Epoch 64/170 => Loss 3.606, Loss_clf 0.826, Loss_fe 0.858, Loss_kd 1.645, Train_accy 73.66, Test_accy 75.51
2024-08-31 15:40:41,531 [foster.py] => Task 6, Epoch 65/170 => Loss 3.579, Loss_clf 0.813, Loss_fe 0.832, Loss_kd 1.654, Train_accy 74.08, Test_accy 76.11
2024-08-31 15:40:46,993 [foster.py] => Task 6, Epoch 66/170 => Loss 3.548, Loss_clf 0.806, Loss_fe 0.811, Loss_kd 1.652, Train_accy 74.20
2024-08-31 15:40:54,089 [foster.py] => Task 6, Epoch 67/170 => Loss 3.632, Loss_clf 0.840, Loss_fe 0.849, Loss_kd 1.663, Train_accy 72.99, Test_accy 74.17
2024-08-31 15:41:01,663 [foster.py] => Task 6, Epoch 68/170 => Loss 3.636, Loss_clf 0.837, Loss_fe 0.847, Loss_kd 1.669, Train_accy 73.46, Test_accy 72.91
2024-08-31 15:41:09,003 [foster.py] => Task 6, Epoch 69/170 => Loss 3.575, Loss_clf 0.795, Loss_fe 0.853, Loss_kd 1.649, Train_accy 74.15, Test_accy 75.71
2024-08-31 15:41:16,028 [foster.py] => Task 6, Epoch 70/170 => Loss 3.568, Loss_clf 0.811, Loss_fe 0.826, Loss_kd 1.652, Train_accy 74.78, Test_accy 72.34
2024-08-31 15:41:21,330 [foster.py] => Task 6, Epoch 71/170 => Loss 3.512, Loss_clf 0.785, Loss_fe 0.796, Loss_kd 1.652, Train_accy 75.69
2024-08-31 15:41:28,386 [foster.py] => Task 6, Epoch 72/170 => Loss 3.535, Loss_clf 0.807, Loss_fe 0.812, Loss_kd 1.639, Train_accy 74.80, Test_accy 72.17
2024-08-31 15:41:35,384 [foster.py] => Task 6, Epoch 73/170 => Loss 3.542, Loss_clf 0.809, Loss_fe 0.808, Loss_kd 1.647, Train_accy 74.38, Test_accy 76.03
2024-08-31 15:41:42,436 [foster.py] => Task 6, Epoch 74/170 => Loss 3.518, Loss_clf 0.792, Loss_fe 0.793, Loss_kd 1.653, Train_accy 74.93, Test_accy 71.60
2024-08-31 15:41:49,436 [foster.py] => Task 6, Epoch 75/170 => Loss 3.530, Loss_clf 0.800, Loss_fe 0.811, Loss_kd 1.641, Train_accy 74.91, Test_accy 75.51
2024-08-31 15:41:54,777 [foster.py] => Task 6, Epoch 76/170 => Loss 3.568, Loss_clf 0.791, Loss_fe 0.846, Loss_kd 1.652, Train_accy 75.31
2024-08-31 15:42:01,796 [foster.py] => Task 6, Epoch 77/170 => Loss 3.421, Loss_clf 0.750, Loss_fe 0.750, Loss_kd 1.644, Train_accy 77.05, Test_accy 74.97
2024-08-31 15:42:08,856 [foster.py] => Task 6, Epoch 78/170 => Loss 3.477, Loss_clf 0.761, Loss_fe 0.780, Loss_kd 1.656, Train_accy 76.34, Test_accy 73.80
2024-08-31 15:42:15,917 [foster.py] => Task 6, Epoch 79/170 => Loss 3.514, Loss_clf 0.796, Loss_fe 0.786, Loss_kd 1.653, Train_accy 75.11, Test_accy 72.54
2024-08-31 15:42:23,043 [foster.py] => Task 6, Epoch 80/170 => Loss 3.438, Loss_clf 0.751, Loss_fe 0.755, Loss_kd 1.653, Train_accy 76.70, Test_accy 72.63
2024-08-31 15:42:28,383 [foster.py] => Task 6, Epoch 81/170 => Loss 3.493, Loss_clf 0.771, Loss_fe 0.780, Loss_kd 1.661, Train_accy 75.96
2024-08-31 15:42:35,453 [foster.py] => Task 6, Epoch 82/170 => Loss 3.492, Loss_clf 0.774, Loss_fe 0.799, Loss_kd 1.641, Train_accy 75.22, Test_accy 72.43
2024-08-31 15:42:42,571 [foster.py] => Task 6, Epoch 83/170 => Loss 3.537, Loss_clf 0.818, Loss_fe 0.785, Loss_kd 1.655, Train_accy 73.86, Test_accy 74.86
2024-08-31 15:42:49,609 [foster.py] => Task 6, Epoch 84/170 => Loss 3.517, Loss_clf 0.799, Loss_fe 0.789, Loss_kd 1.650, Train_accy 74.93, Test_accy 74.63
2024-08-31 15:42:56,657 [foster.py] => Task 6, Epoch 85/170 => Loss 3.458, Loss_clf 0.767, Loss_fe 0.746, Loss_kd 1.663, Train_accy 76.36, Test_accy 70.20
2024-08-31 15:43:02,088 [foster.py] => Task 6, Epoch 86/170 => Loss 3.463, Loss_clf 0.763, Loss_fe 0.763, Loss_kd 1.657, Train_accy 76.18
2024-08-31 15:43:09,078 [foster.py] => Task 6, Epoch 87/170 => Loss 3.460, Loss_clf 0.768, Loss_fe 0.769, Loss_kd 1.645, Train_accy 76.47, Test_accy 73.83
2024-08-31 15:43:16,085 [foster.py] => Task 6, Epoch 88/170 => Loss 3.442, Loss_clf 0.758, Loss_fe 0.758, Loss_kd 1.648, Train_accy 75.60, Test_accy 75.51
2024-08-31 15:43:23,105 [foster.py] => Task 6, Epoch 89/170 => Loss 3.426, Loss_clf 0.747, Loss_fe 0.757, Loss_kd 1.644, Train_accy 76.34, Test_accy 72.91
2024-08-31 15:43:30,236 [foster.py] => Task 6, Epoch 90/170 => Loss 3.372, Loss_clf 0.722, Loss_fe 0.717, Loss_kd 1.654, Train_accy 77.21, Test_accy 72.51
2024-08-31 15:43:35,586 [foster.py] => Task 6, Epoch 91/170 => Loss 3.445, Loss_clf 0.766, Loss_fe 0.740, Loss_kd 1.659, Train_accy 76.58
2024-08-31 15:43:42,661 [foster.py] => Task 6, Epoch 92/170 => Loss 3.434, Loss_clf 0.758, Loss_fe 0.728, Loss_kd 1.667, Train_accy 76.34, Test_accy 74.69
2024-08-31 15:43:49,775 [foster.py] => Task 6, Epoch 93/170 => Loss 3.352, Loss_clf 0.750, Loss_fe 0.686, Loss_kd 1.639, Train_accy 76.90, Test_accy 74.89
2024-08-31 15:43:56,849 [foster.py] => Task 6, Epoch 94/170 => Loss 3.377, Loss_clf 0.747, Loss_fe 0.699, Loss_kd 1.652, Train_accy 76.38, Test_accy 74.57
2024-08-31 15:44:03,867 [foster.py] => Task 6, Epoch 95/170 => Loss 3.373, Loss_clf 0.751, Loss_fe 0.698, Loss_kd 1.646, Train_accy 76.43, Test_accy 74.89
2024-08-31 15:44:09,237 [foster.py] => Task 6, Epoch 96/170 => Loss 3.335, Loss_clf 0.707, Loss_fe 0.704, Loss_kd 1.646, Train_accy 77.92
2024-08-31 15:44:16,274 [foster.py] => Task 6, Epoch 97/170 => Loss 3.307, Loss_clf 0.717, Loss_fe 0.670, Loss_kd 1.643, Train_accy 77.68, Test_accy 74.54
2024-08-31 15:44:23,377 [foster.py] => Task 6, Epoch 98/170 => Loss 3.313, Loss_clf 0.712, Loss_fe 0.674, Loss_kd 1.649, Train_accy 78.04, Test_accy 74.49
2024-08-31 15:44:30,368 [foster.py] => Task 6, Epoch 99/170 => Loss 3.337, Loss_clf 0.719, Loss_fe 0.677, Loss_kd 1.660, Train_accy 77.79, Test_accy 74.14
2024-08-31 15:44:37,368 [foster.py] => Task 6, Epoch 100/170 => Loss 3.363, Loss_clf 0.725, Loss_fe 0.703, Loss_kd 1.655, Train_accy 77.70, Test_accy 76.20
2024-08-31 15:44:42,766 [foster.py] => Task 6, Epoch 101/170 => Loss 3.212, Loss_clf 0.657, Loss_fe 0.633, Loss_kd 1.644, Train_accy 79.49
2024-08-31 15:44:49,689 [foster.py] => Task 6, Epoch 102/170 => Loss 3.288, Loss_clf 0.700, Loss_fe 0.649, Loss_kd 1.659, Train_accy 78.01, Test_accy 75.83
2024-08-31 15:44:56,689 [foster.py] => Task 6, Epoch 103/170 => Loss 3.283, Loss_clf 0.690, Loss_fe 0.665, Loss_kd 1.649, Train_accy 78.21, Test_accy 74.54
2024-08-31 15:45:03,715 [foster.py] => Task 6, Epoch 104/170 => Loss 3.242, Loss_clf 0.676, Loss_fe 0.643, Loss_kd 1.645, Train_accy 79.46, Test_accy 74.86
2024-08-31 15:45:10,677 [foster.py] => Task 6, Epoch 105/170 => Loss 3.272, Loss_clf 0.696, Loss_fe 0.644, Loss_kd 1.653, Train_accy 78.28, Test_accy 76.37
2024-08-31 15:45:15,985 [foster.py] => Task 6, Epoch 106/170 => Loss 3.194, Loss_clf 0.656, Loss_fe 0.615, Loss_kd 1.646, Train_accy 79.04
2024-08-31 15:45:23,005 [foster.py] => Task 6, Epoch 107/170 => Loss 3.214, Loss_clf 0.654, Loss_fe 0.632, Loss_kd 1.650, Train_accy 79.73, Test_accy 76.23
2024-08-31 15:45:30,063 [foster.py] => Task 6, Epoch 108/170 => Loss 3.216, Loss_clf 0.664, Loss_fe 0.620, Loss_kd 1.653, Train_accy 80.20, Test_accy 75.69
2024-08-31 15:45:37,184 [foster.py] => Task 6, Epoch 109/170 => Loss 3.180, Loss_clf 0.654, Loss_fe 0.608, Loss_kd 1.641, Train_accy 79.73, Test_accy 73.74
2024-08-31 15:45:44,234 [foster.py] => Task 6, Epoch 110/170 => Loss 3.138, Loss_clf 0.643, Loss_fe 0.576, Loss_kd 1.642, Train_accy 80.71, Test_accy 75.23
2024-08-31 15:45:49,618 [foster.py] => Task 6, Epoch 111/170 => Loss 3.195, Loss_clf 0.678, Loss_fe 0.585, Loss_kd 1.653, Train_accy 80.09
2024-08-31 15:45:56,644 [foster.py] => Task 6, Epoch 112/170 => Loss 3.201, Loss_clf 0.661, Loss_fe 0.605, Loss_kd 1.655, Train_accy 79.82, Test_accy 73.23
2024-08-31 15:46:03,668 [foster.py] => Task 6, Epoch 113/170 => Loss 3.242, Loss_clf 0.677, Loss_fe 0.620, Loss_kd 1.665, Train_accy 79.33, Test_accy 74.97
2024-08-31 15:46:10,671 [foster.py] => Task 6, Epoch 114/170 => Loss 3.158, Loss_clf 0.655, Loss_fe 0.580, Loss_kd 1.645, Train_accy 79.96, Test_accy 71.83
2024-08-31 15:46:17,678 [foster.py] => Task 6, Epoch 115/170 => Loss 3.155, Loss_clf 0.641, Loss_fe 0.591, Loss_kd 1.645, Train_accy 80.54, Test_accy 76.80
2024-08-31 15:46:23,019 [foster.py] => Task 6, Epoch 116/170 => Loss 3.230, Loss_clf 0.679, Loss_fe 0.613, Loss_kd 1.657, Train_accy 78.84
2024-08-31 15:46:30,079 [foster.py] => Task 6, Epoch 117/170 => Loss 3.105, Loss_clf 0.614, Loss_fe 0.565, Loss_kd 1.647, Train_accy 80.96, Test_accy 72.40
2024-08-31 15:46:37,107 [foster.py] => Task 6, Epoch 118/170 => Loss 3.116, Loss_clf 0.632, Loss_fe 0.548, Loss_kd 1.656, Train_accy 80.78, Test_accy 76.83
2024-08-31 15:46:44,188 [foster.py] => Task 6, Epoch 119/170 => Loss 3.090, Loss_clf 0.614, Loss_fe 0.550, Loss_kd 1.649, Train_accy 80.94, Test_accy 75.49
2024-08-31 15:46:51,217 [foster.py] => Task 6, Epoch 120/170 => Loss 3.133, Loss_clf 0.643, Loss_fe 0.560, Loss_kd 1.651, Train_accy 79.42, Test_accy 76.06
2024-08-31 15:46:56,557 [foster.py] => Task 6, Epoch 121/170 => Loss 3.076, Loss_clf 0.610, Loss_fe 0.543, Loss_kd 1.644, Train_accy 81.81
2024-08-31 15:47:03,647 [foster.py] => Task 6, Epoch 122/170 => Loss 3.033, Loss_clf 0.604, Loss_fe 0.525, Loss_kd 1.628, Train_accy 82.25, Test_accy 75.60
2024-08-31 15:47:10,689 [foster.py] => Task 6, Epoch 123/170 => Loss 3.019, Loss_clf 0.591, Loss_fe 0.498, Loss_kd 1.651, Train_accy 82.17, Test_accy 75.11
2024-08-31 15:47:17,675 [foster.py] => Task 6, Epoch 124/170 => Loss 3.066, Loss_clf 0.609, Loss_fe 0.519, Loss_kd 1.657, Train_accy 81.65, Test_accy 77.51
2024-08-31 15:47:24,730 [foster.py] => Task 6, Epoch 125/170 => Loss 3.038, Loss_clf 0.594, Loss_fe 0.519, Loss_kd 1.648, Train_accy 82.21, Test_accy 75.26
2024-08-31 15:47:30,150 [foster.py] => Task 6, Epoch 126/170 => Loss 2.979, Loss_clf 0.576, Loss_fe 0.484, Loss_kd 1.641, Train_accy 82.08
2024-08-31 15:47:37,109 [foster.py] => Task 6, Epoch 127/170 => Loss 2.988, Loss_clf 0.579, Loss_fe 0.489, Loss_kd 1.642, Train_accy 82.54, Test_accy 76.31
2024-08-31 15:47:44,219 [foster.py] => Task 6, Epoch 128/170 => Loss 3.007, Loss_clf 0.590, Loss_fe 0.491, Loss_kd 1.647, Train_accy 82.17, Test_accy 76.06
2024-08-31 15:47:51,267 [foster.py] => Task 6, Epoch 129/170 => Loss 2.999, Loss_clf 0.592, Loss_fe 0.486, Loss_kd 1.644, Train_accy 82.21, Test_accy 76.57
2024-08-31 15:47:58,249 [foster.py] => Task 6, Epoch 130/170 => Loss 2.960, Loss_clf 0.575, Loss_fe 0.471, Loss_kd 1.637, Train_accy 82.88, Test_accy 77.69
2024-08-31 15:48:03,565 [foster.py] => Task 6, Epoch 131/170 => Loss 2.978, Loss_clf 0.575, Loss_fe 0.468, Loss_kd 1.655, Train_accy 82.68
2024-08-31 15:48:10,618 [foster.py] => Task 6, Epoch 132/170 => Loss 2.986, Loss_clf 0.589, Loss_fe 0.465, Loss_kd 1.653, Train_accy 82.25, Test_accy 75.31
2024-08-31 15:48:17,639 [foster.py] => Task 6, Epoch 133/170 => Loss 2.922, Loss_clf 0.547, Loss_fe 0.443, Loss_kd 1.653, Train_accy 84.15, Test_accy 77.17
2024-08-31 15:48:24,667 [foster.py] => Task 6, Epoch 134/170 => Loss 2.960, Loss_clf 0.565, Loss_fe 0.466, Loss_kd 1.650, Train_accy 83.06, Test_accy 77.09
2024-08-31 15:48:31,719 [foster.py] => Task 6, Epoch 135/170 => Loss 2.904, Loss_clf 0.545, Loss_fe 0.445, Loss_kd 1.638, Train_accy 82.88, Test_accy 76.43
2024-08-31 15:48:37,112 [foster.py] => Task 6, Epoch 136/170 => Loss 2.912, Loss_clf 0.556, Loss_fe 0.433, Loss_kd 1.645, Train_accy 83.44
2024-08-31 15:48:44,184 [foster.py] => Task 6, Epoch 137/170 => Loss 2.968, Loss_clf 0.574, Loss_fe 0.452, Loss_kd 1.662, Train_accy 82.95, Test_accy 78.06
2024-08-31 15:48:51,199 [foster.py] => Task 6, Epoch 138/170 => Loss 2.857, Loss_clf 0.522, Loss_fe 0.406, Loss_kd 1.650, Train_accy 84.53, Test_accy 77.71
2024-08-31 15:48:58,200 [foster.py] => Task 6, Epoch 139/170 => Loss 2.865, Loss_clf 0.540, Loss_fe 0.398, Loss_kd 1.649, Train_accy 83.73, Test_accy 77.09
2024-08-31 15:49:05,186 [foster.py] => Task 6, Epoch 140/170 => Loss 2.884, Loss_clf 0.539, Loss_fe 0.420, Loss_kd 1.647, Train_accy 84.08, Test_accy 76.80
2024-08-31 15:49:10,560 [foster.py] => Task 6, Epoch 141/170 => Loss 2.837, Loss_clf 0.520, Loss_fe 0.385, Loss_kd 1.652, Train_accy 84.80
2024-08-31 15:49:17,537 [foster.py] => Task 6, Epoch 142/170 => Loss 2.807, Loss_clf 0.503, Loss_fe 0.403, Loss_kd 1.627, Train_accy 85.07, Test_accy 77.09
2024-08-31 15:49:24,551 [foster.py] => Task 6, Epoch 143/170 => Loss 2.848, Loss_clf 0.527, Loss_fe 0.394, Loss_kd 1.649, Train_accy 84.91, Test_accy 77.29
2024-08-31 15:49:31,603 [foster.py] => Task 6, Epoch 144/170 => Loss 2.789, Loss_clf 0.496, Loss_fe 0.378, Loss_kd 1.638, Train_accy 85.27, Test_accy 78.37
2024-08-31 15:49:38,586 [foster.py] => Task 6, Epoch 145/170 => Loss 2.809, Loss_clf 0.506, Loss_fe 0.384, Loss_kd 1.642, Train_accy 85.71, Test_accy 77.83
2024-08-31 15:49:43,893 [foster.py] => Task 6, Epoch 146/170 => Loss 2.778, Loss_clf 0.491, Loss_fe 0.364, Loss_kd 1.646, Train_accy 85.67
2024-08-31 15:49:50,905 [foster.py] => Task 6, Epoch 147/170 => Loss 2.784, Loss_clf 0.490, Loss_fe 0.359, Loss_kd 1.656, Train_accy 85.31, Test_accy 77.51
2024-08-31 15:49:57,948 [foster.py] => Task 6, Epoch 148/170 => Loss 2.780, Loss_clf 0.492, Loss_fe 0.365, Loss_kd 1.646, Train_accy 85.45, Test_accy 77.26
2024-08-31 15:50:04,934 [foster.py] => Task 6, Epoch 149/170 => Loss 2.780, Loss_clf 0.494, Loss_fe 0.357, Loss_kd 1.650, Train_accy 85.45, Test_accy 77.34
2024-08-31 15:50:11,947 [foster.py] => Task 6, Epoch 150/170 => Loss 2.706, Loss_clf 0.455, Loss_fe 0.334, Loss_kd 1.640, Train_accy 86.21, Test_accy 77.57
2024-08-31 15:50:17,364 [foster.py] => Task 6, Epoch 151/170 => Loss 2.778, Loss_clf 0.492, Loss_fe 0.348, Loss_kd 1.658, Train_accy 85.47
2024-08-31 15:50:24,360 [foster.py] => Task 6, Epoch 152/170 => Loss 2.707, Loss_clf 0.458, Loss_fe 0.330, Loss_kd 1.642, Train_accy 86.94, Test_accy 77.83
2024-08-31 15:50:31,399 [foster.py] => Task 6, Epoch 153/170 => Loss 2.746, Loss_clf 0.480, Loss_fe 0.340, Loss_kd 1.648, Train_accy 85.31, Test_accy 77.80
2024-08-31 15:50:38,435 [foster.py] => Task 6, Epoch 154/170 => Loss 2.753, Loss_clf 0.487, Loss_fe 0.334, Loss_kd 1.653, Train_accy 85.94, Test_accy 77.69
2024-08-31 15:50:45,461 [foster.py] => Task 6, Epoch 155/170 => Loss 2.732, Loss_clf 0.478, Loss_fe 0.331, Loss_kd 1.645, Train_accy 86.32, Test_accy 77.60
2024-08-31 15:50:50,756 [foster.py] => Task 6, Epoch 156/170 => Loss 2.719, Loss_clf 0.475, Loss_fe 0.336, Loss_kd 1.632, Train_accy 86.36
2024-08-31 15:50:57,752 [foster.py] => Task 6, Epoch 157/170 => Loss 2.740, Loss_clf 0.493, Loss_fe 0.334, Loss_kd 1.636, Train_accy 85.22, Test_accy 77.54
2024-08-31 15:51:04,716 [foster.py] => Task 6, Epoch 158/170 => Loss 2.741, Loss_clf 0.475, Loss_fe 0.330, Loss_kd 1.657, Train_accy 86.43, Test_accy 78.06
2024-08-31 15:51:11,723 [foster.py] => Task 6, Epoch 159/170 => Loss 2.745, Loss_clf 0.487, Loss_fe 0.329, Loss_kd 1.651, Train_accy 85.94, Test_accy 77.94
2024-08-31 15:51:18,798 [foster.py] => Task 6, Epoch 160/170 => Loss 2.698, Loss_clf 0.463, Loss_fe 0.306, Loss_kd 1.650, Train_accy 87.30, Test_accy 77.97
2024-08-31 15:51:24,123 [foster.py] => Task 6, Epoch 161/170 => Loss 2.716, Loss_clf 0.462, Loss_fe 0.321, Loss_kd 1.654, Train_accy 86.09
2024-08-31 15:51:31,129 [foster.py] => Task 6, Epoch 162/170 => Loss 2.689, Loss_clf 0.452, Loss_fe 0.309, Loss_kd 1.649, Train_accy 86.85, Test_accy 77.97
2024-08-31 15:51:38,155 [foster.py] => Task 6, Epoch 163/170 => Loss 2.723, Loss_clf 0.466, Loss_fe 0.334, Loss_kd 1.646, Train_accy 86.43, Test_accy 77.94
2024-08-31 15:51:45,093 [foster.py] => Task 6, Epoch 164/170 => Loss 2.706, Loss_clf 0.466, Loss_fe 0.307, Loss_kd 1.654, Train_accy 86.63, Test_accy 77.97
2024-08-31 15:51:52,154 [foster.py] => Task 6, Epoch 165/170 => Loss 2.695, Loss_clf 0.454, Loss_fe 0.311, Loss_kd 1.651, Train_accy 87.01, Test_accy 77.89
2024-08-31 15:51:57,524 [foster.py] => Task 6, Epoch 166/170 => Loss 2.724, Loss_clf 0.478, Loss_fe 0.309, Loss_kd 1.657, Train_accy 86.16
2024-08-31 15:52:04,613 [foster.py] => Task 6, Epoch 167/170 => Loss 2.726, Loss_clf 0.479, Loss_fe 0.311, Loss_kd 1.656, Train_accy 86.07, Test_accy 77.83
2024-08-31 15:52:11,619 [foster.py] => Task 6, Epoch 168/170 => Loss 2.744, Loss_clf 0.480, Loss_fe 0.329, Loss_kd 1.656, Train_accy 86.27, Test_accy 78.00
2024-08-31 15:52:18,642 [foster.py] => Task 6, Epoch 169/170 => Loss 2.675, Loss_clf 0.455, Loss_fe 0.300, Loss_kd 1.643, Train_accy 86.92, Test_accy 77.94
2024-08-31 15:52:25,672 [foster.py] => Task 6, Epoch 170/170 => Loss 2.697, Loss_clf 0.459, Loss_fe 0.304, Loss_kd 1.655, Train_accy 86.67, Test_accy 77.89
2024-08-31 15:52:25,675 [foster.py] => do not weight align teacher!
2024-08-31 15:52:25,676 [foster.py] => per cls weights : [1.0313348  1.0313348  1.0313348  1.0313348  1.0313348  1.0313348
 1.0313348  1.0313348  1.0313348  1.0313348  1.0313348  1.0313348
 1.0313348  1.0313348  1.0313348  1.0313348  1.0313348  1.0313348
 1.0313348  1.0313348  1.0313348  1.0313348  1.0313348  1.0313348
 1.0313348  1.0313348  1.0313348  1.0313348  1.0313348  1.0313348
 0.81199122 0.81199122 0.81199122 0.81199122 0.81199122]
2024-08-31 15:52:34,577 [foster.py] => SNet: Task 6, Epoch 1/130 => Loss 24.207,  Loss1 0.613, Train_accy 50.00, Test_accy 64.80
2024-08-31 15:52:41,898 [foster.py] => SNet: Task 6, Epoch 2/130 => Loss 23.991,  Loss1 0.614, Train_accy 64.49
2024-08-31 15:52:49,364 [foster.py] => SNet: Task 6, Epoch 3/130 => Loss 23.998,  Loss1 0.613, Train_accy 67.68
2024-08-31 15:52:56,605 [foster.py] => SNet: Task 6, Epoch 4/130 => Loss 23.972,  Loss1 0.614, Train_accy 68.84
2024-08-31 15:53:03,821 [foster.py] => SNet: Task 6, Epoch 5/130 => Loss 23.939,  Loss1 0.614, Train_accy 70.54
2024-08-31 15:53:12,461 [foster.py] => SNet: Task 6, Epoch 6/130 => Loss 23.969,  Loss1 0.614, Train_accy 71.14, Test_accy 70.09
2024-08-31 15:53:19,614 [foster.py] => SNet: Task 6, Epoch 7/130 => Loss 23.954,  Loss1 0.613, Train_accy 71.07
2024-08-31 15:53:27,333 [foster.py] => SNet: Task 6, Epoch 8/130 => Loss 23.961,  Loss1 0.613, Train_accy 72.54
2024-08-31 15:53:34,702 [foster.py] => SNet: Task 6, Epoch 9/130 => Loss 23.938,  Loss1 0.614, Train_accy 72.39
2024-08-31 15:53:41,896 [foster.py] => SNet: Task 6, Epoch 10/130 => Loss 23.973,  Loss1 0.613, Train_accy 72.23
2024-08-31 15:53:50,946 [foster.py] => SNet: Task 6, Epoch 11/130 => Loss 23.938,  Loss1 0.613, Train_accy 73.77, Test_accy 71.09
2024-08-31 15:53:58,225 [foster.py] => SNet: Task 6, Epoch 12/130 => Loss 23.928,  Loss1 0.614, Train_accy 74.08
2024-08-31 15:54:05,744 [foster.py] => SNet: Task 6, Epoch 13/130 => Loss 23.908,  Loss1 0.613, Train_accy 74.69
2024-08-31 15:54:13,294 [foster.py] => SNet: Task 6, Epoch 14/130 => Loss 23.952,  Loss1 0.613, Train_accy 74.11
2024-08-31 15:54:20,695 [foster.py] => SNet: Task 6, Epoch 15/130 => Loss 23.935,  Loss1 0.614, Train_accy 75.51
2024-08-31 15:54:29,287 [foster.py] => SNet: Task 6, Epoch 16/130 => Loss 23.943,  Loss1 0.614, Train_accy 73.77, Test_accy 70.77
2024-08-31 15:54:36,493 [foster.py] => SNet: Task 6, Epoch 17/130 => Loss 23.921,  Loss1 0.614, Train_accy 75.25
2024-08-31 15:54:43,631 [foster.py] => SNet: Task 6, Epoch 18/130 => Loss 23.937,  Loss1 0.613, Train_accy 75.80
2024-08-31 15:54:50,740 [foster.py] => SNet: Task 6, Epoch 19/130 => Loss 23.907,  Loss1 0.614, Train_accy 76.45
2024-08-31 15:54:57,936 [foster.py] => SNet: Task 6, Epoch 20/130 => Loss 23.887,  Loss1 0.614, Train_accy 76.29
2024-08-31 15:55:06,593 [foster.py] => SNet: Task 6, Epoch 21/130 => Loss 23.897,  Loss1 0.614, Train_accy 76.79, Test_accy 73.83
2024-08-31 15:55:14,016 [foster.py] => SNet: Task 6, Epoch 22/130 => Loss 23.916,  Loss1 0.614, Train_accy 76.29
2024-08-31 15:55:21,278 [foster.py] => SNet: Task 6, Epoch 23/130 => Loss 23.917,  Loss1 0.614, Train_accy 76.32
2024-08-31 15:55:28,446 [foster.py] => SNet: Task 6, Epoch 24/130 => Loss 23.892,  Loss1 0.614, Train_accy 76.88
2024-08-31 15:55:35,865 [foster.py] => SNet: Task 6, Epoch 25/130 => Loss 23.870,  Loss1 0.614, Train_accy 77.88
2024-08-31 15:55:44,491 [foster.py] => SNet: Task 6, Epoch 26/130 => Loss 23.905,  Loss1 0.614, Train_accy 76.99, Test_accy 74.23
2024-08-31 15:55:51,581 [foster.py] => SNet: Task 6, Epoch 27/130 => Loss 23.903,  Loss1 0.613, Train_accy 77.54
2024-08-31 15:55:58,808 [foster.py] => SNet: Task 6, Epoch 28/130 => Loss 23.903,  Loss1 0.614, Train_accy 77.50
2024-08-31 15:56:06,114 [foster.py] => SNet: Task 6, Epoch 29/130 => Loss 23.931,  Loss1 0.614, Train_accy 77.46
2024-08-31 15:56:13,186 [foster.py] => SNet: Task 6, Epoch 30/130 => Loss 23.888,  Loss1 0.614, Train_accy 77.70
2024-08-31 15:56:21,677 [foster.py] => SNet: Task 6, Epoch 31/130 => Loss 23.911,  Loss1 0.614, Train_accy 77.99, Test_accy 73.94
2024-08-31 15:56:28,868 [foster.py] => SNet: Task 6, Epoch 32/130 => Loss 23.893,  Loss1 0.613, Train_accy 77.81
2024-08-31 15:56:36,093 [foster.py] => SNet: Task 6, Epoch 33/130 => Loss 23.904,  Loss1 0.614, Train_accy 78.12
2024-08-31 15:56:43,795 [foster.py] => SNet: Task 6, Epoch 34/130 => Loss 23.918,  Loss1 0.614, Train_accy 78.71
2024-08-31 15:56:50,869 [foster.py] => SNet: Task 6, Epoch 35/130 => Loss 23.892,  Loss1 0.614, Train_accy 79.35
2024-08-31 15:56:59,431 [foster.py] => SNet: Task 6, Epoch 36/130 => Loss 23.896,  Loss1 0.614, Train_accy 78.84, Test_accy 74.37
2024-08-31 15:57:06,906 [foster.py] => SNet: Task 6, Epoch 37/130 => Loss 23.878,  Loss1 0.614, Train_accy 79.35
2024-08-31 15:57:14,019 [foster.py] => SNet: Task 6, Epoch 38/130 => Loss 23.866,  Loss1 0.614, Train_accy 79.35
2024-08-31 15:57:21,321 [foster.py] => SNet: Task 6, Epoch 39/130 => Loss 23.878,  Loss1 0.614, Train_accy 78.66
2024-08-31 15:57:28,719 [foster.py] => SNet: Task 6, Epoch 40/130 => Loss 23.880,  Loss1 0.613, Train_accy 79.87
2024-08-31 15:57:37,717 [foster.py] => SNet: Task 6, Epoch 41/130 => Loss 23.859,  Loss1 0.614, Train_accy 78.75, Test_accy 73.91
2024-08-31 15:57:44,852 [foster.py] => SNet: Task 6, Epoch 42/130 => Loss 23.886,  Loss1 0.614, Train_accy 79.80
2024-08-31 15:57:52,077 [foster.py] => SNet: Task 6, Epoch 43/130 => Loss 23.901,  Loss1 0.614, Train_accy 80.27
2024-08-31 15:57:59,162 [foster.py] => SNet: Task 6, Epoch 44/130 => Loss 23.880,  Loss1 0.614, Train_accy 80.67
2024-08-31 15:58:06,741 [foster.py] => SNet: Task 6, Epoch 45/130 => Loss 23.867,  Loss1 0.614, Train_accy 80.29
2024-08-31 15:58:15,498 [foster.py] => SNet: Task 6, Epoch 46/130 => Loss 23.868,  Loss1 0.614, Train_accy 80.07, Test_accy 74.71
2024-08-31 15:58:22,646 [foster.py] => SNet: Task 6, Epoch 47/130 => Loss 23.876,  Loss1 0.614, Train_accy 80.25
2024-08-31 15:58:29,917 [foster.py] => SNet: Task 6, Epoch 48/130 => Loss 23.911,  Loss1 0.614, Train_accy 79.78
2024-08-31 15:58:37,229 [foster.py] => SNet: Task 6, Epoch 49/130 => Loss 23.849,  Loss1 0.614, Train_accy 80.33
2024-08-31 15:58:44,656 [foster.py] => SNet: Task 6, Epoch 50/130 => Loss 23.879,  Loss1 0.614, Train_accy 79.87
2024-08-31 15:58:53,191 [foster.py] => SNet: Task 6, Epoch 51/130 => Loss 23.872,  Loss1 0.614, Train_accy 81.56, Test_accy 75.97
2024-08-31 15:59:00,372 [foster.py] => SNet: Task 6, Epoch 52/130 => Loss 23.873,  Loss1 0.614, Train_accy 80.40
2024-08-31 15:59:07,527 [foster.py] => SNet: Task 6, Epoch 53/130 => Loss 23.872,  Loss1 0.614, Train_accy 81.12
2024-08-31 15:59:14,680 [foster.py] => SNet: Task 6, Epoch 54/130 => Loss 23.878,  Loss1 0.614, Train_accy 80.98
2024-08-31 15:59:22,025 [foster.py] => SNet: Task 6, Epoch 55/130 => Loss 23.867,  Loss1 0.614, Train_accy 80.69
2024-08-31 15:59:30,641 [foster.py] => SNet: Task 6, Epoch 56/130 => Loss 23.881,  Loss1 0.614, Train_accy 80.65, Test_accy 75.03
2024-08-31 15:59:37,843 [foster.py] => SNet: Task 6, Epoch 57/130 => Loss 23.881,  Loss1 0.614, Train_accy 79.84
2024-08-31 15:59:44,993 [foster.py] => SNet: Task 6, Epoch 58/130 => Loss 23.866,  Loss1 0.614, Train_accy 81.29
2024-08-31 15:59:52,173 [foster.py] => SNet: Task 6, Epoch 59/130 => Loss 23.864,  Loss1 0.614, Train_accy 81.56
2024-08-31 15:59:59,593 [foster.py] => SNet: Task 6, Epoch 60/130 => Loss 23.852,  Loss1 0.614, Train_accy 80.56
2024-08-31 16:00:08,567 [foster.py] => SNet: Task 6, Epoch 61/130 => Loss 23.874,  Loss1 0.613, Train_accy 80.65, Test_accy 75.37
2024-08-31 16:00:15,904 [foster.py] => SNet: Task 6, Epoch 62/130 => Loss 23.870,  Loss1 0.614, Train_accy 81.32
2024-08-31 16:00:23,089 [foster.py] => SNet: Task 6, Epoch 63/130 => Loss 23.873,  Loss1 0.614, Train_accy 80.85
2024-08-31 16:00:30,180 [foster.py] => SNet: Task 6, Epoch 64/130 => Loss 23.847,  Loss1 0.614, Train_accy 81.63
2024-08-31 16:00:37,362 [foster.py] => SNet: Task 6, Epoch 65/130 => Loss 23.879,  Loss1 0.614, Train_accy 81.99
2024-08-31 16:00:46,084 [foster.py] => SNet: Task 6, Epoch 66/130 => Loss 23.874,  Loss1 0.614, Train_accy 81.21, Test_accy 75.20
2024-08-31 16:00:53,289 [foster.py] => SNet: Task 6, Epoch 67/130 => Loss 23.875,  Loss1 0.614, Train_accy 81.16
2024-08-31 16:01:00,538 [foster.py] => SNet: Task 6, Epoch 68/130 => Loss 23.864,  Loss1 0.613, Train_accy 81.29
2024-08-31 16:01:08,485 [foster.py] => SNet: Task 6, Epoch 69/130 => Loss 23.890,  Loss1 0.614, Train_accy 80.98
2024-08-31 16:01:15,804 [foster.py] => SNet: Task 6, Epoch 70/130 => Loss 23.869,  Loss1 0.614, Train_accy 82.59
2024-08-31 16:01:24,761 [foster.py] => SNet: Task 6, Epoch 71/130 => Loss 23.848,  Loss1 0.614, Train_accy 81.83, Test_accy 74.63
2024-08-31 16:01:32,044 [foster.py] => SNet: Task 6, Epoch 72/130 => Loss 23.871,  Loss1 0.614, Train_accy 81.94
2024-08-31 16:01:39,308 [foster.py] => SNet: Task 6, Epoch 73/130 => Loss 23.866,  Loss1 0.614, Train_accy 81.67
2024-08-31 16:01:46,496 [foster.py] => SNet: Task 6, Epoch 74/130 => Loss 23.858,  Loss1 0.614, Train_accy 82.86
2024-08-31 16:01:53,676 [foster.py] => SNet: Task 6, Epoch 75/130 => Loss 23.866,  Loss1 0.614, Train_accy 82.63
2024-08-31 16:02:02,307 [foster.py] => SNet: Task 6, Epoch 76/130 => Loss 23.863,  Loss1 0.614, Train_accy 82.01, Test_accy 75.97
2024-08-31 16:02:09,667 [foster.py] => SNet: Task 6, Epoch 77/130 => Loss 23.879,  Loss1 0.614, Train_accy 81.99
2024-08-31 16:02:16,914 [foster.py] => SNet: Task 6, Epoch 78/130 => Loss 23.885,  Loss1 0.614, Train_accy 81.56
2024-08-31 16:02:24,286 [foster.py] => SNet: Task 6, Epoch 79/130 => Loss 23.853,  Loss1 0.614, Train_accy 82.81
2024-08-31 16:02:31,562 [foster.py] => SNet: Task 6, Epoch 80/130 => Loss 23.879,  Loss1 0.614, Train_accy 82.28
2024-08-31 16:02:40,002 [foster.py] => SNet: Task 6, Epoch 81/130 => Loss 23.859,  Loss1 0.614, Train_accy 81.79, Test_accy 76.00
2024-08-31 16:02:47,215 [foster.py] => SNet: Task 6, Epoch 82/130 => Loss 23.876,  Loss1 0.614, Train_accy 81.92
2024-08-31 16:02:54,386 [foster.py] => SNet: Task 6, Epoch 83/130 => Loss 23.821,  Loss1 0.614, Train_accy 82.88
2024-08-31 16:03:01,599 [foster.py] => SNet: Task 6, Epoch 84/130 => Loss 23.882,  Loss1 0.614, Train_accy 81.76
2024-08-31 16:03:08,851 [foster.py] => SNet: Task 6, Epoch 85/130 => Loss 23.851,  Loss1 0.614, Train_accy 82.30
2024-08-31 16:03:17,613 [foster.py] => SNet: Task 6, Epoch 86/130 => Loss 23.862,  Loss1 0.614, Train_accy 82.54, Test_accy 76.17
2024-08-31 16:03:24,858 [foster.py] => SNet: Task 6, Epoch 87/130 => Loss 23.852,  Loss1 0.614, Train_accy 81.85
2024-08-31 16:03:32,363 [foster.py] => SNet: Task 6, Epoch 88/130 => Loss 23.843,  Loss1 0.614, Train_accy 81.65
2024-08-31 16:03:39,503 [foster.py] => SNet: Task 6, Epoch 89/130 => Loss 23.875,  Loss1 0.613, Train_accy 83.35
2024-08-31 16:03:47,211 [foster.py] => SNet: Task 6, Epoch 90/130 => Loss 23.849,  Loss1 0.614, Train_accy 81.83
2024-08-31 16:03:55,749 [foster.py] => SNet: Task 6, Epoch 91/130 => Loss 23.847,  Loss1 0.614, Train_accy 83.19, Test_accy 76.00
2024-08-31 16:04:03,150 [foster.py] => SNet: Task 6, Epoch 92/130 => Loss 23.856,  Loss1 0.614, Train_accy 82.41
2024-08-31 16:04:10,361 [foster.py] => SNet: Task 6, Epoch 93/130 => Loss 23.800,  Loss1 0.614, Train_accy 82.95
2024-08-31 16:04:17,559 [foster.py] => SNet: Task 6, Epoch 94/130 => Loss 23.826,  Loss1 0.613, Train_accy 83.17
2024-08-31 16:04:24,822 [foster.py] => SNet: Task 6, Epoch 95/130 => Loss 23.821,  Loss1 0.614, Train_accy 82.61
2024-08-31 16:04:33,700 [foster.py] => SNet: Task 6, Epoch 96/130 => Loss 23.850,  Loss1 0.614, Train_accy 83.12, Test_accy 76.23
2024-08-31 16:04:40,888 [foster.py] => SNet: Task 6, Epoch 97/130 => Loss 23.879,  Loss1 0.614, Train_accy 82.05
2024-08-31 16:04:48,047 [foster.py] => SNet: Task 6, Epoch 98/130 => Loss 23.858,  Loss1 0.614, Train_accy 82.72
2024-08-31 16:04:55,252 [foster.py] => SNet: Task 6, Epoch 99/130 => Loss 23.832,  Loss1 0.614, Train_accy 83.19
2024-08-31 16:05:02,442 [foster.py] => SNet: Task 6, Epoch 100/130 => Loss 23.865,  Loss1 0.614, Train_accy 82.23
2024-08-31 16:05:11,235 [foster.py] => SNet: Task 6, Epoch 101/130 => Loss 23.828,  Loss1 0.614, Train_accy 83.73, Test_accy 75.83
2024-08-31 16:05:18,482 [foster.py] => SNet: Task 6, Epoch 102/130 => Loss 23.871,  Loss1 0.614, Train_accy 82.21
2024-08-31 16:05:25,756 [foster.py] => SNet: Task 6, Epoch 103/130 => Loss 23.851,  Loss1 0.614, Train_accy 82.92
2024-08-31 16:05:32,968 [foster.py] => SNet: Task 6, Epoch 104/130 => Loss 23.855,  Loss1 0.614, Train_accy 82.30
2024-08-31 16:05:40,487 [foster.py] => SNet: Task 6, Epoch 105/130 => Loss 23.855,  Loss1 0.614, Train_accy 82.97
2024-08-31 16:05:49,101 [foster.py] => SNet: Task 6, Epoch 106/130 => Loss 23.866,  Loss1 0.614, Train_accy 82.99, Test_accy 76.23
2024-08-31 16:05:56,300 [foster.py] => SNet: Task 6, Epoch 107/130 => Loss 23.860,  Loss1 0.614, Train_accy 82.75
2024-08-31 16:06:03,727 [foster.py] => SNet: Task 6, Epoch 108/130 => Loss 23.834,  Loss1 0.614, Train_accy 83.26
2024-08-31 16:06:11,043 [foster.py] => SNet: Task 6, Epoch 109/130 => Loss 23.859,  Loss1 0.614, Train_accy 82.57
2024-08-31 16:06:18,131 [foster.py] => SNet: Task 6, Epoch 110/130 => Loss 23.860,  Loss1 0.614, Train_accy 82.08
2024-08-31 16:06:26,771 [foster.py] => SNet: Task 6, Epoch 111/130 => Loss 23.893,  Loss1 0.614, Train_accy 83.35, Test_accy 76.60
2024-08-31 16:06:34,131 [foster.py] => SNet: Task 6, Epoch 112/130 => Loss 23.865,  Loss1 0.614, Train_accy 82.54
2024-08-31 16:06:41,558 [foster.py] => SNet: Task 6, Epoch 113/130 => Loss 23.867,  Loss1 0.614, Train_accy 83.64
2024-08-31 16:06:49,046 [foster.py] => SNet: Task 6, Epoch 114/130 => Loss 23.866,  Loss1 0.614, Train_accy 82.70
2024-08-31 16:06:56,194 [foster.py] => SNet: Task 6, Epoch 115/130 => Loss 23.821,  Loss1 0.614, Train_accy 82.99
2024-08-31 16:07:04,781 [foster.py] => SNet: Task 6, Epoch 116/130 => Loss 23.862,  Loss1 0.614, Train_accy 82.75, Test_accy 76.37
2024-08-31 16:07:12,127 [foster.py] => SNet: Task 6, Epoch 117/130 => Loss 23.849,  Loss1 0.614, Train_accy 83.84
2024-08-31 16:07:19,368 [foster.py] => SNet: Task 6, Epoch 118/130 => Loss 23.862,  Loss1 0.614, Train_accy 81.96
2024-08-31 16:07:26,838 [foster.py] => SNet: Task 6, Epoch 119/130 => Loss 23.859,  Loss1 0.614, Train_accy 82.75
2024-08-31 16:07:34,135 [foster.py] => SNet: Task 6, Epoch 120/130 => Loss 23.854,  Loss1 0.614, Train_accy 83.19
2024-08-31 16:07:42,710 [foster.py] => SNet: Task 6, Epoch 121/130 => Loss 23.846,  Loss1 0.614, Train_accy 83.91, Test_accy 76.34
2024-08-31 16:07:49,836 [foster.py] => SNet: Task 6, Epoch 122/130 => Loss 23.850,  Loss1 0.614, Train_accy 82.95
2024-08-31 16:07:57,192 [foster.py] => SNet: Task 6, Epoch 123/130 => Loss 23.873,  Loss1 0.614, Train_accy 82.03
2024-08-31 16:08:04,304 [foster.py] => SNet: Task 6, Epoch 124/130 => Loss 23.829,  Loss1 0.614, Train_accy 82.95
2024-08-31 16:08:11,773 [foster.py] => SNet: Task 6, Epoch 125/130 => Loss 23.855,  Loss1 0.614, Train_accy 83.10
2024-08-31 16:08:20,317 [foster.py] => SNet: Task 6, Epoch 126/130 => Loss 23.857,  Loss1 0.614, Train_accy 83.77, Test_accy 76.60
2024-08-31 16:08:27,492 [foster.py] => SNet: Task 6, Epoch 127/130 => Loss 23.851,  Loss1 0.614, Train_accy 83.39
2024-08-31 16:08:34,824 [foster.py] => SNet: Task 6, Epoch 128/130 => Loss 23.867,  Loss1 0.614, Train_accy 82.86
2024-08-31 16:08:42,007 [foster.py] => SNet: Task 6, Epoch 129/130 => Loss 23.862,  Loss1 0.614, Train_accy 82.59
2024-08-31 16:08:49,431 [foster.py] => SNet: Task 6, Epoch 130/130 => Loss 23.856,  Loss1 0.614, Train_accy 83.46
2024-08-31 16:08:49,432 [foster.py] => do not weight align student!
2024-08-31 16:08:50,896 [foster.py] => darknet eval: 
2024-08-31 16:08:50,897 [foster.py] => CNN top1 curve: 76.46
2024-08-31 16:08:50,897 [foster.py] => CNN top5 curve: 95.37
2024-08-31 16:08:50,897 [foster.py] => CNN top1 平均值: 76.46
2024-08-31 16:08:50,900 [foster.py] => timees : 2125.4090435504913
2024-08-31 16:08:50,901 [base.py] => Reducing exemplars...(57 per classes)
2024-08-31 16:09:01,464 [base.py] => Constructing exemplars...(57 per classes)
2024-08-31 16:09:10,009 [foster.py] => Exemplar size: 1995
2024-08-31 16:09:10,009 [trainer.py] => CNN: {'total': 77.89, '00-09': 79.2, '10-19': 68.2, '20-29': 81.1, '30-39': 88.2, 'old': 76.17, 'new': 88.2}
2024-08-31 16:09:10,009 [trainer.py] => NME: {'total': 75.09, '00-09': 77.1, '10-19': 68.5, '20-29': 74.8, '30-39': 84.8, 'old': 73.47, 'new': 84.8}
2024-08-31 16:09:10,009 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89]
2024-08-31 16:09:10,009 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86]
2024-08-31 16:09:10,010 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09]
2024-08-31 16:09:10,010 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97]

2024-08-31 16:09:10,010 [trainer.py] => CNN top1 平均值: 86.52
2024-08-31 16:09:10,012 [trainer.py] => All params: 1291288
2024-08-31 16:09:10,015 [trainer.py] => Trainable params: 648064
2024-08-31 16:09:10,127 [foster.py] => Learning on 35-40
2024-08-31 16:09:10,131 [foster.py] => All params: 1292583
2024-08-31 16:09:10,133 [foster.py] => Trainable params: 649034
2024-08-31 16:09:10,180 [foster.py] => per cls weights : [1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991
 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991
 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991
 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991
 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991
 1.01613991 1.01613991 1.01613991 1.01613991 1.01613991 0.88702062
 0.88702062 0.88702062 0.88702062 0.88702062]
2024-08-31 16:09:15,682 [foster.py] => Task 7, Epoch 1/170 => Loss 5.329, Loss_clf 1.460, Loss_fe 1.745, Loss_kd 1.854, Train_accy 58.58
2024-08-31 16:09:22,945 [foster.py] => Task 7, Epoch 2/170 => Loss 4.331, Loss_clf 0.999, Loss_fe 1.246, Loss_kd 1.820, Train_accy 69.10, Test_accy 67.28
2024-08-31 16:09:30,248 [foster.py] => Task 7, Epoch 3/170 => Loss 4.256, Loss_clf 1.012, Loss_fe 1.145, Loss_kd 1.831, Train_accy 69.63, Test_accy 65.03
2024-08-31 16:09:37,398 [foster.py] => Task 7, Epoch 4/170 => Loss 4.280, Loss_clf 1.026, Loss_fe 1.163, Loss_kd 1.826, Train_accy 68.65, Test_accy 63.32
2024-08-31 16:09:44,598 [foster.py] => Task 7, Epoch 5/170 => Loss 4.103, Loss_clf 0.951, Loss_fe 1.067, Loss_kd 1.820, Train_accy 71.21, Test_accy 70.95
2024-08-31 16:09:50,111 [foster.py] => Task 7, Epoch 6/170 => Loss 4.218, Loss_clf 0.983, Loss_fe 1.126, Loss_kd 1.841, Train_accy 70.30
2024-08-31 16:09:57,316 [foster.py] => Task 7, Epoch 7/170 => Loss 4.209, Loss_clf 0.990, Loss_fe 1.113, Loss_kd 1.838, Train_accy 69.32, Test_accy 65.97
2024-08-31 16:10:04,659 [foster.py] => Task 7, Epoch 8/170 => Loss 4.261, Loss_clf 0.982, Loss_fe 1.195, Loss_kd 1.819, Train_accy 70.81, Test_accy 68.78
2024-08-31 16:10:12,024 [foster.py] => Task 7, Epoch 9/170 => Loss 4.170, Loss_clf 0.938, Loss_fe 1.124, Loss_kd 1.840, Train_accy 71.10, Test_accy 68.30
2024-08-31 16:10:19,349 [foster.py] => Task 7, Epoch 10/170 => Loss 4.008, Loss_clf 0.895, Loss_fe 1.028, Loss_kd 1.819, Train_accy 72.08, Test_accy 69.15
2024-08-31 16:10:24,814 [foster.py] => Task 7, Epoch 11/170 => Loss 4.101, Loss_clf 0.968, Loss_fe 1.040, Loss_kd 1.828, Train_accy 71.30
2024-08-31 16:10:32,066 [foster.py] => Task 7, Epoch 12/170 => Loss 4.154, Loss_clf 0.977, Loss_fe 1.061, Loss_kd 1.847, Train_accy 70.21, Test_accy 66.47
2024-08-31 16:10:39,325 [foster.py] => Task 7, Epoch 13/170 => Loss 4.193, Loss_clf 0.945, Loss_fe 1.139, Loss_kd 1.841, Train_accy 71.97, Test_accy 66.47
2024-08-31 16:10:46,472 [foster.py] => Task 7, Epoch 14/170 => Loss 4.089, Loss_clf 0.928, Loss_fe 1.057, Loss_kd 1.837, Train_accy 70.97, Test_accy 69.10
2024-08-31 16:10:53,686 [foster.py] => Task 7, Epoch 15/170 => Loss 4.057, Loss_clf 0.911, Loss_fe 1.036, Loss_kd 1.842, Train_accy 72.17, Test_accy 63.80
2024-08-31 16:10:59,236 [foster.py] => Task 7, Epoch 16/170 => Loss 4.111, Loss_clf 0.963, Loss_fe 1.046, Loss_kd 1.836, Train_accy 71.64
2024-08-31 16:11:06,445 [foster.py] => Task 7, Epoch 17/170 => Loss 4.201, Loss_clf 0.964, Loss_fe 1.131, Loss_kd 1.839, Train_accy 71.10, Test_accy 62.38
2024-08-31 16:11:13,635 [foster.py] => Task 7, Epoch 18/170 => Loss 4.136, Loss_clf 0.950, Loss_fe 1.101, Loss_kd 1.821, Train_accy 71.12, Test_accy 69.82
2024-08-31 16:11:20,884 [foster.py] => Task 7, Epoch 19/170 => Loss 4.197, Loss_clf 0.939, Loss_fe 1.163, Loss_kd 1.829, Train_accy 71.86, Test_accy 69.58
2024-08-31 16:11:28,132 [foster.py] => Task 7, Epoch 20/170 => Loss 4.211, Loss_clf 0.946, Loss_fe 1.167, Loss_kd 1.832, Train_accy 71.50, Test_accy 69.97
2024-08-31 16:11:33,623 [foster.py] => Task 7, Epoch 21/170 => Loss 4.145, Loss_clf 0.919, Loss_fe 1.139, Loss_kd 1.822, Train_accy 71.21
2024-08-31 16:11:40,850 [foster.py] => Task 7, Epoch 22/170 => Loss 4.119, Loss_clf 0.945, Loss_fe 1.077, Loss_kd 1.831, Train_accy 71.52, Test_accy 68.38
2024-08-31 16:11:48,063 [foster.py] => Task 7, Epoch 23/170 => Loss 4.053, Loss_clf 0.916, Loss_fe 1.057, Loss_kd 1.817, Train_accy 71.95, Test_accy 70.50
2024-08-31 16:11:55,354 [foster.py] => Task 7, Epoch 24/170 => Loss 4.057, Loss_clf 0.893, Loss_fe 1.051, Loss_kd 1.845, Train_accy 72.04, Test_accy 68.32
2024-08-31 16:12:02,535 [foster.py] => Task 7, Epoch 25/170 => Loss 4.119, Loss_clf 0.960, Loss_fe 1.057, Loss_kd 1.836, Train_accy 70.92, Test_accy 69.62
2024-08-31 16:12:08,049 [foster.py] => Task 7, Epoch 26/170 => Loss 4.189, Loss_clf 0.988, Loss_fe 1.089, Loss_kd 1.844, Train_accy 69.72
2024-08-31 16:12:15,233 [foster.py] => Task 7, Epoch 27/170 => Loss 4.052, Loss_clf 0.906, Loss_fe 1.066, Loss_kd 1.817, Train_accy 72.26, Test_accy 66.40
2024-08-31 16:12:22,579 [foster.py] => Task 7, Epoch 28/170 => Loss 4.001, Loss_clf 0.881, Loss_fe 1.030, Loss_kd 1.824, Train_accy 72.55, Test_accy 65.95
2024-08-31 16:12:29,820 [foster.py] => Task 7, Epoch 29/170 => Loss 4.020, Loss_clf 0.885, Loss_fe 1.027, Loss_kd 1.840, Train_accy 73.77, Test_accy 69.12
2024-08-31 16:12:37,070 [foster.py] => Task 7, Epoch 30/170 => Loss 4.079, Loss_clf 0.935, Loss_fe 1.059, Loss_kd 1.820, Train_accy 71.81, Test_accy 62.62
2024-08-31 16:12:42,631 [foster.py] => Task 7, Epoch 31/170 => Loss 4.083, Loss_clf 0.927, Loss_fe 1.055, Loss_kd 1.834, Train_accy 72.19
2024-08-31 16:12:49,839 [foster.py] => Task 7, Epoch 32/170 => Loss 4.114, Loss_clf 0.957, Loss_fe 1.053, Loss_kd 1.837, Train_accy 71.28, Test_accy 72.00
2024-08-31 16:12:57,063 [foster.py] => Task 7, Epoch 33/170 => Loss 4.018, Loss_clf 0.907, Loss_fe 1.019, Loss_kd 1.827, Train_accy 73.35, Test_accy 68.72
2024-08-31 16:13:04,286 [foster.py] => Task 7, Epoch 34/170 => Loss 4.099, Loss_clf 0.915, Loss_fe 1.082, Loss_kd 1.836, Train_accy 72.21, Test_accy 65.55
2024-08-31 16:13:11,518 [foster.py] => Task 7, Epoch 35/170 => Loss 4.033, Loss_clf 0.890, Loss_fe 1.049, Loss_kd 1.828, Train_accy 73.21, Test_accy 70.05
2024-08-31 16:13:16,917 [foster.py] => Task 7, Epoch 36/170 => Loss 4.139, Loss_clf 0.921, Loss_fe 1.115, Loss_kd 1.836, Train_accy 71.30
2024-08-31 16:13:24,110 [foster.py] => Task 7, Epoch 37/170 => Loss 4.117, Loss_clf 0.971, Loss_fe 1.060, Loss_kd 1.821, Train_accy 70.14, Test_accy 69.88
2024-08-31 16:13:31,376 [foster.py] => Task 7, Epoch 38/170 => Loss 4.121, Loss_clf 0.947, Loss_fe 1.072, Loss_kd 1.836, Train_accy 72.04, Test_accy 70.47
2024-08-31 16:13:38,597 [foster.py] => Task 7, Epoch 39/170 => Loss 4.053, Loss_clf 0.909, Loss_fe 1.046, Loss_kd 1.832, Train_accy 71.68, Test_accy 70.95
2024-08-31 16:13:45,792 [foster.py] => Task 7, Epoch 40/170 => Loss 4.003, Loss_clf 0.893, Loss_fe 1.015, Loss_kd 1.829, Train_accy 73.26, Test_accy 69.85
2024-08-31 16:13:51,223 [foster.py] => Task 7, Epoch 41/170 => Loss 4.009, Loss_clf 0.868, Loss_fe 1.062, Loss_kd 1.815, Train_accy 72.95
2024-08-31 16:13:58,478 [foster.py] => Task 7, Epoch 42/170 => Loss 4.059, Loss_clf 0.901, Loss_fe 1.066, Loss_kd 1.827, Train_accy 72.46, Test_accy 69.53
2024-08-31 16:14:05,721 [foster.py] => Task 7, Epoch 43/170 => Loss 4.006, Loss_clf 0.925, Loss_fe 1.010, Loss_kd 1.809, Train_accy 71.92, Test_accy 70.30
2024-08-31 16:14:13,082 [foster.py] => Task 7, Epoch 44/170 => Loss 3.963, Loss_clf 0.879, Loss_fe 1.001, Loss_kd 1.819, Train_accy 73.46, Test_accy 71.68
2024-08-31 16:14:20,274 [foster.py] => Task 7, Epoch 45/170 => Loss 3.973, Loss_clf 0.888, Loss_fe 0.998, Loss_kd 1.822, Train_accy 73.13, Test_accy 70.15
2024-08-31 16:14:25,719 [foster.py] => Task 7, Epoch 46/170 => Loss 3.969, Loss_clf 0.864, Loss_fe 1.003, Loss_kd 1.836, Train_accy 73.13
2024-08-31 16:14:33,048 [foster.py] => Task 7, Epoch 47/170 => Loss 3.952, Loss_clf 0.886, Loss_fe 0.990, Loss_kd 1.814, Train_accy 74.08, Test_accy 70.95
2024-08-31 16:14:40,337 [foster.py] => Task 7, Epoch 48/170 => Loss 3.957, Loss_clf 0.870, Loss_fe 1.003, Loss_kd 1.820, Train_accy 73.88, Test_accy 69.10
2024-08-31 16:14:47,602 [foster.py] => Task 7, Epoch 49/170 => Loss 3.922, Loss_clf 0.869, Loss_fe 0.967, Loss_kd 1.822, Train_accy 72.70, Test_accy 70.03
2024-08-31 16:14:54,967 [foster.py] => Task 7, Epoch 50/170 => Loss 3.992, Loss_clf 0.921, Loss_fe 0.969, Loss_kd 1.836, Train_accy 71.64, Test_accy 68.15
2024-08-31 16:15:00,500 [foster.py] => Task 7, Epoch 51/170 => Loss 3.979, Loss_clf 0.877, Loss_fe 1.008, Loss_kd 1.829, Train_accy 72.37
2024-08-31 16:15:07,751 [foster.py] => Task 7, Epoch 52/170 => Loss 4.030, Loss_clf 0.957, Loss_fe 0.996, Loss_kd 1.814, Train_accy 71.48, Test_accy 68.70
2024-08-31 16:15:15,016 [foster.py] => Task 7, Epoch 53/170 => Loss 3.977, Loss_clf 0.886, Loss_fe 1.011, Loss_kd 1.816, Train_accy 73.06, Test_accy 67.78
2024-08-31 16:15:22,178 [foster.py] => Task 7, Epoch 54/170 => Loss 3.933, Loss_clf 0.862, Loss_fe 0.995, Loss_kd 1.813, Train_accy 73.08, Test_accy 71.72
2024-08-31 16:15:29,390 [foster.py] => Task 7, Epoch 55/170 => Loss 3.873, Loss_clf 0.849, Loss_fe 0.934, Loss_kd 1.825, Train_accy 73.84, Test_accy 67.90
2024-08-31 16:15:34,836 [foster.py] => Task 7, Epoch 56/170 => Loss 3.975, Loss_clf 0.864, Loss_fe 1.004, Loss_kd 1.840, Train_accy 74.26
2024-08-31 16:15:42,028 [foster.py] => Task 7, Epoch 57/170 => Loss 4.002, Loss_clf 0.887, Loss_fe 1.016, Loss_kd 1.833, Train_accy 71.79, Test_accy 70.80
2024-08-31 16:15:49,290 [foster.py] => Task 7, Epoch 58/170 => Loss 3.923, Loss_clf 0.854, Loss_fe 0.986, Loss_kd 1.819, Train_accy 74.17, Test_accy 70.70
2024-08-31 16:15:56,594 [foster.py] => Task 7, Epoch 59/170 => Loss 3.975, Loss_clf 0.863, Loss_fe 1.017, Loss_kd 1.829, Train_accy 73.04, Test_accy 71.90
2024-08-31 16:16:03,775 [foster.py] => Task 7, Epoch 60/170 => Loss 3.870, Loss_clf 0.861, Loss_fe 0.929, Loss_kd 1.817, Train_accy 73.10, Test_accy 73.08
2024-08-31 16:16:09,279 [foster.py] => Task 7, Epoch 61/170 => Loss 3.877, Loss_clf 0.865, Loss_fe 0.919, Loss_kd 1.828, Train_accy 74.26
2024-08-31 16:16:16,570 [foster.py] => Task 7, Epoch 62/170 => Loss 3.964, Loss_clf 0.850, Loss_fe 1.024, Loss_kd 1.825, Train_accy 73.15, Test_accy 67.80
2024-08-31 16:16:23,799 [foster.py] => Task 7, Epoch 63/170 => Loss 3.868, Loss_clf 0.859, Loss_fe 0.922, Loss_kd 1.822, Train_accy 73.62, Test_accy 69.25
2024-08-31 16:16:31,018 [foster.py] => Task 7, Epoch 64/170 => Loss 3.890, Loss_clf 0.854, Loss_fe 0.952, Loss_kd 1.820, Train_accy 73.21, Test_accy 69.85
2024-08-31 16:16:38,315 [foster.py] => Task 7, Epoch 65/170 => Loss 3.832, Loss_clf 0.835, Loss_fe 0.909, Loss_kd 1.823, Train_accy 74.53, Test_accy 71.45
2024-08-31 16:16:43,824 [foster.py] => Task 7, Epoch 66/170 => Loss 3.852, Loss_clf 0.842, Loss_fe 0.923, Loss_kd 1.821, Train_accy 74.62
2024-08-31 16:16:51,045 [foster.py] => Task 7, Epoch 67/170 => Loss 3.837, Loss_clf 0.840, Loss_fe 0.914, Loss_kd 1.819, Train_accy 74.82, Test_accy 69.40
2024-08-31 16:16:58,229 [foster.py] => Task 7, Epoch 68/170 => Loss 3.888, Loss_clf 0.842, Loss_fe 0.960, Loss_kd 1.821, Train_accy 73.82, Test_accy 72.05
2024-08-31 16:17:05,479 [foster.py] => Task 7, Epoch 69/170 => Loss 3.879, Loss_clf 0.851, Loss_fe 0.941, Loss_kd 1.823, Train_accy 73.97, Test_accy 71.18
2024-08-31 16:17:12,821 [foster.py] => Task 7, Epoch 70/170 => Loss 3.759, Loss_clf 0.806, Loss_fe 0.884, Loss_kd 1.807, Train_accy 74.99, Test_accy 73.53
2024-08-31 16:17:18,379 [foster.py] => Task 7, Epoch 71/170 => Loss 3.774, Loss_clf 0.821, Loss_fe 0.860, Loss_kd 1.828, Train_accy 75.04
2024-08-31 16:17:25,668 [foster.py] => Task 7, Epoch 72/170 => Loss 3.949, Loss_clf 0.873, Loss_fe 0.982, Loss_kd 1.828, Train_accy 73.44, Test_accy 70.42
2024-08-31 16:17:32,970 [foster.py] => Task 7, Epoch 73/170 => Loss 3.882, Loss_clf 0.861, Loss_fe 0.943, Loss_kd 1.815, Train_accy 74.22, Test_accy 69.95
2024-08-31 16:17:40,225 [foster.py] => Task 7, Epoch 74/170 => Loss 3.904, Loss_clf 0.869, Loss_fe 0.935, Loss_kd 1.834, Train_accy 73.73, Test_accy 70.20
2024-08-31 16:17:47,481 [foster.py] => Task 7, Epoch 75/170 => Loss 3.762, Loss_clf 0.809, Loss_fe 0.882, Loss_kd 1.809, Train_accy 75.68, Test_accy 72.40
2024-08-31 16:17:52,907 [foster.py] => Task 7, Epoch 76/170 => Loss 3.792, Loss_clf 0.830, Loss_fe 0.864, Loss_kd 1.832, Train_accy 74.91
2024-08-31 16:18:00,131 [foster.py] => Task 7, Epoch 77/170 => Loss 3.808, Loss_clf 0.823, Loss_fe 0.884, Loss_kd 1.834, Train_accy 74.57, Test_accy 71.30
2024-08-31 16:18:07,381 [foster.py] => Task 7, Epoch 78/170 => Loss 3.774, Loss_clf 0.796, Loss_fe 0.889, Loss_kd 1.824, Train_accy 75.64, Test_accy 70.97
2024-08-31 16:18:14,730 [foster.py] => Task 7, Epoch 79/170 => Loss 3.767, Loss_clf 0.813, Loss_fe 0.883, Loss_kd 1.809, Train_accy 74.99, Test_accy 71.05
2024-08-31 16:18:21,950 [foster.py] => Task 7, Epoch 80/170 => Loss 3.720, Loss_clf 0.795, Loss_fe 0.845, Loss_kd 1.816, Train_accy 76.17, Test_accy 68.62
2024-08-31 16:18:27,442 [foster.py] => Task 7, Epoch 81/170 => Loss 3.799, Loss_clf 0.829, Loss_fe 0.885, Loss_kd 1.821, Train_accy 74.15
2024-08-31 16:18:34,785 [foster.py] => Task 7, Epoch 82/170 => Loss 3.786, Loss_clf 0.821, Loss_fe 0.873, Loss_kd 1.827, Train_accy 75.31, Test_accy 70.38
2024-08-31 16:18:41,983 [foster.py] => Task 7, Epoch 83/170 => Loss 3.729, Loss_clf 0.784, Loss_fe 0.863, Loss_kd 1.818, Train_accy 75.51, Test_accy 71.62
2024-08-31 16:18:49,105 [foster.py] => Task 7, Epoch 84/170 => Loss 3.769, Loss_clf 0.810, Loss_fe 0.872, Loss_kd 1.823, Train_accy 76.11, Test_accy 71.92
2024-08-31 16:18:56,281 [foster.py] => Task 7, Epoch 85/170 => Loss 3.745, Loss_clf 0.792, Loss_fe 0.879, Loss_kd 1.812, Train_accy 76.84, Test_accy 73.28
2024-08-31 16:19:01,702 [foster.py] => Task 7, Epoch 86/170 => Loss 3.826, Loss_clf 0.850, Loss_fe 0.883, Loss_kd 1.828, Train_accy 74.15
2024-08-31 16:19:08,999 [foster.py] => Task 7, Epoch 87/170 => Loss 3.787, Loss_clf 0.830, Loss_fe 0.860, Loss_kd 1.831, Train_accy 75.31, Test_accy 71.97
2024-08-31 16:19:16,237 [foster.py] => Task 7, Epoch 88/170 => Loss 3.724, Loss_clf 0.808, Loss_fe 0.845, Loss_kd 1.809, Train_accy 74.62, Test_accy 71.97
2024-08-31 16:19:23,516 [foster.py] => Task 7, Epoch 89/170 => Loss 3.628, Loss_clf 0.752, Loss_fe 0.791, Loss_kd 1.821, Train_accy 76.95, Test_accy 70.92
2024-08-31 16:19:30,746 [foster.py] => Task 7, Epoch 90/170 => Loss 3.660, Loss_clf 0.767, Loss_fe 0.806, Loss_kd 1.823, Train_accy 77.00, Test_accy 72.85
2024-08-31 16:19:36,283 [foster.py] => Task 7, Epoch 91/170 => Loss 3.718, Loss_clf 0.779, Loss_fe 0.834, Loss_kd 1.839, Train_accy 76.37
2024-08-31 16:19:43,521 [foster.py] => Task 7, Epoch 92/170 => Loss 3.691, Loss_clf 0.792, Loss_fe 0.818, Loss_kd 1.817, Train_accy 75.97, Test_accy 72.97
2024-08-31 16:19:50,729 [foster.py] => Task 7, Epoch 93/170 => Loss 3.615, Loss_clf 0.757, Loss_fe 0.787, Loss_kd 1.809, Train_accy 76.95, Test_accy 72.10
2024-08-31 16:19:57,929 [foster.py] => Task 7, Epoch 94/170 => Loss 3.558, Loss_clf 0.724, Loss_fe 0.760, Loss_kd 1.811, Train_accy 77.02, Test_accy 71.08
2024-08-31 16:20:05,111 [foster.py] => Task 7, Epoch 95/170 => Loss 3.656, Loss_clf 0.764, Loss_fe 0.807, Loss_kd 1.821, Train_accy 76.44, Test_accy 71.58
2024-08-31 16:20:10,676 [foster.py] => Task 7, Epoch 96/170 => Loss 3.593, Loss_clf 0.736, Loss_fe 0.758, Loss_kd 1.833, Train_accy 76.95
2024-08-31 16:20:17,920 [foster.py] => Task 7, Epoch 97/170 => Loss 3.617, Loss_clf 0.751, Loss_fe 0.792, Loss_kd 1.811, Train_accy 78.00, Test_accy 67.42
2024-08-31 16:20:25,222 [foster.py] => Task 7, Epoch 98/170 => Loss 3.692, Loss_clf 0.791, Loss_fe 0.806, Loss_kd 1.830, Train_accy 76.69, Test_accy 71.58
2024-08-31 16:20:32,413 [foster.py] => Task 7, Epoch 99/170 => Loss 3.670, Loss_clf 0.784, Loss_fe 0.781, Loss_kd 1.838, Train_accy 76.31, Test_accy 70.90
2024-08-31 16:20:39,691 [foster.py] => Task 7, Epoch 100/170 => Loss 3.603, Loss_clf 0.736, Loss_fe 0.799, Loss_kd 1.806, Train_accy 77.71, Test_accy 73.68
2024-08-31 16:20:45,136 [foster.py] => Task 7, Epoch 101/170 => Loss 3.552, Loss_clf 0.724, Loss_fe 0.764, Loss_kd 1.802, Train_accy 78.26
2024-08-31 16:20:52,358 [foster.py] => Task 7, Epoch 102/170 => Loss 3.538, Loss_clf 0.704, Loss_fe 0.749, Loss_kd 1.820, Train_accy 78.69, Test_accy 70.80
2024-08-31 16:20:59,487 [foster.py] => Task 7, Epoch 103/170 => Loss 3.529, Loss_clf 0.708, Loss_fe 0.750, Loss_kd 1.809, Train_accy 78.24, Test_accy 71.85
2024-08-31 16:21:06,724 [foster.py] => Task 7, Epoch 104/170 => Loss 3.453, Loss_clf 0.689, Loss_fe 0.686, Loss_kd 1.815, Train_accy 78.84, Test_accy 70.28
2024-08-31 16:21:14,031 [foster.py] => Task 7, Epoch 105/170 => Loss 3.593, Loss_clf 0.757, Loss_fe 0.742, Loss_kd 1.828, Train_accy 77.11, Test_accy 69.80
2024-08-31 16:21:19,446 [foster.py] => Task 7, Epoch 106/170 => Loss 3.552, Loss_clf 0.737, Loss_fe 0.743, Loss_kd 1.810, Train_accy 77.20
2024-08-31 16:21:26,615 [foster.py] => Task 7, Epoch 107/170 => Loss 3.494, Loss_clf 0.696, Loss_fe 0.721, Loss_kd 1.814, Train_accy 79.76, Test_accy 74.05
2024-08-31 16:21:33,782 [foster.py] => Task 7, Epoch 108/170 => Loss 3.566, Loss_clf 0.748, Loss_fe 0.737, Loss_kd 1.818, Train_accy 76.80, Test_accy 69.50
2024-08-31 16:21:41,112 [foster.py] => Task 7, Epoch 109/170 => Loss 3.527, Loss_clf 0.707, Loss_fe 0.741, Loss_kd 1.815, Train_accy 79.11, Test_accy 71.85
2024-08-31 16:21:48,443 [foster.py] => Task 7, Epoch 110/170 => Loss 3.549, Loss_clf 0.733, Loss_fe 0.740, Loss_kd 1.814, Train_accy 76.80, Test_accy 70.92
2024-08-31 16:21:53,933 [foster.py] => Task 7, Epoch 111/170 => Loss 3.520, Loss_clf 0.722, Loss_fe 0.715, Loss_kd 1.819, Train_accy 78.51
2024-08-31 16:22:01,245 [foster.py] => Task 7, Epoch 112/170 => Loss 3.543, Loss_clf 0.734, Loss_fe 0.725, Loss_kd 1.820, Train_accy 78.13, Test_accy 69.92
2024-08-31 16:22:08,508 [foster.py] => Task 7, Epoch 113/170 => Loss 3.556, Loss_clf 0.745, Loss_fe 0.726, Loss_kd 1.821, Train_accy 77.37, Test_accy 73.82
2024-08-31 16:22:15,680 [foster.py] => Task 7, Epoch 114/170 => Loss 3.529, Loss_clf 0.718, Loss_fe 0.729, Loss_kd 1.818, Train_accy 78.38, Test_accy 68.45
2024-08-31 16:22:22,932 [foster.py] => Task 7, Epoch 115/170 => Loss 3.479, Loss_clf 0.702, Loss_fe 0.724, Loss_kd 1.793, Train_accy 78.91, Test_accy 69.35
2024-08-31 16:22:28,425 [foster.py] => Task 7, Epoch 116/170 => Loss 3.409, Loss_clf 0.680, Loss_fe 0.659, Loss_kd 1.808, Train_accy 79.24
2024-08-31 16:22:35,668 [foster.py] => Task 7, Epoch 117/170 => Loss 3.416, Loss_clf 0.681, Loss_fe 0.667, Loss_kd 1.806, Train_accy 79.73, Test_accy 72.42
2024-08-31 16:22:42,917 [foster.py] => Task 7, Epoch 118/170 => Loss 3.445, Loss_clf 0.705, Loss_fe 0.679, Loss_kd 1.800, Train_accy 79.07, Test_accy 70.45
2024-08-31 16:22:50,144 [foster.py] => Task 7, Epoch 119/170 => Loss 3.453, Loss_clf 0.708, Loss_fe 0.669, Loss_kd 1.813, Train_accy 79.62, Test_accy 73.62
2024-08-31 16:22:57,370 [foster.py] => Task 7, Epoch 120/170 => Loss 3.438, Loss_clf 0.704, Loss_fe 0.652, Loss_kd 1.819, Train_accy 78.46, Test_accy 72.38
2024-08-31 16:23:02,794 [foster.py] => Task 7, Epoch 121/170 => Loss 3.471, Loss_clf 0.692, Loss_fe 0.675, Loss_kd 1.837, Train_accy 79.93
2024-08-31 16:23:10,058 [foster.py] => Task 7, Epoch 122/170 => Loss 3.413, Loss_clf 0.671, Loss_fe 0.653, Loss_kd 1.825, Train_accy 79.51, Test_accy 71.75
2024-08-31 16:23:17,198 [foster.py] => Task 7, Epoch 123/170 => Loss 3.372, Loss_clf 0.665, Loss_fe 0.634, Loss_kd 1.810, Train_accy 80.69, Test_accy 74.40
2024-08-31 16:23:24,458 [foster.py] => Task 7, Epoch 124/170 => Loss 3.371, Loss_clf 0.660, Loss_fe 0.617, Loss_kd 1.830, Train_accy 80.53, Test_accy 72.90
2024-08-31 16:23:31,697 [foster.py] => Task 7, Epoch 125/170 => Loss 3.365, Loss_clf 0.668, Loss_fe 0.616, Loss_kd 1.818, Train_accy 80.53, Test_accy 74.32
2024-08-31 16:23:37,148 [foster.py] => Task 7, Epoch 126/170 => Loss 3.313, Loss_clf 0.638, Loss_fe 0.605, Loss_kd 1.808, Train_accy 81.36
2024-08-31 16:23:44,353 [foster.py] => Task 7, Epoch 127/170 => Loss 3.391, Loss_clf 0.678, Loss_fe 0.634, Loss_kd 1.816, Train_accy 79.60, Test_accy 70.70
2024-08-31 16:23:51,569 [foster.py] => Task 7, Epoch 128/170 => Loss 3.285, Loss_clf 0.628, Loss_fe 0.583, Loss_kd 1.811, Train_accy 81.33, Test_accy 72.75
2024-08-31 16:23:58,835 [foster.py] => Task 7, Epoch 129/170 => Loss 3.248, Loss_clf 0.623, Loss_fe 0.559, Loss_kd 1.804, Train_accy 81.98, Test_accy 74.05
2024-08-31 16:24:06,220 [foster.py] => Task 7, Epoch 130/170 => Loss 3.282, Loss_clf 0.642, Loss_fe 0.553, Loss_kd 1.822, Train_accy 81.16, Test_accy 74.62
2024-08-31 16:24:11,770 [foster.py] => Task 7, Epoch 131/170 => Loss 3.281, Loss_clf 0.632, Loss_fe 0.571, Loss_kd 1.815, Train_accy 80.65
2024-08-31 16:24:19,038 [foster.py] => Task 7, Epoch 132/170 => Loss 3.272, Loss_clf 0.628, Loss_fe 0.561, Loss_kd 1.819, Train_accy 80.87, Test_accy 72.28
2024-08-31 16:24:26,288 [foster.py] => Task 7, Epoch 133/170 => Loss 3.270, Loss_clf 0.637, Loss_fe 0.552, Loss_kd 1.817, Train_accy 81.11, Test_accy 73.30
2024-08-31 16:24:33,525 [foster.py] => Task 7, Epoch 134/170 => Loss 3.295, Loss_clf 0.647, Loss_fe 0.560, Loss_kd 1.824, Train_accy 81.36, Test_accy 73.62
2024-08-31 16:24:40,732 [foster.py] => Task 7, Epoch 135/170 => Loss 3.234, Loss_clf 0.629, Loss_fe 0.526, Loss_kd 1.815, Train_accy 81.85, Test_accy 74.03
2024-08-31 16:24:46,168 [foster.py] => Task 7, Epoch 136/170 => Loss 3.215, Loss_clf 0.603, Loss_fe 0.523, Loss_kd 1.824, Train_accy 82.76
2024-08-31 16:24:53,396 [foster.py] => Task 7, Epoch 137/170 => Loss 3.186, Loss_clf 0.612, Loss_fe 0.510, Loss_kd 1.804, Train_accy 81.76, Test_accy 74.03
2024-08-31 16:25:00,624 [foster.py] => Task 7, Epoch 138/170 => Loss 3.180, Loss_clf 0.604, Loss_fe 0.507, Loss_kd 1.807, Train_accy 81.54, Test_accy 74.42
2024-08-31 16:25:07,916 [foster.py] => Task 7, Epoch 139/170 => Loss 3.174, Loss_clf 0.589, Loss_fe 0.505, Loss_kd 1.817, Train_accy 82.47, Test_accy 74.50
2024-08-31 16:25:15,170 [foster.py] => Task 7, Epoch 140/170 => Loss 3.157, Loss_clf 0.586, Loss_fe 0.498, Loss_kd 1.810, Train_accy 82.38, Test_accy 73.10
2024-08-31 16:25:20,673 [foster.py] => Task 7, Epoch 141/170 => Loss 3.209, Loss_clf 0.609, Loss_fe 0.523, Loss_kd 1.814, Train_accy 82.29
2024-08-31 16:25:27,829 [foster.py] => Task 7, Epoch 142/170 => Loss 3.159, Loss_clf 0.594, Loss_fe 0.485, Loss_kd 1.817, Train_accy 82.49, Test_accy 75.18
2024-08-31 16:25:35,177 [foster.py] => Task 7, Epoch 143/170 => Loss 3.124, Loss_clf 0.558, Loss_fe 0.481, Loss_kd 1.821, Train_accy 83.72, Test_accy 75.38
2024-08-31 16:25:42,563 [foster.py] => Task 7, Epoch 144/170 => Loss 3.118, Loss_clf 0.586, Loss_fe 0.462, Loss_kd 1.808, Train_accy 83.16, Test_accy 73.60
2024-08-31 16:25:49,991 [foster.py] => Task 7, Epoch 145/170 => Loss 3.117, Loss_clf 0.572, Loss_fe 0.469, Loss_kd 1.814, Train_accy 83.63, Test_accy 74.18
2024-08-31 16:25:55,485 [foster.py] => Task 7, Epoch 146/170 => Loss 3.076, Loss_clf 0.542, Loss_fe 0.456, Loss_kd 1.815, Train_accy 83.85
2024-08-31 16:26:02,712 [foster.py] => Task 7, Epoch 147/170 => Loss 3.112, Loss_clf 0.572, Loss_fe 0.462, Loss_kd 1.815, Train_accy 84.23, Test_accy 73.95
2024-08-31 16:26:09,902 [foster.py] => Task 7, Epoch 148/170 => Loss 3.133, Loss_clf 0.582, Loss_fe 0.463, Loss_kd 1.823, Train_accy 83.45, Test_accy 74.60
2024-08-31 16:26:17,080 [foster.py] => Task 7, Epoch 149/170 => Loss 3.083, Loss_clf 0.569, Loss_fe 0.431, Loss_kd 1.819, Train_accy 84.18, Test_accy 75.15
2024-08-31 16:26:24,276 [foster.py] => Task 7, Epoch 150/170 => Loss 3.095, Loss_clf 0.576, Loss_fe 0.438, Loss_kd 1.818, Train_accy 83.92, Test_accy 74.70
2024-08-31 16:26:29,711 [foster.py] => Task 7, Epoch 151/170 => Loss 3.092, Loss_clf 0.567, Loss_fe 0.435, Loss_kd 1.825, Train_accy 83.27
2024-08-31 16:26:36,978 [foster.py] => Task 7, Epoch 152/170 => Loss 3.076, Loss_clf 0.564, Loss_fe 0.430, Loss_kd 1.818, Train_accy 84.29, Test_accy 74.72
2024-08-31 16:26:44,238 [foster.py] => Task 7, Epoch 153/170 => Loss 3.076, Loss_clf 0.561, Loss_fe 0.433, Loss_kd 1.818, Train_accy 83.36, Test_accy 75.08
2024-08-31 16:26:51,440 [foster.py] => Task 7, Epoch 154/170 => Loss 3.033, Loss_clf 0.539, Loss_fe 0.420, Loss_kd 1.811, Train_accy 84.65, Test_accy 74.58
2024-08-31 16:26:58,711 [foster.py] => Task 7, Epoch 155/170 => Loss 3.121, Loss_clf 0.580, Loss_fe 0.444, Loss_kd 1.832, Train_accy 83.36, Test_accy 74.53
2024-08-31 16:27:04,160 [foster.py] => Task 7, Epoch 156/170 => Loss 3.045, Loss_clf 0.544, Loss_fe 0.425, Loss_kd 1.813, Train_accy 84.89
2024-08-31 16:27:11,336 [foster.py] => Task 7, Epoch 157/170 => Loss 2.982, Loss_clf 0.525, Loss_fe 0.398, Loss_kd 1.799, Train_accy 85.09, Test_accy 74.80
2024-08-31 16:27:18,584 [foster.py] => Task 7, Epoch 158/170 => Loss 2.988, Loss_clf 0.528, Loss_fe 0.392, Loss_kd 1.807, Train_accy 85.47, Test_accy 74.47
2024-08-31 16:27:25,764 [foster.py] => Task 7, Epoch 159/170 => Loss 3.002, Loss_clf 0.529, Loss_fe 0.400, Loss_kd 1.810, Train_accy 85.01, Test_accy 74.60
2024-08-31 16:27:32,929 [foster.py] => Task 7, Epoch 160/170 => Loss 3.075, Loss_clf 0.562, Loss_fe 0.429, Loss_kd 1.821, Train_accy 84.16, Test_accy 74.47
2024-08-31 16:27:38,531 [foster.py] => Task 7, Epoch 161/170 => Loss 3.022, Loss_clf 0.535, Loss_fe 0.403, Loss_kd 1.820, Train_accy 84.43
2024-08-31 16:27:45,860 [foster.py] => Task 7, Epoch 162/170 => Loss 3.015, Loss_clf 0.534, Loss_fe 0.404, Loss_kd 1.814, Train_accy 84.09, Test_accy 74.55
2024-08-31 16:27:53,199 [foster.py] => Task 7, Epoch 163/170 => Loss 3.036, Loss_clf 0.552, Loss_fe 0.403, Loss_kd 1.817, Train_accy 84.36, Test_accy 74.97
2024-08-31 16:28:00,404 [foster.py] => Task 7, Epoch 164/170 => Loss 3.043, Loss_clf 0.561, Loss_fe 0.395, Loss_kd 1.822, Train_accy 83.76, Test_accy 74.65
2024-08-31 16:28:07,704 [foster.py] => Task 7, Epoch 165/170 => Loss 3.020, Loss_clf 0.547, Loss_fe 0.395, Loss_kd 1.815, Train_accy 84.43, Test_accy 74.68
2024-08-31 16:28:13,220 [foster.py] => Task 7, Epoch 166/170 => Loss 3.028, Loss_clf 0.534, Loss_fe 0.400, Loss_kd 1.829, Train_accy 85.14
2024-08-31 16:28:20,463 [foster.py] => Task 7, Epoch 167/170 => Loss 2.990, Loss_clf 0.526, Loss_fe 0.393, Loss_kd 1.809, Train_accy 85.41, Test_accy 74.70
2024-08-31 16:28:27,776 [foster.py] => Task 7, Epoch 168/170 => Loss 2.965, Loss_clf 0.515, Loss_fe 0.378, Loss_kd 1.810, Train_accy 84.85, Test_accy 74.50
2024-08-31 16:28:35,040 [foster.py] => Task 7, Epoch 169/170 => Loss 3.004, Loss_clf 0.540, Loss_fe 0.391, Loss_kd 1.810, Train_accy 84.18, Test_accy 74.88
2024-08-31 16:28:42,359 [foster.py] => Task 7, Epoch 170/170 => Loss 2.996, Loss_clf 0.537, Loss_fe 0.386, Loss_kd 1.810, Train_accy 84.40, Test_accy 74.50
2024-08-31 16:28:42,362 [foster.py] => do not weight align teacher!
2024-08-31 16:28:42,363 [foster.py] => per cls weights : [1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253
 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253
 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253
 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253
 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253
 1.03240253 1.03240253 1.03240253 1.03240253 1.03240253 0.77318232
 0.77318232 0.77318232 0.77318232 0.77318232]
2024-08-31 16:28:51,585 [foster.py] => SNet: Task 7, Epoch 1/130 => Loss 25.170,  Loss1 0.630, Train_accy 53.88, Test_accy 66.25
2024-08-31 16:28:58,950 [foster.py] => SNet: Task 7, Epoch 2/130 => Loss 25.017,  Loss1 0.632, Train_accy 67.43
2024-08-31 16:29:06,472 [foster.py] => SNet: Task 7, Epoch 3/130 => Loss 24.973,  Loss1 0.633, Train_accy 72.06
2024-08-31 16:29:14,131 [foster.py] => SNet: Task 7, Epoch 4/130 => Loss 24.971,  Loss1 0.633, Train_accy 72.37
2024-08-31 16:29:21,353 [foster.py] => SNet: Task 7, Epoch 5/130 => Loss 24.958,  Loss1 0.633, Train_accy 71.92
2024-08-31 16:29:30,305 [foster.py] => SNet: Task 7, Epoch 6/130 => Loss 24.955,  Loss1 0.633, Train_accy 73.77, Test_accy 68.35
2024-08-31 16:29:37,675 [foster.py] => SNet: Task 7, Epoch 7/130 => Loss 24.950,  Loss1 0.634, Train_accy 73.35
2024-08-31 16:29:44,973 [foster.py] => SNet: Task 7, Epoch 8/130 => Loss 24.972,  Loss1 0.633, Train_accy 73.33
2024-08-31 16:29:52,284 [foster.py] => SNet: Task 7, Epoch 9/130 => Loss 25.006,  Loss1 0.633, Train_accy 72.84
2024-08-31 16:29:59,774 [foster.py] => SNet: Task 7, Epoch 10/130 => Loss 24.991,  Loss1 0.634, Train_accy 72.99
2024-08-31 16:30:09,093 [foster.py] => SNet: Task 7, Epoch 11/130 => Loss 24.983,  Loss1 0.633, Train_accy 74.13, Test_accy 68.88
2024-08-31 16:30:16,556 [foster.py] => SNet: Task 7, Epoch 12/130 => Loss 24.961,  Loss1 0.634, Train_accy 74.75
2024-08-31 16:30:24,065 [foster.py] => SNet: Task 7, Epoch 13/130 => Loss 24.945,  Loss1 0.634, Train_accy 74.42
2024-08-31 16:30:31,457 [foster.py] => SNet: Task 7, Epoch 14/130 => Loss 24.954,  Loss1 0.634, Train_accy 75.55
2024-08-31 16:30:38,777 [foster.py] => SNet: Task 7, Epoch 15/130 => Loss 24.954,  Loss1 0.634, Train_accy 75.33
2024-08-31 16:30:47,838 [foster.py] => SNet: Task 7, Epoch 16/130 => Loss 24.954,  Loss1 0.634, Train_accy 75.97, Test_accy 69.92
2024-08-31 16:30:55,302 [foster.py] => SNet: Task 7, Epoch 17/130 => Loss 24.928,  Loss1 0.634, Train_accy 76.08
2024-08-31 16:31:02,727 [foster.py] => SNet: Task 7, Epoch 18/130 => Loss 24.990,  Loss1 0.634, Train_accy 76.11
2024-08-31 16:31:10,020 [foster.py] => SNet: Task 7, Epoch 19/130 => Loss 24.927,  Loss1 0.634, Train_accy 76.20
2024-08-31 16:31:17,335 [foster.py] => SNet: Task 7, Epoch 20/130 => Loss 24.963,  Loss1 0.634, Train_accy 76.95
2024-08-31 16:31:26,165 [foster.py] => SNet: Task 7, Epoch 21/130 => Loss 24.906,  Loss1 0.634, Train_accy 78.04, Test_accy 69.85
2024-08-31 16:31:33,432 [foster.py] => SNet: Task 7, Epoch 22/130 => Loss 24.939,  Loss1 0.633, Train_accy 76.04
2024-08-31 16:31:41,161 [foster.py] => SNet: Task 7, Epoch 23/130 => Loss 24.927,  Loss1 0.634, Train_accy 76.73
2024-08-31 16:31:48,643 [foster.py] => SNet: Task 7, Epoch 24/130 => Loss 24.952,  Loss1 0.634, Train_accy 77.26
2024-08-31 16:31:55,941 [foster.py] => SNet: Task 7, Epoch 25/130 => Loss 24.910,  Loss1 0.634, Train_accy 77.55
2024-08-31 16:32:04,681 [foster.py] => SNet: Task 7, Epoch 26/130 => Loss 24.921,  Loss1 0.634, Train_accy 77.95, Test_accy 71.12
2024-08-31 16:32:12,026 [foster.py] => SNet: Task 7, Epoch 27/130 => Loss 24.908,  Loss1 0.634, Train_accy 76.95
2024-08-31 16:32:19,373 [foster.py] => SNet: Task 7, Epoch 28/130 => Loss 24.951,  Loss1 0.634, Train_accy 77.09
2024-08-31 16:32:26,626 [foster.py] => SNet: Task 7, Epoch 29/130 => Loss 24.926,  Loss1 0.634, Train_accy 77.42
2024-08-31 16:32:34,118 [foster.py] => SNet: Task 7, Epoch 30/130 => Loss 24.927,  Loss1 0.634, Train_accy 77.95
2024-08-31 16:32:43,241 [foster.py] => SNet: Task 7, Epoch 31/130 => Loss 24.922,  Loss1 0.634, Train_accy 78.95, Test_accy 70.15
2024-08-31 16:32:50,789 [foster.py] => SNet: Task 7, Epoch 32/130 => Loss 24.916,  Loss1 0.634, Train_accy 77.49
2024-08-31 16:32:58,346 [foster.py] => SNet: Task 7, Epoch 33/130 => Loss 24.969,  Loss1 0.634, Train_accy 77.66
2024-08-31 16:33:05,996 [foster.py] => SNet: Task 7, Epoch 34/130 => Loss 24.921,  Loss1 0.634, Train_accy 79.09
2024-08-31 16:33:13,244 [foster.py] => SNet: Task 7, Epoch 35/130 => Loss 24.961,  Loss1 0.634, Train_accy 78.89
2024-08-31 16:33:22,393 [foster.py] => SNet: Task 7, Epoch 36/130 => Loss 24.908,  Loss1 0.635, Train_accy 78.04, Test_accy 70.42
2024-08-31 16:33:29,682 [foster.py] => SNet: Task 7, Epoch 37/130 => Loss 24.927,  Loss1 0.634, Train_accy 78.15
2024-08-31 16:33:36,981 [foster.py] => SNet: Task 7, Epoch 38/130 => Loss 24.903,  Loss1 0.634, Train_accy 79.49
2024-08-31 16:33:44,419 [foster.py] => SNet: Task 7, Epoch 39/130 => Loss 24.926,  Loss1 0.634, Train_accy 78.06
2024-08-31 16:33:51,739 [foster.py] => SNet: Task 7, Epoch 40/130 => Loss 24.908,  Loss1 0.634, Train_accy 78.15
2024-08-31 16:34:00,630 [foster.py] => SNet: Task 7, Epoch 41/130 => Loss 24.911,  Loss1 0.634, Train_accy 78.73, Test_accy 71.18
2024-08-31 16:34:08,053 [foster.py] => SNet: Task 7, Epoch 42/130 => Loss 24.906,  Loss1 0.634, Train_accy 78.69
2024-08-31 16:34:15,322 [foster.py] => SNet: Task 7, Epoch 43/130 => Loss 24.932,  Loss1 0.634, Train_accy 79.76
2024-08-31 16:34:22,652 [foster.py] => SNet: Task 7, Epoch 44/130 => Loss 24.928,  Loss1 0.634, Train_accy 77.84
2024-08-31 16:34:30,050 [foster.py] => SNet: Task 7, Epoch 45/130 => Loss 24.915,  Loss1 0.634, Train_accy 78.78
2024-08-31 16:34:39,154 [foster.py] => SNet: Task 7, Epoch 46/130 => Loss 24.911,  Loss1 0.634, Train_accy 78.93, Test_accy 70.75
2024-08-31 16:34:46,698 [foster.py] => SNet: Task 7, Epoch 47/130 => Loss 24.929,  Loss1 0.634, Train_accy 79.64
2024-08-31 16:34:54,082 [foster.py] => SNet: Task 7, Epoch 48/130 => Loss 24.916,  Loss1 0.634, Train_accy 78.87
2024-08-31 16:35:01,450 [foster.py] => SNet: Task 7, Epoch 49/130 => Loss 24.923,  Loss1 0.635, Train_accy 79.67
2024-08-31 16:35:09,036 [foster.py] => SNet: Task 7, Epoch 50/130 => Loss 24.902,  Loss1 0.634, Train_accy 78.53
2024-08-31 16:35:18,061 [foster.py] => SNet: Task 7, Epoch 51/130 => Loss 24.906,  Loss1 0.634, Train_accy 79.29, Test_accy 70.97
2024-08-31 16:35:25,670 [foster.py] => SNet: Task 7, Epoch 52/130 => Loss 24.907,  Loss1 0.635, Train_accy 79.31
2024-08-31 16:35:32,976 [foster.py] => SNet: Task 7, Epoch 53/130 => Loss 24.912,  Loss1 0.634, Train_accy 79.64
2024-08-31 16:35:40,268 [foster.py] => SNet: Task 7, Epoch 54/130 => Loss 24.922,  Loss1 0.634, Train_accy 79.24
2024-08-31 16:35:47,568 [foster.py] => SNet: Task 7, Epoch 55/130 => Loss 24.893,  Loss1 0.635, Train_accy 80.13
2024-08-31 16:35:56,638 [foster.py] => SNet: Task 7, Epoch 56/130 => Loss 24.922,  Loss1 0.634, Train_accy 79.91, Test_accy 71.35
2024-08-31 16:36:04,421 [foster.py] => SNet: Task 7, Epoch 57/130 => Loss 24.919,  Loss1 0.634, Train_accy 79.20
2024-08-31 16:36:12,022 [foster.py] => SNet: Task 7, Epoch 58/130 => Loss 24.898,  Loss1 0.634, Train_accy 79.76
2024-08-31 16:36:19,354 [foster.py] => SNet: Task 7, Epoch 59/130 => Loss 24.909,  Loss1 0.634, Train_accy 80.38
2024-08-31 16:36:26,666 [foster.py] => SNet: Task 7, Epoch 60/130 => Loss 24.914,  Loss1 0.634, Train_accy 80.16
2024-08-31 16:36:35,557 [foster.py] => SNet: Task 7, Epoch 61/130 => Loss 24.907,  Loss1 0.634, Train_accy 79.62, Test_accy 71.65
2024-08-31 16:36:42,796 [foster.py] => SNet: Task 7, Epoch 62/130 => Loss 24.921,  Loss1 0.635, Train_accy 79.42
2024-08-31 16:36:50,128 [foster.py] => SNet: Task 7, Epoch 63/130 => Loss 24.921,  Loss1 0.635, Train_accy 80.13
2024-08-31 16:36:57,444 [foster.py] => SNet: Task 7, Epoch 64/130 => Loss 24.889,  Loss1 0.634, Train_accy 79.91
2024-08-31 16:37:04,988 [foster.py] => SNet: Task 7, Epoch 65/130 => Loss 24.922,  Loss1 0.635, Train_accy 80.24
2024-08-31 16:37:14,199 [foster.py] => SNet: Task 7, Epoch 66/130 => Loss 24.902,  Loss1 0.634, Train_accy 80.40, Test_accy 71.90
2024-08-31 16:37:21,492 [foster.py] => SNet: Task 7, Epoch 67/130 => Loss 24.889,  Loss1 0.635, Train_accy 81.69
2024-08-31 16:37:28,722 [foster.py] => SNet: Task 7, Epoch 68/130 => Loss 24.930,  Loss1 0.634, Train_accy 80.07
2024-08-31 16:37:36,163 [foster.py] => SNet: Task 7, Epoch 69/130 => Loss 24.894,  Loss1 0.635, Train_accy 80.20
2024-08-31 16:37:44,273 [foster.py] => SNet: Task 7, Epoch 70/130 => Loss 24.911,  Loss1 0.634, Train_accy 81.36
2024-08-31 16:37:53,103 [foster.py] => SNet: Task 7, Epoch 71/130 => Loss 24.922,  Loss1 0.634, Train_accy 79.42, Test_accy 71.55
2024-08-31 16:38:00,776 [foster.py] => SNet: Task 7, Epoch 72/130 => Loss 24.906,  Loss1 0.634, Train_accy 81.13
2024-08-31 16:38:08,125 [foster.py] => SNet: Task 7, Epoch 73/130 => Loss 24.911,  Loss1 0.635, Train_accy 79.60
2024-08-31 16:38:16,071 [foster.py] => SNet: Task 7, Epoch 74/130 => Loss 24.898,  Loss1 0.635, Train_accy 80.78
2024-08-31 16:38:23,393 [foster.py] => SNet: Task 7, Epoch 75/130 => Loss 24.884,  Loss1 0.635, Train_accy 81.85
2024-08-31 16:38:32,186 [foster.py] => SNet: Task 7, Epoch 76/130 => Loss 24.926,  Loss1 0.634, Train_accy 79.73, Test_accy 72.35
2024-08-31 16:38:39,704 [foster.py] => SNet: Task 7, Epoch 77/130 => Loss 24.877,  Loss1 0.634, Train_accy 81.45
2024-08-31 16:38:47,088 [foster.py] => SNet: Task 7, Epoch 78/130 => Loss 24.881,  Loss1 0.635, Train_accy 80.80
2024-08-31 16:38:54,686 [foster.py] => SNet: Task 7, Epoch 79/130 => Loss 24.906,  Loss1 0.634, Train_accy 80.27
2024-08-31 16:39:02,192 [foster.py] => SNet: Task 7, Epoch 80/130 => Loss 24.920,  Loss1 0.634, Train_accy 81.36
2024-08-31 16:39:11,196 [foster.py] => SNet: Task 7, Epoch 81/130 => Loss 24.923,  Loss1 0.635, Train_accy 80.96, Test_accy 73.00
2024-08-31 16:39:18,577 [foster.py] => SNet: Task 7, Epoch 82/130 => Loss 24.904,  Loss1 0.634, Train_accy 81.27
2024-08-31 16:39:26,401 [foster.py] => SNet: Task 7, Epoch 83/130 => Loss 24.884,  Loss1 0.634, Train_accy 81.11
2024-08-31 16:39:33,635 [foster.py] => SNet: Task 7, Epoch 84/130 => Loss 24.872,  Loss1 0.635, Train_accy 82.11
2024-08-31 16:39:41,753 [foster.py] => SNet: Task 7, Epoch 85/130 => Loss 24.896,  Loss1 0.635, Train_accy 81.69
2024-08-31 16:39:50,570 [foster.py] => SNet: Task 7, Epoch 86/130 => Loss 24.900,  Loss1 0.635, Train_accy 81.09, Test_accy 72.78
2024-08-31 16:39:58,140 [foster.py] => SNet: Task 7, Epoch 87/130 => Loss 24.939,  Loss1 0.634, Train_accy 80.89
2024-08-31 16:40:05,419 [foster.py] => SNet: Task 7, Epoch 88/130 => Loss 24.926,  Loss1 0.634, Train_accy 81.13
2024-08-31 16:40:12,812 [foster.py] => SNet: Task 7, Epoch 89/130 => Loss 24.910,  Loss1 0.634, Train_accy 81.98
2024-08-31 16:40:20,240 [foster.py] => SNet: Task 7, Epoch 90/130 => Loss 24.903,  Loss1 0.635, Train_accy 81.20
2024-08-31 16:40:29,062 [foster.py] => SNet: Task 7, Epoch 91/130 => Loss 24.910,  Loss1 0.634, Train_accy 80.11, Test_accy 72.70
2024-08-31 16:40:36,629 [foster.py] => SNet: Task 7, Epoch 92/130 => Loss 24.891,  Loss1 0.635, Train_accy 80.69
2024-08-31 16:40:44,341 [foster.py] => SNet: Task 7, Epoch 93/130 => Loss 24.886,  Loss1 0.634, Train_accy 81.76
2024-08-31 16:40:51,726 [foster.py] => SNet: Task 7, Epoch 94/130 => Loss 24.911,  Loss1 0.634, Train_accy 80.73
2024-08-31 16:40:59,051 [foster.py] => SNet: Task 7, Epoch 95/130 => Loss 24.904,  Loss1 0.634, Train_accy 81.02
2024-08-31 16:41:08,020 [foster.py] => SNet: Task 7, Epoch 96/130 => Loss 24.879,  Loss1 0.634, Train_accy 81.22, Test_accy 72.88
2024-08-31 16:41:15,530 [foster.py] => SNet: Task 7, Epoch 97/130 => Loss 24.930,  Loss1 0.634, Train_accy 80.78
2024-08-31 16:41:22,884 [foster.py] => SNet: Task 7, Epoch 98/130 => Loss 24.904,  Loss1 0.635, Train_accy 81.16
2024-08-31 16:41:30,608 [foster.py] => SNet: Task 7, Epoch 99/130 => Loss 24.895,  Loss1 0.635, Train_accy 80.56
2024-08-31 16:41:37,918 [foster.py] => SNet: Task 7, Epoch 100/130 => Loss 24.885,  Loss1 0.634, Train_accy 81.40
2024-08-31 16:41:46,953 [foster.py] => SNet: Task 7, Epoch 101/130 => Loss 24.883,  Loss1 0.634, Train_accy 81.69, Test_accy 73.25
2024-08-31 16:41:54,327 [foster.py] => SNet: Task 7, Epoch 102/130 => Loss 24.887,  Loss1 0.635, Train_accy 81.51
2024-08-31 16:42:01,786 [foster.py] => SNet: Task 7, Epoch 103/130 => Loss 24.881,  Loss1 0.634, Train_accy 82.07
2024-08-31 16:42:09,462 [foster.py] => SNet: Task 7, Epoch 104/130 => Loss 24.900,  Loss1 0.634, Train_accy 81.38
2024-08-31 16:42:16,769 [foster.py] => SNet: Task 7, Epoch 105/130 => Loss 24.879,  Loss1 0.635, Train_accy 81.69
2024-08-31 16:42:25,581 [foster.py] => SNet: Task 7, Epoch 106/130 => Loss 24.885,  Loss1 0.634, Train_accy 81.47, Test_accy 73.10
2024-08-31 16:42:32,885 [foster.py] => SNet: Task 7, Epoch 107/130 => Loss 24.882,  Loss1 0.635, Train_accy 81.45
2024-08-31 16:42:40,322 [foster.py] => SNet: Task 7, Epoch 108/130 => Loss 24.865,  Loss1 0.635, Train_accy 82.51
2024-08-31 16:42:47,693 [foster.py] => SNet: Task 7, Epoch 109/130 => Loss 24.853,  Loss1 0.635, Train_accy 82.34
2024-08-31 16:42:55,218 [foster.py] => SNet: Task 7, Epoch 110/130 => Loss 24.863,  Loss1 0.635, Train_accy 80.93
2024-08-31 16:43:04,341 [foster.py] => SNet: Task 7, Epoch 111/130 => Loss 24.888,  Loss1 0.634, Train_accy 82.00, Test_accy 72.80
2024-08-31 16:43:11,669 [foster.py] => SNet: Task 7, Epoch 112/130 => Loss 24.880,  Loss1 0.635, Train_accy 80.87
2024-08-31 16:43:19,329 [foster.py] => SNet: Task 7, Epoch 113/130 => Loss 24.869,  Loss1 0.635, Train_accy 82.58
2024-08-31 16:43:26,716 [foster.py] => SNet: Task 7, Epoch 114/130 => Loss 24.874,  Loss1 0.634, Train_accy 81.27
2024-08-31 16:43:34,035 [foster.py] => SNet: Task 7, Epoch 115/130 => Loss 24.888,  Loss1 0.635, Train_accy 81.16
2024-08-31 16:43:43,013 [foster.py] => SNet: Task 7, Epoch 116/130 => Loss 24.918,  Loss1 0.634, Train_accy 81.82, Test_accy 72.97
2024-08-31 16:43:50,453 [foster.py] => SNet: Task 7, Epoch 117/130 => Loss 24.896,  Loss1 0.634, Train_accy 82.38
2024-08-31 16:43:57,797 [foster.py] => SNet: Task 7, Epoch 118/130 => Loss 24.890,  Loss1 0.635, Train_accy 81.40
2024-08-31 16:44:05,024 [foster.py] => SNet: Task 7, Epoch 119/130 => Loss 24.902,  Loss1 0.635, Train_accy 81.65
2024-08-31 16:44:12,614 [foster.py] => SNet: Task 7, Epoch 120/130 => Loss 24.868,  Loss1 0.635, Train_accy 80.98
2024-08-31 16:44:21,572 [foster.py] => SNet: Task 7, Epoch 121/130 => Loss 24.873,  Loss1 0.634, Train_accy 80.60, Test_accy 73.22
2024-08-31 16:44:28,893 [foster.py] => SNet: Task 7, Epoch 122/130 => Loss 24.903,  Loss1 0.634, Train_accy 81.45
2024-08-31 16:44:36,657 [foster.py] => SNet: Task 7, Epoch 123/130 => Loss 24.894,  Loss1 0.634, Train_accy 81.07
2024-08-31 16:44:43,986 [foster.py] => SNet: Task 7, Epoch 124/130 => Loss 24.907,  Loss1 0.634, Train_accy 82.29
2024-08-31 16:44:51,478 [foster.py] => SNet: Task 7, Epoch 125/130 => Loss 24.867,  Loss1 0.635, Train_accy 82.20
2024-08-31 16:45:00,413 [foster.py] => SNet: Task 7, Epoch 126/130 => Loss 24.906,  Loss1 0.634, Train_accy 81.49, Test_accy 72.92
2024-08-31 16:45:08,003 [foster.py] => SNet: Task 7, Epoch 127/130 => Loss 24.907,  Loss1 0.634, Train_accy 81.98
2024-08-31 16:45:15,297 [foster.py] => SNet: Task 7, Epoch 128/130 => Loss 24.873,  Loss1 0.635, Train_accy 81.62
2024-08-31 16:45:22,624 [foster.py] => SNet: Task 7, Epoch 129/130 => Loss 24.895,  Loss1 0.635, Train_accy 81.54
2024-08-31 16:45:29,990 [foster.py] => SNet: Task 7, Epoch 130/130 => Loss 24.895,  Loss1 0.635, Train_accy 82.42
2024-08-31 16:45:29,991 [foster.py] => do not weight align student!
2024-08-31 16:45:31,535 [foster.py] => darknet eval: 
2024-08-31 16:45:31,535 [foster.py] => CNN top1 curve: 73.82
2024-08-31 16:45:31,535 [foster.py] => CNN top5 curve: 94.2
2024-08-31 16:45:31,536 [foster.py] => CNN top1 平均值: 73.82
2024-08-31 16:45:31,539 [foster.py] => timees : 2181.378119945526
2024-08-31 16:45:31,540 [base.py] => Reducing exemplars...(50 per classes)
2024-08-31 16:45:43,692 [base.py] => Constructing exemplars...(50 per classes)
2024-08-31 16:45:52,528 [foster.py] => Exemplar size: 2000
2024-08-31 16:45:52,528 [trainer.py] => CNN: {'total': 74.5, '00-09': 75.7, '10-19': 63.4, '20-29': 76.0, '30-39': 82.9, 'old': 73.0, 'new': 85.0}
2024-08-31 16:45:52,528 [trainer.py] => NME: {'total': 72.15, '00-09': 74.0, '10-19': 63.4, '20-29': 76.3, '30-39': 74.9, 'old': 70.91, 'new': 80.8}
2024-08-31 16:45:52,528 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5]
2024-08-31 16:45:52,528 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2]
2024-08-31 16:45:52,528 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15]
2024-08-31 16:45:52,528 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68]

2024-08-31 16:45:52,528 [trainer.py] => CNN top1 平均值: 85.02
2024-08-31 16:45:52,531 [trainer.py] => All params: 1292583
2024-08-31 16:45:52,533 [trainer.py] => Trainable params: 649034
2024-08-31 16:45:52,596 [foster.py] => Learning on 40-45
2024-08-31 16:45:52,600 [foster.py] => All params: 1293878
2024-08-31 16:45:52,602 [foster.py] => Trainable params: 650004
2024-08-31 16:45:52,647 [foster.py] => per cls weights : [1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323 1.01633323
 1.01633323 1.01633323 1.01633323 1.01633323 0.86933412 0.86933412
 0.86933412 0.86933412 0.86933412]
2024-08-31 16:45:58,114 [foster.py] => Task 8, Epoch 1/170 => Loss 5.187, Loss_clf 1.390, Loss_fe 1.445, Loss_kd 2.085, Train_accy 61.11
2024-08-31 16:46:05,588 [foster.py] => Task 8, Epoch 2/170 => Loss 4.521, Loss_clf 1.041, Loss_fe 1.136, Loss_kd 2.079, Train_accy 69.87, Test_accy 70.87
2024-08-31 16:46:12,971 [foster.py] => Task 8, Epoch 3/170 => Loss 4.394, Loss_clf 0.966, Loss_fe 1.082, Loss_kd 2.079, Train_accy 71.31, Test_accy 70.60
2024-08-31 16:46:20,347 [foster.py] => Task 8, Epoch 4/170 => Loss 4.311, Loss_clf 0.932, Loss_fe 1.032, Loss_kd 2.080, Train_accy 73.36, Test_accy 65.29
2024-08-31 16:46:27,902 [foster.py] => Task 8, Epoch 5/170 => Loss 4.314, Loss_clf 0.977, Loss_fe 0.990, Loss_kd 2.081, Train_accy 72.40, Test_accy 68.69
2024-08-31 16:46:33,400 [foster.py] => Task 8, Epoch 6/170 => Loss 4.287, Loss_clf 0.924, Loss_fe 1.016, Loss_kd 2.081, Train_accy 72.38
2024-08-31 16:46:40,731 [foster.py] => Task 8, Epoch 7/170 => Loss 4.181, Loss_clf 0.905, Loss_fe 0.938, Loss_kd 2.074, Train_accy 73.51, Test_accy 66.33
2024-08-31 16:46:48,148 [foster.py] => Task 8, Epoch 8/170 => Loss 4.316, Loss_clf 0.990, Loss_fe 0.970, Loss_kd 2.090, Train_accy 72.07, Test_accy 70.11
2024-08-31 16:46:55,397 [foster.py] => Task 8, Epoch 9/170 => Loss 4.228, Loss_clf 0.916, Loss_fe 0.978, Loss_kd 2.069, Train_accy 73.16, Test_accy 70.27
2024-08-31 16:47:02,724 [foster.py] => Task 8, Epoch 10/170 => Loss 4.225, Loss_clf 0.922, Loss_fe 0.979, Loss_kd 2.060, Train_accy 71.71, Test_accy 66.09
2024-08-31 16:47:08,179 [foster.py] => Task 8, Epoch 11/170 => Loss 4.176, Loss_clf 0.877, Loss_fe 0.953, Loss_kd 2.081, Train_accy 74.62
2024-08-31 16:47:15,479 [foster.py] => Task 8, Epoch 12/170 => Loss 4.263, Loss_clf 0.928, Loss_fe 0.983, Loss_kd 2.086, Train_accy 72.60, Test_accy 70.40
2024-08-31 16:47:22,799 [foster.py] => Task 8, Epoch 13/170 => Loss 4.145, Loss_clf 0.882, Loss_fe 0.925, Loss_kd 2.073, Train_accy 74.09, Test_accy 69.84
2024-08-31 16:47:30,111 [foster.py] => Task 8, Epoch 14/170 => Loss 4.164, Loss_clf 0.870, Loss_fe 0.965, Loss_kd 2.066, Train_accy 73.69, Test_accy 71.04
2024-08-31 16:47:37,474 [foster.py] => Task 8, Epoch 15/170 => Loss 4.216, Loss_clf 0.914, Loss_fe 0.966, Loss_kd 2.072, Train_accy 73.29, Test_accy 65.51
2024-08-31 16:47:42,938 [foster.py] => Task 8, Epoch 16/170 => Loss 4.260, Loss_clf 0.921, Loss_fe 1.003, Loss_kd 2.072, Train_accy 73.02
2024-08-31 16:47:50,231 [foster.py] => Task 8, Epoch 17/170 => Loss 4.286, Loss_clf 0.916, Loss_fe 1.032, Loss_kd 2.073, Train_accy 73.44, Test_accy 69.51
2024-08-31 16:47:57,520 [foster.py] => Task 8, Epoch 18/170 => Loss 4.190, Loss_clf 0.920, Loss_fe 0.947, Loss_kd 2.060, Train_accy 73.16, Test_accy 66.89
2024-08-31 16:48:04,991 [foster.py] => Task 8, Epoch 19/170 => Loss 4.234, Loss_clf 0.952, Loss_fe 0.958, Loss_kd 2.061, Train_accy 72.20, Test_accy 68.93
2024-08-31 16:48:12,397 [foster.py] => Task 8, Epoch 20/170 => Loss 4.227, Loss_clf 0.908, Loss_fe 0.983, Loss_kd 2.072, Train_accy 73.84, Test_accy 69.71
2024-08-31 16:48:17,909 [foster.py] => Task 8, Epoch 21/170 => Loss 4.219, Loss_clf 0.907, Loss_fe 0.968, Loss_kd 2.080, Train_accy 73.33
2024-08-31 16:48:25,221 [foster.py] => Task 8, Epoch 22/170 => Loss 4.262, Loss_clf 0.979, Loss_fe 0.931, Loss_kd 2.086, Train_accy 71.91, Test_accy 69.18
2024-08-31 16:48:32,615 [foster.py] => Task 8, Epoch 23/170 => Loss 4.214, Loss_clf 0.910, Loss_fe 0.966, Loss_kd 2.074, Train_accy 73.58, Test_accy 70.93
2024-08-31 16:48:39,959 [foster.py] => Task 8, Epoch 24/170 => Loss 4.167, Loss_clf 0.889, Loss_fe 0.941, Loss_kd 2.072, Train_accy 73.38, Test_accy 70.60
2024-08-31 16:48:47,348 [foster.py] => Task 8, Epoch 25/170 => Loss 4.238, Loss_clf 0.949, Loss_fe 0.938, Loss_kd 2.086, Train_accy 72.20, Test_accy 67.82
2024-08-31 16:48:52,821 [foster.py] => Task 8, Epoch 26/170 => Loss 4.189, Loss_clf 0.905, Loss_fe 0.952, Loss_kd 2.069, Train_accy 73.64
2024-08-31 16:49:00,313 [foster.py] => Task 8, Epoch 27/170 => Loss 4.115, Loss_clf 0.845, Loss_fe 0.946, Loss_kd 2.062, Train_accy 75.11, Test_accy 67.82
2024-08-31 16:49:07,687 [foster.py] => Task 8, Epoch 28/170 => Loss 4.295, Loss_clf 0.992, Loss_fe 0.966, Loss_kd 2.073, Train_accy 71.44, Test_accy 70.18
2024-08-31 16:49:14,998 [foster.py] => Task 8, Epoch 29/170 => Loss 4.194, Loss_clf 0.886, Loss_fe 0.955, Loss_kd 2.088, Train_accy 73.56, Test_accy 71.07
2024-08-31 16:49:22,332 [foster.py] => Task 8, Epoch 30/170 => Loss 4.198, Loss_clf 0.924, Loss_fe 0.940, Loss_kd 2.071, Train_accy 73.18, Test_accy 71.80
2024-08-31 16:49:27,786 [foster.py] => Task 8, Epoch 31/170 => Loss 4.136, Loss_clf 0.865, Loss_fe 0.935, Loss_kd 2.073, Train_accy 73.98
2024-08-31 16:49:35,236 [foster.py] => Task 8, Epoch 32/170 => Loss 4.143, Loss_clf 0.864, Loss_fe 0.930, Loss_kd 2.085, Train_accy 74.87, Test_accy 70.38
2024-08-31 16:49:42,629 [foster.py] => Task 8, Epoch 33/170 => Loss 4.184, Loss_clf 0.899, Loss_fe 0.951, Loss_kd 2.071, Train_accy 73.89, Test_accy 69.67
2024-08-31 16:49:50,000 [foster.py] => Task 8, Epoch 34/170 => Loss 4.112, Loss_clf 0.857, Loss_fe 0.921, Loss_kd 2.071, Train_accy 74.67, Test_accy 71.38
2024-08-31 16:49:57,338 [foster.py] => Task 8, Epoch 35/170 => Loss 4.114, Loss_clf 0.839, Loss_fe 0.939, Loss_kd 2.071, Train_accy 74.89, Test_accy 70.69
2024-08-31 16:50:02,834 [foster.py] => Task 8, Epoch 36/170 => Loss 4.172, Loss_clf 0.866, Loss_fe 0.983, Loss_kd 2.061, Train_accy 74.96
2024-08-31 16:50:10,157 [foster.py] => Task 8, Epoch 37/170 => Loss 4.146, Loss_clf 0.890, Loss_fe 0.918, Loss_kd 2.074, Train_accy 74.13, Test_accy 70.49
2024-08-31 16:50:17,567 [foster.py] => Task 8, Epoch 38/170 => Loss 4.167, Loss_clf 0.899, Loss_fe 0.925, Loss_kd 2.079, Train_accy 73.47, Test_accy 70.29
2024-08-31 16:50:24,891 [foster.py] => Task 8, Epoch 39/170 => Loss 4.215, Loss_clf 0.896, Loss_fe 0.985, Loss_kd 2.071, Train_accy 73.58, Test_accy 68.49
2024-08-31 16:50:32,218 [foster.py] => Task 8, Epoch 40/170 => Loss 4.131, Loss_clf 0.839, Loss_fe 0.961, Loss_kd 2.069, Train_accy 74.82, Test_accy 68.04
2024-08-31 16:50:37,627 [foster.py] => Task 8, Epoch 41/170 => Loss 4.057, Loss_clf 0.833, Loss_fe 0.899, Loss_kd 2.062, Train_accy 74.60
2024-08-31 16:50:44,973 [foster.py] => Task 8, Epoch 42/170 => Loss 4.093, Loss_clf 0.848, Loss_fe 0.915, Loss_kd 2.067, Train_accy 73.80, Test_accy 70.56
2024-08-31 16:50:52,249 [foster.py] => Task 8, Epoch 43/170 => Loss 4.117, Loss_clf 0.847, Loss_fe 0.933, Loss_kd 2.074, Train_accy 74.78, Test_accy 71.02
2024-08-31 16:50:59,612 [foster.py] => Task 8, Epoch 44/170 => Loss 4.079, Loss_clf 0.848, Loss_fe 0.884, Loss_kd 2.082, Train_accy 74.40, Test_accy 71.49
2024-08-31 16:51:06,954 [foster.py] => Task 8, Epoch 45/170 => Loss 4.077, Loss_clf 0.849, Loss_fe 0.889, Loss_kd 2.076, Train_accy 75.42, Test_accy 67.33
2024-08-31 16:51:12,429 [foster.py] => Task 8, Epoch 46/170 => Loss 4.201, Loss_clf 0.878, Loss_fe 0.982, Loss_kd 2.077, Train_accy 73.78
2024-08-31 16:51:19,814 [foster.py] => Task 8, Epoch 47/170 => Loss 4.179, Loss_clf 0.881, Loss_fe 0.959, Loss_kd 2.075, Train_accy 74.04, Test_accy 70.98
2024-08-31 16:51:27,171 [foster.py] => Task 8, Epoch 48/170 => Loss 4.211, Loss_clf 0.883, Loss_fe 0.995, Loss_kd 2.070, Train_accy 73.13, Test_accy 69.49
2024-08-31 16:51:34,526 [foster.py] => Task 8, Epoch 49/170 => Loss 4.156, Loss_clf 0.845, Loss_fe 0.983, Loss_kd 2.066, Train_accy 74.62, Test_accy 70.96
2024-08-31 16:51:41,888 [foster.py] => Task 8, Epoch 50/170 => Loss 4.075, Loss_clf 0.843, Loss_fe 0.890, Loss_kd 2.078, Train_accy 74.87, Test_accy 70.22
2024-08-31 16:51:47,367 [foster.py] => Task 8, Epoch 51/170 => Loss 4.169, Loss_clf 0.887, Loss_fe 0.933, Loss_kd 2.085, Train_accy 73.47
2024-08-31 16:51:54,670 [foster.py] => Task 8, Epoch 52/170 => Loss 4.123, Loss_clf 0.892, Loss_fe 0.887, Loss_kd 2.079, Train_accy 74.36, Test_accy 70.69
2024-08-31 16:52:02,093 [foster.py] => Task 8, Epoch 53/170 => Loss 4.102, Loss_clf 0.851, Loss_fe 0.912, Loss_kd 2.076, Train_accy 75.91, Test_accy 68.93
2024-08-31 16:52:09,404 [foster.py] => Task 8, Epoch 54/170 => Loss 4.108, Loss_clf 0.866, Loss_fe 0.910, Loss_kd 2.069, Train_accy 74.11, Test_accy 71.27
2024-08-31 16:52:16,772 [foster.py] => Task 8, Epoch 55/170 => Loss 4.107, Loss_clf 0.852, Loss_fe 0.923, Loss_kd 2.069, Train_accy 74.49, Test_accy 68.29
2024-08-31 16:52:22,265 [foster.py] => Task 8, Epoch 56/170 => Loss 4.003, Loss_clf 0.829, Loss_fe 0.858, Loss_kd 2.055, Train_accy 75.27
2024-08-31 16:52:29,784 [foster.py] => Task 8, Epoch 57/170 => Loss 4.052, Loss_clf 0.840, Loss_fe 0.884, Loss_kd 2.066, Train_accy 75.33, Test_accy 71.80
2024-08-31 16:52:37,080 [foster.py] => Task 8, Epoch 58/170 => Loss 4.118, Loss_clf 0.854, Loss_fe 0.923, Loss_kd 2.077, Train_accy 73.98, Test_accy 70.80
2024-08-31 16:52:44,601 [foster.py] => Task 8, Epoch 59/170 => Loss 4.011, Loss_clf 0.823, Loss_fe 0.859, Loss_kd 2.066, Train_accy 75.60, Test_accy 70.16
2024-08-31 16:52:52,003 [foster.py] => Task 8, Epoch 60/170 => Loss 4.024, Loss_clf 0.824, Loss_fe 0.871, Loss_kd 2.066, Train_accy 75.47, Test_accy 68.60
2024-08-31 16:52:57,429 [foster.py] => Task 8, Epoch 61/170 => Loss 4.020, Loss_clf 0.828, Loss_fe 0.846, Loss_kd 2.081, Train_accy 76.20
2024-08-31 16:53:04,724 [foster.py] => Task 8, Epoch 62/170 => Loss 4.042, Loss_clf 0.820, Loss_fe 0.909, Loss_kd 2.053, Train_accy 76.22, Test_accy 70.80
2024-08-31 16:53:12,130 [foster.py] => Task 8, Epoch 63/170 => Loss 4.015, Loss_clf 0.823, Loss_fe 0.873, Loss_kd 2.058, Train_accy 74.82, Test_accy 67.64
2024-08-31 16:53:19,524 [foster.py] => Task 8, Epoch 64/170 => Loss 3.995, Loss_clf 0.821, Loss_fe 0.848, Loss_kd 2.064, Train_accy 75.67, Test_accy 69.53
2024-08-31 16:53:26,848 [foster.py] => Task 8, Epoch 65/170 => Loss 3.986, Loss_clf 0.805, Loss_fe 0.853, Loss_kd 2.065, Train_accy 76.47, Test_accy 67.87
2024-08-31 16:53:32,292 [foster.py] => Task 8, Epoch 66/170 => Loss 4.019, Loss_clf 0.839, Loss_fe 0.854, Loss_kd 2.064, Train_accy 75.13
2024-08-31 16:53:39,612 [foster.py] => Task 8, Epoch 67/170 => Loss 4.113, Loss_clf 0.851, Loss_fe 0.927, Loss_kd 2.072, Train_accy 75.24, Test_accy 72.04
2024-08-31 16:53:46,906 [foster.py] => Task 8, Epoch 68/170 => Loss 4.038, Loss_clf 0.840, Loss_fe 0.867, Loss_kd 2.068, Train_accy 75.56, Test_accy 70.16
2024-08-31 16:53:54,276 [foster.py] => Task 8, Epoch 69/170 => Loss 4.146, Loss_clf 0.893, Loss_fe 0.915, Loss_kd 2.074, Train_accy 74.02, Test_accy 71.71
2024-08-31 16:54:01,697 [foster.py] => Task 8, Epoch 70/170 => Loss 3.943, Loss_clf 0.785, Loss_fe 0.843, Loss_kd 2.054, Train_accy 77.24, Test_accy 69.51
2024-08-31 16:54:07,169 [foster.py] => Task 8, Epoch 71/170 => Loss 3.913, Loss_clf 0.785, Loss_fe 0.796, Loss_kd 2.069, Train_accy 76.38
2024-08-31 16:54:14,541 [foster.py] => Task 8, Epoch 72/170 => Loss 3.956, Loss_clf 0.801, Loss_fe 0.817, Loss_kd 2.074, Train_accy 75.53, Test_accy 71.56
2024-08-31 16:54:21,951 [foster.py] => Task 8, Epoch 73/170 => Loss 3.846, Loss_clf 0.743, Loss_fe 0.784, Loss_kd 2.057, Train_accy 77.84, Test_accy 70.36
2024-08-31 16:54:29,287 [foster.py] => Task 8, Epoch 74/170 => Loss 3.982, Loss_clf 0.823, Loss_fe 0.829, Loss_kd 2.067, Train_accy 76.24, Test_accy 71.18
2024-08-31 16:54:36,679 [foster.py] => Task 8, Epoch 75/170 => Loss 3.969, Loss_clf 0.818, Loss_fe 0.827, Loss_kd 2.061, Train_accy 75.42, Test_accy 71.38
2024-08-31 16:54:42,215 [foster.py] => Task 8, Epoch 76/170 => Loss 4.014, Loss_clf 0.838, Loss_fe 0.828, Loss_kd 2.083, Train_accy 74.44
2024-08-31 16:54:49,597 [foster.py] => Task 8, Epoch 77/170 => Loss 3.954, Loss_clf 0.791, Loss_fe 0.825, Loss_kd 2.075, Train_accy 76.71, Test_accy 71.18
2024-08-31 16:54:56,962 [foster.py] => Task 8, Epoch 78/170 => Loss 3.957, Loss_clf 0.792, Loss_fe 0.833, Loss_kd 2.069, Train_accy 76.89, Test_accy 71.29
2024-08-31 16:55:04,378 [foster.py] => Task 8, Epoch 79/170 => Loss 3.974, Loss_clf 0.845, Loss_fe 0.808, Loss_kd 2.060, Train_accy 75.22, Test_accy 71.47
2024-08-31 16:55:11,728 [foster.py] => Task 8, Epoch 80/170 => Loss 3.940, Loss_clf 0.804, Loss_fe 0.801, Loss_kd 2.072, Train_accy 76.22, Test_accy 69.96
2024-08-31 16:55:17,239 [foster.py] => Task 8, Epoch 81/170 => Loss 3.883, Loss_clf 0.787, Loss_fe 0.770, Loss_kd 2.064, Train_accy 77.33
2024-08-31 16:55:24,577 [foster.py] => Task 8, Epoch 82/170 => Loss 3.919, Loss_clf 0.795, Loss_fe 0.797, Loss_kd 2.064, Train_accy 76.71, Test_accy 70.78
2024-08-31 16:55:31,937 [foster.py] => Task 8, Epoch 83/170 => Loss 3.932, Loss_clf 0.782, Loss_fe 0.830, Loss_kd 2.058, Train_accy 75.56, Test_accy 69.78
2024-08-31 16:55:39,387 [foster.py] => Task 8, Epoch 84/170 => Loss 3.916, Loss_clf 0.789, Loss_fe 0.790, Loss_kd 2.074, Train_accy 76.93, Test_accy 72.22
2024-08-31 16:55:46,722 [foster.py] => Task 8, Epoch 85/170 => Loss 3.802, Loss_clf 0.738, Loss_fe 0.751, Loss_kd 2.052, Train_accy 78.02, Test_accy 70.80
2024-08-31 16:55:52,272 [foster.py] => Task 8, Epoch 86/170 => Loss 3.831, Loss_clf 0.753, Loss_fe 0.771, Loss_kd 2.047, Train_accy 76.38
2024-08-31 16:55:59,610 [foster.py] => Task 8, Epoch 87/170 => Loss 3.808, Loss_clf 0.753, Loss_fe 0.727, Loss_kd 2.066, Train_accy 78.16, Test_accy 70.80
2024-08-31 16:56:06,920 [foster.py] => Task 8, Epoch 88/170 => Loss 3.877, Loss_clf 0.769, Loss_fe 0.787, Loss_kd 2.059, Train_accy 77.36, Test_accy 71.84
2024-08-31 16:56:14,245 [foster.py] => Task 8, Epoch 89/170 => Loss 3.835, Loss_clf 0.747, Loss_fe 0.768, Loss_kd 2.058, Train_accy 78.09, Test_accy 72.58
2024-08-31 16:56:21,584 [foster.py] => Task 8, Epoch 90/170 => Loss 3.829, Loss_clf 0.753, Loss_fe 0.742, Loss_kd 2.071, Train_accy 77.98, Test_accy 70.62
2024-08-31 16:56:27,069 [foster.py] => Task 8, Epoch 91/170 => Loss 3.910, Loss_clf 0.788, Loss_fe 0.771, Loss_kd 2.085, Train_accy 76.56
2024-08-31 16:56:34,442 [foster.py] => Task 8, Epoch 92/170 => Loss 3.882, Loss_clf 0.770, Loss_fe 0.771, Loss_kd 2.078, Train_accy 77.02, Test_accy 70.76
2024-08-31 16:56:41,855 [foster.py] => Task 8, Epoch 93/170 => Loss 3.759, Loss_clf 0.724, Loss_fe 0.715, Loss_kd 2.059, Train_accy 78.27, Test_accy 70.93
2024-08-31 16:56:49,202 [foster.py] => Task 8, Epoch 94/170 => Loss 3.771, Loss_clf 0.738, Loss_fe 0.722, Loss_kd 2.050, Train_accy 78.02, Test_accy 72.16
2024-08-31 16:56:56,568 [foster.py] => Task 8, Epoch 95/170 => Loss 3.909, Loss_clf 0.793, Loss_fe 0.793, Loss_kd 2.061, Train_accy 76.09, Test_accy 72.49
2024-08-31 16:57:02,066 [foster.py] => Task 8, Epoch 96/170 => Loss 3.876, Loss_clf 0.776, Loss_fe 0.771, Loss_kd 2.067, Train_accy 77.73
2024-08-31 16:57:09,371 [foster.py] => Task 8, Epoch 97/170 => Loss 3.789, Loss_clf 0.744, Loss_fe 0.710, Loss_kd 2.072, Train_accy 78.36, Test_accy 71.33
2024-08-31 16:57:16,774 [foster.py] => Task 8, Epoch 98/170 => Loss 3.859, Loss_clf 0.767, Loss_fe 0.761, Loss_kd 2.068, Train_accy 77.53, Test_accy 71.73
2024-08-31 16:57:24,181 [foster.py] => Task 8, Epoch 99/170 => Loss 3.812, Loss_clf 0.756, Loss_fe 0.722, Loss_kd 2.070, Train_accy 78.02, Test_accy 71.56
2024-08-31 16:57:31,425 [foster.py] => Task 8, Epoch 100/170 => Loss 3.828, Loss_clf 0.771, Loss_fe 0.719, Loss_kd 2.075, Train_accy 77.38, Test_accy 71.18
2024-08-31 16:57:36,823 [foster.py] => Task 8, Epoch 101/170 => Loss 3.785, Loss_clf 0.739, Loss_fe 0.712, Loss_kd 2.071, Train_accy 77.84
2024-08-31 16:57:44,111 [foster.py] => Task 8, Epoch 102/170 => Loss 3.695, Loss_clf 0.699, Loss_fe 0.674, Loss_kd 2.060, Train_accy 80.47, Test_accy 71.69
2024-08-31 16:57:51,443 [foster.py] => Task 8, Epoch 103/170 => Loss 3.764, Loss_clf 0.725, Loss_fe 0.703, Loss_kd 2.073, Train_accy 78.89, Test_accy 69.96
2024-08-31 16:57:58,840 [foster.py] => Task 8, Epoch 104/170 => Loss 3.753, Loss_clf 0.739, Loss_fe 0.675, Loss_kd 2.076, Train_accy 78.13, Test_accy 70.71
2024-08-31 16:58:06,246 [foster.py] => Task 8, Epoch 105/170 => Loss 3.736, Loss_clf 0.724, Loss_fe 0.676, Loss_kd 2.073, Train_accy 78.22, Test_accy 69.73
2024-08-31 16:58:11,684 [foster.py] => Task 8, Epoch 106/170 => Loss 3.703, Loss_clf 0.705, Loss_fe 0.676, Loss_kd 2.060, Train_accy 79.27
2024-08-31 16:58:19,069 [foster.py] => Task 8, Epoch 107/170 => Loss 3.728, Loss_clf 0.721, Loss_fe 0.668, Loss_kd 2.076, Train_accy 78.69, Test_accy 71.98
2024-08-31 16:58:26,413 [foster.py] => Task 8, Epoch 108/170 => Loss 3.737, Loss_clf 0.732, Loss_fe 0.668, Loss_kd 2.074, Train_accy 78.27, Test_accy 71.42
2024-08-31 16:58:33,803 [foster.py] => Task 8, Epoch 109/170 => Loss 3.745, Loss_clf 0.731, Loss_fe 0.676, Loss_kd 2.075, Train_accy 78.87, Test_accy 71.80
2024-08-31 16:58:41,119 [foster.py] => Task 8, Epoch 110/170 => Loss 3.677, Loss_clf 0.703, Loss_fe 0.655, Loss_kd 2.058, Train_accy 79.09, Test_accy 72.00
2024-08-31 16:58:46,553 [foster.py] => Task 8, Epoch 111/170 => Loss 3.652, Loss_clf 0.694, Loss_fe 0.636, Loss_kd 2.060, Train_accy 80.16
2024-08-31 16:58:53,886 [foster.py] => Task 8, Epoch 112/170 => Loss 3.668, Loss_clf 0.691, Loss_fe 0.661, Loss_kd 2.054, Train_accy 78.96, Test_accy 70.13
2024-08-31 16:59:01,380 [foster.py] => Task 8, Epoch 113/170 => Loss 3.691, Loss_clf 0.722, Loss_fe 0.635, Loss_kd 2.072, Train_accy 78.82, Test_accy 71.53
2024-08-31 16:59:08,795 [foster.py] => Task 8, Epoch 114/170 => Loss 3.650, Loss_clf 0.689, Loss_fe 0.634, Loss_kd 2.065, Train_accy 79.89, Test_accy 71.04
2024-08-31 16:59:16,262 [foster.py] => Task 8, Epoch 115/170 => Loss 3.624, Loss_clf 0.682, Loss_fe 0.615, Loss_kd 2.065, Train_accy 79.76, Test_accy 71.87
2024-08-31 16:59:21,756 [foster.py] => Task 8, Epoch 116/170 => Loss 3.633, Loss_clf 0.678, Loss_fe 0.621, Loss_kd 2.071, Train_accy 80.16
2024-08-31 16:59:29,097 [foster.py] => Task 8, Epoch 117/170 => Loss 3.622, Loss_clf 0.681, Loss_fe 0.623, Loss_kd 2.057, Train_accy 80.07, Test_accy 71.36
2024-08-31 16:59:36,490 [foster.py] => Task 8, Epoch 118/170 => Loss 3.584, Loss_clf 0.666, Loss_fe 0.595, Loss_kd 2.062, Train_accy 80.29, Test_accy 72.69
2024-08-31 16:59:43,808 [foster.py] => Task 8, Epoch 119/170 => Loss 3.656, Loss_clf 0.710, Loss_fe 0.603, Loss_kd 2.079, Train_accy 80.20, Test_accy 73.31
2024-08-31 16:59:51,203 [foster.py] => Task 8, Epoch 120/170 => Loss 3.586, Loss_clf 0.661, Loss_fe 0.602, Loss_kd 2.062, Train_accy 80.67, Test_accy 71.16
2024-08-31 16:59:56,875 [foster.py] => Task 8, Epoch 121/170 => Loss 3.561, Loss_clf 0.649, Loss_fe 0.583, Loss_kd 2.067, Train_accy 81.27
2024-08-31 17:00:04,505 [foster.py] => Task 8, Epoch 122/170 => Loss 3.575, Loss_clf 0.665, Loss_fe 0.591, Loss_kd 2.058, Train_accy 80.89, Test_accy 72.60
2024-08-31 17:00:12,162 [foster.py] => Task 8, Epoch 123/170 => Loss 3.556, Loss_clf 0.651, Loss_fe 0.591, Loss_kd 2.053, Train_accy 81.53, Test_accy 71.76
2024-08-31 17:00:19,673 [foster.py] => Task 8, Epoch 124/170 => Loss 3.502, Loss_clf 0.628, Loss_fe 0.557, Loss_kd 2.056, Train_accy 81.42, Test_accy 72.36
2024-08-31 17:00:27,037 [foster.py] => Task 8, Epoch 125/170 => Loss 3.545, Loss_clf 0.648, Loss_fe 0.567, Loss_kd 2.068, Train_accy 81.18, Test_accy 72.87
2024-08-31 17:00:32,611 [foster.py] => Task 8, Epoch 126/170 => Loss 3.592, Loss_clf 0.682, Loss_fe 0.575, Loss_kd 2.071, Train_accy 80.71
2024-08-31 17:00:39,957 [foster.py] => Task 8, Epoch 127/170 => Loss 3.534, Loss_clf 0.649, Loss_fe 0.565, Loss_kd 2.058, Train_accy 80.93, Test_accy 71.53
2024-08-31 17:00:47,320 [foster.py] => Task 8, Epoch 128/170 => Loss 3.497, Loss_clf 0.646, Loss_fe 0.536, Loss_kd 2.053, Train_accy 81.51, Test_accy 72.58
2024-08-31 17:00:54,742 [foster.py] => Task 8, Epoch 129/170 => Loss 3.512, Loss_clf 0.635, Loss_fe 0.541, Loss_kd 2.073, Train_accy 82.36, Test_accy 71.80
2024-08-31 17:01:02,072 [foster.py] => Task 8, Epoch 130/170 => Loss 3.531, Loss_clf 0.652, Loss_fe 0.539, Loss_kd 2.076, Train_accy 81.58, Test_accy 72.40
2024-08-31 17:01:07,540 [foster.py] => Task 8, Epoch 131/170 => Loss 3.492, Loss_clf 0.644, Loss_fe 0.530, Loss_kd 2.057, Train_accy 81.27
2024-08-31 17:01:14,894 [foster.py] => Task 8, Epoch 132/170 => Loss 3.391, Loss_clf 0.578, Loss_fe 0.486, Loss_kd 2.065, Train_accy 83.16, Test_accy 72.47
2024-08-31 17:01:22,258 [foster.py] => Task 8, Epoch 133/170 => Loss 3.455, Loss_clf 0.620, Loss_fe 0.496, Loss_kd 2.075, Train_accy 82.13, Test_accy 73.33
2024-08-31 17:01:29,583 [foster.py] => Task 8, Epoch 134/170 => Loss 3.442, Loss_clf 0.610, Loss_fe 0.502, Loss_kd 2.068, Train_accy 81.80, Test_accy 72.51
2024-08-31 17:01:36,965 [foster.py] => Task 8, Epoch 135/170 => Loss 3.444, Loss_clf 0.613, Loss_fe 0.499, Loss_kd 2.070, Train_accy 82.62, Test_accy 73.27
2024-08-31 17:01:42,438 [foster.py] => Task 8, Epoch 136/170 => Loss 3.404, Loss_clf 0.581, Loss_fe 0.499, Loss_kd 2.063, Train_accy 83.04
2024-08-31 17:01:49,746 [foster.py] => Task 8, Epoch 137/170 => Loss 3.390, Loss_clf 0.590, Loss_fe 0.479, Loss_kd 2.059, Train_accy 82.89, Test_accy 73.33
2024-08-31 17:01:57,106 [foster.py] => Task 8, Epoch 138/170 => Loss 3.406, Loss_clf 0.608, Loss_fe 0.472, Loss_kd 2.064, Train_accy 82.40, Test_accy 71.96
2024-08-31 17:02:04,517 [foster.py] => Task 8, Epoch 139/170 => Loss 3.395, Loss_clf 0.595, Loss_fe 0.476, Loss_kd 2.062, Train_accy 83.58, Test_accy 72.51
2024-08-31 17:02:11,890 [foster.py] => Task 8, Epoch 140/170 => Loss 3.400, Loss_clf 0.594, Loss_fe 0.466, Loss_kd 2.077, Train_accy 82.64, Test_accy 71.87
2024-08-31 17:02:17,414 [foster.py] => Task 8, Epoch 141/170 => Loss 3.339, Loss_clf 0.583, Loss_fe 0.446, Loss_kd 2.050, Train_accy 83.16
2024-08-31 17:02:24,803 [foster.py] => Task 8, Epoch 142/170 => Loss 3.323, Loss_clf 0.564, Loss_fe 0.438, Loss_kd 2.059, Train_accy 84.09, Test_accy 72.67
2024-08-31 17:02:32,134 [foster.py] => Task 8, Epoch 143/170 => Loss 3.313, Loss_clf 0.561, Loss_fe 0.437, Loss_kd 2.054, Train_accy 84.13, Test_accy 72.69
2024-08-31 17:02:39,517 [foster.py] => Task 8, Epoch 144/170 => Loss 3.304, Loss_clf 0.557, Loss_fe 0.431, Loss_kd 2.055, Train_accy 83.29, Test_accy 72.64
2024-08-31 17:02:46,888 [foster.py] => Task 8, Epoch 145/170 => Loss 3.334, Loss_clf 0.572, Loss_fe 0.440, Loss_kd 2.061, Train_accy 84.60, Test_accy 72.11
2024-08-31 17:02:52,374 [foster.py] => Task 8, Epoch 146/170 => Loss 3.356, Loss_clf 0.578, Loss_fe 0.434, Loss_kd 2.080, Train_accy 83.27
2024-08-31 17:02:59,706 [foster.py] => Task 8, Epoch 147/170 => Loss 3.257, Loss_clf 0.537, Loss_fe 0.419, Loss_kd 2.041, Train_accy 84.58, Test_accy 72.04
2024-08-31 17:03:07,146 [foster.py] => Task 8, Epoch 148/170 => Loss 3.257, Loss_clf 0.537, Loss_fe 0.404, Loss_kd 2.055, Train_accy 84.80, Test_accy 73.00
2024-08-31 17:03:14,512 [foster.py] => Task 8, Epoch 149/170 => Loss 3.312, Loss_clf 0.570, Loss_fe 0.409, Loss_kd 2.070, Train_accy 83.42, Test_accy 73.36
2024-08-31 17:03:21,881 [foster.py] => Task 8, Epoch 150/170 => Loss 3.274, Loss_clf 0.556, Loss_fe 0.399, Loss_kd 2.057, Train_accy 84.29, Test_accy 72.73
2024-08-31 17:03:27,280 [foster.py] => Task 8, Epoch 151/170 => Loss 3.256, Loss_clf 0.536, Loss_fe 0.388, Loss_kd 2.069, Train_accy 84.84
2024-08-31 17:03:34,670 [foster.py] => Task 8, Epoch 152/170 => Loss 3.239, Loss_clf 0.536, Loss_fe 0.385, Loss_kd 2.056, Train_accy 84.73, Test_accy 73.49
2024-08-31 17:03:42,102 [foster.py] => Task 8, Epoch 153/170 => Loss 3.237, Loss_clf 0.532, Loss_fe 0.377, Loss_kd 2.065, Train_accy 85.42, Test_accy 73.13
2024-08-31 17:03:49,521 [foster.py] => Task 8, Epoch 154/170 => Loss 3.216, Loss_clf 0.526, Loss_fe 0.375, Loss_kd 2.054, Train_accy 85.62, Test_accy 73.31
2024-08-31 17:03:56,833 [foster.py] => Task 8, Epoch 155/170 => Loss 3.241, Loss_clf 0.535, Loss_fe 0.390, Loss_kd 2.054, Train_accy 85.33, Test_accy 73.07
2024-08-31 17:04:02,357 [foster.py] => Task 8, Epoch 156/170 => Loss 3.239, Loss_clf 0.535, Loss_fe 0.381, Loss_kd 2.061, Train_accy 84.73
2024-08-31 17:04:09,726 [foster.py] => Task 8, Epoch 157/170 => Loss 3.230, Loss_clf 0.529, Loss_fe 0.366, Loss_kd 2.072, Train_accy 84.76, Test_accy 73.44
2024-08-31 17:04:17,110 [foster.py] => Task 8, Epoch 158/170 => Loss 3.248, Loss_clf 0.546, Loss_fe 0.379, Loss_kd 2.061, Train_accy 85.02, Test_accy 73.33
2024-08-31 17:04:24,562 [foster.py] => Task 8, Epoch 159/170 => Loss 3.179, Loss_clf 0.515, Loss_fe 0.350, Loss_kd 2.054, Train_accy 85.09, Test_accy 73.16
2024-08-31 17:04:31,971 [foster.py] => Task 8, Epoch 160/170 => Loss 3.207, Loss_clf 0.527, Loss_fe 0.357, Loss_kd 2.062, Train_accy 85.20, Test_accy 73.18
2024-08-31 17:04:37,507 [foster.py] => Task 8, Epoch 161/170 => Loss 3.223, Loss_clf 0.534, Loss_fe 0.354, Loss_kd 2.072, Train_accy 85.38
2024-08-31 17:04:44,828 [foster.py] => Task 8, Epoch 162/170 => Loss 3.196, Loss_clf 0.519, Loss_fe 0.345, Loss_kd 2.070, Train_accy 85.69, Test_accy 73.16
2024-08-31 17:04:52,179 [foster.py] => Task 8, Epoch 163/170 => Loss 3.190, Loss_clf 0.519, Loss_fe 0.348, Loss_kd 2.061, Train_accy 85.58, Test_accy 73.38
2024-08-31 17:04:59,573 [foster.py] => Task 8, Epoch 164/170 => Loss 3.232, Loss_clf 0.535, Loss_fe 0.364, Loss_kd 2.070, Train_accy 85.20, Test_accy 73.11
2024-08-31 17:05:06,914 [foster.py] => Task 8, Epoch 165/170 => Loss 3.207, Loss_clf 0.523, Loss_fe 0.353, Loss_kd 2.068, Train_accy 84.89, Test_accy 73.22
2024-08-31 17:05:12,385 [foster.py] => Task 8, Epoch 166/170 => Loss 3.232, Loss_clf 0.533, Loss_fe 0.361, Loss_kd 2.075, Train_accy 84.76
2024-08-31 17:05:19,822 [foster.py] => Task 8, Epoch 167/170 => Loss 3.153, Loss_clf 0.500, Loss_fe 0.348, Loss_kd 2.045, Train_accy 85.91, Test_accy 73.16
2024-08-31 17:05:27,209 [foster.py] => Task 8, Epoch 168/170 => Loss 3.235, Loss_clf 0.538, Loss_fe 0.363, Loss_kd 2.070, Train_accy 84.62, Test_accy 73.33
2024-08-31 17:05:34,517 [foster.py] => Task 8, Epoch 169/170 => Loss 3.175, Loss_clf 0.501, Loss_fe 0.348, Loss_kd 2.064, Train_accy 85.84, Test_accy 73.42
2024-08-31 17:05:41,883 [foster.py] => Task 8, Epoch 170/170 => Loss 3.239, Loss_clf 0.543, Loss_fe 0.370, Loss_kd 2.063, Train_accy 84.64, Test_accy 73.22
2024-08-31 17:05:41,885 [foster.py] => do not weight align teacher!
2024-08-31 17:05:41,886 [foster.py] => per cls weights : [1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425 1.03319425
 1.03319425 1.03319425 1.03319425 1.03319425 0.73444596 0.73444596
 0.73444596 0.73444596 0.73444596]
2024-08-31 17:05:50,957 [foster.py] => SNet: Task 8, Epoch 1/130 => Loss 26.053,  Loss1 0.646, Train_accy 54.91, Test_accy 64.58
2024-08-31 17:05:58,388 [foster.py] => SNet: Task 8, Epoch 2/130 => Loss 25.929,  Loss1 0.647, Train_accy 70.18
2024-08-31 17:06:05,700 [foster.py] => SNet: Task 8, Epoch 3/130 => Loss 25.890,  Loss1 0.646, Train_accy 72.71
2024-08-31 17:06:13,331 [foster.py] => SNet: Task 8, Epoch 4/130 => Loss 25.885,  Loss1 0.646, Train_accy 72.42
2024-08-31 17:06:20,623 [foster.py] => SNet: Task 8, Epoch 5/130 => Loss 25.888,  Loss1 0.646, Train_accy 73.44
2024-08-31 17:06:30,264 [foster.py] => SNet: Task 8, Epoch 6/130 => Loss 25.870,  Loss1 0.646, Train_accy 74.07, Test_accy 70.36
2024-08-31 17:06:37,841 [foster.py] => SNet: Task 8, Epoch 7/130 => Loss 25.846,  Loss1 0.646, Train_accy 75.20
2024-08-31 17:06:45,564 [foster.py] => SNet: Task 8, Epoch 8/130 => Loss 25.860,  Loss1 0.646, Train_accy 75.31
2024-08-31 17:06:52,868 [foster.py] => SNet: Task 8, Epoch 9/130 => Loss 25.879,  Loss1 0.646, Train_accy 74.58
2024-08-31 17:07:00,531 [foster.py] => SNet: Task 8, Epoch 10/130 => Loss 25.862,  Loss1 0.645, Train_accy 76.20
2024-08-31 17:07:09,380 [foster.py] => SNet: Task 8, Epoch 11/130 => Loss 25.854,  Loss1 0.646, Train_accy 76.04, Test_accy 69.78
2024-08-31 17:07:17,059 [foster.py] => SNet: Task 8, Epoch 12/130 => Loss 25.851,  Loss1 0.646, Train_accy 77.02
2024-08-31 17:07:24,386 [foster.py] => SNet: Task 8, Epoch 13/130 => Loss 25.843,  Loss1 0.646, Train_accy 77.31
2024-08-31 17:07:31,964 [foster.py] => SNet: Task 8, Epoch 14/130 => Loss 25.854,  Loss1 0.646, Train_accy 76.31
2024-08-31 17:07:39,290 [foster.py] => SNet: Task 8, Epoch 15/130 => Loss 25.864,  Loss1 0.646, Train_accy 78.09
2024-08-31 17:07:48,155 [foster.py] => SNet: Task 8, Epoch 16/130 => Loss 25.842,  Loss1 0.646, Train_accy 77.80, Test_accy 70.76
2024-08-31 17:07:55,625 [foster.py] => SNet: Task 8, Epoch 17/130 => Loss 25.876,  Loss1 0.646, Train_accy 77.09
2024-08-31 17:08:03,004 [foster.py] => SNet: Task 8, Epoch 18/130 => Loss 25.846,  Loss1 0.646, Train_accy 77.16
2024-08-31 17:08:10,469 [foster.py] => SNet: Task 8, Epoch 19/130 => Loss 25.866,  Loss1 0.645, Train_accy 76.73
2024-08-31 17:08:17,775 [foster.py] => SNet: Task 8, Epoch 20/130 => Loss 25.861,  Loss1 0.645, Train_accy 77.33
2024-08-31 17:08:26,796 [foster.py] => SNet: Task 8, Epoch 21/130 => Loss 25.861,  Loss1 0.646, Train_accy 78.07, Test_accy 70.71
2024-08-31 17:08:34,198 [foster.py] => SNet: Task 8, Epoch 22/130 => Loss 25.850,  Loss1 0.645, Train_accy 78.04
2024-08-31 17:08:41,848 [foster.py] => SNet: Task 8, Epoch 23/130 => Loss 25.873,  Loss1 0.645, Train_accy 77.58
2024-08-31 17:08:49,158 [foster.py] => SNet: Task 8, Epoch 24/130 => Loss 25.854,  Loss1 0.646, Train_accy 78.20
2024-08-31 17:08:56,458 [foster.py] => SNet: Task 8, Epoch 25/130 => Loss 25.819,  Loss1 0.645, Train_accy 78.96
2024-08-31 17:09:05,424 [foster.py] => SNet: Task 8, Epoch 26/130 => Loss 25.835,  Loss1 0.646, Train_accy 79.40, Test_accy 69.29
2024-08-31 17:09:12,798 [foster.py] => SNet: Task 8, Epoch 27/130 => Loss 25.849,  Loss1 0.645, Train_accy 78.40
2024-08-31 17:09:20,446 [foster.py] => SNet: Task 8, Epoch 28/130 => Loss 25.863,  Loss1 0.645, Train_accy 78.20
2024-08-31 17:09:28,082 [foster.py] => SNet: Task 8, Epoch 29/130 => Loss 25.826,  Loss1 0.645, Train_accy 78.29
2024-08-31 17:09:35,402 [foster.py] => SNet: Task 8, Epoch 30/130 => Loss 25.827,  Loss1 0.646, Train_accy 78.87
2024-08-31 17:09:44,293 [foster.py] => SNet: Task 8, Epoch 31/130 => Loss 25.853,  Loss1 0.645, Train_accy 78.42, Test_accy 70.58
2024-08-31 17:09:51,825 [foster.py] => SNet: Task 8, Epoch 32/130 => Loss 25.818,  Loss1 0.645, Train_accy 79.44
2024-08-31 17:09:59,375 [foster.py] => SNet: Task 8, Epoch 33/130 => Loss 25.855,  Loss1 0.645, Train_accy 79.87
2024-08-31 17:10:06,926 [foster.py] => SNet: Task 8, Epoch 34/130 => Loss 25.795,  Loss1 0.645, Train_accy 80.07
2024-08-31 17:10:14,357 [foster.py] => SNet: Task 8, Epoch 35/130 => Loss 25.826,  Loss1 0.645, Train_accy 78.18
2024-08-31 17:10:23,376 [foster.py] => SNet: Task 8, Epoch 36/130 => Loss 25.796,  Loss1 0.646, Train_accy 79.80, Test_accy 70.84
2024-08-31 17:10:30,688 [foster.py] => SNet: Task 8, Epoch 37/130 => Loss 25.858,  Loss1 0.646, Train_accy 79.78
2024-08-31 17:10:38,099 [foster.py] => SNet: Task 8, Epoch 38/130 => Loss 25.838,  Loss1 0.646, Train_accy 78.62
2024-08-31 17:10:45,756 [foster.py] => SNet: Task 8, Epoch 39/130 => Loss 25.834,  Loss1 0.646, Train_accy 79.62
2024-08-31 17:10:53,171 [foster.py] => SNet: Task 8, Epoch 40/130 => Loss 25.804,  Loss1 0.645, Train_accy 79.22
2024-08-31 17:11:02,320 [foster.py] => SNet: Task 8, Epoch 41/130 => Loss 25.833,  Loss1 0.646, Train_accy 79.40, Test_accy 70.07
2024-08-31 17:11:09,752 [foster.py] => SNet: Task 8, Epoch 42/130 => Loss 25.825,  Loss1 0.646, Train_accy 79.60
2024-08-31 17:11:17,069 [foster.py] => SNet: Task 8, Epoch 43/130 => Loss 25.804,  Loss1 0.646, Train_accy 79.22
2024-08-31 17:11:24,396 [foster.py] => SNet: Task 8, Epoch 44/130 => Loss 25.815,  Loss1 0.646, Train_accy 79.98
2024-08-31 17:11:32,089 [foster.py] => SNet: Task 8, Epoch 45/130 => Loss 25.803,  Loss1 0.645, Train_accy 79.44
2024-08-31 17:11:41,155 [foster.py] => SNet: Task 8, Epoch 46/130 => Loss 25.816,  Loss1 0.645, Train_accy 79.96, Test_accy 71.38
2024-08-31 17:11:48,769 [foster.py] => SNet: Task 8, Epoch 47/130 => Loss 25.821,  Loss1 0.646, Train_accy 80.40
2024-08-31 17:11:56,083 [foster.py] => SNet: Task 8, Epoch 48/130 => Loss 25.856,  Loss1 0.645, Train_accy 80.24
2024-08-31 17:12:03,603 [foster.py] => SNet: Task 8, Epoch 49/130 => Loss 25.820,  Loss1 0.646, Train_accy 80.80
2024-08-31 17:12:11,143 [foster.py] => SNet: Task 8, Epoch 50/130 => Loss 25.844,  Loss1 0.645, Train_accy 80.18
2024-08-31 17:12:20,625 [foster.py] => SNet: Task 8, Epoch 51/130 => Loss 25.825,  Loss1 0.646, Train_accy 79.84, Test_accy 71.16
2024-08-31 17:12:28,238 [foster.py] => SNet: Task 8, Epoch 52/130 => Loss 25.817,  Loss1 0.645, Train_accy 80.82
2024-08-31 17:12:35,786 [foster.py] => SNet: Task 8, Epoch 53/130 => Loss 25.834,  Loss1 0.646, Train_accy 80.22
2024-08-31 17:12:43,112 [foster.py] => SNet: Task 8, Epoch 54/130 => Loss 25.811,  Loss1 0.646, Train_accy 81.56
2024-08-31 17:12:50,370 [foster.py] => SNet: Task 8, Epoch 55/130 => Loss 25.811,  Loss1 0.645, Train_accy 80.96
2024-08-31 17:12:59,509 [foster.py] => SNet: Task 8, Epoch 56/130 => Loss 25.820,  Loss1 0.645, Train_accy 80.84, Test_accy 72.40
2024-08-31 17:13:06,784 [foster.py] => SNet: Task 8, Epoch 57/130 => Loss 25.814,  Loss1 0.645, Train_accy 80.78
2024-08-31 17:13:14,020 [foster.py] => SNet: Task 8, Epoch 58/130 => Loss 25.807,  Loss1 0.646, Train_accy 79.98
2024-08-31 17:13:21,440 [foster.py] => SNet: Task 8, Epoch 59/130 => Loss 25.801,  Loss1 0.646, Train_accy 81.20
2024-08-31 17:13:29,068 [foster.py] => SNet: Task 8, Epoch 60/130 => Loss 25.822,  Loss1 0.645, Train_accy 80.93
2024-08-31 17:13:37,975 [foster.py] => SNet: Task 8, Epoch 61/130 => Loss 25.772,  Loss1 0.646, Train_accy 81.69, Test_accy 72.11
2024-08-31 17:13:45,344 [foster.py] => SNet: Task 8, Epoch 62/130 => Loss 25.815,  Loss1 0.645, Train_accy 80.04
2024-08-31 17:13:52,782 [foster.py] => SNet: Task 8, Epoch 63/130 => Loss 25.819,  Loss1 0.645, Train_accy 81.27
2024-08-31 17:14:00,192 [foster.py] => SNet: Task 8, Epoch 64/130 => Loss 25.841,  Loss1 0.645, Train_accy 80.44
2024-08-31 17:14:07,543 [foster.py] => SNet: Task 8, Epoch 65/130 => Loss 25.819,  Loss1 0.645, Train_accy 82.02
2024-08-31 17:14:16,500 [foster.py] => SNet: Task 8, Epoch 66/130 => Loss 25.800,  Loss1 0.646, Train_accy 81.58, Test_accy 71.18
2024-08-31 17:14:24,079 [foster.py] => SNet: Task 8, Epoch 67/130 => Loss 25.803,  Loss1 0.646, Train_accy 81.96
2024-08-31 17:14:31,596 [foster.py] => SNet: Task 8, Epoch 68/130 => Loss 25.811,  Loss1 0.646, Train_accy 80.98
2024-08-31 17:14:39,105 [foster.py] => SNet: Task 8, Epoch 69/130 => Loss 25.818,  Loss1 0.646, Train_accy 82.29
2024-08-31 17:14:46,530 [foster.py] => SNet: Task 8, Epoch 70/130 => Loss 25.790,  Loss1 0.645, Train_accy 81.09
2024-08-31 17:14:55,645 [foster.py] => SNet: Task 8, Epoch 71/130 => Loss 25.832,  Loss1 0.645, Train_accy 81.53, Test_accy 71.51
2024-08-31 17:15:02,945 [foster.py] => SNet: Task 8, Epoch 72/130 => Loss 25.777,  Loss1 0.646, Train_accy 82.58
2024-08-31 17:15:10,467 [foster.py] => SNet: Task 8, Epoch 73/130 => Loss 25.802,  Loss1 0.645, Train_accy 81.89
2024-08-31 17:15:18,011 [foster.py] => SNet: Task 8, Epoch 74/130 => Loss 25.807,  Loss1 0.646, Train_accy 81.49
2024-08-31 17:15:25,505 [foster.py] => SNet: Task 8, Epoch 75/130 => Loss 25.790,  Loss1 0.645, Train_accy 80.98
2024-08-31 17:15:34,516 [foster.py] => SNet: Task 8, Epoch 76/130 => Loss 25.855,  Loss1 0.646, Train_accy 81.51, Test_accy 71.44
2024-08-31 17:15:41,865 [foster.py] => SNet: Task 8, Epoch 77/130 => Loss 25.802,  Loss1 0.645, Train_accy 81.36
2024-08-31 17:15:49,389 [foster.py] => SNet: Task 8, Epoch 78/130 => Loss 25.808,  Loss1 0.645, Train_accy 82.78
2024-08-31 17:15:56,735 [foster.py] => SNet: Task 8, Epoch 79/130 => Loss 25.814,  Loss1 0.646, Train_accy 81.93
2024-08-31 17:16:04,416 [foster.py] => SNet: Task 8, Epoch 80/130 => Loss 25.751,  Loss1 0.645, Train_accy 81.42
2024-08-31 17:16:13,461 [foster.py] => SNet: Task 8, Epoch 81/130 => Loss 25.796,  Loss1 0.645, Train_accy 83.33, Test_accy 71.53
2024-08-31 17:16:20,989 [foster.py] => SNet: Task 8, Epoch 82/130 => Loss 25.794,  Loss1 0.645, Train_accy 82.18
2024-08-31 17:16:28,505 [foster.py] => SNet: Task 8, Epoch 83/130 => Loss 25.824,  Loss1 0.646, Train_accy 81.69
2024-08-31 17:16:35,883 [foster.py] => SNet: Task 8, Epoch 84/130 => Loss 25.799,  Loss1 0.645, Train_accy 81.69
2024-08-31 17:16:43,145 [foster.py] => SNet: Task 8, Epoch 85/130 => Loss 25.815,  Loss1 0.646, Train_accy 82.07
2024-08-31 17:16:52,175 [foster.py] => SNet: Task 8, Epoch 86/130 => Loss 25.800,  Loss1 0.645, Train_accy 82.24, Test_accy 71.60
2024-08-31 17:16:59,533 [foster.py] => SNet: Task 8, Epoch 87/130 => Loss 25.809,  Loss1 0.645, Train_accy 81.07
2024-08-31 17:17:06,936 [foster.py] => SNet: Task 8, Epoch 88/130 => Loss 25.815,  Loss1 0.645, Train_accy 82.31
2024-08-31 17:17:14,190 [foster.py] => SNet: Task 8, Epoch 89/130 => Loss 25.793,  Loss1 0.645, Train_accy 81.82
2024-08-31 17:17:21,548 [foster.py] => SNet: Task 8, Epoch 90/130 => Loss 25.808,  Loss1 0.646, Train_accy 83.04
2024-08-31 17:17:30,421 [foster.py] => SNet: Task 8, Epoch 91/130 => Loss 25.805,  Loss1 0.646, Train_accy 81.51, Test_accy 72.00
2024-08-31 17:17:37,834 [foster.py] => SNet: Task 8, Epoch 92/130 => Loss 25.812,  Loss1 0.646, Train_accy 82.13
2024-08-31 17:17:45,325 [foster.py] => SNet: Task 8, Epoch 93/130 => Loss 25.806,  Loss1 0.645, Train_accy 81.84
2024-08-31 17:17:52,779 [foster.py] => SNet: Task 8, Epoch 94/130 => Loss 25.812,  Loss1 0.646, Train_accy 81.64
2024-08-31 17:18:00,137 [foster.py] => SNet: Task 8, Epoch 95/130 => Loss 25.804,  Loss1 0.646, Train_accy 81.82
2024-08-31 17:18:09,248 [foster.py] => SNet: Task 8, Epoch 96/130 => Loss 25.805,  Loss1 0.645, Train_accy 81.42, Test_accy 72.00
2024-08-31 17:18:16,921 [foster.py] => SNet: Task 8, Epoch 97/130 => Loss 25.823,  Loss1 0.645, Train_accy 81.51
2024-08-31 17:18:24,172 [foster.py] => SNet: Task 8, Epoch 98/130 => Loss 25.826,  Loss1 0.645, Train_accy 80.91
2024-08-31 17:18:31,579 [foster.py] => SNet: Task 8, Epoch 99/130 => Loss 25.809,  Loss1 0.645, Train_accy 81.91
2024-08-31 17:18:39,274 [foster.py] => SNet: Task 8, Epoch 100/130 => Loss 25.822,  Loss1 0.646, Train_accy 82.31
2024-08-31 17:18:48,495 [foster.py] => SNet: Task 8, Epoch 101/130 => Loss 25.799,  Loss1 0.646, Train_accy 81.78, Test_accy 71.89
2024-08-31 17:18:55,805 [foster.py] => SNet: Task 8, Epoch 102/130 => Loss 25.800,  Loss1 0.646, Train_accy 81.80
2024-08-31 17:19:03,178 [foster.py] => SNet: Task 8, Epoch 103/130 => Loss 25.796,  Loss1 0.645, Train_accy 82.58
2024-08-31 17:19:10,723 [foster.py] => SNet: Task 8, Epoch 104/130 => Loss 25.814,  Loss1 0.646, Train_accy 82.71
2024-08-31 17:19:18,080 [foster.py] => SNet: Task 8, Epoch 105/130 => Loss 25.835,  Loss1 0.645, Train_accy 82.00
2024-08-31 17:19:27,049 [foster.py] => SNet: Task 8, Epoch 106/130 => Loss 25.808,  Loss1 0.646, Train_accy 82.36, Test_accy 72.16
2024-08-31 17:19:34,518 [foster.py] => SNet: Task 8, Epoch 107/130 => Loss 25.813,  Loss1 0.646, Train_accy 81.16
2024-08-31 17:19:42,024 [foster.py] => SNet: Task 8, Epoch 108/130 => Loss 25.812,  Loss1 0.646, Train_accy 82.40
2024-08-31 17:19:49,640 [foster.py] => SNet: Task 8, Epoch 109/130 => Loss 25.789,  Loss1 0.645, Train_accy 81.87
2024-08-31 17:19:57,200 [foster.py] => SNet: Task 8, Epoch 110/130 => Loss 25.806,  Loss1 0.646, Train_accy 82.44
2024-08-31 17:20:06,126 [foster.py] => SNet: Task 8, Epoch 111/130 => Loss 25.775,  Loss1 0.645, Train_accy 83.16, Test_accy 71.64
2024-08-31 17:20:13,473 [foster.py] => SNet: Task 8, Epoch 112/130 => Loss 25.813,  Loss1 0.645, Train_accy 82.87
2024-08-31 17:20:20,898 [foster.py] => SNet: Task 8, Epoch 113/130 => Loss 25.817,  Loss1 0.645, Train_accy 82.16
2024-08-31 17:20:28,161 [foster.py] => SNet: Task 8, Epoch 114/130 => Loss 25.806,  Loss1 0.645, Train_accy 82.11
2024-08-31 17:20:35,443 [foster.py] => SNet: Task 8, Epoch 115/130 => Loss 25.794,  Loss1 0.645, Train_accy 81.64
2024-08-31 17:20:44,719 [foster.py] => SNet: Task 8, Epoch 116/130 => Loss 25.819,  Loss1 0.646, Train_accy 82.00, Test_accy 72.11
2024-08-31 17:20:52,072 [foster.py] => SNet: Task 8, Epoch 117/130 => Loss 25.796,  Loss1 0.645, Train_accy 83.16
2024-08-31 17:20:59,373 [foster.py] => SNet: Task 8, Epoch 118/130 => Loss 25.780,  Loss1 0.645, Train_accy 81.80
2024-08-31 17:21:06,628 [foster.py] => SNet: Task 8, Epoch 119/130 => Loss 25.786,  Loss1 0.645, Train_accy 82.56
2024-08-31 17:21:14,270 [foster.py] => SNet: Task 8, Epoch 120/130 => Loss 25.795,  Loss1 0.645, Train_accy 81.82
2024-08-31 17:21:23,407 [foster.py] => SNet: Task 8, Epoch 121/130 => Loss 25.818,  Loss1 0.645, Train_accy 82.62, Test_accy 71.62
2024-08-31 17:21:31,072 [foster.py] => SNet: Task 8, Epoch 122/130 => Loss 25.806,  Loss1 0.646, Train_accy 82.47
2024-08-31 17:21:38,346 [foster.py] => SNet: Task 8, Epoch 123/130 => Loss 25.785,  Loss1 0.645, Train_accy 81.76
2024-08-31 17:21:45,818 [foster.py] => SNet: Task 8, Epoch 124/130 => Loss 25.795,  Loss1 0.646, Train_accy 81.91
2024-08-31 17:21:53,055 [foster.py] => SNet: Task 8, Epoch 125/130 => Loss 25.804,  Loss1 0.646, Train_accy 82.73
2024-08-31 17:22:02,283 [foster.py] => SNet: Task 8, Epoch 126/130 => Loss 25.798,  Loss1 0.646, Train_accy 82.76, Test_accy 71.87
2024-08-31 17:22:09,625 [foster.py] => SNet: Task 8, Epoch 127/130 => Loss 25.796,  Loss1 0.645, Train_accy 82.02
2024-08-31 17:22:17,199 [foster.py] => SNet: Task 8, Epoch 128/130 => Loss 25.840,  Loss1 0.645, Train_accy 81.38
2024-08-31 17:22:24,508 [foster.py] => SNet: Task 8, Epoch 129/130 => Loss 25.797,  Loss1 0.646, Train_accy 82.24
2024-08-31 17:22:31,876 [foster.py] => SNet: Task 8, Epoch 130/130 => Loss 25.821,  Loss1 0.645, Train_accy 81.76
2024-08-31 17:22:31,876 [foster.py] => do not weight align student!
2024-08-31 17:22:33,508 [foster.py] => darknet eval: 
2024-08-31 17:22:33,508 [foster.py] => CNN top1 curve: 71.93
2024-08-31 17:22:33,509 [foster.py] => CNN top5 curve: 93.29
2024-08-31 17:22:33,509 [foster.py] => CNN top1 平均值: 71.93
2024-08-31 17:22:33,515 [foster.py] => timees : 2200.88721036911
2024-08-31 17:22:33,516 [base.py] => Reducing exemplars...(44 per classes)
2024-08-31 17:22:47,581 [base.py] => Constructing exemplars...(44 per classes)
2024-08-31 17:22:56,665 [foster.py] => Exemplar size: 1980
2024-08-31 17:22:56,665 [trainer.py] => CNN: {'total': 73.22, '00-09': 74.7, '10-19': 60.0, '20-29': 73.8, '30-39': 77.4, '40-49': 87.2, 'old': 71.47, 'new': 87.2}
2024-08-31 17:22:56,665 [trainer.py] => NME: {'total': 70.36, '00-09': 71.6, '10-19': 58.4, '20-29': 73.6, '30-39': 71.4, '40-49': 83.2, 'old': 68.75, 'new': 83.2}
2024-08-31 17:22:56,665 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22]
2024-08-31 17:22:56,665 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6]
2024-08-31 17:22:56,665 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36]
2024-08-31 17:22:56,665 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13]

2024-08-31 17:22:56,666 [trainer.py] => CNN top1 平均值: 83.71
2024-08-31 17:22:56,668 [trainer.py] => All params: 1293878
2024-08-31 17:22:56,671 [trainer.py] => Trainable params: 650004
2024-08-31 17:22:56,733 [foster.py] => Learning on 45-50
2024-08-31 17:22:56,737 [foster.py] => All params: 1295173
2024-08-31 17:22:56,739 [foster.py] => Trainable params: 650974
2024-08-31 17:22:56,786 [foster.py] => per cls weights : [1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  1.0169164  1.0169164  1.0169164
 1.0169164  1.0169164  1.0169164  0.84775236 0.84775236 0.84775236
 0.84775236 0.84775236]
2024-08-31 17:23:02,236 [foster.py] => Task 9, Epoch 1/170 => Loss 5.091, Loss_clf 1.395, Loss_fe 1.480, Loss_kd 1.988, Train_accy 63.46
2024-08-31 17:23:09,546 [foster.py] => Task 9, Epoch 2/170 => Loss 4.046, Loss_clf 0.876, Loss_fe 0.965, Loss_kd 1.979, Train_accy 73.15, Test_accy 66.30
2024-08-31 17:23:16,810 [foster.py] => Task 9, Epoch 3/170 => Loss 3.778, Loss_clf 0.784, Loss_fe 0.827, Loss_kd 1.944, Train_accy 75.83, Test_accy 68.46
2024-08-31 17:23:24,169 [foster.py] => Task 9, Epoch 4/170 => Loss 3.731, Loss_clf 0.759, Loss_fe 0.821, Loss_kd 1.930, Train_accy 76.63, Test_accy 65.86
2024-08-31 17:23:31,658 [foster.py] => Task 9, Epoch 5/170 => Loss 3.733, Loss_clf 0.770, Loss_fe 0.796, Loss_kd 1.946, Train_accy 76.65, Test_accy 67.28
2024-08-31 17:23:37,061 [foster.py] => Task 9, Epoch 6/170 => Loss 3.742, Loss_clf 0.793, Loss_fe 0.798, Loss_kd 1.931, Train_accy 76.38
2024-08-31 17:23:44,429 [foster.py] => Task 9, Epoch 7/170 => Loss 3.713, Loss_clf 0.740, Loss_fe 0.800, Loss_kd 1.950, Train_accy 77.88, Test_accy 67.90
2024-08-31 17:23:51,878 [foster.py] => Task 9, Epoch 8/170 => Loss 3.688, Loss_clf 0.755, Loss_fe 0.759, Loss_kd 1.951, Train_accy 76.92, Test_accy 62.46
2024-08-31 17:23:59,376 [foster.py] => Task 9, Epoch 9/170 => Loss 3.736, Loss_clf 0.773, Loss_fe 0.789, Loss_kd 1.952, Train_accy 76.23, Test_accy 61.72
2024-08-31 17:24:06,862 [foster.py] => Task 9, Epoch 10/170 => Loss 3.742, Loss_clf 0.773, Loss_fe 0.796, Loss_kd 1.951, Train_accy 76.58, Test_accy 67.16
2024-08-31 17:24:12,405 [foster.py] => Task 9, Epoch 11/170 => Loss 3.745, Loss_clf 0.781, Loss_fe 0.798, Loss_kd 1.944, Train_accy 75.96
2024-08-31 17:24:19,769 [foster.py] => Task 9, Epoch 12/170 => Loss 3.728, Loss_clf 0.778, Loss_fe 0.773, Loss_kd 1.954, Train_accy 76.72, Test_accy 70.06
2024-08-31 17:24:27,154 [foster.py] => Task 9, Epoch 13/170 => Loss 3.664, Loss_clf 0.747, Loss_fe 0.756, Loss_kd 1.939, Train_accy 77.46, Test_accy 68.18
2024-08-31 17:24:34,582 [foster.py] => Task 9, Epoch 14/170 => Loss 3.747, Loss_clf 0.821, Loss_fe 0.754, Loss_kd 1.950, Train_accy 75.33, Test_accy 64.84
2024-08-31 17:24:41,931 [foster.py] => Task 9, Epoch 15/170 => Loss 3.667, Loss_clf 0.736, Loss_fe 0.739, Loss_kd 1.968, Train_accy 77.41, Test_accy 68.50
2024-08-31 17:24:47,251 [foster.py] => Task 9, Epoch 16/170 => Loss 3.666, Loss_clf 0.743, Loss_fe 0.767, Loss_kd 1.936, Train_accy 77.46
2024-08-31 17:24:54,558 [foster.py] => Task 9, Epoch 17/170 => Loss 3.728, Loss_clf 0.777, Loss_fe 0.772, Loss_kd 1.956, Train_accy 75.98, Test_accy 64.90
2024-08-31 17:25:02,041 [foster.py] => Task 9, Epoch 18/170 => Loss 3.688, Loss_clf 0.763, Loss_fe 0.763, Loss_kd 1.941, Train_accy 76.90, Test_accy 68.48
2024-08-31 17:25:09,351 [foster.py] => Task 9, Epoch 19/170 => Loss 3.702, Loss_clf 0.753, Loss_fe 0.777, Loss_kd 1.950, Train_accy 77.17, Test_accy 69.14
2024-08-31 17:25:16,702 [foster.py] => Task 9, Epoch 20/170 => Loss 3.591, Loss_clf 0.710, Loss_fe 0.713, Loss_kd 1.946, Train_accy 77.97, Test_accy 66.24
2024-08-31 17:25:22,096 [foster.py] => Task 9, Epoch 21/170 => Loss 3.670, Loss_clf 0.741, Loss_fe 0.753, Loss_kd 1.954, Train_accy 77.66
2024-08-31 17:25:29,489 [foster.py] => Task 9, Epoch 22/170 => Loss 3.693, Loss_clf 0.760, Loss_fe 0.746, Loss_kd 1.963, Train_accy 76.52, Test_accy 68.80
2024-08-31 17:25:36,881 [foster.py] => Task 9, Epoch 23/170 => Loss 3.713, Loss_clf 0.778, Loss_fe 0.765, Loss_kd 1.948, Train_accy 75.45, Test_accy 69.58
2024-08-31 17:25:44,292 [foster.py] => Task 9, Epoch 24/170 => Loss 3.647, Loss_clf 0.717, Loss_fe 0.774, Loss_kd 1.936, Train_accy 77.90, Test_accy 66.30
2024-08-31 17:25:51,651 [foster.py] => Task 9, Epoch 25/170 => Loss 3.702, Loss_clf 0.769, Loss_fe 0.761, Loss_kd 1.950, Train_accy 76.36, Test_accy 67.00
2024-08-31 17:25:56,990 [foster.py] => Task 9, Epoch 26/170 => Loss 3.680, Loss_clf 0.780, Loss_fe 0.734, Loss_kd 1.945, Train_accy 76.67
2024-08-31 17:26:04,384 [foster.py] => Task 9, Epoch 27/170 => Loss 3.701, Loss_clf 0.768, Loss_fe 0.754, Loss_kd 1.957, Train_accy 76.65, Test_accy 70.22
2024-08-31 17:26:11,835 [foster.py] => Task 9, Epoch 28/170 => Loss 3.689, Loss_clf 0.752, Loss_fe 0.762, Loss_kd 1.953, Train_accy 77.25, Test_accy 66.00
2024-08-31 17:26:19,188 [foster.py] => Task 9, Epoch 29/170 => Loss 3.649, Loss_clf 0.727, Loss_fe 0.769, Loss_kd 1.934, Train_accy 77.75, Test_accy 68.30
2024-08-31 17:26:26,564 [foster.py] => Task 9, Epoch 30/170 => Loss 3.658, Loss_clf 0.758, Loss_fe 0.745, Loss_kd 1.935, Train_accy 77.14, Test_accy 69.94
2024-08-31 17:26:31,950 [foster.py] => Task 9, Epoch 31/170 => Loss 3.722, Loss_clf 0.789, Loss_fe 0.754, Loss_kd 1.956, Train_accy 76.21
2024-08-31 17:26:39,273 [foster.py] => Task 9, Epoch 32/170 => Loss 3.691, Loss_clf 0.746, Loss_fe 0.758, Loss_kd 1.964, Train_accy 77.41, Test_accy 69.44
2024-08-31 17:26:46,644 [foster.py] => Task 9, Epoch 33/170 => Loss 3.660, Loss_clf 0.753, Loss_fe 0.732, Loss_kd 1.953, Train_accy 76.58, Test_accy 69.32
2024-08-31 17:26:53,995 [foster.py] => Task 9, Epoch 34/170 => Loss 3.528, Loss_clf 0.690, Loss_fe 0.703, Loss_kd 1.917, Train_accy 77.90, Test_accy 70.04
2024-08-31 17:27:01,404 [foster.py] => Task 9, Epoch 35/170 => Loss 3.691, Loss_clf 0.764, Loss_fe 0.741, Loss_kd 1.964, Train_accy 76.29, Test_accy 58.98
2024-08-31 17:27:06,820 [foster.py] => Task 9, Epoch 36/170 => Loss 3.669, Loss_clf 0.748, Loss_fe 0.748, Loss_kd 1.952, Train_accy 76.45
2024-08-31 17:27:14,235 [foster.py] => Task 9, Epoch 37/170 => Loss 3.599, Loss_clf 0.714, Loss_fe 0.711, Loss_kd 1.952, Train_accy 77.41, Test_accy 68.52
2024-08-31 17:27:21,605 [foster.py] => Task 9, Epoch 38/170 => Loss 3.731, Loss_clf 0.774, Loss_fe 0.777, Loss_kd 1.958, Train_accy 75.85, Test_accy 70.12
2024-08-31 17:27:28,959 [foster.py] => Task 9, Epoch 39/170 => Loss 3.593, Loss_clf 0.713, Loss_fe 0.727, Loss_kd 1.934, Train_accy 77.59, Test_accy 64.96
2024-08-31 17:27:36,263 [foster.py] => Task 9, Epoch 40/170 => Loss 3.570, Loss_clf 0.703, Loss_fe 0.704, Loss_kd 1.943, Train_accy 78.12, Test_accy 70.74
2024-08-31 17:27:41,592 [foster.py] => Task 9, Epoch 41/170 => Loss 3.599, Loss_clf 0.711, Loss_fe 0.724, Loss_kd 1.943, Train_accy 77.88
2024-08-31 17:27:49,050 [foster.py] => Task 9, Epoch 42/170 => Loss 3.590, Loss_clf 0.713, Loss_fe 0.714, Loss_kd 1.943, Train_accy 78.19, Test_accy 69.38
2024-08-31 17:27:56,395 [foster.py] => Task 9, Epoch 43/170 => Loss 3.606, Loss_clf 0.710, Loss_fe 0.736, Loss_kd 1.940, Train_accy 77.12, Test_accy 67.04
2024-08-31 17:28:03,804 [foster.py] => Task 9, Epoch 44/170 => Loss 3.589, Loss_clf 0.705, Loss_fe 0.738, Loss_kd 1.928, Train_accy 77.77, Test_accy 66.44
2024-08-31 17:28:11,200 [foster.py] => Task 9, Epoch 45/170 => Loss 3.617, Loss_clf 0.720, Loss_fe 0.717, Loss_kd 1.958, Train_accy 77.54, Test_accy 69.24
2024-08-31 17:28:16,570 [foster.py] => Task 9, Epoch 46/170 => Loss 3.573, Loss_clf 0.699, Loss_fe 0.715, Loss_kd 1.939, Train_accy 78.64
2024-08-31 17:28:23,957 [foster.py] => Task 9, Epoch 47/170 => Loss 3.609, Loss_clf 0.726, Loss_fe 0.716, Loss_kd 1.946, Train_accy 77.10, Test_accy 69.40
2024-08-31 17:28:31,284 [foster.py] => Task 9, Epoch 48/170 => Loss 3.647, Loss_clf 0.731, Loss_fe 0.730, Loss_kd 1.964, Train_accy 77.48, Test_accy 68.50
2024-08-31 17:28:38,656 [foster.py] => Task 9, Epoch 49/170 => Loss 3.558, Loss_clf 0.706, Loss_fe 0.686, Loss_kd 1.946, Train_accy 77.50, Test_accy 69.62
2024-08-31 17:28:46,022 [foster.py] => Task 9, Epoch 50/170 => Loss 3.584, Loss_clf 0.694, Loss_fe 0.719, Loss_kd 1.950, Train_accy 78.55, Test_accy 64.46
2024-08-31 17:28:51,397 [foster.py] => Task 9, Epoch 51/170 => Loss 3.606, Loss_clf 0.727, Loss_fe 0.708, Loss_kd 1.950, Train_accy 77.21
2024-08-31 17:28:58,747 [foster.py] => Task 9, Epoch 52/170 => Loss 3.578, Loss_clf 0.720, Loss_fe 0.694, Loss_kd 1.944, Train_accy 77.43, Test_accy 69.76
2024-08-31 17:29:06,049 [foster.py] => Task 9, Epoch 53/170 => Loss 3.526, Loss_clf 0.696, Loss_fe 0.666, Loss_kd 1.944, Train_accy 78.12, Test_accy 69.04
2024-08-31 17:29:13,455 [foster.py] => Task 9, Epoch 54/170 => Loss 3.531, Loss_clf 0.692, Loss_fe 0.685, Loss_kd 1.935, Train_accy 78.06, Test_accy 69.80
2024-08-31 17:29:20,791 [foster.py] => Task 9, Epoch 55/170 => Loss 3.539, Loss_clf 0.699, Loss_fe 0.688, Loss_kd 1.932, Train_accy 77.99, Test_accy 70.06
2024-08-31 17:29:26,197 [foster.py] => Task 9, Epoch 56/170 => Loss 3.539, Loss_clf 0.685, Loss_fe 0.685, Loss_kd 1.948, Train_accy 78.44
2024-08-31 17:29:33,666 [foster.py] => Task 9, Epoch 57/170 => Loss 3.512, Loss_clf 0.690, Loss_fe 0.673, Loss_kd 1.930, Train_accy 77.90, Test_accy 68.86
2024-08-31 17:29:41,048 [foster.py] => Task 9, Epoch 58/170 => Loss 3.595, Loss_clf 0.732, Loss_fe 0.690, Loss_kd 1.952, Train_accy 77.46, Test_accy 66.94
2024-08-31 17:29:48,440 [foster.py] => Task 9, Epoch 59/170 => Loss 3.515, Loss_clf 0.677, Loss_fe 0.668, Loss_kd 1.949, Train_accy 79.04, Test_accy 69.26
2024-08-31 17:29:55,780 [foster.py] => Task 9, Epoch 60/170 => Loss 3.514, Loss_clf 0.680, Loss_fe 0.655, Loss_kd 1.956, Train_accy 78.73, Test_accy 69.52
2024-08-31 17:30:01,118 [foster.py] => Task 9, Epoch 61/170 => Loss 3.556, Loss_clf 0.712, Loss_fe 0.674, Loss_kd 1.949, Train_accy 77.48
2024-08-31 17:30:08,421 [foster.py] => Task 9, Epoch 62/170 => Loss 3.584, Loss_clf 0.730, Loss_fe 0.678, Loss_kd 1.955, Train_accy 77.81, Test_accy 69.04
2024-08-31 17:30:15,746 [foster.py] => Task 9, Epoch 63/170 => Loss 3.446, Loss_clf 0.668, Loss_fe 0.628, Loss_kd 1.931, Train_accy 78.77, Test_accy 69.72
2024-08-31 17:30:23,155 [foster.py] => Task 9, Epoch 64/170 => Loss 3.505, Loss_clf 0.675, Loss_fe 0.669, Loss_kd 1.941, Train_accy 78.64, Test_accy 69.44
2024-08-31 17:30:30,529 [foster.py] => Task 9, Epoch 65/170 => Loss 3.499, Loss_clf 0.685, Loss_fe 0.650, Loss_kd 1.943, Train_accy 78.08, Test_accy 70.06
2024-08-31 17:30:35,853 [foster.py] => Task 9, Epoch 66/170 => Loss 3.465, Loss_clf 0.660, Loss_fe 0.652, Loss_kd 1.933, Train_accy 79.31
2024-08-31 17:30:43,308 [foster.py] => Task 9, Epoch 67/170 => Loss 3.492, Loss_clf 0.673, Loss_fe 0.670, Loss_kd 1.931, Train_accy 78.06, Test_accy 68.98
2024-08-31 17:30:50,893 [foster.py] => Task 9, Epoch 68/170 => Loss 3.483, Loss_clf 0.674, Loss_fe 0.642, Loss_kd 1.946, Train_accy 78.79, Test_accy 68.58
2024-08-31 17:30:58,564 [foster.py] => Task 9, Epoch 69/170 => Loss 3.458, Loss_clf 0.660, Loss_fe 0.642, Loss_kd 1.936, Train_accy 79.71, Test_accy 69.32
2024-08-31 17:31:06,160 [foster.py] => Task 9, Epoch 70/170 => Loss 3.506, Loss_clf 0.695, Loss_fe 0.632, Loss_kd 1.957, Train_accy 79.24, Test_accy 69.28
2024-08-31 17:31:11,670 [foster.py] => Task 9, Epoch 71/170 => Loss 3.504, Loss_clf 0.702, Loss_fe 0.640, Loss_kd 1.941, Train_accy 78.35
2024-08-31 17:31:19,035 [foster.py] => Task 9, Epoch 72/170 => Loss 3.476, Loss_clf 0.674, Loss_fe 0.649, Loss_kd 1.934, Train_accy 78.39, Test_accy 71.46
2024-08-31 17:31:26,340 [foster.py] => Task 9, Epoch 73/170 => Loss 3.467, Loss_clf 0.687, Loss_fe 0.620, Loss_kd 1.939, Train_accy 78.08, Test_accy 64.90
2024-08-31 17:31:33,559 [foster.py] => Task 9, Epoch 74/170 => Loss 3.521, Loss_clf 0.694, Loss_fe 0.647, Loss_kd 1.958, Train_accy 78.17, Test_accy 70.96
2024-08-31 17:31:40,802 [foster.py] => Task 9, Epoch 75/170 => Loss 3.454, Loss_clf 0.656, Loss_fe 0.645, Loss_kd 1.934, Train_accy 80.07, Test_accy 69.74
2024-08-31 17:31:46,089 [foster.py] => Task 9, Epoch 76/170 => Loss 3.456, Loss_clf 0.658, Loss_fe 0.631, Loss_kd 1.946, Train_accy 78.66
2024-08-31 17:31:53,341 [foster.py] => Task 9, Epoch 77/170 => Loss 3.435, Loss_clf 0.645, Loss_fe 0.635, Loss_kd 1.936, Train_accy 80.07, Test_accy 71.14
2024-08-31 17:32:00,625 [foster.py] => Task 9, Epoch 78/170 => Loss 3.462, Loss_clf 0.672, Loss_fe 0.605, Loss_kd 1.963, Train_accy 78.44, Test_accy 71.30
2024-08-31 17:32:07,842 [foster.py] => Task 9, Epoch 79/170 => Loss 3.482, Loss_clf 0.684, Loss_fe 0.633, Loss_kd 1.945, Train_accy 79.64, Test_accy 71.04
2024-08-31 17:32:15,093 [foster.py] => Task 9, Epoch 80/170 => Loss 3.352, Loss_clf 0.619, Loss_fe 0.572, Loss_kd 1.940, Train_accy 80.16, Test_accy 71.20
2024-08-31 17:32:20,438 [foster.py] => Task 9, Epoch 81/170 => Loss 3.422, Loss_clf 0.650, Loss_fe 0.617, Loss_kd 1.935, Train_accy 79.89
2024-08-31 17:32:27,815 [foster.py] => Task 9, Epoch 82/170 => Loss 3.427, Loss_clf 0.659, Loss_fe 0.602, Loss_kd 1.946, Train_accy 80.16, Test_accy 68.42
2024-08-31 17:32:35,084 [foster.py] => Task 9, Epoch 83/170 => Loss 3.454, Loss_clf 0.682, Loss_fe 0.608, Loss_kd 1.943, Train_accy 78.59, Test_accy 70.08
2024-08-31 17:32:42,342 [foster.py] => Task 9, Epoch 84/170 => Loss 3.375, Loss_clf 0.621, Loss_fe 0.597, Loss_kd 1.938, Train_accy 80.07, Test_accy 71.12
2024-08-31 17:32:49,586 [foster.py] => Task 9, Epoch 85/170 => Loss 3.386, Loss_clf 0.633, Loss_fe 0.593, Loss_kd 1.940, Train_accy 80.07, Test_accy 70.96
2024-08-31 17:32:54,884 [foster.py] => Task 9, Epoch 86/170 => Loss 3.378, Loss_clf 0.642, Loss_fe 0.563, Loss_kd 1.952, Train_accy 79.73
2024-08-31 17:33:02,105 [foster.py] => Task 9, Epoch 87/170 => Loss 3.394, Loss_clf 0.649, Loss_fe 0.586, Loss_kd 1.940, Train_accy 79.98, Test_accy 67.46
2024-08-31 17:33:09,331 [foster.py] => Task 9, Epoch 88/170 => Loss 3.414, Loss_clf 0.653, Loss_fe 0.593, Loss_kd 1.948, Train_accy 80.60, Test_accy 70.32
2024-08-31 17:33:16,650 [foster.py] => Task 9, Epoch 89/170 => Loss 3.453, Loss_clf 0.690, Loss_fe 0.581, Loss_kd 1.959, Train_accy 78.46, Test_accy 71.12
2024-08-31 17:33:23,900 [foster.py] => Task 9, Epoch 90/170 => Loss 3.360, Loss_clf 0.633, Loss_fe 0.564, Loss_kd 1.942, Train_accy 80.49, Test_accy 65.20
2024-08-31 17:33:29,208 [foster.py] => Task 9, Epoch 91/170 => Loss 3.330, Loss_clf 0.614, Loss_fe 0.552, Loss_kd 1.944, Train_accy 81.45
2024-08-31 17:33:36,501 [foster.py] => Task 9, Epoch 92/170 => Loss 3.391, Loss_clf 0.648, Loss_fe 0.570, Loss_kd 1.952, Train_accy 79.35, Test_accy 70.82
2024-08-31 17:33:43,743 [foster.py] => Task 9, Epoch 93/170 => Loss 3.324, Loss_clf 0.617, Loss_fe 0.549, Loss_kd 1.939, Train_accy 81.47, Test_accy 70.60
2024-08-31 17:33:50,980 [foster.py] => Task 9, Epoch 94/170 => Loss 3.333, Loss_clf 0.615, Loss_fe 0.547, Loss_kd 1.950, Train_accy 81.34, Test_accy 70.62
2024-08-31 17:33:58,252 [foster.py] => Task 9, Epoch 95/170 => Loss 3.304, Loss_clf 0.611, Loss_fe 0.540, Loss_kd 1.934, Train_accy 81.23, Test_accy 68.92
2024-08-31 17:34:03,502 [foster.py] => Task 9, Epoch 96/170 => Loss 3.341, Loss_clf 0.625, Loss_fe 0.550, Loss_kd 1.946, Train_accy 81.07
2024-08-31 17:34:10,805 [foster.py] => Task 9, Epoch 97/170 => Loss 3.309, Loss_clf 0.623, Loss_fe 0.529, Loss_kd 1.937, Train_accy 81.29, Test_accy 67.98
2024-08-31 17:34:18,139 [foster.py] => Task 9, Epoch 98/170 => Loss 3.263, Loss_clf 0.598, Loss_fe 0.516, Loss_kd 1.929, Train_accy 81.96, Test_accy 71.30
2024-08-31 17:34:25,432 [foster.py] => Task 9, Epoch 99/170 => Loss 3.354, Loss_clf 0.642, Loss_fe 0.548, Loss_kd 1.944, Train_accy 80.13, Test_accy 70.60
2024-08-31 17:34:32,689 [foster.py] => Task 9, Epoch 100/170 => Loss 3.353, Loss_clf 0.634, Loss_fe 0.545, Loss_kd 1.953, Train_accy 81.03, Test_accy 69.50
2024-08-31 17:34:38,028 [foster.py] => Task 9, Epoch 101/170 => Loss 3.335, Loss_clf 0.621, Loss_fe 0.561, Loss_kd 1.933, Train_accy 80.67
2024-08-31 17:34:45,411 [foster.py] => Task 9, Epoch 102/170 => Loss 3.279, Loss_clf 0.611, Loss_fe 0.513, Loss_kd 1.935, Train_accy 80.65, Test_accy 68.36
2024-08-31 17:34:52,718 [foster.py] => Task 9, Epoch 103/170 => Loss 3.207, Loss_clf 0.568, Loss_fe 0.490, Loss_kd 1.931, Train_accy 82.14, Test_accy 70.68
2024-08-31 17:34:59,956 [foster.py] => Task 9, Epoch 104/170 => Loss 3.233, Loss_clf 0.589, Loss_fe 0.486, Loss_kd 1.938, Train_accy 81.70, Test_accy 67.90
2024-08-31 17:35:07,231 [foster.py] => Task 9, Epoch 105/170 => Loss 3.255, Loss_clf 0.599, Loss_fe 0.495, Loss_kd 1.941, Train_accy 81.58, Test_accy 70.82
2024-08-31 17:35:12,506 [foster.py] => Task 9, Epoch 106/170 => Loss 3.256, Loss_clf 0.595, Loss_fe 0.484, Loss_kd 1.955, Train_accy 82.17
2024-08-31 17:35:19,757 [foster.py] => Task 9, Epoch 107/170 => Loss 3.235, Loss_clf 0.580, Loss_fe 0.486, Loss_kd 1.948, Train_accy 82.88, Test_accy 71.26
2024-08-31 17:35:26,989 [foster.py] => Task 9, Epoch 108/170 => Loss 3.218, Loss_clf 0.577, Loss_fe 0.483, Loss_kd 1.938, Train_accy 82.77, Test_accy 69.80
2024-08-31 17:35:34,396 [foster.py] => Task 9, Epoch 109/170 => Loss 3.228, Loss_clf 0.598, Loss_fe 0.475, Loss_kd 1.936, Train_accy 82.10, Test_accy 71.14
2024-08-31 17:35:41,698 [foster.py] => Task 9, Epoch 110/170 => Loss 3.203, Loss_clf 0.589, Loss_fe 0.465, Loss_kd 1.930, Train_accy 82.14, Test_accy 71.16
2024-08-31 17:35:47,032 [foster.py] => Task 9, Epoch 111/170 => Loss 3.189, Loss_clf 0.566, Loss_fe 0.464, Loss_kd 1.938, Train_accy 82.54
2024-08-31 17:35:54,266 [foster.py] => Task 9, Epoch 112/170 => Loss 3.173, Loss_clf 0.559, Loss_fe 0.458, Loss_kd 1.936, Train_accy 82.86, Test_accy 72.22
2024-08-31 17:36:01,571 [foster.py] => Task 9, Epoch 113/170 => Loss 3.216, Loss_clf 0.570, Loss_fe 0.477, Loss_kd 1.948, Train_accy 82.54, Test_accy 71.62
2024-08-31 17:36:08,836 [foster.py] => Task 9, Epoch 114/170 => Loss 3.168, Loss_clf 0.562, Loss_fe 0.443, Loss_kd 1.942, Train_accy 83.15, Test_accy 69.60
2024-08-31 17:36:16,059 [foster.py] => Task 9, Epoch 115/170 => Loss 3.214, Loss_clf 0.578, Loss_fe 0.469, Loss_kd 1.946, Train_accy 81.81, Test_accy 71.50
2024-08-31 17:36:21,372 [foster.py] => Task 9, Epoch 116/170 => Loss 3.146, Loss_clf 0.547, Loss_fe 0.443, Loss_kd 1.937, Train_accy 83.30
2024-08-31 17:36:28,586 [foster.py] => Task 9, Epoch 117/170 => Loss 3.161, Loss_clf 0.562, Loss_fe 0.445, Loss_kd 1.936, Train_accy 83.06, Test_accy 70.88
2024-08-31 17:36:35,909 [foster.py] => Task 9, Epoch 118/170 => Loss 3.149, Loss_clf 0.549, Loss_fe 0.434, Loss_kd 1.946, Train_accy 83.57, Test_accy 72.02
2024-08-31 17:36:43,190 [foster.py] => Task 9, Epoch 119/170 => Loss 3.136, Loss_clf 0.556, Loss_fe 0.429, Loss_kd 1.933, Train_accy 83.35, Test_accy 69.70
2024-08-31 17:36:50,413 [foster.py] => Task 9, Epoch 120/170 => Loss 3.101, Loss_clf 0.533, Loss_fe 0.421, Loss_kd 1.928, Train_accy 83.86, Test_accy 71.48
2024-08-31 17:36:55,721 [foster.py] => Task 9, Epoch 121/170 => Loss 3.146, Loss_clf 0.549, Loss_fe 0.412, Loss_kd 1.962, Train_accy 83.64
2024-08-31 17:37:02,946 [foster.py] => Task 9, Epoch 122/170 => Loss 3.083, Loss_clf 0.529, Loss_fe 0.403, Loss_kd 1.932, Train_accy 84.24, Test_accy 71.00
2024-08-31 17:37:10,152 [foster.py] => Task 9, Epoch 123/170 => Loss 3.083, Loss_clf 0.532, Loss_fe 0.391, Loss_kd 1.940, Train_accy 83.71, Test_accy 72.38
2024-08-31 17:37:17,465 [foster.py] => Task 9, Epoch 124/170 => Loss 3.092, Loss_clf 0.531, Loss_fe 0.399, Loss_kd 1.941, Train_accy 84.04, Test_accy 71.40
2024-08-31 17:37:24,747 [foster.py] => Task 9, Epoch 125/170 => Loss 3.103, Loss_clf 0.546, Loss_fe 0.403, Loss_kd 1.934, Train_accy 83.68, Test_accy 71.98
2024-08-31 17:37:30,003 [foster.py] => Task 9, Epoch 126/170 => Loss 3.055, Loss_clf 0.522, Loss_fe 0.383, Loss_kd 1.931, Train_accy 83.97
2024-08-31 17:37:37,241 [foster.py] => Task 9, Epoch 127/170 => Loss 3.072, Loss_clf 0.530, Loss_fe 0.376, Loss_kd 1.945, Train_accy 84.33, Test_accy 72.08
2024-08-31 17:37:44,470 [foster.py] => Task 9, Epoch 128/170 => Loss 3.100, Loss_clf 0.542, Loss_fe 0.393, Loss_kd 1.945, Train_accy 83.59, Test_accy 71.92
2024-08-31 17:37:51,682 [foster.py] => Task 9, Epoch 129/170 => Loss 3.045, Loss_clf 0.515, Loss_fe 0.370, Loss_kd 1.940, Train_accy 85.02, Test_accy 72.20
2024-08-31 17:37:58,924 [foster.py] => Task 9, Epoch 130/170 => Loss 2.975, Loss_clf 0.487, Loss_fe 0.344, Loss_kd 1.926, Train_accy 85.74, Test_accy 72.14
2024-08-31 17:38:04,213 [foster.py] => Task 9, Epoch 131/170 => Loss 3.019, Loss_clf 0.504, Loss_fe 0.361, Loss_kd 1.935, Train_accy 85.40
2024-08-31 17:38:11,435 [foster.py] => Task 9, Epoch 132/170 => Loss 3.030, Loss_clf 0.528, Loss_fe 0.353, Loss_kd 1.930, Train_accy 84.51, Test_accy 71.90
2024-08-31 17:38:18,693 [foster.py] => Task 9, Epoch 133/170 => Loss 3.035, Loss_clf 0.514, Loss_fe 0.355, Loss_kd 1.946, Train_accy 84.64, Test_accy 71.00
2024-08-31 17:38:26,096 [foster.py] => Task 9, Epoch 134/170 => Loss 2.990, Loss_clf 0.496, Loss_fe 0.335, Loss_kd 1.939, Train_accy 85.22, Test_accy 72.26
2024-08-31 17:38:33,316 [foster.py] => Task 9, Epoch 135/170 => Loss 2.969, Loss_clf 0.487, Loss_fe 0.332, Loss_kd 1.931, Train_accy 85.76, Test_accy 72.10
2024-08-31 17:38:38,597 [foster.py] => Task 9, Epoch 136/170 => Loss 2.993, Loss_clf 0.494, Loss_fe 0.348, Loss_kd 1.932, Train_accy 85.22
2024-08-31 17:38:45,932 [foster.py] => Task 9, Epoch 137/170 => Loss 2.959, Loss_clf 0.485, Loss_fe 0.315, Loss_kd 1.939, Train_accy 85.94, Test_accy 72.46
2024-08-31 17:38:53,248 [foster.py] => Task 9, Epoch 138/170 => Loss 2.968, Loss_clf 0.497, Loss_fe 0.318, Loss_kd 1.933, Train_accy 85.85, Test_accy 71.46
2024-08-31 17:39:00,574 [foster.py] => Task 9, Epoch 139/170 => Loss 2.989, Loss_clf 0.495, Loss_fe 0.317, Loss_kd 1.956, Train_accy 86.45, Test_accy 72.74
2024-08-31 17:39:07,804 [foster.py] => Task 9, Epoch 140/170 => Loss 2.946, Loss_clf 0.486, Loss_fe 0.311, Loss_kd 1.930, Train_accy 85.87, Test_accy 72.02
2024-08-31 17:39:13,064 [foster.py] => Task 9, Epoch 141/170 => Loss 2.995, Loss_clf 0.495, Loss_fe 0.334, Loss_kd 1.945, Train_accy 85.42
2024-08-31 17:39:20,289 [foster.py] => Task 9, Epoch 142/170 => Loss 2.940, Loss_clf 0.475, Loss_fe 0.303, Loss_kd 1.942, Train_accy 86.61, Test_accy 72.88
2024-08-31 17:39:27,554 [foster.py] => Task 9, Epoch 143/170 => Loss 2.904, Loss_clf 0.466, Loss_fe 0.287, Loss_kd 1.932, Train_accy 86.12, Test_accy 72.78
2024-08-31 17:39:34,860 [foster.py] => Task 9, Epoch 144/170 => Loss 2.921, Loss_clf 0.477, Loss_fe 0.295, Loss_kd 1.931, Train_accy 86.45, Test_accy 71.98
2024-08-31 17:39:42,161 [foster.py] => Task 9, Epoch 145/170 => Loss 2.859, Loss_clf 0.440, Loss_fe 0.272, Loss_kd 1.928, Train_accy 87.66, Test_accy 72.66
2024-08-31 17:39:47,461 [foster.py] => Task 9, Epoch 146/170 => Loss 2.902, Loss_clf 0.464, Loss_fe 0.284, Loss_kd 1.934, Train_accy 86.27
2024-08-31 17:39:54,707 [foster.py] => Task 9, Epoch 147/170 => Loss 2.907, Loss_clf 0.472, Loss_fe 0.283, Loss_kd 1.933, Train_accy 86.72, Test_accy 72.80
2024-08-31 17:40:02,069 [foster.py] => Task 9, Epoch 148/170 => Loss 2.919, Loss_clf 0.477, Loss_fe 0.280, Loss_kd 1.942, Train_accy 86.27, Test_accy 72.50
2024-08-31 17:40:09,313 [foster.py] => Task 9, Epoch 149/170 => Loss 2.922, Loss_clf 0.472, Loss_fe 0.273, Loss_kd 1.955, Train_accy 86.56, Test_accy 72.34
2024-08-31 17:40:16,528 [foster.py] => Task 9, Epoch 150/170 => Loss 2.849, Loss_clf 0.440, Loss_fe 0.263, Loss_kd 1.928, Train_accy 88.04, Test_accy 72.68
2024-08-31 17:40:21,837 [foster.py] => Task 9, Epoch 151/170 => Loss 2.854, Loss_clf 0.450, Loss_fe 0.252, Loss_kd 1.933, Train_accy 87.86
2024-08-31 17:40:29,051 [foster.py] => Task 9, Epoch 152/170 => Loss 2.881, Loss_clf 0.444, Loss_fe 0.266, Loss_kd 1.951, Train_accy 86.96, Test_accy 72.56
2024-08-31 17:40:36,301 [foster.py] => Task 9, Epoch 153/170 => Loss 2.889, Loss_clf 0.461, Loss_fe 0.256, Loss_kd 1.951, Train_accy 87.50, Test_accy 72.74
2024-08-31 17:40:43,514 [foster.py] => Task 9, Epoch 154/170 => Loss 2.860, Loss_clf 0.436, Loss_fe 0.269, Loss_kd 1.935, Train_accy 87.79, Test_accy 72.68
2024-08-31 17:40:50,766 [foster.py] => Task 9, Epoch 155/170 => Loss 2.864, Loss_clf 0.462, Loss_fe 0.235, Loss_kd 1.946, Train_accy 86.90, Test_accy 72.66
2024-08-31 17:40:56,152 [foster.py] => Task 9, Epoch 156/170 => Loss 2.833, Loss_clf 0.441, Loss_fe 0.242, Loss_kd 1.931, Train_accy 87.39
2024-08-31 17:41:03,404 [foster.py] => Task 9, Epoch 157/170 => Loss 2.848, Loss_clf 0.444, Loss_fe 0.245, Loss_kd 1.939, Train_accy 87.21, Test_accy 72.78
2024-08-31 17:41:10,643 [foster.py] => Task 9, Epoch 158/170 => Loss 2.820, Loss_clf 0.428, Loss_fe 0.223, Loss_kd 1.948, Train_accy 87.63, Test_accy 72.96
2024-08-31 17:41:17,875 [foster.py] => Task 9, Epoch 159/170 => Loss 2.803, Loss_clf 0.427, Loss_fe 0.222, Loss_kd 1.935, Train_accy 88.04, Test_accy 72.62
2024-08-31 17:41:25,094 [foster.py] => Task 9, Epoch 160/170 => Loss 2.890, Loss_clf 0.475, Loss_fe 0.252, Loss_kd 1.943, Train_accy 86.18, Test_accy 72.68
2024-08-31 17:41:30,446 [foster.py] => Task 9, Epoch 161/170 => Loss 2.834, Loss_clf 0.446, Loss_fe 0.235, Loss_kd 1.934, Train_accy 87.19
2024-08-31 17:41:37,657 [foster.py] => Task 9, Epoch 162/170 => Loss 2.826, Loss_clf 0.438, Loss_fe 0.237, Loss_kd 1.932, Train_accy 87.95, Test_accy 72.62
2024-08-31 17:41:44,962 [foster.py] => Task 9, Epoch 163/170 => Loss 2.838, Loss_clf 0.442, Loss_fe 0.238, Loss_kd 1.938, Train_accy 88.08, Test_accy 72.46
2024-08-31 17:41:52,252 [foster.py] => Task 9, Epoch 164/170 => Loss 2.842, Loss_clf 0.444, Loss_fe 0.237, Loss_kd 1.941, Train_accy 87.72, Test_accy 72.52
2024-08-31 17:41:59,511 [foster.py] => Task 9, Epoch 165/170 => Loss 2.790, Loss_clf 0.423, Loss_fe 0.229, Loss_kd 1.920, Train_accy 88.08, Test_accy 72.72
2024-08-31 17:42:04,808 [foster.py] => Task 9, Epoch 166/170 => Loss 2.782, Loss_clf 0.408, Loss_fe 0.219, Loss_kd 1.936, Train_accy 88.75
2024-08-31 17:42:12,076 [foster.py] => Task 9, Epoch 167/170 => Loss 2.825, Loss_clf 0.434, Loss_fe 0.241, Loss_kd 1.931, Train_accy 87.66, Test_accy 72.70
2024-08-31 17:42:19,390 [foster.py] => Task 9, Epoch 168/170 => Loss 2.821, Loss_clf 0.443, Loss_fe 0.225, Loss_kd 1.934, Train_accy 87.54, Test_accy 72.70
2024-08-31 17:42:26,717 [foster.py] => Task 9, Epoch 169/170 => Loss 2.786, Loss_clf 0.419, Loss_fe 0.221, Loss_kd 1.927, Train_accy 88.37, Test_accy 72.70
2024-08-31 17:42:34,093 [foster.py] => Task 9, Epoch 170/170 => Loss 2.772, Loss_clf 0.417, Loss_fe 0.210, Loss_kd 1.927, Train_accy 88.24, Test_accy 72.68
2024-08-31 17:42:34,095 [foster.py] => do not weight align teacher!
2024-08-31 17:42:34,096 [foster.py] => per cls weights : [1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871 1.03400871
 1.03400871 1.03400871 1.03400871 0.69392157 0.69392157 0.69392157
 0.69392157 0.69392157]
2024-08-31 17:42:43,084 [foster.py] => SNet: Task 9, Epoch 1/130 => Loss 26.602,  Loss1 0.665, Train_accy 55.45, Test_accy 63.18
2024-08-31 17:42:50,217 [foster.py] => SNet: Task 9, Epoch 2/130 => Loss 26.398,  Loss1 0.666, Train_accy 73.66
2024-08-31 17:42:57,807 [foster.py] => SNet: Task 9, Epoch 3/130 => Loss 26.378,  Loss1 0.665, Train_accy 76.21
2024-08-31 17:43:05,169 [foster.py] => SNet: Task 9, Epoch 4/130 => Loss 26.390,  Loss1 0.666, Train_accy 77.25
2024-08-31 17:43:12,272 [foster.py] => SNet: Task 9, Epoch 5/130 => Loss 26.341,  Loss1 0.666, Train_accy 77.01
2024-08-31 17:43:21,030 [foster.py] => SNet: Task 9, Epoch 6/130 => Loss 26.374,  Loss1 0.666, Train_accy 77.19, Test_accy 66.26
2024-08-31 17:43:28,374 [foster.py] => SNet: Task 9, Epoch 7/130 => Loss 26.378,  Loss1 0.666, Train_accy 77.52
2024-08-31 17:43:35,503 [foster.py] => SNet: Task 9, Epoch 8/130 => Loss 26.349,  Loss1 0.666, Train_accy 78.26
2024-08-31 17:43:42,561 [foster.py] => SNet: Task 9, Epoch 9/130 => Loss 26.336,  Loss1 0.666, Train_accy 78.26
2024-08-31 17:43:49,712 [foster.py] => SNet: Task 9, Epoch 10/130 => Loss 26.366,  Loss1 0.666, Train_accy 78.28
2024-08-31 17:43:58,810 [foster.py] => SNet: Task 9, Epoch 11/130 => Loss 26.331,  Loss1 0.666, Train_accy 78.93, Test_accy 68.42
2024-08-31 17:44:06,004 [foster.py] => SNet: Task 9, Epoch 12/130 => Loss 26.359,  Loss1 0.666, Train_accy 78.93
2024-08-31 17:44:13,370 [foster.py] => SNet: Task 9, Epoch 13/130 => Loss 26.353,  Loss1 0.666, Train_accy 79.78
2024-08-31 17:44:21,078 [foster.py] => SNet: Task 9, Epoch 14/130 => Loss 26.345,  Loss1 0.666, Train_accy 79.40
2024-08-31 17:44:28,357 [foster.py] => SNet: Task 9, Epoch 15/130 => Loss 26.315,  Loss1 0.666, Train_accy 79.46
2024-08-31 17:44:37,477 [foster.py] => SNet: Task 9, Epoch 16/130 => Loss 26.360,  Loss1 0.666, Train_accy 80.07, Test_accy 68.08
2024-08-31 17:44:44,620 [foster.py] => SNet: Task 9, Epoch 17/130 => Loss 26.320,  Loss1 0.666, Train_accy 80.71
2024-08-31 17:44:52,031 [foster.py] => SNet: Task 9, Epoch 18/130 => Loss 26.321,  Loss1 0.667, Train_accy 80.25
2024-08-31 17:44:59,456 [foster.py] => SNet: Task 9, Epoch 19/130 => Loss 26.361,  Loss1 0.666, Train_accy 80.62
2024-08-31 17:45:06,691 [foster.py] => SNet: Task 9, Epoch 20/130 => Loss 26.316,  Loss1 0.667, Train_accy 80.49
2024-08-31 17:45:15,725 [foster.py] => SNet: Task 9, Epoch 21/130 => Loss 26.303,  Loss1 0.666, Train_accy 80.33, Test_accy 70.04
2024-08-31 17:45:23,050 [foster.py] => SNet: Task 9, Epoch 22/130 => Loss 26.325,  Loss1 0.666, Train_accy 80.29
2024-08-31 17:45:30,354 [foster.py] => SNet: Task 9, Epoch 23/130 => Loss 26.339,  Loss1 0.666, Train_accy 80.33
2024-08-31 17:45:37,630 [foster.py] => SNet: Task 9, Epoch 24/130 => Loss 26.323,  Loss1 0.666, Train_accy 81.07
2024-08-31 17:45:44,931 [foster.py] => SNet: Task 9, Epoch 25/130 => Loss 26.344,  Loss1 0.666, Train_accy 81.34
2024-08-31 17:45:54,033 [foster.py] => SNet: Task 9, Epoch 26/130 => Loss 26.330,  Loss1 0.666, Train_accy 80.78, Test_accy 68.90
2024-08-31 17:46:01,185 [foster.py] => SNet: Task 9, Epoch 27/130 => Loss 26.314,  Loss1 0.666, Train_accy 81.81
2024-08-31 17:46:08,674 [foster.py] => SNet: Task 9, Epoch 28/130 => Loss 26.336,  Loss1 0.666, Train_accy 80.74
2024-08-31 17:46:15,697 [foster.py] => SNet: Task 9, Epoch 29/130 => Loss 26.338,  Loss1 0.666, Train_accy 81.23
2024-08-31 17:46:22,888 [foster.py] => SNet: Task 9, Epoch 30/130 => Loss 26.343,  Loss1 0.666, Train_accy 80.20
2024-08-31 17:46:31,848 [foster.py] => SNet: Task 9, Epoch 31/130 => Loss 26.313,  Loss1 0.666, Train_accy 82.10, Test_accy 70.12
2024-08-31 17:46:38,999 [foster.py] => SNet: Task 9, Epoch 32/130 => Loss 26.323,  Loss1 0.666, Train_accy 81.79
2024-08-31 17:46:46,288 [foster.py] => SNet: Task 9, Epoch 33/130 => Loss 26.310,  Loss1 0.667, Train_accy 81.21
2024-08-31 17:46:53,574 [foster.py] => SNet: Task 9, Epoch 34/130 => Loss 26.329,  Loss1 0.667, Train_accy 82.01
2024-08-31 17:47:00,631 [foster.py] => SNet: Task 9, Epoch 35/130 => Loss 26.343,  Loss1 0.666, Train_accy 81.21
2024-08-31 17:47:09,938 [foster.py] => SNet: Task 9, Epoch 36/130 => Loss 26.363,  Loss1 0.667, Train_accy 81.85, Test_accy 70.82
2024-08-31 17:47:17,196 [foster.py] => SNet: Task 9, Epoch 37/130 => Loss 26.325,  Loss1 0.666, Train_accy 81.65
2024-08-31 17:47:24,852 [foster.py] => SNet: Task 9, Epoch 38/130 => Loss 26.332,  Loss1 0.667, Train_accy 82.19
2024-08-31 17:47:32,164 [foster.py] => SNet: Task 9, Epoch 39/130 => Loss 26.318,  Loss1 0.667, Train_accy 81.70
2024-08-31 17:47:39,592 [foster.py] => SNet: Task 9, Epoch 40/130 => Loss 26.354,  Loss1 0.667, Train_accy 81.85
2024-08-31 17:47:48,799 [foster.py] => SNet: Task 9, Epoch 41/130 => Loss 26.325,  Loss1 0.666, Train_accy 82.17, Test_accy 69.76
2024-08-31 17:47:56,275 [foster.py] => SNet: Task 9, Epoch 42/130 => Loss 26.325,  Loss1 0.666, Train_accy 82.03
2024-08-31 17:48:03,391 [foster.py] => SNet: Task 9, Epoch 43/130 => Loss 26.320,  Loss1 0.666, Train_accy 81.79
2024-08-31 17:48:10,945 [foster.py] => SNet: Task 9, Epoch 44/130 => Loss 26.305,  Loss1 0.666, Train_accy 82.19
2024-08-31 17:48:18,079 [foster.py] => SNet: Task 9, Epoch 45/130 => Loss 26.343,  Loss1 0.666, Train_accy 82.41
2024-08-31 17:48:27,067 [foster.py] => SNet: Task 9, Epoch 46/130 => Loss 26.323,  Loss1 0.667, Train_accy 82.32, Test_accy 69.92
2024-08-31 17:48:34,198 [foster.py] => SNet: Task 9, Epoch 47/130 => Loss 26.317,  Loss1 0.667, Train_accy 81.88
2024-08-31 17:48:41,360 [foster.py] => SNet: Task 9, Epoch 48/130 => Loss 26.300,  Loss1 0.667, Train_accy 81.34
2024-08-31 17:48:48,739 [foster.py] => SNet: Task 9, Epoch 49/130 => Loss 26.319,  Loss1 0.667, Train_accy 83.06
2024-08-31 17:48:56,238 [foster.py] => SNet: Task 9, Epoch 50/130 => Loss 26.329,  Loss1 0.666, Train_accy 83.68
2024-08-31 17:49:04,982 [foster.py] => SNet: Task 9, Epoch 51/130 => Loss 26.322,  Loss1 0.666, Train_accy 82.43, Test_accy 70.56
2024-08-31 17:49:12,262 [foster.py] => SNet: Task 9, Epoch 52/130 => Loss 26.320,  Loss1 0.666, Train_accy 82.77
2024-08-31 17:49:19,698 [foster.py] => SNet: Task 9, Epoch 53/130 => Loss 26.318,  Loss1 0.667, Train_accy 82.54
2024-08-31 17:49:26,907 [foster.py] => SNet: Task 9, Epoch 54/130 => Loss 26.318,  Loss1 0.666, Train_accy 82.86
2024-08-31 17:49:33,928 [foster.py] => SNet: Task 9, Epoch 55/130 => Loss 26.316,  Loss1 0.667, Train_accy 82.72
2024-08-31 17:49:43,147 [foster.py] => SNet: Task 9, Epoch 56/130 => Loss 26.310,  Loss1 0.667, Train_accy 82.46, Test_accy 70.96
2024-08-31 17:49:50,342 [foster.py] => SNet: Task 9, Epoch 57/130 => Loss 26.290,  Loss1 0.667, Train_accy 83.17
2024-08-31 17:49:57,594 [foster.py] => SNet: Task 9, Epoch 58/130 => Loss 26.320,  Loss1 0.667, Train_accy 83.08
2024-08-31 17:50:04,965 [foster.py] => SNet: Task 9, Epoch 59/130 => Loss 26.308,  Loss1 0.667, Train_accy 83.15
2024-08-31 17:50:12,236 [foster.py] => SNet: Task 9, Epoch 60/130 => Loss 26.318,  Loss1 0.667, Train_accy 83.04
2024-08-31 17:50:21,507 [foster.py] => SNet: Task 9, Epoch 61/130 => Loss 26.327,  Loss1 0.667, Train_accy 82.19, Test_accy 70.14
2024-08-31 17:50:28,792 [foster.py] => SNet: Task 9, Epoch 62/130 => Loss 26.314,  Loss1 0.666, Train_accy 84.15
2024-08-31 17:50:36,082 [foster.py] => SNet: Task 9, Epoch 63/130 => Loss 26.318,  Loss1 0.667, Train_accy 83.57
2024-08-31 17:50:43,226 [foster.py] => SNet: Task 9, Epoch 64/130 => Loss 26.300,  Loss1 0.667, Train_accy 83.82
2024-08-31 17:50:50,415 [foster.py] => SNet: Task 9, Epoch 65/130 => Loss 26.317,  Loss1 0.666, Train_accy 83.66
2024-08-31 17:50:59,688 [foster.py] => SNet: Task 9, Epoch 66/130 => Loss 26.287,  Loss1 0.666, Train_accy 84.04, Test_accy 70.32
2024-08-31 17:51:07,015 [foster.py] => SNet: Task 9, Epoch 67/130 => Loss 26.312,  Loss1 0.666, Train_accy 83.97
2024-08-31 17:51:14,533 [foster.py] => SNet: Task 9, Epoch 68/130 => Loss 26.306,  Loss1 0.667, Train_accy 83.50
2024-08-31 17:51:21,602 [foster.py] => SNet: Task 9, Epoch 69/130 => Loss 26.327,  Loss1 0.666, Train_accy 82.39
2024-08-31 17:51:29,037 [foster.py] => SNet: Task 9, Epoch 70/130 => Loss 26.273,  Loss1 0.667, Train_accy 82.95
2024-08-31 17:51:38,494 [foster.py] => SNet: Task 9, Epoch 71/130 => Loss 26.312,  Loss1 0.666, Train_accy 82.95, Test_accy 71.36
2024-08-31 17:51:45,811 [foster.py] => SNet: Task 9, Epoch 72/130 => Loss 26.332,  Loss1 0.666, Train_accy 83.04
2024-08-31 17:51:53,020 [foster.py] => SNet: Task 9, Epoch 73/130 => Loss 26.310,  Loss1 0.667, Train_accy 83.73
2024-08-31 17:52:00,041 [foster.py] => SNet: Task 9, Epoch 74/130 => Loss 26.284,  Loss1 0.666, Train_accy 83.21
2024-08-31 17:52:07,526 [foster.py] => SNet: Task 9, Epoch 75/130 => Loss 26.296,  Loss1 0.666, Train_accy 82.92
2024-08-31 17:52:16,360 [foster.py] => SNet: Task 9, Epoch 76/130 => Loss 26.331,  Loss1 0.667, Train_accy 83.30, Test_accy 70.64
2024-08-31 17:52:23,477 [foster.py] => SNet: Task 9, Epoch 77/130 => Loss 26.328,  Loss1 0.666, Train_accy 83.26
2024-08-31 17:52:30,532 [foster.py] => SNet: Task 9, Epoch 78/130 => Loss 26.303,  Loss1 0.667, Train_accy 83.97
2024-08-31 17:52:37,762 [foster.py] => SNet: Task 9, Epoch 79/130 => Loss 26.323,  Loss1 0.666, Train_accy 82.83
2024-08-31 17:52:44,838 [foster.py] => SNet: Task 9, Epoch 80/130 => Loss 26.279,  Loss1 0.666, Train_accy 84.35
2024-08-31 17:52:54,289 [foster.py] => SNet: Task 9, Epoch 81/130 => Loss 26.287,  Loss1 0.667, Train_accy 83.48, Test_accy 70.58
2024-08-31 17:53:01,422 [foster.py] => SNet: Task 9, Epoch 82/130 => Loss 26.305,  Loss1 0.667, Train_accy 84.62
2024-08-31 17:53:08,655 [foster.py] => SNet: Task 9, Epoch 83/130 => Loss 26.296,  Loss1 0.666, Train_accy 84.91
2024-08-31 17:53:15,754 [foster.py] => SNet: Task 9, Epoch 84/130 => Loss 26.301,  Loss1 0.666, Train_accy 82.83
2024-08-31 17:53:22,869 [foster.py] => SNet: Task 9, Epoch 85/130 => Loss 26.298,  Loss1 0.667, Train_accy 83.75
2024-08-31 17:53:31,936 [foster.py] => SNet: Task 9, Epoch 86/130 => Loss 26.310,  Loss1 0.667, Train_accy 84.22, Test_accy 70.72
2024-08-31 17:53:39,336 [foster.py] => SNet: Task 9, Epoch 87/130 => Loss 26.307,  Loss1 0.666, Train_accy 82.88
2024-08-31 17:53:46,440 [foster.py] => SNet: Task 9, Epoch 88/130 => Loss 26.313,  Loss1 0.667, Train_accy 83.64
2024-08-31 17:53:53,787 [foster.py] => SNet: Task 9, Epoch 89/130 => Loss 26.324,  Loss1 0.667, Train_accy 83.66
2024-08-31 17:54:00,985 [foster.py] => SNet: Task 9, Epoch 90/130 => Loss 26.324,  Loss1 0.666, Train_accy 83.77
2024-08-31 17:54:10,171 [foster.py] => SNet: Task 9, Epoch 91/130 => Loss 26.296,  Loss1 0.666, Train_accy 82.81, Test_accy 71.22
2024-08-31 17:54:17,450 [foster.py] => SNet: Task 9, Epoch 92/130 => Loss 26.314,  Loss1 0.667, Train_accy 83.57
2024-08-31 17:54:24,608 [foster.py] => SNet: Task 9, Epoch 93/130 => Loss 26.319,  Loss1 0.666, Train_accy 84.26
2024-08-31 17:54:31,900 [foster.py] => SNet: Task 9, Epoch 94/130 => Loss 26.314,  Loss1 0.666, Train_accy 83.42
2024-08-31 17:54:39,328 [foster.py] => SNet: Task 9, Epoch 95/130 => Loss 26.312,  Loss1 0.666, Train_accy 82.92
2024-08-31 17:54:48,514 [foster.py] => SNet: Task 9, Epoch 96/130 => Loss 26.324,  Loss1 0.666, Train_accy 82.32, Test_accy 70.78
2024-08-31 17:54:55,636 [foster.py] => SNet: Task 9, Epoch 97/130 => Loss 26.344,  Loss1 0.667, Train_accy 83.66
2024-08-31 17:55:02,800 [foster.py] => SNet: Task 9, Epoch 98/130 => Loss 26.323,  Loss1 0.667, Train_accy 83.79
2024-08-31 17:55:10,500 [foster.py] => SNet: Task 9, Epoch 99/130 => Loss 26.313,  Loss1 0.667, Train_accy 83.91
2024-08-31 17:55:17,813 [foster.py] => SNet: Task 9, Epoch 100/130 => Loss 26.335,  Loss1 0.667, Train_accy 83.35
2024-08-31 17:55:26,598 [foster.py] => SNet: Task 9, Epoch 101/130 => Loss 26.353,  Loss1 0.667, Train_accy 83.88, Test_accy 70.52
2024-08-31 17:55:34,124 [foster.py] => SNet: Task 9, Epoch 102/130 => Loss 26.298,  Loss1 0.667, Train_accy 83.88
2024-08-31 17:55:41,327 [foster.py] => SNet: Task 9, Epoch 103/130 => Loss 26.323,  Loss1 0.666, Train_accy 84.60
2024-08-31 17:55:48,434 [foster.py] => SNet: Task 9, Epoch 104/130 => Loss 26.315,  Loss1 0.667, Train_accy 84.38
2024-08-31 17:55:55,722 [foster.py] => SNet: Task 9, Epoch 105/130 => Loss 26.299,  Loss1 0.666, Train_accy 84.40
2024-08-31 17:56:05,018 [foster.py] => SNet: Task 9, Epoch 106/130 => Loss 26.299,  Loss1 0.667, Train_accy 83.82, Test_accy 70.86
2024-08-31 17:56:12,149 [foster.py] => SNet: Task 9, Epoch 107/130 => Loss 26.281,  Loss1 0.667, Train_accy 84.29
2024-08-31 17:56:19,493 [foster.py] => SNet: Task 9, Epoch 108/130 => Loss 26.301,  Loss1 0.666, Train_accy 84.02
2024-08-31 17:56:26,796 [foster.py] => SNet: Task 9, Epoch 109/130 => Loss 26.287,  Loss1 0.667, Train_accy 84.08
2024-08-31 17:56:34,309 [foster.py] => SNet: Task 9, Epoch 110/130 => Loss 26.278,  Loss1 0.667, Train_accy 84.80
2024-08-31 17:56:43,200 [foster.py] => SNet: Task 9, Epoch 111/130 => Loss 26.307,  Loss1 0.667, Train_accy 84.26, Test_accy 71.02
2024-08-31 17:56:50,359 [foster.py] => SNet: Task 9, Epoch 112/130 => Loss 26.338,  Loss1 0.667, Train_accy 83.93
2024-08-31 17:56:57,763 [foster.py] => SNet: Task 9, Epoch 113/130 => Loss 26.322,  Loss1 0.667, Train_accy 83.53
2024-08-31 17:57:04,896 [foster.py] => SNet: Task 9, Epoch 114/130 => Loss 26.328,  Loss1 0.666, Train_accy 83.64
2024-08-31 17:57:12,678 [foster.py] => SNet: Task 9, Epoch 115/130 => Loss 26.293,  Loss1 0.666, Train_accy 83.79
2024-08-31 17:57:21,491 [foster.py] => SNet: Task 9, Epoch 116/130 => Loss 26.311,  Loss1 0.667, Train_accy 84.33, Test_accy 71.04
2024-08-31 17:57:28,547 [foster.py] => SNet: Task 9, Epoch 117/130 => Loss 26.326,  Loss1 0.667, Train_accy 83.19
2024-08-31 17:57:36,085 [foster.py] => SNet: Task 9, Epoch 118/130 => Loss 26.289,  Loss1 0.666, Train_accy 84.00
2024-08-31 17:57:43,405 [foster.py] => SNet: Task 9, Epoch 119/130 => Loss 26.295,  Loss1 0.666, Train_accy 84.62
2024-08-31 17:57:50,467 [foster.py] => SNet: Task 9, Epoch 120/130 => Loss 26.322,  Loss1 0.666, Train_accy 83.24
2024-08-31 17:57:59,642 [foster.py] => SNet: Task 9, Epoch 121/130 => Loss 26.320,  Loss1 0.667, Train_accy 83.35, Test_accy 71.02
2024-08-31 17:58:06,704 [foster.py] => SNet: Task 9, Epoch 122/130 => Loss 26.310,  Loss1 0.667, Train_accy 83.86
2024-08-31 17:58:13,993 [foster.py] => SNet: Task 9, Epoch 123/130 => Loss 26.273,  Loss1 0.667, Train_accy 84.44
2024-08-31 17:58:21,242 [foster.py] => SNet: Task 9, Epoch 124/130 => Loss 26.304,  Loss1 0.666, Train_accy 84.73
2024-08-31 17:58:29,127 [foster.py] => SNet: Task 9, Epoch 125/130 => Loss 26.318,  Loss1 0.667, Train_accy 83.46
2024-08-31 17:58:38,352 [foster.py] => SNet: Task 9, Epoch 126/130 => Loss 26.299,  Loss1 0.666, Train_accy 85.04, Test_accy 71.12
2024-08-31 17:58:45,563 [foster.py] => SNet: Task 9, Epoch 127/130 => Loss 26.298,  Loss1 0.667, Train_accy 84.38
2024-08-31 17:58:53,084 [foster.py] => SNet: Task 9, Epoch 128/130 => Loss 26.328,  Loss1 0.667, Train_accy 84.58
2024-08-31 17:59:00,359 [foster.py] => SNet: Task 9, Epoch 129/130 => Loss 26.319,  Loss1 0.667, Train_accy 82.86
2024-08-31 17:59:07,511 [foster.py] => SNet: Task 9, Epoch 130/130 => Loss 26.314,  Loss1 0.667, Train_accy 83.73
2024-08-31 17:59:07,511 [foster.py] => do not weight align student!
2024-08-31 17:59:09,224 [foster.py] => darknet eval: 
2024-08-31 17:59:09,224 [foster.py] => CNN top1 curve: 71.0
2024-08-31 17:59:09,224 [foster.py] => CNN top5 curve: 92.84
2024-08-31 17:59:09,224 [foster.py] => CNN top1 平均值: 71.00
2024-08-31 17:59:09,227 [foster.py] => timees : 2172.4600183963776
2024-08-31 17:59:09,228 [base.py] => Reducing exemplars...(40 per classes)
2024-08-31 17:59:24,780 [base.py] => Constructing exemplars...(40 per classes)
2024-08-31 17:59:33,965 [foster.py] => Exemplar size: 2000
2024-08-31 17:59:33,966 [trainer.py] => CNN: {'total': 72.68, '00-09': 75.3, '10-19': 58.5, '20-29': 71.4, '30-39': 74.4, '40-49': 83.8, 'old': 71.09, 'new': 87.0}
2024-08-31 17:59:33,966 [trainer.py] => NME: {'total': 68.62, '00-09': 69.6, '10-19': 58.2, '20-29': 69.3, '30-39': 71.4, '40-49': 74.6, 'old': 66.71, 'new': 85.8}
2024-08-31 17:59:33,966 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68]
2024-08-31 17:59:33,966 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28]
2024-08-31 17:59:33,966 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62]
2024-08-31 17:59:33,966 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94]

2024-08-31 17:59:33,966 [trainer.py] => CNN top1 平均值: 82.61
2024-08-31 17:59:33,969 [trainer.py] => All params: 1295173
2024-08-31 17:59:33,971 [trainer.py] => Trainable params: 650974
2024-08-31 17:59:34,034 [foster.py] => Learning on 50-55
2024-08-31 17:59:34,038 [foster.py] => All params: 1296468
2024-08-31 17:59:34,040 [foster.py] => Trainable params: 651944
2024-08-31 17:59:34,089 [foster.py] => per cls weights : [1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352 1.01715352
 1.01715352 1.01715352 0.82846484 0.82846484 0.82846484 0.82846484
 0.82846484]
2024-08-31 17:59:39,495 [foster.py] => Task 10, Epoch 1/170 => Loss 5.843, Loss_clf 1.777, Loss_fe 1.674, Loss_kd 2.169, Train_accy 60.11
2024-08-31 17:59:47,023 [foster.py] => Task 10, Epoch 2/170 => Loss 4.453, Loss_clf 0.973, Loss_fe 1.096, Loss_kd 2.160, Train_accy 71.27, Test_accy 64.00
2024-08-31 17:59:54,502 [foster.py] => Task 10, Epoch 3/170 => Loss 4.257, Loss_clf 0.899, Loss_fe 0.987, Loss_kd 2.149, Train_accy 72.44, Test_accy 67.38
2024-08-31 18:00:01,917 [foster.py] => Task 10, Epoch 4/170 => Loss 4.223, Loss_clf 0.919, Loss_fe 0.950, Loss_kd 2.134, Train_accy 71.96, Test_accy 62.78
2024-08-31 18:00:09,255 [foster.py] => Task 10, Epoch 5/170 => Loss 4.089, Loss_clf 0.856, Loss_fe 0.892, Loss_kd 2.122, Train_accy 73.73, Test_accy 68.25
2024-08-31 18:00:14,675 [foster.py] => Task 10, Epoch 6/170 => Loss 4.154, Loss_clf 0.898, Loss_fe 0.880, Loss_kd 2.154, Train_accy 73.29
2024-08-31 18:00:22,151 [foster.py] => Task 10, Epoch 7/170 => Loss 4.165, Loss_clf 0.904, Loss_fe 0.891, Loss_kd 2.149, Train_accy 71.87, Test_accy 64.16
2024-08-31 18:00:29,635 [foster.py] => Task 10, Epoch 8/170 => Loss 4.135, Loss_clf 0.902, Loss_fe 0.875, Loss_kd 2.138, Train_accy 72.58, Test_accy 63.40
2024-08-31 18:00:37,103 [foster.py] => Task 10, Epoch 9/170 => Loss 4.276, Loss_clf 0.950, Loss_fe 0.961, Loss_kd 2.145, Train_accy 72.07, Test_accy 63.76
2024-08-31 18:00:44,427 [foster.py] => Task 10, Epoch 10/170 => Loss 4.166, Loss_clf 0.872, Loss_fe 0.915, Loss_kd 2.157, Train_accy 73.44, Test_accy 64.60
2024-08-31 18:00:49,840 [foster.py] => Task 10, Epoch 11/170 => Loss 4.085, Loss_clf 0.854, Loss_fe 0.872, Loss_kd 2.139, Train_accy 73.73
2024-08-31 18:00:57,314 [foster.py] => Task 10, Epoch 12/170 => Loss 4.051, Loss_clf 0.846, Loss_fe 0.853, Loss_kd 2.133, Train_accy 73.69, Test_accy 65.13
2024-08-31 18:01:04,728 [foster.py] => Task 10, Epoch 13/170 => Loss 4.136, Loss_clf 0.899, Loss_fe 0.877, Loss_kd 2.140, Train_accy 73.02, Test_accy 65.73
2024-08-31 18:01:12,104 [foster.py] => Task 10, Epoch 14/170 => Loss 4.066, Loss_clf 0.867, Loss_fe 0.850, Loss_kd 2.131, Train_accy 73.07, Test_accy 62.73
2024-08-31 18:01:19,532 [foster.py] => Task 10, Epoch 15/170 => Loss 3.988, Loss_clf 0.817, Loss_fe 0.812, Loss_kd 2.140, Train_accy 74.47, Test_accy 67.85
2024-08-31 18:01:24,881 [foster.py] => Task 10, Epoch 16/170 => Loss 3.988, Loss_clf 0.798, Loss_fe 0.825, Loss_kd 2.145, Train_accy 75.22
2024-08-31 18:01:32,375 [foster.py] => Task 10, Epoch 17/170 => Loss 4.056, Loss_clf 0.826, Loss_fe 0.854, Loss_kd 2.156, Train_accy 74.60, Test_accy 65.96
2024-08-31 18:01:39,774 [foster.py] => Task 10, Epoch 18/170 => Loss 4.218, Loss_clf 0.875, Loss_fe 0.959, Loss_kd 2.163, Train_accy 72.89, Test_accy 62.49
2024-08-31 18:01:47,228 [foster.py] => Task 10, Epoch 19/170 => Loss 4.076, Loss_clf 0.809, Loss_fe 0.901, Loss_kd 2.146, Train_accy 74.18, Test_accy 66.22
2024-08-31 18:01:54,638 [foster.py] => Task 10, Epoch 20/170 => Loss 4.000, Loss_clf 0.802, Loss_fe 0.822, Loss_kd 2.155, Train_accy 75.56, Test_accy 67.67
2024-08-31 18:02:00,039 [foster.py] => Task 10, Epoch 21/170 => Loss 3.974, Loss_clf 0.801, Loss_fe 0.828, Loss_kd 2.127, Train_accy 74.78
2024-08-31 18:02:07,512 [foster.py] => Task 10, Epoch 22/170 => Loss 4.146, Loss_clf 0.914, Loss_fe 0.873, Loss_kd 2.141, Train_accy 72.78, Test_accy 65.56
2024-08-31 18:02:14,949 [foster.py] => Task 10, Epoch 23/170 => Loss 3.981, Loss_clf 0.796, Loss_fe 0.826, Loss_kd 2.139, Train_accy 75.20, Test_accy 64.16
2024-08-31 18:02:22,470 [foster.py] => Task 10, Epoch 24/170 => Loss 4.022, Loss_clf 0.820, Loss_fe 0.848, Loss_kd 2.136, Train_accy 74.93, Test_accy 68.95
2024-08-31 18:02:29,919 [foster.py] => Task 10, Epoch 25/170 => Loss 3.955, Loss_clf 0.784, Loss_fe 0.807, Loss_kd 2.144, Train_accy 74.62, Test_accy 67.49
2024-08-31 18:02:35,314 [foster.py] => Task 10, Epoch 26/170 => Loss 4.032, Loss_clf 0.845, Loss_fe 0.826, Loss_kd 2.142, Train_accy 74.22
2024-08-31 18:02:42,664 [foster.py] => Task 10, Epoch 27/170 => Loss 4.006, Loss_clf 0.800, Loss_fe 0.858, Loss_kd 2.130, Train_accy 74.87, Test_accy 64.29
2024-08-31 18:02:50,155 [foster.py] => Task 10, Epoch 28/170 => Loss 4.145, Loss_clf 0.884, Loss_fe 0.890, Loss_kd 2.151, Train_accy 71.76, Test_accy 65.64
2024-08-31 18:02:57,589 [foster.py] => Task 10, Epoch 29/170 => Loss 4.048, Loss_clf 0.849, Loss_fe 0.821, Loss_kd 2.158, Train_accy 74.36, Test_accy 63.18
2024-08-31 18:03:05,005 [foster.py] => Task 10, Epoch 30/170 => Loss 3.999, Loss_clf 0.804, Loss_fe 0.826, Loss_kd 2.149, Train_accy 74.96, Test_accy 68.05
2024-08-31 18:03:10,291 [foster.py] => Task 10, Epoch 31/170 => Loss 4.046, Loss_clf 0.826, Loss_fe 0.866, Loss_kd 2.135, Train_accy 73.73
2024-08-31 18:03:17,670 [foster.py] => Task 10, Epoch 32/170 => Loss 3.989, Loss_clf 0.807, Loss_fe 0.830, Loss_kd 2.134, Train_accy 74.49, Test_accy 67.58
2024-08-31 18:03:25,055 [foster.py] => Task 10, Epoch 33/170 => Loss 3.975, Loss_clf 0.812, Loss_fe 0.813, Loss_kd 2.132, Train_accy 75.36, Test_accy 67.51
2024-08-31 18:03:32,406 [foster.py] => Task 10, Epoch 34/170 => Loss 3.968, Loss_clf 0.792, Loss_fe 0.841, Loss_kd 2.117, Train_accy 74.36, Test_accy 68.36
2024-08-31 18:03:39,825 [foster.py] => Task 10, Epoch 35/170 => Loss 3.974, Loss_clf 0.802, Loss_fe 0.803, Loss_kd 2.149, Train_accy 74.02, Test_accy 63.55
2024-08-31 18:03:45,176 [foster.py] => Task 10, Epoch 36/170 => Loss 4.035, Loss_clf 0.843, Loss_fe 0.830, Loss_kd 2.143, Train_accy 74.18
2024-08-31 18:03:52,679 [foster.py] => Task 10, Epoch 37/170 => Loss 4.062, Loss_clf 0.847, Loss_fe 0.840, Loss_kd 2.154, Train_accy 72.53, Test_accy 65.60
2024-08-31 18:04:00,057 [foster.py] => Task 10, Epoch 38/170 => Loss 4.039, Loss_clf 0.817, Loss_fe 0.852, Loss_kd 2.149, Train_accy 74.38, Test_accy 51.51
2024-08-31 18:04:07,370 [foster.py] => Task 10, Epoch 39/170 => Loss 4.039, Loss_clf 0.860, Loss_fe 0.823, Loss_kd 2.138, Train_accy 73.40, Test_accy 66.85
2024-08-31 18:04:14,719 [foster.py] => Task 10, Epoch 40/170 => Loss 3.892, Loss_clf 0.753, Loss_fe 0.796, Loss_kd 2.126, Train_accy 76.02, Test_accy 66.29
2024-08-31 18:04:20,101 [foster.py] => Task 10, Epoch 41/170 => Loss 4.064, Loss_clf 0.867, Loss_fe 0.819, Loss_kd 2.157, Train_accy 72.56
2024-08-31 18:04:27,536 [foster.py] => Task 10, Epoch 42/170 => Loss 4.025, Loss_clf 0.846, Loss_fe 0.802, Loss_kd 2.156, Train_accy 74.31, Test_accy 67.82
2024-08-31 18:04:34,948 [foster.py] => Task 10, Epoch 43/170 => Loss 4.007, Loss_clf 0.803, Loss_fe 0.851, Loss_kd 2.135, Train_accy 73.80, Test_accy 65.04
2024-08-31 18:04:42,374 [foster.py] => Task 10, Epoch 44/170 => Loss 3.992, Loss_clf 0.793, Loss_fe 0.845, Loss_kd 2.136, Train_accy 74.62, Test_accy 66.29
2024-08-31 18:04:49,924 [foster.py] => Task 10, Epoch 45/170 => Loss 3.960, Loss_clf 0.820, Loss_fe 0.780, Loss_kd 2.142, Train_accy 74.42, Test_accy 68.38
2024-08-31 18:04:55,290 [foster.py] => Task 10, Epoch 46/170 => Loss 4.049, Loss_clf 0.842, Loss_fe 0.814, Loss_kd 2.171, Train_accy 73.22
2024-08-31 18:05:02,692 [foster.py] => Task 10, Epoch 47/170 => Loss 3.980, Loss_clf 0.805, Loss_fe 0.811, Loss_kd 2.145, Train_accy 74.40, Test_accy 68.20
2024-08-31 18:05:10,103 [foster.py] => Task 10, Epoch 48/170 => Loss 3.871, Loss_clf 0.748, Loss_fe 0.766, Loss_kd 2.138, Train_accy 76.04, Test_accy 67.35
2024-08-31 18:05:17,531 [foster.py] => Task 10, Epoch 49/170 => Loss 3.984, Loss_clf 0.812, Loss_fe 0.809, Loss_kd 2.144, Train_accy 73.78, Test_accy 65.13
2024-08-31 18:05:25,098 [foster.py] => Task 10, Epoch 50/170 => Loss 3.959, Loss_clf 0.805, Loss_fe 0.806, Loss_kd 2.130, Train_accy 73.44, Test_accy 66.53
2024-08-31 18:05:30,432 [foster.py] => Task 10, Epoch 51/170 => Loss 4.016, Loss_clf 0.854, Loss_fe 0.799, Loss_kd 2.144, Train_accy 73.56
2024-08-31 18:05:37,819 [foster.py] => Task 10, Epoch 52/170 => Loss 3.934, Loss_clf 0.798, Loss_fe 0.780, Loss_kd 2.137, Train_accy 74.87, Test_accy 68.58
2024-08-31 18:05:45,165 [foster.py] => Task 10, Epoch 53/170 => Loss 3.937, Loss_clf 0.780, Loss_fe 0.799, Loss_kd 2.140, Train_accy 75.60, Test_accy 67.49
2024-08-31 18:05:52,631 [foster.py] => Task 10, Epoch 54/170 => Loss 3.912, Loss_clf 0.772, Loss_fe 0.784, Loss_kd 2.137, Train_accy 75.69, Test_accy 67.95
2024-08-31 18:05:59,991 [foster.py] => Task 10, Epoch 55/170 => Loss 3.898, Loss_clf 0.800, Loss_fe 0.740, Loss_kd 2.139, Train_accy 74.33, Test_accy 66.62
2024-08-31 18:06:05,352 [foster.py] => Task 10, Epoch 56/170 => Loss 3.957, Loss_clf 0.795, Loss_fe 0.782, Loss_kd 2.159, Train_accy 75.24
2024-08-31 18:06:12,838 [foster.py] => Task 10, Epoch 57/170 => Loss 3.931, Loss_clf 0.780, Loss_fe 0.784, Loss_kd 2.148, Train_accy 75.09, Test_accy 68.20
2024-08-31 18:06:20,169 [foster.py] => Task 10, Epoch 58/170 => Loss 3.871, Loss_clf 0.747, Loss_fe 0.766, Loss_kd 2.140, Train_accy 76.58, Test_accy 67.89
2024-08-31 18:06:27,564 [foster.py] => Task 10, Epoch 59/170 => Loss 3.862, Loss_clf 0.759, Loss_fe 0.760, Loss_kd 2.126, Train_accy 74.84, Test_accy 68.42
2024-08-31 18:06:34,945 [foster.py] => Task 10, Epoch 60/170 => Loss 3.865, Loss_clf 0.758, Loss_fe 0.765, Loss_kd 2.125, Train_accy 75.02, Test_accy 66.53
2024-08-31 18:06:40,314 [foster.py] => Task 10, Epoch 61/170 => Loss 3.924, Loss_clf 0.798, Loss_fe 0.753, Loss_kd 2.154, Train_accy 75.04
2024-08-31 18:06:47,725 [foster.py] => Task 10, Epoch 62/170 => Loss 3.869, Loss_clf 0.768, Loss_fe 0.750, Loss_kd 2.133, Train_accy 75.73, Test_accy 69.56
2024-08-31 18:06:55,169 [foster.py] => Task 10, Epoch 63/170 => Loss 3.917, Loss_clf 0.783, Loss_fe 0.765, Loss_kd 2.150, Train_accy 75.71, Test_accy 67.55
2024-08-31 18:07:02,598 [foster.py] => Task 10, Epoch 64/170 => Loss 3.894, Loss_clf 0.782, Loss_fe 0.771, Loss_kd 2.124, Train_accy 74.02, Test_accy 67.42
2024-08-31 18:07:09,984 [foster.py] => Task 10, Epoch 65/170 => Loss 3.851, Loss_clf 0.754, Loss_fe 0.731, Loss_kd 2.147, Train_accy 76.16, Test_accy 66.09
2024-08-31 18:07:15,332 [foster.py] => Task 10, Epoch 66/170 => Loss 3.954, Loss_clf 0.814, Loss_fe 0.768, Loss_kd 2.152, Train_accy 74.96
2024-08-31 18:07:22,747 [foster.py] => Task 10, Epoch 67/170 => Loss 3.848, Loss_clf 0.771, Loss_fe 0.720, Loss_kd 2.138, Train_accy 74.51, Test_accy 65.71
2024-08-31 18:07:30,196 [foster.py] => Task 10, Epoch 68/170 => Loss 3.939, Loss_clf 0.805, Loss_fe 0.771, Loss_kd 2.143, Train_accy 74.42, Test_accy 66.31
2024-08-31 18:07:37,609 [foster.py] => Task 10, Epoch 69/170 => Loss 3.773, Loss_clf 0.714, Loss_fe 0.718, Loss_kd 2.124, Train_accy 76.33, Test_accy 68.67
2024-08-31 18:07:45,032 [foster.py] => Task 10, Epoch 70/170 => Loss 3.796, Loss_clf 0.727, Loss_fe 0.720, Loss_kd 2.131, Train_accy 76.47, Test_accy 65.42
2024-08-31 18:07:50,366 [foster.py] => Task 10, Epoch 71/170 => Loss 3.809, Loss_clf 0.742, Loss_fe 0.717, Loss_kd 2.132, Train_accy 75.93
2024-08-31 18:07:57,782 [foster.py] => Task 10, Epoch 72/170 => Loss 3.825, Loss_clf 0.735, Loss_fe 0.746, Loss_kd 2.126, Train_accy 75.87, Test_accy 68.69
2024-08-31 18:08:05,213 [foster.py] => Task 10, Epoch 73/170 => Loss 3.845, Loss_clf 0.745, Loss_fe 0.747, Loss_kd 2.135, Train_accy 76.76, Test_accy 68.67
2024-08-31 18:08:12,673 [foster.py] => Task 10, Epoch 74/170 => Loss 3.797, Loss_clf 0.712, Loss_fe 0.719, Loss_kd 2.147, Train_accy 76.82, Test_accy 65.80
2024-08-31 18:08:20,183 [foster.py] => Task 10, Epoch 75/170 => Loss 3.771, Loss_clf 0.725, Loss_fe 0.696, Loss_kd 2.132, Train_accy 76.29, Test_accy 67.71
2024-08-31 18:08:25,541 [foster.py] => Task 10, Epoch 76/170 => Loss 3.794, Loss_clf 0.726, Loss_fe 0.704, Loss_kd 2.145, Train_accy 76.71
2024-08-31 18:08:33,020 [foster.py] => Task 10, Epoch 77/170 => Loss 3.744, Loss_clf 0.706, Loss_fe 0.689, Loss_kd 2.132, Train_accy 76.98, Test_accy 65.18
2024-08-31 18:08:40,483 [foster.py] => Task 10, Epoch 78/170 => Loss 3.802, Loss_clf 0.762, Loss_fe 0.692, Loss_kd 2.130, Train_accy 75.91, Test_accy 68.00
2024-08-31 18:08:47,974 [foster.py] => Task 10, Epoch 79/170 => Loss 3.765, Loss_clf 0.752, Loss_fe 0.679, Loss_kd 2.117, Train_accy 76.20, Test_accy 67.89
2024-08-31 18:08:55,457 [foster.py] => Task 10, Epoch 80/170 => Loss 3.737, Loss_clf 0.707, Loss_fe 0.677, Loss_kd 2.135, Train_accy 77.09, Test_accy 67.11
2024-08-31 18:09:00,846 [foster.py] => Task 10, Epoch 81/170 => Loss 3.792, Loss_clf 0.734, Loss_fe 0.702, Loss_kd 2.138, Train_accy 77.31
2024-08-31 18:09:08,196 [foster.py] => Task 10, Epoch 82/170 => Loss 3.832, Loss_clf 0.761, Loss_fe 0.708, Loss_kd 2.144, Train_accy 75.80, Test_accy 66.09
2024-08-31 18:09:15,598 [foster.py] => Task 10, Epoch 83/170 => Loss 3.797, Loss_clf 0.747, Loss_fe 0.700, Loss_kd 2.133, Train_accy 76.89, Test_accy 68.04
2024-08-31 18:09:22,992 [foster.py] => Task 10, Epoch 84/170 => Loss 3.740, Loss_clf 0.713, Loss_fe 0.668, Loss_kd 2.140, Train_accy 76.87, Test_accy 66.91
2024-08-31 18:09:30,417 [foster.py] => Task 10, Epoch 85/170 => Loss 3.679, Loss_clf 0.698, Loss_fe 0.635, Loss_kd 2.129, Train_accy 77.49, Test_accy 69.40
2024-08-31 18:09:35,819 [foster.py] => Task 10, Epoch 86/170 => Loss 3.770, Loss_clf 0.706, Loss_fe 0.693, Loss_kd 2.151, Train_accy 77.11
2024-08-31 18:09:43,231 [foster.py] => Task 10, Epoch 87/170 => Loss 3.752, Loss_clf 0.717, Loss_fe 0.681, Loss_kd 2.135, Train_accy 76.84, Test_accy 68.20
2024-08-31 18:09:50,661 [foster.py] => Task 10, Epoch 88/170 => Loss 3.793, Loss_clf 0.725, Loss_fe 0.688, Loss_kd 2.158, Train_accy 76.47, Test_accy 67.76
2024-08-31 18:09:58,120 [foster.py] => Task 10, Epoch 89/170 => Loss 3.773, Loss_clf 0.743, Loss_fe 0.672, Loss_kd 2.139, Train_accy 76.60, Test_accy 68.20
2024-08-31 18:10:05,628 [foster.py] => Task 10, Epoch 90/170 => Loss 3.680, Loss_clf 0.708, Loss_fe 0.631, Loss_kd 2.124, Train_accy 77.78, Test_accy 69.31
2024-08-31 18:10:10,998 [foster.py] => Task 10, Epoch 91/170 => Loss 3.744, Loss_clf 0.723, Loss_fe 0.660, Loss_kd 2.141, Train_accy 77.73
2024-08-31 18:10:18,422 [foster.py] => Task 10, Epoch 92/170 => Loss 3.730, Loss_clf 0.717, Loss_fe 0.660, Loss_kd 2.135, Train_accy 77.27, Test_accy 68.49
2024-08-31 18:10:25,802 [foster.py] => Task 10, Epoch 93/170 => Loss 3.691, Loss_clf 0.698, Loss_fe 0.633, Loss_kd 2.141, Train_accy 77.82, Test_accy 68.58
2024-08-31 18:10:33,237 [foster.py] => Task 10, Epoch 94/170 => Loss 3.657, Loss_clf 0.683, Loss_fe 0.628, Loss_kd 2.128, Train_accy 78.53, Test_accy 69.45
2024-08-31 18:10:40,646 [foster.py] => Task 10, Epoch 95/170 => Loss 3.617, Loss_clf 0.671, Loss_fe 0.598, Loss_kd 2.130, Train_accy 78.18, Test_accy 68.15
2024-08-31 18:10:46,072 [foster.py] => Task 10, Epoch 96/170 => Loss 3.674, Loss_clf 0.700, Loss_fe 0.613, Loss_kd 2.142, Train_accy 77.96
2024-08-31 18:10:53,398 [foster.py] => Task 10, Epoch 97/170 => Loss 3.762, Loss_clf 0.753, Loss_fe 0.648, Loss_kd 2.142, Train_accy 77.13, Test_accy 69.53
2024-08-31 18:11:00,850 [foster.py] => Task 10, Epoch 98/170 => Loss 3.657, Loss_clf 0.683, Loss_fe 0.627, Loss_kd 2.128, Train_accy 78.24, Test_accy 68.55
2024-08-31 18:11:08,261 [foster.py] => Task 10, Epoch 99/170 => Loss 3.600, Loss_clf 0.665, Loss_fe 0.598, Loss_kd 2.121, Train_accy 78.64, Test_accy 68.31
2024-08-31 18:11:15,710 [foster.py] => Task 10, Epoch 100/170 => Loss 3.579, Loss_clf 0.634, Loss_fe 0.599, Loss_kd 2.128, Train_accy 79.33, Test_accy 67.96
2024-08-31 18:11:21,061 [foster.py] => Task 10, Epoch 101/170 => Loss 3.571, Loss_clf 0.655, Loss_fe 0.566, Loss_kd 2.132, Train_accy 78.49
2024-08-31 18:11:28,495 [foster.py] => Task 10, Epoch 102/170 => Loss 3.553, Loss_clf 0.657, Loss_fe 0.553, Loss_kd 2.126, Train_accy 78.62, Test_accy 68.00
2024-08-31 18:11:35,946 [foster.py] => Task 10, Epoch 103/170 => Loss 3.583, Loss_clf 0.657, Loss_fe 0.588, Loss_kd 2.121, Train_accy 78.82, Test_accy 68.64
2024-08-31 18:11:43,346 [foster.py] => Task 10, Epoch 104/170 => Loss 3.653, Loss_clf 0.692, Loss_fe 0.599, Loss_kd 2.144, Train_accy 78.76, Test_accy 69.51
2024-08-31 18:11:50,725 [foster.py] => Task 10, Epoch 105/170 => Loss 3.640, Loss_clf 0.679, Loss_fe 0.607, Loss_kd 2.136, Train_accy 77.60, Test_accy 67.78
2024-08-31 18:11:56,135 [foster.py] => Task 10, Epoch 106/170 => Loss 3.565, Loss_clf 0.664, Loss_fe 0.561, Loss_kd 2.122, Train_accy 79.49
2024-08-31 18:12:03,587 [foster.py] => Task 10, Epoch 107/170 => Loss 3.580, Loss_clf 0.661, Loss_fe 0.580, Loss_kd 2.122, Train_accy 78.56, Test_accy 68.78
2024-08-31 18:12:10,965 [foster.py] => Task 10, Epoch 108/170 => Loss 3.576, Loss_clf 0.653, Loss_fe 0.571, Loss_kd 2.134, Train_accy 79.76, Test_accy 69.00
2024-08-31 18:12:18,296 [foster.py] => Task 10, Epoch 109/170 => Loss 3.584, Loss_clf 0.670, Loss_fe 0.573, Loss_kd 2.124, Train_accy 78.20, Test_accy 69.00
2024-08-31 18:12:25,630 [foster.py] => Task 10, Epoch 110/170 => Loss 3.542, Loss_clf 0.646, Loss_fe 0.566, Loss_kd 2.114, Train_accy 80.31, Test_accy 68.82
2024-08-31 18:12:31,068 [foster.py] => Task 10, Epoch 111/170 => Loss 3.543, Loss_clf 0.629, Loss_fe 0.564, Loss_kd 2.132, Train_accy 80.27
2024-08-31 18:12:38,503 [foster.py] => Task 10, Epoch 112/170 => Loss 3.559, Loss_clf 0.651, Loss_fe 0.554, Loss_kd 2.135, Train_accy 78.73, Test_accy 69.42
2024-08-31 18:12:45,946 [foster.py] => Task 10, Epoch 113/170 => Loss 3.470, Loss_clf 0.621, Loss_fe 0.513, Loss_kd 2.119, Train_accy 79.98, Test_accy 69.35
2024-08-31 18:12:53,352 [foster.py] => Task 10, Epoch 114/170 => Loss 3.500, Loss_clf 0.622, Loss_fe 0.536, Loss_kd 2.125, Train_accy 80.60, Test_accy 69.58
2024-08-31 18:13:00,718 [foster.py] => Task 10, Epoch 115/170 => Loss 3.466, Loss_clf 0.611, Loss_fe 0.511, Loss_kd 2.127, Train_accy 80.40, Test_accy 68.36
2024-08-31 18:13:06,163 [foster.py] => Task 10, Epoch 116/170 => Loss 3.580, Loss_clf 0.654, Loss_fe 0.567, Loss_kd 2.140, Train_accy 79.78
2024-08-31 18:13:13,673 [foster.py] => Task 10, Epoch 117/170 => Loss 3.487, Loss_clf 0.614, Loss_fe 0.519, Loss_kd 2.136, Train_accy 81.24, Test_accy 69.55
2024-08-31 18:13:21,115 [foster.py] => Task 10, Epoch 118/170 => Loss 3.512, Loss_clf 0.636, Loss_fe 0.523, Loss_kd 2.134, Train_accy 79.31, Test_accy 69.95
2024-08-31 18:13:28,580 [foster.py] => Task 10, Epoch 119/170 => Loss 3.495, Loss_clf 0.631, Loss_fe 0.515, Loss_kd 2.131, Train_accy 80.27, Test_accy 69.20
2024-08-31 18:13:35,967 [foster.py] => Task 10, Epoch 120/170 => Loss 3.417, Loss_clf 0.582, Loss_fe 0.487, Loss_kd 2.131, Train_accy 81.47, Test_accy 69.40
2024-08-31 18:13:41,386 [foster.py] => Task 10, Epoch 121/170 => Loss 3.415, Loss_clf 0.593, Loss_fe 0.467, Loss_kd 2.138, Train_accy 81.62
2024-08-31 18:13:48,782 [foster.py] => Task 10, Epoch 122/170 => Loss 3.421, Loss_clf 0.611, Loss_fe 0.481, Loss_kd 2.113, Train_accy 81.96, Test_accy 70.38
2024-08-31 18:13:56,142 [foster.py] => Task 10, Epoch 123/170 => Loss 3.471, Loss_clf 0.624, Loss_fe 0.492, Loss_kd 2.136, Train_accy 81.02, Test_accy 69.67
2024-08-31 18:14:03,563 [foster.py] => Task 10, Epoch 124/170 => Loss 3.403, Loss_clf 0.586, Loss_fe 0.472, Loss_kd 2.127, Train_accy 81.78, Test_accy 69.95
2024-08-31 18:14:10,986 [foster.py] => Task 10, Epoch 125/170 => Loss 3.391, Loss_clf 0.591, Loss_fe 0.456, Loss_kd 2.128, Train_accy 81.00, Test_accy 69.71
2024-08-31 18:14:16,407 [foster.py] => Task 10, Epoch 126/170 => Loss 3.388, Loss_clf 0.584, Loss_fe 0.462, Loss_kd 2.125, Train_accy 81.89
2024-08-31 18:14:23,874 [foster.py] => Task 10, Epoch 127/170 => Loss 3.449, Loss_clf 0.613, Loss_fe 0.484, Loss_kd 2.134, Train_accy 81.13, Test_accy 69.96
2024-08-31 18:14:31,341 [foster.py] => Task 10, Epoch 128/170 => Loss 3.394, Loss_clf 0.589, Loss_fe 0.452, Loss_kd 2.135, Train_accy 81.89, Test_accy 69.95
2024-08-31 18:14:38,908 [foster.py] => Task 10, Epoch 129/170 => Loss 3.402, Loss_clf 0.595, Loss_fe 0.476, Loss_kd 2.115, Train_accy 81.73, Test_accy 70.51
2024-08-31 18:14:46,293 [foster.py] => Task 10, Epoch 130/170 => Loss 3.403, Loss_clf 0.597, Loss_fe 0.456, Loss_kd 2.132, Train_accy 80.82, Test_accy 70.29
2024-08-31 18:14:51,639 [foster.py] => Task 10, Epoch 131/170 => Loss 3.357, Loss_clf 0.575, Loss_fe 0.444, Loss_kd 2.122, Train_accy 82.07
2024-08-31 18:14:59,089 [foster.py] => Task 10, Epoch 132/170 => Loss 3.349, Loss_clf 0.569, Loss_fe 0.430, Loss_kd 2.132, Train_accy 82.38, Test_accy 70.15
2024-08-31 18:15:06,521 [foster.py] => Task 10, Epoch 133/170 => Loss 3.405, Loss_clf 0.601, Loss_fe 0.454, Loss_kd 2.132, Train_accy 81.27, Test_accy 69.07
2024-08-31 18:15:13,947 [foster.py] => Task 10, Epoch 134/170 => Loss 3.355, Loss_clf 0.578, Loss_fe 0.438, Loss_kd 2.122, Train_accy 82.11, Test_accy 70.25
2024-08-31 18:15:21,365 [foster.py] => Task 10, Epoch 135/170 => Loss 3.313, Loss_clf 0.549, Loss_fe 0.411, Loss_kd 2.135, Train_accy 82.89, Test_accy 69.76
2024-08-31 18:15:26,834 [foster.py] => Task 10, Epoch 136/170 => Loss 3.320, Loss_clf 0.568, Loss_fe 0.406, Loss_kd 2.129, Train_accy 83.16
2024-08-31 18:15:34,266 [foster.py] => Task 10, Epoch 137/170 => Loss 3.307, Loss_clf 0.563, Loss_fe 0.402, Loss_kd 2.125, Train_accy 82.62, Test_accy 70.29
2024-08-31 18:15:41,718 [foster.py] => Task 10, Epoch 138/170 => Loss 3.328, Loss_clf 0.563, Loss_fe 0.398, Loss_kd 2.147, Train_accy 83.02, Test_accy 70.13
2024-08-31 18:15:49,102 [foster.py] => Task 10, Epoch 139/170 => Loss 3.306, Loss_clf 0.557, Loss_fe 0.403, Loss_kd 2.129, Train_accy 82.89, Test_accy 70.04
2024-08-31 18:15:56,524 [foster.py] => Task 10, Epoch 140/170 => Loss 3.338, Loss_clf 0.584, Loss_fe 0.409, Loss_kd 2.127, Train_accy 82.40, Test_accy 70.47
2024-08-31 18:16:01,884 [foster.py] => Task 10, Epoch 141/170 => Loss 3.274, Loss_clf 0.547, Loss_fe 0.378, Loss_kd 2.131, Train_accy 83.22
2024-08-31 18:16:09,297 [foster.py] => Task 10, Epoch 142/170 => Loss 3.251, Loss_clf 0.542, Loss_fe 0.358, Loss_kd 2.134, Train_accy 84.36, Test_accy 70.84
2024-08-31 18:16:16,760 [foster.py] => Task 10, Epoch 143/170 => Loss 3.254, Loss_clf 0.546, Loss_fe 0.366, Loss_kd 2.125, Train_accy 83.71, Test_accy 71.13
2024-08-31 18:16:24,150 [foster.py] => Task 10, Epoch 144/170 => Loss 3.241, Loss_clf 0.531, Loss_fe 0.361, Loss_kd 2.131, Train_accy 84.16, Test_accy 70.98
2024-08-31 18:16:31,496 [foster.py] => Task 10, Epoch 145/170 => Loss 3.226, Loss_clf 0.537, Loss_fe 0.345, Loss_kd 2.127, Train_accy 83.33, Test_accy 70.98
2024-08-31 18:16:36,829 [foster.py] => Task 10, Epoch 146/170 => Loss 3.229, Loss_clf 0.531, Loss_fe 0.346, Loss_kd 2.134, Train_accy 84.24
2024-08-31 18:16:44,301 [foster.py] => Task 10, Epoch 147/170 => Loss 3.201, Loss_clf 0.506, Loss_fe 0.350, Loss_kd 2.128, Train_accy 84.53, Test_accy 70.22
2024-08-31 18:16:51,683 [foster.py] => Task 10, Epoch 148/170 => Loss 3.214, Loss_clf 0.527, Loss_fe 0.342, Loss_kd 2.128, Train_accy 84.36, Test_accy 70.60
2024-08-31 18:16:59,097 [foster.py] => Task 10, Epoch 149/170 => Loss 3.185, Loss_clf 0.512, Loss_fe 0.335, Loss_kd 2.122, Train_accy 84.71, Test_accy 70.38
2024-08-31 18:17:06,532 [foster.py] => Task 10, Epoch 150/170 => Loss 3.218, Loss_clf 0.536, Loss_fe 0.330, Loss_kd 2.135, Train_accy 83.89, Test_accy 70.47
2024-08-31 18:17:11,901 [foster.py] => Task 10, Epoch 151/170 => Loss 3.195, Loss_clf 0.514, Loss_fe 0.331, Loss_kd 2.133, Train_accy 84.24
2024-08-31 18:17:19,316 [foster.py] => Task 10, Epoch 152/170 => Loss 3.191, Loss_clf 0.524, Loss_fe 0.331, Loss_kd 2.120, Train_accy 84.49, Test_accy 70.95
2024-08-31 18:17:26,772 [foster.py] => Task 10, Epoch 153/170 => Loss 3.185, Loss_clf 0.510, Loss_fe 0.337, Loss_kd 2.121, Train_accy 84.38, Test_accy 70.64
2024-08-31 18:17:34,169 [foster.py] => Task 10, Epoch 154/170 => Loss 3.202, Loss_clf 0.524, Loss_fe 0.324, Loss_kd 2.136, Train_accy 85.42, Test_accy 70.60
2024-08-31 18:17:41,602 [foster.py] => Task 10, Epoch 155/170 => Loss 3.178, Loss_clf 0.519, Loss_fe 0.307, Loss_kd 2.135, Train_accy 85.42, Test_accy 70.87
2024-08-31 18:17:47,003 [foster.py] => Task 10, Epoch 156/170 => Loss 3.165, Loss_clf 0.481, Loss_fe 0.320, Loss_kd 2.144, Train_accy 85.47
2024-08-31 18:17:54,370 [foster.py] => Task 10, Epoch 157/170 => Loss 3.163, Loss_clf 0.503, Loss_fe 0.305, Loss_kd 2.138, Train_accy 84.98, Test_accy 70.73
2024-08-31 18:18:01,793 [foster.py] => Task 10, Epoch 158/170 => Loss 3.220, Loss_clf 0.533, Loss_fe 0.334, Loss_kd 2.135, Train_accy 84.09, Test_accy 70.69
2024-08-31 18:18:09,265 [foster.py] => Task 10, Epoch 159/170 => Loss 3.125, Loss_clf 0.490, Loss_fe 0.302, Loss_kd 2.117, Train_accy 85.33, Test_accy 70.89
2024-08-31 18:18:16,688 [foster.py] => Task 10, Epoch 160/170 => Loss 3.192, Loss_clf 0.525, Loss_fe 0.319, Loss_kd 2.130, Train_accy 84.47, Test_accy 71.07
2024-08-31 18:18:22,044 [foster.py] => Task 10, Epoch 161/170 => Loss 3.155, Loss_clf 0.504, Loss_fe 0.309, Loss_kd 2.126, Train_accy 84.58
2024-08-31 18:18:29,436 [foster.py] => Task 10, Epoch 162/170 => Loss 3.148, Loss_clf 0.507, Loss_fe 0.301, Loss_kd 2.124, Train_accy 85.96, Test_accy 71.09
2024-08-31 18:18:36,826 [foster.py] => Task 10, Epoch 163/170 => Loss 3.148, Loss_clf 0.503, Loss_fe 0.287, Loss_kd 2.139, Train_accy 85.64, Test_accy 71.15
2024-08-31 18:18:44,272 [foster.py] => Task 10, Epoch 164/170 => Loss 3.112, Loss_clf 0.490, Loss_fe 0.290, Loss_kd 2.116, Train_accy 86.11, Test_accy 70.96
2024-08-31 18:18:51,662 [foster.py] => Task 10, Epoch 165/170 => Loss 3.159, Loss_clf 0.494, Loss_fe 0.299, Loss_kd 2.147, Train_accy 86.11, Test_accy 70.96
2024-08-31 18:18:57,044 [foster.py] => Task 10, Epoch 166/170 => Loss 3.109, Loss_clf 0.480, Loss_fe 0.292, Loss_kd 2.120, Train_accy 86.47
2024-08-31 18:19:04,429 [foster.py] => Task 10, Epoch 167/170 => Loss 3.188, Loss_clf 0.518, Loss_fe 0.309, Loss_kd 2.142, Train_accy 85.22, Test_accy 71.09
2024-08-31 18:19:11,816 [foster.py] => Task 10, Epoch 168/170 => Loss 3.123, Loss_clf 0.483, Loss_fe 0.285, Loss_kd 2.137, Train_accy 85.64, Test_accy 71.04
2024-08-31 18:19:19,396 [foster.py] => Task 10, Epoch 169/170 => Loss 3.193, Loss_clf 0.520, Loss_fe 0.314, Loss_kd 2.141, Train_accy 84.78, Test_accy 70.85
2024-08-31 18:19:26,822 [foster.py] => Task 10, Epoch 170/170 => Loss 3.085, Loss_clf 0.473, Loss_fe 0.276, Loss_kd 2.121, Train_accy 86.16, Test_accy 71.04
2024-08-31 18:19:26,826 [foster.py] => do not weight align teacher!
2024-08-31 18:19:26,828 [foster.py] => per cls weights : [1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916 1.03380916
 1.03380916 1.03380916 0.66190842 0.66190842 0.66190842 0.66190842
 0.66190842]
2024-08-31 18:19:36,108 [foster.py] => SNet: Task 10, Epoch 1/130 => Loss 27.376,  Loss1 0.685, Train_accy 53.60, Test_accy 63.58
2024-08-31 18:19:43,532 [foster.py] => SNet: Task 10, Epoch 2/130 => Loss 27.252,  Loss1 0.684, Train_accy 68.71
2024-08-31 18:19:50,748 [foster.py] => SNet: Task 10, Epoch 3/130 => Loss 27.224,  Loss1 0.685, Train_accy 71.93
2024-08-31 18:19:58,280 [foster.py] => SNet: Task 10, Epoch 4/130 => Loss 27.210,  Loss1 0.685, Train_accy 73.33
2024-08-31 18:20:05,864 [foster.py] => SNet: Task 10, Epoch 5/130 => Loss 27.242,  Loss1 0.684, Train_accy 73.84
2024-08-31 18:20:14,893 [foster.py] => SNet: Task 10, Epoch 6/130 => Loss 27.220,  Loss1 0.684, Train_accy 75.40, Test_accy 67.09
2024-08-31 18:20:22,388 [foster.py] => SNet: Task 10, Epoch 7/130 => Loss 27.230,  Loss1 0.685, Train_accy 74.44
2024-08-31 18:20:29,862 [foster.py] => SNet: Task 10, Epoch 8/130 => Loss 27.252,  Loss1 0.684, Train_accy 75.73
2024-08-31 18:20:37,081 [foster.py] => SNet: Task 10, Epoch 9/130 => Loss 27.191,  Loss1 0.684, Train_accy 74.69
2024-08-31 18:20:44,332 [foster.py] => SNet: Task 10, Epoch 10/130 => Loss 27.222,  Loss1 0.685, Train_accy 76.80
2024-08-31 18:20:53,650 [foster.py] => SNet: Task 10, Epoch 11/130 => Loss 27.240,  Loss1 0.685, Train_accy 75.47, Test_accy 67.67
2024-08-31 18:21:01,210 [foster.py] => SNet: Task 10, Epoch 12/130 => Loss 27.216,  Loss1 0.684, Train_accy 75.04
2024-08-31 18:21:08,468 [foster.py] => SNet: Task 10, Epoch 13/130 => Loss 27.220,  Loss1 0.685, Train_accy 76.13
2024-08-31 18:21:15,672 [foster.py] => SNet: Task 10, Epoch 14/130 => Loss 27.191,  Loss1 0.685, Train_accy 76.62
2024-08-31 18:21:22,894 [foster.py] => SNet: Task 10, Epoch 15/130 => Loss 27.168,  Loss1 0.684, Train_accy 77.36
2024-08-31 18:21:31,984 [foster.py] => SNet: Task 10, Epoch 16/130 => Loss 27.192,  Loss1 0.685, Train_accy 76.09, Test_accy 65.36
2024-08-31 18:21:39,217 [foster.py] => SNet: Task 10, Epoch 17/130 => Loss 27.239,  Loss1 0.685, Train_accy 76.82
2024-08-31 18:21:46,563 [foster.py] => SNet: Task 10, Epoch 18/130 => Loss 27.191,  Loss1 0.684, Train_accy 77.24
2024-08-31 18:21:53,947 [foster.py] => SNet: Task 10, Epoch 19/130 => Loss 27.218,  Loss1 0.685, Train_accy 77.24
2024-08-31 18:22:01,222 [foster.py] => SNet: Task 10, Epoch 20/130 => Loss 27.188,  Loss1 0.685, Train_accy 77.24
2024-08-31 18:22:10,544 [foster.py] => SNet: Task 10, Epoch 21/130 => Loss 27.164,  Loss1 0.684, Train_accy 78.16, Test_accy 68.56
2024-08-31 18:22:18,642 [foster.py] => SNet: Task 10, Epoch 22/130 => Loss 27.184,  Loss1 0.685, Train_accy 79.00
2024-08-31 18:22:25,949 [foster.py] => SNet: Task 10, Epoch 23/130 => Loss 27.199,  Loss1 0.685, Train_accy 78.18
2024-08-31 18:22:33,352 [foster.py] => SNet: Task 10, Epoch 24/130 => Loss 27.179,  Loss1 0.685, Train_accy 78.07
2024-08-31 18:22:40,515 [foster.py] => SNet: Task 10, Epoch 25/130 => Loss 27.195,  Loss1 0.684, Train_accy 78.38
2024-08-31 18:22:50,342 [foster.py] => SNet: Task 10, Epoch 26/130 => Loss 27.202,  Loss1 0.685, Train_accy 78.18, Test_accy 67.67
2024-08-31 18:22:57,666 [foster.py] => SNet: Task 10, Epoch 27/130 => Loss 27.180,  Loss1 0.685, Train_accy 78.04
2024-08-31 18:23:04,815 [foster.py] => SNet: Task 10, Epoch 28/130 => Loss 27.214,  Loss1 0.684, Train_accy 78.09
2024-08-31 18:23:12,490 [foster.py] => SNet: Task 10, Epoch 29/130 => Loss 27.185,  Loss1 0.685, Train_accy 77.11
2024-08-31 18:23:19,857 [foster.py] => SNet: Task 10, Epoch 30/130 => Loss 27.193,  Loss1 0.685, Train_accy 77.49
2024-08-31 18:23:29,012 [foster.py] => SNet: Task 10, Epoch 31/130 => Loss 27.145,  Loss1 0.684, Train_accy 79.24, Test_accy 68.20
2024-08-31 18:23:36,516 [foster.py] => SNet: Task 10, Epoch 32/130 => Loss 27.199,  Loss1 0.685, Train_accy 77.73
2024-08-31 18:23:44,255 [foster.py] => SNet: Task 10, Epoch 33/130 => Loss 27.173,  Loss1 0.685, Train_accy 78.47
2024-08-31 18:23:51,870 [foster.py] => SNet: Task 10, Epoch 34/130 => Loss 27.166,  Loss1 0.684, Train_accy 78.80
2024-08-31 18:23:59,044 [foster.py] => SNet: Task 10, Epoch 35/130 => Loss 27.163,  Loss1 0.684, Train_accy 78.42
2024-08-31 18:24:08,608 [foster.py] => SNet: Task 10, Epoch 36/130 => Loss 27.205,  Loss1 0.685, Train_accy 78.33, Test_accy 68.85
2024-08-31 18:24:15,746 [foster.py] => SNet: Task 10, Epoch 37/130 => Loss 27.197,  Loss1 0.684, Train_accy 78.53
2024-08-31 18:24:22,908 [foster.py] => SNet: Task 10, Epoch 38/130 => Loss 27.155,  Loss1 0.685, Train_accy 78.31
2024-08-31 18:24:30,125 [foster.py] => SNet: Task 10, Epoch 39/130 => Loss 27.176,  Loss1 0.685, Train_accy 77.69
2024-08-31 18:24:37,318 [foster.py] => SNet: Task 10, Epoch 40/130 => Loss 27.172,  Loss1 0.685, Train_accy 79.47
2024-08-31 18:24:46,372 [foster.py] => SNet: Task 10, Epoch 41/130 => Loss 27.189,  Loss1 0.685, Train_accy 78.60, Test_accy 68.40
2024-08-31 18:24:53,886 [foster.py] => SNet: Task 10, Epoch 42/130 => Loss 27.175,  Loss1 0.684, Train_accy 78.29
2024-08-31 18:25:01,512 [foster.py] => SNet: Task 10, Epoch 43/130 => Loss 27.192,  Loss1 0.685, Train_accy 79.31
2024-08-31 18:25:08,771 [foster.py] => SNet: Task 10, Epoch 44/130 => Loss 27.144,  Loss1 0.685, Train_accy 79.76
2024-08-31 18:25:16,009 [foster.py] => SNet: Task 10, Epoch 45/130 => Loss 27.155,  Loss1 0.685, Train_accy 80.18
2024-08-31 18:25:25,485 [foster.py] => SNet: Task 10, Epoch 46/130 => Loss 27.173,  Loss1 0.685, Train_accy 78.36, Test_accy 68.65
2024-08-31 18:25:32,938 [foster.py] => SNet: Task 10, Epoch 47/130 => Loss 27.190,  Loss1 0.685, Train_accy 79.49
2024-08-31 18:25:40,184 [foster.py] => SNet: Task 10, Epoch 48/130 => Loss 27.169,  Loss1 0.684, Train_accy 78.38
2024-08-31 18:25:47,482 [foster.py] => SNet: Task 10, Epoch 49/130 => Loss 27.156,  Loss1 0.685, Train_accy 79.18
2024-08-31 18:25:55,061 [foster.py] => SNet: Task 10, Epoch 50/130 => Loss 27.147,  Loss1 0.685, Train_accy 79.00
2024-08-31 18:26:04,442 [foster.py] => SNet: Task 10, Epoch 51/130 => Loss 27.156,  Loss1 0.684, Train_accy 79.24, Test_accy 67.73
2024-08-31 18:26:11,609 [foster.py] => SNet: Task 10, Epoch 52/130 => Loss 27.195,  Loss1 0.684, Train_accy 80.02
2024-08-31 18:26:18,886 [foster.py] => SNet: Task 10, Epoch 53/130 => Loss 27.163,  Loss1 0.684, Train_accy 80.11
2024-08-31 18:26:26,269 [foster.py] => SNet: Task 10, Epoch 54/130 => Loss 27.170,  Loss1 0.685, Train_accy 79.24
2024-08-31 18:26:33,810 [foster.py] => SNet: Task 10, Epoch 55/130 => Loss 27.191,  Loss1 0.684, Train_accy 80.18
2024-08-31 18:26:43,557 [foster.py] => SNet: Task 10, Epoch 56/130 => Loss 27.199,  Loss1 0.684, Train_accy 79.02, Test_accy 68.84
2024-08-31 18:26:50,971 [foster.py] => SNet: Task 10, Epoch 57/130 => Loss 27.167,  Loss1 0.684, Train_accy 79.38
2024-08-31 18:26:58,098 [foster.py] => SNet: Task 10, Epoch 58/130 => Loss 27.201,  Loss1 0.684, Train_accy 79.58
2024-08-31 18:27:05,305 [foster.py] => SNet: Task 10, Epoch 59/130 => Loss 27.186,  Loss1 0.685, Train_accy 79.58
2024-08-31 18:27:13,096 [foster.py] => SNet: Task 10, Epoch 60/130 => Loss 27.207,  Loss1 0.684, Train_accy 79.96
2024-08-31 18:27:22,148 [foster.py] => SNet: Task 10, Epoch 61/130 => Loss 27.173,  Loss1 0.685, Train_accy 79.22, Test_accy 68.45
2024-08-31 18:27:29,643 [foster.py] => SNet: Task 10, Epoch 62/130 => Loss 27.190,  Loss1 0.684, Train_accy 79.67
2024-08-31 18:27:37,127 [foster.py] => SNet: Task 10, Epoch 63/130 => Loss 27.179,  Loss1 0.685, Train_accy 79.67
2024-08-31 18:27:44,255 [foster.py] => SNet: Task 10, Epoch 64/130 => Loss 27.131,  Loss1 0.684, Train_accy 80.56
2024-08-31 18:27:51,486 [foster.py] => SNet: Task 10, Epoch 65/130 => Loss 27.180,  Loss1 0.684, Train_accy 79.91
2024-08-31 18:28:01,195 [foster.py] => SNet: Task 10, Epoch 66/130 => Loss 27.165,  Loss1 0.684, Train_accy 79.58, Test_accy 68.67
2024-08-31 18:28:08,768 [foster.py] => SNet: Task 10, Epoch 67/130 => Loss 27.166,  Loss1 0.685, Train_accy 79.89
2024-08-31 18:28:16,333 [foster.py] => SNet: Task 10, Epoch 68/130 => Loss 27.157,  Loss1 0.685, Train_accy 80.27
2024-08-31 18:28:23,543 [foster.py] => SNet: Task 10, Epoch 69/130 => Loss 27.183,  Loss1 0.684, Train_accy 80.02
2024-08-31 18:28:30,934 [foster.py] => SNet: Task 10, Epoch 70/130 => Loss 27.197,  Loss1 0.684, Train_accy 78.87
2024-08-31 18:28:39,971 [foster.py] => SNet: Task 10, Epoch 71/130 => Loss 27.189,  Loss1 0.684, Train_accy 79.93, Test_accy 68.85
2024-08-31 18:28:47,493 [foster.py] => SNet: Task 10, Epoch 72/130 => Loss 27.180,  Loss1 0.685, Train_accy 79.69
2024-08-31 18:28:54,836 [foster.py] => SNet: Task 10, Epoch 73/130 => Loss 27.190,  Loss1 0.684, Train_accy 80.27
2024-08-31 18:29:02,289 [foster.py] => SNet: Task 10, Epoch 74/130 => Loss 27.158,  Loss1 0.685, Train_accy 80.58
2024-08-31 18:29:09,489 [foster.py] => SNet: Task 10, Epoch 75/130 => Loss 27.150,  Loss1 0.685, Train_accy 79.31
2024-08-31 18:29:19,132 [foster.py] => SNet: Task 10, Epoch 76/130 => Loss 27.150,  Loss1 0.685, Train_accy 80.36, Test_accy 69.05
2024-08-31 18:29:26,394 [foster.py] => SNet: Task 10, Epoch 77/130 => Loss 27.171,  Loss1 0.685, Train_accy 79.67
2024-08-31 18:29:34,280 [foster.py] => SNet: Task 10, Epoch 78/130 => Loss 27.178,  Loss1 0.684, Train_accy 79.78
2024-08-31 18:29:41,731 [foster.py] => SNet: Task 10, Epoch 79/130 => Loss 27.169,  Loss1 0.684, Train_accy 80.56
2024-08-31 18:29:48,976 [foster.py] => SNet: Task 10, Epoch 80/130 => Loss 27.143,  Loss1 0.684, Train_accy 81.53
2024-08-31 18:29:58,664 [foster.py] => SNet: Task 10, Epoch 81/130 => Loss 27.166,  Loss1 0.684, Train_accy 80.27, Test_accy 69.27
2024-08-31 18:30:05,961 [foster.py] => SNet: Task 10, Epoch 82/130 => Loss 27.131,  Loss1 0.684, Train_accy 80.67
2024-08-31 18:30:13,372 [foster.py] => SNet: Task 10, Epoch 83/130 => Loss 27.159,  Loss1 0.684, Train_accy 80.40
2024-08-31 18:30:20,821 [foster.py] => SNet: Task 10, Epoch 84/130 => Loss 27.137,  Loss1 0.684, Train_accy 80.04
2024-08-31 18:30:28,250 [foster.py] => SNet: Task 10, Epoch 85/130 => Loss 27.137,  Loss1 0.685, Train_accy 81.18
2024-08-31 18:30:37,536 [foster.py] => SNet: Task 10, Epoch 86/130 => Loss 27.162,  Loss1 0.684, Train_accy 79.78, Test_accy 68.13
2024-08-31 18:30:44,813 [foster.py] => SNet: Task 10, Epoch 87/130 => Loss 27.147,  Loss1 0.685, Train_accy 80.40
2024-08-31 18:30:52,103 [foster.py] => SNet: Task 10, Epoch 88/130 => Loss 27.152,  Loss1 0.685, Train_accy 81.04
2024-08-31 18:30:59,414 [foster.py] => SNet: Task 10, Epoch 89/130 => Loss 27.152,  Loss1 0.685, Train_accy 81.40
2024-08-31 18:31:06,844 [foster.py] => SNet: Task 10, Epoch 90/130 => Loss 27.129,  Loss1 0.684, Train_accy 80.84
2024-08-31 18:31:16,212 [foster.py] => SNet: Task 10, Epoch 91/130 => Loss 27.151,  Loss1 0.685, Train_accy 81.49, Test_accy 69.07
2024-08-31 18:31:23,678 [foster.py] => SNet: Task 10, Epoch 92/130 => Loss 27.137,  Loss1 0.684, Train_accy 81.44
2024-08-31 18:31:30,950 [foster.py] => SNet: Task 10, Epoch 93/130 => Loss 27.133,  Loss1 0.684, Train_accy 80.51
2024-08-31 18:31:38,479 [foster.py] => SNet: Task 10, Epoch 94/130 => Loss 27.192,  Loss1 0.685, Train_accy 81.98
2024-08-31 18:31:46,014 [foster.py] => SNet: Task 10, Epoch 95/130 => Loss 27.171,  Loss1 0.685, Train_accy 81.29
2024-08-31 18:31:54,970 [foster.py] => SNet: Task 10, Epoch 96/130 => Loss 27.140,  Loss1 0.684, Train_accy 81.87, Test_accy 69.76
2024-08-31 18:32:02,504 [foster.py] => SNet: Task 10, Epoch 97/130 => Loss 27.164,  Loss1 0.684, Train_accy 80.53
2024-08-31 18:32:10,259 [foster.py] => SNet: Task 10, Epoch 98/130 => Loss 27.169,  Loss1 0.685, Train_accy 80.62
2024-08-31 18:32:17,887 [foster.py] => SNet: Task 10, Epoch 99/130 => Loss 27.170,  Loss1 0.685, Train_accy 80.67
2024-08-31 18:32:25,126 [foster.py] => SNet: Task 10, Epoch 100/130 => Loss 27.156,  Loss1 0.685, Train_accy 80.82
2024-08-31 18:32:34,404 [foster.py] => SNet: Task 10, Epoch 101/130 => Loss 27.130,  Loss1 0.685, Train_accy 80.89, Test_accy 69.07
2024-08-31 18:32:41,904 [foster.py] => SNet: Task 10, Epoch 102/130 => Loss 27.168,  Loss1 0.685, Train_accy 80.60
2024-08-31 18:32:49,753 [foster.py] => SNet: Task 10, Epoch 103/130 => Loss 27.156,  Loss1 0.685, Train_accy 80.44
2024-08-31 18:32:56,929 [foster.py] => SNet: Task 10, Epoch 104/130 => Loss 27.144,  Loss1 0.685, Train_accy 81.02
2024-08-31 18:33:04,167 [foster.py] => SNet: Task 10, Epoch 105/130 => Loss 27.152,  Loss1 0.685, Train_accy 81.00
2024-08-31 18:33:13,597 [foster.py] => SNet: Task 10, Epoch 106/130 => Loss 27.157,  Loss1 0.684, Train_accy 80.93, Test_accy 69.00
2024-08-31 18:33:20,843 [foster.py] => SNet: Task 10, Epoch 107/130 => Loss 27.174,  Loss1 0.685, Train_accy 80.29
2024-08-31 18:33:28,043 [foster.py] => SNet: Task 10, Epoch 108/130 => Loss 27.134,  Loss1 0.685, Train_accy 80.58
2024-08-31 18:33:35,648 [foster.py] => SNet: Task 10, Epoch 109/130 => Loss 27.179,  Loss1 0.684, Train_accy 81.98
2024-08-31 18:33:42,853 [foster.py] => SNet: Task 10, Epoch 110/130 => Loss 27.179,  Loss1 0.684, Train_accy 79.98
2024-08-31 18:33:51,777 [foster.py] => SNet: Task 10, Epoch 111/130 => Loss 27.155,  Loss1 0.684, Train_accy 81.38, Test_accy 68.95
2024-08-31 18:33:59,211 [foster.py] => SNet: Task 10, Epoch 112/130 => Loss 27.175,  Loss1 0.685, Train_accy 80.16
2024-08-31 18:34:06,411 [foster.py] => SNet: Task 10, Epoch 113/130 => Loss 27.178,  Loss1 0.684, Train_accy 81.71
2024-08-31 18:34:13,716 [foster.py] => SNet: Task 10, Epoch 114/130 => Loss 27.181,  Loss1 0.684, Train_accy 80.44
2024-08-31 18:34:20,954 [foster.py] => SNet: Task 10, Epoch 115/130 => Loss 27.155,  Loss1 0.685, Train_accy 80.76
2024-08-31 18:34:30,110 [foster.py] => SNet: Task 10, Epoch 116/130 => Loss 27.171,  Loss1 0.684, Train_accy 80.93, Test_accy 69.35
2024-08-31 18:34:37,403 [foster.py] => SNet: Task 10, Epoch 117/130 => Loss 27.169,  Loss1 0.684, Train_accy 81.29
2024-08-31 18:34:44,693 [foster.py] => SNet: Task 10, Epoch 118/130 => Loss 27.122,  Loss1 0.684, Train_accy 80.73
2024-08-31 18:34:52,106 [foster.py] => SNet: Task 10, Epoch 119/130 => Loss 27.164,  Loss1 0.685, Train_accy 81.22
2024-08-31 18:34:59,349 [foster.py] => SNet: Task 10, Epoch 120/130 => Loss 27.182,  Loss1 0.685, Train_accy 80.87
2024-08-31 18:35:08,315 [foster.py] => SNet: Task 10, Epoch 121/130 => Loss 27.149,  Loss1 0.685, Train_accy 81.18, Test_accy 69.16
2024-08-31 18:35:16,093 [foster.py] => SNet: Task 10, Epoch 122/130 => Loss 27.147,  Loss1 0.685, Train_accy 80.29
2024-08-31 18:35:23,477 [foster.py] => SNet: Task 10, Epoch 123/130 => Loss 27.188,  Loss1 0.685, Train_accy 80.60
2024-08-31 18:35:30,918 [foster.py] => SNet: Task 10, Epoch 124/130 => Loss 27.136,  Loss1 0.685, Train_accy 80.98
2024-08-31 18:35:38,306 [foster.py] => SNet: Task 10, Epoch 125/130 => Loss 27.172,  Loss1 0.685, Train_accy 81.07
2024-08-31 18:35:47,500 [foster.py] => SNet: Task 10, Epoch 126/130 => Loss 27.159,  Loss1 0.685, Train_accy 81.40, Test_accy 69.00
2024-08-31 18:35:54,687 [foster.py] => SNet: Task 10, Epoch 127/130 => Loss 27.121,  Loss1 0.685, Train_accy 81.91
2024-08-31 18:36:02,091 [foster.py] => SNet: Task 10, Epoch 128/130 => Loss 27.162,  Loss1 0.685, Train_accy 81.58
2024-08-31 18:36:09,358 [foster.py] => SNet: Task 10, Epoch 129/130 => Loss 27.152,  Loss1 0.685, Train_accy 80.33
2024-08-31 18:36:16,648 [foster.py] => SNet: Task 10, Epoch 130/130 => Loss 27.133,  Loss1 0.684, Train_accy 81.09
2024-08-31 18:36:16,649 [foster.py] => do not weight align student!
2024-08-31 18:36:18,471 [foster.py] => darknet eval: 
2024-08-31 18:36:18,471 [foster.py] => CNN top1 curve: 69.25
2024-08-31 18:36:18,471 [foster.py] => CNN top5 curve: 92.0
2024-08-31 18:36:18,471 [foster.py] => CNN top1 平均值: 69.25
2024-08-31 18:36:18,474 [foster.py] => timees : 2204.404783010483
2024-08-31 18:36:18,475 [base.py] => Reducing exemplars...(36 per classes)
2024-08-31 18:36:35,766 [base.py] => Constructing exemplars...(36 per classes)
2024-08-31 18:36:45,152 [foster.py] => Exemplar size: 1980
2024-08-31 18:36:45,153 [trainer.py] => CNN: {'total': 71.04, '00-09': 72.5, '10-19': 57.2, '20-29': 69.7, '30-39': 69.1, '40-49': 78.9, '50-59': 86.6, 'old': 69.48, 'new': 86.6}
2024-08-31 18:36:45,153 [trainer.py] => NME: {'total': 66.42, '00-09': 67.4, '10-19': 52.5, '20-29': 67.6, '30-39': 65.4, '40-49': 69.9, '50-59': 85.0, 'old': 64.56, 'new': 85.0}
2024-08-31 18:36:45,153 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04]
2024-08-31 18:36:45,153 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73]
2024-08-31 18:36:45,153 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42]
2024-08-31 18:36:45,153 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98]

2024-08-31 18:36:45,153 [trainer.py] => CNN top1 平均值: 81.55
2024-08-31 18:36:45,156 [trainer.py] => All params: 1296468
2024-08-31 18:36:45,158 [trainer.py] => Trainable params: 651944
2024-08-31 18:36:45,221 [foster.py] => Learning on 55-60
2024-08-31 18:36:45,224 [foster.py] => All params: 1297763
2024-08-31 18:36:45,227 [foster.py] => Trainable params: 652914
2024-08-31 18:36:45,276 [foster.py] => per cls weights : [1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092 1.01777092
 1.01777092 0.80451984 0.80451984 0.80451984 0.80451984 0.80451984]
2024-08-31 18:36:50,586 [foster.py] => Task 11, Epoch 1/170 => Loss 7.617, Loss_clf 3.049, Loss_fe 1.914, Loss_kd 2.426, Train_accy 46.38
2024-08-31 18:36:58,098 [foster.py] => Task 11, Epoch 2/170 => Loss 5.576, Loss_clf 1.543, Loss_fe 1.377, Loss_kd 2.428, Train_accy 57.10, Test_accy 64.12
2024-08-31 18:37:05,496 [foster.py] => Task 11, Epoch 3/170 => Loss 5.200, Loss_clf 1.303, Loss_fe 1.255, Loss_kd 2.416, Train_accy 60.51, Test_accy 65.50
2024-08-31 18:37:12,877 [foster.py] => Task 11, Epoch 4/170 => Loss 5.208, Loss_clf 1.347, Loss_fe 1.206, Loss_kd 2.426, Train_accy 60.58, Test_accy 63.78
2024-08-31 18:37:20,228 [foster.py] => Task 11, Epoch 5/170 => Loss 5.148, Loss_clf 1.297, Loss_fe 1.203, Loss_kd 2.421, Train_accy 62.12, Test_accy 62.92
2024-08-31 18:37:25,530 [foster.py] => Task 11, Epoch 6/170 => Loss 5.235, Loss_clf 1.359, Loss_fe 1.213, Loss_kd 2.435, Train_accy 61.45
2024-08-31 18:37:32,946 [foster.py] => Task 11, Epoch 7/170 => Loss 5.118, Loss_clf 1.300, Loss_fe 1.162, Loss_kd 2.429, Train_accy 61.90, Test_accy 60.63
2024-08-31 18:37:40,368 [foster.py] => Task 11, Epoch 8/170 => Loss 5.144, Loss_clf 1.342, Loss_fe 1.159, Loss_kd 2.417, Train_accy 62.37, Test_accy 63.58
2024-08-31 18:37:47,826 [foster.py] => Task 11, Epoch 9/170 => Loss 5.292, Loss_clf 1.429, Loss_fe 1.199, Loss_kd 2.436, Train_accy 60.92, Test_accy 61.80
2024-08-31 18:37:55,241 [foster.py] => Task 11, Epoch 10/170 => Loss 5.012, Loss_clf 1.225, Loss_fe 1.136, Loss_kd 2.424, Train_accy 64.40, Test_accy 62.95
2024-08-31 18:38:00,509 [foster.py] => Task 11, Epoch 11/170 => Loss 5.048, Loss_clf 1.281, Loss_fe 1.099, Loss_kd 2.440, Train_accy 63.68
2024-08-31 18:38:07,906 [foster.py] => Task 11, Epoch 12/170 => Loss 5.062, Loss_clf 1.271, Loss_fe 1.139, Loss_kd 2.426, Train_accy 64.08, Test_accy 64.33
2024-08-31 18:38:15,336 [foster.py] => Task 11, Epoch 13/170 => Loss 4.980, Loss_clf 1.217, Loss_fe 1.107, Loss_kd 2.430, Train_accy 64.46, Test_accy 61.92
2024-08-31 18:38:22,838 [foster.py] => Task 11, Epoch 14/170 => Loss 4.934, Loss_clf 1.197, Loss_fe 1.109, Loss_kd 2.404, Train_accy 65.69, Test_accy 65.65
2024-08-31 18:38:30,311 [foster.py] => Task 11, Epoch 15/170 => Loss 4.857, Loss_clf 1.120, Loss_fe 1.082, Loss_kd 2.429, Train_accy 65.40, Test_accy 66.58
2024-08-31 18:38:35,573 [foster.py] => Task 11, Epoch 16/170 => Loss 4.925, Loss_clf 1.186, Loss_fe 1.100, Loss_kd 2.415, Train_accy 64.46
2024-08-31 18:38:42,910 [foster.py] => Task 11, Epoch 17/170 => Loss 5.009, Loss_clf 1.244, Loss_fe 1.113, Loss_kd 2.426, Train_accy 63.39, Test_accy 63.40
2024-08-31 18:38:50,288 [foster.py] => Task 11, Epoch 18/170 => Loss 5.151, Loss_clf 1.395, Loss_fe 1.103, Loss_kd 2.427, Train_accy 62.68, Test_accy 64.57
2024-08-31 18:38:57,673 [foster.py] => Task 11, Epoch 19/170 => Loss 4.964, Loss_clf 1.212, Loss_fe 1.115, Loss_kd 2.413, Train_accy 64.89, Test_accy 64.10
2024-08-31 18:39:05,150 [foster.py] => Task 11, Epoch 20/170 => Loss 4.945, Loss_clf 1.221, Loss_fe 1.074, Loss_kd 2.424, Train_accy 64.06, Test_accy 64.18
2024-08-31 18:39:10,426 [foster.py] => Task 11, Epoch 21/170 => Loss 5.049, Loss_clf 1.318, Loss_fe 1.069, Loss_kd 2.435, Train_accy 63.17
2024-08-31 18:39:17,809 [foster.py] => Task 11, Epoch 22/170 => Loss 4.935, Loss_clf 1.179, Loss_fe 1.105, Loss_kd 2.425, Train_accy 65.54, Test_accy 60.02
2024-08-31 18:39:25,217 [foster.py] => Task 11, Epoch 23/170 => Loss 4.898, Loss_clf 1.172, Loss_fe 1.064, Loss_kd 2.435, Train_accy 65.85, Test_accy 62.75
2024-08-31 18:39:32,648 [foster.py] => Task 11, Epoch 24/170 => Loss 4.835, Loss_clf 1.125, Loss_fe 1.061, Loss_kd 2.423, Train_accy 66.67, Test_accy 66.97
2024-08-31 18:39:40,133 [foster.py] => Task 11, Epoch 25/170 => Loss 4.852, Loss_clf 1.148, Loss_fe 1.056, Loss_kd 2.422, Train_accy 65.89, Test_accy 63.52
2024-08-31 18:39:45,356 [foster.py] => Task 11, Epoch 26/170 => Loss 5.132, Loss_clf 1.370, Loss_fe 1.101, Loss_kd 2.435, Train_accy 62.25
2024-08-31 18:39:52,758 [foster.py] => Task 11, Epoch 27/170 => Loss 5.106, Loss_clf 1.358, Loss_fe 1.100, Loss_kd 2.422, Train_accy 63.79, Test_accy 64.93
2024-08-31 18:40:00,145 [foster.py] => Task 11, Epoch 28/170 => Loss 5.055, Loss_clf 1.295, Loss_fe 1.121, Loss_kd 2.414, Train_accy 63.62, Test_accy 66.42
2024-08-31 18:40:07,659 [foster.py] => Task 11, Epoch 29/170 => Loss 4.939, Loss_clf 1.209, Loss_fe 1.069, Loss_kd 2.434, Train_accy 64.71, Test_accy 67.05
2024-08-31 18:40:15,041 [foster.py] => Task 11, Epoch 30/170 => Loss 4.897, Loss_clf 1.190, Loss_fe 1.050, Loss_kd 2.431, Train_accy 65.09, Test_accy 64.12
2024-08-31 18:40:20,334 [foster.py] => Task 11, Epoch 31/170 => Loss 5.026, Loss_clf 1.297, Loss_fe 1.072, Loss_kd 2.430, Train_accy 64.29
2024-08-31 18:40:27,717 [foster.py] => Task 11, Epoch 32/170 => Loss 4.907, Loss_clf 1.184, Loss_fe 1.074, Loss_kd 2.424, Train_accy 65.60, Test_accy 64.45
2024-08-31 18:40:35,124 [foster.py] => Task 11, Epoch 33/170 => Loss 4.940, Loss_clf 1.227, Loss_fe 1.054, Loss_kd 2.432, Train_accy 64.53, Test_accy 66.20
2024-08-31 18:40:42,587 [foster.py] => Task 11, Epoch 34/170 => Loss 4.887, Loss_clf 1.195, Loss_fe 1.049, Loss_kd 2.418, Train_accy 65.27, Test_accy 67.08
2024-08-31 18:40:50,035 [foster.py] => Task 11, Epoch 35/170 => Loss 4.880, Loss_clf 1.138, Loss_fe 1.076, Loss_kd 2.439, Train_accy 65.36, Test_accy 66.02
2024-08-31 18:40:55,316 [foster.py] => Task 11, Epoch 36/170 => Loss 4.930, Loss_clf 1.211, Loss_fe 1.059, Loss_kd 2.433, Train_accy 64.98
2024-08-31 18:41:02,704 [foster.py] => Task 11, Epoch 37/170 => Loss 4.801, Loss_clf 1.115, Loss_fe 1.032, Loss_kd 2.428, Train_accy 67.81, Test_accy 65.42
2024-08-31 18:41:10,138 [foster.py] => Task 11, Epoch 38/170 => Loss 4.829, Loss_clf 1.131, Loss_fe 1.035, Loss_kd 2.436, Train_accy 66.14, Test_accy 64.77
2024-08-31 18:41:17,533 [foster.py] => Task 11, Epoch 39/170 => Loss 4.779, Loss_clf 1.134, Loss_fe 1.005, Loss_kd 2.415, Train_accy 66.79, Test_accy 66.97
2024-08-31 18:41:24,955 [foster.py] => Task 11, Epoch 40/170 => Loss 4.764, Loss_clf 1.104, Loss_fe 1.003, Loss_kd 2.431, Train_accy 67.63, Test_accy 65.62
2024-08-31 18:41:30,296 [foster.py] => Task 11, Epoch 41/170 => Loss 4.901, Loss_clf 1.204, Loss_fe 1.048, Loss_kd 2.423, Train_accy 66.27
2024-08-31 18:41:37,760 [foster.py] => Task 11, Epoch 42/170 => Loss 4.881, Loss_clf 1.178, Loss_fe 1.045, Loss_kd 2.431, Train_accy 65.76, Test_accy 61.18
2024-08-31 18:41:45,145 [foster.py] => Task 11, Epoch 43/170 => Loss 4.959, Loss_clf 1.277, Loss_fe 1.021, Loss_kd 2.434, Train_accy 64.26, Test_accy 64.32
2024-08-31 18:41:52,561 [foster.py] => Task 11, Epoch 44/170 => Loss 4.815, Loss_clf 1.141, Loss_fe 1.017, Loss_kd 2.430, Train_accy 67.37, Test_accy 66.70
2024-08-31 18:42:00,029 [foster.py] => Task 11, Epoch 45/170 => Loss 4.702, Loss_clf 1.073, Loss_fe 0.977, Loss_kd 2.426, Train_accy 68.50, Test_accy 66.82
2024-08-31 18:42:05,351 [foster.py] => Task 11, Epoch 46/170 => Loss 4.792, Loss_clf 1.112, Loss_fe 1.017, Loss_kd 2.436, Train_accy 66.58
2024-08-31 18:42:12,746 [foster.py] => Task 11, Epoch 47/170 => Loss 4.730, Loss_clf 1.079, Loss_fe 0.992, Loss_kd 2.433, Train_accy 67.43, Test_accy 67.33
2024-08-31 18:42:20,146 [foster.py] => Task 11, Epoch 48/170 => Loss 4.652, Loss_clf 1.020, Loss_fe 0.974, Loss_kd 2.432, Train_accy 70.02, Test_accy 66.08
2024-08-31 18:42:27,568 [foster.py] => Task 11, Epoch 49/170 => Loss 4.651, Loss_clf 1.052, Loss_fe 0.956, Loss_kd 2.418, Train_accy 67.70, Test_accy 64.07
2024-08-31 18:42:34,979 [foster.py] => Task 11, Epoch 50/170 => Loss 4.779, Loss_clf 1.113, Loss_fe 1.008, Loss_kd 2.432, Train_accy 67.14, Test_accy 66.48
2024-08-31 18:42:40,298 [foster.py] => Task 11, Epoch 51/170 => Loss 4.701, Loss_clf 1.069, Loss_fe 0.978, Loss_kd 2.428, Train_accy 67.99
2024-08-31 18:42:47,695 [foster.py] => Task 11, Epoch 52/170 => Loss 4.750, Loss_clf 1.121, Loss_fe 0.987, Loss_kd 2.417, Train_accy 67.23, Test_accy 65.60
2024-08-31 18:42:55,155 [foster.py] => Task 11, Epoch 53/170 => Loss 4.673, Loss_clf 1.069, Loss_fe 0.961, Loss_kd 2.419, Train_accy 68.15, Test_accy 67.00
2024-08-31 18:43:02,541 [foster.py] => Task 11, Epoch 54/170 => Loss 4.715, Loss_clf 1.103, Loss_fe 0.968, Loss_kd 2.419, Train_accy 67.30, Test_accy 65.08
2024-08-31 18:43:10,046 [foster.py] => Task 11, Epoch 55/170 => Loss 4.828, Loss_clf 1.178, Loss_fe 0.988, Loss_kd 2.435, Train_accy 65.47, Test_accy 61.30
2024-08-31 18:43:15,440 [foster.py] => Task 11, Epoch 56/170 => Loss 4.732, Loss_clf 1.110, Loss_fe 0.975, Loss_kd 2.421, Train_accy 67.97
2024-08-31 18:43:22,901 [foster.py] => Task 11, Epoch 57/170 => Loss 4.682, Loss_clf 1.070, Loss_fe 0.971, Loss_kd 2.416, Train_accy 68.21, Test_accy 65.12
2024-08-31 18:43:30,353 [foster.py] => Task 11, Epoch 58/170 => Loss 4.695, Loss_clf 1.082, Loss_fe 0.961, Loss_kd 2.425, Train_accy 68.46, Test_accy 64.80
2024-08-31 18:43:37,759 [foster.py] => Task 11, Epoch 59/170 => Loss 4.682, Loss_clf 1.079, Loss_fe 0.949, Loss_kd 2.427, Train_accy 67.92, Test_accy 66.58
2024-08-31 18:43:45,306 [foster.py] => Task 11, Epoch 60/170 => Loss 4.680, Loss_clf 1.049, Loss_fe 0.985, Loss_kd 2.421, Train_accy 69.02, Test_accy 66.53
2024-08-31 18:43:50,596 [foster.py] => Task 11, Epoch 61/170 => Loss 4.574, Loss_clf 1.005, Loss_fe 0.928, Loss_kd 2.416, Train_accy 70.02
2024-08-31 18:43:57,995 [foster.py] => Task 11, Epoch 62/170 => Loss 4.693, Loss_clf 1.073, Loss_fe 0.960, Loss_kd 2.434, Train_accy 68.19, Test_accy 65.42
2024-08-31 18:44:05,404 [foster.py] => Task 11, Epoch 63/170 => Loss 4.605, Loss_clf 1.015, Loss_fe 0.940, Loss_kd 2.425, Train_accy 69.84, Test_accy 66.58
2024-08-31 18:44:12,830 [foster.py] => Task 11, Epoch 64/170 => Loss 4.707, Loss_clf 1.104, Loss_fe 0.946, Loss_kd 2.431, Train_accy 67.28, Test_accy 67.47
2024-08-31 18:44:20,306 [foster.py] => Task 11, Epoch 65/170 => Loss 4.662, Loss_clf 1.069, Loss_fe 0.935, Loss_kd 2.431, Train_accy 67.92, Test_accy 64.53
2024-08-31 18:44:25,573 [foster.py] => Task 11, Epoch 66/170 => Loss 4.602, Loss_clf 1.006, Loss_fe 0.933, Loss_kd 2.436, Train_accy 69.78
2024-08-31 18:44:32,991 [foster.py] => Task 11, Epoch 67/170 => Loss 4.602, Loss_clf 1.010, Loss_fe 0.933, Loss_kd 2.433, Train_accy 69.93, Test_accy 66.35
2024-08-31 18:44:40,340 [foster.py] => Task 11, Epoch 68/170 => Loss 4.618, Loss_clf 1.025, Loss_fe 0.942, Loss_kd 2.426, Train_accy 69.46, Test_accy 66.55
2024-08-31 18:44:47,765 [foster.py] => Task 11, Epoch 69/170 => Loss 4.535, Loss_clf 1.004, Loss_fe 0.896, Loss_kd 2.410, Train_accy 70.42, Test_accy 65.42
2024-08-31 18:44:55,353 [foster.py] => Task 11, Epoch 70/170 => Loss 4.595, Loss_clf 1.014, Loss_fe 0.927, Loss_kd 2.428, Train_accy 69.02, Test_accy 65.70
2024-08-31 18:45:00,629 [foster.py] => Task 11, Epoch 71/170 => Loss 4.563, Loss_clf 1.013, Loss_fe 0.895, Loss_kd 2.429, Train_accy 69.38
2024-08-31 18:45:08,047 [foster.py] => Task 11, Epoch 72/170 => Loss 4.607, Loss_clf 1.042, Loss_fe 0.910, Loss_kd 2.429, Train_accy 68.88, Test_accy 66.05
2024-08-31 18:45:15,504 [foster.py] => Task 11, Epoch 73/170 => Loss 4.784, Loss_clf 1.181, Loss_fe 0.950, Loss_kd 2.427, Train_accy 66.88, Test_accy 64.95
2024-08-31 18:45:22,899 [foster.py] => Task 11, Epoch 74/170 => Loss 4.615, Loss_clf 1.044, Loss_fe 0.912, Loss_kd 2.432, Train_accy 69.22, Test_accy 63.87
2024-08-31 18:45:30,313 [foster.py] => Task 11, Epoch 75/170 => Loss 4.576, Loss_clf 1.012, Loss_fe 0.920, Loss_kd 2.420, Train_accy 70.31, Test_accy 67.73
2024-08-31 18:45:35,574 [foster.py] => Task 11, Epoch 76/170 => Loss 4.508, Loss_clf 0.980, Loss_fe 0.871, Loss_kd 2.431, Train_accy 70.22
2024-08-31 18:45:43,003 [foster.py] => Task 11, Epoch 77/170 => Loss 4.541, Loss_clf 1.002, Loss_fe 0.895, Loss_kd 2.420, Train_accy 70.38, Test_accy 66.30
2024-08-31 18:45:50,390 [foster.py] => Task 11, Epoch 78/170 => Loss 4.457, Loss_clf 0.946, Loss_fe 0.879, Loss_kd 2.408, Train_accy 70.67, Test_accy 68.15
2024-08-31 18:45:57,800 [foster.py] => Task 11, Epoch 79/170 => Loss 4.412, Loss_clf 0.921, Loss_fe 0.848, Loss_kd 2.417, Train_accy 71.94, Test_accy 66.87
2024-08-31 18:46:05,210 [foster.py] => Task 11, Epoch 80/170 => Loss 4.434, Loss_clf 0.933, Loss_fe 0.860, Loss_kd 2.416, Train_accy 71.54, Test_accy 66.32
2024-08-31 18:46:10,608 [foster.py] => Task 11, Epoch 81/170 => Loss 4.494, Loss_clf 0.977, Loss_fe 0.880, Loss_kd 2.413, Train_accy 71.18
2024-08-31 18:46:18,020 [foster.py] => Task 11, Epoch 82/170 => Loss 4.551, Loss_clf 1.022, Loss_fe 0.880, Loss_kd 2.424, Train_accy 69.31, Test_accy 65.23
2024-08-31 18:46:25,519 [foster.py] => Task 11, Epoch 83/170 => Loss 4.428, Loss_clf 0.922, Loss_fe 0.857, Loss_kd 2.424, Train_accy 72.19, Test_accy 67.48
2024-08-31 18:46:33,056 [foster.py] => Task 11, Epoch 84/170 => Loss 4.453, Loss_clf 0.962, Loss_fe 0.848, Loss_kd 2.418, Train_accy 70.87, Test_accy 65.00
2024-08-31 18:46:40,448 [foster.py] => Task 11, Epoch 85/170 => Loss 4.385, Loss_clf 0.922, Loss_fe 0.829, Loss_kd 2.410, Train_accy 71.65, Test_accy 64.28
2024-08-31 18:46:45,719 [foster.py] => Task 11, Epoch 86/170 => Loss 4.387, Loss_clf 0.911, Loss_fe 0.827, Loss_kd 2.424, Train_accy 73.33
2024-08-31 18:46:53,130 [foster.py] => Task 11, Epoch 87/170 => Loss 4.425, Loss_clf 0.947, Loss_fe 0.820, Loss_kd 2.431, Train_accy 71.72, Test_accy 66.27
2024-08-31 18:47:00,502 [foster.py] => Task 11, Epoch 88/170 => Loss 4.434, Loss_clf 0.943, Loss_fe 0.842, Loss_kd 2.423, Train_accy 71.41, Test_accy 67.70
2024-08-31 18:47:07,946 [foster.py] => Task 11, Epoch 89/170 => Loss 4.326, Loss_clf 0.888, Loss_fe 0.789, Loss_kd 2.423, Train_accy 73.08, Test_accy 68.55
2024-08-31 18:47:15,332 [foster.py] => Task 11, Epoch 90/170 => Loss 4.321, Loss_clf 0.876, Loss_fe 0.807, Loss_kd 2.413, Train_accy 73.79, Test_accy 66.55
2024-08-31 18:47:20,618 [foster.py] => Task 11, Epoch 91/170 => Loss 4.312, Loss_clf 0.881, Loss_fe 0.808, Loss_kd 2.400, Train_accy 73.24
2024-08-31 18:47:27,987 [foster.py] => Task 11, Epoch 92/170 => Loss 4.352, Loss_clf 0.911, Loss_fe 0.792, Loss_kd 2.424, Train_accy 72.72, Test_accy 67.45
2024-08-31 18:47:35,439 [foster.py] => Task 11, Epoch 93/170 => Loss 4.356, Loss_clf 0.921, Loss_fe 0.799, Loss_kd 2.411, Train_accy 72.88, Test_accy 68.47
2024-08-31 18:47:42,826 [foster.py] => Task 11, Epoch 94/170 => Loss 4.366, Loss_clf 0.915, Loss_fe 0.798, Loss_kd 2.427, Train_accy 72.32, Test_accy 68.03
2024-08-31 18:47:50,369 [foster.py] => Task 11, Epoch 95/170 => Loss 4.325, Loss_clf 0.894, Loss_fe 0.787, Loss_kd 2.419, Train_accy 73.75, Test_accy 68.17
2024-08-31 18:47:55,636 [foster.py] => Task 11, Epoch 96/170 => Loss 4.340, Loss_clf 0.909, Loss_fe 0.781, Loss_kd 2.424, Train_accy 73.12
2024-08-31 18:48:03,137 [foster.py] => Task 11, Epoch 97/170 => Loss 4.293, Loss_clf 0.896, Loss_fe 0.755, Loss_kd 2.417, Train_accy 73.57, Test_accy 66.68
2024-08-31 18:48:10,549 [foster.py] => Task 11, Epoch 98/170 => Loss 4.334, Loss_clf 0.897, Loss_fe 0.782, Loss_kd 2.428, Train_accy 72.90, Test_accy 65.97
2024-08-31 18:48:17,941 [foster.py] => Task 11, Epoch 99/170 => Loss 4.319, Loss_clf 0.896, Loss_fe 0.765, Loss_kd 2.432, Train_accy 73.44, Test_accy 67.82
2024-08-31 18:48:25,378 [foster.py] => Task 11, Epoch 100/170 => Loss 4.289, Loss_clf 0.883, Loss_fe 0.758, Loss_kd 2.423, Train_accy 73.68, Test_accy 67.92
2024-08-31 18:48:30,638 [foster.py] => Task 11, Epoch 101/170 => Loss 4.266, Loss_clf 0.862, Loss_fe 0.761, Loss_kd 2.418, Train_accy 74.26
2024-08-31 18:48:38,012 [foster.py] => Task 11, Epoch 102/170 => Loss 4.263, Loss_clf 0.856, Loss_fe 0.764, Loss_kd 2.417, Train_accy 74.33, Test_accy 65.22
2024-08-31 18:48:45,484 [foster.py] => Task 11, Epoch 103/170 => Loss 4.260, Loss_clf 0.874, Loss_fe 0.727, Loss_kd 2.432, Train_accy 73.35, Test_accy 67.18
2024-08-31 18:48:52,895 [foster.py] => Task 11, Epoch 104/170 => Loss 4.189, Loss_clf 0.835, Loss_fe 0.718, Loss_kd 2.412, Train_accy 75.27, Test_accy 67.78
2024-08-31 18:49:00,284 [foster.py] => Task 11, Epoch 105/170 => Loss 4.225, Loss_clf 0.842, Loss_fe 0.729, Loss_kd 2.427, Train_accy 74.98, Test_accy 67.60
2024-08-31 18:49:05,612 [foster.py] => Task 11, Epoch 106/170 => Loss 4.203, Loss_clf 0.842, Loss_fe 0.715, Loss_kd 2.421, Train_accy 74.78
2024-08-31 18:49:13,016 [foster.py] => Task 11, Epoch 107/170 => Loss 4.162, Loss_clf 0.824, Loss_fe 0.692, Loss_kd 2.421, Train_accy 75.85, Test_accy 68.53
2024-08-31 18:49:20,446 [foster.py] => Task 11, Epoch 108/170 => Loss 4.184, Loss_clf 0.816, Loss_fe 0.704, Loss_kd 2.437, Train_accy 75.56, Test_accy 66.83
2024-08-31 18:49:27,838 [foster.py] => Task 11, Epoch 109/170 => Loss 4.166, Loss_clf 0.826, Loss_fe 0.686, Loss_kd 2.428, Train_accy 75.74, Test_accy 67.73
2024-08-31 18:49:35,395 [foster.py] => Task 11, Epoch 110/170 => Loss 4.109, Loss_clf 0.791, Loss_fe 0.678, Loss_kd 2.416, Train_accy 76.27, Test_accy 67.92
2024-08-31 18:49:40,673 [foster.py] => Task 11, Epoch 111/170 => Loss 4.123, Loss_clf 0.813, Loss_fe 0.661, Loss_kd 2.423, Train_accy 76.21
2024-08-31 18:49:48,046 [foster.py] => Task 11, Epoch 112/170 => Loss 4.144, Loss_clf 0.809, Loss_fe 0.696, Loss_kd 2.415, Train_accy 75.71, Test_accy 68.88
2024-08-31 18:49:55,462 [foster.py] => Task 11, Epoch 113/170 => Loss 4.040, Loss_clf 0.769, Loss_fe 0.640, Loss_kd 2.408, Train_accy 77.12, Test_accy 67.88
2024-08-31 18:50:02,896 [foster.py] => Task 11, Epoch 114/170 => Loss 4.162, Loss_clf 0.827, Loss_fe 0.688, Loss_kd 2.422, Train_accy 75.87, Test_accy 65.63
2024-08-31 18:50:10,316 [foster.py] => Task 11, Epoch 115/170 => Loss 4.157, Loss_clf 0.836, Loss_fe 0.670, Loss_kd 2.425, Train_accy 74.80, Test_accy 68.00
2024-08-31 18:50:15,685 [foster.py] => Task 11, Epoch 116/170 => Loss 4.055, Loss_clf 0.791, Loss_fe 0.623, Loss_kd 2.416, Train_accy 76.58
2024-08-31 18:50:23,067 [foster.py] => Task 11, Epoch 117/170 => Loss 4.069, Loss_clf 0.774, Loss_fe 0.664, Loss_kd 2.407, Train_accy 77.57, Test_accy 66.03
2024-08-31 18:50:30,449 [foster.py] => Task 11, Epoch 118/170 => Loss 4.024, Loss_clf 0.761, Loss_fe 0.628, Loss_kd 2.410, Train_accy 78.08, Test_accy 68.25
2024-08-31 18:50:37,925 [foster.py] => Task 11, Epoch 119/170 => Loss 4.052, Loss_clf 0.772, Loss_fe 0.634, Loss_kd 2.421, Train_accy 76.99, Test_accy 67.80
2024-08-31 18:50:45,341 [foster.py] => Task 11, Epoch 120/170 => Loss 4.069, Loss_clf 0.785, Loss_fe 0.630, Loss_kd 2.429, Train_accy 77.01, Test_accy 68.38
2024-08-31 18:50:50,655 [foster.py] => Task 11, Epoch 121/170 => Loss 4.004, Loss_clf 0.752, Loss_fe 0.604, Loss_kd 2.423, Train_accy 78.12
2024-08-31 18:50:58,070 [foster.py] => Task 11, Epoch 122/170 => Loss 4.032, Loss_clf 0.775, Loss_fe 0.620, Loss_kd 2.413, Train_accy 76.34, Test_accy 68.85
2024-08-31 18:51:05,656 [foster.py] => Task 11, Epoch 123/170 => Loss 3.992, Loss_clf 0.731, Loss_fe 0.616, Loss_kd 2.420, Train_accy 77.97, Test_accy 69.25
2024-08-31 18:51:13,130 [foster.py] => Task 11, Epoch 124/170 => Loss 3.955, Loss_clf 0.724, Loss_fe 0.584, Loss_kd 2.421, Train_accy 79.06, Test_accy 68.40
2024-08-31 18:51:20,510 [foster.py] => Task 11, Epoch 125/170 => Loss 3.958, Loss_clf 0.726, Loss_fe 0.586, Loss_kd 2.420, Train_accy 78.04, Test_accy 68.87
2024-08-31 18:51:25,891 [foster.py] => Task 11, Epoch 126/170 => Loss 3.961, Loss_clf 0.739, Loss_fe 0.582, Loss_kd 2.416, Train_accy 78.06
2024-08-31 18:51:33,304 [foster.py] => Task 11, Epoch 127/170 => Loss 4.003, Loss_clf 0.750, Loss_fe 0.606, Loss_kd 2.422, Train_accy 77.99, Test_accy 68.33
2024-08-31 18:51:40,794 [foster.py] => Task 11, Epoch 128/170 => Loss 3.926, Loss_clf 0.720, Loss_fe 0.579, Loss_kd 2.403, Train_accy 78.75, Test_accy 67.48
2024-08-31 18:51:48,234 [foster.py] => Task 11, Epoch 129/170 => Loss 3.914, Loss_clf 0.717, Loss_fe 0.567, Loss_kd 2.406, Train_accy 78.71, Test_accy 68.18
2024-08-31 18:51:55,719 [foster.py] => Task 11, Epoch 130/170 => Loss 3.890, Loss_clf 0.698, Loss_fe 0.548, Loss_kd 2.419, Train_accy 79.53, Test_accy 68.28
2024-08-31 18:52:01,038 [foster.py] => Task 11, Epoch 131/170 => Loss 3.827, Loss_clf 0.679, Loss_fe 0.515, Loss_kd 2.408, Train_accy 79.26
2024-08-31 18:52:08,473 [foster.py] => Task 11, Epoch 132/170 => Loss 3.863, Loss_clf 0.692, Loss_fe 0.535, Loss_kd 2.412, Train_accy 79.93, Test_accy 68.90
2024-08-31 18:52:15,884 [foster.py] => Task 11, Epoch 133/170 => Loss 3.838, Loss_clf 0.674, Loss_fe 0.522, Loss_kd 2.418, Train_accy 79.89, Test_accy 68.78
2024-08-31 18:52:23,265 [foster.py] => Task 11, Epoch 134/170 => Loss 3.868, Loss_clf 0.692, Loss_fe 0.527, Loss_kd 2.424, Train_accy 80.74, Test_accy 68.90
2024-08-31 18:52:30,629 [foster.py] => Task 11, Epoch 135/170 => Loss 3.907, Loss_clf 0.704, Loss_fe 0.547, Loss_kd 2.431, Train_accy 79.51, Test_accy 68.80
2024-08-31 18:52:36,020 [foster.py] => Task 11, Epoch 136/170 => Loss 3.913, Loss_clf 0.712, Loss_fe 0.539, Loss_kd 2.436, Train_accy 78.95
2024-08-31 18:52:43,419 [foster.py] => Task 11, Epoch 137/170 => Loss 3.818, Loss_clf 0.668, Loss_fe 0.502, Loss_kd 2.423, Train_accy 80.65, Test_accy 69.15
2024-08-31 18:52:50,971 [foster.py] => Task 11, Epoch 138/170 => Loss 3.761, Loss_clf 0.643, Loss_fe 0.480, Loss_kd 2.414, Train_accy 81.18, Test_accy 68.77
2024-08-31 18:52:58,451 [foster.py] => Task 11, Epoch 139/170 => Loss 3.842, Loss_clf 0.684, Loss_fe 0.502, Loss_kd 2.431, Train_accy 80.38, Test_accy 68.67
2024-08-31 18:53:05,812 [foster.py] => Task 11, Epoch 140/170 => Loss 3.826, Loss_clf 0.679, Loss_fe 0.509, Loss_kd 2.414, Train_accy 80.76, Test_accy 68.73
2024-08-31 18:53:11,086 [foster.py] => Task 11, Epoch 141/170 => Loss 3.747, Loss_clf 0.639, Loss_fe 0.467, Loss_kd 2.417, Train_accy 81.41
2024-08-31 18:53:18,516 [foster.py] => Task 11, Epoch 142/170 => Loss 3.761, Loss_clf 0.645, Loss_fe 0.476, Loss_kd 2.415, Train_accy 81.16, Test_accy 69.07
2024-08-31 18:53:25,945 [foster.py] => Task 11, Epoch 143/170 => Loss 3.779, Loss_clf 0.650, Loss_fe 0.476, Loss_kd 2.428, Train_accy 80.85, Test_accy 68.88
2024-08-31 18:53:33,359 [foster.py] => Task 11, Epoch 144/170 => Loss 3.728, Loss_clf 0.633, Loss_fe 0.460, Loss_kd 2.410, Train_accy 81.54, Test_accy 68.93
2024-08-31 18:53:40,759 [foster.py] => Task 11, Epoch 145/170 => Loss 3.797, Loss_clf 0.676, Loss_fe 0.459, Loss_kd 2.436, Train_accy 81.07, Test_accy 69.12
2024-08-31 18:53:46,034 [foster.py] => Task 11, Epoch 146/170 => Loss 3.703, Loss_clf 0.616, Loss_fe 0.436, Loss_kd 2.426, Train_accy 82.50
2024-08-31 18:53:53,430 [foster.py] => Task 11, Epoch 147/170 => Loss 3.715, Loss_clf 0.626, Loss_fe 0.453, Loss_kd 2.412, Train_accy 82.79, Test_accy 69.22
2024-08-31 18:54:00,814 [foster.py] => Task 11, Epoch 148/170 => Loss 3.707, Loss_clf 0.613, Loss_fe 0.444, Loss_kd 2.425, Train_accy 82.54, Test_accy 68.87
2024-08-31 18:54:08,266 [foster.py] => Task 11, Epoch 149/170 => Loss 3.667, Loss_clf 0.604, Loss_fe 0.433, Loss_kd 2.406, Train_accy 82.59, Test_accy 68.95
2024-08-31 18:54:15,666 [foster.py] => Task 11, Epoch 150/170 => Loss 3.690, Loss_clf 0.608, Loss_fe 0.436, Loss_kd 2.420, Train_accy 82.19, Test_accy 69.37
2024-08-31 18:54:21,044 [foster.py] => Task 11, Epoch 151/170 => Loss 3.677, Loss_clf 0.607, Loss_fe 0.426, Loss_kd 2.419, Train_accy 83.19
2024-08-31 18:54:28,392 [foster.py] => Task 11, Epoch 152/170 => Loss 3.683, Loss_clf 0.609, Loss_fe 0.412, Loss_kd 2.435, Train_accy 83.08, Test_accy 69.03
2024-08-31 18:54:35,888 [foster.py] => Task 11, Epoch 153/170 => Loss 3.650, Loss_clf 0.599, Loss_fe 0.416, Loss_kd 2.411, Train_accy 82.77, Test_accy 69.10
2024-08-31 18:54:43,414 [foster.py] => Task 11, Epoch 154/170 => Loss 3.648, Loss_clf 0.598, Loss_fe 0.416, Loss_kd 2.410, Train_accy 83.17, Test_accy 68.98
2024-08-31 18:54:50,892 [foster.py] => Task 11, Epoch 155/170 => Loss 3.678, Loss_clf 0.618, Loss_fe 0.404, Loss_kd 2.431, Train_accy 82.83, Test_accy 69.43
2024-08-31 18:54:56,232 [foster.py] => Task 11, Epoch 156/170 => Loss 3.679, Loss_clf 0.608, Loss_fe 0.418, Loss_kd 2.427, Train_accy 83.33
2024-08-31 18:55:03,741 [foster.py] => Task 11, Epoch 157/170 => Loss 3.684, Loss_clf 0.612, Loss_fe 0.413, Loss_kd 2.432, Train_accy 82.99, Test_accy 69.48
2024-08-31 18:55:11,175 [foster.py] => Task 11, Epoch 158/170 => Loss 3.604, Loss_clf 0.584, Loss_fe 0.381, Loss_kd 2.416, Train_accy 84.17, Test_accy 69.42
2024-08-31 18:55:18,558 [foster.py] => Task 11, Epoch 159/170 => Loss 3.612, Loss_clf 0.580, Loss_fe 0.384, Loss_kd 2.423, Train_accy 83.48, Test_accy 69.28
2024-08-31 18:55:26,024 [foster.py] => Task 11, Epoch 160/170 => Loss 3.622, Loss_clf 0.588, Loss_fe 0.390, Loss_kd 2.419, Train_accy 83.37, Test_accy 69.22
2024-08-31 18:55:31,289 [foster.py] => Task 11, Epoch 161/170 => Loss 3.609, Loss_clf 0.589, Loss_fe 0.382, Loss_kd 2.414, Train_accy 83.84
2024-08-31 18:55:38,729 [foster.py] => Task 11, Epoch 162/170 => Loss 3.577, Loss_clf 0.566, Loss_fe 0.367, Loss_kd 2.420, Train_accy 84.17, Test_accy 69.30
2024-08-31 18:55:46,108 [foster.py] => Task 11, Epoch 163/170 => Loss 3.566, Loss_clf 0.568, Loss_fe 0.356, Loss_kd 2.418, Train_accy 84.29, Test_accy 69.42
2024-08-31 18:55:53,510 [foster.py] => Task 11, Epoch 164/170 => Loss 3.652, Loss_clf 0.599, Loss_fe 0.403, Loss_kd 2.425, Train_accy 83.55, Test_accy 69.47
2024-08-31 18:56:00,862 [foster.py] => Task 11, Epoch 165/170 => Loss 3.613, Loss_clf 0.588, Loss_fe 0.387, Loss_kd 2.414, Train_accy 83.97, Test_accy 69.45
2024-08-31 18:56:06,190 [foster.py] => Task 11, Epoch 166/170 => Loss 3.595, Loss_clf 0.581, Loss_fe 0.382, Loss_kd 2.408, Train_accy 83.59
2024-08-31 18:56:13,568 [foster.py] => Task 11, Epoch 167/170 => Loss 3.614, Loss_clf 0.587, Loss_fe 0.387, Loss_kd 2.415, Train_accy 83.73, Test_accy 69.37
2024-08-31 18:56:20,951 [foster.py] => Task 11, Epoch 168/170 => Loss 3.596, Loss_clf 0.564, Loss_fe 0.389, Loss_kd 2.418, Train_accy 83.55, Test_accy 69.35
2024-08-31 18:56:28,343 [foster.py] => Task 11, Epoch 169/170 => Loss 3.616, Loss_clf 0.578, Loss_fe 0.389, Loss_kd 2.424, Train_accy 83.79, Test_accy 69.30
2024-08-31 18:56:35,695 [foster.py] => Task 11, Epoch 170/170 => Loss 3.603, Loss_clf 0.587, Loss_fe 0.376, Loss_kd 2.416, Train_accy 83.59, Test_accy 69.45
2024-08-31 18:56:35,700 [foster.py] => do not weight align teacher!
2024-08-31 18:56:35,701 [foster.py] => per cls weights : [1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878 1.03399878
 1.03399878 0.62601341 0.62601341 0.62601341 0.62601341 0.62601341]
2024-08-31 18:56:45,190 [foster.py] => SNet: Task 11, Epoch 1/130 => Loss 28.233,  Loss1 0.701, Train_accy 45.87, Test_accy 61.33
2024-08-31 18:56:52,571 [foster.py] => SNet: Task 11, Epoch 2/130 => Loss 28.122,  Loss1 0.699, Train_accy 55.27
2024-08-31 18:56:59,852 [foster.py] => SNet: Task 11, Epoch 3/130 => Loss 28.100,  Loss1 0.699, Train_accy 60.25
2024-08-31 18:57:07,029 [foster.py] => SNet: Task 11, Epoch 4/130 => Loss 28.073,  Loss1 0.698, Train_accy 62.68
2024-08-31 18:57:14,667 [foster.py] => SNet: Task 11, Epoch 5/130 => Loss 28.068,  Loss1 0.698, Train_accy 63.46
2024-08-31 18:57:23,708 [foster.py] => SNet: Task 11, Epoch 6/130 => Loss 28.093,  Loss1 0.697, Train_accy 63.53, Test_accy 64.93
2024-08-31 18:57:31,263 [foster.py] => SNet: Task 11, Epoch 7/130 => Loss 28.035,  Loss1 0.697, Train_accy 66.38
2024-08-31 18:57:38,369 [foster.py] => SNet: Task 11, Epoch 8/130 => Loss 28.063,  Loss1 0.697, Train_accy 66.45
2024-08-31 18:57:46,071 [foster.py] => SNet: Task 11, Epoch 9/130 => Loss 28.038,  Loss1 0.697, Train_accy 68.21
2024-08-31 18:57:53,661 [foster.py] => SNet: Task 11, Epoch 10/130 => Loss 28.015,  Loss1 0.697, Train_accy 67.99
2024-08-31 18:58:02,925 [foster.py] => SNet: Task 11, Epoch 11/130 => Loss 28.029,  Loss1 0.697, Train_accy 68.82, Test_accy 65.45
2024-08-31 18:58:10,030 [foster.py] => SNet: Task 11, Epoch 12/130 => Loss 28.059,  Loss1 0.697, Train_accy 69.17
2024-08-31 18:58:17,076 [foster.py] => SNet: Task 11, Epoch 13/130 => Loss 28.029,  Loss1 0.697, Train_accy 69.46
2024-08-31 18:58:24,744 [foster.py] => SNet: Task 11, Epoch 14/130 => Loss 28.065,  Loss1 0.697, Train_accy 68.97
2024-08-31 18:58:31,995 [foster.py] => SNet: Task 11, Epoch 15/130 => Loss 28.015,  Loss1 0.697, Train_accy 69.80
2024-08-31 18:58:41,280 [foster.py] => SNet: Task 11, Epoch 16/130 => Loss 28.039,  Loss1 0.697, Train_accy 69.69, Test_accy 65.70
2024-08-31 18:58:48,393 [foster.py] => SNet: Task 11, Epoch 17/130 => Loss 28.023,  Loss1 0.696, Train_accy 70.29
2024-08-31 18:58:55,660 [foster.py] => SNet: Task 11, Epoch 18/130 => Loss 28.034,  Loss1 0.697, Train_accy 70.87
2024-08-31 18:59:02,734 [foster.py] => SNet: Task 11, Epoch 19/130 => Loss 28.006,  Loss1 0.697, Train_accy 71.47
2024-08-31 18:59:10,130 [foster.py] => SNet: Task 11, Epoch 20/130 => Loss 28.018,  Loss1 0.696, Train_accy 71.09
2024-08-31 18:59:19,412 [foster.py] => SNet: Task 11, Epoch 21/130 => Loss 28.003,  Loss1 0.696, Train_accy 73.08, Test_accy 65.93
2024-08-31 18:59:26,546 [foster.py] => SNet: Task 11, Epoch 22/130 => Loss 28.032,  Loss1 0.696, Train_accy 73.15
2024-08-31 18:59:33,715 [foster.py] => SNet: Task 11, Epoch 23/130 => Loss 28.012,  Loss1 0.696, Train_accy 71.83
2024-08-31 18:59:41,072 [foster.py] => SNet: Task 11, Epoch 24/130 => Loss 28.026,  Loss1 0.696, Train_accy 72.63
2024-08-31 18:59:48,207 [foster.py] => SNet: Task 11, Epoch 25/130 => Loss 28.011,  Loss1 0.696, Train_accy 73.48
2024-08-31 18:59:57,308 [foster.py] => SNet: Task 11, Epoch 26/130 => Loss 28.019,  Loss1 0.696, Train_accy 72.86, Test_accy 64.80
2024-08-31 19:00:04,517 [foster.py] => SNet: Task 11, Epoch 27/130 => Loss 27.989,  Loss1 0.696, Train_accy 71.96
2024-08-31 19:00:11,956 [foster.py] => SNet: Task 11, Epoch 28/130 => Loss 27.994,  Loss1 0.696, Train_accy 72.41
2024-08-31 19:00:19,285 [foster.py] => SNet: Task 11, Epoch 29/130 => Loss 28.013,  Loss1 0.696, Train_accy 73.21
2024-08-31 19:00:27,013 [foster.py] => SNet: Task 11, Epoch 30/130 => Loss 28.015,  Loss1 0.697, Train_accy 73.35
2024-08-31 19:00:35,918 [foster.py] => SNet: Task 11, Epoch 31/130 => Loss 27.993,  Loss1 0.696, Train_accy 74.20, Test_accy 66.27
2024-08-31 19:00:43,094 [foster.py] => SNet: Task 11, Epoch 32/130 => Loss 28.020,  Loss1 0.696, Train_accy 72.19
2024-08-31 19:00:50,125 [foster.py] => SNet: Task 11, Epoch 33/130 => Loss 28.011,  Loss1 0.696, Train_accy 74.22
2024-08-31 19:00:57,207 [foster.py] => SNet: Task 11, Epoch 34/130 => Loss 28.012,  Loss1 0.696, Train_accy 74.80
2024-08-31 19:01:04,190 [foster.py] => SNet: Task 11, Epoch 35/130 => Loss 28.012,  Loss1 0.696, Train_accy 74.06
2024-08-31 19:01:13,152 [foster.py] => SNet: Task 11, Epoch 36/130 => Loss 27.998,  Loss1 0.696, Train_accy 74.64, Test_accy 66.53
2024-08-31 19:01:20,289 [foster.py] => SNet: Task 11, Epoch 37/130 => Loss 28.012,  Loss1 0.696, Train_accy 74.29
2024-08-31 19:01:27,528 [foster.py] => SNet: Task 11, Epoch 38/130 => Loss 28.000,  Loss1 0.696, Train_accy 74.20
2024-08-31 19:01:34,722 [foster.py] => SNet: Task 11, Epoch 39/130 => Loss 27.985,  Loss1 0.696, Train_accy 75.13
2024-08-31 19:01:42,183 [foster.py] => SNet: Task 11, Epoch 40/130 => Loss 27.992,  Loss1 0.696, Train_accy 74.82
2024-08-31 19:01:51,189 [foster.py] => SNet: Task 11, Epoch 41/130 => Loss 27.992,  Loss1 0.696, Train_accy 74.38, Test_accy 65.82
2024-08-31 19:01:58,204 [foster.py] => SNet: Task 11, Epoch 42/130 => Loss 27.992,  Loss1 0.696, Train_accy 75.87
2024-08-31 19:02:05,511 [foster.py] => SNet: Task 11, Epoch 43/130 => Loss 27.956,  Loss1 0.696, Train_accy 74.33
2024-08-31 19:02:12,603 [foster.py] => SNet: Task 11, Epoch 44/130 => Loss 27.999,  Loss1 0.696, Train_accy 74.55
2024-08-31 19:02:19,881 [foster.py] => SNet: Task 11, Epoch 45/130 => Loss 28.021,  Loss1 0.696, Train_accy 74.78
2024-08-31 19:02:29,129 [foster.py] => SNet: Task 11, Epoch 46/130 => Loss 27.998,  Loss1 0.696, Train_accy 74.29, Test_accy 66.98
2024-08-31 19:02:36,343 [foster.py] => SNet: Task 11, Epoch 47/130 => Loss 27.999,  Loss1 0.696, Train_accy 76.27
2024-08-31 19:02:43,467 [foster.py] => SNet: Task 11, Epoch 48/130 => Loss 28.005,  Loss1 0.696, Train_accy 74.67
2024-08-31 19:02:50,581 [foster.py] => SNet: Task 11, Epoch 49/130 => Loss 27.998,  Loss1 0.696, Train_accy 74.93
2024-08-31 19:02:57,827 [foster.py] => SNet: Task 11, Epoch 50/130 => Loss 27.974,  Loss1 0.696, Train_accy 76.07
2024-08-31 19:03:06,915 [foster.py] => SNet: Task 11, Epoch 51/130 => Loss 27.985,  Loss1 0.696, Train_accy 75.33, Test_accy 67.07
2024-08-31 19:03:14,412 [foster.py] => SNet: Task 11, Epoch 52/130 => Loss 27.990,  Loss1 0.696, Train_accy 74.96
2024-08-31 19:03:21,770 [foster.py] => SNet: Task 11, Epoch 53/130 => Loss 27.992,  Loss1 0.696, Train_accy 76.16
2024-08-31 19:03:28,985 [foster.py] => SNet: Task 11, Epoch 54/130 => Loss 28.015,  Loss1 0.696, Train_accy 75.49
2024-08-31 19:03:36,520 [foster.py] => SNet: Task 11, Epoch 55/130 => Loss 28.000,  Loss1 0.696, Train_accy 76.50
2024-08-31 19:03:46,045 [foster.py] => SNet: Task 11, Epoch 56/130 => Loss 27.961,  Loss1 0.696, Train_accy 75.49, Test_accy 67.17
2024-08-31 19:03:53,347 [foster.py] => SNet: Task 11, Epoch 57/130 => Loss 27.955,  Loss1 0.696, Train_accy 76.72
2024-08-31 19:04:00,419 [foster.py] => SNet: Task 11, Epoch 58/130 => Loss 27.978,  Loss1 0.697, Train_accy 76.07
2024-08-31 19:04:07,540 [foster.py] => SNet: Task 11, Epoch 59/130 => Loss 27.999,  Loss1 0.696, Train_accy 76.65
2024-08-31 19:04:14,647 [foster.py] => SNet: Task 11, Epoch 60/130 => Loss 27.972,  Loss1 0.696, Train_accy 76.74
2024-08-31 19:04:23,877 [foster.py] => SNet: Task 11, Epoch 61/130 => Loss 27.996,  Loss1 0.696, Train_accy 76.52, Test_accy 67.78
2024-08-31 19:04:31,333 [foster.py] => SNet: Task 11, Epoch 62/130 => Loss 27.998,  Loss1 0.696, Train_accy 76.27
2024-08-31 19:04:38,713 [foster.py] => SNet: Task 11, Epoch 63/130 => Loss 27.956,  Loss1 0.696, Train_accy 75.89
2024-08-31 19:04:46,329 [foster.py] => SNet: Task 11, Epoch 64/130 => Loss 27.992,  Loss1 0.696, Train_accy 75.09
2024-08-31 19:04:53,625 [foster.py] => SNet: Task 11, Epoch 65/130 => Loss 27.986,  Loss1 0.696, Train_accy 76.65
2024-08-31 19:05:02,980 [foster.py] => SNet: Task 11, Epoch 66/130 => Loss 27.966,  Loss1 0.696, Train_accy 75.76, Test_accy 67.33
2024-08-31 19:05:10,128 [foster.py] => SNet: Task 11, Epoch 67/130 => Loss 27.993,  Loss1 0.696, Train_accy 76.96
2024-08-31 19:05:17,253 [foster.py] => SNet: Task 11, Epoch 68/130 => Loss 27.975,  Loss1 0.696, Train_accy 77.14
2024-08-31 19:05:24,587 [foster.py] => SNet: Task 11, Epoch 69/130 => Loss 27.947,  Loss1 0.696, Train_accy 77.05
2024-08-31 19:05:32,066 [foster.py] => SNet: Task 11, Epoch 70/130 => Loss 27.970,  Loss1 0.696, Train_accy 76.50
2024-08-31 19:05:41,030 [foster.py] => SNet: Task 11, Epoch 71/130 => Loss 28.008,  Loss1 0.696, Train_accy 76.92, Test_accy 67.33
2024-08-31 19:05:48,531 [foster.py] => SNet: Task 11, Epoch 72/130 => Loss 27.970,  Loss1 0.696, Train_accy 76.43
2024-08-31 19:05:55,577 [foster.py] => SNet: Task 11, Epoch 73/130 => Loss 27.971,  Loss1 0.696, Train_accy 76.41
2024-08-31 19:06:02,929 [foster.py] => SNet: Task 11, Epoch 74/130 => Loss 27.969,  Loss1 0.696, Train_accy 76.54
2024-08-31 19:06:09,954 [foster.py] => SNet: Task 11, Epoch 75/130 => Loss 27.996,  Loss1 0.696, Train_accy 77.17
2024-08-31 19:06:18,971 [foster.py] => SNet: Task 11, Epoch 76/130 => Loss 27.966,  Loss1 0.696, Train_accy 77.21, Test_accy 67.60
2024-08-31 19:06:26,387 [foster.py] => SNet: Task 11, Epoch 77/130 => Loss 27.977,  Loss1 0.696, Train_accy 77.03
2024-08-31 19:06:33,642 [foster.py] => SNet: Task 11, Epoch 78/130 => Loss 27.970,  Loss1 0.696, Train_accy 78.04
2024-08-31 19:06:41,021 [foster.py] => SNet: Task 11, Epoch 79/130 => Loss 27.965,  Loss1 0.696, Train_accy 77.10
2024-08-31 19:06:48,212 [foster.py] => SNet: Task 11, Epoch 80/130 => Loss 27.985,  Loss1 0.696, Train_accy 76.56
2024-08-31 19:06:57,136 [foster.py] => SNet: Task 11, Epoch 81/130 => Loss 27.996,  Loss1 0.695, Train_accy 78.15, Test_accy 67.92
2024-08-31 19:07:05,409 [foster.py] => SNet: Task 11, Epoch 82/130 => Loss 28.013,  Loss1 0.696, Train_accy 77.30
2024-08-31 19:07:12,846 [foster.py] => SNet: Task 11, Epoch 83/130 => Loss 27.997,  Loss1 0.696, Train_accy 77.34
2024-08-31 19:07:20,012 [foster.py] => SNet: Task 11, Epoch 84/130 => Loss 27.990,  Loss1 0.696, Train_accy 76.81
2024-08-31 19:07:27,234 [foster.py] => SNet: Task 11, Epoch 85/130 => Loss 27.961,  Loss1 0.696, Train_accy 76.58
2024-08-31 19:07:36,550 [foster.py] => SNet: Task 11, Epoch 86/130 => Loss 27.978,  Loss1 0.696, Train_accy 77.97, Test_accy 67.58
2024-08-31 19:07:43,737 [foster.py] => SNet: Task 11, Epoch 87/130 => Loss 27.954,  Loss1 0.696, Train_accy 76.61
2024-08-31 19:07:51,128 [foster.py] => SNet: Task 11, Epoch 88/130 => Loss 27.982,  Loss1 0.696, Train_accy 77.63
2024-08-31 19:07:58,225 [foster.py] => SNet: Task 11, Epoch 89/130 => Loss 27.976,  Loss1 0.696, Train_accy 77.32
2024-08-31 19:08:05,476 [foster.py] => SNet: Task 11, Epoch 90/130 => Loss 27.959,  Loss1 0.696, Train_accy 77.23
2024-08-31 19:08:14,417 [foster.py] => SNet: Task 11, Epoch 91/130 => Loss 27.968,  Loss1 0.696, Train_accy 77.59, Test_accy 67.72
2024-08-31 19:08:21,705 [foster.py] => SNet: Task 11, Epoch 92/130 => Loss 27.960,  Loss1 0.696, Train_accy 77.52
2024-08-31 19:08:29,410 [foster.py] => SNet: Task 11, Epoch 93/130 => Loss 27.952,  Loss1 0.696, Train_accy 78.33
2024-08-31 19:08:36,915 [foster.py] => SNet: Task 11, Epoch 94/130 => Loss 27.983,  Loss1 0.696, Train_accy 78.91
2024-08-31 19:08:44,077 [foster.py] => SNet: Task 11, Epoch 95/130 => Loss 27.985,  Loss1 0.696, Train_accy 77.32
2024-08-31 19:08:53,009 [foster.py] => SNet: Task 11, Epoch 96/130 => Loss 27.975,  Loss1 0.696, Train_accy 77.63, Test_accy 67.25
2024-08-31 19:09:00,403 [foster.py] => SNet: Task 11, Epoch 97/130 => Loss 27.954,  Loss1 0.696, Train_accy 79.46
2024-08-31 19:09:07,601 [foster.py] => SNet: Task 11, Epoch 98/130 => Loss 27.971,  Loss1 0.696, Train_accy 77.50
2024-08-31 19:09:14,988 [foster.py] => SNet: Task 11, Epoch 99/130 => Loss 27.988,  Loss1 0.696, Train_accy 77.75
2024-08-31 19:09:22,324 [foster.py] => SNet: Task 11, Epoch 100/130 => Loss 27.952,  Loss1 0.696, Train_accy 77.66
2024-08-31 19:09:31,480 [foster.py] => SNet: Task 11, Epoch 101/130 => Loss 27.961,  Loss1 0.696, Train_accy 78.66, Test_accy 67.55
2024-08-31 19:09:38,769 [foster.py] => SNet: Task 11, Epoch 102/130 => Loss 27.940,  Loss1 0.695, Train_accy 77.97
2024-08-31 19:09:46,128 [foster.py] => SNet: Task 11, Epoch 103/130 => Loss 27.972,  Loss1 0.696, Train_accy 77.30
2024-08-31 19:09:53,358 [foster.py] => SNet: Task 11, Epoch 104/130 => Loss 27.972,  Loss1 0.696, Train_accy 78.08
2024-08-31 19:10:00,907 [foster.py] => SNet: Task 11, Epoch 105/130 => Loss 27.976,  Loss1 0.696, Train_accy 77.48
2024-08-31 19:10:09,953 [foster.py] => SNet: Task 11, Epoch 106/130 => Loss 27.981,  Loss1 0.696, Train_accy 78.19, Test_accy 67.53
2024-08-31 19:10:17,347 [foster.py] => SNet: Task 11, Epoch 107/130 => Loss 27.973,  Loss1 0.696, Train_accy 77.86
2024-08-31 19:10:24,866 [foster.py] => SNet: Task 11, Epoch 108/130 => Loss 27.971,  Loss1 0.696, Train_accy 77.32
2024-08-31 19:10:32,426 [foster.py] => SNet: Task 11, Epoch 109/130 => Loss 27.970,  Loss1 0.696, Train_accy 76.85
2024-08-31 19:10:39,805 [foster.py] => SNet: Task 11, Epoch 110/130 => Loss 27.954,  Loss1 0.696, Train_accy 78.17
2024-08-31 19:10:49,107 [foster.py] => SNet: Task 11, Epoch 111/130 => Loss 27.963,  Loss1 0.695, Train_accy 78.91, Test_accy 67.55
2024-08-31 19:10:56,367 [foster.py] => SNet: Task 11, Epoch 112/130 => Loss 27.970,  Loss1 0.695, Train_accy 78.42
2024-08-31 19:11:03,606 [foster.py] => SNet: Task 11, Epoch 113/130 => Loss 27.956,  Loss1 0.696, Train_accy 78.15
2024-08-31 19:11:10,941 [foster.py] => SNet: Task 11, Epoch 114/130 => Loss 27.951,  Loss1 0.696, Train_accy 76.74
2024-08-31 19:11:18,123 [foster.py] => SNet: Task 11, Epoch 115/130 => Loss 27.986,  Loss1 0.696, Train_accy 78.24
2024-08-31 19:11:27,293 [foster.py] => SNet: Task 11, Epoch 116/130 => Loss 27.970,  Loss1 0.696, Train_accy 78.62, Test_accy 67.57
2024-08-31 19:11:34,564 [foster.py] => SNet: Task 11, Epoch 117/130 => Loss 27.959,  Loss1 0.696, Train_accy 78.04
2024-08-31 19:11:41,983 [foster.py] => SNet: Task 11, Epoch 118/130 => Loss 28.019,  Loss1 0.696, Train_accy 78.35
2024-08-31 19:11:49,148 [foster.py] => SNet: Task 11, Epoch 119/130 => Loss 27.941,  Loss1 0.696, Train_accy 77.79
2024-08-31 19:11:56,257 [foster.py] => SNet: Task 11, Epoch 120/130 => Loss 27.993,  Loss1 0.696, Train_accy 77.17
2024-08-31 19:12:05,778 [foster.py] => SNet: Task 11, Epoch 121/130 => Loss 27.949,  Loss1 0.696, Train_accy 79.00, Test_accy 67.75
2024-08-31 19:12:12,934 [foster.py] => SNet: Task 11, Epoch 122/130 => Loss 27.956,  Loss1 0.696, Train_accy 77.54
2024-08-31 19:12:20,321 [foster.py] => SNet: Task 11, Epoch 123/130 => Loss 27.996,  Loss1 0.695, Train_accy 79.00
2024-08-31 19:12:28,022 [foster.py] => SNet: Task 11, Epoch 124/130 => Loss 28.001,  Loss1 0.696, Train_accy 77.50
2024-08-31 19:12:35,245 [foster.py] => SNet: Task 11, Epoch 125/130 => Loss 27.953,  Loss1 0.696, Train_accy 78.88
2024-08-31 19:12:44,571 [foster.py] => SNet: Task 11, Epoch 126/130 => Loss 28.000,  Loss1 0.696, Train_accy 77.43, Test_accy 67.63
2024-08-31 19:12:51,597 [foster.py] => SNet: Task 11, Epoch 127/130 => Loss 27.949,  Loss1 0.696, Train_accy 78.75
2024-08-31 19:12:58,966 [foster.py] => SNet: Task 11, Epoch 128/130 => Loss 27.994,  Loss1 0.696, Train_accy 77.90
2024-08-31 19:13:06,415 [foster.py] => SNet: Task 11, Epoch 129/130 => Loss 27.980,  Loss1 0.696, Train_accy 78.26
2024-08-31 19:13:13,499 [foster.py] => SNet: Task 11, Epoch 130/130 => Loss 27.964,  Loss1 0.696, Train_accy 78.12
2024-08-31 19:13:13,500 [foster.py] => do not weight align student!
2024-08-31 19:13:15,432 [foster.py] => darknet eval: 
2024-08-31 19:13:15,432 [foster.py] => CNN top1 curve: 67.73
2024-08-31 19:13:15,432 [foster.py] => CNN top5 curve: 90.65
2024-08-31 19:13:15,433 [foster.py] => CNN top1 平均值: 67.73
2024-08-31 19:13:15,436 [foster.py] => timees : 2190.179241657257
2024-08-31 19:13:15,437 [base.py] => Reducing exemplars...(33 per classes)
2024-08-31 19:13:34,551 [base.py] => Constructing exemplars...(33 per classes)
2024-08-31 19:13:44,059 [foster.py] => Exemplar size: 1980
2024-08-31 19:13:44,060 [trainer.py] => CNN: {'total': 69.45, '00-09': 71.9, '10-19': 55.2, '20-29': 66.8, '30-39': 67.8, '40-49': 77.1, '50-59': 77.9, 'old': 68.62, 'new': 78.6}
2024-08-31 19:13:44,060 [trainer.py] => NME: {'total': 64.53, '00-09': 64.1, '10-19': 49.6, '20-29': 65.4, '30-39': 64.8, '40-49': 74.0, '50-59': 69.3, 'old': 63.27, 'new': 78.4}
2024-08-31 19:13:44,060 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45]
2024-08-31 19:13:44,060 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43]
2024-08-31 19:13:44,060 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53]
2024-08-31 19:13:44,060 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28]

2024-08-31 19:13:44,060 [trainer.py] => CNN top1 平均值: 80.55
2024-08-31 19:13:44,063 [trainer.py] => All params: 1297763
2024-08-31 19:13:44,065 [trainer.py] => Trainable params: 652914
2024-08-31 19:13:44,128 [foster.py] => Learning on 60-65
2024-08-31 19:13:44,132 [foster.py] => All params: 1299058
2024-08-31 19:13:44,134 [foster.py] => Trainable params: 653884
2024-08-31 19:13:44,184 [foster.py] => per cls weights : [1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797 1.01812797
 0.78246438 0.78246438 0.78246438 0.78246438 0.78246438]
2024-08-31 19:13:49,620 [foster.py] => Task 12, Epoch 1/170 => Loss 7.407, Loss_clf 2.818, Loss_fe 1.866, Loss_kd 2.506, Train_accy 51.61
2024-08-31 19:13:57,133 [foster.py] => Task 12, Epoch 2/170 => Loss 5.112, Loss_clf 1.230, Loss_fe 1.211, Loss_kd 2.458, Train_accy 67.79, Test_accy 64.72
2024-08-31 19:14:04,571 [foster.py] => Task 12, Epoch 3/170 => Loss 4.744, Loss_clf 1.032, Loss_fe 1.048, Loss_kd 2.452, Train_accy 70.47, Test_accy 63.97
2024-08-31 19:14:12,066 [foster.py] => Task 12, Epoch 4/170 => Loss 4.594, Loss_clf 0.982, Loss_fe 0.960, Loss_kd 2.442, Train_accy 70.36, Test_accy 63.32
2024-08-31 19:14:19,662 [foster.py] => Task 12, Epoch 5/170 => Loss 4.554, Loss_clf 0.987, Loss_fe 0.905, Loss_kd 2.451, Train_accy 70.67, Test_accy 65.42
2024-08-31 19:14:24,995 [foster.py] => Task 12, Epoch 6/170 => Loss 4.613, Loss_clf 1.010, Loss_fe 0.933, Loss_kd 2.458, Train_accy 71.12
2024-08-31 19:14:32,476 [foster.py] => Task 12, Epoch 7/170 => Loss 4.524, Loss_clf 0.982, Loss_fe 0.889, Loss_kd 2.443, Train_accy 71.83, Test_accy 64.08
2024-08-31 19:14:39,944 [foster.py] => Task 12, Epoch 8/170 => Loss 4.637, Loss_clf 1.017, Loss_fe 0.937, Loss_kd 2.470, Train_accy 69.93, Test_accy 64.95
2024-08-31 19:14:47,415 [foster.py] => Task 12, Epoch 9/170 => Loss 4.532, Loss_clf 0.969, Loss_fe 0.898, Loss_kd 2.454, Train_accy 72.10, Test_accy 59.77
2024-08-31 19:14:54,854 [foster.py] => Task 12, Epoch 10/170 => Loss 4.460, Loss_clf 0.926, Loss_fe 0.866, Loss_kd 2.456, Train_accy 71.94, Test_accy 64.57
2024-08-31 19:15:00,108 [foster.py] => Task 12, Epoch 11/170 => Loss 4.532, Loss_clf 0.991, Loss_fe 0.875, Loss_kd 2.455, Train_accy 70.04
2024-08-31 19:15:07,620 [foster.py] => Task 12, Epoch 12/170 => Loss 4.501, Loss_clf 0.971, Loss_fe 0.875, Loss_kd 2.445, Train_accy 72.23, Test_accy 61.60
2024-08-31 19:15:15,131 [foster.py] => Task 12, Epoch 13/170 => Loss 4.485, Loss_clf 0.946, Loss_fe 0.874, Loss_kd 2.455, Train_accy 72.57, Test_accy 63.29
2024-08-31 19:15:22,663 [foster.py] => Task 12, Epoch 14/170 => Loss 4.479, Loss_clf 0.965, Loss_fe 0.851, Loss_kd 2.453, Train_accy 71.76, Test_accy 61.11
2024-08-31 19:15:30,096 [foster.py] => Task 12, Epoch 15/170 => Loss 4.580, Loss_clf 0.979, Loss_fe 0.922, Loss_kd 2.468, Train_accy 71.05, Test_accy 64.09
2024-08-31 19:15:35,362 [foster.py] => Task 12, Epoch 16/170 => Loss 4.479, Loss_clf 0.957, Loss_fe 0.866, Loss_kd 2.446, Train_accy 71.67
2024-08-31 19:15:42,912 [foster.py] => Task 12, Epoch 17/170 => Loss 4.513, Loss_clf 0.958, Loss_fe 0.886, Loss_kd 2.459, Train_accy 71.34, Test_accy 61.26
2024-08-31 19:15:50,404 [foster.py] => Task 12, Epoch 18/170 => Loss 4.555, Loss_clf 0.987, Loss_fe 0.907, Loss_kd 2.451, Train_accy 70.96, Test_accy 62.02
2024-08-31 19:15:57,900 [foster.py] => Task 12, Epoch 19/170 => Loss 4.514, Loss_clf 0.953, Loss_fe 0.889, Loss_kd 2.460, Train_accy 71.41, Test_accy 62.40
2024-08-31 19:16:05,427 [foster.py] => Task 12, Epoch 20/170 => Loss 4.403, Loss_clf 0.890, Loss_fe 0.864, Loss_kd 2.440, Train_accy 72.25, Test_accy 64.00
2024-08-31 19:16:10,788 [foster.py] => Task 12, Epoch 21/170 => Loss 4.456, Loss_clf 0.942, Loss_fe 0.853, Loss_kd 2.451, Train_accy 71.50
2024-08-31 19:16:18,402 [foster.py] => Task 12, Epoch 22/170 => Loss 4.489, Loss_clf 0.911, Loss_fe 0.894, Loss_kd 2.471, Train_accy 72.68, Test_accy 64.02
2024-08-31 19:16:25,892 [foster.py] => Task 12, Epoch 23/170 => Loss 4.391, Loss_clf 0.894, Loss_fe 0.850, Loss_kd 2.438, Train_accy 72.52, Test_accy 64.40
2024-08-31 19:16:33,396 [foster.py] => Task 12, Epoch 24/170 => Loss 4.518, Loss_clf 0.956, Loss_fe 0.897, Loss_kd 2.455, Train_accy 72.19, Test_accy 63.88
2024-08-31 19:16:40,934 [foster.py] => Task 12, Epoch 25/170 => Loss 4.401, Loss_clf 0.879, Loss_fe 0.860, Loss_kd 2.452, Train_accy 72.52, Test_accy 63.34
2024-08-31 19:16:46,197 [foster.py] => Task 12, Epoch 26/170 => Loss 4.448, Loss_clf 0.933, Loss_fe 0.844, Loss_kd 2.460, Train_accy 72.39
2024-08-31 19:16:53,717 [foster.py] => Task 12, Epoch 27/170 => Loss 4.391, Loss_clf 0.883, Loss_fe 0.850, Loss_kd 2.448, Train_accy 72.61, Test_accy 65.12
2024-08-31 19:17:01,139 [foster.py] => Task 12, Epoch 28/170 => Loss 4.383, Loss_clf 0.872, Loss_fe 0.850, Loss_kd 2.451, Train_accy 72.77, Test_accy 63.74
2024-08-31 19:17:08,705 [foster.py] => Task 12, Epoch 29/170 => Loss 4.455, Loss_clf 0.937, Loss_fe 0.856, Loss_kd 2.452, Train_accy 72.50, Test_accy 60.88
2024-08-31 19:17:16,131 [foster.py] => Task 12, Epoch 30/170 => Loss 4.396, Loss_clf 0.895, Loss_fe 0.847, Loss_kd 2.445, Train_accy 73.04, Test_accy 64.12
2024-08-31 19:17:21,434 [foster.py] => Task 12, Epoch 31/170 => Loss 4.356, Loss_clf 0.871, Loss_fe 0.816, Loss_kd 2.459, Train_accy 72.34
2024-08-31 19:17:28,897 [foster.py] => Task 12, Epoch 32/170 => Loss 4.387, Loss_clf 0.891, Loss_fe 0.835, Loss_kd 2.451, Train_accy 72.95, Test_accy 64.69
2024-08-31 19:17:36,346 [foster.py] => Task 12, Epoch 33/170 => Loss 4.489, Loss_clf 0.954, Loss_fe 0.865, Loss_kd 2.459, Train_accy 71.38, Test_accy 64.91
2024-08-31 19:17:43,926 [foster.py] => Task 12, Epoch 34/170 => Loss 4.499, Loss_clf 0.965, Loss_fe 0.857, Loss_kd 2.466, Train_accy 70.98, Test_accy 65.20
2024-08-31 19:17:51,436 [foster.py] => Task 12, Epoch 35/170 => Loss 4.534, Loss_clf 0.965, Loss_fe 0.897, Loss_kd 2.462, Train_accy 70.22, Test_accy 65.22
2024-08-31 19:17:56,674 [foster.py] => Task 12, Epoch 36/170 => Loss 4.413, Loss_clf 0.890, Loss_fe 0.839, Loss_kd 2.473, Train_accy 72.39
2024-08-31 19:18:04,160 [foster.py] => Task 12, Epoch 37/170 => Loss 4.437, Loss_clf 0.923, Loss_fe 0.830, Loss_kd 2.472, Train_accy 71.00, Test_accy 65.88
2024-08-31 19:18:11,626 [foster.py] => Task 12, Epoch 38/170 => Loss 4.423, Loss_clf 0.927, Loss_fe 0.832, Loss_kd 2.454, Train_accy 71.56, Test_accy 65.32
2024-08-31 19:18:19,099 [foster.py] => Task 12, Epoch 39/170 => Loss 4.432, Loss_clf 0.923, Loss_fe 0.851, Loss_kd 2.448, Train_accy 71.88, Test_accy 55.46
2024-08-31 19:18:26,673 [foster.py] => Task 12, Epoch 40/170 => Loss 4.400, Loss_clf 0.899, Loss_fe 0.842, Loss_kd 2.450, Train_accy 72.25, Test_accy 63.60
2024-08-31 19:18:32,015 [foster.py] => Task 12, Epoch 41/170 => Loss 4.327, Loss_clf 0.849, Loss_fe 0.818, Loss_kd 2.450, Train_accy 73.08
2024-08-31 19:18:39,609 [foster.py] => Task 12, Epoch 42/170 => Loss 4.411, Loss_clf 0.922, Loss_fe 0.833, Loss_kd 2.447, Train_accy 72.66, Test_accy 63.32
2024-08-31 19:18:47,119 [foster.py] => Task 12, Epoch 43/170 => Loss 4.480, Loss_clf 0.939, Loss_fe 0.881, Loss_kd 2.450, Train_accy 70.54, Test_accy 64.35
2024-08-31 19:18:54,624 [foster.py] => Task 12, Epoch 44/170 => Loss 4.333, Loss_clf 0.871, Loss_fe 0.789, Loss_kd 2.463, Train_accy 74.24, Test_accy 65.78
2024-08-31 19:19:02,118 [foster.py] => Task 12, Epoch 45/170 => Loss 4.309, Loss_clf 0.837, Loss_fe 0.807, Loss_kd 2.454, Train_accy 73.57, Test_accy 63.94
2024-08-31 19:19:07,530 [foster.py] => Task 12, Epoch 46/170 => Loss 4.372, Loss_clf 0.889, Loss_fe 0.810, Loss_kd 2.463, Train_accy 72.81
2024-08-31 19:19:15,013 [foster.py] => Task 12, Epoch 47/170 => Loss 4.406, Loss_clf 0.915, Loss_fe 0.819, Loss_kd 2.461, Train_accy 72.99, Test_accy 59.05
2024-08-31 19:19:22,557 [foster.py] => Task 12, Epoch 48/170 => Loss 4.387, Loss_clf 0.893, Loss_fe 0.837, Loss_kd 2.448, Train_accy 72.88, Test_accy 62.63
2024-08-31 19:19:30,092 [foster.py] => Task 12, Epoch 49/170 => Loss 4.325, Loss_clf 0.857, Loss_fe 0.795, Loss_kd 2.463, Train_accy 73.50, Test_accy 63.77
2024-08-31 19:19:37,621 [foster.py] => Task 12, Epoch 50/170 => Loss 4.348, Loss_clf 0.851, Loss_fe 0.834, Loss_kd 2.452, Train_accy 73.37, Test_accy 64.86
2024-08-31 19:19:42,830 [foster.py] => Task 12, Epoch 51/170 => Loss 4.368, Loss_clf 0.909, Loss_fe 0.802, Loss_kd 2.448, Train_accy 72.32
2024-08-31 19:19:50,435 [foster.py] => Task 12, Epoch 52/170 => Loss 4.363, Loss_clf 0.883, Loss_fe 0.827, Loss_kd 2.444, Train_accy 72.30, Test_accy 64.63
2024-08-31 19:19:57,945 [foster.py] => Task 12, Epoch 53/170 => Loss 4.270, Loss_clf 0.823, Loss_fe 0.790, Loss_kd 2.447, Train_accy 74.49, Test_accy 64.95
2024-08-31 19:20:05,505 [foster.py] => Task 12, Epoch 54/170 => Loss 4.284, Loss_clf 0.825, Loss_fe 0.799, Loss_kd 2.450, Train_accy 73.62, Test_accy 64.58
2024-08-31 19:20:12,968 [foster.py] => Task 12, Epoch 55/170 => Loss 4.247, Loss_clf 0.810, Loss_fe 0.771, Loss_kd 2.456, Train_accy 74.46, Test_accy 63.20
2024-08-31 19:20:18,251 [foster.py] => Task 12, Epoch 56/170 => Loss 4.293, Loss_clf 0.826, Loss_fe 0.803, Loss_kd 2.454, Train_accy 73.17
2024-08-31 19:20:25,720 [foster.py] => Task 12, Epoch 57/170 => Loss 4.257, Loss_clf 0.825, Loss_fe 0.784, Loss_kd 2.439, Train_accy 73.24, Test_accy 66.02
2024-08-31 19:20:33,193 [foster.py] => Task 12, Epoch 58/170 => Loss 4.333, Loss_clf 0.876, Loss_fe 0.775, Loss_kd 2.470, Train_accy 73.33, Test_accy 64.72
2024-08-31 19:20:40,732 [foster.py] => Task 12, Epoch 59/170 => Loss 4.355, Loss_clf 0.868, Loss_fe 0.811, Loss_kd 2.465, Train_accy 73.39, Test_accy 62.28
2024-08-31 19:20:48,253 [foster.py] => Task 12, Epoch 60/170 => Loss 4.326, Loss_clf 0.871, Loss_fe 0.790, Loss_kd 2.456, Train_accy 72.54, Test_accy 60.17
2024-08-31 19:20:53,475 [foster.py] => Task 12, Epoch 61/170 => Loss 4.285, Loss_clf 0.862, Loss_fe 0.770, Loss_kd 2.445, Train_accy 73.55
2024-08-31 19:21:00,939 [foster.py] => Task 12, Epoch 62/170 => Loss 4.333, Loss_clf 0.885, Loss_fe 0.788, Loss_kd 2.451, Train_accy 73.17, Test_accy 64.75
2024-08-31 19:21:08,501 [foster.py] => Task 12, Epoch 63/170 => Loss 4.275, Loss_clf 0.839, Loss_fe 0.782, Loss_kd 2.445, Train_accy 74.40, Test_accy 63.18
2024-08-31 19:21:15,962 [foster.py] => Task 12, Epoch 64/170 => Loss 4.286, Loss_clf 0.846, Loss_fe 0.778, Loss_kd 2.453, Train_accy 73.79, Test_accy 65.32
2024-08-31 19:21:23,432 [foster.py] => Task 12, Epoch 65/170 => Loss 4.304, Loss_clf 0.857, Loss_fe 0.777, Loss_kd 2.460, Train_accy 72.43, Test_accy 64.00
2024-08-31 19:21:28,662 [foster.py] => Task 12, Epoch 66/170 => Loss 4.273, Loss_clf 0.857, Loss_fe 0.754, Loss_kd 2.452, Train_accy 73.95
2024-08-31 19:21:36,126 [foster.py] => Task 12, Epoch 67/170 => Loss 4.265, Loss_clf 0.848, Loss_fe 0.769, Loss_kd 2.439, Train_accy 72.46, Test_accy 64.92
2024-08-31 19:21:43,707 [foster.py] => Task 12, Epoch 68/170 => Loss 4.234, Loss_clf 0.816, Loss_fe 0.746, Loss_kd 2.461, Train_accy 74.84, Test_accy 65.42
2024-08-31 19:21:51,174 [foster.py] => Task 12, Epoch 69/170 => Loss 4.239, Loss_clf 0.825, Loss_fe 0.760, Loss_kd 2.445, Train_accy 74.35, Test_accy 64.94
2024-08-31 19:21:58,735 [foster.py] => Task 12, Epoch 70/170 => Loss 4.145, Loss_clf 0.796, Loss_fe 0.699, Loss_kd 2.441, Train_accy 74.93, Test_accy 65.38
2024-08-31 19:22:04,012 [foster.py] => Task 12, Epoch 71/170 => Loss 4.157, Loss_clf 0.774, Loss_fe 0.731, Loss_kd 2.444, Train_accy 75.20
2024-08-31 19:22:11,492 [foster.py] => Task 12, Epoch 72/170 => Loss 4.227, Loss_clf 0.796, Loss_fe 0.763, Loss_kd 2.458, Train_accy 74.02, Test_accy 63.54
2024-08-31 19:22:19,052 [foster.py] => Task 12, Epoch 73/170 => Loss 4.194, Loss_clf 0.796, Loss_fe 0.723, Loss_kd 2.465, Train_accy 74.42, Test_accy 64.25
2024-08-31 19:22:26,605 [foster.py] => Task 12, Epoch 74/170 => Loss 4.128, Loss_clf 0.780, Loss_fe 0.703, Loss_kd 2.436, Train_accy 74.91, Test_accy 65.51
2024-08-31 19:22:34,115 [foster.py] => Task 12, Epoch 75/170 => Loss 4.205, Loss_clf 0.823, Loss_fe 0.720, Loss_kd 2.453, Train_accy 74.49, Test_accy 63.80
2024-08-31 19:22:39,491 [foster.py] => Task 12, Epoch 76/170 => Loss 4.255, Loss_clf 0.873, Loss_fe 0.725, Loss_kd 2.449, Train_accy 73.79
2024-08-31 19:22:46,970 [foster.py] => Task 12, Epoch 77/170 => Loss 4.285, Loss_clf 0.832, Loss_fe 0.770, Loss_kd 2.472, Train_accy 74.64, Test_accy 64.85
2024-08-31 19:22:54,422 [foster.py] => Task 12, Epoch 78/170 => Loss 4.165, Loss_clf 0.803, Loss_fe 0.723, Loss_kd 2.430, Train_accy 74.82, Test_accy 65.18
2024-08-31 19:23:01,912 [foster.py] => Task 12, Epoch 79/170 => Loss 4.100, Loss_clf 0.776, Loss_fe 0.681, Loss_kd 2.435, Train_accy 74.53, Test_accy 65.49
2024-08-31 19:23:09,439 [foster.py] => Task 12, Epoch 80/170 => Loss 4.162, Loss_clf 0.801, Loss_fe 0.715, Loss_kd 2.437, Train_accy 75.20, Test_accy 64.65
2024-08-31 19:23:14,782 [foster.py] => Task 12, Epoch 81/170 => Loss 4.231, Loss_clf 0.837, Loss_fe 0.720, Loss_kd 2.463, Train_accy 73.35
2024-08-31 19:23:22,308 [foster.py] => Task 12, Epoch 82/170 => Loss 4.176, Loss_clf 0.803, Loss_fe 0.709, Loss_kd 2.454, Train_accy 74.26, Test_accy 66.52
2024-08-31 19:23:29,757 [foster.py] => Task 12, Epoch 83/170 => Loss 4.152, Loss_clf 0.779, Loss_fe 0.718, Loss_kd 2.446, Train_accy 74.44, Test_accy 64.18
2024-08-31 19:23:37,209 [foster.py] => Task 12, Epoch 84/170 => Loss 4.143, Loss_clf 0.791, Loss_fe 0.693, Loss_kd 2.449, Train_accy 75.29, Test_accy 65.38
2024-08-31 19:23:44,718 [foster.py] => Task 12, Epoch 85/170 => Loss 4.154, Loss_clf 0.787, Loss_fe 0.697, Loss_kd 2.460, Train_accy 75.36, Test_accy 65.43
2024-08-31 19:23:50,012 [foster.py] => Task 12, Epoch 86/170 => Loss 4.140, Loss_clf 0.784, Loss_fe 0.694, Loss_kd 2.452, Train_accy 75.18
2024-08-31 19:23:57,514 [foster.py] => Task 12, Epoch 87/170 => Loss 4.117, Loss_clf 0.777, Loss_fe 0.672, Loss_kd 2.458, Train_accy 75.18, Test_accy 66.43
2024-08-31 19:24:04,955 [foster.py] => Task 12, Epoch 88/170 => Loss 4.054, Loss_clf 0.743, Loss_fe 0.673, Loss_kd 2.431, Train_accy 75.87, Test_accy 65.83
2024-08-31 19:24:12,489 [foster.py] => Task 12, Epoch 89/170 => Loss 4.069, Loss_clf 0.761, Loss_fe 0.656, Loss_kd 2.443, Train_accy 76.09, Test_accy 66.72
2024-08-31 19:24:20,006 [foster.py] => Task 12, Epoch 90/170 => Loss 4.162, Loss_clf 0.793, Loss_fe 0.696, Loss_kd 2.464, Train_accy 75.56, Test_accy 65.48
2024-08-31 19:24:25,249 [foster.py] => Task 12, Epoch 91/170 => Loss 4.081, Loss_clf 0.747, Loss_fe 0.661, Loss_kd 2.462, Train_accy 76.32
2024-08-31 19:24:32,710 [foster.py] => Task 12, Epoch 92/170 => Loss 4.017, Loss_clf 0.728, Loss_fe 0.641, Loss_kd 2.439, Train_accy 76.74, Test_accy 65.95
2024-08-31 19:24:40,164 [foster.py] => Task 12, Epoch 93/170 => Loss 4.058, Loss_clf 0.743, Loss_fe 0.653, Loss_kd 2.453, Train_accy 75.74, Test_accy 65.77
2024-08-31 19:24:47,724 [foster.py] => Task 12, Epoch 94/170 => Loss 4.017, Loss_clf 0.720, Loss_fe 0.651, Loss_kd 2.437, Train_accy 77.72, Test_accy 65.97
2024-08-31 19:24:55,234 [foster.py] => Task 12, Epoch 95/170 => Loss 4.032, Loss_clf 0.733, Loss_fe 0.651, Loss_kd 2.440, Train_accy 75.85, Test_accy 67.14
2024-08-31 19:25:00,438 [foster.py] => Task 12, Epoch 96/170 => Loss 4.057, Loss_clf 0.773, Loss_fe 0.624, Loss_kd 2.451, Train_accy 76.25
2024-08-31 19:25:07,865 [foster.py] => Task 12, Epoch 97/170 => Loss 4.013, Loss_clf 0.727, Loss_fe 0.633, Loss_kd 2.444, Train_accy 76.32, Test_accy 65.68
2024-08-31 19:25:15,327 [foster.py] => Task 12, Epoch 98/170 => Loss 4.072, Loss_clf 0.773, Loss_fe 0.639, Loss_kd 2.452, Train_accy 76.00, Test_accy 64.98
2024-08-31 19:25:22,777 [foster.py] => Task 12, Epoch 99/170 => Loss 4.010, Loss_clf 0.729, Loss_fe 0.627, Loss_kd 2.445, Train_accy 75.83, Test_accy 66.32
2024-08-31 19:25:30,229 [foster.py] => Task 12, Epoch 100/170 => Loss 3.990, Loss_clf 0.733, Loss_fe 0.622, Loss_kd 2.428, Train_accy 76.52, Test_accy 66.68
2024-08-31 19:25:35,409 [foster.py] => Task 12, Epoch 101/170 => Loss 4.031, Loss_clf 0.740, Loss_fe 0.616, Loss_kd 2.465, Train_accy 77.21
2024-08-31 19:25:42,875 [foster.py] => Task 12, Epoch 102/170 => Loss 4.019, Loss_clf 0.745, Loss_fe 0.616, Loss_kd 2.449, Train_accy 76.21, Test_accy 64.66
2024-08-31 19:25:50,422 [foster.py] => Task 12, Epoch 103/170 => Loss 4.054, Loss_clf 0.753, Loss_fe 0.635, Loss_kd 2.457, Train_accy 77.41, Test_accy 65.45
2024-08-31 19:25:57,877 [foster.py] => Task 12, Epoch 104/170 => Loss 3.965, Loss_clf 0.714, Loss_fe 0.589, Loss_kd 2.451, Train_accy 76.27, Test_accy 65.40
2024-08-31 19:26:05,334 [foster.py] => Task 12, Epoch 105/170 => Loss 3.952, Loss_clf 0.702, Loss_fe 0.594, Loss_kd 2.447, Train_accy 77.61, Test_accy 65.71
2024-08-31 19:26:10,560 [foster.py] => Task 12, Epoch 106/170 => Loss 3.942, Loss_clf 0.704, Loss_fe 0.577, Loss_kd 2.451, Train_accy 77.83
2024-08-31 19:26:18,037 [foster.py] => Task 12, Epoch 107/170 => Loss 3.938, Loss_clf 0.707, Loss_fe 0.571, Loss_kd 2.451, Train_accy 77.57, Test_accy 65.68
2024-08-31 19:26:25,591 [foster.py] => Task 12, Epoch 108/170 => Loss 3.956, Loss_clf 0.712, Loss_fe 0.590, Loss_kd 2.446, Train_accy 77.48, Test_accy 65.66
2024-08-31 19:26:33,128 [foster.py] => Task 12, Epoch 109/170 => Loss 3.952, Loss_clf 0.705, Loss_fe 0.580, Loss_kd 2.458, Train_accy 77.86, Test_accy 66.69
2024-08-31 19:26:40,596 [foster.py] => Task 12, Epoch 110/170 => Loss 3.934, Loss_clf 0.708, Loss_fe 0.573, Loss_kd 2.444, Train_accy 77.70, Test_accy 66.91
2024-08-31 19:26:45,918 [foster.py] => Task 12, Epoch 111/170 => Loss 3.898, Loss_clf 0.689, Loss_fe 0.560, Loss_kd 2.440, Train_accy 78.64
2024-08-31 19:26:53,392 [foster.py] => Task 12, Epoch 112/170 => Loss 3.854, Loss_clf 0.666, Loss_fe 0.544, Loss_kd 2.436, Train_accy 78.50, Test_accy 66.68
2024-08-31 19:27:00,936 [foster.py] => Task 12, Epoch 113/170 => Loss 3.864, Loss_clf 0.672, Loss_fe 0.540, Loss_kd 2.444, Train_accy 78.62, Test_accy 67.48
2024-08-31 19:27:08,422 [foster.py] => Task 12, Epoch 114/170 => Loss 3.839, Loss_clf 0.651, Loss_fe 0.540, Loss_kd 2.440, Train_accy 79.96, Test_accy 66.02
2024-08-31 19:27:15,933 [foster.py] => Task 12, Epoch 115/170 => Loss 3.846, Loss_clf 0.663, Loss_fe 0.540, Loss_kd 2.436, Train_accy 78.55, Test_accy 64.40
2024-08-31 19:27:21,204 [foster.py] => Task 12, Epoch 116/170 => Loss 3.864, Loss_clf 0.681, Loss_fe 0.547, Loss_kd 2.429, Train_accy 78.53
2024-08-31 19:27:28,704 [foster.py] => Task 12, Epoch 117/170 => Loss 3.866, Loss_clf 0.665, Loss_fe 0.536, Loss_kd 2.456, Train_accy 78.79, Test_accy 66.60
2024-08-31 19:27:36,177 [foster.py] => Task 12, Epoch 118/170 => Loss 3.867, Loss_clf 0.677, Loss_fe 0.539, Loss_kd 2.442, Train_accy 78.66, Test_accy 67.51
2024-08-31 19:27:43,627 [foster.py] => Task 12, Epoch 119/170 => Loss 3.857, Loss_clf 0.673, Loss_fe 0.509, Loss_kd 2.464, Train_accy 78.33, Test_accy 64.31
2024-08-31 19:27:51,217 [foster.py] => Task 12, Epoch 120/170 => Loss 3.767, Loss_clf 0.639, Loss_fe 0.496, Loss_kd 2.426, Train_accy 79.80, Test_accy 67.08
2024-08-31 19:27:56,638 [foster.py] => Task 12, Epoch 121/170 => Loss 3.795, Loss_clf 0.642, Loss_fe 0.510, Loss_kd 2.435, Train_accy 80.49
2024-08-31 19:28:04,153 [foster.py] => Task 12, Epoch 122/170 => Loss 3.810, Loss_clf 0.646, Loss_fe 0.508, Loss_kd 2.447, Train_accy 79.42, Test_accy 66.89
2024-08-31 19:28:11,671 [foster.py] => Task 12, Epoch 123/170 => Loss 3.809, Loss_clf 0.654, Loss_fe 0.502, Loss_kd 2.444, Train_accy 80.11, Test_accy 67.35
2024-08-31 19:28:19,297 [foster.py] => Task 12, Epoch 124/170 => Loss 3.777, Loss_clf 0.642, Loss_fe 0.484, Loss_kd 2.442, Train_accy 80.02, Test_accy 67.45
2024-08-31 19:28:26,908 [foster.py] => Task 12, Epoch 125/170 => Loss 3.761, Loss_clf 0.626, Loss_fe 0.480, Loss_kd 2.446, Train_accy 79.67, Test_accy 67.08
2024-08-31 19:28:32,162 [foster.py] => Task 12, Epoch 126/170 => Loss 3.764, Loss_clf 0.636, Loss_fe 0.479, Loss_kd 2.441, Train_accy 80.11
2024-08-31 19:28:39,703 [foster.py] => Task 12, Epoch 127/170 => Loss 3.806, Loss_clf 0.649, Loss_fe 0.501, Loss_kd 2.447, Train_accy 80.60, Test_accy 67.02
2024-08-31 19:28:47,143 [foster.py] => Task 12, Epoch 128/170 => Loss 3.718, Loss_clf 0.612, Loss_fe 0.463, Loss_kd 2.435, Train_accy 80.00, Test_accy 66.32
2024-08-31 19:28:54,615 [foster.py] => Task 12, Epoch 129/170 => Loss 3.732, Loss_clf 0.625, Loss_fe 0.464, Loss_kd 2.436, Train_accy 79.78, Test_accy 67.18
2024-08-31 19:29:02,078 [foster.py] => Task 12, Epoch 130/170 => Loss 3.758, Loss_clf 0.632, Loss_fe 0.462, Loss_kd 2.455, Train_accy 80.71, Test_accy 67.49
2024-08-31 19:29:07,346 [foster.py] => Task 12, Epoch 131/170 => Loss 3.718, Loss_clf 0.604, Loss_fe 0.467, Loss_kd 2.439, Train_accy 81.34
2024-08-31 19:29:14,865 [foster.py] => Task 12, Epoch 132/170 => Loss 3.752, Loss_clf 0.638, Loss_fe 0.454, Loss_kd 2.451, Train_accy 80.07, Test_accy 66.11
2024-08-31 19:29:22,325 [foster.py] => Task 12, Epoch 133/170 => Loss 3.683, Loss_clf 0.595, Loss_fe 0.446, Loss_kd 2.435, Train_accy 80.85, Test_accy 67.62
2024-08-31 19:29:29,852 [foster.py] => Task 12, Epoch 134/170 => Loss 3.703, Loss_clf 0.599, Loss_fe 0.434, Loss_kd 2.460, Train_accy 81.96, Test_accy 67.25
2024-08-31 19:29:37,284 [foster.py] => Task 12, Epoch 135/170 => Loss 3.744, Loss_clf 0.625, Loss_fe 0.433, Loss_kd 2.475, Train_accy 80.51, Test_accy 67.31
2024-08-31 19:29:42,483 [foster.py] => Task 12, Epoch 136/170 => Loss 3.655, Loss_clf 0.590, Loss_fe 0.419, Loss_kd 2.438, Train_accy 81.56
2024-08-31 19:29:49,938 [foster.py] => Task 12, Epoch 137/170 => Loss 3.655, Loss_clf 0.589, Loss_fe 0.418, Loss_kd 2.440, Train_accy 82.32, Test_accy 67.18
2024-08-31 19:29:57,460 [foster.py] => Task 12, Epoch 138/170 => Loss 3.639, Loss_clf 0.584, Loss_fe 0.409, Loss_kd 2.438, Train_accy 82.63, Test_accy 67.63
2024-08-31 19:30:04,981 [foster.py] => Task 12, Epoch 139/170 => Loss 3.668, Loss_clf 0.605, Loss_fe 0.405, Loss_kd 2.449, Train_accy 81.74, Test_accy 67.03
2024-08-31 19:30:12,442 [foster.py] => Task 12, Epoch 140/170 => Loss 3.630, Loss_clf 0.577, Loss_fe 0.411, Loss_kd 2.434, Train_accy 82.83, Test_accy 67.08
2024-08-31 19:30:17,691 [foster.py] => Task 12, Epoch 141/170 => Loss 3.641, Loss_clf 0.583, Loss_fe 0.398, Loss_kd 2.451, Train_accy 81.43
2024-08-31 19:30:25,156 [foster.py] => Task 12, Epoch 142/170 => Loss 3.594, Loss_clf 0.558, Loss_fe 0.389, Loss_kd 2.440, Train_accy 83.01, Test_accy 67.42
2024-08-31 19:30:32,677 [foster.py] => Task 12, Epoch 143/170 => Loss 3.593, Loss_clf 0.560, Loss_fe 0.376, Loss_kd 2.447, Train_accy 83.19, Test_accy 67.98
2024-08-31 19:30:40,209 [foster.py] => Task 12, Epoch 144/170 => Loss 3.617, Loss_clf 0.574, Loss_fe 0.384, Loss_kd 2.450, Train_accy 83.48, Test_accy 67.40
2024-08-31 19:30:47,670 [foster.py] => Task 12, Epoch 145/170 => Loss 3.651, Loss_clf 0.588, Loss_fe 0.412, Loss_kd 2.442, Train_accy 82.32, Test_accy 67.71
2024-08-31 19:30:52,950 [foster.py] => Task 12, Epoch 146/170 => Loss 3.571, Loss_clf 0.550, Loss_fe 0.366, Loss_kd 2.446, Train_accy 84.00
2024-08-31 19:31:00,486 [foster.py] => Task 12, Epoch 147/170 => Loss 3.590, Loss_clf 0.565, Loss_fe 0.367, Loss_kd 2.449, Train_accy 83.15, Test_accy 67.51
2024-08-31 19:31:08,014 [foster.py] => Task 12, Epoch 148/170 => Loss 3.578, Loss_clf 0.566, Loss_fe 0.357, Loss_kd 2.447, Train_accy 83.28, Test_accy 67.42
2024-08-31 19:31:15,545 [foster.py] => Task 12, Epoch 149/170 => Loss 3.536, Loss_clf 0.542, Loss_fe 0.351, Loss_kd 2.436, Train_accy 83.68, Test_accy 67.60
2024-08-31 19:31:23,173 [foster.py] => Task 12, Epoch 150/170 => Loss 3.584, Loss_clf 0.562, Loss_fe 0.358, Loss_kd 2.455, Train_accy 83.19, Test_accy 67.55
2024-08-31 19:31:28,426 [foster.py] => Task 12, Epoch 151/170 => Loss 3.519, Loss_clf 0.530, Loss_fe 0.348, Loss_kd 2.433, Train_accy 84.04
2024-08-31 19:31:35,856 [foster.py] => Task 12, Epoch 152/170 => Loss 3.550, Loss_clf 0.547, Loss_fe 0.357, Loss_kd 2.438, Train_accy 83.46, Test_accy 67.60
2024-08-31 19:31:43,300 [foster.py] => Task 12, Epoch 153/170 => Loss 3.547, Loss_clf 0.541, Loss_fe 0.354, Loss_kd 2.443, Train_accy 83.71, Test_accy 67.89
2024-08-31 19:31:50,844 [foster.py] => Task 12, Epoch 154/170 => Loss 3.575, Loss_clf 0.558, Loss_fe 0.353, Loss_kd 2.455, Train_accy 84.04, Test_accy 67.74
2024-08-31 19:31:58,351 [foster.py] => Task 12, Epoch 155/170 => Loss 3.490, Loss_clf 0.518, Loss_fe 0.323, Loss_kd 2.441, Train_accy 84.73, Test_accy 67.48
2024-08-31 19:32:03,623 [foster.py] => Task 12, Epoch 156/170 => Loss 3.471, Loss_clf 0.513, Loss_fe 0.326, Loss_kd 2.425, Train_accy 84.75
2024-08-31 19:32:11,094 [foster.py] => Task 12, Epoch 157/170 => Loss 3.559, Loss_clf 0.552, Loss_fe 0.346, Loss_kd 2.452, Train_accy 84.22, Test_accy 67.91
2024-08-31 19:32:18,639 [foster.py] => Task 12, Epoch 158/170 => Loss 3.496, Loss_clf 0.524, Loss_fe 0.319, Loss_kd 2.445, Train_accy 84.75, Test_accy 67.78
2024-08-31 19:32:26,195 [foster.py] => Task 12, Epoch 159/170 => Loss 3.545, Loss_clf 0.545, Loss_fe 0.346, Loss_kd 2.446, Train_accy 84.02, Test_accy 67.54
2024-08-31 19:32:33,772 [foster.py] => Task 12, Epoch 160/170 => Loss 3.512, Loss_clf 0.519, Loss_fe 0.339, Loss_kd 2.445, Train_accy 85.25, Test_accy 67.88
2024-08-31 19:32:39,068 [foster.py] => Task 12, Epoch 161/170 => Loss 3.515, Loss_clf 0.543, Loss_fe 0.324, Loss_kd 2.440, Train_accy 83.93
2024-08-31 19:32:46,590 [foster.py] => Task 12, Epoch 162/170 => Loss 3.469, Loss_clf 0.512, Loss_fe 0.311, Loss_kd 2.438, Train_accy 85.22, Test_accy 67.74
2024-08-31 19:32:54,093 [foster.py] => Task 12, Epoch 163/170 => Loss 3.482, Loss_clf 0.524, Loss_fe 0.319, Loss_kd 2.432, Train_accy 85.09, Test_accy 67.71
2024-08-31 19:33:01,611 [foster.py] => Task 12, Epoch 164/170 => Loss 3.461, Loss_clf 0.504, Loss_fe 0.307, Loss_kd 2.442, Train_accy 85.92, Test_accy 67.74
2024-08-31 19:33:09,090 [foster.py] => Task 12, Epoch 165/170 => Loss 3.508, Loss_clf 0.543, Loss_fe 0.318, Loss_kd 2.439, Train_accy 84.33, Test_accy 67.82
2024-08-31 19:33:14,340 [foster.py] => Task 12, Epoch 166/170 => Loss 3.531, Loss_clf 0.540, Loss_fe 0.330, Loss_kd 2.452, Train_accy 84.15
2024-08-31 19:33:21,856 [foster.py] => Task 12, Epoch 167/170 => Loss 3.501, Loss_clf 0.529, Loss_fe 0.319, Loss_kd 2.444, Train_accy 84.64, Test_accy 67.78
2024-08-31 19:33:29,403 [foster.py] => Task 12, Epoch 168/170 => Loss 3.505, Loss_clf 0.521, Loss_fe 0.326, Loss_kd 2.449, Train_accy 85.02, Test_accy 67.69
2024-08-31 19:33:36,926 [foster.py] => Task 12, Epoch 169/170 => Loss 3.515, Loss_clf 0.540, Loss_fe 0.317, Loss_kd 2.448, Train_accy 83.97, Test_accy 67.77
2024-08-31 19:33:44,418 [foster.py] => Task 12, Epoch 170/170 => Loss 3.494, Loss_clf 0.521, Loss_fe 0.321, Loss_kd 2.443, Train_accy 85.20, Test_accy 67.80
2024-08-31 19:33:44,421 [foster.py] => do not weight align teacher!
2024-08-31 19:33:44,422 [foster.py] => per cls weights : [1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424 1.03368424
 0.59578912 0.59578912 0.59578912 0.59578912 0.59578912]
2024-08-31 19:33:54,005 [foster.py] => SNet: Task 12, Epoch 1/130 => Loss 28.745,  Loss1 0.715, Train_accy 49.35, Test_accy 60.85
2024-08-31 19:34:01,477 [foster.py] => SNet: Task 12, Epoch 2/130 => Loss 28.611,  Loss1 0.716, Train_accy 61.61
2024-08-31 19:34:08,930 [foster.py] => SNet: Task 12, Epoch 3/130 => Loss 28.578,  Loss1 0.715, Train_accy 66.54
2024-08-31 19:34:16,018 [foster.py] => SNet: Task 12, Epoch 4/130 => Loss 28.584,  Loss1 0.716, Train_accy 66.92
2024-08-31 19:34:23,310 [foster.py] => SNet: Task 12, Epoch 5/130 => Loss 28.579,  Loss1 0.716, Train_accy 68.84
2024-08-31 19:34:32,390 [foster.py] => SNet: Task 12, Epoch 6/130 => Loss 28.557,  Loss1 0.716, Train_accy 68.71, Test_accy 64.11
2024-08-31 19:34:39,488 [foster.py] => SNet: Task 12, Epoch 7/130 => Loss 28.540,  Loss1 0.716, Train_accy 69.96
2024-08-31 19:34:46,577 [foster.py] => SNet: Task 12, Epoch 8/130 => Loss 28.545,  Loss1 0.715, Train_accy 70.11
2024-08-31 19:34:54,538 [foster.py] => SNet: Task 12, Epoch 9/130 => Loss 28.576,  Loss1 0.716, Train_accy 71.27
2024-08-31 19:35:01,583 [foster.py] => SNet: Task 12, Epoch 10/130 => Loss 28.564,  Loss1 0.716, Train_accy 71.00
2024-08-31 19:35:10,666 [foster.py] => SNet: Task 12, Epoch 11/130 => Loss 28.543,  Loss1 0.716, Train_accy 70.98, Test_accy 65.15
2024-08-31 19:35:17,877 [foster.py] => SNet: Task 12, Epoch 12/130 => Loss 28.570,  Loss1 0.715, Train_accy 71.43
2024-08-31 19:35:25,190 [foster.py] => SNet: Task 12, Epoch 13/130 => Loss 28.530,  Loss1 0.716, Train_accy 71.56
2024-08-31 19:35:32,365 [foster.py] => SNet: Task 12, Epoch 14/130 => Loss 28.546,  Loss1 0.716, Train_accy 72.97
2024-08-31 19:35:39,446 [foster.py] => SNet: Task 12, Epoch 15/130 => Loss 28.531,  Loss1 0.716, Train_accy 72.39
2024-08-31 19:35:48,832 [foster.py] => SNet: Task 12, Epoch 16/130 => Loss 28.546,  Loss1 0.716, Train_accy 72.70, Test_accy 65.85
2024-08-31 19:35:55,988 [foster.py] => SNet: Task 12, Epoch 17/130 => Loss 28.565,  Loss1 0.716, Train_accy 72.59
2024-08-31 19:36:03,218 [foster.py] => SNet: Task 12, Epoch 18/130 => Loss 28.515,  Loss1 0.716, Train_accy 72.41
2024-08-31 19:36:10,409 [foster.py] => SNet: Task 12, Epoch 19/130 => Loss 28.531,  Loss1 0.715, Train_accy 73.68
2024-08-31 19:36:17,781 [foster.py] => SNet: Task 12, Epoch 20/130 => Loss 28.556,  Loss1 0.715, Train_accy 72.19
2024-08-31 19:36:26,826 [foster.py] => SNet: Task 12, Epoch 21/130 => Loss 28.558,  Loss1 0.715, Train_accy 72.61, Test_accy 65.49
2024-08-31 19:36:34,206 [foster.py] => SNet: Task 12, Epoch 22/130 => Loss 28.529,  Loss1 0.716, Train_accy 74.35
2024-08-31 19:36:41,293 [foster.py] => SNet: Task 12, Epoch 23/130 => Loss 28.556,  Loss1 0.715, Train_accy 74.31
2024-08-31 19:36:48,698 [foster.py] => SNet: Task 12, Epoch 24/130 => Loss 28.554,  Loss1 0.716, Train_accy 74.29
2024-08-31 19:36:56,098 [foster.py] => SNet: Task 12, Epoch 25/130 => Loss 28.526,  Loss1 0.715, Train_accy 74.06
2024-08-31 19:37:05,227 [foster.py] => SNet: Task 12, Epoch 26/130 => Loss 28.567,  Loss1 0.715, Train_accy 74.49, Test_accy 65.45
2024-08-31 19:37:12,676 [foster.py] => SNet: Task 12, Epoch 27/130 => Loss 28.534,  Loss1 0.715, Train_accy 75.27
2024-08-31 19:37:19,811 [foster.py] => SNet: Task 12, Epoch 28/130 => Loss 28.562,  Loss1 0.716, Train_accy 74.33
2024-08-31 19:37:26,909 [foster.py] => SNet: Task 12, Epoch 29/130 => Loss 28.544,  Loss1 0.715, Train_accy 73.82
2024-08-31 19:37:34,626 [foster.py] => SNet: Task 12, Epoch 30/130 => Loss 28.529,  Loss1 0.716, Train_accy 74.38
2024-08-31 19:37:43,610 [foster.py] => SNet: Task 12, Epoch 31/130 => Loss 28.549,  Loss1 0.716, Train_accy 74.55, Test_accy 65.98
2024-08-31 19:37:50,743 [foster.py] => SNet: Task 12, Epoch 32/130 => Loss 28.551,  Loss1 0.715, Train_accy 73.12
2024-08-31 19:37:57,842 [foster.py] => SNet: Task 12, Epoch 33/130 => Loss 28.534,  Loss1 0.716, Train_accy 74.29
2024-08-31 19:38:04,917 [foster.py] => SNet: Task 12, Epoch 34/130 => Loss 28.513,  Loss1 0.716, Train_accy 75.18
2024-08-31 19:38:12,044 [foster.py] => SNet: Task 12, Epoch 35/130 => Loss 28.543,  Loss1 0.716, Train_accy 74.89
2024-08-31 19:38:21,347 [foster.py] => SNet: Task 12, Epoch 36/130 => Loss 28.544,  Loss1 0.716, Train_accy 74.98, Test_accy 65.02
2024-08-31 19:38:28,500 [foster.py] => SNet: Task 12, Epoch 37/130 => Loss 28.536,  Loss1 0.716, Train_accy 75.65
2024-08-31 19:38:36,275 [foster.py] => SNet: Task 12, Epoch 38/130 => Loss 28.513,  Loss1 0.715, Train_accy 75.25
2024-08-31 19:38:43,741 [foster.py] => SNet: Task 12, Epoch 39/130 => Loss 28.519,  Loss1 0.715, Train_accy 74.82
2024-08-31 19:38:50,853 [foster.py] => SNet: Task 12, Epoch 40/130 => Loss 28.499,  Loss1 0.715, Train_accy 73.77
2024-08-31 19:38:59,898 [foster.py] => SNet: Task 12, Epoch 41/130 => Loss 28.537,  Loss1 0.715, Train_accy 74.20, Test_accy 65.86
2024-08-31 19:39:07,079 [foster.py] => SNet: Task 12, Epoch 42/130 => Loss 28.546,  Loss1 0.716, Train_accy 75.38
2024-08-31 19:39:14,199 [foster.py] => SNet: Task 12, Epoch 43/130 => Loss 28.532,  Loss1 0.715, Train_accy 75.20
2024-08-31 19:39:21,276 [foster.py] => SNet: Task 12, Epoch 44/130 => Loss 28.539,  Loss1 0.716, Train_accy 74.69
2024-08-31 19:39:28,464 [foster.py] => SNet: Task 12, Epoch 45/130 => Loss 28.531,  Loss1 0.716, Train_accy 75.60
2024-08-31 19:39:38,006 [foster.py] => SNet: Task 12, Epoch 46/130 => Loss 28.525,  Loss1 0.715, Train_accy 74.93, Test_accy 65.32
2024-08-31 19:39:45,488 [foster.py] => SNet: Task 12, Epoch 47/130 => Loss 28.539,  Loss1 0.715, Train_accy 76.00
2024-08-31 19:39:53,368 [foster.py] => SNet: Task 12, Epoch 48/130 => Loss 28.541,  Loss1 0.716, Train_accy 75.11
2024-08-31 19:40:00,651 [foster.py] => SNet: Task 12, Epoch 49/130 => Loss 28.505,  Loss1 0.715, Train_accy 75.45
2024-08-31 19:40:07,915 [foster.py] => SNet: Task 12, Epoch 50/130 => Loss 28.525,  Loss1 0.715, Train_accy 75.33
2024-08-31 19:40:17,330 [foster.py] => SNet: Task 12, Epoch 51/130 => Loss 28.544,  Loss1 0.715, Train_accy 75.07, Test_accy 66.15
2024-08-31 19:40:24,428 [foster.py] => SNet: Task 12, Epoch 52/130 => Loss 28.533,  Loss1 0.715, Train_accy 76.12
2024-08-31 19:40:31,791 [foster.py] => SNet: Task 12, Epoch 53/130 => Loss 28.515,  Loss1 0.715, Train_accy 76.36
2024-08-31 19:40:38,949 [foster.py] => SNet: Task 12, Epoch 54/130 => Loss 28.504,  Loss1 0.716, Train_accy 76.36
2024-08-31 19:40:46,540 [foster.py] => SNet: Task 12, Epoch 55/130 => Loss 28.522,  Loss1 0.715, Train_accy 75.18
2024-08-31 19:40:55,867 [foster.py] => SNet: Task 12, Epoch 56/130 => Loss 28.536,  Loss1 0.716, Train_accy 75.80, Test_accy 66.66
2024-08-31 19:41:03,006 [foster.py] => SNet: Task 12, Epoch 57/130 => Loss 28.497,  Loss1 0.716, Train_accy 75.71
2024-08-31 19:41:10,193 [foster.py] => SNet: Task 12, Epoch 58/130 => Loss 28.491,  Loss1 0.715, Train_accy 77.63
2024-08-31 19:41:17,426 [foster.py] => SNet: Task 12, Epoch 59/130 => Loss 28.513,  Loss1 0.716, Train_accy 75.85
2024-08-31 19:41:24,754 [foster.py] => SNet: Task 12, Epoch 60/130 => Loss 28.559,  Loss1 0.716, Train_accy 76.43
2024-08-31 19:41:33,852 [foster.py] => SNet: Task 12, Epoch 61/130 => Loss 28.495,  Loss1 0.716, Train_accy 76.36, Test_accy 66.14
2024-08-31 19:41:41,315 [foster.py] => SNet: Task 12, Epoch 62/130 => Loss 28.527,  Loss1 0.716, Train_accy 76.18
2024-08-31 19:41:48,587 [foster.py] => SNet: Task 12, Epoch 63/130 => Loss 28.500,  Loss1 0.716, Train_accy 76.94
2024-08-31 19:41:56,329 [foster.py] => SNet: Task 12, Epoch 64/130 => Loss 28.541,  Loss1 0.716, Train_accy 75.54
2024-08-31 19:42:03,496 [foster.py] => SNet: Task 12, Epoch 65/130 => Loss 28.507,  Loss1 0.715, Train_accy 75.62
2024-08-31 19:42:12,808 [foster.py] => SNet: Task 12, Epoch 66/130 => Loss 28.500,  Loss1 0.716, Train_accy 76.07, Test_accy 66.58
2024-08-31 19:42:20,033 [foster.py] => SNet: Task 12, Epoch 67/130 => Loss 28.563,  Loss1 0.715, Train_accy 75.62
2024-08-31 19:42:27,426 [foster.py] => SNet: Task 12, Epoch 68/130 => Loss 28.480,  Loss1 0.716, Train_accy 77.10
2024-08-31 19:42:34,794 [foster.py] => SNet: Task 12, Epoch 69/130 => Loss 28.500,  Loss1 0.716, Train_accy 76.14
2024-08-31 19:42:42,386 [foster.py] => SNet: Task 12, Epoch 70/130 => Loss 28.523,  Loss1 0.715, Train_accy 77.59
2024-08-31 19:42:51,771 [foster.py] => SNet: Task 12, Epoch 71/130 => Loss 28.505,  Loss1 0.716, Train_accy 76.05, Test_accy 66.11
2024-08-31 19:42:59,047 [foster.py] => SNet: Task 12, Epoch 72/130 => Loss 28.533,  Loss1 0.715, Train_accy 76.23
2024-08-31 19:43:06,398 [foster.py] => SNet: Task 12, Epoch 73/130 => Loss 28.477,  Loss1 0.716, Train_accy 77.48
2024-08-31 19:43:13,643 [foster.py] => SNet: Task 12, Epoch 74/130 => Loss 28.534,  Loss1 0.715, Train_accy 75.76
2024-08-31 19:43:20,756 [foster.py] => SNet: Task 12, Epoch 75/130 => Loss 28.513,  Loss1 0.716, Train_accy 77.77
2024-08-31 19:43:30,317 [foster.py] => SNet: Task 12, Epoch 76/130 => Loss 28.533,  Loss1 0.715, Train_accy 76.27, Test_accy 66.97
2024-08-31 19:43:37,654 [foster.py] => SNet: Task 12, Epoch 77/130 => Loss 28.508,  Loss1 0.716, Train_accy 76.34
2024-08-31 19:43:44,813 [foster.py] => SNet: Task 12, Epoch 78/130 => Loss 28.508,  Loss1 0.715, Train_accy 76.83
2024-08-31 19:43:52,275 [foster.py] => SNet: Task 12, Epoch 79/130 => Loss 28.540,  Loss1 0.715, Train_accy 77.19
2024-08-31 19:43:59,777 [foster.py] => SNet: Task 12, Epoch 80/130 => Loss 28.490,  Loss1 0.716, Train_accy 77.10
2024-08-31 19:44:08,737 [foster.py] => SNet: Task 12, Epoch 81/130 => Loss 28.519,  Loss1 0.716, Train_accy 76.16, Test_accy 66.26
2024-08-31 19:44:16,146 [foster.py] => SNet: Task 12, Epoch 82/130 => Loss 28.502,  Loss1 0.716, Train_accy 77.17
2024-08-31 19:44:23,188 [foster.py] => SNet: Task 12, Epoch 83/130 => Loss 28.537,  Loss1 0.715, Train_accy 76.27
2024-08-31 19:44:30,375 [foster.py] => SNet: Task 12, Epoch 84/130 => Loss 28.496,  Loss1 0.715, Train_accy 77.46
2024-08-31 19:44:37,413 [foster.py] => SNet: Task 12, Epoch 85/130 => Loss 28.513,  Loss1 0.716, Train_accy 77.59
2024-08-31 19:44:46,437 [foster.py] => SNet: Task 12, Epoch 86/130 => Loss 28.520,  Loss1 0.716, Train_accy 76.47, Test_accy 66.83
2024-08-31 19:44:53,896 [foster.py] => SNet: Task 12, Epoch 87/130 => Loss 28.542,  Loss1 0.716, Train_accy 76.67
2024-08-31 19:45:01,186 [foster.py] => SNet: Task 12, Epoch 88/130 => Loss 28.502,  Loss1 0.716, Train_accy 77.05
2024-08-31 19:45:08,246 [foster.py] => SNet: Task 12, Epoch 89/130 => Loss 28.523,  Loss1 0.716, Train_accy 77.50
2024-08-31 19:45:15,340 [foster.py] => SNet: Task 12, Epoch 90/130 => Loss 28.520,  Loss1 0.716, Train_accy 76.50
2024-08-31 19:45:25,253 [foster.py] => SNet: Task 12, Epoch 91/130 => Loss 28.488,  Loss1 0.716, Train_accy 77.19, Test_accy 66.69
2024-08-31 19:45:32,367 [foster.py] => SNet: Task 12, Epoch 92/130 => Loss 28.533,  Loss1 0.715, Train_accy 75.85
2024-08-31 19:45:39,678 [foster.py] => SNet: Task 12, Epoch 93/130 => Loss 28.505,  Loss1 0.716, Train_accy 77.95
2024-08-31 19:45:46,818 [foster.py] => SNet: Task 12, Epoch 94/130 => Loss 28.517,  Loss1 0.715, Train_accy 77.66
2024-08-31 19:45:54,484 [foster.py] => SNet: Task 12, Epoch 95/130 => Loss 28.501,  Loss1 0.716, Train_accy 77.50
2024-08-31 19:46:03,510 [foster.py] => SNet: Task 12, Epoch 96/130 => Loss 28.502,  Loss1 0.716, Train_accy 77.37, Test_accy 67.17
2024-08-31 19:46:10,588 [foster.py] => SNet: Task 12, Epoch 97/130 => Loss 28.513,  Loss1 0.715, Train_accy 77.12
2024-08-31 19:46:18,380 [foster.py] => SNet: Task 12, Epoch 98/130 => Loss 28.496,  Loss1 0.716, Train_accy 77.10
2024-08-31 19:46:25,415 [foster.py] => SNet: Task 12, Epoch 99/130 => Loss 28.551,  Loss1 0.715, Train_accy 77.03
2024-08-31 19:46:32,961 [foster.py] => SNet: Task 12, Epoch 100/130 => Loss 28.554,  Loss1 0.715, Train_accy 77.79
2024-08-31 19:46:42,225 [foster.py] => SNet: Task 12, Epoch 101/130 => Loss 28.493,  Loss1 0.716, Train_accy 76.16, Test_accy 66.57
2024-08-31 19:46:49,651 [foster.py] => SNet: Task 12, Epoch 102/130 => Loss 28.505,  Loss1 0.716, Train_accy 77.54
2024-08-31 19:46:57,030 [foster.py] => SNet: Task 12, Epoch 103/130 => Loss 28.492,  Loss1 0.716, Train_accy 76.90
2024-08-31 19:47:04,169 [foster.py] => SNet: Task 12, Epoch 104/130 => Loss 28.549,  Loss1 0.716, Train_accy 76.72
2024-08-31 19:47:11,613 [foster.py] => SNet: Task 12, Epoch 105/130 => Loss 28.533,  Loss1 0.716, Train_accy 77.63
2024-08-31 19:47:20,740 [foster.py] => SNet: Task 12, Epoch 106/130 => Loss 28.486,  Loss1 0.716, Train_accy 77.25, Test_accy 66.94
2024-08-31 19:47:27,957 [foster.py] => SNet: Task 12, Epoch 107/130 => Loss 28.511,  Loss1 0.715, Train_accy 76.76
2024-08-31 19:47:35,390 [foster.py] => SNet: Task 12, Epoch 108/130 => Loss 28.501,  Loss1 0.715, Train_accy 77.34
2024-08-31 19:47:42,745 [foster.py] => SNet: Task 12, Epoch 109/130 => Loss 28.527,  Loss1 0.716, Train_accy 76.54
2024-08-31 19:47:50,005 [foster.py] => SNet: Task 12, Epoch 110/130 => Loss 28.508,  Loss1 0.716, Train_accy 77.79
2024-08-31 19:47:59,245 [foster.py] => SNet: Task 12, Epoch 111/130 => Loss 28.467,  Loss1 0.716, Train_accy 77.88, Test_accy 66.85
2024-08-31 19:48:06,793 [foster.py] => SNet: Task 12, Epoch 112/130 => Loss 28.503,  Loss1 0.716, Train_accy 77.19
2024-08-31 19:48:14,218 [foster.py] => SNet: Task 12, Epoch 113/130 => Loss 28.538,  Loss1 0.716, Train_accy 77.21
2024-08-31 19:48:21,680 [foster.py] => SNet: Task 12, Epoch 114/130 => Loss 28.523,  Loss1 0.716, Train_accy 76.90
2024-08-31 19:48:28,795 [foster.py] => SNet: Task 12, Epoch 115/130 => Loss 28.511,  Loss1 0.716, Train_accy 77.05
2024-08-31 19:48:37,883 [foster.py] => SNet: Task 12, Epoch 116/130 => Loss 28.497,  Loss1 0.715, Train_accy 77.59, Test_accy 66.97
2024-08-31 19:48:45,151 [foster.py] => SNet: Task 12, Epoch 117/130 => Loss 28.524,  Loss1 0.716, Train_accy 77.10
2024-08-31 19:48:52,230 [foster.py] => SNet: Task 12, Epoch 118/130 => Loss 28.502,  Loss1 0.716, Train_accy 76.18
2024-08-31 19:48:59,399 [foster.py] => SNet: Task 12, Epoch 119/130 => Loss 28.509,  Loss1 0.715, Train_accy 76.67
2024-08-31 19:49:06,529 [foster.py] => SNet: Task 12, Epoch 120/130 => Loss 28.487,  Loss1 0.715, Train_accy 78.08
2024-08-31 19:49:15,751 [foster.py] => SNet: Task 12, Epoch 121/130 => Loss 28.481,  Loss1 0.715, Train_accy 77.43, Test_accy 67.06
2024-08-31 19:49:22,804 [foster.py] => SNet: Task 12, Epoch 122/130 => Loss 28.492,  Loss1 0.716, Train_accy 77.83
2024-08-31 19:49:29,993 [foster.py] => SNet: Task 12, Epoch 123/130 => Loss 28.502,  Loss1 0.716, Train_accy 78.24
2024-08-31 19:49:37,405 [foster.py] => SNet: Task 12, Epoch 124/130 => Loss 28.510,  Loss1 0.716, Train_accy 77.14
2024-08-31 19:49:44,863 [foster.py] => SNet: Task 12, Epoch 125/130 => Loss 28.509,  Loss1 0.716, Train_accy 77.10
2024-08-31 19:49:54,099 [foster.py] => SNet: Task 12, Epoch 126/130 => Loss 28.524,  Loss1 0.716, Train_accy 76.83, Test_accy 66.88
2024-08-31 19:50:01,218 [foster.py] => SNet: Task 12, Epoch 127/130 => Loss 28.529,  Loss1 0.716, Train_accy 77.68
2024-08-31 19:50:08,282 [foster.py] => SNet: Task 12, Epoch 128/130 => Loss 28.495,  Loss1 0.716, Train_accy 78.28
2024-08-31 19:50:15,523 [foster.py] => SNet: Task 12, Epoch 129/130 => Loss 28.520,  Loss1 0.715, Train_accy 77.66
2024-08-31 19:50:22,732 [foster.py] => SNet: Task 12, Epoch 130/130 => Loss 28.507,  Loss1 0.716, Train_accy 77.05
2024-08-31 19:50:22,733 [foster.py] => do not weight align student!
2024-08-31 19:50:25,261 [foster.py] => darknet eval: 
2024-08-31 19:50:25,261 [foster.py] => CNN top1 curve: 66.82
2024-08-31 19:50:25,262 [foster.py] => CNN top5 curve: 89.82
2024-08-31 19:50:25,262 [foster.py] => CNN top1 平均值: 66.82
2024-08-31 19:50:25,265 [foster.py] => timees : 2201.100489616394
2024-08-31 19:50:25,266 [base.py] => Reducing exemplars...(30 per classes)
2024-08-31 19:50:46,299 [base.py] => Constructing exemplars...(30 per classes)
2024-08-31 19:50:56,072 [foster.py] => Exemplar size: 1950
2024-08-31 19:50:56,072 [trainer.py] => CNN: {'total': 67.8, '00-09': 69.7, '10-19': 52.1, '20-29': 67.3, '30-39': 64.9, '40-49': 75.5, '50-59': 71.2, '60-69': 80.0, 'old': 66.78, 'new': 80.0}
2024-08-31 19:50:56,072 [trainer.py] => NME: {'total': 62.46, '00-09': 62.0, '10-19': 48.8, '20-29': 64.7, '30-39': 61.2, '40-49': 70.5, '50-59': 58.3, '60-69': 81.0, 'old': 60.92, 'new': 81.0}
2024-08-31 19:50:56,072 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8]
2024-08-31 19:50:56,072 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48]
2024-08-31 19:50:56,072 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46]
2024-08-31 19:50:56,073 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62]

2024-08-31 19:50:56,073 [trainer.py] => CNN top1 平均值: 79.57
2024-08-31 19:50:56,075 [trainer.py] => All params: 1299058
2024-08-31 19:50:56,078 [trainer.py] => Trainable params: 653884
2024-08-31 19:50:56,141 [foster.py] => Learning on 65-70
2024-08-31 19:50:56,144 [foster.py] => All params: 1300353
2024-08-31 19:50:56,146 [foster.py] => Trainable params: 654854
2024-08-31 19:50:56,199 [foster.py] => per cls weights : [1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494
 1.01873494 1.01873494 1.01873494 1.01873494 1.01873494 0.75644575
 0.75644575 0.75644575 0.75644575 0.75644575]
2024-08-31 19:51:01,713 [foster.py] => Task 13, Epoch 1/170 => Loss 7.124, Loss_clf 2.679, Loss_fe 1.634, Loss_kd 2.603, Train_accy 54.61
2024-08-31 19:51:09,420 [foster.py] => Task 13, Epoch 2/170 => Loss 5.019, Loss_clf 1.080, Loss_fe 1.188, Loss_kd 2.547, Train_accy 70.67, Test_accy 60.66
2024-08-31 19:51:17,010 [foster.py] => Task 13, Epoch 3/170 => Loss 4.764, Loss_clf 0.971, Loss_fe 1.029, Loss_kd 2.558, Train_accy 70.65, Test_accy 63.74
2024-08-31 19:51:24,658 [foster.py] => Task 13, Epoch 4/170 => Loss 4.625, Loss_clf 0.927, Loss_fe 0.924, Loss_kd 2.569, Train_accy 73.30, Test_accy 63.70
2024-08-31 19:51:32,191 [foster.py] => Task 13, Epoch 5/170 => Loss 4.593, Loss_clf 0.958, Loss_fe 0.873, Loss_kd 2.558, Train_accy 72.00, Test_accy 63.00
2024-08-31 19:51:37,425 [foster.py] => Task 13, Epoch 6/170 => Loss 4.526, Loss_clf 0.883, Loss_fe 0.885, Loss_kd 2.554, Train_accy 73.28
2024-08-31 19:51:45,013 [foster.py] => Task 13, Epoch 7/170 => Loss 4.558, Loss_clf 0.924, Loss_fe 0.862, Loss_kd 2.567, Train_accy 72.63, Test_accy 62.56
2024-08-31 19:51:52,649 [foster.py] => Task 13, Epoch 8/170 => Loss 4.483, Loss_clf 0.863, Loss_fe 0.836, Loss_kd 2.578, Train_accy 73.93, Test_accy 61.83
2024-08-31 19:52:00,336 [foster.py] => Task 13, Epoch 9/170 => Loss 4.481, Loss_clf 0.882, Loss_fe 0.838, Loss_kd 2.557, Train_accy 73.24, Test_accy 64.89
2024-08-31 19:52:08,015 [foster.py] => Task 13, Epoch 10/170 => Loss 4.487, Loss_clf 0.884, Loss_fe 0.844, Loss_kd 2.556, Train_accy 73.51, Test_accy 63.96
2024-08-31 19:52:13,272 [foster.py] => Task 13, Epoch 11/170 => Loss 4.366, Loss_clf 0.809, Loss_fe 0.803, Loss_kd 2.552, Train_accy 75.26
2024-08-31 19:52:20,879 [foster.py] => Task 13, Epoch 12/170 => Loss 4.489, Loss_clf 0.872, Loss_fe 0.841, Loss_kd 2.572, Train_accy 73.26, Test_accy 58.93
2024-08-31 19:52:28,464 [foster.py] => Task 13, Epoch 13/170 => Loss 4.513, Loss_clf 0.921, Loss_fe 0.824, Loss_kd 2.564, Train_accy 72.79, Test_accy 62.71
2024-08-31 19:52:36,043 [foster.py] => Task 13, Epoch 14/170 => Loss 4.451, Loss_clf 0.876, Loss_fe 0.797, Loss_kd 2.573, Train_accy 73.21, Test_accy 65.01
2024-08-31 19:52:43,653 [foster.py] => Task 13, Epoch 15/170 => Loss 4.488, Loss_clf 0.870, Loss_fe 0.847, Loss_kd 2.567, Train_accy 73.53, Test_accy 65.36
2024-08-31 19:52:48,942 [foster.py] => Task 13, Epoch 16/170 => Loss 4.423, Loss_clf 0.839, Loss_fe 0.816, Loss_kd 2.565, Train_accy 73.87
2024-08-31 19:52:56,533 [foster.py] => Task 13, Epoch 17/170 => Loss 4.443, Loss_clf 0.854, Loss_fe 0.814, Loss_kd 2.571, Train_accy 73.48, Test_accy 62.19
2024-08-31 19:53:04,140 [foster.py] => Task 13, Epoch 18/170 => Loss 4.387, Loss_clf 0.839, Loss_fe 0.792, Loss_kd 2.554, Train_accy 74.29, Test_accy 65.29
2024-08-31 19:53:11,805 [foster.py] => Task 13, Epoch 19/170 => Loss 4.421, Loss_clf 0.846, Loss_fe 0.813, Loss_kd 2.558, Train_accy 74.25, Test_accy 64.47
2024-08-31 19:53:19,417 [foster.py] => Task 13, Epoch 20/170 => Loss 4.454, Loss_clf 0.862, Loss_fe 0.826, Loss_kd 2.563, Train_accy 73.44, Test_accy 63.96
2024-08-31 19:53:24,650 [foster.py] => Task 13, Epoch 21/170 => Loss 4.517, Loss_clf 0.908, Loss_fe 0.832, Loss_kd 2.573, Train_accy 73.06
2024-08-31 19:53:32,194 [foster.py] => Task 13, Epoch 22/170 => Loss 4.436, Loss_clf 0.865, Loss_fe 0.808, Loss_kd 2.560, Train_accy 73.57, Test_accy 63.86
2024-08-31 19:53:39,823 [foster.py] => Task 13, Epoch 23/170 => Loss 4.563, Loss_clf 0.972, Loss_fe 0.832, Loss_kd 2.556, Train_accy 72.47, Test_accy 63.86
2024-08-31 19:53:47,414 [foster.py] => Task 13, Epoch 24/170 => Loss 4.616, Loss_clf 0.979, Loss_fe 0.865, Loss_kd 2.568, Train_accy 71.39, Test_accy 60.69
2024-08-31 19:53:55,055 [foster.py] => Task 13, Epoch 25/170 => Loss 4.602, Loss_clf 0.995, Loss_fe 0.849, Loss_kd 2.555, Train_accy 71.44, Test_accy 62.09
2024-08-31 19:54:00,299 [foster.py] => Task 13, Epoch 26/170 => Loss 4.466, Loss_clf 0.864, Loss_fe 0.834, Loss_kd 2.565, Train_accy 73.57
2024-08-31 19:54:07,898 [foster.py] => Task 13, Epoch 27/170 => Loss 4.472, Loss_clf 0.868, Loss_fe 0.834, Loss_kd 2.567, Train_accy 73.60, Test_accy 62.21
2024-08-31 19:54:15,450 [foster.py] => Task 13, Epoch 28/170 => Loss 4.504, Loss_clf 0.903, Loss_fe 0.822, Loss_kd 2.575, Train_accy 72.88, Test_accy 64.59
2024-08-31 19:54:23,036 [foster.py] => Task 13, Epoch 29/170 => Loss 4.500, Loss_clf 0.878, Loss_fe 0.846, Loss_kd 2.573, Train_accy 72.47, Test_accy 64.33
2024-08-31 19:54:30,642 [foster.py] => Task 13, Epoch 30/170 => Loss 4.406, Loss_clf 0.845, Loss_fe 0.788, Loss_kd 2.570, Train_accy 74.43, Test_accy 64.23
2024-08-31 19:54:35,883 [foster.py] => Task 13, Epoch 31/170 => Loss 4.431, Loss_clf 0.854, Loss_fe 0.808, Loss_kd 2.566, Train_accy 73.89
2024-08-31 19:54:43,452 [foster.py] => Task 13, Epoch 32/170 => Loss 4.467, Loss_clf 0.901, Loss_fe 0.788, Loss_kd 2.574, Train_accy 72.52, Test_accy 64.53
2024-08-31 19:54:51,081 [foster.py] => Task 13, Epoch 33/170 => Loss 4.472, Loss_clf 0.874, Loss_fe 0.814, Loss_kd 2.580, Train_accy 74.02, Test_accy 63.17
2024-08-31 19:54:58,661 [foster.py] => Task 13, Epoch 34/170 => Loss 4.496, Loss_clf 0.892, Loss_fe 0.826, Loss_kd 2.575, Train_accy 73.57, Test_accy 63.26
2024-08-31 19:55:06,295 [foster.py] => Task 13, Epoch 35/170 => Loss 4.420, Loss_clf 0.853, Loss_fe 0.803, Loss_kd 2.561, Train_accy 73.93, Test_accy 63.06
2024-08-31 19:55:11,525 [foster.py] => Task 13, Epoch 36/170 => Loss 4.398, Loss_clf 0.847, Loss_fe 0.778, Loss_kd 2.570, Train_accy 72.90
2024-08-31 19:55:19,101 [foster.py] => Task 13, Epoch 37/170 => Loss 4.532, Loss_clf 0.955, Loss_fe 0.805, Loss_kd 2.569, Train_accy 71.80, Test_accy 63.91
2024-08-31 19:55:26,716 [foster.py] => Task 13, Epoch 38/170 => Loss 4.478, Loss_clf 0.876, Loss_fe 0.820, Loss_kd 2.579, Train_accy 72.40, Test_accy 62.19
2024-08-31 19:55:34,352 [foster.py] => Task 13, Epoch 39/170 => Loss 4.386, Loss_clf 0.817, Loss_fe 0.802, Loss_kd 2.564, Train_accy 74.54, Test_accy 63.79
2024-08-31 19:55:41,958 [foster.py] => Task 13, Epoch 40/170 => Loss 4.356, Loss_clf 0.818, Loss_fe 0.777, Loss_kd 2.559, Train_accy 74.99, Test_accy 64.29
2024-08-31 19:55:47,236 [foster.py] => Task 13, Epoch 41/170 => Loss 4.366, Loss_clf 0.824, Loss_fe 0.765, Loss_kd 2.574, Train_accy 74.09
2024-08-31 19:55:54,731 [foster.py] => Task 13, Epoch 42/170 => Loss 4.330, Loss_clf 0.810, Loss_fe 0.753, Loss_kd 2.565, Train_accy 74.11, Test_accy 64.64
2024-08-31 19:56:02,379 [foster.py] => Task 13, Epoch 43/170 => Loss 4.369, Loss_clf 0.848, Loss_fe 0.757, Loss_kd 2.561, Train_accy 73.06, Test_accy 65.63
2024-08-31 19:56:10,042 [foster.py] => Task 13, Epoch 44/170 => Loss 4.417, Loss_clf 0.848, Loss_fe 0.807, Loss_kd 2.559, Train_accy 73.19, Test_accy 64.43
2024-08-31 19:56:17,650 [foster.py] => Task 13, Epoch 45/170 => Loss 4.364, Loss_clf 0.817, Loss_fe 0.776, Loss_kd 2.568, Train_accy 73.51, Test_accy 63.70
2024-08-31 19:56:22,924 [foster.py] => Task 13, Epoch 46/170 => Loss 4.380, Loss_clf 0.831, Loss_fe 0.779, Loss_kd 2.567, Train_accy 74.16
2024-08-31 19:56:30,502 [foster.py] => Task 13, Epoch 47/170 => Loss 4.365, Loss_clf 0.834, Loss_fe 0.755, Loss_kd 2.573, Train_accy 73.51, Test_accy 64.04
2024-08-31 19:56:38,101 [foster.py] => Task 13, Epoch 48/170 => Loss 4.323, Loss_clf 0.821, Loss_fe 0.739, Loss_kd 2.560, Train_accy 75.53, Test_accy 63.57
2024-08-31 19:56:45,685 [foster.py] => Task 13, Epoch 49/170 => Loss 4.398, Loss_clf 0.848, Loss_fe 0.790, Loss_kd 2.558, Train_accy 72.83, Test_accy 63.94
2024-08-31 19:56:53,259 [foster.py] => Task 13, Epoch 50/170 => Loss 4.341, Loss_clf 0.822, Loss_fe 0.760, Loss_kd 2.557, Train_accy 74.34, Test_accy 64.26
2024-08-31 19:56:58,595 [foster.py] => Task 13, Epoch 51/170 => Loss 4.320, Loss_clf 0.801, Loss_fe 0.758, Loss_kd 2.559, Train_accy 73.91
2024-08-31 19:57:06,310 [foster.py] => Task 13, Epoch 52/170 => Loss 4.363, Loss_clf 0.847, Loss_fe 0.753, Loss_kd 2.560, Train_accy 73.06, Test_accy 64.66
2024-08-31 19:57:13,876 [foster.py] => Task 13, Epoch 53/170 => Loss 4.350, Loss_clf 0.834, Loss_fe 0.750, Loss_kd 2.563, Train_accy 74.45, Test_accy 64.27
2024-08-31 19:57:21,463 [foster.py] => Task 13, Epoch 54/170 => Loss 4.326, Loss_clf 0.824, Loss_fe 0.742, Loss_kd 2.558, Train_accy 73.96, Test_accy 64.11
2024-08-31 19:57:29,016 [foster.py] => Task 13, Epoch 55/170 => Loss 4.340, Loss_clf 0.834, Loss_fe 0.740, Loss_kd 2.564, Train_accy 74.34, Test_accy 64.84
2024-08-31 19:57:34,258 [foster.py] => Task 13, Epoch 56/170 => Loss 4.248, Loss_clf 0.775, Loss_fe 0.714, Loss_kd 2.557, Train_accy 74.63
2024-08-31 19:57:41,860 [foster.py] => Task 13, Epoch 57/170 => Loss 4.335, Loss_clf 0.822, Loss_fe 0.743, Loss_kd 2.568, Train_accy 73.26, Test_accy 62.10
2024-08-31 19:57:49,457 [foster.py] => Task 13, Epoch 58/170 => Loss 4.303, Loss_clf 0.816, Loss_fe 0.728, Loss_kd 2.557, Train_accy 74.07, Test_accy 64.14
2024-08-31 19:57:57,021 [foster.py] => Task 13, Epoch 59/170 => Loss 4.347, Loss_clf 0.822, Loss_fe 0.756, Loss_kd 2.566, Train_accy 73.33, Test_accy 64.90
2024-08-31 19:58:04,646 [foster.py] => Task 13, Epoch 60/170 => Loss 4.333, Loss_clf 0.832, Loss_fe 0.740, Loss_kd 2.560, Train_accy 73.24, Test_accy 60.90
2024-08-31 19:58:09,867 [foster.py] => Task 13, Epoch 61/170 => Loss 4.288, Loss_clf 0.801, Loss_fe 0.727, Loss_kd 2.558, Train_accy 73.84
2024-08-31 19:58:17,450 [foster.py] => Task 13, Epoch 62/170 => Loss 4.273, Loss_clf 0.775, Loss_fe 0.724, Loss_kd 2.571, Train_accy 75.03, Test_accy 58.04
2024-08-31 19:58:25,019 [foster.py] => Task 13, Epoch 63/170 => Loss 4.287, Loss_clf 0.795, Loss_fe 0.728, Loss_kd 2.561, Train_accy 75.21, Test_accy 63.51
2024-08-31 19:58:32,580 [foster.py] => Task 13, Epoch 64/170 => Loss 4.264, Loss_clf 0.800, Loss_fe 0.714, Loss_kd 2.549, Train_accy 74.54, Test_accy 64.70
2024-08-31 19:58:40,151 [foster.py] => Task 13, Epoch 65/170 => Loss 4.269, Loss_clf 0.796, Loss_fe 0.710, Loss_kd 2.561, Train_accy 74.85, Test_accy 63.80
2024-08-31 19:58:45,478 [foster.py] => Task 13, Epoch 66/170 => Loss 4.322, Loss_clf 0.830, Loss_fe 0.722, Loss_kd 2.567, Train_accy 73.82
2024-08-31 19:58:53,152 [foster.py] => Task 13, Epoch 67/170 => Loss 4.300, Loss_clf 0.811, Loss_fe 0.720, Loss_kd 2.567, Train_accy 73.57, Test_accy 64.97
2024-08-31 19:59:00,786 [foster.py] => Task 13, Epoch 68/170 => Loss 4.279, Loss_clf 0.792, Loss_fe 0.703, Loss_kd 2.580, Train_accy 75.35, Test_accy 65.93
2024-08-31 19:59:08,313 [foster.py] => Task 13, Epoch 69/170 => Loss 4.187, Loss_clf 0.734, Loss_fe 0.695, Loss_kd 2.556, Train_accy 76.29, Test_accy 63.47
2024-08-31 19:59:15,959 [foster.py] => Task 13, Epoch 70/170 => Loss 4.227, Loss_clf 0.776, Loss_fe 0.692, Loss_kd 2.557, Train_accy 75.26, Test_accy 65.20
2024-08-31 19:59:21,298 [foster.py] => Task 13, Epoch 71/170 => Loss 4.166, Loss_clf 0.736, Loss_fe 0.671, Loss_kd 2.556, Train_accy 76.34
2024-08-31 19:59:28,941 [foster.py] => Task 13, Epoch 72/170 => Loss 4.226, Loss_clf 0.764, Loss_fe 0.712, Loss_kd 2.548, Train_accy 75.64, Test_accy 64.66
2024-08-31 19:59:36,514 [foster.py] => Task 13, Epoch 73/170 => Loss 4.231, Loss_clf 0.771, Loss_fe 0.692, Loss_kd 2.566, Train_accy 75.39, Test_accy 62.67
2024-08-31 19:59:44,180 [foster.py] => Task 13, Epoch 74/170 => Loss 4.244, Loss_clf 0.771, Loss_fe 0.707, Loss_kd 2.563, Train_accy 74.38, Test_accy 65.39
2024-08-31 19:59:51,884 [foster.py] => Task 13, Epoch 75/170 => Loss 4.234, Loss_clf 0.791, Loss_fe 0.682, Loss_kd 2.559, Train_accy 74.81, Test_accy 64.34
2024-08-31 19:59:57,183 [foster.py] => Task 13, Epoch 76/170 => Loss 4.208, Loss_clf 0.783, Loss_fe 0.657, Loss_kd 2.566, Train_accy 74.92
2024-08-31 20:00:04,816 [foster.py] => Task 13, Epoch 77/170 => Loss 4.182, Loss_clf 0.756, Loss_fe 0.672, Loss_kd 2.553, Train_accy 75.80, Test_accy 65.00
2024-08-31 20:00:12,457 [foster.py] => Task 13, Epoch 78/170 => Loss 4.227, Loss_clf 0.781, Loss_fe 0.678, Loss_kd 2.564, Train_accy 76.09, Test_accy 64.96
2024-08-31 20:00:20,162 [foster.py] => Task 13, Epoch 79/170 => Loss 4.211, Loss_clf 0.765, Loss_fe 0.684, Loss_kd 2.560, Train_accy 76.09, Test_accy 64.67
2024-08-31 20:00:27,732 [foster.py] => Task 13, Epoch 80/170 => Loss 4.188, Loss_clf 0.767, Loss_fe 0.656, Loss_kd 2.562, Train_accy 75.17, Test_accy 64.79
2024-08-31 20:00:32,987 [foster.py] => Task 13, Epoch 81/170 => Loss 4.177, Loss_clf 0.765, Loss_fe 0.651, Loss_kd 2.559, Train_accy 75.78
2024-08-31 20:00:40,511 [foster.py] => Task 13, Epoch 82/170 => Loss 4.143, Loss_clf 0.740, Loss_fe 0.638, Loss_kd 2.562, Train_accy 76.61, Test_accy 62.56
2024-08-31 20:00:48,129 [foster.py] => Task 13, Epoch 83/170 => Loss 4.209, Loss_clf 0.772, Loss_fe 0.670, Loss_kd 2.565, Train_accy 75.69, Test_accy 63.83
2024-08-31 20:00:55,689 [foster.py] => Task 13, Epoch 84/170 => Loss 4.134, Loss_clf 0.750, Loss_fe 0.640, Loss_kd 2.543, Train_accy 77.10, Test_accy 63.24
2024-08-31 20:01:03,309 [foster.py] => Task 13, Epoch 85/170 => Loss 4.176, Loss_clf 0.754, Loss_fe 0.653, Loss_kd 2.566, Train_accy 75.78, Test_accy 64.56
2024-08-31 20:01:08,582 [foster.py] => Task 13, Epoch 86/170 => Loss 4.099, Loss_clf 0.718, Loss_fe 0.649, Loss_kd 2.533, Train_accy 77.06
2024-08-31 20:01:16,174 [foster.py] => Task 13, Epoch 87/170 => Loss 4.118, Loss_clf 0.729, Loss_fe 0.626, Loss_kd 2.561, Train_accy 76.52, Test_accy 64.64
2024-08-31 20:01:23,760 [foster.py] => Task 13, Epoch 88/170 => Loss 4.153, Loss_clf 0.729, Loss_fe 0.646, Loss_kd 2.576, Train_accy 77.33, Test_accy 64.47
2024-08-31 20:01:31,341 [foster.py] => Task 13, Epoch 89/170 => Loss 4.149, Loss_clf 0.764, Loss_fe 0.620, Loss_kd 2.563, Train_accy 76.38, Test_accy 65.13
2024-08-31 20:01:38,972 [foster.py] => Task 13, Epoch 90/170 => Loss 4.064, Loss_clf 0.695, Loss_fe 0.616, Loss_kd 2.552, Train_accy 77.42, Test_accy 65.47
2024-08-31 20:01:44,241 [foster.py] => Task 13, Epoch 91/170 => Loss 4.087, Loss_clf 0.709, Loss_fe 0.617, Loss_kd 2.559, Train_accy 77.51
2024-08-31 20:01:51,839 [foster.py] => Task 13, Epoch 92/170 => Loss 4.068, Loss_clf 0.725, Loss_fe 0.594, Loss_kd 2.548, Train_accy 76.70, Test_accy 65.96
2024-08-31 20:01:59,572 [foster.py] => Task 13, Epoch 93/170 => Loss 4.081, Loss_clf 0.716, Loss_fe 0.599, Loss_kd 2.563, Train_accy 76.74, Test_accy 64.14
2024-08-31 20:02:07,245 [foster.py] => Task 13, Epoch 94/170 => Loss 4.060, Loss_clf 0.708, Loss_fe 0.590, Loss_kd 2.560, Train_accy 78.11, Test_accy 65.99
2024-08-31 20:02:14,812 [foster.py] => Task 13, Epoch 95/170 => Loss 4.035, Loss_clf 0.698, Loss_fe 0.587, Loss_kd 2.548, Train_accy 77.89, Test_accy 64.97
2024-08-31 20:02:20,124 [foster.py] => Task 13, Epoch 96/170 => Loss 4.037, Loss_clf 0.695, Loss_fe 0.597, Loss_kd 2.544, Train_accy 78.58
2024-08-31 20:02:27,784 [foster.py] => Task 13, Epoch 97/170 => Loss 4.029, Loss_clf 0.691, Loss_fe 0.585, Loss_kd 2.552, Train_accy 77.87, Test_accy 64.80
2024-08-31 20:02:35,509 [foster.py] => Task 13, Epoch 98/170 => Loss 4.042, Loss_clf 0.712, Loss_fe 0.594, Loss_kd 2.535, Train_accy 76.70, Test_accy 63.41
2024-08-31 20:02:43,164 [foster.py] => Task 13, Epoch 99/170 => Loss 4.048, Loss_clf 0.708, Loss_fe 0.574, Loss_kd 2.564, Train_accy 78.13, Test_accy 64.80
2024-08-31 20:02:50,793 [foster.py] => Task 13, Epoch 100/170 => Loss 4.030, Loss_clf 0.716, Loss_fe 0.558, Loss_kd 2.555, Train_accy 78.31, Test_accy 65.64
2024-08-31 20:02:56,031 [foster.py] => Task 13, Epoch 101/170 => Loss 4.005, Loss_clf 0.688, Loss_fe 0.561, Loss_kd 2.555, Train_accy 78.36
2024-08-31 20:03:03,635 [foster.py] => Task 13, Epoch 102/170 => Loss 4.017, Loss_clf 0.698, Loss_fe 0.559, Loss_kd 2.559, Train_accy 78.22, Test_accy 66.03
2024-08-31 20:03:11,163 [foster.py] => Task 13, Epoch 103/170 => Loss 3.990, Loss_clf 0.698, Loss_fe 0.536, Loss_kd 2.555, Train_accy 78.11, Test_accy 66.16
2024-08-31 20:03:18,765 [foster.py] => Task 13, Epoch 104/170 => Loss 3.936, Loss_clf 0.656, Loss_fe 0.533, Loss_kd 2.546, Train_accy 79.44, Test_accy 65.84
2024-08-31 20:03:26,339 [foster.py] => Task 13, Epoch 105/170 => Loss 3.992, Loss_clf 0.683, Loss_fe 0.539, Loss_kd 2.567, Train_accy 79.15, Test_accy 63.87
2024-08-31 20:03:31,570 [foster.py] => Task 13, Epoch 106/170 => Loss 3.975, Loss_clf 0.685, Loss_fe 0.530, Loss_kd 2.558, Train_accy 78.85
2024-08-31 20:03:39,197 [foster.py] => Task 13, Epoch 107/170 => Loss 3.921, Loss_clf 0.646, Loss_fe 0.524, Loss_kd 2.550, Train_accy 80.27, Test_accy 65.90
2024-08-31 20:03:46,752 [foster.py] => Task 13, Epoch 108/170 => Loss 3.961, Loss_clf 0.687, Loss_fe 0.522, Loss_kd 2.551, Train_accy 78.70, Test_accy 66.51
2024-08-31 20:03:54,303 [foster.py] => Task 13, Epoch 109/170 => Loss 3.971, Loss_clf 0.668, Loss_fe 0.541, Loss_kd 2.559, Train_accy 79.24, Test_accy 65.71
2024-08-31 20:04:01,913 [foster.py] => Task 13, Epoch 110/170 => Loss 3.912, Loss_clf 0.654, Loss_fe 0.510, Loss_kd 2.546, Train_accy 79.91, Test_accy 66.19
2024-08-31 20:04:07,249 [foster.py] => Task 13, Epoch 111/170 => Loss 3.913, Loss_clf 0.652, Loss_fe 0.512, Loss_kd 2.548, Train_accy 79.91
2024-08-31 20:04:14,841 [foster.py] => Task 13, Epoch 112/170 => Loss 3.862, Loss_clf 0.636, Loss_fe 0.484, Loss_kd 2.541, Train_accy 79.93, Test_accy 66.56
2024-08-31 20:04:22,448 [foster.py] => Task 13, Epoch 113/170 => Loss 3.887, Loss_clf 0.644, Loss_fe 0.487, Loss_kd 2.555, Train_accy 79.73, Test_accy 65.84
2024-08-31 20:04:30,013 [foster.py] => Task 13, Epoch 114/170 => Loss 3.895, Loss_clf 0.648, Loss_fe 0.500, Loss_kd 2.547, Train_accy 79.82, Test_accy 65.83
2024-08-31 20:04:37,615 [foster.py] => Task 13, Epoch 115/170 => Loss 3.920, Loss_clf 0.659, Loss_fe 0.493, Loss_kd 2.566, Train_accy 79.66, Test_accy 65.51
2024-08-31 20:04:42,906 [foster.py] => Task 13, Epoch 116/170 => Loss 3.907, Loss_clf 0.661, Loss_fe 0.486, Loss_kd 2.558, Train_accy 79.03
2024-08-31 20:04:50,547 [foster.py] => Task 13, Epoch 117/170 => Loss 3.848, Loss_clf 0.640, Loss_fe 0.456, Loss_kd 2.551, Train_accy 80.74, Test_accy 66.23
2024-08-31 20:04:58,225 [foster.py] => Task 13, Epoch 118/170 => Loss 3.843, Loss_clf 0.628, Loss_fe 0.461, Loss_kd 2.552, Train_accy 81.15, Test_accy 65.76
2024-08-31 20:05:05,761 [foster.py] => Task 13, Epoch 119/170 => Loss 3.836, Loss_clf 0.628, Loss_fe 0.445, Loss_kd 2.562, Train_accy 81.28, Test_accy 66.16
2024-08-31 20:05:13,419 [foster.py] => Task 13, Epoch 120/170 => Loss 3.841, Loss_clf 0.629, Loss_fe 0.457, Loss_kd 2.553, Train_accy 80.88, Test_accy 66.01
2024-08-31 20:05:18,785 [foster.py] => Task 13, Epoch 121/170 => Loss 3.852, Loss_clf 0.631, Loss_fe 0.455, Loss_kd 2.564, Train_accy 80.43
2024-08-31 20:05:26,374 [foster.py] => Task 13, Epoch 122/170 => Loss 3.814, Loss_clf 0.613, Loss_fe 0.444, Loss_kd 2.555, Train_accy 81.80, Test_accy 66.30
2024-08-31 20:05:34,019 [foster.py] => Task 13, Epoch 123/170 => Loss 3.791, Loss_clf 0.602, Loss_fe 0.435, Loss_kd 2.553, Train_accy 81.93, Test_accy 66.81
2024-08-31 20:05:41,606 [foster.py] => Task 13, Epoch 124/170 => Loss 3.821, Loss_clf 0.612, Loss_fe 0.440, Loss_kd 2.566, Train_accy 81.51, Test_accy 65.89
2024-08-31 20:05:49,270 [foster.py] => Task 13, Epoch 125/170 => Loss 3.786, Loss_clf 0.603, Loss_fe 0.430, Loss_kd 2.552, Train_accy 81.96, Test_accy 65.56
2024-08-31 20:05:54,574 [foster.py] => Task 13, Epoch 126/170 => Loss 3.789, Loss_clf 0.606, Loss_fe 0.422, Loss_kd 2.558, Train_accy 81.78
2024-08-31 20:06:02,260 [foster.py] => Task 13, Epoch 127/170 => Loss 3.745, Loss_clf 0.579, Loss_fe 0.411, Loss_kd 2.554, Train_accy 82.40, Test_accy 65.60
2024-08-31 20:06:09,834 [foster.py] => Task 13, Epoch 128/170 => Loss 3.746, Loss_clf 0.587, Loss_fe 0.401, Loss_kd 2.556, Train_accy 82.61, Test_accy 67.00
2024-08-31 20:06:17,455 [foster.py] => Task 13, Epoch 129/170 => Loss 3.732, Loss_clf 0.581, Loss_fe 0.402, Loss_kd 2.548, Train_accy 83.42, Test_accy 66.09
2024-08-31 20:06:25,100 [foster.py] => Task 13, Epoch 130/170 => Loss 3.750, Loss_clf 0.593, Loss_fe 0.396, Loss_kd 2.559, Train_accy 82.58, Test_accy 66.20
2024-08-31 20:06:30,418 [foster.py] => Task 13, Epoch 131/170 => Loss 3.749, Loss_clf 0.590, Loss_fe 0.398, Loss_kd 2.559, Train_accy 82.74
2024-08-31 20:06:37,976 [foster.py] => Task 13, Epoch 132/170 => Loss 3.747, Loss_clf 0.592, Loss_fe 0.384, Loss_kd 2.567, Train_accy 82.52, Test_accy 66.56
2024-08-31 20:06:45,556 [foster.py] => Task 13, Epoch 133/170 => Loss 3.745, Loss_clf 0.597, Loss_fe 0.387, Loss_kd 2.559, Train_accy 82.09, Test_accy 66.86
2024-08-31 20:06:53,239 [foster.py] => Task 13, Epoch 134/170 => Loss 3.762, Loss_clf 0.601, Loss_fe 0.396, Loss_kd 2.562, Train_accy 82.07, Test_accy 66.90
2024-08-31 20:07:00,812 [foster.py] => Task 13, Epoch 135/170 => Loss 3.758, Loss_clf 0.599, Loss_fe 0.377, Loss_kd 2.579, Train_accy 82.38, Test_accy 67.14
2024-08-31 20:07:06,040 [foster.py] => Task 13, Epoch 136/170 => Loss 3.654, Loss_clf 0.551, Loss_fe 0.351, Loss_kd 2.551, Train_accy 83.82
2024-08-31 20:07:13,725 [foster.py] => Task 13, Epoch 137/170 => Loss 3.646, Loss_clf 0.544, Loss_fe 0.357, Loss_kd 2.544, Train_accy 84.16, Test_accy 66.53
2024-08-31 20:07:21,363 [foster.py] => Task 13, Epoch 138/170 => Loss 3.686, Loss_clf 0.563, Loss_fe 0.367, Loss_kd 2.555, Train_accy 83.78, Test_accy 66.77
2024-08-31 20:07:28,970 [foster.py] => Task 13, Epoch 139/170 => Loss 3.671, Loss_clf 0.566, Loss_fe 0.352, Loss_kd 2.552, Train_accy 84.02, Test_accy 66.47
2024-08-31 20:07:36,529 [foster.py] => Task 13, Epoch 140/170 => Loss 3.639, Loss_clf 0.551, Loss_fe 0.336, Loss_kd 2.550, Train_accy 83.71, Test_accy 66.91
2024-08-31 20:07:41,790 [foster.py] => Task 13, Epoch 141/170 => Loss 3.634, Loss_clf 0.542, Loss_fe 0.330, Loss_kd 2.560, Train_accy 84.27
2024-08-31 20:07:49,388 [foster.py] => Task 13, Epoch 142/170 => Loss 3.627, Loss_clf 0.547, Loss_fe 0.331, Loss_kd 2.549, Train_accy 83.89, Test_accy 66.96
2024-08-31 20:07:56,925 [foster.py] => Task 13, Epoch 143/170 => Loss 3.635, Loss_clf 0.559, Loss_fe 0.322, Loss_kd 2.553, Train_accy 84.18, Test_accy 66.76
2024-08-31 20:08:04,517 [foster.py] => Task 13, Epoch 144/170 => Loss 3.573, Loss_clf 0.513, Loss_fe 0.313, Loss_kd 2.546, Train_accy 85.64, Test_accy 67.17
2024-08-31 20:08:12,085 [foster.py] => Task 13, Epoch 145/170 => Loss 3.559, Loss_clf 0.511, Loss_fe 0.302, Loss_kd 2.546, Train_accy 84.97, Test_accy 66.70
2024-08-31 20:08:17,338 [foster.py] => Task 13, Epoch 146/170 => Loss 3.641, Loss_clf 0.550, Loss_fe 0.323, Loss_kd 2.566, Train_accy 84.92
2024-08-31 20:08:24,931 [foster.py] => Task 13, Epoch 147/170 => Loss 3.608, Loss_clf 0.537, Loss_fe 0.312, Loss_kd 2.558, Train_accy 84.97, Test_accy 67.26
2024-08-31 20:08:32,539 [foster.py] => Task 13, Epoch 148/170 => Loss 3.618, Loss_clf 0.549, Loss_fe 0.308, Loss_kd 2.558, Train_accy 83.89, Test_accy 67.09
2024-08-31 20:08:40,127 [foster.py] => Task 13, Epoch 149/170 => Loss 3.605, Loss_clf 0.541, Loss_fe 0.305, Loss_kd 2.557, Train_accy 84.58, Test_accy 67.23
2024-08-31 20:08:47,677 [foster.py] => Task 13, Epoch 150/170 => Loss 3.530, Loss_clf 0.507, Loss_fe 0.284, Loss_kd 2.538, Train_accy 85.42, Test_accy 67.21
2024-08-31 20:08:52,918 [foster.py] => Task 13, Epoch 151/170 => Loss 3.537, Loss_clf 0.511, Loss_fe 0.275, Loss_kd 2.549, Train_accy 85.84
2024-08-31 20:09:00,536 [foster.py] => Task 13, Epoch 152/170 => Loss 3.610, Loss_clf 0.548, Loss_fe 0.292, Loss_kd 2.568, Train_accy 84.74, Test_accy 67.07
2024-08-31 20:09:08,190 [foster.py] => Task 13, Epoch 153/170 => Loss 3.529, Loss_clf 0.500, Loss_fe 0.280, Loss_kd 2.548, Train_accy 85.66, Test_accy 67.00
2024-08-31 20:09:15,861 [foster.py] => Task 13, Epoch 154/170 => Loss 3.568, Loss_clf 0.523, Loss_fe 0.275, Loss_kd 2.568, Train_accy 85.48, Test_accy 67.04
2024-08-31 20:09:23,511 [foster.py] => Task 13, Epoch 155/170 => Loss 3.513, Loss_clf 0.501, Loss_fe 0.261, Loss_kd 2.550, Train_accy 86.22, Test_accy 66.96
2024-08-31 20:09:28,849 [foster.py] => Task 13, Epoch 156/170 => Loss 3.541, Loss_clf 0.520, Loss_fe 0.267, Loss_kd 2.552, Train_accy 85.15
2024-08-31 20:09:36,493 [foster.py] => Task 13, Epoch 157/170 => Loss 3.534, Loss_clf 0.509, Loss_fe 0.278, Loss_kd 2.546, Train_accy 85.87, Test_accy 67.31
2024-08-31 20:09:44,177 [foster.py] => Task 13, Epoch 158/170 => Loss 3.531, Loss_clf 0.516, Loss_fe 0.273, Loss_kd 2.541, Train_accy 85.62, Test_accy 67.24
2024-08-31 20:09:51,721 [foster.py] => Task 13, Epoch 159/170 => Loss 3.532, Loss_clf 0.507, Loss_fe 0.268, Loss_kd 2.557, Train_accy 85.89, Test_accy 67.07
2024-08-31 20:09:59,317 [foster.py] => Task 13, Epoch 160/170 => Loss 3.505, Loss_clf 0.502, Loss_fe 0.258, Loss_kd 2.544, Train_accy 85.89, Test_accy 67.06
2024-08-31 20:10:04,884 [foster.py] => Task 13, Epoch 161/170 => Loss 3.493, Loss_clf 0.489, Loss_fe 0.257, Loss_kd 2.547, Train_accy 86.58
2024-08-31 20:10:12,433 [foster.py] => Task 13, Epoch 162/170 => Loss 3.515, Loss_clf 0.496, Loss_fe 0.265, Loss_kd 2.552, Train_accy 86.79, Test_accy 67.06
2024-08-31 20:10:20,064 [foster.py] => Task 13, Epoch 163/170 => Loss 3.539, Loss_clf 0.511, Loss_fe 0.275, Loss_kd 2.552, Train_accy 85.21, Test_accy 67.10
2024-08-31 20:10:27,707 [foster.py] => Task 13, Epoch 164/170 => Loss 3.535, Loss_clf 0.519, Loss_fe 0.262, Loss_kd 2.552, Train_accy 85.57, Test_accy 67.16
2024-08-31 20:10:35,371 [foster.py] => Task 13, Epoch 165/170 => Loss 3.556, Loss_clf 0.520, Loss_fe 0.270, Loss_kd 2.563, Train_accy 85.98, Test_accy 67.14
2024-08-31 20:10:40,660 [foster.py] => Task 13, Epoch 166/170 => Loss 3.525, Loss_clf 0.513, Loss_fe 0.255, Loss_kd 2.555, Train_accy 85.60
2024-08-31 20:10:48,164 [foster.py] => Task 13, Epoch 167/170 => Loss 3.497, Loss_clf 0.494, Loss_fe 0.251, Loss_kd 2.551, Train_accy 86.79, Test_accy 67.11
2024-08-31 20:10:55,715 [foster.py] => Task 13, Epoch 168/170 => Loss 3.542, Loss_clf 0.502, Loss_fe 0.277, Loss_kd 2.561, Train_accy 86.52, Test_accy 67.10
2024-08-31 20:11:03,380 [foster.py] => Task 13, Epoch 169/170 => Loss 3.582, Loss_clf 0.537, Loss_fe 0.271, Loss_kd 2.571, Train_accy 84.67, Test_accy 67.20
2024-08-31 20:11:11,004 [foster.py] => Task 13, Epoch 170/170 => Loss 3.518, Loss_clf 0.505, Loss_fe 0.259, Loss_kd 2.552, Train_accy 86.72, Test_accy 67.11
2024-08-31 20:11:11,006 [foster.py] => do not weight align teacher!
2024-08-31 20:11:11,007 [foster.py] => per cls weights : [1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  1.0336269
 1.0336269  1.0336269  1.0336269  1.0336269  1.0336269  0.56285032
 0.56285032 0.56285032 0.56285032 0.56285032]
2024-08-31 20:11:20,515 [foster.py] => SNet: Task 13, Epoch 1/130 => Loss 29.296,  Loss1 0.726, Train_accy 49.57, Test_accy 61.73
2024-08-31 20:11:28,050 [foster.py] => SNet: Task 13, Epoch 2/130 => Loss 29.152,  Loss1 0.727, Train_accy 66.43
2024-08-31 20:11:35,293 [foster.py] => SNet: Task 13, Epoch 3/130 => Loss 29.152,  Loss1 0.727, Train_accy 69.66
2024-08-31 20:11:42,651 [foster.py] => SNet: Task 13, Epoch 4/130 => Loss 29.145,  Loss1 0.727, Train_accy 71.57
2024-08-31 20:11:50,305 [foster.py] => SNet: Task 13, Epoch 5/130 => Loss 29.137,  Loss1 0.727, Train_accy 72.79
2024-08-31 20:11:59,455 [foster.py] => SNet: Task 13, Epoch 6/130 => Loss 29.118,  Loss1 0.727, Train_accy 74.07, Test_accy 64.50
2024-08-31 20:12:06,887 [foster.py] => SNet: Task 13, Epoch 7/130 => Loss 29.076,  Loss1 0.727, Train_accy 73.08
2024-08-31 20:12:14,077 [foster.py] => SNet: Task 13, Epoch 8/130 => Loss 29.108,  Loss1 0.727, Train_accy 75.08
2024-08-31 20:12:21,157 [foster.py] => SNet: Task 13, Epoch 9/130 => Loss 29.103,  Loss1 0.727, Train_accy 74.65
2024-08-31 20:12:28,293 [foster.py] => SNet: Task 13, Epoch 10/130 => Loss 29.109,  Loss1 0.728, Train_accy 75.33
2024-08-31 20:12:37,865 [foster.py] => SNet: Task 13, Epoch 11/130 => Loss 29.133,  Loss1 0.727, Train_accy 75.55, Test_accy 63.50
2024-08-31 20:12:45,029 [foster.py] => SNet: Task 13, Epoch 12/130 => Loss 29.088,  Loss1 0.727, Train_accy 75.60
2024-08-31 20:12:52,362 [foster.py] => SNet: Task 13, Epoch 13/130 => Loss 29.093,  Loss1 0.728, Train_accy 77.66
2024-08-31 20:12:59,636 [foster.py] => SNet: Task 13, Epoch 14/130 => Loss 29.127,  Loss1 0.727, Train_accy 76.02
2024-08-31 20:13:06,915 [foster.py] => SNet: Task 13, Epoch 15/130 => Loss 29.079,  Loss1 0.727, Train_accy 76.54
2024-08-31 20:13:16,315 [foster.py] => SNet: Task 13, Epoch 16/130 => Loss 29.111,  Loss1 0.727, Train_accy 76.58, Test_accy 63.69
2024-08-31 20:13:23,515 [foster.py] => SNet: Task 13, Epoch 17/130 => Loss 29.114,  Loss1 0.727, Train_accy 76.65
2024-08-31 20:13:30,619 [foster.py] => SNet: Task 13, Epoch 18/130 => Loss 29.081,  Loss1 0.727, Train_accy 76.58
2024-08-31 20:13:37,832 [foster.py] => SNet: Task 13, Epoch 19/130 => Loss 29.073,  Loss1 0.727, Train_accy 77.57
2024-08-31 20:13:45,010 [foster.py] => SNet: Task 13, Epoch 20/130 => Loss 29.104,  Loss1 0.727, Train_accy 75.66
2024-08-31 20:13:54,377 [foster.py] => SNet: Task 13, Epoch 21/130 => Loss 29.107,  Loss1 0.727, Train_accy 77.15, Test_accy 64.80
2024-08-31 20:14:01,433 [foster.py] => SNet: Task 13, Epoch 22/130 => Loss 29.108,  Loss1 0.727, Train_accy 76.36
2024-08-31 20:14:08,655 [foster.py] => SNet: Task 13, Epoch 23/130 => Loss 29.094,  Loss1 0.727, Train_accy 77.69
2024-08-31 20:14:15,776 [foster.py] => SNet: Task 13, Epoch 24/130 => Loss 29.096,  Loss1 0.727, Train_accy 77.84
2024-08-31 20:14:23,021 [foster.py] => SNet: Task 13, Epoch 25/130 => Loss 29.071,  Loss1 0.727, Train_accy 78.29
2024-08-31 20:14:32,536 [foster.py] => SNet: Task 13, Epoch 26/130 => Loss 29.082,  Loss1 0.727, Train_accy 77.57, Test_accy 65.10
2024-08-31 20:14:39,635 [foster.py] => SNet: Task 13, Epoch 27/130 => Loss 29.123,  Loss1 0.727, Train_accy 76.76
2024-08-31 20:14:46,794 [foster.py] => SNet: Task 13, Epoch 28/130 => Loss 29.114,  Loss1 0.727, Train_accy 77.30
2024-08-31 20:14:53,909 [foster.py] => SNet: Task 13, Epoch 29/130 => Loss 29.070,  Loss1 0.727, Train_accy 78.54
2024-08-31 20:15:01,312 [foster.py] => SNet: Task 13, Epoch 30/130 => Loss 29.075,  Loss1 0.727, Train_accy 77.26
2024-08-31 20:15:10,480 [foster.py] => SNet: Task 13, Epoch 31/130 => Loss 29.078,  Loss1 0.727, Train_accy 78.13, Test_accy 65.29
2024-08-31 20:15:17,606 [foster.py] => SNet: Task 13, Epoch 32/130 => Loss 29.089,  Loss1 0.727, Train_accy 78.09
2024-08-31 20:15:25,014 [foster.py] => SNet: Task 13, Epoch 33/130 => Loss 29.094,  Loss1 0.727, Train_accy 77.80
2024-08-31 20:15:32,183 [foster.py] => SNet: Task 13, Epoch 34/130 => Loss 29.103,  Loss1 0.727, Train_accy 77.73
2024-08-31 20:15:39,625 [foster.py] => SNet: Task 13, Epoch 35/130 => Loss 29.122,  Loss1 0.727, Train_accy 77.84
2024-08-31 20:15:48,853 [foster.py] => SNet: Task 13, Epoch 36/130 => Loss 29.089,  Loss1 0.728, Train_accy 78.09, Test_accy 64.97
2024-08-31 20:15:56,217 [foster.py] => SNet: Task 13, Epoch 37/130 => Loss 29.077,  Loss1 0.727, Train_accy 79.69
2024-08-31 20:16:03,299 [foster.py] => SNet: Task 13, Epoch 38/130 => Loss 29.068,  Loss1 0.727, Train_accy 79.30
2024-08-31 20:16:10,696 [foster.py] => SNet: Task 13, Epoch 39/130 => Loss 29.067,  Loss1 0.727, Train_accy 78.99
2024-08-31 20:16:17,934 [foster.py] => SNet: Task 13, Epoch 40/130 => Loss 29.073,  Loss1 0.727, Train_accy 79.82
2024-08-31 20:16:27,349 [foster.py] => SNet: Task 13, Epoch 41/130 => Loss 29.089,  Loss1 0.727, Train_accy 78.52, Test_accy 64.90
2024-08-31 20:16:34,756 [foster.py] => SNet: Task 13, Epoch 42/130 => Loss 29.077,  Loss1 0.727, Train_accy 78.85
2024-08-31 20:16:41,980 [foster.py] => SNet: Task 13, Epoch 43/130 => Loss 29.082,  Loss1 0.727, Train_accy 79.21
2024-08-31 20:16:49,031 [foster.py] => SNet: Task 13, Epoch 44/130 => Loss 29.088,  Loss1 0.727, Train_accy 79.42
2024-08-31 20:16:56,107 [foster.py] => SNet: Task 13, Epoch 45/130 => Loss 29.050,  Loss1 0.727, Train_accy 79.62
2024-08-31 20:17:05,530 [foster.py] => SNet: Task 13, Epoch 46/130 => Loss 29.088,  Loss1 0.727, Train_accy 78.29, Test_accy 64.96
2024-08-31 20:17:12,979 [foster.py] => SNet: Task 13, Epoch 47/130 => Loss 29.081,  Loss1 0.727, Train_accy 78.11
2024-08-31 20:17:20,462 [foster.py] => SNet: Task 13, Epoch 48/130 => Loss 29.060,  Loss1 0.727, Train_accy 80.09
2024-08-31 20:17:27,750 [foster.py] => SNet: Task 13, Epoch 49/130 => Loss 29.093,  Loss1 0.728, Train_accy 78.97
2024-08-31 20:17:34,934 [foster.py] => SNet: Task 13, Epoch 50/130 => Loss 29.081,  Loss1 0.727, Train_accy 79.15
2024-08-31 20:17:44,196 [foster.py] => SNet: Task 13, Epoch 51/130 => Loss 29.108,  Loss1 0.727, Train_accy 79.33, Test_accy 65.34
2024-08-31 20:17:51,302 [foster.py] => SNet: Task 13, Epoch 52/130 => Loss 29.071,  Loss1 0.727, Train_accy 79.84
2024-08-31 20:17:58,330 [foster.py] => SNet: Task 13, Epoch 53/130 => Loss 29.052,  Loss1 0.727, Train_accy 79.55
2024-08-31 20:18:05,932 [foster.py] => SNet: Task 13, Epoch 54/130 => Loss 29.081,  Loss1 0.727, Train_accy 80.54
2024-08-31 20:18:13,282 [foster.py] => SNet: Task 13, Epoch 55/130 => Loss 29.073,  Loss1 0.727, Train_accy 79.66
2024-08-31 20:18:22,594 [foster.py] => SNet: Task 13, Epoch 56/130 => Loss 29.082,  Loss1 0.727, Train_accy 79.69, Test_accy 65.89
2024-08-31 20:18:30,189 [foster.py] => SNet: Task 13, Epoch 57/130 => Loss 29.089,  Loss1 0.727, Train_accy 80.16
2024-08-31 20:18:37,485 [foster.py] => SNet: Task 13, Epoch 58/130 => Loss 29.063,  Loss1 0.727, Train_accy 80.81
2024-08-31 20:18:44,660 [foster.py] => SNet: Task 13, Epoch 59/130 => Loss 29.082,  Loss1 0.727, Train_accy 78.45
2024-08-31 20:18:52,058 [foster.py] => SNet: Task 13, Epoch 60/130 => Loss 29.075,  Loss1 0.727, Train_accy 79.39
2024-08-31 20:19:01,262 [foster.py] => SNet: Task 13, Epoch 61/130 => Loss 29.098,  Loss1 0.727, Train_accy 80.36, Test_accy 65.33
2024-08-31 20:19:08,403 [foster.py] => SNet: Task 13, Epoch 62/130 => Loss 29.105,  Loss1 0.727, Train_accy 78.34
2024-08-31 20:19:16,220 [foster.py] => SNet: Task 13, Epoch 63/130 => Loss 29.102,  Loss1 0.727, Train_accy 79.93
2024-08-31 20:19:23,580 [foster.py] => SNet: Task 13, Epoch 64/130 => Loss 29.073,  Loss1 0.727, Train_accy 79.69
2024-08-31 20:19:30,717 [foster.py] => SNet: Task 13, Epoch 65/130 => Loss 29.091,  Loss1 0.727, Train_accy 79.57
2024-08-31 20:19:40,344 [foster.py] => SNet: Task 13, Epoch 66/130 => Loss 29.111,  Loss1 0.727, Train_accy 79.46, Test_accy 66.07
2024-08-31 20:19:47,853 [foster.py] => SNet: Task 13, Epoch 67/130 => Loss 29.099,  Loss1 0.727, Train_accy 79.53
2024-08-31 20:19:55,160 [foster.py] => SNet: Task 13, Epoch 68/130 => Loss 29.098,  Loss1 0.727, Train_accy 79.57
2024-08-31 20:20:02,256 [foster.py] => SNet: Task 13, Epoch 69/130 => Loss 29.092,  Loss1 0.727, Train_accy 79.82
2024-08-31 20:20:09,403 [foster.py] => SNet: Task 13, Epoch 70/130 => Loss 29.106,  Loss1 0.727, Train_accy 80.79
2024-08-31 20:20:18,787 [foster.py] => SNet: Task 13, Epoch 71/130 => Loss 29.086,  Loss1 0.727, Train_accy 80.29, Test_accy 66.14
2024-08-31 20:20:25,882 [foster.py] => SNet: Task 13, Epoch 72/130 => Loss 29.069,  Loss1 0.727, Train_accy 80.49
2024-08-31 20:20:33,135 [foster.py] => SNet: Task 13, Epoch 73/130 => Loss 29.122,  Loss1 0.727, Train_accy 79.42
2024-08-31 20:20:40,181 [foster.py] => SNet: Task 13, Epoch 74/130 => Loss 29.060,  Loss1 0.728, Train_accy 79.89
2024-08-31 20:20:47,491 [foster.py] => SNet: Task 13, Epoch 75/130 => Loss 29.076,  Loss1 0.727, Train_accy 79.93
2024-08-31 20:20:56,980 [foster.py] => SNet: Task 13, Epoch 76/130 => Loss 29.098,  Loss1 0.727, Train_accy 79.84, Test_accy 66.03
2024-08-31 20:21:04,062 [foster.py] => SNet: Task 13, Epoch 77/130 => Loss 29.059,  Loss1 0.727, Train_accy 79.75
2024-08-31 20:21:11,808 [foster.py] => SNet: Task 13, Epoch 78/130 => Loss 29.053,  Loss1 0.727, Train_accy 80.22
2024-08-31 20:21:18,879 [foster.py] => SNet: Task 13, Epoch 79/130 => Loss 29.076,  Loss1 0.727, Train_accy 80.34
2024-08-31 20:21:25,920 [foster.py] => SNet: Task 13, Epoch 80/130 => Loss 29.054,  Loss1 0.727, Train_accy 80.38
2024-08-31 20:21:35,407 [foster.py] => SNet: Task 13, Epoch 81/130 => Loss 29.074,  Loss1 0.727, Train_accy 80.72, Test_accy 66.46
2024-08-31 20:21:42,872 [foster.py] => SNet: Task 13, Epoch 82/130 => Loss 29.069,  Loss1 0.727, Train_accy 80.85
2024-08-31 20:21:49,958 [foster.py] => SNet: Task 13, Epoch 83/130 => Loss 29.082,  Loss1 0.727, Train_accy 80.02
2024-08-31 20:21:57,138 [foster.py] => SNet: Task 13, Epoch 84/130 => Loss 29.071,  Loss1 0.727, Train_accy 80.65
2024-08-31 20:22:04,311 [foster.py] => SNet: Task 13, Epoch 85/130 => Loss 29.082,  Loss1 0.727, Train_accy 80.07
2024-08-31 20:22:13,472 [foster.py] => SNet: Task 13, Epoch 86/130 => Loss 29.095,  Loss1 0.727, Train_accy 80.52, Test_accy 65.77
2024-08-31 20:22:20,722 [foster.py] => SNet: Task 13, Epoch 87/130 => Loss 29.101,  Loss1 0.727, Train_accy 79.98
2024-08-31 20:22:28,470 [foster.py] => SNet: Task 13, Epoch 88/130 => Loss 29.073,  Loss1 0.727, Train_accy 80.83
2024-08-31 20:22:35,576 [foster.py] => SNet: Task 13, Epoch 89/130 => Loss 29.072,  Loss1 0.727, Train_accy 80.29
2024-08-31 20:22:42,914 [foster.py] => SNet: Task 13, Epoch 90/130 => Loss 29.083,  Loss1 0.727, Train_accy 80.81
2024-08-31 20:22:52,211 [foster.py] => SNet: Task 13, Epoch 91/130 => Loss 29.095,  Loss1 0.727, Train_accy 80.45, Test_accy 66.01
2024-08-31 20:22:59,350 [foster.py] => SNet: Task 13, Epoch 92/130 => Loss 29.050,  Loss1 0.727, Train_accy 79.57
2024-08-31 20:23:06,450 [foster.py] => SNet: Task 13, Epoch 93/130 => Loss 29.084,  Loss1 0.727, Train_accy 80.58
2024-08-31 20:23:14,038 [foster.py] => SNet: Task 13, Epoch 94/130 => Loss 29.076,  Loss1 0.727, Train_accy 80.34
2024-08-31 20:23:21,337 [foster.py] => SNet: Task 13, Epoch 95/130 => Loss 29.084,  Loss1 0.728, Train_accy 80.88
2024-08-31 20:23:30,477 [foster.py] => SNet: Task 13, Epoch 96/130 => Loss 29.092,  Loss1 0.727, Train_accy 80.27, Test_accy 65.86
2024-08-31 20:23:37,566 [foster.py] => SNet: Task 13, Epoch 97/130 => Loss 29.069,  Loss1 0.728, Train_accy 80.81
2024-08-31 20:23:44,860 [foster.py] => SNet: Task 13, Epoch 98/130 => Loss 29.070,  Loss1 0.727, Train_accy 79.66
2024-08-31 20:23:52,291 [foster.py] => SNet: Task 13, Epoch 99/130 => Loss 29.074,  Loss1 0.727, Train_accy 80.07
2024-08-31 20:23:59,662 [foster.py] => SNet: Task 13, Epoch 100/130 => Loss 29.074,  Loss1 0.727, Train_accy 80.83
2024-08-31 20:24:09,249 [foster.py] => SNet: Task 13, Epoch 101/130 => Loss 29.088,  Loss1 0.727, Train_accy 80.54, Test_accy 66.04
2024-08-31 20:24:16,271 [foster.py] => SNet: Task 13, Epoch 102/130 => Loss 29.040,  Loss1 0.727, Train_accy 81.15
2024-08-31 20:24:23,385 [foster.py] => SNet: Task 13, Epoch 103/130 => Loss 29.078,  Loss1 0.727, Train_accy 81.19
2024-08-31 20:24:30,817 [foster.py] => SNet: Task 13, Epoch 104/130 => Loss 29.051,  Loss1 0.727, Train_accy 81.01
2024-08-31 20:24:38,624 [foster.py] => SNet: Task 13, Epoch 105/130 => Loss 29.065,  Loss1 0.727, Train_accy 80.58
2024-08-31 20:24:47,798 [foster.py] => SNet: Task 13, Epoch 106/130 => Loss 29.054,  Loss1 0.727, Train_accy 80.83, Test_accy 66.13
2024-08-31 20:24:55,373 [foster.py] => SNet: Task 13, Epoch 107/130 => Loss 29.099,  Loss1 0.727, Train_accy 80.31
2024-08-31 20:25:02,423 [foster.py] => SNet: Task 13, Epoch 108/130 => Loss 29.089,  Loss1 0.727, Train_accy 79.93
2024-08-31 20:25:09,550 [foster.py] => SNet: Task 13, Epoch 109/130 => Loss 29.045,  Loss1 0.727, Train_accy 82.20
2024-08-31 20:25:16,650 [foster.py] => SNet: Task 13, Epoch 110/130 => Loss 29.073,  Loss1 0.727, Train_accy 81.24
2024-08-31 20:25:25,854 [foster.py] => SNet: Task 13, Epoch 111/130 => Loss 29.072,  Loss1 0.727, Train_accy 81.37, Test_accy 65.89
2024-08-31 20:25:33,196 [foster.py] => SNet: Task 13, Epoch 112/130 => Loss 29.058,  Loss1 0.727, Train_accy 80.09
2024-08-31 20:25:40,334 [foster.py] => SNet: Task 13, Epoch 113/130 => Loss 29.065,  Loss1 0.727, Train_accy 81.15
2024-08-31 20:25:47,567 [foster.py] => SNet: Task 13, Epoch 114/130 => Loss 29.084,  Loss1 0.727, Train_accy 80.18
2024-08-31 20:25:54,666 [foster.py] => SNet: Task 13, Epoch 115/130 => Loss 29.079,  Loss1 0.727, Train_accy 81.06
2024-08-31 20:26:04,023 [foster.py] => SNet: Task 13, Epoch 116/130 => Loss 29.083,  Loss1 0.727, Train_accy 80.72, Test_accy 66.31
2024-08-31 20:26:11,297 [foster.py] => SNet: Task 13, Epoch 117/130 => Loss 29.093,  Loss1 0.727, Train_accy 80.99
2024-08-31 20:26:18,777 [foster.py] => SNet: Task 13, Epoch 118/130 => Loss 29.063,  Loss1 0.727, Train_accy 81.24
2024-08-31 20:26:25,833 [foster.py] => SNet: Task 13, Epoch 119/130 => Loss 29.067,  Loss1 0.727, Train_accy 80.70
2024-08-31 20:26:33,269 [foster.py] => SNet: Task 13, Epoch 120/130 => Loss 29.051,  Loss1 0.727, Train_accy 80.43
2024-08-31 20:26:42,605 [foster.py] => SNet: Task 13, Epoch 121/130 => Loss 29.052,  Loss1 0.727, Train_accy 81.51, Test_accy 66.10
2024-08-31 20:26:49,994 [foster.py] => SNet: Task 13, Epoch 122/130 => Loss 29.066,  Loss1 0.727, Train_accy 81.03
2024-08-31 20:26:57,456 [foster.py] => SNet: Task 13, Epoch 123/130 => Loss 29.068,  Loss1 0.727, Train_accy 80.09
2024-08-31 20:27:04,716 [foster.py] => SNet: Task 13, Epoch 124/130 => Loss 29.064,  Loss1 0.727, Train_accy 80.43
2024-08-31 20:27:11,876 [foster.py] => SNet: Task 13, Epoch 125/130 => Loss 29.076,  Loss1 0.727, Train_accy 80.38
2024-08-31 20:27:21,230 [foster.py] => SNet: Task 13, Epoch 126/130 => Loss 29.069,  Loss1 0.727, Train_accy 80.09, Test_accy 66.21
2024-08-31 20:27:28,278 [foster.py] => SNet: Task 13, Epoch 127/130 => Loss 29.080,  Loss1 0.727, Train_accy 81.08
2024-08-31 20:27:36,180 [foster.py] => SNet: Task 13, Epoch 128/130 => Loss 29.099,  Loss1 0.727, Train_accy 80.65
2024-08-31 20:27:43,187 [foster.py] => SNet: Task 13, Epoch 129/130 => Loss 29.059,  Loss1 0.727, Train_accy 81.06
2024-08-31 20:27:50,250 [foster.py] => SNet: Task 13, Epoch 130/130 => Loss 29.097,  Loss1 0.727, Train_accy 80.27
2024-08-31 20:27:50,250 [foster.py] => do not weight align student!
2024-08-31 20:27:52,316 [foster.py] => darknet eval: 
2024-08-31 20:27:52,316 [foster.py] => CNN top1 curve: 66.11
2024-08-31 20:27:52,316 [foster.py] => CNN top5 curve: 89.59
2024-08-31 20:27:52,317 [foster.py] => CNN top1 平均值: 66.11
2024-08-31 20:27:52,320 [foster.py] => timees : 2216.1401097774506
2024-08-31 20:27:52,321 [base.py] => Reducing exemplars...(28 per classes)
2024-08-31 20:28:14,929 [base.py] => Constructing exemplars...(28 per classes)
2024-08-31 20:28:24,906 [foster.py] => Exemplar size: 1960
2024-08-31 20:28:24,906 [trainer.py] => CNN: {'total': 67.11, '00-09': 67.6, '10-19': 50.7, '20-29': 67.1, '30-39': 63.5, '40-49': 73.4, '50-59': 70.2, '60-69': 77.3, 'old': 65.51, 'new': 88.0}
2024-08-31 20:28:24,907 [trainer.py] => NME: {'total': 61.64, '00-09': 59.7, '10-19': 44.8, '20-29': 60.5, '30-39': 59.2, '40-49': 70.7, '50-59': 68.7, '60-69': 67.9, 'old': 59.63, 'new': 87.8}
2024-08-31 20:28:24,907 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11]
2024-08-31 20:28:24,907 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87]
2024-08-31 20:28:24,907 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64]
2024-08-31 20:28:24,907 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44]

2024-08-31 20:28:24,907 [trainer.py] => CNN top1 平均值: 78.68
2024-08-31 20:28:24,909 [trainer.py] => All params: 1300353
2024-08-31 20:28:24,912 [trainer.py] => Trainable params: 654854
2024-08-31 20:28:24,975 [foster.py] => Learning on 70-75
2024-08-31 20:28:24,978 [foster.py] => All params: 1301648
2024-08-31 20:28:24,980 [foster.py] => Trainable params: 655824
2024-08-31 20:28:25,030 [foster.py] => per cls weights : [1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298 1.01884298
 1.01884298 1.01884298 1.01884298 1.01884298 0.73619831 0.73619831
 0.73619831 0.73619831 0.73619831]
2024-08-31 20:28:30,501 [foster.py] => Task 14, Epoch 1/170 => Loss 7.379, Loss_clf 2.490, Loss_fe 1.972, Loss_kd 2.715, Train_accy 56.95
2024-08-31 20:28:38,311 [foster.py] => Task 14, Epoch 2/170 => Loss 5.598, Loss_clf 1.088, Loss_fe 1.608, Loss_kd 2.700, Train_accy 70.27, Test_accy 61.56
2024-08-31 20:28:46,001 [foster.py] => Task 14, Epoch 3/170 => Loss 5.328, Loss_clf 1.029, Loss_fe 1.410, Loss_kd 2.689, Train_accy 69.98, Test_accy 58.76
2024-08-31 20:28:53,689 [foster.py] => Task 14, Epoch 4/170 => Loss 5.239, Loss_clf 1.039, Loss_fe 1.294, Loss_kd 2.705, Train_accy 69.06, Test_accy 60.55
2024-08-31 20:29:01,408 [foster.py] => Task 14, Epoch 5/170 => Loss 5.167, Loss_clf 1.024, Loss_fe 1.226, Loss_kd 2.716, Train_accy 69.62, Test_accy 59.97
2024-08-31 20:29:06,719 [foster.py] => Task 14, Epoch 6/170 => Loss 5.111, Loss_clf 1.038, Loss_fe 1.169, Loss_kd 2.703, Train_accy 68.45
2024-08-31 20:29:14,384 [foster.py] => Task 14, Epoch 7/170 => Loss 4.965, Loss_clf 0.951, Loss_fe 1.120, Loss_kd 2.695, Train_accy 70.47, Test_accy 62.59
2024-08-31 20:29:22,073 [foster.py] => Task 14, Epoch 8/170 => Loss 4.958, Loss_clf 0.969, Loss_fe 1.078, Loss_kd 2.710, Train_accy 70.54, Test_accy 61.96
2024-08-31 20:29:29,745 [foster.py] => Task 14, Epoch 9/170 => Loss 4.920, Loss_clf 0.967, Loss_fe 1.047, Loss_kd 2.706, Train_accy 70.04, Test_accy 59.97
2024-08-31 20:29:37,487 [foster.py] => Task 14, Epoch 10/170 => Loss 4.990, Loss_clf 1.040, Loss_fe 1.043, Loss_kd 2.706, Train_accy 68.34, Test_accy 60.04
2024-08-31 20:29:42,718 [foster.py] => Task 14, Epoch 11/170 => Loss 4.923, Loss_clf 1.016, Loss_fe 0.991, Loss_kd 2.715, Train_accy 69.28
2024-08-31 20:29:50,434 [foster.py] => Task 14, Epoch 12/170 => Loss 4.863, Loss_clf 0.989, Loss_fe 0.972, Loss_kd 2.702, Train_accy 69.80, Test_accy 60.59
2024-08-31 20:29:58,042 [foster.py] => Task 14, Epoch 13/170 => Loss 4.791, Loss_clf 0.937, Loss_fe 0.965, Loss_kd 2.690, Train_accy 71.10, Test_accy 60.87
2024-08-31 20:30:05,761 [foster.py] => Task 14, Epoch 14/170 => Loss 4.788, Loss_clf 0.929, Loss_fe 0.963, Loss_kd 2.697, Train_accy 70.49, Test_accy 62.15
2024-08-31 20:30:13,525 [foster.py] => Task 14, Epoch 15/170 => Loss 4.846, Loss_clf 0.983, Loss_fe 0.959, Loss_kd 2.705, Train_accy 70.61, Test_accy 62.43
2024-08-31 20:30:18,758 [foster.py] => Task 14, Epoch 16/170 => Loss 4.858, Loss_clf 0.960, Loss_fe 1.002, Loss_kd 2.696, Train_accy 70.83
2024-08-31 20:30:26,539 [foster.py] => Task 14, Epoch 17/170 => Loss 4.753, Loss_clf 0.906, Loss_fe 0.951, Loss_kd 2.697, Train_accy 71.39, Test_accy 61.72
2024-08-31 20:30:34,234 [foster.py] => Task 14, Epoch 18/170 => Loss 4.753, Loss_clf 0.919, Loss_fe 0.934, Loss_kd 2.702, Train_accy 71.08, Test_accy 62.75
2024-08-31 20:30:41,914 [foster.py] => Task 14, Epoch 19/170 => Loss 4.890, Loss_clf 1.038, Loss_fe 0.959, Loss_kd 2.694, Train_accy 69.24, Test_accy 59.96
2024-08-31 20:30:49,642 [foster.py] => Task 14, Epoch 20/170 => Loss 4.934, Loss_clf 1.047, Loss_fe 0.963, Loss_kd 2.724, Train_accy 68.74, Test_accy 62.87
2024-08-31 20:30:54,926 [foster.py] => Task 14, Epoch 21/170 => Loss 4.803, Loss_clf 0.950, Loss_fe 0.958, Loss_kd 2.697, Train_accy 70.47
2024-08-31 20:31:02,643 [foster.py] => Task 14, Epoch 22/170 => Loss 4.780, Loss_clf 0.948, Loss_fe 0.934, Loss_kd 2.699, Train_accy 70.65, Test_accy 61.45
2024-08-31 20:31:10,443 [foster.py] => Task 14, Epoch 23/170 => Loss 4.757, Loss_clf 0.919, Loss_fe 0.950, Loss_kd 2.690, Train_accy 69.62, Test_accy 60.65
2024-08-31 20:31:18,162 [foster.py] => Task 14, Epoch 24/170 => Loss 4.773, Loss_clf 0.928, Loss_fe 0.951, Loss_kd 2.696, Train_accy 70.27, Test_accy 62.88
2024-08-31 20:31:25,940 [foster.py] => Task 14, Epoch 25/170 => Loss 4.909, Loss_clf 1.022, Loss_fe 0.987, Loss_kd 2.701, Train_accy 68.79, Test_accy 59.32
2024-08-31 20:31:31,235 [foster.py] => Task 14, Epoch 26/170 => Loss 4.918, Loss_clf 0.995, Loss_fe 1.008, Loss_kd 2.716, Train_accy 68.57
2024-08-31 20:31:38,930 [foster.py] => Task 14, Epoch 27/170 => Loss 4.778, Loss_clf 0.953, Loss_fe 0.929, Loss_kd 2.697, Train_accy 69.96, Test_accy 61.00
2024-08-31 20:31:46,619 [foster.py] => Task 14, Epoch 28/170 => Loss 4.899, Loss_clf 1.062, Loss_fe 0.933, Loss_kd 2.706, Train_accy 68.21, Test_accy 56.77
2024-08-31 20:31:54,326 [foster.py] => Task 14, Epoch 29/170 => Loss 4.951, Loss_clf 1.078, Loss_fe 0.974, Loss_kd 2.700, Train_accy 68.27, Test_accy 57.72
2024-08-31 20:32:02,041 [foster.py] => Task 14, Epoch 30/170 => Loss 4.890, Loss_clf 1.001, Loss_fe 0.983, Loss_kd 2.708, Train_accy 68.50, Test_accy 60.39
2024-08-31 20:32:07,274 [foster.py] => Task 14, Epoch 31/170 => Loss 4.810, Loss_clf 0.960, Loss_fe 0.949, Loss_kd 2.702, Train_accy 69.62
2024-08-31 20:32:14,912 [foster.py] => Task 14, Epoch 32/170 => Loss 4.719, Loss_clf 0.927, Loss_fe 0.896, Loss_kd 2.698, Train_accy 70.38, Test_accy 61.96
2024-08-31 20:32:22,604 [foster.py] => Task 14, Epoch 33/170 => Loss 4.791, Loss_clf 0.961, Loss_fe 0.923, Loss_kd 2.708, Train_accy 68.48, Test_accy 62.61
2024-08-31 20:32:30,301 [foster.py] => Task 14, Epoch 34/170 => Loss 4.782, Loss_clf 0.979, Loss_fe 0.907, Loss_kd 2.698, Train_accy 69.10, Test_accy 61.05
2024-08-31 20:32:38,062 [foster.py] => Task 14, Epoch 35/170 => Loss 4.929, Loss_clf 1.061, Loss_fe 0.947, Loss_kd 2.721, Train_accy 68.30, Test_accy 62.37
2024-08-31 20:32:43,348 [foster.py] => Task 14, Epoch 36/170 => Loss 4.814, Loss_clf 0.974, Loss_fe 0.923, Loss_kd 2.718, Train_accy 69.17
2024-08-31 20:32:51,106 [foster.py] => Task 14, Epoch 37/170 => Loss 4.782, Loss_clf 0.999, Loss_fe 0.885, Loss_kd 2.699, Train_accy 67.60, Test_accy 58.47
2024-08-31 20:32:58,845 [foster.py] => Task 14, Epoch 38/170 => Loss 4.849, Loss_clf 0.988, Loss_fe 0.937, Loss_kd 2.724, Train_accy 68.88, Test_accy 60.47
2024-08-31 20:33:06,592 [foster.py] => Task 14, Epoch 39/170 => Loss 4.715, Loss_clf 0.925, Loss_fe 0.896, Loss_kd 2.697, Train_accy 70.85, Test_accy 60.15
2024-08-31 20:33:14,325 [foster.py] => Task 14, Epoch 40/170 => Loss 4.787, Loss_clf 0.956, Loss_fe 0.920, Loss_kd 2.712, Train_accy 70.00, Test_accy 60.44
2024-08-31 20:33:19,581 [foster.py] => Task 14, Epoch 41/170 => Loss 4.945, Loss_clf 1.122, Loss_fe 0.915, Loss_kd 2.709, Train_accy 67.58
2024-08-31 20:33:27,329 [foster.py] => Task 14, Epoch 42/170 => Loss 4.855, Loss_clf 1.027, Loss_fe 0.917, Loss_kd 2.712, Train_accy 69.39, Test_accy 54.09
2024-08-31 20:33:35,015 [foster.py] => Task 14, Epoch 43/170 => Loss 4.795, Loss_clf 0.966, Loss_fe 0.927, Loss_kd 2.704, Train_accy 69.46, Test_accy 62.03
2024-08-31 20:33:42,782 [foster.py] => Task 14, Epoch 44/170 => Loss 4.718, Loss_clf 0.901, Loss_fe 0.919, Loss_kd 2.699, Train_accy 69.69, Test_accy 60.36
2024-08-31 20:33:50,535 [foster.py] => Task 14, Epoch 45/170 => Loss 4.676, Loss_clf 0.929, Loss_fe 0.856, Loss_kd 2.693, Train_accy 69.89, Test_accy 62.19
2024-08-31 20:33:55,795 [foster.py] => Task 14, Epoch 46/170 => Loss 4.744, Loss_clf 0.945, Loss_fe 0.899, Loss_kd 2.702, Train_accy 69.15
2024-08-31 20:34:03,519 [foster.py] => Task 14, Epoch 47/170 => Loss 4.791, Loss_clf 1.021, Loss_fe 0.887, Loss_kd 2.686, Train_accy 69.60, Test_accy 60.71
2024-08-31 20:34:11,312 [foster.py] => Task 14, Epoch 48/170 => Loss 4.738, Loss_clf 0.921, Loss_fe 0.906, Loss_kd 2.712, Train_accy 70.34, Test_accy 61.80
2024-08-31 20:34:19,077 [foster.py] => Task 14, Epoch 49/170 => Loss 4.661, Loss_clf 0.885, Loss_fe 0.870, Loss_kd 2.707, Train_accy 70.92, Test_accy 61.33
2024-08-31 20:34:26,881 [foster.py] => Task 14, Epoch 50/170 => Loss 4.676, Loss_clf 0.907, Loss_fe 0.856, Loss_kd 2.714, Train_accy 70.56, Test_accy 62.19
2024-08-31 20:34:32,190 [foster.py] => Task 14, Epoch 51/170 => Loss 4.739, Loss_clf 0.950, Loss_fe 0.875, Loss_kd 2.715, Train_accy 68.65
2024-08-31 20:34:39,959 [foster.py] => Task 14, Epoch 52/170 => Loss 4.761, Loss_clf 0.949, Loss_fe 0.906, Loss_kd 2.707, Train_accy 70.49, Test_accy 62.31
2024-08-31 20:34:47,672 [foster.py] => Task 14, Epoch 53/170 => Loss 4.674, Loss_clf 0.908, Loss_fe 0.868, Loss_kd 2.700, Train_accy 69.91, Test_accy 62.25
2024-08-31 20:34:55,433 [foster.py] => Task 14, Epoch 54/170 => Loss 4.621, Loss_clf 0.880, Loss_fe 0.851, Loss_kd 2.693, Train_accy 68.72, Test_accy 62.68
2024-08-31 20:35:03,241 [foster.py] => Task 14, Epoch 55/170 => Loss 4.657, Loss_clf 0.907, Loss_fe 0.867, Loss_kd 2.686, Train_accy 69.55, Test_accy 62.39
2024-08-31 20:35:08,539 [foster.py] => Task 14, Epoch 56/170 => Loss 4.625, Loss_clf 0.888, Loss_fe 0.837, Loss_kd 2.701, Train_accy 70.56
2024-08-31 20:35:16,257 [foster.py] => Task 14, Epoch 57/170 => Loss 4.604, Loss_clf 0.871, Loss_fe 0.837, Loss_kd 2.698, Train_accy 71.88, Test_accy 63.47
2024-08-31 20:35:24,037 [foster.py] => Task 14, Epoch 58/170 => Loss 4.636, Loss_clf 0.892, Loss_fe 0.854, Loss_kd 2.692, Train_accy 69.64, Test_accy 61.76
2024-08-31 20:35:31,769 [foster.py] => Task 14, Epoch 59/170 => Loss 4.639, Loss_clf 0.879, Loss_fe 0.854, Loss_kd 2.707, Train_accy 70.76, Test_accy 57.53
2024-08-31 20:35:39,515 [foster.py] => Task 14, Epoch 60/170 => Loss 4.655, Loss_clf 0.918, Loss_fe 0.832, Loss_kd 2.706, Train_accy 69.80, Test_accy 60.97
2024-08-31 20:35:44,768 [foster.py] => Task 14, Epoch 61/170 => Loss 4.604, Loss_clf 0.856, Loss_fe 0.852, Loss_kd 2.698, Train_accy 71.79
2024-08-31 20:35:52,447 [foster.py] => Task 14, Epoch 62/170 => Loss 4.650, Loss_clf 0.893, Loss_fe 0.864, Loss_kd 2.695, Train_accy 69.46, Test_accy 61.79
2024-08-31 20:36:00,258 [foster.py] => Task 14, Epoch 63/170 => Loss 4.631, Loss_clf 0.891, Loss_fe 0.834, Loss_kd 2.707, Train_accy 70.27, Test_accy 59.71
2024-08-31 20:36:08,008 [foster.py] => Task 14, Epoch 64/170 => Loss 4.592, Loss_clf 0.857, Loss_fe 0.840, Loss_kd 2.697, Train_accy 70.85, Test_accy 63.27
2024-08-31 20:36:15,699 [foster.py] => Task 14, Epoch 65/170 => Loss 4.577, Loss_clf 0.871, Loss_fe 0.824, Loss_kd 2.685, Train_accy 70.65, Test_accy 58.53
2024-08-31 20:36:21,001 [foster.py] => Task 14, Epoch 66/170 => Loss 4.615, Loss_clf 0.881, Loss_fe 0.845, Loss_kd 2.692, Train_accy 70.16
2024-08-31 20:36:28,672 [foster.py] => Task 14, Epoch 67/170 => Loss 4.613, Loss_clf 0.894, Loss_fe 0.822, Loss_kd 2.699, Train_accy 69.82, Test_accy 56.89
2024-08-31 20:36:36,396 [foster.py] => Task 14, Epoch 68/170 => Loss 4.669, Loss_clf 0.906, Loss_fe 0.867, Loss_kd 2.698, Train_accy 69.04, Test_accy 62.08
2024-08-31 20:36:44,127 [foster.py] => Task 14, Epoch 69/170 => Loss 4.608, Loss_clf 0.898, Loss_fe 0.820, Loss_kd 2.693, Train_accy 71.66, Test_accy 63.21
2024-08-31 20:36:51,772 [foster.py] => Task 14, Epoch 70/170 => Loss 4.603, Loss_clf 0.881, Loss_fe 0.822, Loss_kd 2.701, Train_accy 70.11, Test_accy 62.59
2024-08-31 20:36:57,044 [foster.py] => Task 14, Epoch 71/170 => Loss 4.545, Loss_clf 0.855, Loss_fe 0.799, Loss_kd 2.694, Train_accy 71.41
2024-08-31 20:37:04,791 [foster.py] => Task 14, Epoch 72/170 => Loss 4.605, Loss_clf 0.890, Loss_fe 0.810, Loss_kd 2.707, Train_accy 70.72, Test_accy 62.17
2024-08-31 20:37:12,487 [foster.py] => Task 14, Epoch 73/170 => Loss 4.563, Loss_clf 0.855, Loss_fe 0.811, Loss_kd 2.699, Train_accy 72.31, Test_accy 63.35
2024-08-31 20:37:20,194 [foster.py] => Task 14, Epoch 74/170 => Loss 4.647, Loss_clf 0.904, Loss_fe 0.833, Loss_kd 2.711, Train_accy 69.84, Test_accy 62.57
2024-08-31 20:37:28,013 [foster.py] => Task 14, Epoch 75/170 => Loss 4.590, Loss_clf 0.891, Loss_fe 0.799, Loss_kd 2.701, Train_accy 70.99, Test_accy 62.72
2024-08-31 20:37:33,249 [foster.py] => Task 14, Epoch 76/170 => Loss 4.577, Loss_clf 0.880, Loss_fe 0.795, Loss_kd 2.704, Train_accy 70.43
2024-08-31 20:37:41,084 [foster.py] => Task 14, Epoch 77/170 => Loss 4.516, Loss_clf 0.853, Loss_fe 0.761, Loss_kd 2.704, Train_accy 70.92, Test_accy 63.13
2024-08-31 20:37:48,773 [foster.py] => Task 14, Epoch 78/170 => Loss 4.534, Loss_clf 0.843, Loss_fe 0.784, Loss_kd 2.709, Train_accy 71.41, Test_accy 60.63
2024-08-31 20:37:56,496 [foster.py] => Task 14, Epoch 79/170 => Loss 4.544, Loss_clf 0.867, Loss_fe 0.778, Loss_kd 2.700, Train_accy 71.08, Test_accy 62.81
2024-08-31 20:38:04,160 [foster.py] => Task 14, Epoch 80/170 => Loss 4.510, Loss_clf 0.850, Loss_fe 0.769, Loss_kd 2.693, Train_accy 72.22, Test_accy 62.08
2024-08-31 20:38:09,395 [foster.py] => Task 14, Epoch 81/170 => Loss 4.464, Loss_clf 0.834, Loss_fe 0.743, Loss_kd 2.690, Train_accy 72.42
2024-08-31 20:38:17,078 [foster.py] => Task 14, Epoch 82/170 => Loss 4.488, Loss_clf 0.845, Loss_fe 0.757, Loss_kd 2.688, Train_accy 72.02, Test_accy 60.49
2024-08-31 20:38:24,761 [foster.py] => Task 14, Epoch 83/170 => Loss 4.585, Loss_clf 0.912, Loss_fe 0.775, Loss_kd 2.699, Train_accy 71.19, Test_accy 62.89
2024-08-31 20:38:32,512 [foster.py] => Task 14, Epoch 84/170 => Loss 4.520, Loss_clf 0.862, Loss_fe 0.759, Loss_kd 2.701, Train_accy 71.73, Test_accy 60.99
2024-08-31 20:38:40,201 [foster.py] => Task 14, Epoch 85/170 => Loss 4.509, Loss_clf 0.846, Loss_fe 0.780, Loss_kd 2.686, Train_accy 71.91, Test_accy 63.40
2024-08-31 20:38:45,441 [foster.py] => Task 14, Epoch 86/170 => Loss 4.488, Loss_clf 0.853, Loss_fe 0.745, Loss_kd 2.692, Train_accy 71.75
2024-08-31 20:38:53,123 [foster.py] => Task 14, Epoch 87/170 => Loss 4.464, Loss_clf 0.817, Loss_fe 0.752, Loss_kd 2.697, Train_accy 72.31, Test_accy 62.93
2024-08-31 20:39:00,813 [foster.py] => Task 14, Epoch 88/170 => Loss 4.422, Loss_clf 0.798, Loss_fe 0.724, Loss_kd 2.702, Train_accy 73.25, Test_accy 62.72
2024-08-31 20:39:08,599 [foster.py] => Task 14, Epoch 89/170 => Loss 4.444, Loss_clf 0.819, Loss_fe 0.728, Loss_kd 2.699, Train_accy 72.53, Test_accy 62.80
2024-08-31 20:39:16,319 [foster.py] => Task 14, Epoch 90/170 => Loss 4.474, Loss_clf 0.836, Loss_fe 0.739, Loss_kd 2.701, Train_accy 71.50, Test_accy 61.92
2024-08-31 20:39:21,640 [foster.py] => Task 14, Epoch 91/170 => Loss 4.393, Loss_clf 0.788, Loss_fe 0.722, Loss_kd 2.686, Train_accy 73.81
2024-08-31 20:39:29,384 [foster.py] => Task 14, Epoch 92/170 => Loss 4.399, Loss_clf 0.795, Loss_fe 0.710, Loss_kd 2.696, Train_accy 72.80, Test_accy 63.23
2024-08-31 20:39:37,076 [foster.py] => Task 14, Epoch 93/170 => Loss 4.410, Loss_clf 0.824, Loss_fe 0.696, Loss_kd 2.692, Train_accy 73.03, Test_accy 62.67
2024-08-31 20:39:44,749 [foster.py] => Task 14, Epoch 94/170 => Loss 4.488, Loss_clf 0.843, Loss_fe 0.736, Loss_kd 2.710, Train_accy 71.14, Test_accy 62.52
2024-08-31 20:39:52,547 [foster.py] => Task 14, Epoch 95/170 => Loss 4.378, Loss_clf 0.800, Loss_fe 0.695, Loss_kd 2.686, Train_accy 73.09, Test_accy 62.49
2024-08-31 20:39:57,866 [foster.py] => Task 14, Epoch 96/170 => Loss 4.386, Loss_clf 0.800, Loss_fe 0.696, Loss_kd 2.692, Train_accy 73.12
2024-08-31 20:40:05,602 [foster.py] => Task 14, Epoch 97/170 => Loss 4.371, Loss_clf 0.787, Loss_fe 0.689, Loss_kd 2.697, Train_accy 73.39, Test_accy 62.71
2024-08-31 20:40:13,314 [foster.py] => Task 14, Epoch 98/170 => Loss 4.394, Loss_clf 0.796, Loss_fe 0.700, Loss_kd 2.699, Train_accy 73.57, Test_accy 62.28
2024-08-31 20:40:21,056 [foster.py] => Task 14, Epoch 99/170 => Loss 4.375, Loss_clf 0.808, Loss_fe 0.670, Loss_kd 2.699, Train_accy 73.95, Test_accy 62.21
2024-08-31 20:40:28,708 [foster.py] => Task 14, Epoch 100/170 => Loss 4.344, Loss_clf 0.773, Loss_fe 0.690, Loss_kd 2.684, Train_accy 73.81, Test_accy 63.80
2024-08-31 20:40:33,961 [foster.py] => Task 14, Epoch 101/170 => Loss 4.326, Loss_clf 0.787, Loss_fe 0.649, Loss_kd 2.692, Train_accy 73.05
2024-08-31 20:40:41,657 [foster.py] => Task 14, Epoch 102/170 => Loss 4.300, Loss_clf 0.773, Loss_fe 0.645, Loss_kd 2.685, Train_accy 73.97, Test_accy 63.81
2024-08-31 20:40:49,433 [foster.py] => Task 14, Epoch 103/170 => Loss 4.344, Loss_clf 0.783, Loss_fe 0.666, Loss_kd 2.697, Train_accy 74.66, Test_accy 59.13
2024-08-31 20:40:57,217 [foster.py] => Task 14, Epoch 104/170 => Loss 4.376, Loss_clf 0.794, Loss_fe 0.686, Loss_kd 2.698, Train_accy 73.54, Test_accy 63.52
2024-08-31 20:41:04,945 [foster.py] => Task 14, Epoch 105/170 => Loss 4.332, Loss_clf 0.775, Loss_fe 0.653, Loss_kd 2.705, Train_accy 73.99, Test_accy 63.77
2024-08-31 20:41:10,242 [foster.py] => Task 14, Epoch 106/170 => Loss 4.285, Loss_clf 0.770, Loss_fe 0.625, Loss_kd 2.693, Train_accy 74.55
2024-08-31 20:41:17,944 [foster.py] => Task 14, Epoch 107/170 => Loss 4.239, Loss_clf 0.721, Loss_fe 0.636, Loss_kd 2.686, Train_accy 75.47, Test_accy 63.25
2024-08-31 20:41:25,687 [foster.py] => Task 14, Epoch 108/170 => Loss 4.268, Loss_clf 0.762, Loss_fe 0.622, Loss_kd 2.687, Train_accy 74.87, Test_accy 64.01
2024-08-31 20:41:33,429 [foster.py] => Task 14, Epoch 109/170 => Loss 4.276, Loss_clf 0.756, Loss_fe 0.626, Loss_kd 2.696, Train_accy 75.90, Test_accy 64.49
2024-08-31 20:41:41,098 [foster.py] => Task 14, Epoch 110/170 => Loss 4.230, Loss_clf 0.728, Loss_fe 0.617, Loss_kd 2.688, Train_accy 76.48, Test_accy 63.23
2024-08-31 20:41:46,363 [foster.py] => Task 14, Epoch 111/170 => Loss 4.302, Loss_clf 0.772, Loss_fe 0.647, Loss_kd 2.686, Train_accy 74.71
2024-08-31 20:41:54,077 [foster.py] => Task 14, Epoch 112/170 => Loss 4.188, Loss_clf 0.721, Loss_fe 0.585, Loss_kd 2.684, Train_accy 76.55, Test_accy 63.73
2024-08-31 20:42:01,852 [foster.py] => Task 14, Epoch 113/170 => Loss 4.274, Loss_clf 0.771, Loss_fe 0.601, Loss_kd 2.704, Train_accy 73.88, Test_accy 63.40
2024-08-31 20:42:09,598 [foster.py] => Task 14, Epoch 114/170 => Loss 4.237, Loss_clf 0.747, Loss_fe 0.607, Loss_kd 2.687, Train_accy 76.14, Test_accy 63.65
2024-08-31 20:42:17,291 [foster.py] => Task 14, Epoch 115/170 => Loss 4.263, Loss_clf 0.747, Loss_fe 0.612, Loss_kd 2.706, Train_accy 75.76, Test_accy 63.21
2024-08-31 20:42:22,570 [foster.py] => Task 14, Epoch 116/170 => Loss 4.237, Loss_clf 0.740, Loss_fe 0.606, Loss_kd 2.693, Train_accy 75.49
2024-08-31 20:42:30,308 [foster.py] => Task 14, Epoch 117/170 => Loss 4.151, Loss_clf 0.698, Loss_fe 0.568, Loss_kd 2.687, Train_accy 76.46, Test_accy 63.72
2024-08-31 20:42:38,035 [foster.py] => Task 14, Epoch 118/170 => Loss 4.154, Loss_clf 0.704, Loss_fe 0.560, Loss_kd 2.692, Train_accy 76.14, Test_accy 64.44
2024-08-31 20:42:45,810 [foster.py] => Task 14, Epoch 119/170 => Loss 4.103, Loss_clf 0.683, Loss_fe 0.534, Loss_kd 2.689, Train_accy 77.40, Test_accy 62.81
2024-08-31 20:42:53,478 [foster.py] => Task 14, Epoch 120/170 => Loss 4.157, Loss_clf 0.710, Loss_fe 0.555, Loss_kd 2.694, Train_accy 76.57, Test_accy 64.17
2024-08-31 20:42:58,704 [foster.py] => Task 14, Epoch 121/170 => Loss 4.179, Loss_clf 0.720, Loss_fe 0.560, Loss_kd 2.701, Train_accy 76.10
2024-08-31 20:43:06,452 [foster.py] => Task 14, Epoch 122/170 => Loss 4.110, Loss_clf 0.694, Loss_fe 0.535, Loss_kd 2.685, Train_accy 77.96, Test_accy 63.88
2024-08-31 20:43:14,149 [foster.py] => Task 14, Epoch 123/170 => Loss 4.133, Loss_clf 0.700, Loss_fe 0.540, Loss_kd 2.695, Train_accy 77.53, Test_accy 62.99
2024-08-31 20:43:21,840 [foster.py] => Task 14, Epoch 124/170 => Loss 4.119, Loss_clf 0.700, Loss_fe 0.536, Loss_kd 2.686, Train_accy 77.49, Test_accy 64.51
2024-08-31 20:43:29,534 [foster.py] => Task 14, Epoch 125/170 => Loss 4.086, Loss_clf 0.689, Loss_fe 0.519, Loss_kd 2.681, Train_accy 78.72, Test_accy 64.55
2024-08-31 20:43:34,811 [foster.py] => Task 14, Epoch 126/170 => Loss 4.060, Loss_clf 0.668, Loss_fe 0.514, Loss_kd 2.681, Train_accy 78.14
2024-08-31 20:43:42,519 [foster.py] => Task 14, Epoch 127/170 => Loss 4.095, Loss_clf 0.691, Loss_fe 0.518, Loss_kd 2.689, Train_accy 77.69, Test_accy 64.40
2024-08-31 20:43:50,265 [foster.py] => Task 14, Epoch 128/170 => Loss 4.019, Loss_clf 0.655, Loss_fe 0.489, Loss_kd 2.678, Train_accy 78.23, Test_accy 64.04
2024-08-31 20:43:57,955 [foster.py] => Task 14, Epoch 129/170 => Loss 4.002, Loss_clf 0.641, Loss_fe 0.475, Loss_kd 2.689, Train_accy 79.28, Test_accy 63.67
2024-08-31 20:44:05,649 [foster.py] => Task 14, Epoch 130/170 => Loss 4.024, Loss_clf 0.646, Loss_fe 0.480, Loss_kd 2.699, Train_accy 79.22, Test_accy 63.57
2024-08-31 20:44:10,973 [foster.py] => Task 14, Epoch 131/170 => Loss 4.048, Loss_clf 0.664, Loss_fe 0.499, Loss_kd 2.688, Train_accy 78.03
2024-08-31 20:44:18,752 [foster.py] => Task 14, Epoch 132/170 => Loss 3.997, Loss_clf 0.644, Loss_fe 0.465, Loss_kd 2.690, Train_accy 80.02, Test_accy 63.60
2024-08-31 20:44:26,482 [foster.py] => Task 14, Epoch 133/170 => Loss 4.014, Loss_clf 0.652, Loss_fe 0.466, Loss_kd 2.698, Train_accy 80.18, Test_accy 64.48
2024-08-31 20:44:34,281 [foster.py] => Task 14, Epoch 134/170 => Loss 4.005, Loss_clf 0.654, Loss_fe 0.460, Loss_kd 2.693, Train_accy 79.98, Test_accy 63.93
2024-08-31 20:44:41,994 [foster.py] => Task 14, Epoch 135/170 => Loss 3.980, Loss_clf 0.640, Loss_fe 0.455, Loss_kd 2.688, Train_accy 80.13, Test_accy 64.37
2024-08-31 20:44:47,391 [foster.py] => Task 14, Epoch 136/170 => Loss 3.982, Loss_clf 0.655, Loss_fe 0.445, Loss_kd 2.684, Train_accy 79.08
2024-08-31 20:44:55,084 [foster.py] => Task 14, Epoch 137/170 => Loss 3.912, Loss_clf 0.598, Loss_fe 0.439, Loss_kd 2.678, Train_accy 80.70, Test_accy 64.00
2024-08-31 20:45:02,767 [foster.py] => Task 14, Epoch 138/170 => Loss 3.975, Loss_clf 0.642, Loss_fe 0.442, Loss_kd 2.694, Train_accy 80.00, Test_accy 64.81
2024-08-31 20:45:10,511 [foster.py] => Task 14, Epoch 139/170 => Loss 3.911, Loss_clf 0.610, Loss_fe 0.414, Loss_kd 2.690, Train_accy 80.02, Test_accy 64.37
2024-08-31 20:45:18,274 [foster.py] => Task 14, Epoch 140/170 => Loss 3.939, Loss_clf 0.633, Loss_fe 0.416, Loss_kd 2.692, Train_accy 80.72, Test_accy 64.16
2024-08-31 20:45:23,568 [foster.py] => Task 14, Epoch 141/170 => Loss 3.905, Loss_clf 0.594, Loss_fe 0.418, Loss_kd 2.695, Train_accy 82.13
2024-08-31 20:45:31,280 [foster.py] => Task 14, Epoch 142/170 => Loss 3.897, Loss_clf 0.609, Loss_fe 0.400, Loss_kd 2.691, Train_accy 81.17, Test_accy 65.05
2024-08-31 20:45:38,997 [foster.py] => Task 14, Epoch 143/170 => Loss 3.899, Loss_clf 0.621, Loss_fe 0.396, Loss_kd 2.684, Train_accy 80.96, Test_accy 64.71
2024-08-31 20:45:46,762 [foster.py] => Task 14, Epoch 144/170 => Loss 3.923, Loss_clf 0.621, Loss_fe 0.407, Loss_kd 2.697, Train_accy 81.12, Test_accy 65.09
2024-08-31 20:45:54,517 [foster.py] => Task 14, Epoch 145/170 => Loss 3.876, Loss_clf 0.602, Loss_fe 0.389, Loss_kd 2.688, Train_accy 81.95, Test_accy 64.67
2024-08-31 20:45:59,863 [foster.py] => Task 14, Epoch 146/170 => Loss 3.836, Loss_clf 0.581, Loss_fe 0.378, Loss_kd 2.681, Train_accy 82.06
2024-08-31 20:46:07,570 [foster.py] => Task 14, Epoch 147/170 => Loss 3.863, Loss_clf 0.600, Loss_fe 0.366, Loss_kd 2.699, Train_accy 82.24, Test_accy 64.68
2024-08-31 20:46:15,250 [foster.py] => Task 14, Epoch 148/170 => Loss 3.930, Loss_clf 0.635, Loss_fe 0.395, Loss_kd 2.702, Train_accy 80.96, Test_accy 65.23
2024-08-31 20:46:23,053 [foster.py] => Task 14, Epoch 149/170 => Loss 3.837, Loss_clf 0.580, Loss_fe 0.369, Loss_kd 2.691, Train_accy 82.80, Test_accy 64.77
2024-08-31 20:46:30,737 [foster.py] => Task 14, Epoch 150/170 => Loss 3.832, Loss_clf 0.583, Loss_fe 0.359, Loss_kd 2.692, Train_accy 82.40, Test_accy 64.92
2024-08-31 20:46:36,067 [foster.py] => Task 14, Epoch 151/170 => Loss 3.802, Loss_clf 0.573, Loss_fe 0.346, Loss_kd 2.685, Train_accy 82.76
2024-08-31 20:46:43,721 [foster.py] => Task 14, Epoch 152/170 => Loss 3.887, Loss_clf 0.616, Loss_fe 0.364, Loss_kd 2.708, Train_accy 81.77, Test_accy 64.92
2024-08-31 20:46:51,411 [foster.py] => Task 14, Epoch 153/170 => Loss 3.858, Loss_clf 0.604, Loss_fe 0.364, Loss_kd 2.693, Train_accy 81.75, Test_accy 64.69
2024-08-31 20:46:59,069 [foster.py] => Task 14, Epoch 154/170 => Loss 3.836, Loss_clf 0.586, Loss_fe 0.368, Loss_kd 2.686, Train_accy 82.02, Test_accy 64.72
2024-08-31 20:47:06,789 [foster.py] => Task 14, Epoch 155/170 => Loss 3.789, Loss_clf 0.562, Loss_fe 0.341, Loss_kd 2.688, Train_accy 82.94, Test_accy 64.79
2024-08-31 20:47:12,025 [foster.py] => Task 14, Epoch 156/170 => Loss 3.787, Loss_clf 0.558, Loss_fe 0.354, Loss_kd 2.679, Train_accy 83.12
2024-08-31 20:47:19,752 [foster.py] => Task 14, Epoch 157/170 => Loss 3.776, Loss_clf 0.563, Loss_fe 0.327, Loss_kd 2.688, Train_accy 83.43, Test_accy 65.00
2024-08-31 20:47:27,496 [foster.py] => Task 14, Epoch 158/170 => Loss 3.766, Loss_clf 0.554, Loss_fe 0.334, Loss_kd 2.682, Train_accy 83.81, Test_accy 64.79
2024-08-31 20:47:35,178 [foster.py] => Task 14, Epoch 159/170 => Loss 3.744, Loss_clf 0.538, Loss_fe 0.321, Loss_kd 2.688, Train_accy 84.73, Test_accy 65.05
2024-08-31 20:47:42,892 [foster.py] => Task 14, Epoch 160/170 => Loss 3.758, Loss_clf 0.561, Loss_fe 0.317, Loss_kd 2.684, Train_accy 83.41, Test_accy 64.99
2024-08-31 20:47:48,151 [foster.py] => Task 14, Epoch 161/170 => Loss 3.733, Loss_clf 0.540, Loss_fe 0.309, Loss_kd 2.687, Train_accy 83.52
2024-08-31 20:47:55,774 [foster.py] => Task 14, Epoch 162/170 => Loss 3.806, Loss_clf 0.567, Loss_fe 0.335, Loss_kd 2.705, Train_accy 83.36, Test_accy 64.87
2024-08-31 20:48:03,532 [foster.py] => Task 14, Epoch 163/170 => Loss 3.765, Loss_clf 0.556, Loss_fe 0.321, Loss_kd 2.690, Train_accy 83.45, Test_accy 65.01
2024-08-31 20:48:11,227 [foster.py] => Task 14, Epoch 164/170 => Loss 3.743, Loss_clf 0.555, Loss_fe 0.311, Loss_kd 2.680, Train_accy 84.17, Test_accy 64.81
2024-08-31 20:48:18,945 [foster.py] => Task 14, Epoch 165/170 => Loss 3.743, Loss_clf 0.549, Loss_fe 0.312, Loss_kd 2.686, Train_accy 84.98, Test_accy 64.84
2024-08-31 20:48:24,254 [foster.py] => Task 14, Epoch 166/170 => Loss 3.762, Loss_clf 0.559, Loss_fe 0.318, Loss_kd 2.689, Train_accy 84.22
2024-08-31 20:48:31,935 [foster.py] => Task 14, Epoch 167/170 => Loss 3.774, Loss_clf 0.561, Loss_fe 0.324, Loss_kd 2.692, Train_accy 83.34, Test_accy 64.89
2024-08-31 20:48:39,650 [foster.py] => Task 14, Epoch 168/170 => Loss 3.759, Loss_clf 0.546, Loss_fe 0.315, Loss_kd 2.700, Train_accy 84.66, Test_accy 64.92
2024-08-31 20:48:47,395 [foster.py] => Task 14, Epoch 169/170 => Loss 3.741, Loss_clf 0.551, Loss_fe 0.314, Loss_kd 2.680, Train_accy 83.48, Test_accy 64.84
2024-08-31 20:48:55,220 [foster.py] => Task 14, Epoch 170/170 => Loss 3.733, Loss_clf 0.546, Loss_fe 0.306, Loss_kd 2.684, Train_accy 84.01, Test_accy 64.85
2024-08-31 20:48:55,222 [foster.py] => do not weight align teacher!
2024-08-31 20:48:55,223 [foster.py] => per cls weights : [1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112 1.03294112
 1.03294112 1.03294112 1.03294112 1.03294112 0.53882428 0.53882428
 0.53882428 0.53882428 0.53882428]
2024-08-31 20:49:04,791 [foster.py] => SNet: Task 14, Epoch 1/130 => Loss 29.867,  Loss1 0.743, Train_accy 47.65, Test_accy 61.87
2024-08-31 20:49:12,164 [foster.py] => SNet: Task 14, Epoch 2/130 => Loss 29.745,  Loss1 0.742, Train_accy 58.21
2024-08-31 20:49:19,230 [foster.py] => SNet: Task 14, Epoch 3/130 => Loss 29.724,  Loss1 0.742, Train_accy 63.59
2024-08-31 20:49:26,318 [foster.py] => SNet: Task 14, Epoch 4/130 => Loss 29.714,  Loss1 0.742, Train_accy 64.69
2024-08-31 20:49:33,360 [foster.py] => SNet: Task 14, Epoch 5/130 => Loss 29.716,  Loss1 0.742, Train_accy 66.91
2024-08-31 20:49:42,749 [foster.py] => SNet: Task 14, Epoch 6/130 => Loss 29.725,  Loss1 0.742, Train_accy 67.33, Test_accy 62.44
2024-08-31 20:49:50,453 [foster.py] => SNet: Task 14, Epoch 7/130 => Loss 29.741,  Loss1 0.742, Train_accy 67.22
2024-08-31 20:49:57,726 [foster.py] => SNet: Task 14, Epoch 8/130 => Loss 29.714,  Loss1 0.742, Train_accy 68.32
2024-08-31 20:50:04,803 [foster.py] => SNet: Task 14, Epoch 9/130 => Loss 29.745,  Loss1 0.742, Train_accy 69.80
2024-08-31 20:50:11,938 [foster.py] => SNet: Task 14, Epoch 10/130 => Loss 29.705,  Loss1 0.742, Train_accy 68.30
2024-08-31 20:50:21,314 [foster.py] => SNet: Task 14, Epoch 11/130 => Loss 29.740,  Loss1 0.742, Train_accy 69.60, Test_accy 62.48
2024-08-31 20:50:28,780 [foster.py] => SNet: Task 14, Epoch 12/130 => Loss 29.740,  Loss1 0.742, Train_accy 69.44
2024-08-31 20:50:35,837 [foster.py] => SNet: Task 14, Epoch 13/130 => Loss 29.716,  Loss1 0.742, Train_accy 70.61
2024-08-31 20:50:43,607 [foster.py] => SNet: Task 14, Epoch 14/130 => Loss 29.691,  Loss1 0.742, Train_accy 70.52
2024-08-31 20:50:51,006 [foster.py] => SNet: Task 14, Epoch 15/130 => Loss 29.708,  Loss1 0.742, Train_accy 70.22
2024-08-31 20:51:00,268 [foster.py] => SNet: Task 14, Epoch 16/130 => Loss 29.696,  Loss1 0.742, Train_accy 70.52, Test_accy 61.25
2024-08-31 20:51:07,717 [foster.py] => SNet: Task 14, Epoch 17/130 => Loss 29.721,  Loss1 0.742, Train_accy 69.75
2024-08-31 20:51:15,009 [foster.py] => SNet: Task 14, Epoch 18/130 => Loss 29.719,  Loss1 0.742, Train_accy 70.49
2024-08-31 20:51:22,492 [foster.py] => SNet: Task 14, Epoch 19/130 => Loss 29.696,  Loss1 0.742, Train_accy 71.05
2024-08-31 20:51:29,982 [foster.py] => SNet: Task 14, Epoch 20/130 => Loss 29.696,  Loss1 0.742, Train_accy 70.31
2024-08-31 20:51:39,348 [foster.py] => SNet: Task 14, Epoch 21/130 => Loss 29.724,  Loss1 0.742, Train_accy 71.43, Test_accy 62.95
2024-08-31 20:51:46,672 [foster.py] => SNet: Task 14, Epoch 22/130 => Loss 29.708,  Loss1 0.742, Train_accy 70.29
2024-08-31 20:51:53,833 [foster.py] => SNet: Task 14, Epoch 23/130 => Loss 29.724,  Loss1 0.742, Train_accy 71.95
2024-08-31 20:52:01,166 [foster.py] => SNet: Task 14, Epoch 24/130 => Loss 29.690,  Loss1 0.742, Train_accy 71.77
2024-08-31 20:52:08,337 [foster.py] => SNet: Task 14, Epoch 25/130 => Loss 29.709,  Loss1 0.742, Train_accy 71.57
2024-08-31 20:52:17,719 [foster.py] => SNet: Task 14, Epoch 26/130 => Loss 29.721,  Loss1 0.742, Train_accy 70.76, Test_accy 63.24
2024-08-31 20:52:24,823 [foster.py] => SNet: Task 14, Epoch 27/130 => Loss 29.702,  Loss1 0.742, Train_accy 72.02
2024-08-31 20:52:31,861 [foster.py] => SNet: Task 14, Epoch 28/130 => Loss 29.757,  Loss1 0.742, Train_accy 70.47
2024-08-31 20:52:39,065 [foster.py] => SNet: Task 14, Epoch 29/130 => Loss 29.716,  Loss1 0.742, Train_accy 71.61
2024-08-31 20:52:46,468 [foster.py] => SNet: Task 14, Epoch 30/130 => Loss 29.727,  Loss1 0.742, Train_accy 70.90
2024-08-31 20:52:55,857 [foster.py] => SNet: Task 14, Epoch 31/130 => Loss 29.705,  Loss1 0.742, Train_accy 71.84, Test_accy 63.45
2024-08-31 20:53:03,002 [foster.py] => SNet: Task 14, Epoch 32/130 => Loss 29.702,  Loss1 0.742, Train_accy 71.64
2024-08-31 20:53:10,382 [foster.py] => SNet: Task 14, Epoch 33/130 => Loss 29.718,  Loss1 0.742, Train_accy 72.20
2024-08-31 20:53:17,994 [foster.py] => SNet: Task 14, Epoch 34/130 => Loss 29.723,  Loss1 0.742, Train_accy 71.86
2024-08-31 20:53:25,592 [foster.py] => SNet: Task 14, Epoch 35/130 => Loss 29.688,  Loss1 0.742, Train_accy 72.11
2024-08-31 20:53:35,054 [foster.py] => SNet: Task 14, Epoch 36/130 => Loss 29.695,  Loss1 0.742, Train_accy 71.66, Test_accy 63.40
2024-08-31 20:53:42,446 [foster.py] => SNet: Task 14, Epoch 37/130 => Loss 29.718,  Loss1 0.742, Train_accy 71.88
2024-08-31 20:53:49,559 [foster.py] => SNet: Task 14, Epoch 38/130 => Loss 29.694,  Loss1 0.742, Train_accy 71.88
2024-08-31 20:53:56,734 [foster.py] => SNet: Task 14, Epoch 39/130 => Loss 29.669,  Loss1 0.742, Train_accy 72.40
2024-08-31 20:54:04,028 [foster.py] => SNet: Task 14, Epoch 40/130 => Loss 29.704,  Loss1 0.742, Train_accy 73.41
2024-08-31 20:54:13,259 [foster.py] => SNet: Task 14, Epoch 41/130 => Loss 29.667,  Loss1 0.742, Train_accy 72.35, Test_accy 63.84
2024-08-31 20:54:20,585 [foster.py] => SNet: Task 14, Epoch 42/130 => Loss 29.713,  Loss1 0.742, Train_accy 72.24
2024-08-31 20:54:27,766 [foster.py] => SNet: Task 14, Epoch 43/130 => Loss 29.700,  Loss1 0.742, Train_accy 71.32
2024-08-31 20:54:34,888 [foster.py] => SNet: Task 14, Epoch 44/130 => Loss 29.726,  Loss1 0.742, Train_accy 72.26
2024-08-31 20:54:42,004 [foster.py] => SNet: Task 14, Epoch 45/130 => Loss 29.692,  Loss1 0.742, Train_accy 71.88
2024-08-31 20:54:51,421 [foster.py] => SNet: Task 14, Epoch 46/130 => Loss 29.676,  Loss1 0.742, Train_accy 72.74, Test_accy 63.92
2024-08-31 20:54:58,722 [foster.py] => SNet: Task 14, Epoch 47/130 => Loss 29.712,  Loss1 0.742, Train_accy 72.83
2024-08-31 20:55:06,100 [foster.py] => SNet: Task 14, Epoch 48/130 => Loss 29.701,  Loss1 0.742, Train_accy 72.20
2024-08-31 20:55:13,414 [foster.py] => SNet: Task 14, Epoch 49/130 => Loss 29.682,  Loss1 0.742, Train_accy 72.35
2024-08-31 20:55:20,843 [foster.py] => SNet: Task 14, Epoch 50/130 => Loss 29.697,  Loss1 0.742, Train_accy 72.51
2024-08-31 20:55:30,463 [foster.py] => SNet: Task 14, Epoch 51/130 => Loss 29.649,  Loss1 0.742, Train_accy 73.72, Test_accy 63.69
2024-08-31 20:55:37,633 [foster.py] => SNet: Task 14, Epoch 52/130 => Loss 29.674,  Loss1 0.742, Train_accy 73.77
2024-08-31 20:55:44,690 [foster.py] => SNet: Task 14, Epoch 53/130 => Loss 29.719,  Loss1 0.742, Train_accy 73.50
2024-08-31 20:55:51,819 [foster.py] => SNet: Task 14, Epoch 54/130 => Loss 29.686,  Loss1 0.742, Train_accy 73.77
2024-08-31 20:55:59,189 [foster.py] => SNet: Task 14, Epoch 55/130 => Loss 29.723,  Loss1 0.742, Train_accy 72.33
2024-08-31 20:56:08,485 [foster.py] => SNet: Task 14, Epoch 56/130 => Loss 29.697,  Loss1 0.742, Train_accy 73.00, Test_accy 63.56
2024-08-31 20:56:16,205 [foster.py] => SNet: Task 14, Epoch 57/130 => Loss 29.696,  Loss1 0.742, Train_accy 74.10
2024-08-31 20:56:23,299 [foster.py] => SNet: Task 14, Epoch 58/130 => Loss 29.694,  Loss1 0.742, Train_accy 72.22
2024-08-31 20:56:30,645 [foster.py] => SNet: Task 14, Epoch 59/130 => Loss 29.703,  Loss1 0.742, Train_accy 73.21
2024-08-31 20:56:37,831 [foster.py] => SNet: Task 14, Epoch 60/130 => Loss 29.679,  Loss1 0.742, Train_accy 72.47
2024-08-31 20:56:47,141 [foster.py] => SNet: Task 14, Epoch 61/130 => Loss 29.691,  Loss1 0.742, Train_accy 72.62, Test_accy 63.51
2024-08-31 20:56:54,233 [foster.py] => SNet: Task 14, Epoch 62/130 => Loss 29.691,  Loss1 0.742, Train_accy 74.13
2024-08-31 20:57:01,357 [foster.py] => SNet: Task 14, Epoch 63/130 => Loss 29.678,  Loss1 0.742, Train_accy 73.59
2024-08-31 20:57:08,889 [foster.py] => SNet: Task 14, Epoch 64/130 => Loss 29.724,  Loss1 0.742, Train_accy 72.94
2024-08-31 20:57:16,190 [foster.py] => SNet: Task 14, Epoch 65/130 => Loss 29.685,  Loss1 0.742, Train_accy 72.83
2024-08-31 20:57:25,497 [foster.py] => SNet: Task 14, Epoch 66/130 => Loss 29.705,  Loss1 0.742, Train_accy 72.83, Test_accy 64.03
2024-08-31 20:57:32,760 [foster.py] => SNet: Task 14, Epoch 67/130 => Loss 29.707,  Loss1 0.742, Train_accy 73.74
2024-08-31 20:57:39,815 [foster.py] => SNet: Task 14, Epoch 68/130 => Loss 29.700,  Loss1 0.742, Train_accy 73.00
2024-08-31 20:57:47,568 [foster.py] => SNet: Task 14, Epoch 69/130 => Loss 29.692,  Loss1 0.742, Train_accy 73.27
2024-08-31 20:57:54,670 [foster.py] => SNet: Task 14, Epoch 70/130 => Loss 29.685,  Loss1 0.742, Train_accy 73.95
2024-08-31 20:58:03,949 [foster.py] => SNet: Task 14, Epoch 71/130 => Loss 29.674,  Loss1 0.742, Train_accy 73.30, Test_accy 63.52
2024-08-31 20:58:11,436 [foster.py] => SNet: Task 14, Epoch 72/130 => Loss 29.730,  Loss1 0.742, Train_accy 73.74
2024-08-31 20:58:18,454 [foster.py] => SNet: Task 14, Epoch 73/130 => Loss 29.678,  Loss1 0.742, Train_accy 74.57
2024-08-31 20:58:25,607 [foster.py] => SNet: Task 14, Epoch 74/130 => Loss 29.705,  Loss1 0.742, Train_accy 73.32
2024-08-31 20:58:33,004 [foster.py] => SNet: Task 14, Epoch 75/130 => Loss 29.684,  Loss1 0.742, Train_accy 74.17
2024-08-31 20:58:42,412 [foster.py] => SNet: Task 14, Epoch 76/130 => Loss 29.698,  Loss1 0.742, Train_accy 73.77, Test_accy 64.71
2024-08-31 20:58:49,663 [foster.py] => SNet: Task 14, Epoch 77/130 => Loss 29.685,  Loss1 0.742, Train_accy 72.49
2024-08-31 20:58:57,710 [foster.py] => SNet: Task 14, Epoch 78/130 => Loss 29.677,  Loss1 0.742, Train_accy 73.86
2024-08-31 20:59:04,822 [foster.py] => SNet: Task 14, Epoch 79/130 => Loss 29.738,  Loss1 0.742, Train_accy 72.71
2024-08-31 20:59:12,419 [foster.py] => SNet: Task 14, Epoch 80/130 => Loss 29.676,  Loss1 0.742, Train_accy 72.87
2024-08-31 20:59:22,174 [foster.py] => SNet: Task 14, Epoch 81/130 => Loss 29.721,  Loss1 0.742, Train_accy 73.03, Test_accy 64.03
2024-08-31 20:59:29,726 [foster.py] => SNet: Task 14, Epoch 82/130 => Loss 29.674,  Loss1 0.742, Train_accy 73.81
2024-08-31 20:59:36,854 [foster.py] => SNet: Task 14, Epoch 83/130 => Loss 29.684,  Loss1 0.742, Train_accy 73.72
2024-08-31 20:59:44,442 [foster.py] => SNet: Task 14, Epoch 84/130 => Loss 29.696,  Loss1 0.742, Train_accy 73.59
2024-08-31 20:59:51,834 [foster.py] => SNet: Task 14, Epoch 85/130 => Loss 29.693,  Loss1 0.742, Train_accy 73.36
2024-08-31 21:00:01,182 [foster.py] => SNet: Task 14, Epoch 86/130 => Loss 29.693,  Loss1 0.742, Train_accy 74.60, Test_accy 64.13
2024-08-31 21:00:08,317 [foster.py] => SNet: Task 14, Epoch 87/130 => Loss 29.678,  Loss1 0.742, Train_accy 74.37
2024-08-31 21:00:15,730 [foster.py] => SNet: Task 14, Epoch 88/130 => Loss 29.682,  Loss1 0.742, Train_accy 74.60
2024-08-31 21:00:23,128 [foster.py] => SNet: Task 14, Epoch 89/130 => Loss 29.682,  Loss1 0.742, Train_accy 72.91
2024-08-31 21:00:30,491 [foster.py] => SNet: Task 14, Epoch 90/130 => Loss 29.690,  Loss1 0.742, Train_accy 73.81
2024-08-31 21:00:39,789 [foster.py] => SNet: Task 14, Epoch 91/130 => Loss 29.669,  Loss1 0.742, Train_accy 74.48, Test_accy 64.37
2024-08-31 21:00:47,051 [foster.py] => SNet: Task 14, Epoch 92/130 => Loss 29.663,  Loss1 0.742, Train_accy 73.59
2024-08-31 21:00:54,645 [foster.py] => SNet: Task 14, Epoch 93/130 => Loss 29.660,  Loss1 0.742, Train_accy 73.65
2024-08-31 21:01:01,913 [foster.py] => SNet: Task 14, Epoch 94/130 => Loss 29.716,  Loss1 0.742, Train_accy 72.85
2024-08-31 21:01:09,192 [foster.py] => SNet: Task 14, Epoch 95/130 => Loss 29.688,  Loss1 0.742, Train_accy 73.57
2024-08-31 21:01:18,490 [foster.py] => SNet: Task 14, Epoch 96/130 => Loss 29.683,  Loss1 0.742, Train_accy 73.41, Test_accy 63.91
2024-08-31 21:01:25,572 [foster.py] => SNet: Task 14, Epoch 97/130 => Loss 29.693,  Loss1 0.742, Train_accy 73.70
2024-08-31 21:01:32,741 [foster.py] => SNet: Task 14, Epoch 98/130 => Loss 29.698,  Loss1 0.742, Train_accy 73.74
2024-08-31 21:01:40,017 [foster.py] => SNet: Task 14, Epoch 99/130 => Loss 29.679,  Loss1 0.742, Train_accy 73.07
2024-08-31 21:01:47,412 [foster.py] => SNet: Task 14, Epoch 100/130 => Loss 29.658,  Loss1 0.742, Train_accy 74.75
2024-08-31 21:01:56,766 [foster.py] => SNet: Task 14, Epoch 101/130 => Loss 29.692,  Loss1 0.742, Train_accy 72.71, Test_accy 64.13
2024-08-31 21:02:04,166 [foster.py] => SNet: Task 14, Epoch 102/130 => Loss 29.690,  Loss1 0.742, Train_accy 74.78
2024-08-31 21:02:11,314 [foster.py] => SNet: Task 14, Epoch 103/130 => Loss 29.689,  Loss1 0.742, Train_accy 74.08
2024-08-31 21:02:18,709 [foster.py] => SNet: Task 14, Epoch 104/130 => Loss 29.696,  Loss1 0.742, Train_accy 73.34
2024-08-31 21:02:25,926 [foster.py] => SNet: Task 14, Epoch 105/130 => Loss 29.702,  Loss1 0.742, Train_accy 74.22
2024-08-31 21:02:35,233 [foster.py] => SNet: Task 14, Epoch 106/130 => Loss 29.658,  Loss1 0.742, Train_accy 74.17, Test_accy 63.91
2024-08-31 21:02:42,518 [foster.py] => SNet: Task 14, Epoch 107/130 => Loss 29.701,  Loss1 0.742, Train_accy 73.21
2024-08-31 21:02:49,839 [foster.py] => SNet: Task 14, Epoch 108/130 => Loss 29.672,  Loss1 0.742, Train_accy 74.98
2024-08-31 21:02:57,002 [foster.py] => SNet: Task 14, Epoch 109/130 => Loss 29.681,  Loss1 0.742, Train_accy 74.06
2024-08-31 21:03:04,485 [foster.py] => SNet: Task 14, Epoch 110/130 => Loss 29.713,  Loss1 0.742, Train_accy 73.63
2024-08-31 21:03:13,930 [foster.py] => SNet: Task 14, Epoch 111/130 => Loss 29.688,  Loss1 0.742, Train_accy 72.94, Test_accy 64.07
2024-08-31 21:03:20,958 [foster.py] => SNet: Task 14, Epoch 112/130 => Loss 29.699,  Loss1 0.742, Train_accy 74.01
2024-08-31 21:03:28,722 [foster.py] => SNet: Task 14, Epoch 113/130 => Loss 29.675,  Loss1 0.742, Train_accy 74.19
2024-08-31 21:03:36,182 [foster.py] => SNet: Task 14, Epoch 114/130 => Loss 29.712,  Loss1 0.742, Train_accy 74.13
2024-08-31 21:03:43,286 [foster.py] => SNet: Task 14, Epoch 115/130 => Loss 29.657,  Loss1 0.742, Train_accy 75.07
2024-08-31 21:03:52,541 [foster.py] => SNet: Task 14, Epoch 116/130 => Loss 29.681,  Loss1 0.742, Train_accy 74.28, Test_accy 64.36
2024-08-31 21:04:00,047 [foster.py] => SNet: Task 14, Epoch 117/130 => Loss 29.708,  Loss1 0.742, Train_accy 73.70
2024-08-31 21:04:07,352 [foster.py] => SNet: Task 14, Epoch 118/130 => Loss 29.680,  Loss1 0.742, Train_accy 73.63
2024-08-31 21:04:14,863 [foster.py] => SNet: Task 14, Epoch 119/130 => Loss 29.695,  Loss1 0.742, Train_accy 74.19
2024-08-31 21:04:21,998 [foster.py] => SNet: Task 14, Epoch 120/130 => Loss 29.694,  Loss1 0.742, Train_accy 73.81
2024-08-31 21:04:31,225 [foster.py] => SNet: Task 14, Epoch 121/130 => Loss 29.687,  Loss1 0.742, Train_accy 73.63, Test_accy 64.28
2024-08-31 21:04:38,365 [foster.py] => SNet: Task 14, Epoch 122/130 => Loss 29.676,  Loss1 0.742, Train_accy 73.09
2024-08-31 21:04:45,637 [foster.py] => SNet: Task 14, Epoch 123/130 => Loss 29.702,  Loss1 0.742, Train_accy 73.21
2024-08-31 21:04:52,716 [foster.py] => SNet: Task 14, Epoch 124/130 => Loss 29.688,  Loss1 0.742, Train_accy 74.17
2024-08-31 21:05:00,068 [foster.py] => SNet: Task 14, Epoch 125/130 => Loss 29.682,  Loss1 0.742, Train_accy 75.27
2024-08-31 21:05:09,628 [foster.py] => SNet: Task 14, Epoch 126/130 => Loss 29.716,  Loss1 0.742, Train_accy 73.07, Test_accy 64.12
2024-08-31 21:05:17,102 [foster.py] => SNet: Task 14, Epoch 127/130 => Loss 29.675,  Loss1 0.742, Train_accy 74.19
2024-08-31 21:05:24,286 [foster.py] => SNet: Task 14, Epoch 128/130 => Loss 29.688,  Loss1 0.742, Train_accy 75.07
2024-08-31 21:05:31,615 [foster.py] => SNet: Task 14, Epoch 129/130 => Loss 29.701,  Loss1 0.742, Train_accy 74.44
2024-08-31 21:05:39,414 [foster.py] => SNet: Task 14, Epoch 130/130 => Loss 29.697,  Loss1 0.742, Train_accy 73.79
2024-08-31 21:05:39,415 [foster.py] => do not weight align student!
2024-08-31 21:05:41,606 [foster.py] => darknet eval: 
2024-08-31 21:05:41,606 [foster.py] => CNN top1 curve: 64.11
2024-08-31 21:05:41,606 [foster.py] => CNN top5 curve: 88.71
2024-08-31 21:05:41,606 [foster.py] => CNN top1 平均值: 64.11
2024-08-31 21:05:41,610 [foster.py] => timees : 2236.598376750946
2024-08-31 21:05:41,611 [base.py] => Reducing exemplars...(26 per classes)
2024-08-31 21:06:06,034 [base.py] => Constructing exemplars...(26 per classes)
2024-08-31 21:06:16,310 [foster.py] => Exemplar size: 1950
2024-08-31 21:06:16,310 [trainer.py] => CNN: {'total': 64.85, '00-09': 65.4, '10-19': 47.3, '20-29': 65.0, '30-39': 60.2, '40-49': 72.1, '50-59': 64.1, '60-69': 74.4, '70-79': 75.8, 'old': 64.07, 'new': 75.8}
2024-08-31 21:06:16,310 [trainer.py] => NME: {'total': 59.17, '00-09': 57.6, '10-19': 41.5, '20-29': 60.5, '30-39': 55.1, '40-49': 68.0, '50-59': 59.5, '60-69': 61.1, '70-79': 81.0, 'old': 57.61, 'new': 81.0}
2024-08-31 21:06:16,310 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85]
2024-08-31 21:06:16,310 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96]
2024-08-31 21:06:16,310 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17]
2024-08-31 21:06:16,310 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84]

2024-08-31 21:06:16,310 [trainer.py] => CNN top1 平均值: 77.75
2024-08-31 21:06:16,313 [trainer.py] => All params: 1301648
2024-08-31 21:06:16,315 [trainer.py] => Trainable params: 655824
2024-08-31 21:06:16,378 [foster.py] => Learning on 75-80
2024-08-31 21:06:16,382 [foster.py] => All params: 1302943
2024-08-31 21:06:16,384 [foster.py] => Trainable params: 656794
2024-08-31 21:06:16,438 [foster.py] => per cls weights : [1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264 1.01909264
 1.01909264 1.01909264 1.01909264 0.71361043 0.71361043 0.71361043
 0.71361043 0.71361043]
2024-08-31 21:06:21,807 [foster.py] => Task 15, Epoch 1/170 => Loss 7.443, Loss_clf 2.725, Loss_fe 1.746, Loss_kd 2.778, Train_accy 54.40
2024-08-31 21:06:29,703 [foster.py] => Task 15, Epoch 2/170 => Loss 5.377, Loss_clf 1.214, Loss_fe 1.228, Loss_kd 2.743, Train_accy 67.08, Test_accy 57.54
2024-08-31 21:06:37,528 [foster.py] => Task 15, Epoch 3/170 => Loss 5.016, Loss_clf 1.050, Loss_fe 1.029, Loss_kd 2.746, Train_accy 66.22, Test_accy 56.50
2024-08-31 21:06:45,380 [foster.py] => Task 15, Epoch 4/170 => Loss 4.891, Loss_clf 0.992, Loss_fe 0.949, Loss_kd 2.758, Train_accy 68.45, Test_accy 59.09
2024-08-31 21:06:53,243 [foster.py] => Task 15, Epoch 5/170 => Loss 4.834, Loss_clf 0.959, Loss_fe 0.941, Loss_kd 2.743, Train_accy 68.25, Test_accy 61.14
2024-08-31 21:06:58,562 [foster.py] => Task 15, Epoch 6/170 => Loss 4.813, Loss_clf 0.988, Loss_fe 0.903, Loss_kd 2.732, Train_accy 67.26
2024-08-31 21:07:06,419 [foster.py] => Task 15, Epoch 7/170 => Loss 4.827, Loss_clf 0.988, Loss_fe 0.899, Loss_kd 2.750, Train_accy 67.64, Test_accy 59.14
2024-08-31 21:07:14,305 [foster.py] => Task 15, Epoch 8/170 => Loss 4.761, Loss_clf 0.947, Loss_fe 0.880, Loss_kd 2.744, Train_accy 67.96, Test_accy 58.32
2024-08-31 21:07:22,174 [foster.py] => Task 15, Epoch 9/170 => Loss 4.883, Loss_clf 1.028, Loss_fe 0.902, Loss_kd 2.762, Train_accy 67.30, Test_accy 58.31
2024-08-31 21:07:30,001 [foster.py] => Task 15, Epoch 10/170 => Loss 4.745, Loss_clf 0.930, Loss_fe 0.873, Loss_kd 2.752, Train_accy 67.80, Test_accy 57.46
2024-08-31 21:07:35,299 [foster.py] => Task 15, Epoch 11/170 => Loss 4.739, Loss_clf 0.925, Loss_fe 0.867, Loss_kd 2.757, Train_accy 68.43
2024-08-31 21:07:43,213 [foster.py] => Task 15, Epoch 12/170 => Loss 4.681, Loss_clf 0.886, Loss_fe 0.848, Loss_kd 2.756, Train_accy 69.08, Test_accy 58.69
2024-08-31 21:07:51,049 [foster.py] => Task 15, Epoch 13/170 => Loss 4.775, Loss_clf 0.967, Loss_fe 0.861, Loss_kd 2.756, Train_accy 67.28, Test_accy 58.92
2024-08-31 21:07:58,876 [foster.py] => Task 15, Epoch 14/170 => Loss 4.724, Loss_clf 0.911, Loss_fe 0.860, Loss_kd 2.763, Train_accy 68.97, Test_accy 61.69
2024-08-31 21:08:06,760 [foster.py] => Task 15, Epoch 15/170 => Loss 4.710, Loss_clf 0.933, Loss_fe 0.848, Loss_kd 2.740, Train_accy 67.15, Test_accy 60.72
2024-08-31 21:08:12,032 [foster.py] => Task 15, Epoch 16/170 => Loss 4.713, Loss_clf 0.922, Loss_fe 0.854, Loss_kd 2.748, Train_accy 69.24
2024-08-31 21:08:19,959 [foster.py] => Task 15, Epoch 17/170 => Loss 4.704, Loss_clf 0.919, Loss_fe 0.855, Loss_kd 2.741, Train_accy 68.56, Test_accy 57.46
2024-08-31 21:08:27,722 [foster.py] => Task 15, Epoch 18/170 => Loss 4.680, Loss_clf 0.890, Loss_fe 0.851, Loss_kd 2.750, Train_accy 67.55, Test_accy 58.72
2024-08-31 21:08:35,521 [foster.py] => Task 15, Epoch 19/170 => Loss 4.692, Loss_clf 0.891, Loss_fe 0.851, Loss_kd 2.760, Train_accy 69.19, Test_accy 59.99
2024-08-31 21:08:43,415 [foster.py] => Task 15, Epoch 20/170 => Loss 4.712, Loss_clf 0.925, Loss_fe 0.849, Loss_kd 2.749, Train_accy 68.36, Test_accy 58.34
2024-08-31 21:08:48,820 [foster.py] => Task 15, Epoch 21/170 => Loss 4.712, Loss_clf 0.933, Loss_fe 0.841, Loss_kd 2.749, Train_accy 66.90
2024-08-31 21:08:56,757 [foster.py] => Task 15, Epoch 22/170 => Loss 4.800, Loss_clf 0.985, Loss_fe 0.878, Loss_kd 2.748, Train_accy 68.13, Test_accy 60.66
2024-08-31 21:09:04,621 [foster.py] => Task 15, Epoch 23/170 => Loss 4.723, Loss_clf 0.925, Loss_fe 0.851, Loss_kd 2.758, Train_accy 67.98, Test_accy 58.09
2024-08-31 21:09:12,455 [foster.py] => Task 15, Epoch 24/170 => Loss 4.716, Loss_clf 0.912, Loss_fe 0.859, Loss_kd 2.755, Train_accy 68.97, Test_accy 56.71
2024-08-31 21:09:20,323 [foster.py] => Task 15, Epoch 25/170 => Loss 4.827, Loss_clf 1.004, Loss_fe 0.872, Loss_kd 2.761, Train_accy 67.30, Test_accy 60.30
2024-08-31 21:09:25,585 [foster.py] => Task 15, Epoch 26/170 => Loss 4.832, Loss_clf 0.994, Loss_fe 0.906, Loss_kd 2.743, Train_accy 66.45
2024-08-31 21:09:33,413 [foster.py] => Task 15, Epoch 27/170 => Loss 4.742, Loss_clf 0.951, Loss_fe 0.855, Loss_kd 2.746, Train_accy 67.30, Test_accy 60.09
2024-08-31 21:09:41,282 [foster.py] => Task 15, Epoch 28/170 => Loss 4.705, Loss_clf 0.910, Loss_fe 0.849, Loss_kd 2.756, Train_accy 67.87, Test_accy 58.49
2024-08-31 21:09:49,120 [foster.py] => Task 15, Epoch 29/170 => Loss 4.720, Loss_clf 0.949, Loss_fe 0.831, Loss_kd 2.751, Train_accy 68.27, Test_accy 60.44
2024-08-31 21:09:56,982 [foster.py] => Task 15, Epoch 30/170 => Loss 4.727, Loss_clf 0.948, Loss_fe 0.841, Loss_kd 2.749, Train_accy 66.18, Test_accy 59.60
2024-08-31 21:10:02,293 [foster.py] => Task 15, Epoch 31/170 => Loss 4.753, Loss_clf 0.951, Loss_fe 0.857, Loss_kd 2.756, Train_accy 67.57
2024-08-31 21:10:10,189 [foster.py] => Task 15, Epoch 32/170 => Loss 4.702, Loss_clf 0.918, Loss_fe 0.846, Loss_kd 2.749, Train_accy 68.97, Test_accy 60.44
2024-08-31 21:10:17,919 [foster.py] => Task 15, Epoch 33/170 => Loss 4.707, Loss_clf 0.913, Loss_fe 0.848, Loss_kd 2.757, Train_accy 67.08, Test_accy 60.51
2024-08-31 21:10:25,770 [foster.py] => Task 15, Epoch 34/170 => Loss 4.716, Loss_clf 0.909, Loss_fe 0.875, Loss_kd 2.744, Train_accy 67.12, Test_accy 59.81
2024-08-31 21:10:33,608 [foster.py] => Task 15, Epoch 35/170 => Loss 4.829, Loss_clf 0.995, Loss_fe 0.880, Loss_kd 2.764, Train_accy 64.88, Test_accy 59.79
2024-08-31 21:10:39,007 [foster.py] => Task 15, Epoch 36/170 => Loss 4.841, Loss_clf 1.025, Loss_fe 0.876, Loss_kd 2.751, Train_accy 66.27
2024-08-31 21:10:46,839 [foster.py] => Task 15, Epoch 37/170 => Loss 4.655, Loss_clf 0.902, Loss_fe 0.836, Loss_kd 2.729, Train_accy 68.40, Test_accy 60.44
2024-08-31 21:10:54,649 [foster.py] => Task 15, Epoch 38/170 => Loss 4.774, Loss_clf 0.960, Loss_fe 0.872, Loss_kd 2.753, Train_accy 66.67, Test_accy 59.35
2024-08-31 21:11:02,507 [foster.py] => Task 15, Epoch 39/170 => Loss 4.691, Loss_clf 0.937, Loss_fe 0.820, Loss_kd 2.746, Train_accy 67.15, Test_accy 60.84
2024-08-31 21:11:10,375 [foster.py] => Task 15, Epoch 40/170 => Loss 4.627, Loss_clf 0.883, Loss_fe 0.817, Loss_kd 2.738, Train_accy 69.12, Test_accy 59.31
2024-08-31 21:11:15,763 [foster.py] => Task 15, Epoch 41/170 => Loss 4.712, Loss_clf 0.932, Loss_fe 0.850, Loss_kd 2.742, Train_accy 66.76
2024-08-31 21:11:23,579 [foster.py] => Task 15, Epoch 42/170 => Loss 4.714, Loss_clf 0.942, Loss_fe 0.842, Loss_kd 2.741, Train_accy 66.61, Test_accy 53.32
2024-08-31 21:11:31,398 [foster.py] => Task 15, Epoch 43/170 => Loss 4.986, Loss_clf 1.156, Loss_fe 0.902, Loss_kd 2.740, Train_accy 66.54, Test_accy 56.35
2024-08-31 21:11:39,301 [foster.py] => Task 15, Epoch 44/170 => Loss 4.788, Loss_clf 0.943, Loss_fe 0.884, Loss_kd 2.771, Train_accy 66.34, Test_accy 60.26
2024-08-31 21:11:47,192 [foster.py] => Task 15, Epoch 45/170 => Loss 4.745, Loss_clf 0.944, Loss_fe 0.854, Loss_kd 2.758, Train_accy 66.88, Test_accy 60.29
2024-08-31 21:11:52,454 [foster.py] => Task 15, Epoch 46/170 => Loss 4.644, Loss_clf 0.883, Loss_fe 0.828, Loss_kd 2.745, Train_accy 66.94
2024-08-31 21:12:00,424 [foster.py] => Task 15, Epoch 47/170 => Loss 4.711, Loss_clf 0.928, Loss_fe 0.838, Loss_kd 2.755, Train_accy 65.98, Test_accy 60.74
2024-08-31 21:12:08,331 [foster.py] => Task 15, Epoch 48/170 => Loss 4.674, Loss_clf 0.907, Loss_fe 0.829, Loss_kd 2.749, Train_accy 68.65, Test_accy 59.89
2024-08-31 21:12:16,219 [foster.py] => Task 15, Epoch 49/170 => Loss 4.663, Loss_clf 0.910, Loss_fe 0.807, Loss_kd 2.756, Train_accy 67.82, Test_accy 60.21
2024-08-31 21:12:24,088 [foster.py] => Task 15, Epoch 50/170 => Loss 4.619, Loss_clf 0.859, Loss_fe 0.829, Loss_kd 2.742, Train_accy 67.93, Test_accy 59.58
2024-08-31 21:12:29,437 [foster.py] => Task 15, Epoch 51/170 => Loss 4.657, Loss_clf 0.889, Loss_fe 0.828, Loss_kd 2.751, Train_accy 67.37
2024-08-31 21:12:37,238 [foster.py] => Task 15, Epoch 52/170 => Loss 4.648, Loss_clf 0.879, Loss_fe 0.826, Loss_kd 2.754, Train_accy 67.96, Test_accy 60.62
2024-08-31 21:12:45,110 [foster.py] => Task 15, Epoch 53/170 => Loss 4.576, Loss_clf 0.844, Loss_fe 0.810, Loss_kd 2.734, Train_accy 68.72, Test_accy 60.71
2024-08-31 21:12:52,963 [foster.py] => Task 15, Epoch 54/170 => Loss 4.593, Loss_clf 0.849, Loss_fe 0.802, Loss_kd 2.752, Train_accy 68.90, Test_accy 60.24
2024-08-31 21:13:00,823 [foster.py] => Task 15, Epoch 55/170 => Loss 4.597, Loss_clf 0.860, Loss_fe 0.805, Loss_kd 2.744, Train_accy 67.26, Test_accy 61.84
2024-08-31 21:13:06,063 [foster.py] => Task 15, Epoch 56/170 => Loss 4.563, Loss_clf 0.854, Loss_fe 0.783, Loss_kd 2.737, Train_accy 68.04
2024-08-31 21:13:13,872 [foster.py] => Task 15, Epoch 57/170 => Loss 4.575, Loss_clf 0.858, Loss_fe 0.798, Loss_kd 2.732, Train_accy 66.85, Test_accy 59.71
2024-08-31 21:13:21,766 [foster.py] => Task 15, Epoch 58/170 => Loss 4.561, Loss_clf 0.833, Loss_fe 0.781, Loss_kd 2.758, Train_accy 67.71, Test_accy 60.79
2024-08-31 21:13:29,596 [foster.py] => Task 15, Epoch 59/170 => Loss 4.629, Loss_clf 0.873, Loss_fe 0.812, Loss_kd 2.755, Train_accy 67.01, Test_accy 61.05
2024-08-31 21:13:37,447 [foster.py] => Task 15, Epoch 60/170 => Loss 4.628, Loss_clf 0.907, Loss_fe 0.788, Loss_kd 2.745, Train_accy 66.20, Test_accy 58.15
2024-08-31 21:13:42,707 [foster.py] => Task 15, Epoch 61/170 => Loss 4.547, Loss_clf 0.837, Loss_fe 0.795, Loss_kd 2.728, Train_accy 68.22
2024-08-31 21:13:50,614 [foster.py] => Task 15, Epoch 62/170 => Loss 4.549, Loss_clf 0.858, Loss_fe 0.763, Loss_kd 2.740, Train_accy 67.78, Test_accy 59.66
2024-08-31 21:13:58,565 [foster.py] => Task 15, Epoch 63/170 => Loss 4.601, Loss_clf 0.876, Loss_fe 0.803, Loss_kd 2.734, Train_accy 67.46, Test_accy 60.92
2024-08-31 21:14:06,389 [foster.py] => Task 15, Epoch 64/170 => Loss 4.578, Loss_clf 0.850, Loss_fe 0.812, Loss_kd 2.729, Train_accy 67.35, Test_accy 61.16
2024-08-31 21:14:14,248 [foster.py] => Task 15, Epoch 65/170 => Loss 4.555, Loss_clf 0.845, Loss_fe 0.786, Loss_kd 2.736, Train_accy 67.71, Test_accy 59.75
2024-08-31 21:14:19,584 [foster.py] => Task 15, Epoch 66/170 => Loss 4.509, Loss_clf 0.807, Loss_fe 0.778, Loss_kd 2.736, Train_accy 67.66
2024-08-31 21:14:27,454 [foster.py] => Task 15, Epoch 67/170 => Loss 4.566, Loss_clf 0.866, Loss_fe 0.757, Loss_kd 2.754, Train_accy 67.42, Test_accy 60.19
2024-08-31 21:14:35,481 [foster.py] => Task 15, Epoch 68/170 => Loss 4.598, Loss_clf 0.900, Loss_fe 0.760, Loss_kd 2.749, Train_accy 66.52, Test_accy 59.79
2024-08-31 21:14:43,333 [foster.py] => Task 15, Epoch 69/170 => Loss 4.571, Loss_clf 0.860, Loss_fe 0.773, Loss_kd 2.749, Train_accy 67.71, Test_accy 58.32
2024-08-31 21:14:51,232 [foster.py] => Task 15, Epoch 70/170 => Loss 4.525, Loss_clf 0.826, Loss_fe 0.770, Loss_kd 2.741, Train_accy 69.51, Test_accy 61.09
2024-08-31 21:14:56,560 [foster.py] => Task 15, Epoch 71/170 => Loss 4.515, Loss_clf 0.821, Loss_fe 0.760, Loss_kd 2.745, Train_accy 68.49
2024-08-31 21:15:04,400 [foster.py] => Task 15, Epoch 72/170 => Loss 4.603, Loss_clf 0.913, Loss_fe 0.754, Loss_kd 2.748, Train_accy 67.26, Test_accy 60.70
2024-08-31 21:15:12,220 [foster.py] => Task 15, Epoch 73/170 => Loss 4.547, Loss_clf 0.846, Loss_fe 0.754, Loss_kd 2.758, Train_accy 68.58, Test_accy 61.02
2024-08-31 21:15:20,105 [foster.py] => Task 15, Epoch 74/170 => Loss 4.525, Loss_clf 0.836, Loss_fe 0.742, Loss_kd 2.758, Train_accy 68.83, Test_accy 60.04
2024-08-31 21:15:27,956 [foster.py] => Task 15, Epoch 75/170 => Loss 4.548, Loss_clf 0.866, Loss_fe 0.745, Loss_kd 2.748, Train_accy 67.17, Test_accy 61.25
2024-08-31 21:15:33,256 [foster.py] => Task 15, Epoch 76/170 => Loss 4.593, Loss_clf 0.885, Loss_fe 0.759, Loss_kd 2.760, Train_accy 68.27
2024-08-31 21:15:41,158 [foster.py] => Task 15, Epoch 77/170 => Loss 4.466, Loss_clf 0.795, Loss_fe 0.740, Loss_kd 2.743, Train_accy 68.27, Test_accy 61.06
2024-08-31 21:15:49,037 [foster.py] => Task 15, Epoch 78/170 => Loss 4.457, Loss_clf 0.799, Loss_fe 0.727, Loss_kd 2.742, Train_accy 68.34, Test_accy 58.89
2024-08-31 21:15:56,961 [foster.py] => Task 15, Epoch 79/170 => Loss 4.563, Loss_clf 0.868, Loss_fe 0.745, Loss_kd 2.760, Train_accy 68.16, Test_accy 61.49
2024-08-31 21:16:04,843 [foster.py] => Task 15, Epoch 80/170 => Loss 4.459, Loss_clf 0.820, Loss_fe 0.714, Loss_kd 2.738, Train_accy 69.35, Test_accy 60.64
2024-08-31 21:16:10,147 [foster.py] => Task 15, Epoch 81/170 => Loss 4.475, Loss_clf 0.838, Loss_fe 0.689, Loss_kd 2.759, Train_accy 69.66
2024-08-31 21:16:18,074 [foster.py] => Task 15, Epoch 82/170 => Loss 4.504, Loss_clf 0.844, Loss_fe 0.715, Loss_kd 2.756, Train_accy 69.12, Test_accy 60.20
2024-08-31 21:16:25,875 [foster.py] => Task 15, Epoch 83/170 => Loss 4.471, Loss_clf 0.826, Loss_fe 0.720, Loss_kd 2.737, Train_accy 70.13, Test_accy 61.39
2024-08-31 21:16:33,766 [foster.py] => Task 15, Epoch 84/170 => Loss 4.460, Loss_clf 0.812, Loss_fe 0.709, Loss_kd 2.750, Train_accy 67.60, Test_accy 61.40
2024-08-31 21:16:41,610 [foster.py] => Task 15, Epoch 85/170 => Loss 4.353, Loss_clf 0.751, Loss_fe 0.684, Loss_kd 2.730, Train_accy 69.80, Test_accy 61.20
2024-08-31 21:16:46,894 [foster.py] => Task 15, Epoch 86/170 => Loss 4.421, Loss_clf 0.805, Loss_fe 0.681, Loss_kd 2.747, Train_accy 68.43
2024-08-31 21:16:54,772 [foster.py] => Task 15, Epoch 87/170 => Loss 4.464, Loss_clf 0.821, Loss_fe 0.705, Loss_kd 2.749, Train_accy 69.03, Test_accy 61.91
2024-08-31 21:17:02,662 [foster.py] => Task 15, Epoch 88/170 => Loss 4.435, Loss_clf 0.815, Loss_fe 0.695, Loss_kd 2.736, Train_accy 69.21, Test_accy 61.48
2024-08-31 21:17:10,570 [foster.py] => Task 15, Epoch 89/170 => Loss 4.385, Loss_clf 0.789, Loss_fe 0.662, Loss_kd 2.746, Train_accy 69.66, Test_accy 62.62
2024-08-31 21:17:18,555 [foster.py] => Task 15, Epoch 90/170 => Loss 4.419, Loss_clf 0.818, Loss_fe 0.672, Loss_kd 2.741, Train_accy 69.10, Test_accy 61.58
2024-08-31 21:17:23,917 [foster.py] => Task 15, Epoch 91/170 => Loss 4.390, Loss_clf 0.784, Loss_fe 0.670, Loss_kd 2.747, Train_accy 70.13
2024-08-31 21:17:31,779 [foster.py] => Task 15, Epoch 92/170 => Loss 4.423, Loss_clf 0.814, Loss_fe 0.677, Loss_kd 2.744, Train_accy 69.93, Test_accy 59.59
2024-08-31 21:17:39,714 [foster.py] => Task 15, Epoch 93/170 => Loss 4.407, Loss_clf 0.812, Loss_fe 0.666, Loss_kd 2.742, Train_accy 69.39, Test_accy 59.45
2024-08-31 21:17:47,705 [foster.py] => Task 15, Epoch 94/170 => Loss 4.401, Loss_clf 0.791, Loss_fe 0.666, Loss_kd 2.755, Train_accy 69.80, Test_accy 61.40
2024-08-31 21:17:55,529 [foster.py] => Task 15, Epoch 95/170 => Loss 4.325, Loss_clf 0.757, Loss_fe 0.649, Loss_kd 2.732, Train_accy 70.47, Test_accy 61.56
2024-08-31 21:18:00,792 [foster.py] => Task 15, Epoch 96/170 => Loss 4.346, Loss_clf 0.774, Loss_fe 0.645, Loss_kd 2.739, Train_accy 70.20
2024-08-31 21:18:08,634 [foster.py] => Task 15, Epoch 97/170 => Loss 4.346, Loss_clf 0.777, Loss_fe 0.636, Loss_kd 2.745, Train_accy 69.60, Test_accy 61.49
2024-08-31 21:18:16,485 [foster.py] => Task 15, Epoch 98/170 => Loss 4.310, Loss_clf 0.740, Loss_fe 0.648, Loss_kd 2.734, Train_accy 71.78, Test_accy 61.60
2024-08-31 21:18:24,338 [foster.py] => Task 15, Epoch 99/170 => Loss 4.238, Loss_clf 0.710, Loss_fe 0.611, Loss_kd 2.730, Train_accy 71.87, Test_accy 62.41
2024-08-31 21:18:32,265 [foster.py] => Task 15, Epoch 100/170 => Loss 4.324, Loss_clf 0.764, Loss_fe 0.620, Loss_kd 2.750, Train_accy 71.24, Test_accy 60.55
2024-08-31 21:18:37,529 [foster.py] => Task 15, Epoch 101/170 => Loss 4.336, Loss_clf 0.769, Loss_fe 0.636, Loss_kd 2.743, Train_accy 70.29
2024-08-31 21:18:45,349 [foster.py] => Task 15, Epoch 102/170 => Loss 4.293, Loss_clf 0.747, Loss_fe 0.635, Loss_kd 2.724, Train_accy 70.09, Test_accy 61.34
2024-08-31 21:18:53,157 [foster.py] => Task 15, Epoch 103/170 => Loss 4.283, Loss_clf 0.750, Loss_fe 0.608, Loss_kd 2.738, Train_accy 70.90, Test_accy 62.48
2024-08-31 21:19:01,073 [foster.py] => Task 15, Epoch 104/170 => Loss 4.262, Loss_clf 0.729, Loss_fe 0.594, Loss_kd 2.751, Train_accy 72.79, Test_accy 61.62
2024-08-31 21:19:08,868 [foster.py] => Task 15, Epoch 105/170 => Loss 4.299, Loss_clf 0.762, Loss_fe 0.595, Loss_kd 2.753, Train_accy 71.69, Test_accy 60.90
2024-08-31 21:19:14,136 [foster.py] => Task 15, Epoch 106/170 => Loss 4.232, Loss_clf 0.715, Loss_fe 0.606, Loss_kd 2.724, Train_accy 72.92
2024-08-31 21:19:22,104 [foster.py] => Task 15, Epoch 107/170 => Loss 4.278, Loss_clf 0.745, Loss_fe 0.595, Loss_kd 2.750, Train_accy 72.49, Test_accy 62.12
2024-08-31 21:19:30,065 [foster.py] => Task 15, Epoch 108/170 => Loss 4.283, Loss_clf 0.746, Loss_fe 0.601, Loss_kd 2.748, Train_accy 71.55, Test_accy 62.25
2024-08-31 21:19:37,969 [foster.py] => Task 15, Epoch 109/170 => Loss 4.272, Loss_clf 0.749, Loss_fe 0.588, Loss_kd 2.746, Train_accy 72.16, Test_accy 62.26
2024-08-31 21:19:45,878 [foster.py] => Task 15, Epoch 110/170 => Loss 4.221, Loss_clf 0.732, Loss_fe 0.556, Loss_kd 2.745, Train_accy 72.04, Test_accy 62.08
2024-08-31 21:19:51,191 [foster.py] => Task 15, Epoch 111/170 => Loss 4.211, Loss_clf 0.716, Loss_fe 0.581, Loss_kd 2.728, Train_accy 73.21
2024-08-31 21:19:59,030 [foster.py] => Task 15, Epoch 112/170 => Loss 4.248, Loss_clf 0.746, Loss_fe 0.597, Loss_kd 2.719, Train_accy 71.30, Test_accy 62.50
2024-08-31 21:20:06,885 [foster.py] => Task 15, Epoch 113/170 => Loss 4.207, Loss_clf 0.720, Loss_fe 0.570, Loss_kd 2.730, Train_accy 70.85, Test_accy 61.79
2024-08-31 21:20:14,796 [foster.py] => Task 15, Epoch 114/170 => Loss 4.216, Loss_clf 0.726, Loss_fe 0.568, Loss_kd 2.735, Train_accy 72.36, Test_accy 62.34
2024-08-31 21:20:22,668 [foster.py] => Task 15, Epoch 115/170 => Loss 4.183, Loss_clf 0.704, Loss_fe 0.564, Loss_kd 2.728, Train_accy 73.01, Test_accy 61.40
2024-08-31 21:20:27,986 [foster.py] => Task 15, Epoch 116/170 => Loss 4.246, Loss_clf 0.746, Loss_fe 0.557, Loss_kd 2.754, Train_accy 72.11
2024-08-31 21:20:35,878 [foster.py] => Task 15, Epoch 117/170 => Loss 4.210, Loss_clf 0.723, Loss_fe 0.549, Loss_kd 2.749, Train_accy 72.11, Test_accy 60.92
2024-08-31 21:20:43,847 [foster.py] => Task 15, Epoch 118/170 => Loss 4.130, Loss_clf 0.685, Loss_fe 0.532, Loss_kd 2.726, Train_accy 72.94, Test_accy 62.60
2024-08-31 21:20:51,732 [foster.py] => Task 15, Epoch 119/170 => Loss 4.116, Loss_clf 0.687, Loss_fe 0.496, Loss_kd 2.744, Train_accy 75.21, Test_accy 62.74
2024-08-31 21:20:59,672 [foster.py] => Task 15, Epoch 120/170 => Loss 4.154, Loss_clf 0.713, Loss_fe 0.514, Loss_kd 2.739, Train_accy 73.26, Test_accy 61.81
2024-08-31 21:21:04,971 [foster.py] => Task 15, Epoch 121/170 => Loss 4.132, Loss_clf 0.702, Loss_fe 0.505, Loss_kd 2.737, Train_accy 73.93
2024-08-31 21:21:12,761 [foster.py] => Task 15, Epoch 122/170 => Loss 4.143, Loss_clf 0.684, Loss_fe 0.527, Loss_kd 2.744, Train_accy 73.87, Test_accy 62.82
2024-08-31 21:21:20,611 [foster.py] => Task 15, Epoch 123/170 => Loss 4.137, Loss_clf 0.695, Loss_fe 0.513, Loss_kd 2.742, Train_accy 73.91, Test_accy 62.44
2024-08-31 21:21:28,419 [foster.py] => Task 15, Epoch 124/170 => Loss 4.102, Loss_clf 0.686, Loss_fe 0.492, Loss_kd 2.737, Train_accy 73.93, Test_accy 62.74
2024-08-31 21:21:36,203 [foster.py] => Task 15, Epoch 125/170 => Loss 4.062, Loss_clf 0.661, Loss_fe 0.489, Loss_kd 2.725, Train_accy 74.63, Test_accy 62.45
2024-08-31 21:21:41,563 [foster.py] => Task 15, Epoch 126/170 => Loss 4.112, Loss_clf 0.689, Loss_fe 0.492, Loss_kd 2.742, Train_accy 73.28
2024-08-31 21:21:49,362 [foster.py] => Task 15, Epoch 127/170 => Loss 4.118, Loss_clf 0.685, Loss_fe 0.499, Loss_kd 2.746, Train_accy 75.39, Test_accy 62.52
2024-08-31 21:21:57,175 [foster.py] => Task 15, Epoch 128/170 => Loss 4.091, Loss_clf 0.685, Loss_fe 0.471, Loss_kd 2.746, Train_accy 73.80, Test_accy 62.14
2024-08-31 21:22:04,998 [foster.py] => Task 15, Epoch 129/170 => Loss 4.015, Loss_clf 0.648, Loss_fe 0.446, Loss_kd 2.732, Train_accy 76.00, Test_accy 62.60
2024-08-31 21:22:12,850 [foster.py] => Task 15, Epoch 130/170 => Loss 3.965, Loss_clf 0.626, Loss_fe 0.421, Loss_kd 2.731, Train_accy 76.94, Test_accy 62.14
2024-08-31 21:22:18,210 [foster.py] => Task 15, Epoch 131/170 => Loss 4.048, Loss_clf 0.660, Loss_fe 0.445, Loss_kd 2.754, Train_accy 75.96
2024-08-31 21:22:26,075 [foster.py] => Task 15, Epoch 132/170 => Loss 4.011, Loss_clf 0.651, Loss_fe 0.458, Loss_kd 2.715, Train_accy 74.38, Test_accy 62.26
2024-08-31 21:22:33,959 [foster.py] => Task 15, Epoch 133/170 => Loss 4.003, Loss_clf 0.636, Loss_fe 0.433, Loss_kd 2.746, Train_accy 76.27, Test_accy 63.01
2024-08-31 21:22:41,809 [foster.py] => Task 15, Epoch 134/170 => Loss 3.972, Loss_clf 0.631, Loss_fe 0.427, Loss_kd 2.726, Train_accy 76.49, Test_accy 62.72
2024-08-31 21:22:49,700 [foster.py] => Task 15, Epoch 135/170 => Loss 3.987, Loss_clf 0.645, Loss_fe 0.418, Loss_kd 2.735, Train_accy 76.90, Test_accy 63.08
2024-08-31 21:22:55,066 [foster.py] => Task 15, Epoch 136/170 => Loss 3.941, Loss_clf 0.615, Loss_fe 0.418, Loss_kd 2.722, Train_accy 76.25
2024-08-31 21:23:02,977 [foster.py] => Task 15, Epoch 137/170 => Loss 3.941, Loss_clf 0.613, Loss_fe 0.401, Loss_kd 2.739, Train_accy 77.55, Test_accy 63.30
2024-08-31 21:23:10,832 [foster.py] => Task 15, Epoch 138/170 => Loss 3.946, Loss_clf 0.612, Loss_fe 0.403, Loss_kd 2.742, Train_accy 78.16, Test_accy 62.54
2024-08-31 21:23:18,725 [foster.py] => Task 15, Epoch 139/170 => Loss 3.916, Loss_clf 0.600, Loss_fe 0.387, Loss_kd 2.740, Train_accy 78.20, Test_accy 62.89
2024-08-31 21:23:26,551 [foster.py] => Task 15, Epoch 140/170 => Loss 3.888, Loss_clf 0.597, Loss_fe 0.381, Loss_kd 2.723, Train_accy 78.31, Test_accy 63.11
2024-08-31 21:23:31,879 [foster.py] => Task 15, Epoch 141/170 => Loss 3.915, Loss_clf 0.608, Loss_fe 0.386, Loss_kd 2.733, Train_accy 78.58
2024-08-31 21:23:39,806 [foster.py] => Task 15, Epoch 142/170 => Loss 3.964, Loss_clf 0.629, Loss_fe 0.396, Loss_kd 2.751, Train_accy 76.65, Test_accy 62.59
2024-08-31 21:23:47,641 [foster.py] => Task 15, Epoch 143/170 => Loss 3.917, Loss_clf 0.602, Loss_fe 0.383, Loss_kd 2.744, Train_accy 77.93, Test_accy 62.96
2024-08-31 21:23:55,558 [foster.py] => Task 15, Epoch 144/170 => Loss 3.868, Loss_clf 0.595, Loss_fe 0.351, Loss_kd 2.734, Train_accy 78.63, Test_accy 63.05
2024-08-31 21:24:03,321 [foster.py] => Task 15, Epoch 145/170 => Loss 3.844, Loss_clf 0.572, Loss_fe 0.363, Loss_kd 2.722, Train_accy 79.30, Test_accy 62.98
2024-08-31 21:24:08,631 [foster.py] => Task 15, Epoch 146/170 => Loss 3.891, Loss_clf 0.583, Loss_fe 0.370, Loss_kd 2.749, Train_accy 78.99
2024-08-31 21:24:16,515 [foster.py] => Task 15, Epoch 147/170 => Loss 3.855, Loss_clf 0.576, Loss_fe 0.355, Loss_kd 2.737, Train_accy 79.78, Test_accy 63.30
2024-08-31 21:24:24,308 [foster.py] => Task 15, Epoch 148/170 => Loss 3.834, Loss_clf 0.572, Loss_fe 0.341, Loss_kd 2.734, Train_accy 79.03, Test_accy 63.30
2024-08-31 21:24:32,201 [foster.py] => Task 15, Epoch 149/170 => Loss 3.853, Loss_clf 0.574, Loss_fe 0.357, Loss_kd 2.735, Train_accy 79.30, Test_accy 62.94
2024-08-31 21:24:40,110 [foster.py] => Task 15, Epoch 150/170 => Loss 3.843, Loss_clf 0.580, Loss_fe 0.339, Loss_kd 2.737, Train_accy 79.82, Test_accy 63.11
2024-08-31 21:24:45,406 [foster.py] => Task 15, Epoch 151/170 => Loss 3.857, Loss_clf 0.586, Loss_fe 0.346, Loss_kd 2.737, Train_accy 79.73
2024-08-31 21:24:53,241 [foster.py] => Task 15, Epoch 152/170 => Loss 3.849, Loss_clf 0.590, Loss_fe 0.345, Loss_kd 2.727, Train_accy 79.42, Test_accy 63.01
2024-08-31 21:25:01,123 [foster.py] => Task 15, Epoch 153/170 => Loss 3.806, Loss_clf 0.562, Loss_fe 0.315, Loss_kd 2.741, Train_accy 80.49, Test_accy 63.21
2024-08-31 21:25:09,041 [foster.py] => Task 15, Epoch 154/170 => Loss 3.865, Loss_clf 0.595, Loss_fe 0.341, Loss_kd 2.742, Train_accy 79.89, Test_accy 63.29
2024-08-31 21:25:16,873 [foster.py] => Task 15, Epoch 155/170 => Loss 3.797, Loss_clf 0.563, Loss_fe 0.311, Loss_kd 2.736, Train_accy 79.89, Test_accy 63.48
2024-08-31 21:25:22,199 [foster.py] => Task 15, Epoch 156/170 => Loss 3.812, Loss_clf 0.579, Loss_fe 0.311, Loss_kd 2.734, Train_accy 80.13
2024-08-31 21:25:30,087 [foster.py] => Task 15, Epoch 157/170 => Loss 3.811, Loss_clf 0.566, Loss_fe 0.318, Loss_kd 2.739, Train_accy 80.70, Test_accy 63.46
2024-08-31 21:25:37,971 [foster.py] => Task 15, Epoch 158/170 => Loss 3.784, Loss_clf 0.559, Loss_fe 0.303, Loss_kd 2.734, Train_accy 80.72, Test_accy 63.31
2024-08-31 21:25:45,803 [foster.py] => Task 15, Epoch 159/170 => Loss 3.799, Loss_clf 0.568, Loss_fe 0.295, Loss_kd 2.747, Train_accy 80.54, Test_accy 63.41
2024-08-31 21:25:53,637 [foster.py] => Task 15, Epoch 160/170 => Loss 3.778, Loss_clf 0.564, Loss_fe 0.305, Loss_kd 2.723, Train_accy 80.04, Test_accy 63.41
2024-08-31 21:25:58,972 [foster.py] => Task 15, Epoch 161/170 => Loss 3.765, Loss_clf 0.538, Loss_fe 0.297, Loss_kd 2.742, Train_accy 81.12
2024-08-31 21:26:06,907 [foster.py] => Task 15, Epoch 162/170 => Loss 3.758, Loss_clf 0.546, Loss_fe 0.294, Loss_kd 2.731, Train_accy 81.19, Test_accy 63.28
2024-08-31 21:26:14,798 [foster.py] => Task 15, Epoch 163/170 => Loss 3.773, Loss_clf 0.544, Loss_fe 0.306, Loss_kd 2.735, Train_accy 81.28, Test_accy 63.34
2024-08-31 21:26:22,724 [foster.py] => Task 15, Epoch 164/170 => Loss 3.742, Loss_clf 0.546, Loss_fe 0.279, Loss_kd 2.730, Train_accy 80.94, Test_accy 63.39
2024-08-31 21:26:30,617 [foster.py] => Task 15, Epoch 165/170 => Loss 3.725, Loss_clf 0.527, Loss_fe 0.289, Loss_kd 2.722, Train_accy 81.26, Test_accy 63.39
2024-08-31 21:26:35,911 [foster.py] => Task 15, Epoch 166/170 => Loss 3.782, Loss_clf 0.559, Loss_fe 0.299, Loss_kd 2.737, Train_accy 81.21
2024-08-31 21:26:43,762 [foster.py] => Task 15, Epoch 167/170 => Loss 3.779, Loss_clf 0.555, Loss_fe 0.297, Loss_kd 2.739, Train_accy 80.92, Test_accy 63.34
2024-08-31 21:26:51,660 [foster.py] => Task 15, Epoch 168/170 => Loss 3.764, Loss_clf 0.539, Loss_fe 0.298, Loss_kd 2.739, Train_accy 81.01, Test_accy 63.31
2024-08-31 21:26:59,530 [foster.py] => Task 15, Epoch 169/170 => Loss 3.780, Loss_clf 0.555, Loss_fe 0.300, Loss_kd 2.737, Train_accy 81.06, Test_accy 63.38
2024-08-31 21:27:07,383 [foster.py] => Task 15, Epoch 170/170 => Loss 3.770, Loss_clf 0.551, Loss_fe 0.290, Loss_kd 2.741, Train_accy 81.46, Test_accy 63.39
2024-08-31 21:27:07,385 [foster.py] => do not weight align teacher!
2024-08-31 21:27:07,388 [foster.py] => per cls weights : [1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763 1.03243763
 1.03243763 1.03243763 1.03243763 0.51343561 0.51343561 0.51343561
 0.51343561 0.51343561]
2024-08-31 21:27:17,110 [foster.py] => SNet: Task 15, Epoch 1/130 => Loss 30.323,  Loss1 0.748, Train_accy 39.55, Test_accy 60.22
2024-08-31 21:27:24,487 [foster.py] => SNet: Task 15, Epoch 2/130 => Loss 30.246,  Loss1 0.748, Train_accy 47.82
2024-08-31 21:27:31,660 [foster.py] => SNet: Task 15, Epoch 3/130 => Loss 30.214,  Loss1 0.749, Train_accy 52.45
2024-08-31 21:27:39,195 [foster.py] => SNet: Task 15, Epoch 4/130 => Loss 30.216,  Loss1 0.749, Train_accy 54.83
2024-08-31 21:27:46,324 [foster.py] => SNet: Task 15, Epoch 5/130 => Loss 30.196,  Loss1 0.748, Train_accy 56.11
2024-08-31 21:27:56,248 [foster.py] => SNet: Task 15, Epoch 6/130 => Loss 30.192,  Loss1 0.749, Train_accy 57.75, Test_accy 61.40
2024-08-31 21:28:03,504 [foster.py] => SNet: Task 15, Epoch 7/130 => Loss 30.172,  Loss1 0.749, Train_accy 59.33
2024-08-31 21:28:10,677 [foster.py] => SNet: Task 15, Epoch 8/130 => Loss 30.175,  Loss1 0.749, Train_accy 58.74
2024-08-31 21:28:17,767 [foster.py] => SNet: Task 15, Epoch 9/130 => Loss 30.216,  Loss1 0.749, Train_accy 59.17
2024-08-31 21:28:24,917 [foster.py] => SNet: Task 15, Epoch 10/130 => Loss 30.175,  Loss1 0.749, Train_accy 59.80
2024-08-31 21:28:34,393 [foster.py] => SNet: Task 15, Epoch 11/130 => Loss 30.187,  Loss1 0.749, Train_accy 59.57, Test_accy 61.44
2024-08-31 21:28:41,703 [foster.py] => SNet: Task 15, Epoch 12/130 => Loss 30.176,  Loss1 0.749, Train_accy 59.87
2024-08-31 21:28:48,776 [foster.py] => SNet: Task 15, Epoch 13/130 => Loss 30.209,  Loss1 0.749, Train_accy 60.88
2024-08-31 21:28:55,948 [foster.py] => SNet: Task 15, Epoch 14/130 => Loss 30.177,  Loss1 0.749, Train_accy 62.13
2024-08-31 21:29:03,019 [foster.py] => SNet: Task 15, Epoch 15/130 => Loss 30.181,  Loss1 0.749, Train_accy 61.53
2024-08-31 21:29:12,385 [foster.py] => SNet: Task 15, Epoch 16/130 => Loss 30.215,  Loss1 0.749, Train_accy 62.22, Test_accy 61.50
2024-08-31 21:29:19,654 [foster.py] => SNet: Task 15, Epoch 17/130 => Loss 30.166,  Loss1 0.749, Train_accy 61.71
2024-08-31 21:29:27,703 [foster.py] => SNet: Task 15, Epoch 18/130 => Loss 30.160,  Loss1 0.749, Train_accy 61.82
2024-08-31 21:29:34,903 [foster.py] => SNet: Task 15, Epoch 19/130 => Loss 30.179,  Loss1 0.749, Train_accy 62.16
2024-08-31 21:29:42,124 [foster.py] => SNet: Task 15, Epoch 20/130 => Loss 30.192,  Loss1 0.749, Train_accy 63.26
2024-08-31 21:29:51,734 [foster.py] => SNet: Task 15, Epoch 21/130 => Loss 30.173,  Loss1 0.749, Train_accy 62.52, Test_accy 62.61
2024-08-31 21:29:59,106 [foster.py] => SNet: Task 15, Epoch 22/130 => Loss 30.181,  Loss1 0.749, Train_accy 62.76
2024-08-31 21:30:06,384 [foster.py] => SNet: Task 15, Epoch 23/130 => Loss 30.173,  Loss1 0.749, Train_accy 63.19
2024-08-31 21:30:13,798 [foster.py] => SNet: Task 15, Epoch 24/130 => Loss 30.202,  Loss1 0.749, Train_accy 63.87
2024-08-31 21:30:20,905 [foster.py] => SNet: Task 15, Epoch 25/130 => Loss 30.160,  Loss1 0.749, Train_accy 63.28
2024-08-31 21:30:30,369 [foster.py] => SNet: Task 15, Epoch 26/130 => Loss 30.196,  Loss1 0.749, Train_accy 63.17, Test_accy 62.25
2024-08-31 21:30:37,884 [foster.py] => SNet: Task 15, Epoch 27/130 => Loss 30.197,  Loss1 0.749, Train_accy 63.10
2024-08-31 21:30:45,349 [foster.py] => SNet: Task 15, Epoch 28/130 => Loss 30.190,  Loss1 0.749, Train_accy 64.43
2024-08-31 21:30:52,940 [foster.py] => SNet: Task 15, Epoch 29/130 => Loss 30.183,  Loss1 0.749, Train_accy 64.38
2024-08-31 21:31:00,227 [foster.py] => SNet: Task 15, Epoch 30/130 => Loss 30.175,  Loss1 0.749, Train_accy 62.94
2024-08-31 21:31:09,713 [foster.py] => SNet: Task 15, Epoch 31/130 => Loss 30.213,  Loss1 0.749, Train_accy 62.88, Test_accy 63.20
2024-08-31 21:31:17,128 [foster.py] => SNet: Task 15, Epoch 32/130 => Loss 30.171,  Loss1 0.749, Train_accy 64.07
2024-08-31 21:31:24,580 [foster.py] => SNet: Task 15, Epoch 33/130 => Loss 30.195,  Loss1 0.749, Train_accy 63.57
2024-08-31 21:31:31,880 [foster.py] => SNet: Task 15, Epoch 34/130 => Loss 30.180,  Loss1 0.749, Train_accy 63.73
2024-08-31 21:31:39,444 [foster.py] => SNet: Task 15, Epoch 35/130 => Loss 30.169,  Loss1 0.749, Train_accy 63.93
2024-08-31 21:31:49,293 [foster.py] => SNet: Task 15, Epoch 36/130 => Loss 30.182,  Loss1 0.749, Train_accy 64.81, Test_accy 62.78
2024-08-31 21:31:56,730 [foster.py] => SNet: Task 15, Epoch 37/130 => Loss 30.179,  Loss1 0.749, Train_accy 64.63
2024-08-31 21:32:03,926 [foster.py] => SNet: Task 15, Epoch 38/130 => Loss 30.198,  Loss1 0.749, Train_accy 63.89
2024-08-31 21:32:11,326 [foster.py] => SNet: Task 15, Epoch 39/130 => Loss 30.149,  Loss1 0.749, Train_accy 64.65
2024-08-31 21:32:18,557 [foster.py] => SNet: Task 15, Epoch 40/130 => Loss 30.140,  Loss1 0.749, Train_accy 64.85
2024-08-31 21:32:27,951 [foster.py] => SNet: Task 15, Epoch 41/130 => Loss 30.165,  Loss1 0.749, Train_accy 64.92, Test_accy 61.04
2024-08-31 21:32:35,550 [foster.py] => SNet: Task 15, Epoch 42/130 => Loss 30.179,  Loss1 0.749, Train_accy 64.09
2024-08-31 21:32:42,647 [foster.py] => SNet: Task 15, Epoch 43/130 => Loss 30.175,  Loss1 0.749, Train_accy 64.65
2024-08-31 21:32:49,989 [foster.py] => SNet: Task 15, Epoch 44/130 => Loss 30.167,  Loss1 0.749, Train_accy 65.24
2024-08-31 21:32:57,385 [foster.py] => SNet: Task 15, Epoch 45/130 => Loss 30.156,  Loss1 0.749, Train_accy 64.58
2024-08-31 21:33:06,783 [foster.py] => SNet: Task 15, Epoch 46/130 => Loss 30.166,  Loss1 0.749, Train_accy 64.11, Test_accy 62.08
2024-08-31 21:33:14,102 [foster.py] => SNet: Task 15, Epoch 47/130 => Loss 30.186,  Loss1 0.749, Train_accy 65.33
2024-08-31 21:33:21,442 [foster.py] => SNet: Task 15, Epoch 48/130 => Loss 30.185,  Loss1 0.749, Train_accy 63.96
2024-08-31 21:33:28,773 [foster.py] => SNet: Task 15, Epoch 49/130 => Loss 30.173,  Loss1 0.749, Train_accy 65.08
2024-08-31 21:33:35,886 [foster.py] => SNet: Task 15, Epoch 50/130 => Loss 30.183,  Loss1 0.749, Train_accy 66.25
2024-08-31 21:33:45,667 [foster.py] => SNet: Task 15, Epoch 51/130 => Loss 30.189,  Loss1 0.749, Train_accy 66.20, Test_accy 62.72
2024-08-31 21:33:52,963 [foster.py] => SNet: Task 15, Epoch 52/130 => Loss 30.148,  Loss1 0.749, Train_accy 65.87
2024-08-31 21:34:00,319 [foster.py] => SNet: Task 15, Epoch 53/130 => Loss 30.165,  Loss1 0.749, Train_accy 66.00
2024-08-31 21:34:07,380 [foster.py] => SNet: Task 15, Epoch 54/130 => Loss 30.167,  Loss1 0.749, Train_accy 65.84
2024-08-31 21:34:14,790 [foster.py] => SNet: Task 15, Epoch 55/130 => Loss 30.170,  Loss1 0.749, Train_accy 66.02
2024-08-31 21:34:24,100 [foster.py] => SNet: Task 15, Epoch 56/130 => Loss 30.174,  Loss1 0.749, Train_accy 65.37, Test_accy 62.45
2024-08-31 21:34:31,381 [foster.py] => SNet: Task 15, Epoch 57/130 => Loss 30.171,  Loss1 0.749, Train_accy 66.09
2024-08-31 21:34:38,557 [foster.py] => SNet: Task 15, Epoch 58/130 => Loss 30.201,  Loss1 0.749, Train_accy 64.88
2024-08-31 21:34:45,787 [foster.py] => SNet: Task 15, Epoch 59/130 => Loss 30.181,  Loss1 0.749, Train_accy 65.60
2024-08-31 21:34:52,987 [foster.py] => SNet: Task 15, Epoch 60/130 => Loss 30.164,  Loss1 0.749, Train_accy 64.83
2024-08-31 21:35:02,763 [foster.py] => SNet: Task 15, Epoch 61/130 => Loss 30.152,  Loss1 0.749, Train_accy 66.02, Test_accy 62.51
2024-08-31 21:35:09,980 [foster.py] => SNet: Task 15, Epoch 62/130 => Loss 30.158,  Loss1 0.749, Train_accy 65.96
2024-08-31 21:35:17,066 [foster.py] => SNet: Task 15, Epoch 63/130 => Loss 30.145,  Loss1 0.749, Train_accy 65.37
2024-08-31 21:35:24,164 [foster.py] => SNet: Task 15, Epoch 64/130 => Loss 30.191,  Loss1 0.749, Train_accy 66.02
2024-08-31 21:35:31,865 [foster.py] => SNet: Task 15, Epoch 65/130 => Loss 30.162,  Loss1 0.749, Train_accy 65.96
2024-08-31 21:35:41,475 [foster.py] => SNet: Task 15, Epoch 66/130 => Loss 30.171,  Loss1 0.749, Train_accy 65.62, Test_accy 62.89
2024-08-31 21:35:48,800 [foster.py] => SNet: Task 15, Epoch 67/130 => Loss 30.156,  Loss1 0.749, Train_accy 66.56
2024-08-31 21:35:56,035 [foster.py] => SNet: Task 15, Epoch 68/130 => Loss 30.169,  Loss1 0.749, Train_accy 66.13
2024-08-31 21:36:03,321 [foster.py] => SNet: Task 15, Epoch 69/130 => Loss 30.162,  Loss1 0.749, Train_accy 66.25
2024-08-31 21:36:10,535 [foster.py] => SNet: Task 15, Epoch 70/130 => Loss 30.153,  Loss1 0.749, Train_accy 65.21
2024-08-31 21:36:20,329 [foster.py] => SNet: Task 15, Epoch 71/130 => Loss 30.172,  Loss1 0.749, Train_accy 65.28, Test_accy 62.71
2024-08-31 21:36:28,122 [foster.py] => SNet: Task 15, Epoch 72/130 => Loss 30.174,  Loss1 0.749, Train_accy 66.18
2024-08-31 21:36:35,270 [foster.py] => SNet: Task 15, Epoch 73/130 => Loss 30.160,  Loss1 0.749, Train_accy 66.00
2024-08-31 21:36:42,640 [foster.py] => SNet: Task 15, Epoch 74/130 => Loss 30.176,  Loss1 0.749, Train_accy 65.64
2024-08-31 21:36:49,697 [foster.py] => SNet: Task 15, Epoch 75/130 => Loss 30.145,  Loss1 0.749, Train_accy 66.04
2024-08-31 21:36:59,311 [foster.py] => SNet: Task 15, Epoch 76/130 => Loss 30.161,  Loss1 0.749, Train_accy 66.09, Test_accy 63.19
2024-08-31 21:37:06,850 [foster.py] => SNet: Task 15, Epoch 77/130 => Loss 30.155,  Loss1 0.749, Train_accy 66.18
2024-08-31 21:37:14,262 [foster.py] => SNet: Task 15, Epoch 78/130 => Loss 30.193,  Loss1 0.749, Train_accy 66.29
2024-08-31 21:37:21,611 [foster.py] => SNet: Task 15, Epoch 79/130 => Loss 30.176,  Loss1 0.749, Train_accy 65.62
2024-08-31 21:37:29,202 [foster.py] => SNet: Task 15, Epoch 80/130 => Loss 30.208,  Loss1 0.749, Train_accy 65.19
2024-08-31 21:37:38,939 [foster.py] => SNet: Task 15, Epoch 81/130 => Loss 30.171,  Loss1 0.749, Train_accy 65.71, Test_accy 63.28
2024-08-31 21:37:46,098 [foster.py] => SNet: Task 15, Epoch 82/130 => Loss 30.168,  Loss1 0.749, Train_accy 66.16
2024-08-31 21:37:53,253 [foster.py] => SNet: Task 15, Epoch 83/130 => Loss 30.148,  Loss1 0.749, Train_accy 66.88
2024-08-31 21:38:00,596 [foster.py] => SNet: Task 15, Epoch 84/130 => Loss 30.171,  Loss1 0.749, Train_accy 66.63
2024-08-31 21:38:07,708 [foster.py] => SNet: Task 15, Epoch 85/130 => Loss 30.146,  Loss1 0.749, Train_accy 66.09
2024-08-31 21:38:17,119 [foster.py] => SNet: Task 15, Epoch 86/130 => Loss 30.136,  Loss1 0.749, Train_accy 65.80, Test_accy 62.99
2024-08-31 21:38:24,146 [foster.py] => SNet: Task 15, Epoch 87/130 => Loss 30.180,  Loss1 0.749, Train_accy 66.22
2024-08-31 21:38:31,535 [foster.py] => SNet: Task 15, Epoch 88/130 => Loss 30.183,  Loss1 0.749, Train_accy 65.37
2024-08-31 21:38:38,968 [foster.py] => SNet: Task 15, Epoch 89/130 => Loss 30.139,  Loss1 0.749, Train_accy 66.92
2024-08-31 21:38:46,589 [foster.py] => SNet: Task 15, Epoch 90/130 => Loss 30.150,  Loss1 0.749, Train_accy 65.98
2024-08-31 21:38:55,927 [foster.py] => SNet: Task 15, Epoch 91/130 => Loss 30.183,  Loss1 0.749, Train_accy 66.74, Test_accy 63.14
2024-08-31 21:39:03,752 [foster.py] => SNet: Task 15, Epoch 92/130 => Loss 30.168,  Loss1 0.749, Train_accy 66.49
2024-08-31 21:39:11,289 [foster.py] => SNet: Task 15, Epoch 93/130 => Loss 30.160,  Loss1 0.749, Train_accy 66.83
2024-08-31 21:39:18,483 [foster.py] => SNet: Task 15, Epoch 94/130 => Loss 30.166,  Loss1 0.749, Train_accy 65.89
2024-08-31 21:39:25,585 [foster.py] => SNet: Task 15, Epoch 95/130 => Loss 30.169,  Loss1 0.749, Train_accy 65.93
2024-08-31 21:39:35,076 [foster.py] => SNet: Task 15, Epoch 96/130 => Loss 30.148,  Loss1 0.749, Train_accy 66.09, Test_accy 63.28
2024-08-31 21:39:42,285 [foster.py] => SNet: Task 15, Epoch 97/130 => Loss 30.180,  Loss1 0.749, Train_accy 66.79
2024-08-31 21:39:49,379 [foster.py] => SNet: Task 15, Epoch 98/130 => Loss 30.174,  Loss1 0.749, Train_accy 67.60
2024-08-31 21:39:56,541 [foster.py] => SNet: Task 15, Epoch 99/130 => Loss 30.178,  Loss1 0.749, Train_accy 66.72
2024-08-31 21:40:03,944 [foster.py] => SNet: Task 15, Epoch 100/130 => Loss 30.145,  Loss1 0.749, Train_accy 67.33
2024-08-31 21:40:13,586 [foster.py] => SNet: Task 15, Epoch 101/130 => Loss 30.155,  Loss1 0.749, Train_accy 66.43, Test_accy 63.24
2024-08-31 21:40:20,700 [foster.py] => SNet: Task 15, Epoch 102/130 => Loss 30.146,  Loss1 0.749, Train_accy 66.72
2024-08-31 21:40:28,214 [foster.py] => SNet: Task 15, Epoch 103/130 => Loss 30.165,  Loss1 0.749, Train_accy 66.90
2024-08-31 21:40:35,740 [foster.py] => SNet: Task 15, Epoch 104/130 => Loss 30.152,  Loss1 0.749, Train_accy 66.99
2024-08-31 21:40:42,935 [foster.py] => SNet: Task 15, Epoch 105/130 => Loss 30.182,  Loss1 0.749, Train_accy 65.84
2024-08-31 21:40:52,433 [foster.py] => SNet: Task 15, Epoch 106/130 => Loss 30.155,  Loss1 0.749, Train_accy 66.72, Test_accy 63.05
2024-08-31 21:40:59,818 [foster.py] => SNet: Task 15, Epoch 107/130 => Loss 30.146,  Loss1 0.749, Train_accy 66.70
2024-08-31 21:41:06,940 [foster.py] => SNet: Task 15, Epoch 108/130 => Loss 30.178,  Loss1 0.749, Train_accy 66.02
2024-08-31 21:41:14,248 [foster.py] => SNet: Task 15, Epoch 109/130 => Loss 30.163,  Loss1 0.749, Train_accy 67.35
2024-08-31 21:41:21,535 [foster.py] => SNet: Task 15, Epoch 110/130 => Loss 30.150,  Loss1 0.749, Train_accy 67.10
2024-08-31 21:41:31,164 [foster.py] => SNet: Task 15, Epoch 111/130 => Loss 30.171,  Loss1 0.749, Train_accy 67.12, Test_accy 63.20
2024-08-31 21:41:38,562 [foster.py] => SNet: Task 15, Epoch 112/130 => Loss 30.178,  Loss1 0.749, Train_accy 66.43
2024-08-31 21:41:45,651 [foster.py] => SNet: Task 15, Epoch 113/130 => Loss 30.159,  Loss1 0.749, Train_accy 66.18
2024-08-31 21:41:52,961 [foster.py] => SNet: Task 15, Epoch 114/130 => Loss 30.180,  Loss1 0.749, Train_accy 66.11
2024-08-31 21:42:00,141 [foster.py] => SNet: Task 15, Epoch 115/130 => Loss 30.162,  Loss1 0.749, Train_accy 67.01
2024-08-31 21:42:10,111 [foster.py] => SNet: Task 15, Epoch 116/130 => Loss 30.169,  Loss1 0.749, Train_accy 65.66, Test_accy 63.30
2024-08-31 21:42:18,042 [foster.py] => SNet: Task 15, Epoch 117/130 => Loss 30.171,  Loss1 0.749, Train_accy 66.49
2024-08-31 21:42:25,573 [foster.py] => SNet: Task 15, Epoch 118/130 => Loss 30.182,  Loss1 0.749, Train_accy 65.37
2024-08-31 21:42:32,655 [foster.py] => SNet: Task 15, Epoch 119/130 => Loss 30.169,  Loss1 0.749, Train_accy 67.66
2024-08-31 21:42:39,886 [foster.py] => SNet: Task 15, Epoch 120/130 => Loss 30.133,  Loss1 0.749, Train_accy 67.17
2024-08-31 21:42:49,362 [foster.py] => SNet: Task 15, Epoch 121/130 => Loss 30.167,  Loss1 0.749, Train_accy 65.93, Test_accy 63.15
2024-08-31 21:42:56,679 [foster.py] => SNet: Task 15, Epoch 122/130 => Loss 30.147,  Loss1 0.749, Train_accy 67.48
2024-08-31 21:43:04,154 [foster.py] => SNet: Task 15, Epoch 123/130 => Loss 30.141,  Loss1 0.749, Train_accy 66.85
2024-08-31 21:43:11,648 [foster.py] => SNet: Task 15, Epoch 124/130 => Loss 30.176,  Loss1 0.749, Train_accy 66.58
2024-08-31 21:43:18,814 [foster.py] => SNet: Task 15, Epoch 125/130 => Loss 30.174,  Loss1 0.749, Train_accy 66.34
2024-08-31 21:43:28,311 [foster.py] => SNet: Task 15, Epoch 126/130 => Loss 30.166,  Loss1 0.749, Train_accy 66.38, Test_accy 63.30
2024-08-31 21:43:35,637 [foster.py] => SNet: Task 15, Epoch 127/130 => Loss 30.172,  Loss1 0.749, Train_accy 66.63
2024-08-31 21:43:43,157 [foster.py] => SNet: Task 15, Epoch 128/130 => Loss 30.168,  Loss1 0.749, Train_accy 66.97
2024-08-31 21:43:50,375 [foster.py] => SNet: Task 15, Epoch 129/130 => Loss 30.153,  Loss1 0.749, Train_accy 66.40
2024-08-31 21:43:57,461 [foster.py] => SNet: Task 15, Epoch 130/130 => Loss 30.140,  Loss1 0.749, Train_accy 67.48
2024-08-31 21:43:57,461 [foster.py] => do not weight align student!
2024-08-31 21:43:59,725 [foster.py] => darknet eval: 
2024-08-31 21:43:59,725 [foster.py] => CNN top1 curve: 63.3
2024-08-31 21:43:59,726 [foster.py] => CNN top5 curve: 88.45
2024-08-31 21:43:59,726 [foster.py] => CNN top1 平均值: 63.30
2024-08-31 21:43:59,731 [foster.py] => timees : 2263.312049150467
2024-08-31 21:43:59,732 [base.py] => Reducing exemplars...(25 per classes)
2024-08-31 21:44:25,840 [base.py] => Constructing exemplars...(25 per classes)
2024-08-31 21:44:36,347 [foster.py] => Exemplar size: 2000
2024-08-31 21:44:36,347 [trainer.py] => CNN: {'total': 63.39, '00-09': 62.5, '10-19': 46.8, '20-29': 66.9, '30-39': 59.7, '40-49': 70.5, '50-59': 59.4, '60-69': 74.8, '70-79': 66.5, 'old': 63.13, 'new': 67.2}
2024-08-31 21:44:36,348 [trainer.py] => NME: {'total': 56.89, '00-09': 53.8, '10-19': 40.1, '20-29': 60.1, '30-39': 52.2, '40-49': 62.7, '50-59': 53.9, '60-69': 66.6, '70-79': 65.7, 'old': 55.31, 'new': 80.6}
2024-08-31 21:44:36,348 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85, 63.39]
2024-08-31 21:44:36,348 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96, 88.72]
2024-08-31 21:44:36,349 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17, 56.89]
2024-08-31 21:44:36,351 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84, 84.65]

2024-08-31 21:44:36,351 [trainer.py] => CNN top1 平均值: 76.86
2024-08-31 21:44:36,354 [trainer.py] => All params: 1302943
2024-08-31 21:44:36,356 [trainer.py] => Trainable params: 656794
2024-08-31 21:44:36,422 [foster.py] => Learning on 80-85
2024-08-31 21:44:36,425 [foster.py] => All params: 1304238
2024-08-31 21:44:36,427 [foster.py] => Trainable params: 657764
2024-08-31 21:44:36,479 [foster.py] => per cls weights : [1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084 1.01869084
 1.01869084 1.01869084 0.70094659 0.70094659 0.70094659 0.70094659
 0.70094659]
2024-08-31 21:44:41,899 [foster.py] => Task 16, Epoch 1/170 => Loss 9.969, Loss_clf 5.027, Loss_fe 1.802, Loss_kd 2.947, Train_accy 51.20
2024-08-31 21:44:49,956 [foster.py] => Task 16, Epoch 2/170 => Loss 5.925, Loss_clf 1.335, Loss_fe 1.493, Loss_kd 2.907, Train_accy 67.22, Test_accy 53.42
2024-08-31 21:44:58,007 [foster.py] => Task 16, Epoch 3/170 => Loss 5.600, Loss_clf 1.233, Loss_fe 1.277, Loss_kd 2.901, Train_accy 67.64, Test_accy 59.45
2024-08-31 21:45:06,125 [foster.py] => Task 16, Epoch 4/170 => Loss 5.303, Loss_clf 1.047, Loss_fe 1.153, Loss_kd 2.913, Train_accy 68.38, Test_accy 59.81
2024-08-31 21:45:14,215 [foster.py] => Task 16, Epoch 5/170 => Loss 5.240, Loss_clf 1.088, Loss_fe 1.071, Loss_kd 2.892, Train_accy 67.36, Test_accy 60.46
2024-08-31 21:45:19,674 [foster.py] => Task 16, Epoch 6/170 => Loss 5.188, Loss_clf 1.029, Loss_fe 1.063, Loss_kd 2.907, Train_accy 69.09
2024-08-31 21:45:27,725 [foster.py] => Task 16, Epoch 7/170 => Loss 4.977, Loss_clf 0.912, Loss_fe 0.983, Loss_kd 2.894, Train_accy 70.07, Test_accy 58.92
2024-08-31 21:45:35,858 [foster.py] => Task 16, Epoch 8/170 => Loss 4.993, Loss_clf 0.964, Loss_fe 0.917, Loss_kd 2.922, Train_accy 68.87, Test_accy 60.00
2024-08-31 21:45:43,970 [foster.py] => Task 16, Epoch 9/170 => Loss 4.969, Loss_clf 0.915, Loss_fe 0.973, Loss_kd 2.893, Train_accy 70.33, Test_accy 58.55
2024-08-31 21:45:52,039 [foster.py] => Task 16, Epoch 10/170 => Loss 4.993, Loss_clf 1.001, Loss_fe 0.915, Loss_kd 2.890, Train_accy 68.73, Test_accy 58.65
2024-08-31 21:45:57,432 [foster.py] => Task 16, Epoch 11/170 => Loss 5.024, Loss_clf 1.003, Loss_fe 0.921, Loss_kd 2.910, Train_accy 68.51
2024-08-31 21:46:05,565 [foster.py] => Task 16, Epoch 12/170 => Loss 4.955, Loss_clf 0.963, Loss_fe 0.890, Loss_kd 2.914, Train_accy 69.09, Test_accy 59.34
2024-08-31 21:46:13,580 [foster.py] => Task 16, Epoch 13/170 => Loss 5.002, Loss_clf 0.959, Loss_fe 0.936, Loss_kd 2.918, Train_accy 69.60, Test_accy 60.28
2024-08-31 21:46:21,681 [foster.py] => Task 16, Epoch 14/170 => Loss 5.002, Loss_clf 1.003, Loss_fe 0.899, Loss_kd 2.912, Train_accy 67.09, Test_accy 56.32
2024-08-31 21:46:29,703 [foster.py] => Task 16, Epoch 15/170 => Loss 4.899, Loss_clf 0.919, Loss_fe 0.888, Loss_kd 2.904, Train_accy 69.16, Test_accy 60.00
2024-08-31 21:46:35,124 [foster.py] => Task 16, Epoch 16/170 => Loss 5.025, Loss_clf 1.044, Loss_fe 0.868, Loss_kd 2.923, Train_accy 68.02
2024-08-31 21:46:43,315 [foster.py] => Task 16, Epoch 17/170 => Loss 5.001, Loss_clf 0.998, Loss_fe 0.919, Loss_kd 2.897, Train_accy 68.40, Test_accy 60.04
2024-08-31 21:46:51,346 [foster.py] => Task 16, Epoch 18/170 => Loss 4.959, Loss_clf 1.034, Loss_fe 0.850, Loss_kd 2.888, Train_accy 68.71, Test_accy 58.45
2024-08-31 21:46:59,462 [foster.py] => Task 16, Epoch 19/170 => Loss 5.041, Loss_clf 1.026, Loss_fe 0.921, Loss_kd 2.907, Train_accy 69.31, Test_accy 60.58
2024-08-31 21:47:07,557 [foster.py] => Task 16, Epoch 20/170 => Loss 4.864, Loss_clf 0.893, Loss_fe 0.884, Loss_kd 2.900, Train_accy 68.51, Test_accy 58.21
2024-08-31 21:47:12,963 [foster.py] => Task 16, Epoch 21/170 => Loss 5.035, Loss_clf 1.028, Loss_fe 0.924, Loss_kd 2.896, Train_accy 67.44
2024-08-31 21:47:21,046 [foster.py] => Task 16, Epoch 22/170 => Loss 5.031, Loss_clf 1.011, Loss_fe 0.925, Loss_kd 2.908, Train_accy 68.51, Test_accy 59.76
2024-08-31 21:47:29,113 [foster.py] => Task 16, Epoch 23/170 => Loss 4.913, Loss_clf 0.947, Loss_fe 0.878, Loss_kd 2.900, Train_accy 70.27, Test_accy 61.01
2024-08-31 21:47:37,210 [foster.py] => Task 16, Epoch 24/170 => Loss 4.924, Loss_clf 0.924, Loss_fe 0.896, Loss_kd 2.916, Train_accy 68.91, Test_accy 59.01
2024-08-31 21:47:45,312 [foster.py] => Task 16, Epoch 25/170 => Loss 4.871, Loss_clf 0.924, Loss_fe 0.845, Loss_kd 2.913, Train_accy 69.16, Test_accy 58.64
2024-08-31 21:47:50,783 [foster.py] => Task 16, Epoch 26/170 => Loss 4.880, Loss_clf 0.921, Loss_fe 0.871, Loss_kd 2.900, Train_accy 68.67
2024-08-31 21:47:58,823 [foster.py] => Task 16, Epoch 27/170 => Loss 4.997, Loss_clf 1.038, Loss_fe 0.863, Loss_kd 2.908, Train_accy 67.49, Test_accy 55.99
2024-08-31 21:48:06,961 [foster.py] => Task 16, Epoch 28/170 => Loss 5.008, Loss_clf 1.007, Loss_fe 0.907, Loss_kd 2.907, Train_accy 68.58, Test_accy 59.68
2024-08-31 21:48:15,131 [foster.py] => Task 16, Epoch 29/170 => Loss 4.931, Loss_clf 0.947, Loss_fe 0.890, Loss_kd 2.906, Train_accy 68.58, Test_accy 59.04
2024-08-31 21:48:23,223 [foster.py] => Task 16, Epoch 30/170 => Loss 4.932, Loss_clf 0.988, Loss_fe 0.866, Loss_kd 2.892, Train_accy 68.42, Test_accy 58.06
2024-08-31 21:48:28,603 [foster.py] => Task 16, Epoch 31/170 => Loss 5.015, Loss_clf 1.023, Loss_fe 0.890, Loss_kd 2.913, Train_accy 67.67
2024-08-31 21:48:36,678 [foster.py] => Task 16, Epoch 32/170 => Loss 4.933, Loss_clf 0.934, Loss_fe 0.896, Loss_kd 2.916, Train_accy 67.51, Test_accy 58.98
2024-08-31 21:48:44,750 [foster.py] => Task 16, Epoch 33/170 => Loss 4.792, Loss_clf 0.878, Loss_fe 0.819, Loss_kd 2.907, Train_accy 71.20, Test_accy 56.45
2024-08-31 21:48:52,875 [foster.py] => Task 16, Epoch 34/170 => Loss 4.867, Loss_clf 0.925, Loss_fe 0.863, Loss_kd 2.892, Train_accy 68.78, Test_accy 60.84
2024-08-31 21:49:00,992 [foster.py] => Task 16, Epoch 35/170 => Loss 4.858, Loss_clf 0.904, Loss_fe 0.865, Loss_kd 2.902, Train_accy 68.20, Test_accy 58.01
2024-08-31 21:49:06,452 [foster.py] => Task 16, Epoch 36/170 => Loss 4.879, Loss_clf 0.876, Loss_fe 0.905, Loss_kd 2.910, Train_accy 69.78
2024-08-31 21:49:14,547 [foster.py] => Task 16, Epoch 37/170 => Loss 4.911, Loss_clf 0.959, Loss_fe 0.851, Loss_kd 2.914, Train_accy 68.49, Test_accy 60.88
2024-08-31 21:49:22,625 [foster.py] => Task 16, Epoch 38/170 => Loss 4.846, Loss_clf 0.900, Loss_fe 0.840, Loss_kd 2.918, Train_accy 67.89, Test_accy 58.71
2024-08-31 21:49:30,661 [foster.py] => Task 16, Epoch 39/170 => Loss 4.929, Loss_clf 0.966, Loss_fe 0.873, Loss_kd 2.902, Train_accy 69.13, Test_accy 57.94
2024-08-31 21:49:38,710 [foster.py] => Task 16, Epoch 40/170 => Loss 4.889, Loss_clf 0.952, Loss_fe 0.854, Loss_kd 2.896, Train_accy 68.93, Test_accy 59.81
2024-08-31 21:49:44,072 [foster.py] => Task 16, Epoch 41/170 => Loss 4.925, Loss_clf 0.950, Loss_fe 0.888, Loss_kd 2.900, Train_accy 69.71
2024-08-31 21:49:52,151 [foster.py] => Task 16, Epoch 42/170 => Loss 4.944, Loss_clf 1.016, Loss_fe 0.837, Loss_kd 2.904, Train_accy 68.27, Test_accy 59.26
2024-08-31 21:50:00,344 [foster.py] => Task 16, Epoch 43/170 => Loss 4.914, Loss_clf 0.934, Loss_fe 0.884, Loss_kd 2.909, Train_accy 68.18, Test_accy 59.29
2024-08-31 21:50:08,410 [foster.py] => Task 16, Epoch 44/170 => Loss 4.838, Loss_clf 0.913, Loss_fe 0.844, Loss_kd 2.895, Train_accy 70.00, Test_accy 59.15
2024-08-31 21:50:16,554 [foster.py] => Task 16, Epoch 45/170 => Loss 4.975, Loss_clf 1.012, Loss_fe 0.855, Loss_kd 2.920, Train_accy 66.82, Test_accy 58.48
2024-08-31 21:50:21,962 [foster.py] => Task 16, Epoch 46/170 => Loss 4.884, Loss_clf 0.933, Loss_fe 0.860, Loss_kd 2.905, Train_accy 69.64
2024-08-31 21:50:30,024 [foster.py] => Task 16, Epoch 47/170 => Loss 4.820, Loss_clf 0.885, Loss_fe 0.832, Loss_kd 2.915, Train_accy 68.87, Test_accy 60.04
2024-08-31 21:50:38,185 [foster.py] => Task 16, Epoch 48/170 => Loss 4.866, Loss_clf 0.941, Loss_fe 0.834, Loss_kd 2.904, Train_accy 70.20, Test_accy 60.18
2024-08-31 21:50:46,246 [foster.py] => Task 16, Epoch 49/170 => Loss 5.022, Loss_clf 0.996, Loss_fe 0.905, Loss_kd 2.932, Train_accy 68.29, Test_accy 59.00
2024-08-31 21:50:54,339 [foster.py] => Task 16, Epoch 50/170 => Loss 4.866, Loss_clf 0.958, Loss_fe 0.814, Loss_kd 2.907, Train_accy 68.02, Test_accy 58.46
2024-08-31 21:50:59,708 [foster.py] => Task 16, Epoch 51/170 => Loss 4.766, Loss_clf 0.884, Loss_fe 0.801, Loss_kd 2.894, Train_accy 71.02
2024-08-31 21:51:07,804 [foster.py] => Task 16, Epoch 52/170 => Loss 4.877, Loss_clf 0.948, Loss_fe 0.836, Loss_kd 2.905, Train_accy 68.58, Test_accy 59.98
2024-08-31 21:51:15,914 [foster.py] => Task 16, Epoch 53/170 => Loss 4.770, Loss_clf 0.872, Loss_fe 0.812, Loss_kd 2.899, Train_accy 70.02, Test_accy 58.55
2024-08-31 21:51:23,975 [foster.py] => Task 16, Epoch 54/170 => Loss 4.772, Loss_clf 0.878, Loss_fe 0.799, Loss_kd 2.908, Train_accy 69.38, Test_accy 58.96
2024-08-31 21:51:32,012 [foster.py] => Task 16, Epoch 55/170 => Loss 4.845, Loss_clf 0.928, Loss_fe 0.827, Loss_kd 2.903, Train_accy 69.00, Test_accy 59.80
2024-08-31 21:51:37,462 [foster.py] => Task 16, Epoch 56/170 => Loss 4.837, Loss_clf 0.915, Loss_fe 0.843, Loss_kd 2.893, Train_accy 68.40
2024-08-31 21:51:45,509 [foster.py] => Task 16, Epoch 57/170 => Loss 4.814, Loss_clf 0.898, Loss_fe 0.822, Loss_kd 2.906, Train_accy 68.51, Test_accy 60.38
2024-08-31 21:51:53,559 [foster.py] => Task 16, Epoch 58/170 => Loss 4.862, Loss_clf 0.971, Loss_fe 0.801, Loss_kd 2.903, Train_accy 68.93, Test_accy 60.58
2024-08-31 21:52:01,683 [foster.py] => Task 16, Epoch 59/170 => Loss 4.776, Loss_clf 0.894, Loss_fe 0.796, Loss_kd 2.900, Train_accy 69.60, Test_accy 60.27
2024-08-31 21:52:09,920 [foster.py] => Task 16, Epoch 60/170 => Loss 4.700, Loss_clf 0.837, Loss_fe 0.773, Loss_kd 2.903, Train_accy 70.29, Test_accy 59.25
2024-08-31 21:52:15,312 [foster.py] => Task 16, Epoch 61/170 => Loss 4.751, Loss_clf 0.868, Loss_fe 0.795, Loss_kd 2.901, Train_accy 70.38
2024-08-31 21:52:23,398 [foster.py] => Task 16, Epoch 62/170 => Loss 4.727, Loss_clf 0.861, Loss_fe 0.787, Loss_kd 2.892, Train_accy 70.58, Test_accy 59.78
2024-08-31 21:52:31,459 [foster.py] => Task 16, Epoch 63/170 => Loss 4.743, Loss_clf 0.875, Loss_fe 0.791, Loss_kd 2.890, Train_accy 70.02, Test_accy 60.48
2024-08-31 21:52:39,499 [foster.py] => Task 16, Epoch 64/170 => Loss 4.729, Loss_clf 0.870, Loss_fe 0.772, Loss_kd 2.900, Train_accy 70.49, Test_accy 60.71
2024-08-31 21:52:47,625 [foster.py] => Task 16, Epoch 65/170 => Loss 4.720, Loss_clf 0.848, Loss_fe 0.787, Loss_kd 2.898, Train_accy 70.80, Test_accy 57.96
2024-08-31 21:52:53,063 [foster.py] => Task 16, Epoch 66/170 => Loss 4.738, Loss_clf 0.875, Loss_fe 0.785, Loss_kd 2.892, Train_accy 68.91
2024-08-31 21:53:01,073 [foster.py] => Task 16, Epoch 67/170 => Loss 4.689, Loss_clf 0.842, Loss_fe 0.766, Loss_kd 2.894, Train_accy 70.29, Test_accy 60.94
2024-08-31 21:53:09,087 [foster.py] => Task 16, Epoch 68/170 => Loss 4.766, Loss_clf 0.897, Loss_fe 0.787, Loss_kd 2.895, Train_accy 70.51, Test_accy 59.74
2024-08-31 21:53:17,130 [foster.py] => Task 16, Epoch 69/170 => Loss 4.820, Loss_clf 0.945, Loss_fe 0.780, Loss_kd 2.907, Train_accy 68.73, Test_accy 59.49
2024-08-31 21:53:25,202 [foster.py] => Task 16, Epoch 70/170 => Loss 4.759, Loss_clf 0.867, Loss_fe 0.805, Loss_kd 2.900, Train_accy 70.44, Test_accy 60.66
2024-08-31 21:53:30,603 [foster.py] => Task 16, Epoch 71/170 => Loss 4.724, Loss_clf 0.858, Loss_fe 0.778, Loss_kd 2.900, Train_accy 70.62
2024-08-31 21:53:38,629 [foster.py] => Task 16, Epoch 72/170 => Loss 4.763, Loss_clf 0.905, Loss_fe 0.757, Loss_kd 2.914, Train_accy 69.89, Test_accy 60.95
2024-08-31 21:53:46,680 [foster.py] => Task 16, Epoch 73/170 => Loss 4.747, Loss_clf 0.868, Loss_fe 0.788, Loss_kd 2.905, Train_accy 69.80, Test_accy 59.42
2024-08-31 21:53:54,755 [foster.py] => Task 16, Epoch 74/170 => Loss 4.786, Loss_clf 0.901, Loss_fe 0.801, Loss_kd 2.898, Train_accy 69.16, Test_accy 60.24
2024-08-31 21:54:02,929 [foster.py] => Task 16, Epoch 75/170 => Loss 4.649, Loss_clf 0.824, Loss_fe 0.736, Loss_kd 2.902, Train_accy 71.29, Test_accy 61.36
2024-08-31 21:54:08,304 [foster.py] => Task 16, Epoch 76/170 => Loss 4.623, Loss_clf 0.813, Loss_fe 0.724, Loss_kd 2.899, Train_accy 71.11
2024-08-31 21:54:16,348 [foster.py] => Task 16, Epoch 77/170 => Loss 4.689, Loss_clf 0.848, Loss_fe 0.760, Loss_kd 2.894, Train_accy 69.40, Test_accy 59.87
2024-08-31 21:54:24,468 [foster.py] => Task 16, Epoch 78/170 => Loss 4.668, Loss_clf 0.849, Loss_fe 0.739, Loss_kd 2.893, Train_accy 70.64, Test_accy 60.21
2024-08-31 21:54:32,554 [foster.py] => Task 16, Epoch 79/170 => Loss 4.703, Loss_clf 0.848, Loss_fe 0.758, Loss_kd 2.910, Train_accy 70.24, Test_accy 59.98
2024-08-31 21:54:40,622 [foster.py] => Task 16, Epoch 80/170 => Loss 4.701, Loss_clf 0.869, Loss_fe 0.738, Loss_kd 2.907, Train_accy 70.98, Test_accy 60.86
2024-08-31 21:54:46,104 [foster.py] => Task 16, Epoch 81/170 => Loss 4.743, Loss_clf 0.870, Loss_fe 0.762, Loss_kd 2.923, Train_accy 70.07
2024-08-31 21:54:54,175 [foster.py] => Task 16, Epoch 82/170 => Loss 4.676, Loss_clf 0.839, Loss_fe 0.749, Loss_kd 2.900, Train_accy 71.33, Test_accy 61.11
2024-08-31 21:55:02,336 [foster.py] => Task 16, Epoch 83/170 => Loss 4.652, Loss_clf 0.822, Loss_fe 0.728, Loss_kd 2.915, Train_accy 71.42, Test_accy 60.65
2024-08-31 21:55:10,477 [foster.py] => Task 16, Epoch 84/170 => Loss 4.631, Loss_clf 0.815, Loss_fe 0.734, Loss_kd 2.896, Train_accy 70.69, Test_accy 60.80
2024-08-31 21:55:18,616 [foster.py] => Task 16, Epoch 85/170 => Loss 4.608, Loss_clf 0.817, Loss_fe 0.717, Loss_kd 2.889, Train_accy 70.96, Test_accy 59.74
2024-08-31 21:55:24,013 [foster.py] => Task 16, Epoch 86/170 => Loss 4.588, Loss_clf 0.793, Loss_fe 0.711, Loss_kd 2.898, Train_accy 71.84
2024-08-31 21:55:32,120 [foster.py] => Task 16, Epoch 87/170 => Loss 4.651, Loss_clf 0.839, Loss_fe 0.726, Loss_kd 2.900, Train_accy 71.24, Test_accy 59.82
2024-08-31 21:55:40,235 [foster.py] => Task 16, Epoch 88/170 => Loss 4.635, Loss_clf 0.823, Loss_fe 0.721, Loss_kd 2.905, Train_accy 70.36, Test_accy 60.86
2024-08-31 21:55:48,298 [foster.py] => Task 16, Epoch 89/170 => Loss 4.578, Loss_clf 0.796, Loss_fe 0.700, Loss_kd 2.896, Train_accy 72.07, Test_accy 60.81
2024-08-31 21:55:56,311 [foster.py] => Task 16, Epoch 90/170 => Loss 4.599, Loss_clf 0.822, Loss_fe 0.689, Loss_kd 2.902, Train_accy 71.20, Test_accy 59.82
2024-08-31 21:56:01,748 [foster.py] => Task 16, Epoch 91/170 => Loss 4.630, Loss_clf 0.834, Loss_fe 0.706, Loss_kd 2.903, Train_accy 72.18
2024-08-31 21:56:09,888 [foster.py] => Task 16, Epoch 92/170 => Loss 4.574, Loss_clf 0.791, Loss_fe 0.702, Loss_kd 2.894, Train_accy 72.56, Test_accy 61.55
2024-08-31 21:56:18,054 [foster.py] => Task 16, Epoch 93/170 => Loss 4.546, Loss_clf 0.788, Loss_fe 0.680, Loss_kd 2.892, Train_accy 72.60, Test_accy 60.68
2024-08-31 21:56:26,123 [foster.py] => Task 16, Epoch 94/170 => Loss 4.495, Loss_clf 0.744, Loss_fe 0.673, Loss_kd 2.891, Train_accy 73.51, Test_accy 61.14
2024-08-31 21:56:34,198 [foster.py] => Task 16, Epoch 95/170 => Loss 4.501, Loss_clf 0.772, Loss_fe 0.645, Loss_kd 2.897, Train_accy 71.47, Test_accy 60.92
2024-08-31 21:56:39,579 [foster.py] => Task 16, Epoch 96/170 => Loss 4.534, Loss_clf 0.803, Loss_fe 0.662, Loss_kd 2.884, Train_accy 71.53
2024-08-31 21:56:47,721 [foster.py] => Task 16, Epoch 97/170 => Loss 4.657, Loss_clf 0.837, Loss_fe 0.742, Loss_kd 2.892, Train_accy 69.96, Test_accy 61.41
2024-08-31 21:56:55,757 [foster.py] => Task 16, Epoch 98/170 => Loss 4.596, Loss_clf 0.832, Loss_fe 0.680, Loss_kd 2.897, Train_accy 71.20, Test_accy 60.95
2024-08-31 21:57:03,836 [foster.py] => Task 16, Epoch 99/170 => Loss 4.501, Loss_clf 0.777, Loss_fe 0.643, Loss_kd 2.894, Train_accy 71.91, Test_accy 60.94
2024-08-31 21:57:12,000 [foster.py] => Task 16, Epoch 100/170 => Loss 4.500, Loss_clf 0.768, Loss_fe 0.648, Loss_kd 2.898, Train_accy 73.36, Test_accy 61.56
2024-08-31 21:57:17,417 [foster.py] => Task 16, Epoch 101/170 => Loss 4.514, Loss_clf 0.768, Loss_fe 0.652, Loss_kd 2.907, Train_accy 72.62
2024-08-31 21:57:25,518 [foster.py] => Task 16, Epoch 102/170 => Loss 4.469, Loss_clf 0.756, Loss_fe 0.642, Loss_kd 2.885, Train_accy 72.53, Test_accy 60.85
2024-08-31 21:57:33,648 [foster.py] => Task 16, Epoch 103/170 => Loss 4.482, Loss_clf 0.757, Loss_fe 0.655, Loss_kd 2.884, Train_accy 73.13, Test_accy 61.60
2024-08-31 21:57:41,720 [foster.py] => Task 16, Epoch 104/170 => Loss 4.524, Loss_clf 0.775, Loss_fe 0.666, Loss_kd 2.896, Train_accy 72.78, Test_accy 61.31
2024-08-31 21:57:49,807 [foster.py] => Task 16, Epoch 105/170 => Loss 4.463, Loss_clf 0.756, Loss_fe 0.630, Loss_kd 2.891, Train_accy 73.18, Test_accy 61.48
2024-08-31 21:57:55,312 [foster.py] => Task 16, Epoch 106/170 => Loss 4.540, Loss_clf 0.811, Loss_fe 0.648, Loss_kd 2.895, Train_accy 72.78
2024-08-31 21:58:03,372 [foster.py] => Task 16, Epoch 107/170 => Loss 4.493, Loss_clf 0.783, Loss_fe 0.636, Loss_kd 2.889, Train_accy 72.31, Test_accy 61.12
2024-08-31 21:58:11,473 [foster.py] => Task 16, Epoch 108/170 => Loss 4.502, Loss_clf 0.785, Loss_fe 0.629, Loss_kd 2.902, Train_accy 73.09, Test_accy 60.79
2024-08-31 21:58:19,507 [foster.py] => Task 16, Epoch 109/170 => Loss 4.487, Loss_clf 0.773, Loss_fe 0.632, Loss_kd 2.895, Train_accy 73.24, Test_accy 60.51
2024-08-31 21:58:27,598 [foster.py] => Task 16, Epoch 110/170 => Loss 4.410, Loss_clf 0.740, Loss_fe 0.599, Loss_kd 2.885, Train_accy 75.22, Test_accy 61.87
2024-08-31 21:58:33,028 [foster.py] => Task 16, Epoch 111/170 => Loss 4.412, Loss_clf 0.724, Loss_fe 0.612, Loss_kd 2.890, Train_accy 74.07
2024-08-31 21:58:41,088 [foster.py] => Task 16, Epoch 112/170 => Loss 4.346, Loss_clf 0.705, Loss_fe 0.572, Loss_kd 2.884, Train_accy 74.73, Test_accy 61.60
2024-08-31 21:58:49,157 [foster.py] => Task 16, Epoch 113/170 => Loss 4.414, Loss_clf 0.737, Loss_fe 0.600, Loss_kd 2.891, Train_accy 75.31, Test_accy 61.86
2024-08-31 21:58:57,359 [foster.py] => Task 16, Epoch 114/170 => Loss 4.431, Loss_clf 0.746, Loss_fe 0.594, Loss_kd 2.904, Train_accy 74.20, Test_accy 61.73
2024-08-31 21:59:05,422 [foster.py] => Task 16, Epoch 115/170 => Loss 4.437, Loss_clf 0.735, Loss_fe 0.613, Loss_kd 2.902, Train_accy 73.96, Test_accy 61.98
2024-08-31 21:59:10,838 [foster.py] => Task 16, Epoch 116/170 => Loss 4.397, Loss_clf 0.731, Loss_fe 0.577, Loss_kd 2.903, Train_accy 74.13
2024-08-31 21:59:18,878 [foster.py] => Task 16, Epoch 117/170 => Loss 4.412, Loss_clf 0.732, Loss_fe 0.588, Loss_kd 2.905, Train_accy 74.40, Test_accy 61.78
2024-08-31 21:59:26,986 [foster.py] => Task 16, Epoch 118/170 => Loss 4.372, Loss_clf 0.729, Loss_fe 0.557, Loss_kd 2.900, Train_accy 74.69, Test_accy 61.96
2024-08-31 21:59:35,071 [foster.py] => Task 16, Epoch 119/170 => Loss 4.363, Loss_clf 0.725, Loss_fe 0.559, Loss_kd 2.893, Train_accy 73.93, Test_accy 61.27
2024-08-31 21:59:43,149 [foster.py] => Task 16, Epoch 120/170 => Loss 4.388, Loss_clf 0.747, Loss_fe 0.560, Loss_kd 2.895, Train_accy 74.44, Test_accy 61.09
2024-08-31 21:59:48,586 [foster.py] => Task 16, Epoch 121/170 => Loss 4.374, Loss_clf 0.734, Loss_fe 0.550, Loss_kd 2.903, Train_accy 74.42
2024-08-31 21:59:56,698 [foster.py] => Task 16, Epoch 122/170 => Loss 4.373, Loss_clf 0.724, Loss_fe 0.566, Loss_kd 2.897, Train_accy 74.31, Test_accy 61.51
2024-08-31 22:00:04,841 [foster.py] => Task 16, Epoch 123/170 => Loss 4.323, Loss_clf 0.705, Loss_fe 0.545, Loss_kd 2.887, Train_accy 76.22, Test_accy 61.54
2024-08-31 22:00:12,883 [foster.py] => Task 16, Epoch 124/170 => Loss 4.329, Loss_clf 0.699, Loss_fe 0.540, Loss_kd 2.902, Train_accy 75.64, Test_accy 61.81
2024-08-31 22:00:20,982 [foster.py] => Task 16, Epoch 125/170 => Loss 4.343, Loss_clf 0.708, Loss_fe 0.551, Loss_kd 2.897, Train_accy 75.73, Test_accy 60.89
2024-08-31 22:00:26,388 [foster.py] => Task 16, Epoch 126/170 => Loss 4.375, Loss_clf 0.735, Loss_fe 0.553, Loss_kd 2.901, Train_accy 74.76
2024-08-31 22:00:34,496 [foster.py] => Task 16, Epoch 127/170 => Loss 4.337, Loss_clf 0.714, Loss_fe 0.566, Loss_kd 2.872, Train_accy 75.47, Test_accy 62.12
2024-08-31 22:00:42,642 [foster.py] => Task 16, Epoch 128/170 => Loss 4.298, Loss_clf 0.699, Loss_fe 0.528, Loss_kd 2.885, Train_accy 74.91, Test_accy 61.60
2024-08-31 22:00:50,791 [foster.py] => Task 16, Epoch 129/170 => Loss 4.212, Loss_clf 0.658, Loss_fe 0.486, Loss_kd 2.882, Train_accy 76.04, Test_accy 61.88
2024-08-31 22:00:58,901 [foster.py] => Task 16, Epoch 130/170 => Loss 4.198, Loss_clf 0.638, Loss_fe 0.491, Loss_kd 2.883, Train_accy 78.80, Test_accy 61.89
2024-08-31 22:01:04,374 [foster.py] => Task 16, Epoch 131/170 => Loss 4.283, Loss_clf 0.712, Loss_fe 0.495, Loss_kd 2.890, Train_accy 75.69
2024-08-31 22:01:12,519 [foster.py] => Task 16, Epoch 132/170 => Loss 4.243, Loss_clf 0.667, Loss_fe 0.485, Loss_kd 2.903, Train_accy 78.20, Test_accy 62.31
2024-08-31 22:01:20,597 [foster.py] => Task 16, Epoch 133/170 => Loss 4.249, Loss_clf 0.677, Loss_fe 0.498, Loss_kd 2.888, Train_accy 76.27, Test_accy 62.28
2024-08-31 22:01:28,737 [foster.py] => Task 16, Epoch 134/170 => Loss 4.196, Loss_clf 0.658, Loss_fe 0.466, Loss_kd 2.886, Train_accy 77.78, Test_accy 62.20
2024-08-31 22:01:36,946 [foster.py] => Task 16, Epoch 135/170 => Loss 4.208, Loss_clf 0.657, Loss_fe 0.469, Loss_kd 2.896, Train_accy 77.76, Test_accy 62.33
2024-08-31 22:01:42,396 [foster.py] => Task 16, Epoch 136/170 => Loss 4.192, Loss_clf 0.647, Loss_fe 0.463, Loss_kd 2.896, Train_accy 78.13
2024-08-31 22:01:50,457 [foster.py] => Task 16, Epoch 137/170 => Loss 4.193, Loss_clf 0.650, Loss_fe 0.445, Loss_kd 2.911, Train_accy 77.71, Test_accy 62.28
2024-08-31 22:01:58,531 [foster.py] => Task 16, Epoch 138/170 => Loss 4.130, Loss_clf 0.628, Loss_fe 0.438, Loss_kd 2.878, Train_accy 78.84, Test_accy 62.62
2024-08-31 22:02:06,602 [foster.py] => Task 16, Epoch 139/170 => Loss 4.146, Loss_clf 0.633, Loss_fe 0.435, Loss_kd 2.892, Train_accy 77.22, Test_accy 62.45
2024-08-31 22:02:14,770 [foster.py] => Task 16, Epoch 140/170 => Loss 4.130, Loss_clf 0.615, Loss_fe 0.436, Loss_kd 2.893, Train_accy 78.91, Test_accy 62.49
2024-08-31 22:02:20,218 [foster.py] => Task 16, Epoch 141/170 => Loss 4.138, Loss_clf 0.636, Loss_fe 0.429, Loss_kd 2.888, Train_accy 78.96
2024-08-31 22:02:28,275 [foster.py] => Task 16, Epoch 142/170 => Loss 4.124, Loss_clf 0.630, Loss_fe 0.433, Loss_kd 2.875, Train_accy 77.04, Test_accy 62.39
2024-08-31 22:02:36,361 [foster.py] => Task 16, Epoch 143/170 => Loss 4.125, Loss_clf 0.620, Loss_fe 0.430, Loss_kd 2.889, Train_accy 79.47, Test_accy 62.61
2024-08-31 22:02:44,426 [foster.py] => Task 16, Epoch 144/170 => Loss 4.087, Loss_clf 0.608, Loss_fe 0.412, Loss_kd 2.882, Train_accy 79.53, Test_accy 62.62
2024-08-31 22:02:52,518 [foster.py] => Task 16, Epoch 145/170 => Loss 4.099, Loss_clf 0.618, Loss_fe 0.410, Loss_kd 2.886, Train_accy 79.51, Test_accy 62.58
2024-08-31 22:02:58,044 [foster.py] => Task 16, Epoch 146/170 => Loss 4.090, Loss_clf 0.601, Loss_fe 0.422, Loss_kd 2.881, Train_accy 79.49
2024-08-31 22:03:06,100 [foster.py] => Task 16, Epoch 147/170 => Loss 4.101, Loss_clf 0.630, Loss_fe 0.409, Loss_kd 2.877, Train_accy 78.47, Test_accy 62.27
2024-08-31 22:03:14,183 [foster.py] => Task 16, Epoch 148/170 => Loss 4.154, Loss_clf 0.643, Loss_fe 0.416, Loss_kd 2.908, Train_accy 79.49, Test_accy 62.53
2024-08-31 22:03:22,290 [foster.py] => Task 16, Epoch 149/170 => Loss 4.079, Loss_clf 0.605, Loss_fe 0.402, Loss_kd 2.886, Train_accy 80.00, Test_accy 62.55
2024-08-31 22:03:30,314 [foster.py] => Task 16, Epoch 150/170 => Loss 4.086, Loss_clf 0.626, Loss_fe 0.388, Loss_kd 2.887, Train_accy 79.91, Test_accy 62.69
2024-08-31 22:03:35,775 [foster.py] => Task 16, Epoch 151/170 => Loss 4.081, Loss_clf 0.611, Loss_fe 0.386, Loss_kd 2.898, Train_accy 79.82
2024-08-31 22:03:43,854 [foster.py] => Task 16, Epoch 152/170 => Loss 4.020, Loss_clf 0.579, Loss_fe 0.360, Loss_kd 2.895, Train_accy 81.20, Test_accy 62.86
2024-08-31 22:03:51,969 [foster.py] => Task 16, Epoch 153/170 => Loss 4.079, Loss_clf 0.610, Loss_fe 0.397, Loss_kd 2.887, Train_accy 79.51, Test_accy 62.64
2024-08-31 22:04:00,151 [foster.py] => Task 16, Epoch 154/170 => Loss 4.063, Loss_clf 0.608, Loss_fe 0.383, Loss_kd 2.887, Train_accy 80.22, Test_accy 62.52
2024-08-31 22:04:08,194 [foster.py] => Task 16, Epoch 155/170 => Loss 4.056, Loss_clf 0.603, Loss_fe 0.379, Loss_kd 2.888, Train_accy 80.69, Test_accy 62.72
2024-08-31 22:04:13,633 [foster.py] => Task 16, Epoch 156/170 => Loss 4.036, Loss_clf 0.589, Loss_fe 0.376, Loss_kd 2.885, Train_accy 80.73
2024-08-31 22:04:21,703 [foster.py] => Task 16, Epoch 157/170 => Loss 4.047, Loss_clf 0.589, Loss_fe 0.377, Loss_kd 2.895, Train_accy 81.40, Test_accy 62.74
2024-08-31 22:04:29,739 [foster.py] => Task 16, Epoch 158/170 => Loss 4.043, Loss_clf 0.588, Loss_fe 0.368, Loss_kd 2.900, Train_accy 80.98, Test_accy 62.75
2024-08-31 22:04:37,912 [foster.py] => Task 16, Epoch 159/170 => Loss 4.012, Loss_clf 0.583, Loss_fe 0.356, Loss_kd 2.887, Train_accy 80.96, Test_accy 62.75
2024-08-31 22:04:45,993 [foster.py] => Task 16, Epoch 160/170 => Loss 3.970, Loss_clf 0.550, Loss_fe 0.353, Loss_kd 2.882, Train_accy 81.47, Test_accy 62.86
2024-08-31 22:04:51,350 [foster.py] => Task 16, Epoch 161/170 => Loss 4.027, Loss_clf 0.585, Loss_fe 0.348, Loss_kd 2.906, Train_accy 81.02
2024-08-31 22:04:59,328 [foster.py] => Task 16, Epoch 162/170 => Loss 3.999, Loss_clf 0.580, Loss_fe 0.343, Loss_kd 2.891, Train_accy 81.44, Test_accy 62.84
2024-08-31 22:05:07,378 [foster.py] => Task 16, Epoch 163/170 => Loss 4.019, Loss_clf 0.588, Loss_fe 0.366, Loss_kd 2.881, Train_accy 81.11, Test_accy 62.84
2024-08-31 22:05:15,449 [foster.py] => Task 16, Epoch 164/170 => Loss 3.988, Loss_clf 0.568, Loss_fe 0.345, Loss_kd 2.890, Train_accy 81.73, Test_accy 62.72
2024-08-31 22:05:23,539 [foster.py] => Task 16, Epoch 165/170 => Loss 3.969, Loss_clf 0.567, Loss_fe 0.333, Loss_kd 2.884, Train_accy 81.44, Test_accy 62.68
2024-08-31 22:05:29,026 [foster.py] => Task 16, Epoch 166/170 => Loss 4.023, Loss_clf 0.596, Loss_fe 0.348, Loss_kd 2.893, Train_accy 81.11
2024-08-31 22:05:37,171 [foster.py] => Task 16, Epoch 167/170 => Loss 3.989, Loss_clf 0.577, Loss_fe 0.356, Loss_kd 2.871, Train_accy 81.09, Test_accy 62.72
2024-08-31 22:05:45,236 [foster.py] => Task 16, Epoch 168/170 => Loss 3.994, Loss_clf 0.582, Loss_fe 0.345, Loss_kd 2.881, Train_accy 81.00, Test_accy 62.69
2024-08-31 22:05:53,251 [foster.py] => Task 16, Epoch 169/170 => Loss 4.041, Loss_clf 0.601, Loss_fe 0.355, Loss_kd 2.898, Train_accy 80.73, Test_accy 62.71
2024-08-31 22:06:01,353 [foster.py] => Task 16, Epoch 170/170 => Loss 3.960, Loss_clf 0.562, Loss_fe 0.331, Loss_kd 2.881, Train_accy 81.84, Test_accy 62.78
2024-08-31 22:06:01,356 [foster.py] => do not weight align teacher!
2024-08-31 22:06:01,359 [foster.py] => per cls weights : [1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751 1.03126751
 1.03126751 1.03126751 0.49971982 0.49971982 0.49971982 0.49971982
 0.49971982]
2024-08-31 22:06:11,642 [foster.py] => SNet: Task 16, Epoch 1/130 => Loss 30.833,  Loss1 0.756, Train_accy 40.49, Test_accy 59.51
2024-08-31 22:06:19,307 [foster.py] => SNet: Task 16, Epoch 2/130 => Loss 30.742,  Loss1 0.756, Train_accy 50.36
2024-08-31 22:06:26,630 [foster.py] => SNet: Task 16, Epoch 3/130 => Loss 30.725,  Loss1 0.756, Train_accy 54.67
2024-08-31 22:06:34,097 [foster.py] => SNet: Task 16, Epoch 4/130 => Loss 30.748,  Loss1 0.755, Train_accy 58.33
2024-08-31 22:06:41,779 [foster.py] => SNet: Task 16, Epoch 5/130 => Loss 30.749,  Loss1 0.755, Train_accy 58.89
2024-08-31 22:06:51,869 [foster.py] => SNet: Task 16, Epoch 6/130 => Loss 30.722,  Loss1 0.755, Train_accy 61.04, Test_accy 61.01
2024-08-31 22:06:59,084 [foster.py] => SNet: Task 16, Epoch 7/130 => Loss 30.737,  Loss1 0.755, Train_accy 60.93
2024-08-31 22:07:06,420 [foster.py] => SNet: Task 16, Epoch 8/130 => Loss 30.739,  Loss1 0.756, Train_accy 62.04
2024-08-31 22:07:14,187 [foster.py] => SNet: Task 16, Epoch 9/130 => Loss 30.737,  Loss1 0.756, Train_accy 63.04
2024-08-31 22:07:21,384 [foster.py] => SNet: Task 16, Epoch 10/130 => Loss 30.733,  Loss1 0.756, Train_accy 62.80
2024-08-31 22:07:31,269 [foster.py] => SNet: Task 16, Epoch 11/130 => Loss 30.765,  Loss1 0.756, Train_accy 62.96, Test_accy 60.84
2024-08-31 22:07:38,930 [foster.py] => SNet: Task 16, Epoch 12/130 => Loss 30.725,  Loss1 0.756, Train_accy 63.27
2024-08-31 22:07:46,541 [foster.py] => SNet: Task 16, Epoch 13/130 => Loss 30.718,  Loss1 0.756, Train_accy 64.07
2024-08-31 22:07:54,011 [foster.py] => SNet: Task 16, Epoch 14/130 => Loss 30.702,  Loss1 0.756, Train_accy 63.84
2024-08-31 22:08:01,330 [foster.py] => SNet: Task 16, Epoch 15/130 => Loss 30.698,  Loss1 0.756, Train_accy 65.00
2024-08-31 22:08:10,968 [foster.py] => SNet: Task 16, Epoch 16/130 => Loss 30.706,  Loss1 0.756, Train_accy 64.27, Test_accy 61.96
2024-08-31 22:08:18,533 [foster.py] => SNet: Task 16, Epoch 17/130 => Loss 30.693,  Loss1 0.756, Train_accy 64.00
2024-08-31 22:08:26,072 [foster.py] => SNet: Task 16, Epoch 18/130 => Loss 30.723,  Loss1 0.756, Train_accy 64.04
2024-08-31 22:08:33,626 [foster.py] => SNet: Task 16, Epoch 19/130 => Loss 30.726,  Loss1 0.756, Train_accy 66.22
2024-08-31 22:08:41,129 [foster.py] => SNet: Task 16, Epoch 20/130 => Loss 30.716,  Loss1 0.756, Train_accy 64.71
2024-08-31 22:08:51,133 [foster.py] => SNet: Task 16, Epoch 21/130 => Loss 30.714,  Loss1 0.756, Train_accy 65.09, Test_accy 60.60
2024-08-31 22:08:58,587 [foster.py] => SNet: Task 16, Epoch 22/130 => Loss 30.705,  Loss1 0.756, Train_accy 65.11
2024-08-31 22:09:05,781 [foster.py] => SNet: Task 16, Epoch 23/130 => Loss 30.714,  Loss1 0.756, Train_accy 66.91
2024-08-31 22:09:13,005 [foster.py] => SNet: Task 16, Epoch 24/130 => Loss 30.729,  Loss1 0.756, Train_accy 65.07
2024-08-31 22:09:20,596 [foster.py] => SNet: Task 16, Epoch 25/130 => Loss 30.696,  Loss1 0.756, Train_accy 66.11
2024-08-31 22:09:30,250 [foster.py] => SNet: Task 16, Epoch 26/130 => Loss 30.696,  Loss1 0.756, Train_accy 65.53, Test_accy 61.41
2024-08-31 22:09:37,649 [foster.py] => SNet: Task 16, Epoch 27/130 => Loss 30.680,  Loss1 0.756, Train_accy 66.38
2024-08-31 22:09:44,944 [foster.py] => SNet: Task 16, Epoch 28/130 => Loss 30.700,  Loss1 0.756, Train_accy 66.60
2024-08-31 22:09:52,870 [foster.py] => SNet: Task 16, Epoch 29/130 => Loss 30.720,  Loss1 0.755, Train_accy 65.76
2024-08-31 22:10:00,295 [foster.py] => SNet: Task 16, Epoch 30/130 => Loss 30.719,  Loss1 0.756, Train_accy 65.36
2024-08-31 22:10:09,998 [foster.py] => SNet: Task 16, Epoch 31/130 => Loss 30.705,  Loss1 0.755, Train_accy 67.38, Test_accy 60.78
2024-08-31 22:10:17,206 [foster.py] => SNet: Task 16, Epoch 32/130 => Loss 30.690,  Loss1 0.755, Train_accy 67.51
2024-08-31 22:10:24,666 [foster.py] => SNet: Task 16, Epoch 33/130 => Loss 30.693,  Loss1 0.756, Train_accy 67.11
2024-08-31 22:10:31,897 [foster.py] => SNet: Task 16, Epoch 34/130 => Loss 30.698,  Loss1 0.756, Train_accy 66.56
2024-08-31 22:10:39,085 [foster.py] => SNet: Task 16, Epoch 35/130 => Loss 30.713,  Loss1 0.756, Train_accy 66.67
2024-08-31 22:10:48,700 [foster.py] => SNet: Task 16, Epoch 36/130 => Loss 30.699,  Loss1 0.756, Train_accy 67.80, Test_accy 61.99
2024-08-31 22:10:56,182 [foster.py] => SNet: Task 16, Epoch 37/130 => Loss 30.693,  Loss1 0.756, Train_accy 67.67
2024-08-31 22:11:03,578 [foster.py] => SNet: Task 16, Epoch 38/130 => Loss 30.711,  Loss1 0.756, Train_accy 67.38
2024-08-31 22:11:10,838 [foster.py] => SNet: Task 16, Epoch 39/130 => Loss 30.668,  Loss1 0.755, Train_accy 67.02
2024-08-31 22:11:18,146 [foster.py] => SNet: Task 16, Epoch 40/130 => Loss 30.686,  Loss1 0.755, Train_accy 67.29
2024-08-31 22:11:27,837 [foster.py] => SNet: Task 16, Epoch 41/130 => Loss 30.720,  Loss1 0.756, Train_accy 67.82, Test_accy 61.58
2024-08-31 22:11:35,288 [foster.py] => SNet: Task 16, Epoch 42/130 => Loss 30.723,  Loss1 0.756, Train_accy 66.84
2024-08-31 22:11:42,663 [foster.py] => SNet: Task 16, Epoch 43/130 => Loss 30.717,  Loss1 0.756, Train_accy 67.78
2024-08-31 22:11:49,958 [foster.py] => SNet: Task 16, Epoch 44/130 => Loss 30.697,  Loss1 0.756, Train_accy 67.96
2024-08-31 22:11:57,240 [foster.py] => SNet: Task 16, Epoch 45/130 => Loss 30.687,  Loss1 0.756, Train_accy 67.33
2024-08-31 22:12:06,936 [foster.py] => SNet: Task 16, Epoch 46/130 => Loss 30.688,  Loss1 0.755, Train_accy 67.69, Test_accy 62.07
2024-08-31 22:12:14,437 [foster.py] => SNet: Task 16, Epoch 47/130 => Loss 30.724,  Loss1 0.756, Train_accy 67.56
2024-08-31 22:12:21,675 [foster.py] => SNet: Task 16, Epoch 48/130 => Loss 30.722,  Loss1 0.756, Train_accy 68.13
2024-08-31 22:12:29,117 [foster.py] => SNet: Task 16, Epoch 49/130 => Loss 30.693,  Loss1 0.756, Train_accy 67.53
2024-08-31 22:12:36,692 [foster.py] => SNet: Task 16, Epoch 50/130 => Loss 30.717,  Loss1 0.756, Train_accy 68.40
2024-08-31 22:12:46,383 [foster.py] => SNet: Task 16, Epoch 51/130 => Loss 30.700,  Loss1 0.756, Train_accy 67.00, Test_accy 61.06
2024-08-31 22:12:53,869 [foster.py] => SNet: Task 16, Epoch 52/130 => Loss 30.716,  Loss1 0.756, Train_accy 68.40
2024-08-31 22:13:01,131 [foster.py] => SNet: Task 16, Epoch 53/130 => Loss 30.687,  Loss1 0.756, Train_accy 67.58
2024-08-31 22:13:08,406 [foster.py] => SNet: Task 16, Epoch 54/130 => Loss 30.719,  Loss1 0.756, Train_accy 67.69
2024-08-31 22:13:15,916 [foster.py] => SNet: Task 16, Epoch 55/130 => Loss 30.727,  Loss1 0.756, Train_accy 68.44
2024-08-31 22:13:25,538 [foster.py] => SNet: Task 16, Epoch 56/130 => Loss 30.706,  Loss1 0.756, Train_accy 68.33, Test_accy 61.80
2024-08-31 22:13:32,835 [foster.py] => SNet: Task 16, Epoch 57/130 => Loss 30.666,  Loss1 0.755, Train_accy 67.00
2024-08-31 22:13:40,053 [foster.py] => SNet: Task 16, Epoch 58/130 => Loss 30.709,  Loss1 0.756, Train_accy 67.96
2024-08-31 22:13:47,645 [foster.py] => SNet: Task 16, Epoch 59/130 => Loss 30.696,  Loss1 0.756, Train_accy 67.89
2024-08-31 22:13:55,002 [foster.py] => SNet: Task 16, Epoch 60/130 => Loss 30.673,  Loss1 0.756, Train_accy 67.33
2024-08-31 22:14:04,603 [foster.py] => SNet: Task 16, Epoch 61/130 => Loss 30.681,  Loss1 0.756, Train_accy 68.69, Test_accy 61.80
2024-08-31 22:14:12,206 [foster.py] => SNet: Task 16, Epoch 62/130 => Loss 30.675,  Loss1 0.756, Train_accy 68.78
2024-08-31 22:14:19,492 [foster.py] => SNet: Task 16, Epoch 63/130 => Loss 30.723,  Loss1 0.755, Train_accy 68.18
2024-08-31 22:14:26,892 [foster.py] => SNet: Task 16, Epoch 64/130 => Loss 30.720,  Loss1 0.756, Train_accy 68.76
2024-08-31 22:14:34,269 [foster.py] => SNet: Task 16, Epoch 65/130 => Loss 30.666,  Loss1 0.756, Train_accy 68.84
2024-08-31 22:14:43,854 [foster.py] => SNet: Task 16, Epoch 66/130 => Loss 30.697,  Loss1 0.756, Train_accy 67.16, Test_accy 61.86
2024-08-31 22:14:51,307 [foster.py] => SNet: Task 16, Epoch 67/130 => Loss 30.693,  Loss1 0.756, Train_accy 67.96
2024-08-31 22:14:58,785 [foster.py] => SNet: Task 16, Epoch 68/130 => Loss 30.678,  Loss1 0.756, Train_accy 68.49
2024-08-31 22:15:06,281 [foster.py] => SNet: Task 16, Epoch 69/130 => Loss 30.686,  Loss1 0.756, Train_accy 68.58
2024-08-31 22:15:13,897 [foster.py] => SNet: Task 16, Epoch 70/130 => Loss 30.692,  Loss1 0.756, Train_accy 68.20
2024-08-31 22:15:23,485 [foster.py] => SNet: Task 16, Epoch 71/130 => Loss 30.709,  Loss1 0.756, Train_accy 69.47, Test_accy 61.94
2024-08-31 22:15:31,117 [foster.py] => SNet: Task 16, Epoch 72/130 => Loss 30.708,  Loss1 0.755, Train_accy 68.44
2024-08-31 22:15:38,507 [foster.py] => SNet: Task 16, Epoch 73/130 => Loss 30.679,  Loss1 0.755, Train_accy 69.27
2024-08-31 22:15:46,053 [foster.py] => SNet: Task 16, Epoch 74/130 => Loss 30.683,  Loss1 0.756, Train_accy 68.00
2024-08-31 22:15:53,298 [foster.py] => SNet: Task 16, Epoch 75/130 => Loss 30.691,  Loss1 0.756, Train_accy 69.04
2024-08-31 22:16:03,537 [foster.py] => SNet: Task 16, Epoch 76/130 => Loss 30.703,  Loss1 0.756, Train_accy 67.58, Test_accy 61.76
2024-08-31 22:16:10,987 [foster.py] => SNet: Task 16, Epoch 77/130 => Loss 30.701,  Loss1 0.756, Train_accy 68.76
2024-08-31 22:16:18,678 [foster.py] => SNet: Task 16, Epoch 78/130 => Loss 30.689,  Loss1 0.756, Train_accy 68.58
2024-08-31 22:16:26,265 [foster.py] => SNet: Task 16, Epoch 79/130 => Loss 30.678,  Loss1 0.755, Train_accy 68.84
2024-08-31 22:16:33,996 [foster.py] => SNet: Task 16, Epoch 80/130 => Loss 30.715,  Loss1 0.756, Train_accy 68.44
2024-08-31 22:16:43,772 [foster.py] => SNet: Task 16, Epoch 81/130 => Loss 30.716,  Loss1 0.756, Train_accy 68.87, Test_accy 61.85
2024-08-31 22:16:51,271 [foster.py] => SNet: Task 16, Epoch 82/130 => Loss 30.696,  Loss1 0.755, Train_accy 68.87
2024-08-31 22:16:58,618 [foster.py] => SNet: Task 16, Epoch 83/130 => Loss 30.685,  Loss1 0.756, Train_accy 69.71
2024-08-31 22:17:06,164 [foster.py] => SNet: Task 16, Epoch 84/130 => Loss 30.702,  Loss1 0.756, Train_accy 68.27
2024-08-31 22:17:13,539 [foster.py] => SNet: Task 16, Epoch 85/130 => Loss 30.696,  Loss1 0.756, Train_accy 68.40
2024-08-31 22:17:23,300 [foster.py] => SNet: Task 16, Epoch 86/130 => Loss 30.678,  Loss1 0.756, Train_accy 69.98, Test_accy 62.04
2024-08-31 22:17:31,296 [foster.py] => SNet: Task 16, Epoch 87/130 => Loss 30.675,  Loss1 0.756, Train_accy 69.27
2024-08-31 22:17:38,970 [foster.py] => SNet: Task 16, Epoch 88/130 => Loss 30.675,  Loss1 0.756, Train_accy 69.04
2024-08-31 22:17:46,615 [foster.py] => SNet: Task 16, Epoch 89/130 => Loss 30.710,  Loss1 0.756, Train_accy 69.18
2024-08-31 22:17:53,798 [foster.py] => SNet: Task 16, Epoch 90/130 => Loss 30.684,  Loss1 0.756, Train_accy 69.44
2024-08-31 22:18:03,588 [foster.py] => SNet: Task 16, Epoch 91/130 => Loss 30.702,  Loss1 0.756, Train_accy 67.58, Test_accy 61.88
2024-08-31 22:18:10,830 [foster.py] => SNet: Task 16, Epoch 92/130 => Loss 30.699,  Loss1 0.756, Train_accy 70.07
2024-08-31 22:18:18,422 [foster.py] => SNet: Task 16, Epoch 93/130 => Loss 30.716,  Loss1 0.756, Train_accy 68.04
2024-08-31 22:18:25,864 [foster.py] => SNet: Task 16, Epoch 94/130 => Loss 30.735,  Loss1 0.756, Train_accy 69.20
2024-08-31 22:18:33,481 [foster.py] => SNet: Task 16, Epoch 95/130 => Loss 30.712,  Loss1 0.756, Train_accy 69.69
2024-08-31 22:18:43,136 [foster.py] => SNet: Task 16, Epoch 96/130 => Loss 30.714,  Loss1 0.756, Train_accy 69.89, Test_accy 62.19
2024-08-31 22:18:50,355 [foster.py] => SNet: Task 16, Epoch 97/130 => Loss 30.709,  Loss1 0.756, Train_accy 68.64
2024-08-31 22:18:57,549 [foster.py] => SNet: Task 16, Epoch 98/130 => Loss 30.661,  Loss1 0.756, Train_accy 69.24
2024-08-31 22:19:04,996 [foster.py] => SNet: Task 16, Epoch 99/130 => Loss 30.698,  Loss1 0.756, Train_accy 68.71
2024-08-31 22:19:12,544 [foster.py] => SNet: Task 16, Epoch 100/130 => Loss 30.661,  Loss1 0.756, Train_accy 69.80
2024-08-31 22:19:22,395 [foster.py] => SNet: Task 16, Epoch 101/130 => Loss 30.712,  Loss1 0.755, Train_accy 68.89, Test_accy 61.95
2024-08-31 22:19:29,947 [foster.py] => SNet: Task 16, Epoch 102/130 => Loss 30.693,  Loss1 0.756, Train_accy 68.47
2024-08-31 22:19:37,610 [foster.py] => SNet: Task 16, Epoch 103/130 => Loss 30.669,  Loss1 0.755, Train_accy 69.62
2024-08-31 22:19:44,978 [foster.py] => SNet: Task 16, Epoch 104/130 => Loss 30.690,  Loss1 0.756, Train_accy 68.96
2024-08-31 22:19:52,282 [foster.py] => SNet: Task 16, Epoch 105/130 => Loss 30.726,  Loss1 0.756, Train_accy 69.60
2024-08-31 22:20:01,853 [foster.py] => SNet: Task 16, Epoch 106/130 => Loss 30.701,  Loss1 0.756, Train_accy 68.62, Test_accy 62.22
2024-08-31 22:20:09,105 [foster.py] => SNet: Task 16, Epoch 107/130 => Loss 30.702,  Loss1 0.756, Train_accy 69.42
2024-08-31 22:20:16,522 [foster.py] => SNet: Task 16, Epoch 108/130 => Loss 30.698,  Loss1 0.756, Train_accy 69.38
2024-08-31 22:20:23,836 [foster.py] => SNet: Task 16, Epoch 109/130 => Loss 30.678,  Loss1 0.756, Train_accy 68.44
2024-08-31 22:20:31,709 [foster.py] => SNet: Task 16, Epoch 110/130 => Loss 30.678,  Loss1 0.756, Train_accy 69.27
2024-08-31 22:20:41,723 [foster.py] => SNet: Task 16, Epoch 111/130 => Loss 30.682,  Loss1 0.756, Train_accy 67.93, Test_accy 62.31
2024-08-31 22:20:49,166 [foster.py] => SNet: Task 16, Epoch 112/130 => Loss 30.714,  Loss1 0.756, Train_accy 68.84
2024-08-31 22:20:56,725 [foster.py] => SNet: Task 16, Epoch 113/130 => Loss 30.698,  Loss1 0.756, Train_accy 68.73
2024-08-31 22:21:03,987 [foster.py] => SNet: Task 16, Epoch 114/130 => Loss 30.696,  Loss1 0.756, Train_accy 69.80
2024-08-31 22:21:11,822 [foster.py] => SNet: Task 16, Epoch 115/130 => Loss 30.693,  Loss1 0.756, Train_accy 69.40
2024-08-31 22:21:21,528 [foster.py] => SNet: Task 16, Epoch 116/130 => Loss 30.653,  Loss1 0.756, Train_accy 69.69, Test_accy 61.78
2024-08-31 22:21:28,923 [foster.py] => SNet: Task 16, Epoch 117/130 => Loss 30.681,  Loss1 0.756, Train_accy 69.76
2024-08-31 22:21:36,478 [foster.py] => SNet: Task 16, Epoch 118/130 => Loss 30.701,  Loss1 0.756, Train_accy 69.91
2024-08-31 22:21:43,765 [foster.py] => SNet: Task 16, Epoch 119/130 => Loss 30.684,  Loss1 0.756, Train_accy 69.82
2024-08-31 22:21:51,289 [foster.py] => SNet: Task 16, Epoch 120/130 => Loss 30.687,  Loss1 0.756, Train_accy 69.42
2024-08-31 22:22:01,434 [foster.py] => SNet: Task 16, Epoch 121/130 => Loss 30.674,  Loss1 0.756, Train_accy 69.07, Test_accy 62.15
2024-08-31 22:22:08,951 [foster.py] => SNet: Task 16, Epoch 122/130 => Loss 30.708,  Loss1 0.756, Train_accy 69.09
2024-08-31 22:22:16,213 [foster.py] => SNet: Task 16, Epoch 123/130 => Loss 30.678,  Loss1 0.755, Train_accy 70.27
2024-08-31 22:22:23,553 [foster.py] => SNet: Task 16, Epoch 124/130 => Loss 30.712,  Loss1 0.756, Train_accy 69.16
2024-08-31 22:22:31,003 [foster.py] => SNet: Task 16, Epoch 125/130 => Loss 30.699,  Loss1 0.756, Train_accy 68.69
2024-08-31 22:22:40,980 [foster.py] => SNet: Task 16, Epoch 126/130 => Loss 30.688,  Loss1 0.756, Train_accy 69.87, Test_accy 62.40
2024-08-31 22:22:48,334 [foster.py] => SNet: Task 16, Epoch 127/130 => Loss 30.695,  Loss1 0.756, Train_accy 68.38
2024-08-31 22:22:55,538 [foster.py] => SNet: Task 16, Epoch 128/130 => Loss 30.663,  Loss1 0.756, Train_accy 70.44
2024-08-31 22:23:02,723 [foster.py] => SNet: Task 16, Epoch 129/130 => Loss 30.671,  Loss1 0.756, Train_accy 68.40
2024-08-31 22:23:10,241 [foster.py] => SNet: Task 16, Epoch 130/130 => Loss 30.693,  Loss1 0.756, Train_accy 69.11
2024-08-31 22:23:10,241 [foster.py] => do not weight align student!
2024-08-31 22:23:12,643 [foster.py] => darknet eval: 
2024-08-31 22:23:12,643 [foster.py] => CNN top1 curve: 61.8
2024-08-31 22:23:12,643 [foster.py] => CNN top5 curve: 88.04
2024-08-31 22:23:12,643 [foster.py] => CNN top1 平均值: 61.80
2024-08-31 22:23:12,647 [foster.py] => timees : 2316.1871733665466
2024-08-31 22:23:12,648 [base.py] => Reducing exemplars...(23 per classes)
2024-08-31 22:23:40,495 [base.py] => Constructing exemplars...(23 per classes)
2024-08-31 22:23:51,218 [foster.py] => Exemplar size: 1955
2024-08-31 22:23:51,218 [trainer.py] => CNN: {'total': 62.78, '00-09': 64.5, '10-19': 45.5, '20-29': 64.2, '30-39': 57.3, '40-49': 68.6, '50-59': 59.7, '60-69': 71.6, '70-79': 64.2, '80-89': 76.0, 'old': 61.95, 'new': 76.0}
2024-08-31 22:23:51,218 [trainer.py] => NME: {'total': 56.42, '00-09': 52.5, '10-19': 37.4, '20-29': 56.5, '30-39': 51.5, '40-49': 63.4, '50-59': 55.7, '60-69': 64.2, '70-79': 57.3, '80-89': 82.2, 'old': 54.81, 'new': 82.2}
2024-08-31 22:23:51,218 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85, 63.39, 62.78]
2024-08-31 22:23:51,218 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96, 88.72, 88.04]
2024-08-31 22:23:51,218 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17, 56.89, 56.42]
2024-08-31 22:23:51,218 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84, 84.65, 84.15]

2024-08-31 22:23:51,218 [trainer.py] => CNN top1 平均值: 76.03
2024-08-31 22:23:51,221 [trainer.py] => All params: 1304238
2024-08-31 22:23:51,223 [trainer.py] => Trainable params: 657764
2024-08-31 22:23:51,287 [foster.py] => Learning on 85-90
2024-08-31 22:23:51,290 [foster.py] => All params: 1305533
2024-08-31 22:23:51,293 [foster.py] => Trainable params: 658734
2024-08-31 22:23:51,345 [foster.py] => per cls weights : [1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954 1.01915954
 1.01915954 0.67428777 0.67428777 0.67428777 0.67428777 0.67428777]
2024-08-31 22:23:56,830 [foster.py] => Task 17, Epoch 1/170 => Loss 12.527, Loss_clf 7.122, Loss_fe 2.134, Loss_kd 3.081, Train_accy 43.05
2024-08-31 22:24:04,792 [foster.py] => Task 17, Epoch 2/170 => Loss 6.977, Loss_clf 1.999, Loss_fe 1.718, Loss_kd 3.071, Train_accy 58.00, Test_accy 56.99
2024-08-31 22:24:12,826 [foster.py] => Task 17, Epoch 3/170 => Loss 6.270, Loss_clf 1.411, Loss_fe 1.613, Loss_kd 3.058, Train_accy 60.79, Test_accy 55.30
2024-08-31 22:24:20,776 [foster.py] => Task 17, Epoch 4/170 => Loss 6.139, Loss_clf 1.372, Loss_fe 1.514, Loss_kd 3.065, Train_accy 61.30, Test_accy 54.51
2024-08-31 22:24:28,779 [foster.py] => Task 17, Epoch 5/170 => Loss 6.086, Loss_clf 1.419, Loss_fe 1.409, Loss_kd 3.069, Train_accy 59.96, Test_accy 58.44
2024-08-31 22:24:34,043 [foster.py] => Task 17, Epoch 6/170 => Loss 6.102, Loss_clf 1.531, Loss_fe 1.328, Loss_kd 3.055, Train_accy 60.43
2024-08-31 22:24:42,067 [foster.py] => Task 17, Epoch 7/170 => Loss 5.964, Loss_clf 1.452, Loss_fe 1.263, Loss_kd 3.062, Train_accy 60.22, Test_accy 53.44
2024-08-31 22:24:50,105 [foster.py] => Task 17, Epoch 8/170 => Loss 5.743, Loss_clf 1.286, Loss_fe 1.205, Loss_kd 3.065, Train_accy 61.55, Test_accy 57.62
2024-08-31 22:24:58,138 [foster.py] => Task 17, Epoch 9/170 => Loss 5.784, Loss_clf 1.359, Loss_fe 1.173, Loss_kd 3.065, Train_accy 61.01, Test_accy 52.88
2024-08-31 22:25:06,193 [foster.py] => Task 17, Epoch 10/170 => Loss 5.907, Loss_clf 1.490, Loss_fe 1.164, Loss_kd 3.065, Train_accy 60.07, Test_accy 58.20
2024-08-31 22:25:11,508 [foster.py] => Task 17, Epoch 11/170 => Loss 5.894, Loss_clf 1.485, Loss_fe 1.150, Loss_kd 3.072, Train_accy 61.41
2024-08-31 22:25:19,594 [foster.py] => Task 17, Epoch 12/170 => Loss 5.825, Loss_clf 1.435, Loss_fe 1.131, Loss_kd 3.072, Train_accy 61.84, Test_accy 58.52
2024-08-31 22:25:27,663 [foster.py] => Task 17, Epoch 13/170 => Loss 5.797, Loss_clf 1.410, Loss_fe 1.133, Loss_kd 3.066, Train_accy 62.07, Test_accy 55.20
2024-08-31 22:25:35,741 [foster.py] => Task 17, Epoch 14/170 => Loss 5.680, Loss_clf 1.317, Loss_fe 1.100, Loss_kd 3.076, Train_accy 61.41, Test_accy 57.29
2024-08-31 22:25:43,799 [foster.py] => Task 17, Epoch 15/170 => Loss 5.527, Loss_clf 1.182, Loss_fe 1.106, Loss_kd 3.052, Train_accy 64.13, Test_accy 58.88
2024-08-31 22:25:49,107 [foster.py] => Task 17, Epoch 16/170 => Loss 5.466, Loss_clf 1.158, Loss_fe 1.063, Loss_kd 3.058, Train_accy 64.80
2024-08-31 22:25:57,137 [foster.py] => Task 17, Epoch 17/170 => Loss 5.562, Loss_clf 1.283, Loss_fe 1.041, Loss_kd 3.052, Train_accy 64.49, Test_accy 55.28
2024-08-31 22:26:05,195 [foster.py] => Task 17, Epoch 18/170 => Loss 5.596, Loss_clf 1.285, Loss_fe 1.066, Loss_kd 3.058, Train_accy 62.76, Test_accy 57.48
2024-08-31 22:26:13,223 [foster.py] => Task 17, Epoch 19/170 => Loss 5.560, Loss_clf 1.245, Loss_fe 1.049, Loss_kd 3.078, Train_accy 64.33, Test_accy 57.84
2024-08-31 22:26:21,292 [foster.py] => Task 17, Epoch 20/170 => Loss 5.439, Loss_clf 1.129, Loss_fe 1.061, Loss_kd 3.062, Train_accy 64.15, Test_accy 58.10
2024-08-31 22:26:26,610 [foster.py] => Task 17, Epoch 21/170 => Loss 5.589, Loss_clf 1.278, Loss_fe 1.061, Loss_kd 3.063, Train_accy 63.25
2024-08-31 22:26:34,726 [foster.py] => Task 17, Epoch 22/170 => Loss 5.534, Loss_clf 1.245, Loss_fe 1.041, Loss_kd 3.061, Train_accy 62.92, Test_accy 56.84
2024-08-31 22:26:42,788 [foster.py] => Task 17, Epoch 23/170 => Loss 5.646, Loss_clf 1.329, Loss_fe 1.071, Loss_kd 3.059, Train_accy 62.15, Test_accy 57.52
2024-08-31 22:26:50,853 [foster.py] => Task 17, Epoch 24/170 => Loss 5.513, Loss_clf 1.228, Loss_fe 1.044, Loss_kd 3.055, Train_accy 64.56, Test_accy 57.00
2024-08-31 22:26:58,873 [foster.py] => Task 17, Epoch 25/170 => Loss 5.609, Loss_clf 1.314, Loss_fe 1.043, Loss_kd 3.065, Train_accy 64.20, Test_accy 57.93
2024-08-31 22:27:04,245 [foster.py] => Task 17, Epoch 26/170 => Loss 5.631, Loss_clf 1.313, Loss_fe 1.058, Loss_kd 3.073, Train_accy 63.39
2024-08-31 22:27:12,334 [foster.py] => Task 17, Epoch 27/170 => Loss 5.522, Loss_clf 1.272, Loss_fe 1.021, Loss_kd 3.044, Train_accy 64.98, Test_accy 58.31
2024-08-31 22:27:20,400 [foster.py] => Task 17, Epoch 28/170 => Loss 5.551, Loss_clf 1.257, Loss_fe 1.032, Loss_kd 3.074, Train_accy 63.52, Test_accy 58.31
2024-08-31 22:27:28,469 [foster.py] => Task 17, Epoch 29/170 => Loss 5.721, Loss_clf 1.396, Loss_fe 1.066, Loss_kd 3.072, Train_accy 62.94, Test_accy 55.72
2024-08-31 22:27:36,549 [foster.py] => Task 17, Epoch 30/170 => Loss 5.437, Loss_clf 1.141, Loss_fe 1.049, Loss_kd 3.061, Train_accy 63.86, Test_accy 59.54
2024-08-31 22:27:41,805 [foster.py] => Task 17, Epoch 31/170 => Loss 5.477, Loss_clf 1.217, Loss_fe 1.005, Loss_kd 3.069, Train_accy 64.69
2024-08-31 22:27:49,899 [foster.py] => Task 17, Epoch 32/170 => Loss 5.681, Loss_clf 1.406, Loss_fe 1.035, Loss_kd 3.054, Train_accy 61.39, Test_accy 43.94
2024-08-31 22:27:57,907 [foster.py] => Task 17, Epoch 33/170 => Loss 5.640, Loss_clf 1.296, Loss_fe 1.085, Loss_kd 3.073, Train_accy 63.52, Test_accy 57.09
2024-08-31 22:28:05,879 [foster.py] => Task 17, Epoch 34/170 => Loss 5.400, Loss_clf 1.113, Loss_fe 1.039, Loss_kd 3.062, Train_accy 65.23, Test_accy 58.36
2024-08-31 22:28:13,888 [foster.py] => Task 17, Epoch 35/170 => Loss 5.442, Loss_clf 1.204, Loss_fe 0.983, Loss_kd 3.069, Train_accy 63.77, Test_accy 59.04
2024-08-31 22:28:19,239 [foster.py] => Task 17, Epoch 36/170 => Loss 5.403, Loss_clf 1.148, Loss_fe 0.998, Loss_kd 3.070, Train_accy 64.42
2024-08-31 22:28:27,281 [foster.py] => Task 17, Epoch 37/170 => Loss 5.344, Loss_clf 1.112, Loss_fe 0.978, Loss_kd 3.068, Train_accy 64.44, Test_accy 56.60
2024-08-31 22:28:35,354 [foster.py] => Task 17, Epoch 38/170 => Loss 5.573, Loss_clf 1.328, Loss_fe 0.994, Loss_kd 3.064, Train_accy 62.56, Test_accy 58.91
2024-08-31 22:28:43,372 [foster.py] => Task 17, Epoch 39/170 => Loss 5.503, Loss_clf 1.249, Loss_fe 1.004, Loss_kd 3.064, Train_accy 63.68, Test_accy 58.39
2024-08-31 22:28:51,424 [foster.py] => Task 17, Epoch 40/170 => Loss 5.325, Loss_clf 1.127, Loss_fe 0.953, Loss_kd 3.059, Train_accy 65.19, Test_accy 56.69
2024-08-31 22:28:56,800 [foster.py] => Task 17, Epoch 41/170 => Loss 5.463, Loss_clf 1.220, Loss_fe 0.999, Loss_kd 3.058, Train_accy 64.85
2024-08-31 22:29:04,882 [foster.py] => Task 17, Epoch 42/170 => Loss 5.457, Loss_clf 1.214, Loss_fe 0.989, Loss_kd 3.068, Train_accy 65.32, Test_accy 58.92
2024-08-31 22:29:12,981 [foster.py] => Task 17, Epoch 43/170 => Loss 5.358, Loss_clf 1.128, Loss_fe 0.992, Loss_kd 3.053, Train_accy 66.35, Test_accy 57.32
2024-08-31 22:29:21,029 [foster.py] => Task 17, Epoch 44/170 => Loss 5.361, Loss_clf 1.140, Loss_fe 0.972, Loss_kd 3.064, Train_accy 64.89, Test_accy 59.37
2024-08-31 22:29:29,091 [foster.py] => Task 17, Epoch 45/170 => Loss 5.520, Loss_clf 1.289, Loss_fe 0.981, Loss_kd 3.064, Train_accy 63.66, Test_accy 54.96
2024-08-31 22:29:34,465 [foster.py] => Task 17, Epoch 46/170 => Loss 5.242, Loss_clf 1.030, Loss_fe 0.966, Loss_kd 3.061, Train_accy 66.49
2024-08-31 22:29:42,526 [foster.py] => Task 17, Epoch 47/170 => Loss 5.242, Loss_clf 1.076, Loss_fe 0.929, Loss_kd 3.052, Train_accy 65.43, Test_accy 58.20
2024-08-31 22:29:50,650 [foster.py] => Task 17, Epoch 48/170 => Loss 5.258, Loss_clf 1.075, Loss_fe 0.934, Loss_kd 3.062, Train_accy 64.85, Test_accy 58.26
2024-08-31 22:29:58,629 [foster.py] => Task 17, Epoch 49/170 => Loss 5.468, Loss_clf 1.226, Loss_fe 0.961, Loss_kd 3.093, Train_accy 63.75, Test_accy 58.69
2024-08-31 22:30:06,690 [foster.py] => Task 17, Epoch 50/170 => Loss 5.355, Loss_clf 1.129, Loss_fe 0.963, Loss_kd 3.076, Train_accy 63.86, Test_accy 57.86
2024-08-31 22:30:11,968 [foster.py] => Task 17, Epoch 51/170 => Loss 5.297, Loss_clf 1.101, Loss_fe 0.939, Loss_kd 3.070, Train_accy 65.45
2024-08-31 22:30:19,990 [foster.py] => Task 17, Epoch 52/170 => Loss 5.264, Loss_clf 1.072, Loss_fe 0.942, Loss_kd 3.063, Train_accy 65.41, Test_accy 58.82
2024-08-31 22:30:28,145 [foster.py] => Task 17, Epoch 53/170 => Loss 5.245, Loss_clf 1.086, Loss_fe 0.907, Loss_kd 3.066, Train_accy 64.78, Test_accy 55.49
2024-08-31 22:30:36,256 [foster.py] => Task 17, Epoch 54/170 => Loss 5.327, Loss_clf 1.154, Loss_fe 0.936, Loss_kd 3.052, Train_accy 64.74, Test_accy 58.31
2024-08-31 22:30:44,281 [foster.py] => Task 17, Epoch 55/170 => Loss 5.316, Loss_clf 1.128, Loss_fe 0.935, Loss_kd 3.067, Train_accy 66.15, Test_accy 59.16
2024-08-31 22:30:49,595 [foster.py] => Task 17, Epoch 56/170 => Loss 5.389, Loss_clf 1.183, Loss_fe 0.942, Loss_kd 3.077, Train_accy 64.89
2024-08-31 22:30:57,702 [foster.py] => Task 17, Epoch 57/170 => Loss 5.274, Loss_clf 1.105, Loss_fe 0.915, Loss_kd 3.067, Train_accy 64.67, Test_accy 56.19
2024-08-31 22:31:05,795 [foster.py] => Task 17, Epoch 58/170 => Loss 5.351, Loss_clf 1.160, Loss_fe 0.944, Loss_kd 3.061, Train_accy 63.77, Test_accy 59.79
2024-08-31 22:31:13,821 [foster.py] => Task 17, Epoch 59/170 => Loss 5.246, Loss_clf 1.078, Loss_fe 0.928, Loss_kd 3.054, Train_accy 64.83, Test_accy 59.07
2024-08-31 22:31:21,849 [foster.py] => Task 17, Epoch 60/170 => Loss 5.237, Loss_clf 1.056, Loss_fe 0.931, Loss_kd 3.064, Train_accy 65.97, Test_accy 59.66
2024-08-31 22:31:27,157 [foster.py] => Task 17, Epoch 61/170 => Loss 5.171, Loss_clf 1.026, Loss_fe 0.888, Loss_kd 3.071, Train_accy 66.24
2024-08-31 22:31:35,185 [foster.py] => Task 17, Epoch 62/170 => Loss 5.112, Loss_clf 1.015, Loss_fe 0.862, Loss_kd 3.051, Train_accy 67.63, Test_accy 59.24
2024-08-31 22:31:43,327 [foster.py] => Task 17, Epoch 63/170 => Loss 5.186, Loss_clf 1.079, Loss_fe 0.872, Loss_kd 3.051, Train_accy 66.31, Test_accy 58.51
2024-08-31 22:31:51,313 [foster.py] => Task 17, Epoch 64/170 => Loss 5.246, Loss_clf 1.094, Loss_fe 0.900, Loss_kd 3.066, Train_accy 65.72, Test_accy 59.23
2024-08-31 22:31:59,337 [foster.py] => Task 17, Epoch 65/170 => Loss 5.146, Loss_clf 1.037, Loss_fe 0.874, Loss_kd 3.050, Train_accy 65.59, Test_accy 59.32
2024-08-31 22:32:04,677 [foster.py] => Task 17, Epoch 66/170 => Loss 5.107, Loss_clf 0.981, Loss_fe 0.889, Loss_kd 3.051, Train_accy 67.90
2024-08-31 22:32:12,671 [foster.py] => Task 17, Epoch 67/170 => Loss 5.149, Loss_clf 1.026, Loss_fe 0.867, Loss_kd 3.069, Train_accy 66.69, Test_accy 58.68
2024-08-31 22:32:20,814 [foster.py] => Task 17, Epoch 68/170 => Loss 5.156, Loss_clf 1.019, Loss_fe 0.882, Loss_kd 3.068, Train_accy 65.75, Test_accy 59.93
2024-08-31 22:32:28,863 [foster.py] => Task 17, Epoch 69/170 => Loss 5.198, Loss_clf 1.062, Loss_fe 0.889, Loss_kd 3.062, Train_accy 66.15, Test_accy 57.50
2024-08-31 22:32:36,933 [foster.py] => Task 17, Epoch 70/170 => Loss 5.233, Loss_clf 1.098, Loss_fe 0.891, Loss_kd 3.058, Train_accy 66.60, Test_accy 59.14
2024-08-31 22:32:42,204 [foster.py] => Task 17, Epoch 71/170 => Loss 5.153, Loss_clf 1.058, Loss_fe 0.856, Loss_kd 3.054, Train_accy 67.09
2024-08-31 22:32:50,249 [foster.py] => Task 17, Epoch 72/170 => Loss 5.155, Loss_clf 1.047, Loss_fe 0.865, Loss_kd 3.058, Train_accy 67.30, Test_accy 59.37
2024-08-31 22:32:58,303 [foster.py] => Task 17, Epoch 73/170 => Loss 5.110, Loss_clf 1.005, Loss_fe 0.852, Loss_kd 3.067, Train_accy 67.27, Test_accy 59.02
2024-08-31 22:33:06,330 [foster.py] => Task 17, Epoch 74/170 => Loss 5.092, Loss_clf 1.007, Loss_fe 0.840, Loss_kd 3.059, Train_accy 67.92, Test_accy 57.78
2024-08-31 22:33:14,460 [foster.py] => Task 17, Epoch 75/170 => Loss 5.096, Loss_clf 1.029, Loss_fe 0.821, Loss_kd 3.060, Train_accy 67.16, Test_accy 60.09
2024-08-31 22:33:19,716 [foster.py] => Task 17, Epoch 76/170 => Loss 5.140, Loss_clf 1.026, Loss_fe 0.860, Loss_kd 3.067, Train_accy 67.47
2024-08-31 22:33:27,746 [foster.py] => Task 17, Epoch 77/170 => Loss 5.066, Loss_clf 0.980, Loss_fe 0.843, Loss_kd 3.058, Train_accy 66.89, Test_accy 57.27
2024-08-31 22:33:35,767 [foster.py] => Task 17, Epoch 78/170 => Loss 5.049, Loss_clf 0.989, Loss_fe 0.821, Loss_kd 3.053, Train_accy 68.35, Test_accy 57.84
2024-08-31 22:33:43,799 [foster.py] => Task 17, Epoch 79/170 => Loss 5.097, Loss_clf 1.030, Loss_fe 0.828, Loss_kd 3.054, Train_accy 67.34, Test_accy 54.92
2024-08-31 22:33:51,772 [foster.py] => Task 17, Epoch 80/170 => Loss 5.056, Loss_clf 1.011, Loss_fe 0.803, Loss_kd 3.056, Train_accy 68.06, Test_accy 60.08
2024-08-31 22:33:57,084 [foster.py] => Task 17, Epoch 81/170 => Loss 5.066, Loss_clf 0.991, Loss_fe 0.825, Loss_kd 3.064, Train_accy 68.37
2024-08-31 22:34:05,144 [foster.py] => Task 17, Epoch 82/170 => Loss 5.027, Loss_clf 0.970, Loss_fe 0.799, Loss_kd 3.071, Train_accy 68.44, Test_accy 59.92
2024-08-31 22:34:13,162 [foster.py] => Task 17, Epoch 83/170 => Loss 5.010, Loss_clf 0.970, Loss_fe 0.795, Loss_kd 3.058, Train_accy 69.05, Test_accy 58.36
2024-08-31 22:34:21,146 [foster.py] => Task 17, Epoch 84/170 => Loss 5.017, Loss_clf 0.945, Loss_fe 0.828, Loss_kd 3.058, Train_accy 67.79, Test_accy 59.37
2024-08-31 22:34:29,166 [foster.py] => Task 17, Epoch 85/170 => Loss 5.034, Loss_clf 0.992, Loss_fe 0.792, Loss_kd 3.064, Train_accy 68.82, Test_accy 59.51
2024-08-31 22:34:34,491 [foster.py] => Task 17, Epoch 86/170 => Loss 4.998, Loss_clf 0.975, Loss_fe 0.789, Loss_kd 3.048, Train_accy 68.69
2024-08-31 22:34:42,564 [foster.py] => Task 17, Epoch 87/170 => Loss 4.929, Loss_clf 0.929, Loss_fe 0.764, Loss_kd 3.052, Train_accy 69.56, Test_accy 60.26
2024-08-31 22:34:50,671 [foster.py] => Task 17, Epoch 88/170 => Loss 4.950, Loss_clf 0.949, Loss_fe 0.756, Loss_kd 3.059, Train_accy 68.55, Test_accy 59.94
2024-08-31 22:34:58,761 [foster.py] => Task 17, Epoch 89/170 => Loss 4.978, Loss_clf 0.952, Loss_fe 0.788, Loss_kd 3.052, Train_accy 68.44, Test_accy 58.62
2024-08-31 22:35:06,797 [foster.py] => Task 17, Epoch 90/170 => Loss 4.892, Loss_clf 0.903, Loss_fe 0.740, Loss_kd 3.063, Train_accy 69.67, Test_accy 59.82
2024-08-31 22:35:12,097 [foster.py] => Task 17, Epoch 91/170 => Loss 4.997, Loss_clf 0.948, Loss_fe 0.806, Loss_kd 3.058, Train_accy 68.78
2024-08-31 22:35:20,176 [foster.py] => Task 17, Epoch 92/170 => Loss 4.949, Loss_clf 0.943, Loss_fe 0.764, Loss_kd 3.056, Train_accy 69.47, Test_accy 58.46
2024-08-31 22:35:28,273 [foster.py] => Task 17, Epoch 93/170 => Loss 4.904, Loss_clf 0.915, Loss_fe 0.744, Loss_kd 3.060, Train_accy 70.55, Test_accy 59.74
2024-08-31 22:35:36,402 [foster.py] => Task 17, Epoch 94/170 => Loss 4.917, Loss_clf 0.927, Loss_fe 0.750, Loss_kd 3.055, Train_accy 69.32, Test_accy 59.92
2024-08-31 22:35:44,505 [foster.py] => Task 17, Epoch 95/170 => Loss 4.910, Loss_clf 0.913, Loss_fe 0.751, Loss_kd 3.060, Train_accy 69.70, Test_accy 59.60
2024-08-31 22:35:49,774 [foster.py] => Task 17, Epoch 96/170 => Loss 4.817, Loss_clf 0.870, Loss_fe 0.714, Loss_kd 3.048, Train_accy 71.00
2024-08-31 22:35:57,826 [foster.py] => Task 17, Epoch 97/170 => Loss 4.964, Loss_clf 0.964, Loss_fe 0.756, Loss_kd 3.059, Train_accy 68.96, Test_accy 59.51
2024-08-31 22:36:05,854 [foster.py] => Task 17, Epoch 98/170 => Loss 4.865, Loss_clf 0.915, Loss_fe 0.707, Loss_kd 3.058, Train_accy 70.46, Test_accy 60.37
2024-08-31 22:36:13,883 [foster.py] => Task 17, Epoch 99/170 => Loss 4.891, Loss_clf 0.920, Loss_fe 0.724, Loss_kd 3.060, Train_accy 70.17, Test_accy 59.56
2024-08-31 22:36:21,931 [foster.py] => Task 17, Epoch 100/170 => Loss 4.812, Loss_clf 0.865, Loss_fe 0.708, Loss_kd 3.054, Train_accy 70.75, Test_accy 60.39
2024-08-31 22:36:27,294 [foster.py] => Task 17, Epoch 101/170 => Loss 4.791, Loss_clf 0.870, Loss_fe 0.691, Loss_kd 3.045, Train_accy 71.56
2024-08-31 22:36:35,387 [foster.py] => Task 17, Epoch 102/170 => Loss 4.830, Loss_clf 0.896, Loss_fe 0.693, Loss_kd 3.056, Train_accy 69.63, Test_accy 59.38
2024-08-31 22:36:43,480 [foster.py] => Task 17, Epoch 103/170 => Loss 4.815, Loss_clf 0.875, Loss_fe 0.712, Loss_kd 3.044, Train_accy 70.80, Test_accy 60.18
2024-08-31 22:36:51,500 [foster.py] => Task 17, Epoch 104/170 => Loss 4.841, Loss_clf 0.874, Loss_fe 0.728, Loss_kd 3.053, Train_accy 71.25, Test_accy 59.92
2024-08-31 22:36:59,649 [foster.py] => Task 17, Epoch 105/170 => Loss 4.763, Loss_clf 0.842, Loss_fe 0.690, Loss_kd 3.047, Train_accy 72.50, Test_accy 59.98
2024-08-31 22:37:04,982 [foster.py] => Task 17, Epoch 106/170 => Loss 4.748, Loss_clf 0.836, Loss_fe 0.682, Loss_kd 3.045, Train_accy 72.21
2024-08-31 22:37:13,060 [foster.py] => Task 17, Epoch 107/170 => Loss 4.777, Loss_clf 0.858, Loss_fe 0.681, Loss_kd 3.053, Train_accy 72.46, Test_accy 59.56
2024-08-31 22:37:21,185 [foster.py] => Task 17, Epoch 108/170 => Loss 4.828, Loss_clf 0.882, Loss_fe 0.696, Loss_kd 3.064, Train_accy 70.39, Test_accy 60.32
2024-08-31 22:37:29,252 [foster.py] => Task 17, Epoch 109/170 => Loss 4.723, Loss_clf 0.832, Loss_fe 0.650, Loss_kd 3.055, Train_accy 71.92, Test_accy 60.90
2024-08-31 22:37:37,280 [foster.py] => Task 17, Epoch 110/170 => Loss 4.787, Loss_clf 0.872, Loss_fe 0.661, Loss_kd 3.068, Train_accy 71.69, Test_accy 59.57
2024-08-31 22:37:42,622 [foster.py] => Task 17, Epoch 111/170 => Loss 4.702, Loss_clf 0.826, Loss_fe 0.644, Loss_kd 3.046, Train_accy 73.45
2024-08-31 22:37:50,677 [foster.py] => Task 17, Epoch 112/170 => Loss 4.699, Loss_clf 0.812, Loss_fe 0.649, Loss_kd 3.052, Train_accy 73.06, Test_accy 59.66
2024-08-31 22:37:58,677 [foster.py] => Task 17, Epoch 113/170 => Loss 4.718, Loss_clf 0.835, Loss_fe 0.646, Loss_kd 3.052, Train_accy 72.21, Test_accy 60.93
2024-08-31 22:38:06,763 [foster.py] => Task 17, Epoch 114/170 => Loss 4.673, Loss_clf 0.812, Loss_fe 0.623, Loss_kd 3.053, Train_accy 72.86, Test_accy 60.73
2024-08-31 22:38:14,797 [foster.py] => Task 17, Epoch 115/170 => Loss 4.640, Loss_clf 0.791, Loss_fe 0.614, Loss_kd 3.050, Train_accy 74.05, Test_accy 59.32
2024-08-31 22:38:20,098 [foster.py] => Task 17, Epoch 116/170 => Loss 4.700, Loss_clf 0.815, Loss_fe 0.637, Loss_kd 3.062, Train_accy 73.51
2024-08-31 22:38:28,126 [foster.py] => Task 17, Epoch 117/170 => Loss 4.702, Loss_clf 0.821, Loss_fe 0.639, Loss_kd 3.056, Train_accy 72.77, Test_accy 60.68
2024-08-31 22:38:36,243 [foster.py] => Task 17, Epoch 118/170 => Loss 4.693, Loss_clf 0.830, Loss_fe 0.618, Loss_kd 3.059, Train_accy 72.95, Test_accy 59.21
2024-08-31 22:38:44,271 [foster.py] => Task 17, Epoch 119/170 => Loss 4.652, Loss_clf 0.817, Loss_fe 0.603, Loss_kd 3.047, Train_accy 72.84, Test_accy 61.01
2024-08-31 22:38:52,293 [foster.py] => Task 17, Epoch 120/170 => Loss 4.637, Loss_clf 0.799, Loss_fe 0.599, Loss_kd 3.054, Train_accy 73.60, Test_accy 60.10
2024-08-31 22:38:57,573 [foster.py] => Task 17, Epoch 121/170 => Loss 4.640, Loss_clf 0.799, Loss_fe 0.591, Loss_kd 3.064, Train_accy 73.69
2024-08-31 22:39:05,668 [foster.py] => Task 17, Epoch 122/170 => Loss 4.582, Loss_clf 0.772, Loss_fe 0.573, Loss_kd 3.051, Train_accy 74.70, Test_accy 59.62
2024-08-31 22:39:13,710 [foster.py] => Task 17, Epoch 123/170 => Loss 4.609, Loss_clf 0.778, Loss_fe 0.595, Loss_kd 3.050, Train_accy 74.64, Test_accy 60.49
2024-08-31 22:39:21,734 [foster.py] => Task 17, Epoch 124/170 => Loss 4.552, Loss_clf 0.757, Loss_fe 0.566, Loss_kd 3.044, Train_accy 75.04, Test_accy 61.30
2024-08-31 22:39:29,741 [foster.py] => Task 17, Epoch 125/170 => Loss 4.569, Loss_clf 0.761, Loss_fe 0.551, Loss_kd 3.070, Train_accy 75.29, Test_accy 60.09
2024-08-31 22:39:35,054 [foster.py] => Task 17, Epoch 126/170 => Loss 4.497, Loss_clf 0.741, Loss_fe 0.528, Loss_kd 3.044, Train_accy 75.94
2024-08-31 22:39:43,207 [foster.py] => Task 17, Epoch 127/170 => Loss 4.578, Loss_clf 0.783, Loss_fe 0.544, Loss_kd 3.065, Train_accy 75.15, Test_accy 60.68
2024-08-31 22:39:51,305 [foster.py] => Task 17, Epoch 128/170 => Loss 4.491, Loss_clf 0.721, Loss_fe 0.537, Loss_kd 3.048, Train_accy 76.99, Test_accy 61.24
2024-08-31 22:39:59,262 [foster.py] => Task 17, Epoch 129/170 => Loss 4.537, Loss_clf 0.762, Loss_fe 0.535, Loss_kd 3.055, Train_accy 75.29, Test_accy 60.86
2024-08-31 22:40:07,353 [foster.py] => Task 17, Epoch 130/170 => Loss 4.531, Loss_clf 0.758, Loss_fe 0.529, Loss_kd 3.059, Train_accy 75.60, Test_accy 61.01
2024-08-31 22:40:12,666 [foster.py] => Task 17, Epoch 131/170 => Loss 4.491, Loss_clf 0.733, Loss_fe 0.515, Loss_kd 3.058, Train_accy 77.37
2024-08-31 22:40:20,727 [foster.py] => Task 17, Epoch 132/170 => Loss 4.484, Loss_clf 0.729, Loss_fe 0.513, Loss_kd 3.057, Train_accy 77.06, Test_accy 61.07
2024-08-31 22:40:28,723 [foster.py] => Task 17, Epoch 133/170 => Loss 4.417, Loss_clf 0.708, Loss_fe 0.476, Loss_kd 3.048, Train_accy 77.17, Test_accy 59.89
2024-08-31 22:40:36,748 [foster.py] => Task 17, Epoch 134/170 => Loss 4.416, Loss_clf 0.705, Loss_fe 0.483, Loss_kd 3.043, Train_accy 76.99, Test_accy 60.63
2024-08-31 22:40:44,889 [foster.py] => Task 17, Epoch 135/170 => Loss 4.438, Loss_clf 0.711, Loss_fe 0.491, Loss_kd 3.050, Train_accy 76.75, Test_accy 60.82
2024-08-31 22:40:50,239 [foster.py] => Task 17, Epoch 136/170 => Loss 4.414, Loss_clf 0.699, Loss_fe 0.473, Loss_kd 3.057, Train_accy 78.16
2024-08-31 22:40:58,257 [foster.py] => Task 17, Epoch 137/170 => Loss 4.370, Loss_clf 0.684, Loss_fe 0.462, Loss_kd 3.040, Train_accy 77.64, Test_accy 61.37
2024-08-31 22:41:06,305 [foster.py] => Task 17, Epoch 138/170 => Loss 4.414, Loss_clf 0.697, Loss_fe 0.474, Loss_kd 3.058, Train_accy 78.41, Test_accy 60.77
2024-08-31 22:41:14,316 [foster.py] => Task 17, Epoch 139/170 => Loss 4.389, Loss_clf 0.682, Loss_fe 0.464, Loss_kd 3.057, Train_accy 78.18, Test_accy 61.19
2024-08-31 22:41:22,394 [foster.py] => Task 17, Epoch 140/170 => Loss 4.414, Loss_clf 0.707, Loss_fe 0.463, Loss_kd 3.059, Train_accy 78.16, Test_accy 61.40
2024-08-31 22:41:27,730 [foster.py] => Task 17, Epoch 141/170 => Loss 4.348, Loss_clf 0.666, Loss_fe 0.449, Loss_kd 3.048, Train_accy 78.81
2024-08-31 22:41:35,773 [foster.py] => Task 17, Epoch 142/170 => Loss 4.389, Loss_clf 0.707, Loss_fe 0.449, Loss_kd 3.049, Train_accy 77.73, Test_accy 61.44
2024-08-31 22:41:43,824 [foster.py] => Task 17, Epoch 143/170 => Loss 4.295, Loss_clf 0.641, Loss_fe 0.422, Loss_kd 3.048, Train_accy 80.18, Test_accy 61.24
2024-08-31 22:41:51,879 [foster.py] => Task 17, Epoch 144/170 => Loss 4.337, Loss_clf 0.676, Loss_fe 0.423, Loss_kd 3.052, Train_accy 77.98, Test_accy 61.18
2024-08-31 22:41:59,899 [foster.py] => Task 17, Epoch 145/170 => Loss 4.327, Loss_clf 0.663, Loss_fe 0.433, Loss_kd 3.046, Train_accy 79.69, Test_accy 61.72
2024-08-31 22:42:05,148 [foster.py] => Task 17, Epoch 146/170 => Loss 4.336, Loss_clf 0.670, Loss_fe 0.433, Loss_kd 3.049, Train_accy 78.56
2024-08-31 22:42:13,238 [foster.py] => Task 17, Epoch 147/170 => Loss 4.328, Loss_clf 0.674, Loss_fe 0.416, Loss_kd 3.053, Train_accy 79.57, Test_accy 61.56
2024-08-31 22:42:21,351 [foster.py] => Task 17, Epoch 148/170 => Loss 4.266, Loss_clf 0.643, Loss_fe 0.382, Loss_kd 3.056, Train_accy 80.47, Test_accy 61.44
2024-08-31 22:42:29,473 [foster.py] => Task 17, Epoch 149/170 => Loss 4.319, Loss_clf 0.661, Loss_fe 0.403, Loss_kd 3.069, Train_accy 80.02, Test_accy 61.70
2024-08-31 22:42:37,529 [foster.py] => Task 17, Epoch 150/170 => Loss 4.255, Loss_clf 0.628, Loss_fe 0.395, Loss_kd 3.047, Train_accy 80.36, Test_accy 61.59
2024-08-31 22:42:42,881 [foster.py] => Task 17, Epoch 151/170 => Loss 4.248, Loss_clf 0.629, Loss_fe 0.378, Loss_kd 3.057, Train_accy 80.81
2024-08-31 22:42:50,888 [foster.py] => Task 17, Epoch 152/170 => Loss 4.340, Loss_clf 0.668, Loss_fe 0.413, Loss_kd 3.071, Train_accy 79.91, Test_accy 61.46
2024-08-31 22:42:58,877 [foster.py] => Task 17, Epoch 153/170 => Loss 4.219, Loss_clf 0.611, Loss_fe 0.374, Loss_kd 3.048, Train_accy 80.25, Test_accy 61.34
2024-08-31 22:43:06,937 [foster.py] => Task 17, Epoch 154/170 => Loss 4.223, Loss_clf 0.611, Loss_fe 0.377, Loss_kd 3.050, Train_accy 81.17, Test_accy 61.69
2024-08-31 22:43:14,949 [foster.py] => Task 17, Epoch 155/170 => Loss 4.289, Loss_clf 0.652, Loss_fe 0.381, Loss_kd 3.070, Train_accy 80.18, Test_accy 61.52
2024-08-31 22:43:20,249 [foster.py] => Task 17, Epoch 156/170 => Loss 4.249, Loss_clf 0.632, Loss_fe 0.381, Loss_kd 3.051, Train_accy 80.65
2024-08-31 22:43:28,268 [foster.py] => Task 17, Epoch 157/170 => Loss 4.246, Loss_clf 0.630, Loss_fe 0.379, Loss_kd 3.052, Train_accy 80.54, Test_accy 61.42
2024-08-31 22:43:36,291 [foster.py] => Task 17, Epoch 158/170 => Loss 4.195, Loss_clf 0.601, Loss_fe 0.361, Loss_kd 3.048, Train_accy 81.19, Test_accy 61.50
2024-08-31 22:43:44,346 [foster.py] => Task 17, Epoch 159/170 => Loss 4.178, Loss_clf 0.598, Loss_fe 0.344, Loss_kd 3.052, Train_accy 82.27, Test_accy 61.39
2024-08-31 22:43:52,437 [foster.py] => Task 17, Epoch 160/170 => Loss 4.199, Loss_clf 0.602, Loss_fe 0.353, Loss_kd 3.059, Train_accy 81.71, Test_accy 61.40
2024-08-31 22:43:57,766 [foster.py] => Task 17, Epoch 161/170 => Loss 4.197, Loss_clf 0.607, Loss_fe 0.363, Loss_kd 3.042, Train_accy 82.15
2024-08-31 22:44:05,847 [foster.py] => Task 17, Epoch 162/170 => Loss 4.269, Loss_clf 0.645, Loss_fe 0.376, Loss_kd 3.062, Train_accy 80.56, Test_accy 61.44
2024-08-31 22:44:13,914 [foster.py] => Task 17, Epoch 163/170 => Loss 4.187, Loss_clf 0.602, Loss_fe 0.357, Loss_kd 3.043, Train_accy 81.66, Test_accy 61.39
2024-08-31 22:44:22,029 [foster.py] => Task 17, Epoch 164/170 => Loss 4.179, Loss_clf 0.608, Loss_fe 0.348, Loss_kd 3.039, Train_accy 81.77, Test_accy 61.54
2024-08-31 22:44:29,993 [foster.py] => Task 17, Epoch 165/170 => Loss 4.187, Loss_clf 0.598, Loss_fe 0.361, Loss_kd 3.044, Train_accy 82.07, Test_accy 61.56
2024-08-31 22:44:35,354 [foster.py] => Task 17, Epoch 166/170 => Loss 4.215, Loss_clf 0.618, Loss_fe 0.360, Loss_kd 3.052, Train_accy 80.85
2024-08-31 22:44:43,469 [foster.py] => Task 17, Epoch 167/170 => Loss 4.177, Loss_clf 0.592, Loss_fe 0.353, Loss_kd 3.047, Train_accy 82.47, Test_accy 61.53
2024-08-31 22:44:51,524 [foster.py] => Task 17, Epoch 168/170 => Loss 4.208, Loss_clf 0.620, Loss_fe 0.352, Loss_kd 3.051, Train_accy 81.03, Test_accy 61.57
2024-08-31 22:44:59,681 [foster.py] => Task 17, Epoch 169/170 => Loss 4.213, Loss_clf 0.613, Loss_fe 0.353, Loss_kd 3.061, Train_accy 80.45, Test_accy 61.67
2024-08-31 22:45:07,737 [foster.py] => Task 17, Epoch 170/170 => Loss 4.221, Loss_clf 0.619, Loss_fe 0.352, Loss_kd 3.064, Train_accy 82.29, Test_accy 61.57
2024-08-31 22:45:07,741 [foster.py] => do not weight align teacher!
2024-08-31 22:45:07,744 [foster.py] => per cls weights : [1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165 1.03105165
 1.03105165 0.47212202 0.47212202 0.47212202 0.47212202 0.47212202]
2024-08-31 22:45:17,921 [foster.py] => SNet: Task 17, Epoch 1/130 => Loss 31.367,  Loss1 0.766, Train_accy 38.56, Test_accy 58.73
2024-08-31 22:45:25,392 [foster.py] => SNet: Task 17, Epoch 2/130 => Loss 31.266,  Loss1 0.766, Train_accy 45.75
2024-08-31 22:45:32,693 [foster.py] => SNet: Task 17, Epoch 3/130 => Loss 31.261,  Loss1 0.766, Train_accy 50.19
2024-08-31 22:45:39,749 [foster.py] => SNet: Task 17, Epoch 4/130 => Loss 31.276,  Loss1 0.766, Train_accy 53.20
2024-08-31 22:45:46,832 [foster.py] => SNet: Task 17, Epoch 5/130 => Loss 31.265,  Loss1 0.766, Train_accy 55.87
2024-08-31 22:45:56,396 [foster.py] => SNet: Task 17, Epoch 6/130 => Loss 31.246,  Loss1 0.766, Train_accy 55.91, Test_accy 60.28
2024-08-31 22:46:03,535 [foster.py] => SNet: Task 17, Epoch 7/130 => Loss 31.265,  Loss1 0.766, Train_accy 58.14
2024-08-31 22:46:10,850 [foster.py] => SNet: Task 17, Epoch 8/130 => Loss 31.231,  Loss1 0.765, Train_accy 60.09
2024-08-31 22:46:18,364 [foster.py] => SNet: Task 17, Epoch 9/130 => Loss 31.266,  Loss1 0.766, Train_accy 59.62
2024-08-31 22:46:25,682 [foster.py] => SNet: Task 17, Epoch 10/130 => Loss 31.237,  Loss1 0.766, Train_accy 59.89
2024-08-31 22:46:35,440 [foster.py] => SNet: Task 17, Epoch 11/130 => Loss 31.251,  Loss1 0.766, Train_accy 60.54, Test_accy 59.19
2024-08-31 22:46:42,754 [foster.py] => SNet: Task 17, Epoch 12/130 => Loss 31.246,  Loss1 0.766, Train_accy 61.39
2024-08-31 22:46:50,086 [foster.py] => SNet: Task 17, Epoch 13/130 => Loss 31.253,  Loss1 0.765, Train_accy 61.44
2024-08-31 22:46:57,460 [foster.py] => SNet: Task 17, Epoch 14/130 => Loss 31.240,  Loss1 0.765, Train_accy 61.44
2024-08-31 22:47:04,828 [foster.py] => SNet: Task 17, Epoch 15/130 => Loss 31.247,  Loss1 0.765, Train_accy 62.45
2024-08-31 22:47:14,445 [foster.py] => SNet: Task 17, Epoch 16/130 => Loss 31.253,  Loss1 0.765, Train_accy 62.58, Test_accy 60.43
2024-08-31 22:47:21,771 [foster.py] => SNet: Task 17, Epoch 17/130 => Loss 31.250,  Loss1 0.765, Train_accy 62.67
2024-08-31 22:47:29,096 [foster.py] => SNet: Task 17, Epoch 18/130 => Loss 31.257,  Loss1 0.765, Train_accy 63.41
2024-08-31 22:47:36,356 [foster.py] => SNet: Task 17, Epoch 19/130 => Loss 31.246,  Loss1 0.766, Train_accy 63.28
2024-08-31 22:47:43,761 [foster.py] => SNet: Task 17, Epoch 20/130 => Loss 31.253,  Loss1 0.765, Train_accy 63.12
2024-08-31 22:47:53,503 [foster.py] => SNet: Task 17, Epoch 21/130 => Loss 31.227,  Loss1 0.765, Train_accy 63.79, Test_accy 59.93
2024-08-31 22:48:00,865 [foster.py] => SNet: Task 17, Epoch 22/130 => Loss 31.255,  Loss1 0.766, Train_accy 64.53
2024-08-31 22:48:08,264 [foster.py] => SNet: Task 17, Epoch 23/130 => Loss 31.237,  Loss1 0.766, Train_accy 63.84
2024-08-31 22:48:15,403 [foster.py] => SNet: Task 17, Epoch 24/130 => Loss 31.241,  Loss1 0.765, Train_accy 63.41
2024-08-31 22:48:23,351 [foster.py] => SNet: Task 17, Epoch 25/130 => Loss 31.253,  Loss1 0.766, Train_accy 65.21
2024-08-31 22:48:33,678 [foster.py] => SNet: Task 17, Epoch 26/130 => Loss 31.236,  Loss1 0.765, Train_accy 64.83, Test_accy 60.33
2024-08-31 22:48:40,940 [foster.py] => SNet: Task 17, Epoch 27/130 => Loss 31.240,  Loss1 0.765, Train_accy 64.76
2024-08-31 22:48:48,384 [foster.py] => SNet: Task 17, Epoch 28/130 => Loss 31.261,  Loss1 0.765, Train_accy 65.50
2024-08-31 22:48:55,583 [foster.py] => SNet: Task 17, Epoch 29/130 => Loss 31.231,  Loss1 0.765, Train_accy 65.75
2024-08-31 22:49:02,899 [foster.py] => SNet: Task 17, Epoch 30/130 => Loss 31.225,  Loss1 0.765, Train_accy 64.42
2024-08-31 22:49:12,460 [foster.py] => SNet: Task 17, Epoch 31/130 => Loss 31.231,  Loss1 0.765, Train_accy 66.60, Test_accy 60.59
2024-08-31 22:49:19,759 [foster.py] => SNet: Task 17, Epoch 32/130 => Loss 31.231,  Loss1 0.765, Train_accy 65.39
2024-08-31 22:49:26,932 [foster.py] => SNet: Task 17, Epoch 33/130 => Loss 31.214,  Loss1 0.765, Train_accy 64.42
2024-08-31 22:49:34,024 [foster.py] => SNet: Task 17, Epoch 34/130 => Loss 31.250,  Loss1 0.765, Train_accy 65.30
2024-08-31 22:49:41,636 [foster.py] => SNet: Task 17, Epoch 35/130 => Loss 31.238,  Loss1 0.765, Train_accy 66.62
2024-08-31 22:49:51,313 [foster.py] => SNet: Task 17, Epoch 36/130 => Loss 31.249,  Loss1 0.765, Train_accy 65.84, Test_accy 60.20
2024-08-31 22:49:58,892 [foster.py] => SNet: Task 17, Epoch 37/130 => Loss 31.262,  Loss1 0.765, Train_accy 65.54
2024-08-31 22:50:06,054 [foster.py] => SNet: Task 17, Epoch 38/130 => Loss 31.222,  Loss1 0.765, Train_accy 66.82
2024-08-31 22:50:13,581 [foster.py] => SNet: Task 17, Epoch 39/130 => Loss 31.216,  Loss1 0.765, Train_accy 64.96
2024-08-31 22:50:20,760 [foster.py] => SNet: Task 17, Epoch 40/130 => Loss 31.230,  Loss1 0.765, Train_accy 66.37
2024-08-31 22:50:30,564 [foster.py] => SNet: Task 17, Epoch 41/130 => Loss 31.246,  Loss1 0.765, Train_accy 66.62, Test_accy 60.32
2024-08-31 22:50:37,767 [foster.py] => SNet: Task 17, Epoch 42/130 => Loss 31.236,  Loss1 0.765, Train_accy 66.33
2024-08-31 22:50:45,250 [foster.py] => SNet: Task 17, Epoch 43/130 => Loss 31.265,  Loss1 0.765, Train_accy 66.17
2024-08-31 22:50:52,686 [foster.py] => SNet: Task 17, Epoch 44/130 => Loss 31.242,  Loss1 0.766, Train_accy 65.79
2024-08-31 22:50:59,827 [foster.py] => SNet: Task 17, Epoch 45/130 => Loss 31.245,  Loss1 0.765, Train_accy 67.09
2024-08-31 22:51:09,540 [foster.py] => SNet: Task 17, Epoch 46/130 => Loss 31.215,  Loss1 0.765, Train_accy 68.53, Test_accy 60.79
2024-08-31 22:51:16,689 [foster.py] => SNet: Task 17, Epoch 47/130 => Loss 31.248,  Loss1 0.765, Train_accy 65.99
2024-08-31 22:51:24,039 [foster.py] => SNet: Task 17, Epoch 48/130 => Loss 31.220,  Loss1 0.766, Train_accy 66.91
2024-08-31 22:51:31,402 [foster.py] => SNet: Task 17, Epoch 49/130 => Loss 31.228,  Loss1 0.765, Train_accy 66.69
2024-08-31 22:51:38,572 [foster.py] => SNet: Task 17, Epoch 50/130 => Loss 31.236,  Loss1 0.765, Train_accy 67.54
2024-08-31 22:51:48,071 [foster.py] => SNet: Task 17, Epoch 51/130 => Loss 31.235,  Loss1 0.765, Train_accy 66.85, Test_accy 60.81
2024-08-31 22:51:55,401 [foster.py] => SNet: Task 17, Epoch 52/130 => Loss 31.263,  Loss1 0.765, Train_accy 67.14
2024-08-31 22:52:02,696 [foster.py] => SNet: Task 17, Epoch 53/130 => Loss 31.225,  Loss1 0.765, Train_accy 66.73
2024-08-31 22:52:09,883 [foster.py] => SNet: Task 17, Epoch 54/130 => Loss 31.204,  Loss1 0.765, Train_accy 67.47
2024-08-31 22:52:17,010 [foster.py] => SNet: Task 17, Epoch 55/130 => Loss 31.230,  Loss1 0.765, Train_accy 66.49
2024-08-31 22:52:26,689 [foster.py] => SNet: Task 17, Epoch 56/130 => Loss 31.203,  Loss1 0.765, Train_accy 66.94, Test_accy 60.51
2024-08-31 22:52:34,119 [foster.py] => SNet: Task 17, Epoch 57/130 => Loss 31.219,  Loss1 0.765, Train_accy 66.73
2024-08-31 22:52:41,395 [foster.py] => SNet: Task 17, Epoch 58/130 => Loss 31.229,  Loss1 0.765, Train_accy 67.00
2024-08-31 22:52:48,536 [foster.py] => SNet: Task 17, Epoch 59/130 => Loss 31.229,  Loss1 0.765, Train_accy 67.03
2024-08-31 22:52:55,735 [foster.py] => SNet: Task 17, Epoch 60/130 => Loss 31.218,  Loss1 0.766, Train_accy 66.31
2024-08-31 22:53:05,519 [foster.py] => SNet: Task 17, Epoch 61/130 => Loss 31.214,  Loss1 0.765, Train_accy 66.53, Test_accy 60.34
2024-08-31 22:53:12,917 [foster.py] => SNet: Task 17, Epoch 62/130 => Loss 31.243,  Loss1 0.765, Train_accy 66.73
2024-08-31 22:53:20,072 [foster.py] => SNet: Task 17, Epoch 63/130 => Loss 31.253,  Loss1 0.765, Train_accy 67.34
2024-08-31 22:53:27,374 [foster.py] => SNet: Task 17, Epoch 64/130 => Loss 31.209,  Loss1 0.765, Train_accy 66.64
2024-08-31 22:53:34,520 [foster.py] => SNet: Task 17, Epoch 65/130 => Loss 31.234,  Loss1 0.765, Train_accy 67.92
2024-08-31 22:53:44,164 [foster.py] => SNet: Task 17, Epoch 66/130 => Loss 31.229,  Loss1 0.765, Train_accy 67.16, Test_accy 60.42
2024-08-31 22:53:51,507 [foster.py] => SNet: Task 17, Epoch 67/130 => Loss 31.207,  Loss1 0.765, Train_accy 68.22
2024-08-31 22:53:58,840 [foster.py] => SNet: Task 17, Epoch 68/130 => Loss 31.197,  Loss1 0.765, Train_accy 67.61
2024-08-31 22:54:06,083 [foster.py] => SNet: Task 17, Epoch 69/130 => Loss 31.198,  Loss1 0.765, Train_accy 67.92
2024-08-31 22:54:13,706 [foster.py] => SNet: Task 17, Epoch 70/130 => Loss 31.238,  Loss1 0.765, Train_accy 68.33
2024-08-31 22:54:23,541 [foster.py] => SNet: Task 17, Epoch 71/130 => Loss 31.202,  Loss1 0.765, Train_accy 67.47, Test_accy 61.09
2024-08-31 22:54:30,860 [foster.py] => SNet: Task 17, Epoch 72/130 => Loss 31.237,  Loss1 0.765, Train_accy 67.45
2024-08-31 22:54:38,231 [foster.py] => SNet: Task 17, Epoch 73/130 => Loss 31.216,  Loss1 0.765, Train_accy 67.30
2024-08-31 22:54:45,599 [foster.py] => SNet: Task 17, Epoch 74/130 => Loss 31.212,  Loss1 0.765, Train_accy 67.23
2024-08-31 22:54:53,085 [foster.py] => SNet: Task 17, Epoch 75/130 => Loss 31.202,  Loss1 0.765, Train_accy 68.06
2024-08-31 22:55:02,688 [foster.py] => SNet: Task 17, Epoch 76/130 => Loss 31.228,  Loss1 0.765, Train_accy 67.16, Test_accy 60.74
2024-08-31 22:55:10,005 [foster.py] => SNet: Task 17, Epoch 77/130 => Loss 31.227,  Loss1 0.765, Train_accy 68.04
2024-08-31 22:55:17,529 [foster.py] => SNet: Task 17, Epoch 78/130 => Loss 31.215,  Loss1 0.765, Train_accy 68.28
2024-08-31 22:55:25,225 [foster.py] => SNet: Task 17, Epoch 79/130 => Loss 31.211,  Loss1 0.765, Train_accy 68.66
2024-08-31 22:55:32,528 [foster.py] => SNet: Task 17, Epoch 80/130 => Loss 31.205,  Loss1 0.765, Train_accy 67.52
2024-08-31 22:55:42,343 [foster.py] => SNet: Task 17, Epoch 81/130 => Loss 31.228,  Loss1 0.765, Train_accy 68.08, Test_accy 60.66
2024-08-31 22:55:49,494 [foster.py] => SNet: Task 17, Epoch 82/130 => Loss 31.216,  Loss1 0.765, Train_accy 67.92
2024-08-31 22:55:56,834 [foster.py] => SNet: Task 17, Epoch 83/130 => Loss 31.212,  Loss1 0.765, Train_accy 67.86
2024-08-31 22:56:04,196 [foster.py] => SNet: Task 17, Epoch 84/130 => Loss 31.180,  Loss1 0.765, Train_accy 67.07
2024-08-31 22:56:11,403 [foster.py] => SNet: Task 17, Epoch 85/130 => Loss 31.234,  Loss1 0.766, Train_accy 67.59
2024-08-31 22:56:21,108 [foster.py] => SNet: Task 17, Epoch 86/130 => Loss 31.182,  Loss1 0.765, Train_accy 68.69, Test_accy 61.39
2024-08-31 22:56:28,340 [foster.py] => SNet: Task 17, Epoch 87/130 => Loss 31.211,  Loss1 0.765, Train_accy 68.13
2024-08-31 22:56:35,485 [foster.py] => SNet: Task 17, Epoch 88/130 => Loss 31.212,  Loss1 0.765, Train_accy 67.92
2024-08-31 22:56:42,854 [foster.py] => SNet: Task 17, Epoch 89/130 => Loss 31.217,  Loss1 0.765, Train_accy 68.82
2024-08-31 22:56:49,971 [foster.py] => SNet: Task 17, Epoch 90/130 => Loss 31.205,  Loss1 0.766, Train_accy 68.66
2024-08-31 22:56:59,716 [foster.py] => SNet: Task 17, Epoch 91/130 => Loss 31.207,  Loss1 0.765, Train_accy 68.19, Test_accy 60.58
2024-08-31 22:57:06,913 [foster.py] => SNet: Task 17, Epoch 92/130 => Loss 31.227,  Loss1 0.765, Train_accy 67.36
2024-08-31 22:57:14,393 [foster.py] => SNet: Task 17, Epoch 93/130 => Loss 31.221,  Loss1 0.765, Train_accy 68.37
2024-08-31 22:57:21,818 [foster.py] => SNet: Task 17, Epoch 94/130 => Loss 31.222,  Loss1 0.765, Train_accy 68.01
2024-08-31 22:57:29,170 [foster.py] => SNet: Task 17, Epoch 95/130 => Loss 31.233,  Loss1 0.766, Train_accy 67.47
2024-08-31 22:57:39,096 [foster.py] => SNet: Task 17, Epoch 96/130 => Loss 31.189,  Loss1 0.765, Train_accy 70.03, Test_accy 61.10
2024-08-31 22:57:46,367 [foster.py] => SNet: Task 17, Epoch 97/130 => Loss 31.210,  Loss1 0.765, Train_accy 67.90
2024-08-31 22:57:53,438 [foster.py] => SNet: Task 17, Epoch 98/130 => Loss 31.223,  Loss1 0.765, Train_accy 68.75
2024-08-31 22:58:00,924 [foster.py] => SNet: Task 17, Epoch 99/130 => Loss 31.217,  Loss1 0.765, Train_accy 68.31
2024-08-31 22:58:08,369 [foster.py] => SNet: Task 17, Epoch 100/130 => Loss 31.240,  Loss1 0.765, Train_accy 68.13
2024-08-31 22:58:18,040 [foster.py] => SNet: Task 17, Epoch 101/130 => Loss 31.218,  Loss1 0.765, Train_accy 69.05, Test_accy 61.27
2024-08-31 22:58:25,466 [foster.py] => SNet: Task 17, Epoch 102/130 => Loss 31.237,  Loss1 0.766, Train_accy 68.71
2024-08-31 22:58:32,817 [foster.py] => SNet: Task 17, Epoch 103/130 => Loss 31.225,  Loss1 0.765, Train_accy 67.63
2024-08-31 22:58:40,107 [foster.py] => SNet: Task 17, Epoch 104/130 => Loss 31.239,  Loss1 0.765, Train_accy 67.74
2024-08-31 22:58:47,746 [foster.py] => SNet: Task 17, Epoch 105/130 => Loss 31.215,  Loss1 0.765, Train_accy 67.50
2024-08-31 22:58:57,596 [foster.py] => SNet: Task 17, Epoch 106/130 => Loss 31.221,  Loss1 0.765, Train_accy 69.34, Test_accy 61.53
2024-08-31 22:59:04,787 [foster.py] => SNet: Task 17, Epoch 107/130 => Loss 31.235,  Loss1 0.765, Train_accy 67.41
2024-08-31 22:59:12,304 [foster.py] => SNet: Task 17, Epoch 108/130 => Loss 31.235,  Loss1 0.765, Train_accy 68.42
2024-08-31 22:59:19,764 [foster.py] => SNet: Task 17, Epoch 109/130 => Loss 31.205,  Loss1 0.765, Train_accy 69.29
2024-08-31 22:59:26,914 [foster.py] => SNet: Task 17, Epoch 110/130 => Loss 31.211,  Loss1 0.765, Train_accy 69.41
2024-08-31 22:59:36,630 [foster.py] => SNet: Task 17, Epoch 111/130 => Loss 31.224,  Loss1 0.766, Train_accy 68.13, Test_accy 61.29
2024-08-31 22:59:44,152 [foster.py] => SNet: Task 17, Epoch 112/130 => Loss 31.226,  Loss1 0.765, Train_accy 68.69
2024-08-31 22:59:51,603 [foster.py] => SNet: Task 17, Epoch 113/130 => Loss 31.215,  Loss1 0.765, Train_accy 67.99
2024-08-31 22:59:58,938 [foster.py] => SNet: Task 17, Epoch 114/130 => Loss 31.195,  Loss1 0.765, Train_accy 68.24
2024-08-31 23:00:06,064 [foster.py] => SNet: Task 17, Epoch 115/130 => Loss 31.196,  Loss1 0.765, Train_accy 68.84
2024-08-31 23:00:15,922 [foster.py] => SNet: Task 17, Epoch 116/130 => Loss 31.221,  Loss1 0.765, Train_accy 68.53, Test_accy 61.24
2024-08-31 23:00:23,368 [foster.py] => SNet: Task 17, Epoch 117/130 => Loss 31.237,  Loss1 0.765, Train_accy 68.64
2024-08-31 23:00:30,666 [foster.py] => SNet: Task 17, Epoch 118/130 => Loss 31.193,  Loss1 0.765, Train_accy 68.51
2024-08-31 23:00:37,814 [foster.py] => SNet: Task 17, Epoch 119/130 => Loss 31.220,  Loss1 0.765, Train_accy 67.59
2024-08-31 23:00:45,014 [foster.py] => SNet: Task 17, Epoch 120/130 => Loss 31.249,  Loss1 0.765, Train_accy 67.45
2024-08-31 23:00:54,755 [foster.py] => SNet: Task 17, Epoch 121/130 => Loss 31.221,  Loss1 0.765, Train_accy 68.15, Test_accy 61.24
2024-08-31 23:01:02,398 [foster.py] => SNet: Task 17, Epoch 122/130 => Loss 31.196,  Loss1 0.765, Train_accy 69.58
2024-08-31 23:01:09,929 [foster.py] => SNet: Task 17, Epoch 123/130 => Loss 31.188,  Loss1 0.765, Train_accy 68.33
2024-08-31 23:01:17,097 [foster.py] => SNet: Task 17, Epoch 124/130 => Loss 31.231,  Loss1 0.765, Train_accy 69.27
2024-08-31 23:01:24,192 [foster.py] => SNet: Task 17, Epoch 125/130 => Loss 31.210,  Loss1 0.765, Train_accy 69.34
2024-08-31 23:01:33,886 [foster.py] => SNet: Task 17, Epoch 126/130 => Loss 31.215,  Loss1 0.765, Train_accy 68.78, Test_accy 61.24
2024-08-31 23:01:41,590 [foster.py] => SNet: Task 17, Epoch 127/130 => Loss 31.220,  Loss1 0.765, Train_accy 68.69
2024-08-31 23:01:48,882 [foster.py] => SNet: Task 17, Epoch 128/130 => Loss 31.237,  Loss1 0.765, Train_accy 69.29
2024-08-31 23:01:56,126 [foster.py] => SNet: Task 17, Epoch 129/130 => Loss 31.218,  Loss1 0.765, Train_accy 69.05
2024-08-31 23:02:03,615 [foster.py] => SNet: Task 17, Epoch 130/130 => Loss 31.201,  Loss1 0.765, Train_accy 69.14
2024-08-31 23:02:03,616 [foster.py] => do not weight align student!
2024-08-31 23:02:06,068 [foster.py] => darknet eval: 
2024-08-31 23:02:06,069 [foster.py] => CNN top1 curve: 61.42
2024-08-31 23:02:06,069 [foster.py] => CNN top5 curve: 87.24
2024-08-31 23:02:06,069 [foster.py] => CNN top1 平均值: 61.42
2024-08-31 23:02:06,075 [foster.py] => timees : 2294.7487156391144
2024-08-31 23:02:06,076 [base.py] => Reducing exemplars...(22 per classes)
2024-08-31 23:02:36,028 [base.py] => Constructing exemplars...(22 per classes)
2024-08-31 23:02:46,906 [foster.py] => Exemplar size: 1980
2024-08-31 23:02:46,906 [trainer.py] => CNN: {'total': 61.57, '00-09': 61.9, '10-19': 44.1, '20-29': 61.4, '30-39': 56.0, '40-49': 66.5, '50-59': 57.1, '60-69': 69.7, '70-79': 63.6, '80-89': 73.8, 'old': 60.91, 'new': 72.8}
2024-08-31 23:02:46,906 [trainer.py] => NME: {'total': 55.28, '00-09': 51.9, '10-19': 36.4, '20-29': 53.6, '30-39': 48.0, '40-49': 62.3, '50-59': 53.4, '60-69': 60.8, '70-79': 64.6, '80-89': 66.5, 'old': 54.13, 'new': 74.8}
2024-08-31 23:02:46,906 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85, 63.39, 62.78, 61.57]
2024-08-31 23:02:46,906 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96, 88.72, 88.04, 87.48]
2024-08-31 23:02:46,906 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17, 56.89, 56.42, 55.28]
2024-08-31 23:02:46,906 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84, 84.65, 84.15, 82.79]

2024-08-31 23:02:46,906 [trainer.py] => CNN top1 平均值: 75.22
2024-08-31 23:02:46,909 [trainer.py] => All params: 1305533
2024-08-31 23:02:46,911 [trainer.py] => Trainable params: 658734
2024-08-31 23:02:47,022 [foster.py] => Learning on 90-95
2024-08-31 23:02:47,026 [foster.py] => All params: 1306828
2024-08-31 23:02:47,028 [foster.py] => Trainable params: 659704
2024-08-31 23:02:47,083 [foster.py] => per cls weights : [1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929 1.01891929
 0.65945275 0.65945275 0.65945275 0.65945275 0.65945275]
2024-08-31 23:02:52,331 [foster.py] => Task 18, Epoch 1/170 => Loss 12.876, Loss_clf 7.408, Loss_fe 2.080, Loss_kd 3.201, Train_accy 42.97
2024-08-31 23:03:00,457 [foster.py] => Task 18, Epoch 2/170 => Loss 6.597, Loss_clf 1.562, Loss_fe 1.690, Loss_kd 3.160, Train_accy 65.02, Test_accy 55.84
2024-08-31 23:03:08,591 [foster.py] => Task 18, Epoch 3/170 => Loss 6.288, Loss_clf 1.338, Loss_fe 1.600, Loss_kd 3.165, Train_accy 64.15, Test_accy 57.41
2024-08-31 23:03:16,709 [foster.py] => Task 18, Epoch 4/170 => Loss 6.190, Loss_clf 1.261, Loss_fe 1.583, Loss_kd 3.161, Train_accy 64.53, Test_accy 56.35
2024-08-31 23:03:24,890 [foster.py] => Task 18, Epoch 5/170 => Loss 6.132, Loss_clf 1.236, Loss_fe 1.544, Loss_kd 3.167, Train_accy 63.10, Test_accy 54.86
2024-08-31 23:03:30,199 [foster.py] => Task 18, Epoch 6/170 => Loss 6.061, Loss_clf 1.216, Loss_fe 1.500, Loss_kd 3.161, Train_accy 63.24
2024-08-31 23:03:38,328 [foster.py] => Task 18, Epoch 7/170 => Loss 6.041, Loss_clf 1.214, Loss_fe 1.486, Loss_kd 3.158, Train_accy 64.40, Test_accy 56.68
2024-08-31 23:03:46,442 [foster.py] => Task 18, Epoch 8/170 => Loss 5.970, Loss_clf 1.153, Loss_fe 1.479, Loss_kd 3.155, Train_accy 64.89, Test_accy 57.78
2024-08-31 23:03:54,655 [foster.py] => Task 18, Epoch 9/170 => Loss 6.119, Loss_clf 1.305, Loss_fe 1.460, Loss_kd 3.170, Train_accy 63.08, Test_accy 55.93
2024-08-31 23:04:02,800 [foster.py] => Task 18, Epoch 10/170 => Loss 6.149, Loss_clf 1.358, Loss_fe 1.444, Loss_kd 3.164, Train_accy 62.54, Test_accy 56.93
2024-08-31 23:04:08,128 [foster.py] => Task 18, Epoch 11/170 => Loss 6.006, Loss_clf 1.239, Loss_fe 1.433, Loss_kd 3.152, Train_accy 62.70
2024-08-31 23:04:16,291 [foster.py] => Task 18, Epoch 12/170 => Loss 5.955, Loss_clf 1.205, Loss_fe 1.410, Loss_kd 3.157, Train_accy 63.48, Test_accy 57.61
2024-08-31 23:04:24,487 [foster.py] => Task 18, Epoch 13/170 => Loss 6.027, Loss_clf 1.282, Loss_fe 1.392, Loss_kd 3.170, Train_accy 61.83, Test_accy 54.99
2024-08-31 23:04:32,637 [foster.py] => Task 18, Epoch 14/170 => Loss 5.931, Loss_clf 1.206, Loss_fe 1.379, Loss_kd 3.163, Train_accy 63.91, Test_accy 56.29
2024-08-31 23:04:40,846 [foster.py] => Task 18, Epoch 15/170 => Loss 6.023, Loss_clf 1.305, Loss_fe 1.368, Loss_kd 3.167, Train_accy 63.06, Test_accy 58.21
2024-08-31 23:04:46,215 [foster.py] => Task 18, Epoch 16/170 => Loss 5.979, Loss_clf 1.251, Loss_fe 1.379, Loss_kd 3.166, Train_accy 63.55
2024-08-31 23:04:54,426 [foster.py] => Task 18, Epoch 17/170 => Loss 5.917, Loss_clf 1.195, Loss_fe 1.376, Loss_kd 3.163, Train_accy 63.77, Test_accy 57.47
2024-08-31 23:05:02,641 [foster.py] => Task 18, Epoch 18/170 => Loss 5.774, Loss_clf 1.105, Loss_fe 1.317, Loss_kd 3.170, Train_accy 64.24, Test_accy 58.09
2024-08-31 23:05:10,754 [foster.py] => Task 18, Epoch 19/170 => Loss 5.996, Loss_clf 1.296, Loss_fe 1.342, Loss_kd 3.176, Train_accy 60.76, Test_accy 57.93
2024-08-31 23:05:18,934 [foster.py] => Task 18, Epoch 20/170 => Loss 5.966, Loss_clf 1.294, Loss_fe 1.331, Loss_kd 3.159, Train_accy 62.88, Test_accy 56.62
2024-08-31 23:05:24,208 [foster.py] => Task 18, Epoch 21/170 => Loss 5.776, Loss_clf 1.102, Loss_fe 1.317, Loss_kd 3.174, Train_accy 63.68
2024-08-31 23:05:32,345 [foster.py] => Task 18, Epoch 22/170 => Loss 5.778, Loss_clf 1.138, Loss_fe 1.291, Loss_kd 3.166, Train_accy 63.50, Test_accy 55.21
2024-08-31 23:05:40,468 [foster.py] => Task 18, Epoch 23/170 => Loss 5.863, Loss_clf 1.210, Loss_fe 1.307, Loss_kd 3.164, Train_accy 63.91, Test_accy 57.71
2024-08-31 23:05:48,676 [foster.py] => Task 18, Epoch 24/170 => Loss 5.810, Loss_clf 1.196, Loss_fe 1.265, Loss_kd 3.167, Train_accy 64.06, Test_accy 58.14
2024-08-31 23:05:56,819 [foster.py] => Task 18, Epoch 25/170 => Loss 5.777, Loss_clf 1.117, Loss_fe 1.306, Loss_kd 3.172, Train_accy 64.35, Test_accy 56.91
2024-08-31 23:06:02,200 [foster.py] => Task 18, Epoch 26/170 => Loss 5.824, Loss_clf 1.215, Loss_fe 1.268, Loss_kd 3.159, Train_accy 63.57
2024-08-31 23:06:10,444 [foster.py] => Task 18, Epoch 27/170 => Loss 5.920, Loss_clf 1.302, Loss_fe 1.265, Loss_kd 3.171, Train_accy 63.42, Test_accy 58.06
2024-08-31 23:06:18,548 [foster.py] => Task 18, Epoch 28/170 => Loss 5.874, Loss_clf 1.282, Loss_fe 1.248, Loss_kd 3.163, Train_accy 63.01, Test_accy 58.04
2024-08-31 23:06:26,672 [foster.py] => Task 18, Epoch 29/170 => Loss 5.768, Loss_clf 1.154, Loss_fe 1.262, Loss_kd 3.170, Train_accy 63.55, Test_accy 57.01
2024-08-31 23:06:34,851 [foster.py] => Task 18, Epoch 30/170 => Loss 5.639, Loss_clf 1.053, Loss_fe 1.241, Loss_kd 3.163, Train_accy 65.13, Test_accy 57.94
2024-08-31 23:06:40,164 [foster.py] => Task 18, Epoch 31/170 => Loss 5.714, Loss_clf 1.168, Loss_fe 1.201, Loss_kd 3.163, Train_accy 63.48
2024-08-31 23:06:48,348 [foster.py] => Task 18, Epoch 32/170 => Loss 5.647, Loss_clf 1.074, Loss_fe 1.222, Loss_kd 3.169, Train_accy 64.46, Test_accy 58.38
2024-08-31 23:06:56,471 [foster.py] => Task 18, Epoch 33/170 => Loss 5.804, Loss_clf 1.203, Loss_fe 1.241, Loss_kd 3.178, Train_accy 62.12, Test_accy 56.00
2024-08-31 23:07:04,694 [foster.py] => Task 18, Epoch 34/170 => Loss 5.968, Loss_clf 1.379, Loss_fe 1.235, Loss_kd 3.173, Train_accy 62.41, Test_accy 56.78
2024-08-31 23:07:12,828 [foster.py] => Task 18, Epoch 35/170 => Loss 5.813, Loss_clf 1.269, Loss_fe 1.207, Loss_kd 3.157, Train_accy 63.97, Test_accy 56.01
2024-08-31 23:07:18,248 [foster.py] => Task 18, Epoch 36/170 => Loss 5.789, Loss_clf 1.230, Loss_fe 1.210, Loss_kd 3.168, Train_accy 64.04
2024-08-31 23:07:26,320 [foster.py] => Task 18, Epoch 37/170 => Loss 5.658, Loss_clf 1.111, Loss_fe 1.190, Loss_kd 3.174, Train_accy 63.95, Test_accy 57.33
2024-08-31 23:07:34,452 [foster.py] => Task 18, Epoch 38/170 => Loss 5.729, Loss_clf 1.213, Loss_fe 1.177, Loss_kd 3.157, Train_accy 63.86, Test_accy 57.23
2024-08-31 23:07:42,562 [foster.py] => Task 18, Epoch 39/170 => Loss 5.684, Loss_clf 1.163, Loss_fe 1.162, Loss_kd 3.177, Train_accy 65.07, Test_accy 57.68
2024-08-31 23:07:50,765 [foster.py] => Task 18, Epoch 40/170 => Loss 5.704, Loss_clf 1.177, Loss_fe 1.176, Loss_kd 3.169, Train_accy 63.01, Test_accy 57.17
2024-08-31 23:07:56,097 [foster.py] => Task 18, Epoch 41/170 => Loss 5.767, Loss_clf 1.254, Loss_fe 1.167, Loss_kd 3.164, Train_accy 63.24
2024-08-31 23:08:04,304 [foster.py] => Task 18, Epoch 42/170 => Loss 5.719, Loss_clf 1.199, Loss_fe 1.171, Loss_kd 3.167, Train_accy 63.71, Test_accy 57.85
2024-08-31 23:08:12,466 [foster.py] => Task 18, Epoch 43/170 => Loss 5.548, Loss_clf 1.056, Loss_fe 1.152, Loss_kd 3.160, Train_accy 65.04, Test_accy 57.18
2024-08-31 23:08:20,633 [foster.py] => Task 18, Epoch 44/170 => Loss 5.673, Loss_clf 1.182, Loss_fe 1.131, Loss_kd 3.178, Train_accy 62.39, Test_accy 55.89
2024-08-31 23:08:28,895 [foster.py] => Task 18, Epoch 45/170 => Loss 5.537, Loss_clf 1.056, Loss_fe 1.142, Loss_kd 3.158, Train_accy 65.45, Test_accy 57.81
2024-08-31 23:08:34,214 [foster.py] => Task 18, Epoch 46/170 => Loss 5.578, Loss_clf 1.087, Loss_fe 1.143, Loss_kd 3.167, Train_accy 63.28
2024-08-31 23:08:42,390 [foster.py] => Task 18, Epoch 47/170 => Loss 5.449, Loss_clf 1.002, Loss_fe 1.102, Loss_kd 3.164, Train_accy 66.16, Test_accy 58.44
2024-08-31 23:08:50,478 [foster.py] => Task 18, Epoch 48/170 => Loss 5.495, Loss_clf 1.070, Loss_fe 1.083, Loss_kd 3.161, Train_accy 64.96, Test_accy 57.09
2024-08-31 23:08:58,694 [foster.py] => Task 18, Epoch 49/170 => Loss 5.613, Loss_clf 1.151, Loss_fe 1.100, Loss_kd 3.179, Train_accy 63.93, Test_accy 57.86
2024-08-31 23:09:06,796 [foster.py] => Task 18, Epoch 50/170 => Loss 5.481, Loss_clf 1.051, Loss_fe 1.093, Loss_kd 3.156, Train_accy 66.72, Test_accy 57.20
2024-08-31 23:09:12,111 [foster.py] => Task 18, Epoch 51/170 => Loss 5.600, Loss_clf 1.166, Loss_fe 1.092, Loss_kd 3.162, Train_accy 63.93
2024-08-31 23:09:20,282 [foster.py] => Task 18, Epoch 52/170 => Loss 5.531, Loss_clf 1.060, Loss_fe 1.115, Loss_kd 3.174, Train_accy 66.56, Test_accy 56.61
2024-08-31 23:09:28,500 [foster.py] => Task 18, Epoch 53/170 => Loss 5.428, Loss_clf 1.038, Loss_fe 1.048, Loss_kd 3.162, Train_accy 67.05, Test_accy 57.42
2024-08-31 23:09:36,683 [foster.py] => Task 18, Epoch 54/170 => Loss 5.404, Loss_clf 1.028, Loss_fe 1.038, Loss_kd 3.157, Train_accy 65.36, Test_accy 57.67
2024-08-31 23:09:44,882 [foster.py] => Task 18, Epoch 55/170 => Loss 5.498, Loss_clf 1.064, Loss_fe 1.081, Loss_kd 3.172, Train_accy 65.98, Test_accy 55.44
2024-08-31 23:09:50,109 [foster.py] => Task 18, Epoch 56/170 => Loss 5.512, Loss_clf 1.096, Loss_fe 1.066, Loss_kd 3.169, Train_accy 64.71
2024-08-31 23:09:58,224 [foster.py] => Task 18, Epoch 57/170 => Loss 5.423, Loss_clf 1.051, Loss_fe 1.035, Loss_kd 3.156, Train_accy 65.85, Test_accy 57.74
2024-08-31 23:10:06,435 [foster.py] => Task 18, Epoch 58/170 => Loss 5.380, Loss_clf 1.021, Loss_fe 1.026, Loss_kd 3.153, Train_accy 65.92, Test_accy 58.20
2024-08-31 23:10:14,617 [foster.py] => Task 18, Epoch 59/170 => Loss 5.523, Loss_clf 1.122, Loss_fe 1.049, Loss_kd 3.171, Train_accy 64.04, Test_accy 58.78
2024-08-31 23:10:22,843 [foster.py] => Task 18, Epoch 60/170 => Loss 5.427, Loss_clf 1.032, Loss_fe 1.057, Loss_kd 3.157, Train_accy 65.11, Test_accy 56.65
2024-08-31 23:10:28,236 [foster.py] => Task 18, Epoch 61/170 => Loss 5.428, Loss_clf 1.049, Loss_fe 1.034, Loss_kd 3.164, Train_accy 66.52
2024-08-31 23:10:36,344 [foster.py] => Task 18, Epoch 62/170 => Loss 5.417, Loss_clf 1.038, Loss_fe 1.034, Loss_kd 3.164, Train_accy 66.76, Test_accy 57.67
2024-08-31 23:10:44,468 [foster.py] => Task 18, Epoch 63/170 => Loss 5.375, Loss_clf 1.010, Loss_fe 1.015, Loss_kd 3.168, Train_accy 66.96, Test_accy 58.36
2024-08-31 23:10:52,574 [foster.py] => Task 18, Epoch 64/170 => Loss 5.543, Loss_clf 1.154, Loss_fe 1.033, Loss_kd 3.175, Train_accy 63.53, Test_accy 57.48
2024-08-31 23:11:00,696 [foster.py] => Task 18, Epoch 65/170 => Loss 5.429, Loss_clf 1.057, Loss_fe 1.030, Loss_kd 3.161, Train_accy 65.89, Test_accy 59.35
2024-08-31 23:11:05,974 [foster.py] => Task 18, Epoch 66/170 => Loss 5.348, Loss_clf 1.018, Loss_fe 0.990, Loss_kd 3.159, Train_accy 66.83
2024-08-31 23:11:14,181 [foster.py] => Task 18, Epoch 67/170 => Loss 5.324, Loss_clf 0.986, Loss_fe 1.003, Loss_kd 3.154, Train_accy 66.99, Test_accy 58.53
2024-08-31 23:11:22,327 [foster.py] => Task 18, Epoch 68/170 => Loss 5.248, Loss_clf 0.938, Loss_fe 0.970, Loss_kd 3.158, Train_accy 68.28, Test_accy 58.58
2024-08-31 23:11:30,483 [foster.py] => Task 18, Epoch 69/170 => Loss 5.292, Loss_clf 0.966, Loss_fe 0.983, Loss_kd 3.162, Train_accy 66.50, Test_accy 58.42
2024-08-31 23:11:38,654 [foster.py] => Task 18, Epoch 70/170 => Loss 5.310, Loss_clf 0.997, Loss_fe 0.980, Loss_kd 3.152, Train_accy 66.09, Test_accy 58.72
2024-08-31 23:11:43,939 [foster.py] => Task 18, Epoch 71/170 => Loss 5.296, Loss_clf 0.970, Loss_fe 0.982, Loss_kd 3.162, Train_accy 67.10
2024-08-31 23:11:52,024 [foster.py] => Task 18, Epoch 72/170 => Loss 5.393, Loss_clf 1.062, Loss_fe 0.988, Loss_kd 3.163, Train_accy 65.98, Test_accy 58.46
2024-08-31 23:12:00,232 [foster.py] => Task 18, Epoch 73/170 => Loss 5.313, Loss_clf 0.998, Loss_fe 0.978, Loss_kd 3.157, Train_accy 66.00, Test_accy 58.72
2024-08-31 23:12:08,480 [foster.py] => Task 18, Epoch 74/170 => Loss 5.244, Loss_clf 0.948, Loss_fe 0.958, Loss_kd 3.157, Train_accy 67.37, Test_accy 58.17
2024-08-31 23:12:16,665 [foster.py] => Task 18, Epoch 75/170 => Loss 5.300, Loss_clf 0.990, Loss_fe 0.964, Loss_kd 3.165, Train_accy 67.92, Test_accy 58.54
2024-08-31 23:12:21,950 [foster.py] => Task 18, Epoch 76/170 => Loss 5.290, Loss_clf 0.987, Loss_fe 0.958, Loss_kd 3.164, Train_accy 66.83
2024-08-31 23:12:30,111 [foster.py] => Task 18, Epoch 77/170 => Loss 5.272, Loss_clf 0.975, Loss_fe 0.953, Loss_kd 3.163, Train_accy 66.81, Test_accy 58.13
2024-08-31 23:12:38,265 [foster.py] => Task 18, Epoch 78/170 => Loss 5.278, Loss_clf 0.978, Loss_fe 0.964, Loss_kd 3.155, Train_accy 65.85, Test_accy 59.05
2024-08-31 23:12:46,446 [foster.py] => Task 18, Epoch 79/170 => Loss 5.242, Loss_clf 0.966, Loss_fe 0.925, Loss_kd 3.170, Train_accy 67.39, Test_accy 57.14
2024-08-31 23:12:54,703 [foster.py] => Task 18, Epoch 80/170 => Loss 5.333, Loss_clf 1.057, Loss_fe 0.931, Loss_kd 3.164, Train_accy 67.08, Test_accy 53.14
2024-08-31 23:13:00,027 [foster.py] => Task 18, Epoch 81/170 => Loss 5.297, Loss_clf 1.031, Loss_fe 0.928, Loss_kd 3.157, Train_accy 68.62
2024-08-31 23:13:08,281 [foster.py] => Task 18, Epoch 82/170 => Loss 5.238, Loss_clf 0.967, Loss_fe 0.924, Loss_kd 3.165, Train_accy 67.83, Test_accy 58.54
2024-08-31 23:13:16,466 [foster.py] => Task 18, Epoch 83/170 => Loss 5.143, Loss_clf 0.917, Loss_fe 0.894, Loss_kd 3.151, Train_accy 68.44, Test_accy 59.05
2024-08-31 23:13:24,699 [foster.py] => Task 18, Epoch 84/170 => Loss 5.208, Loss_clf 0.964, Loss_fe 0.908, Loss_kd 3.155, Train_accy 67.83, Test_accy 59.04
2024-08-31 23:13:32,844 [foster.py] => Task 18, Epoch 85/170 => Loss 5.179, Loss_clf 0.952, Loss_fe 0.891, Loss_kd 3.155, Train_accy 68.28, Test_accy 57.84
2024-08-31 23:13:38,128 [foster.py] => Task 18, Epoch 86/170 => Loss 5.225, Loss_clf 0.968, Loss_fe 0.918, Loss_kd 3.157, Train_accy 68.10
2024-08-31 23:13:46,301 [foster.py] => Task 18, Epoch 87/170 => Loss 5.183, Loss_clf 0.938, Loss_fe 0.905, Loss_kd 3.159, Train_accy 68.33, Test_accy 58.68
2024-08-31 23:13:54,520 [foster.py] => Task 18, Epoch 88/170 => Loss 5.135, Loss_clf 0.914, Loss_fe 0.872, Loss_kd 3.167, Train_accy 70.04, Test_accy 58.46
2024-08-31 23:14:02,737 [foster.py] => Task 18, Epoch 89/170 => Loss 5.201, Loss_clf 0.958, Loss_fe 0.911, Loss_kd 3.151, Train_accy 67.17, Test_accy 58.41
2024-08-31 23:14:10,860 [foster.py] => Task 18, Epoch 90/170 => Loss 5.219, Loss_clf 0.974, Loss_fe 0.901, Loss_kd 3.163, Train_accy 68.50, Test_accy 58.84
2024-08-31 23:14:16,251 [foster.py] => Task 18, Epoch 91/170 => Loss 5.218, Loss_clf 0.985, Loss_fe 0.890, Loss_kd 3.162, Train_accy 66.85
2024-08-31 23:14:24,422 [foster.py] => Task 18, Epoch 92/170 => Loss 5.174, Loss_clf 0.953, Loss_fe 0.879, Loss_kd 3.160, Train_accy 67.57, Test_accy 58.67
2024-08-31 23:14:32,563 [foster.py] => Task 18, Epoch 93/170 => Loss 5.168, Loss_clf 0.942, Loss_fe 0.877, Loss_kd 3.167, Train_accy 68.88, Test_accy 58.52
2024-08-31 23:14:40,692 [foster.py] => Task 18, Epoch 94/170 => Loss 5.119, Loss_clf 0.912, Loss_fe 0.869, Loss_kd 3.158, Train_accy 68.42, Test_accy 58.72
2024-08-31 23:14:48,864 [foster.py] => Task 18, Epoch 95/170 => Loss 5.036, Loss_clf 0.873, Loss_fe 0.834, Loss_kd 3.149, Train_accy 69.42, Test_accy 59.45
2024-08-31 23:14:54,198 [foster.py] => Task 18, Epoch 96/170 => Loss 5.091, Loss_clf 0.917, Loss_fe 0.847, Loss_kd 3.147, Train_accy 67.72
2024-08-31 23:15:02,348 [foster.py] => Task 18, Epoch 97/170 => Loss 5.096, Loss_clf 0.907, Loss_fe 0.847, Loss_kd 3.160, Train_accy 68.88, Test_accy 59.32
2024-08-31 23:15:10,546 [foster.py] => Task 18, Epoch 98/170 => Loss 5.147, Loss_clf 0.941, Loss_fe 0.862, Loss_kd 3.162, Train_accy 68.08, Test_accy 57.86
2024-08-31 23:15:18,680 [foster.py] => Task 18, Epoch 99/170 => Loss 5.140, Loss_clf 0.950, Loss_fe 0.844, Loss_kd 3.164, Train_accy 68.97, Test_accy 58.95
2024-08-31 23:15:26,838 [foster.py] => Task 18, Epoch 100/170 => Loss 5.134, Loss_clf 0.929, Loss_fe 0.852, Loss_kd 3.171, Train_accy 67.70, Test_accy 59.89
2024-08-31 23:15:32,154 [foster.py] => Task 18, Epoch 101/170 => Loss 5.014, Loss_clf 0.863, Loss_fe 0.810, Loss_kd 3.160, Train_accy 69.67
2024-08-31 23:15:40,286 [foster.py] => Task 18, Epoch 102/170 => Loss 5.057, Loss_clf 0.921, Loss_fe 0.803, Loss_kd 3.153, Train_accy 69.17, Test_accy 58.68
2024-08-31 23:15:48,453 [foster.py] => Task 18, Epoch 103/170 => Loss 5.030, Loss_clf 0.881, Loss_fe 0.814, Loss_kd 3.155, Train_accy 70.51, Test_accy 58.98
2024-08-31 23:15:56,674 [foster.py] => Task 18, Epoch 104/170 => Loss 5.039, Loss_clf 0.903, Loss_fe 0.796, Loss_kd 3.158, Train_accy 69.33, Test_accy 59.14
2024-08-31 23:16:04,815 [foster.py] => Task 18, Epoch 105/170 => Loss 5.052, Loss_clf 0.879, Loss_fe 0.833, Loss_kd 3.159, Train_accy 69.89, Test_accy 59.09
2024-08-31 23:16:10,111 [foster.py] => Task 18, Epoch 106/170 => Loss 5.038, Loss_clf 0.889, Loss_fe 0.800, Loss_kd 3.168, Train_accy 69.29
2024-08-31 23:16:18,263 [foster.py] => Task 18, Epoch 107/170 => Loss 5.003, Loss_clf 0.871, Loss_fe 0.803, Loss_kd 3.149, Train_accy 69.38, Test_accy 59.08
2024-08-31 23:16:26,566 [foster.py] => Task 18, Epoch 108/170 => Loss 4.976, Loss_clf 0.861, Loss_fe 0.778, Loss_kd 3.157, Train_accy 69.62, Test_accy 59.26
2024-08-31 23:16:34,689 [foster.py] => Task 18, Epoch 109/170 => Loss 5.002, Loss_clf 0.877, Loss_fe 0.780, Loss_kd 3.164, Train_accy 68.77, Test_accy 58.61
2024-08-31 23:16:42,801 [foster.py] => Task 18, Epoch 110/170 => Loss 4.943, Loss_clf 0.851, Loss_fe 0.763, Loss_kd 3.148, Train_accy 70.42, Test_accy 59.49
2024-08-31 23:16:48,120 [foster.py] => Task 18, Epoch 111/170 => Loss 4.962, Loss_clf 0.853, Loss_fe 0.777, Loss_kd 3.151, Train_accy 70.56
2024-08-31 23:16:56,254 [foster.py] => Task 18, Epoch 112/170 => Loss 4.961, Loss_clf 0.851, Loss_fe 0.758, Loss_kd 3.170, Train_accy 71.45, Test_accy 59.36
2024-08-31 23:17:04,440 [foster.py] => Task 18, Epoch 113/170 => Loss 4.897, Loss_clf 0.823, Loss_fe 0.740, Loss_kd 3.154, Train_accy 71.63, Test_accy 59.58
2024-08-31 23:17:12,609 [foster.py] => Task 18, Epoch 114/170 => Loss 4.956, Loss_clf 0.858, Loss_fe 0.770, Loss_kd 3.147, Train_accy 69.98, Test_accy 59.56
2024-08-31 23:17:20,717 [foster.py] => Task 18, Epoch 115/170 => Loss 4.909, Loss_clf 0.834, Loss_fe 0.739, Loss_kd 3.155, Train_accy 71.54, Test_accy 59.60
2024-08-31 23:17:26,017 [foster.py] => Task 18, Epoch 116/170 => Loss 4.878, Loss_clf 0.821, Loss_fe 0.725, Loss_kd 3.151, Train_accy 71.74
2024-08-31 23:17:34,233 [foster.py] => Task 18, Epoch 117/170 => Loss 4.879, Loss_clf 0.815, Loss_fe 0.735, Loss_kd 3.148, Train_accy 71.96, Test_accy 59.74
2024-08-31 23:17:42,348 [foster.py] => Task 18, Epoch 118/170 => Loss 4.930, Loss_clf 0.862, Loss_fe 0.723, Loss_kd 3.164, Train_accy 71.94, Test_accy 59.80
2024-08-31 23:17:50,508 [foster.py] => Task 18, Epoch 119/170 => Loss 4.876, Loss_clf 0.835, Loss_fe 0.702, Loss_kd 3.157, Train_accy 72.25, Test_accy 59.54
2024-08-31 23:17:58,680 [foster.py] => Task 18, Epoch 120/170 => Loss 4.901, Loss_clf 0.837, Loss_fe 0.726, Loss_kd 3.157, Train_accy 71.16, Test_accy 59.33
2024-08-31 23:18:04,046 [foster.py] => Task 18, Epoch 121/170 => Loss 4.889, Loss_clf 0.830, Loss_fe 0.713, Loss_kd 3.164, Train_accy 72.34
2024-08-31 23:18:12,235 [foster.py] => Task 18, Epoch 122/170 => Loss 4.830, Loss_clf 0.801, Loss_fe 0.691, Loss_kd 3.157, Train_accy 73.26, Test_accy 58.94
2024-08-31 23:18:20,391 [foster.py] => Task 18, Epoch 123/170 => Loss 4.860, Loss_clf 0.839, Loss_fe 0.688, Loss_kd 3.153, Train_accy 72.25, Test_accy 59.14
2024-08-31 23:18:28,532 [foster.py] => Task 18, Epoch 124/170 => Loss 4.857, Loss_clf 0.819, Loss_fe 0.689, Loss_kd 3.168, Train_accy 71.96, Test_accy 60.19
2024-08-31 23:18:36,674 [foster.py] => Task 18, Epoch 125/170 => Loss 4.825, Loss_clf 0.804, Loss_fe 0.685, Loss_kd 3.155, Train_accy 73.21, Test_accy 59.83
2024-08-31 23:18:41,969 [foster.py] => Task 18, Epoch 126/170 => Loss 4.713, Loss_clf 0.751, Loss_fe 0.646, Loss_kd 3.137, Train_accy 73.53
2024-08-31 23:18:50,151 [foster.py] => Task 18, Epoch 127/170 => Loss 4.788, Loss_clf 0.795, Loss_fe 0.676, Loss_kd 3.137, Train_accy 72.28, Test_accy 59.47
2024-08-31 23:18:58,342 [foster.py] => Task 18, Epoch 128/170 => Loss 4.760, Loss_clf 0.771, Loss_fe 0.651, Loss_kd 3.157, Train_accy 74.35, Test_accy 59.62
2024-08-31 23:19:06,514 [foster.py] => Task 18, Epoch 129/170 => Loss 4.768, Loss_clf 0.780, Loss_fe 0.658, Loss_kd 3.149, Train_accy 73.24, Test_accy 59.82
2024-08-31 23:19:14,742 [foster.py] => Task 18, Epoch 130/170 => Loss 4.777, Loss_clf 0.794, Loss_fe 0.656, Loss_kd 3.147, Train_accy 73.01, Test_accy 60.16
2024-08-31 23:19:20,124 [foster.py] => Task 18, Epoch 131/170 => Loss 4.756, Loss_clf 0.783, Loss_fe 0.629, Loss_kd 3.162, Train_accy 73.50
2024-08-31 23:19:28,317 [foster.py] => Task 18, Epoch 132/170 => Loss 4.756, Loss_clf 0.779, Loss_fe 0.641, Loss_kd 3.155, Train_accy 74.49, Test_accy 60.21
2024-08-31 23:19:36,486 [foster.py] => Task 18, Epoch 133/170 => Loss 4.704, Loss_clf 0.756, Loss_fe 0.630, Loss_kd 3.138, Train_accy 73.55, Test_accy 59.77
2024-08-31 23:19:44,614 [foster.py] => Task 18, Epoch 134/170 => Loss 4.726, Loss_clf 0.763, Loss_fe 0.624, Loss_kd 3.158, Train_accy 74.15, Test_accy 59.75
2024-08-31 23:19:52,834 [foster.py] => Task 18, Epoch 135/170 => Loss 4.686, Loss_clf 0.743, Loss_fe 0.620, Loss_kd 3.143, Train_accy 75.45, Test_accy 60.04
2024-08-31 23:19:58,093 [foster.py] => Task 18, Epoch 136/170 => Loss 4.711, Loss_clf 0.757, Loss_fe 0.617, Loss_kd 3.156, Train_accy 74.11
2024-08-31 23:20:06,281 [foster.py] => Task 18, Epoch 137/170 => Loss 4.696, Loss_clf 0.746, Loss_fe 0.614, Loss_kd 3.156, Train_accy 74.84, Test_accy 59.89
2024-08-31 23:20:14,408 [foster.py] => Task 18, Epoch 138/170 => Loss 4.670, Loss_clf 0.749, Loss_fe 0.587, Loss_kd 3.153, Train_accy 74.84, Test_accy 60.52
2024-08-31 23:20:22,544 [foster.py] => Task 18, Epoch 139/170 => Loss 4.657, Loss_clf 0.738, Loss_fe 0.593, Loss_kd 3.145, Train_accy 75.42, Test_accy 60.13
2024-08-31 23:20:30,698 [foster.py] => Task 18, Epoch 140/170 => Loss 4.666, Loss_clf 0.762, Loss_fe 0.561, Loss_kd 3.161, Train_accy 74.13, Test_accy 59.83
2024-08-31 23:20:36,005 [foster.py] => Task 18, Epoch 141/170 => Loss 4.686, Loss_clf 0.755, Loss_fe 0.596, Loss_kd 3.154, Train_accy 75.31
2024-08-31 23:20:44,161 [foster.py] => Task 18, Epoch 142/170 => Loss 4.669, Loss_clf 0.744, Loss_fe 0.592, Loss_kd 3.153, Train_accy 75.89, Test_accy 60.39
2024-08-31 23:20:52,424 [foster.py] => Task 18, Epoch 143/170 => Loss 4.661, Loss_clf 0.751, Loss_fe 0.567, Loss_kd 3.162, Train_accy 75.71, Test_accy 60.18
2024-08-31 23:21:00,566 [foster.py] => Task 18, Epoch 144/170 => Loss 4.625, Loss_clf 0.744, Loss_fe 0.547, Loss_kd 3.154, Train_accy 75.42, Test_accy 59.89
2024-08-31 23:21:08,727 [foster.py] => Task 18, Epoch 145/170 => Loss 4.599, Loss_clf 0.714, Loss_fe 0.559, Loss_kd 3.146, Train_accy 76.43, Test_accy 60.22
2024-08-31 23:21:14,057 [foster.py] => Task 18, Epoch 146/170 => Loss 4.598, Loss_clf 0.715, Loss_fe 0.550, Loss_kd 3.153, Train_accy 75.62
2024-08-31 23:21:22,168 [foster.py] => Task 18, Epoch 147/170 => Loss 4.609, Loss_clf 0.725, Loss_fe 0.527, Loss_kd 3.175, Train_accy 76.38, Test_accy 60.21
2024-08-31 23:21:30,365 [foster.py] => Task 18, Epoch 148/170 => Loss 4.507, Loss_clf 0.674, Loss_fe 0.505, Loss_kd 3.148, Train_accy 76.94, Test_accy 60.28
2024-08-31 23:21:38,498 [foster.py] => Task 18, Epoch 149/170 => Loss 4.569, Loss_clf 0.703, Loss_fe 0.535, Loss_kd 3.151, Train_accy 77.77, Test_accy 60.39
2024-08-31 23:21:46,719 [foster.py] => Task 18, Epoch 150/170 => Loss 4.558, Loss_clf 0.708, Loss_fe 0.509, Loss_kd 3.161, Train_accy 77.05, Test_accy 60.21
2024-08-31 23:21:52,073 [foster.py] => Task 18, Epoch 151/170 => Loss 4.535, Loss_clf 0.704, Loss_fe 0.497, Loss_kd 3.153, Train_accy 77.72
2024-08-31 23:22:00,208 [foster.py] => Task 18, Epoch 152/170 => Loss 4.540, Loss_clf 0.687, Loss_fe 0.503, Loss_kd 3.168, Train_accy 78.30, Test_accy 60.17
2024-08-31 23:22:08,328 [foster.py] => Task 18, Epoch 153/170 => Loss 4.552, Loss_clf 0.701, Loss_fe 0.512, Loss_kd 3.158, Train_accy 77.34, Test_accy 60.27
2024-08-31 23:22:16,527 [foster.py] => Task 18, Epoch 154/170 => Loss 4.505, Loss_clf 0.686, Loss_fe 0.496, Loss_kd 3.143, Train_accy 78.21, Test_accy 60.24
2024-08-31 23:22:24,649 [foster.py] => Task 18, Epoch 155/170 => Loss 4.513, Loss_clf 0.686, Loss_fe 0.493, Loss_kd 3.153, Train_accy 77.21, Test_accy 60.09
2024-08-31 23:22:29,925 [foster.py] => Task 18, Epoch 156/170 => Loss 4.530, Loss_clf 0.693, Loss_fe 0.506, Loss_kd 3.151, Train_accy 77.77
2024-08-31 23:22:38,055 [foster.py] => Task 18, Epoch 157/170 => Loss 4.561, Loss_clf 0.709, Loss_fe 0.501, Loss_kd 3.169, Train_accy 77.05, Test_accy 60.21
2024-08-31 23:22:46,230 [foster.py] => Task 18, Epoch 158/170 => Loss 4.514, Loss_clf 0.687, Loss_fe 0.487, Loss_kd 3.159, Train_accy 77.77, Test_accy 60.29
2024-08-31 23:22:54,345 [foster.py] => Task 18, Epoch 159/170 => Loss 4.516, Loss_clf 0.683, Loss_fe 0.487, Loss_kd 3.165, Train_accy 78.17, Test_accy 60.16
2024-08-31 23:23:02,531 [foster.py] => Task 18, Epoch 160/170 => Loss 4.532, Loss_clf 0.697, Loss_fe 0.494, Loss_kd 3.159, Train_accy 78.46, Test_accy 60.46
2024-08-31 23:23:07,775 [foster.py] => Task 18, Epoch 161/170 => Loss 4.503, Loss_clf 0.688, Loss_fe 0.492, Loss_kd 3.143, Train_accy 77.68
2024-08-31 23:23:15,913 [foster.py] => Task 18, Epoch 162/170 => Loss 4.437, Loss_clf 0.649, Loss_fe 0.451, Loss_kd 3.156, Train_accy 79.44, Test_accy 60.27
2024-08-31 23:23:24,146 [foster.py] => Task 18, Epoch 163/170 => Loss 4.485, Loss_clf 0.667, Loss_fe 0.477, Loss_kd 3.160, Train_accy 78.73, Test_accy 60.35
2024-08-31 23:23:32,276 [foster.py] => Task 18, Epoch 164/170 => Loss 4.418, Loss_clf 0.640, Loss_fe 0.462, Loss_kd 3.137, Train_accy 79.33, Test_accy 60.31
2024-08-31 23:23:40,477 [foster.py] => Task 18, Epoch 165/170 => Loss 4.458, Loss_clf 0.662, Loss_fe 0.470, Loss_kd 3.146, Train_accy 78.48, Test_accy 60.33
2024-08-31 23:23:45,824 [foster.py] => Task 18, Epoch 166/170 => Loss 4.497, Loss_clf 0.682, Loss_fe 0.468, Loss_kd 3.165, Train_accy 77.92
2024-08-31 23:23:54,044 [foster.py] => Task 18, Epoch 167/170 => Loss 4.473, Loss_clf 0.668, Loss_fe 0.473, Loss_kd 3.152, Train_accy 78.66, Test_accy 60.33
2024-08-31 23:24:02,263 [foster.py] => Task 18, Epoch 168/170 => Loss 4.497, Loss_clf 0.681, Loss_fe 0.463, Loss_kd 3.172, Train_accy 78.77, Test_accy 60.38
2024-08-31 23:24:10,422 [foster.py] => Task 18, Epoch 169/170 => Loss 4.465, Loss_clf 0.672, Loss_fe 0.453, Loss_kd 3.159, Train_accy 78.86, Test_accy 60.46
2024-08-31 23:24:18,671 [foster.py] => Task 18, Epoch 170/170 => Loss 4.460, Loss_clf 0.668, Loss_fe 0.461, Loss_kd 3.151, Train_accy 78.50, Test_accy 60.40
2024-08-31 23:24:18,676 [foster.py] => do not weight align teacher!
2024-08-31 23:24:18,680 [foster.py] => per cls weights : [1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815 1.03014815
 0.45733335 0.45733335 0.45733335 0.45733335 0.45733335]
2024-08-31 23:24:28,571 [foster.py] => SNet: Task 18, Epoch 1/130 => Loss 31.806,  Loss1 0.776, Train_accy 39.75, Test_accy 57.76
2024-08-31 23:24:36,025 [foster.py] => SNet: Task 18, Epoch 2/130 => Loss 31.715,  Loss1 0.776, Train_accy 45.07
2024-08-31 23:24:43,526 [foster.py] => SNet: Task 18, Epoch 3/130 => Loss 31.715,  Loss1 0.775, Train_accy 48.84
2024-08-31 23:24:50,647 [foster.py] => SNet: Task 18, Epoch 4/130 => Loss 31.698,  Loss1 0.775, Train_accy 50.78
2024-08-31 23:24:57,908 [foster.py] => SNet: Task 18, Epoch 5/130 => Loss 31.682,  Loss1 0.775, Train_accy 52.43
2024-08-31 23:25:07,591 [foster.py] => SNet: Task 18, Epoch 6/130 => Loss 31.681,  Loss1 0.775, Train_accy 54.35, Test_accy 58.66
2024-08-31 23:25:14,917 [foster.py] => SNet: Task 18, Epoch 7/130 => Loss 31.713,  Loss1 0.775, Train_accy 54.73
2024-08-31 23:25:22,444 [foster.py] => SNet: Task 18, Epoch 8/130 => Loss 31.691,  Loss1 0.775, Train_accy 55.02
2024-08-31 23:25:29,939 [foster.py] => SNet: Task 18, Epoch 9/130 => Loss 31.690,  Loss1 0.775, Train_accy 55.09
2024-08-31 23:25:37,254 [foster.py] => SNet: Task 18, Epoch 10/130 => Loss 31.668,  Loss1 0.775, Train_accy 56.14
2024-08-31 23:25:47,201 [foster.py] => SNet: Task 18, Epoch 11/130 => Loss 31.710,  Loss1 0.774, Train_accy 57.34, Test_accy 58.85
2024-08-31 23:25:54,592 [foster.py] => SNet: Task 18, Epoch 12/130 => Loss 31.709,  Loss1 0.775, Train_accy 57.10
2024-08-31 23:26:02,251 [foster.py] => SNet: Task 18, Epoch 13/130 => Loss 31.671,  Loss1 0.775, Train_accy 58.79
2024-08-31 23:26:09,723 [foster.py] => SNet: Task 18, Epoch 14/130 => Loss 31.709,  Loss1 0.775, Train_accy 57.68
2024-08-31 23:26:17,005 [foster.py] => SNet: Task 18, Epoch 15/130 => Loss 31.690,  Loss1 0.774, Train_accy 57.99
2024-08-31 23:26:26,765 [foster.py] => SNet: Task 18, Epoch 16/130 => Loss 31.649,  Loss1 0.775, Train_accy 59.35, Test_accy 59.66
2024-08-31 23:26:34,212 [foster.py] => SNet: Task 18, Epoch 17/130 => Loss 31.690,  Loss1 0.775, Train_accy 59.13
2024-08-31 23:26:41,356 [foster.py] => SNet: Task 18, Epoch 18/130 => Loss 31.699,  Loss1 0.774, Train_accy 59.04
2024-08-31 23:26:48,718 [foster.py] => SNet: Task 18, Epoch 19/130 => Loss 31.674,  Loss1 0.774, Train_accy 58.48
2024-08-31 23:26:56,091 [foster.py] => SNet: Task 18, Epoch 20/130 => Loss 31.697,  Loss1 0.774, Train_accy 58.28
2024-08-31 23:27:05,961 [foster.py] => SNet: Task 18, Epoch 21/130 => Loss 31.662,  Loss1 0.774, Train_accy 58.04, Test_accy 59.15
2024-08-31 23:27:13,173 [foster.py] => SNet: Task 18, Epoch 22/130 => Loss 31.685,  Loss1 0.775, Train_accy 58.84
2024-08-31 23:27:20,596 [foster.py] => SNet: Task 18, Epoch 23/130 => Loss 31.701,  Loss1 0.775, Train_accy 58.91
2024-08-31 23:27:27,766 [foster.py] => SNet: Task 18, Epoch 24/130 => Loss 31.712,  Loss1 0.774, Train_accy 59.49
2024-08-31 23:27:34,937 [foster.py] => SNet: Task 18, Epoch 25/130 => Loss 31.661,  Loss1 0.774, Train_accy 60.92
2024-08-31 23:27:44,676 [foster.py] => SNet: Task 18, Epoch 26/130 => Loss 31.668,  Loss1 0.775, Train_accy 59.33, Test_accy 59.63
2024-08-31 23:27:52,007 [foster.py] => SNet: Task 18, Epoch 27/130 => Loss 31.661,  Loss1 0.775, Train_accy 60.42
2024-08-31 23:27:59,484 [foster.py] => SNet: Task 18, Epoch 28/130 => Loss 31.642,  Loss1 0.774, Train_accy 60.42
2024-08-31 23:28:06,973 [foster.py] => SNet: Task 18, Epoch 29/130 => Loss 31.685,  Loss1 0.774, Train_accy 60.33
2024-08-31 23:28:14,460 [foster.py] => SNet: Task 18, Epoch 30/130 => Loss 31.694,  Loss1 0.774, Train_accy 59.53
2024-08-31 23:28:24,560 [foster.py] => SNet: Task 18, Epoch 31/130 => Loss 31.665,  Loss1 0.774, Train_accy 61.25, Test_accy 59.09
2024-08-31 23:28:32,016 [foster.py] => SNet: Task 18, Epoch 32/130 => Loss 31.692,  Loss1 0.774, Train_accy 60.74
2024-08-31 23:28:39,267 [foster.py] => SNet: Task 18, Epoch 33/130 => Loss 31.662,  Loss1 0.775, Train_accy 60.98
2024-08-31 23:28:46,578 [foster.py] => SNet: Task 18, Epoch 34/130 => Loss 31.692,  Loss1 0.774, Train_accy 60.76
2024-08-31 23:28:54,030 [foster.py] => SNet: Task 18, Epoch 35/130 => Loss 31.675,  Loss1 0.775, Train_accy 61.72
2024-08-31 23:29:03,688 [foster.py] => SNet: Task 18, Epoch 36/130 => Loss 31.671,  Loss1 0.774, Train_accy 61.74, Test_accy 59.43
2024-08-31 23:29:10,946 [foster.py] => SNet: Task 18, Epoch 37/130 => Loss 31.685,  Loss1 0.775, Train_accy 60.27
2024-08-31 23:29:18,389 [foster.py] => SNet: Task 18, Epoch 38/130 => Loss 31.679,  Loss1 0.774, Train_accy 60.94
2024-08-31 23:29:25,501 [foster.py] => SNet: Task 18, Epoch 39/130 => Loss 31.652,  Loss1 0.774, Train_accy 61.07
2024-08-31 23:29:32,726 [foster.py] => SNet: Task 18, Epoch 40/130 => Loss 31.661,  Loss1 0.774, Train_accy 61.23
2024-08-31 23:29:42,442 [foster.py] => SNet: Task 18, Epoch 41/130 => Loss 31.688,  Loss1 0.774, Train_accy 61.05, Test_accy 59.93
2024-08-31 23:29:50,228 [foster.py] => SNet: Task 18, Epoch 42/130 => Loss 31.680,  Loss1 0.774, Train_accy 60.27
2024-08-31 23:29:57,343 [foster.py] => SNet: Task 18, Epoch 43/130 => Loss 31.676,  Loss1 0.774, Train_accy 61.54
2024-08-31 23:30:04,660 [foster.py] => SNet: Task 18, Epoch 44/130 => Loss 31.691,  Loss1 0.774, Train_accy 60.80
2024-08-31 23:30:12,134 [foster.py] => SNet: Task 18, Epoch 45/130 => Loss 31.644,  Loss1 0.774, Train_accy 61.18
2024-08-31 23:30:21,852 [foster.py] => SNet: Task 18, Epoch 46/130 => Loss 31.661,  Loss1 0.774, Train_accy 62.30, Test_accy 59.25
2024-08-31 23:30:29,247 [foster.py] => SNet: Task 18, Epoch 47/130 => Loss 31.665,  Loss1 0.774, Train_accy 61.27
2024-08-31 23:30:36,599 [foster.py] => SNet: Task 18, Epoch 48/130 => Loss 31.651,  Loss1 0.774, Train_accy 62.63
2024-08-31 23:30:43,999 [foster.py] => SNet: Task 18, Epoch 49/130 => Loss 31.691,  Loss1 0.775, Train_accy 61.90
2024-08-31 23:30:51,544 [foster.py] => SNet: Task 18, Epoch 50/130 => Loss 31.669,  Loss1 0.774, Train_accy 60.96
2024-08-31 23:31:01,413 [foster.py] => SNet: Task 18, Epoch 51/130 => Loss 31.672,  Loss1 0.774, Train_accy 61.76, Test_accy 59.47
2024-08-31 23:31:08,533 [foster.py] => SNet: Task 18, Epoch 52/130 => Loss 31.662,  Loss1 0.774, Train_accy 60.27
2024-08-31 23:31:15,833 [foster.py] => SNet: Task 18, Epoch 53/130 => Loss 31.687,  Loss1 0.774, Train_accy 62.01
2024-08-31 23:31:23,563 [foster.py] => SNet: Task 18, Epoch 54/130 => Loss 31.667,  Loss1 0.774, Train_accy 61.03
2024-08-31 23:31:30,766 [foster.py] => SNet: Task 18, Epoch 55/130 => Loss 31.671,  Loss1 0.774, Train_accy 62.70
2024-08-31 23:31:40,906 [foster.py] => SNet: Task 18, Epoch 56/130 => Loss 31.674,  Loss1 0.774, Train_accy 61.67, Test_accy 59.92
2024-08-31 23:31:48,343 [foster.py] => SNet: Task 18, Epoch 57/130 => Loss 31.651,  Loss1 0.774, Train_accy 62.83
2024-08-31 23:31:56,007 [foster.py] => SNet: Task 18, Epoch 58/130 => Loss 31.667,  Loss1 0.774, Train_accy 61.47
2024-08-31 23:32:03,213 [foster.py] => SNet: Task 18, Epoch 59/130 => Loss 31.662,  Loss1 0.774, Train_accy 61.79
2024-08-31 23:32:10,598 [foster.py] => SNet: Task 18, Epoch 60/130 => Loss 31.652,  Loss1 0.774, Train_accy 62.08
2024-08-31 23:32:20,611 [foster.py] => SNet: Task 18, Epoch 61/130 => Loss 31.681,  Loss1 0.774, Train_accy 62.34, Test_accy 59.81
2024-08-31 23:32:28,160 [foster.py] => SNet: Task 18, Epoch 62/130 => Loss 31.685,  Loss1 0.775, Train_accy 61.96
2024-08-31 23:32:35,708 [foster.py] => SNet: Task 18, Epoch 63/130 => Loss 31.643,  Loss1 0.774, Train_accy 62.43
2024-08-31 23:32:42,760 [foster.py] => SNet: Task 18, Epoch 64/130 => Loss 31.677,  Loss1 0.774, Train_accy 61.61
2024-08-31 23:32:50,121 [foster.py] => SNet: Task 18, Epoch 65/130 => Loss 31.698,  Loss1 0.774, Train_accy 61.27
2024-08-31 23:32:59,842 [foster.py] => SNet: Task 18, Epoch 66/130 => Loss 31.681,  Loss1 0.774, Train_accy 62.97, Test_accy 59.78
2024-08-31 23:33:07,036 [foster.py] => SNet: Task 18, Epoch 67/130 => Loss 31.674,  Loss1 0.774, Train_accy 61.79
2024-08-31 23:33:14,445 [foster.py] => SNet: Task 18, Epoch 68/130 => Loss 31.642,  Loss1 0.774, Train_accy 61.72
2024-08-31 23:33:21,751 [foster.py] => SNet: Task 18, Epoch 69/130 => Loss 31.653,  Loss1 0.774, Train_accy 62.25
2024-08-31 23:33:29,271 [foster.py] => SNet: Task 18, Epoch 70/130 => Loss 31.662,  Loss1 0.774, Train_accy 62.03
2024-08-31 23:33:38,906 [foster.py] => SNet: Task 18, Epoch 71/130 => Loss 31.664,  Loss1 0.774, Train_accy 61.18, Test_accy 59.75
2024-08-31 23:33:46,293 [foster.py] => SNet: Task 18, Epoch 72/130 => Loss 31.694,  Loss1 0.774, Train_accy 62.59
2024-08-31 23:33:53,465 [foster.py] => SNet: Task 18, Epoch 73/130 => Loss 31.668,  Loss1 0.774, Train_accy 61.43
2024-08-31 23:34:00,508 [foster.py] => SNet: Task 18, Epoch 74/130 => Loss 31.671,  Loss1 0.774, Train_accy 62.41
2024-08-31 23:34:07,682 [foster.py] => SNet: Task 18, Epoch 75/130 => Loss 31.666,  Loss1 0.774, Train_accy 62.14
2024-08-31 23:34:17,344 [foster.py] => SNet: Task 18, Epoch 76/130 => Loss 31.653,  Loss1 0.774, Train_accy 62.28, Test_accy 60.34
2024-08-31 23:34:24,552 [foster.py] => SNet: Task 18, Epoch 77/130 => Loss 31.663,  Loss1 0.775, Train_accy 62.43
2024-08-31 23:34:31,896 [foster.py] => SNet: Task 18, Epoch 78/130 => Loss 31.670,  Loss1 0.774, Train_accy 61.34
2024-08-31 23:34:39,157 [foster.py] => SNet: Task 18, Epoch 79/130 => Loss 31.680,  Loss1 0.774, Train_accy 63.28
2024-08-31 23:34:46,228 [foster.py] => SNet: Task 18, Epoch 80/130 => Loss 31.654,  Loss1 0.774, Train_accy 62.59
2024-08-31 23:34:56,196 [foster.py] => SNet: Task 18, Epoch 81/130 => Loss 31.659,  Loss1 0.774, Train_accy 62.86, Test_accy 59.74
2024-08-31 23:35:03,488 [foster.py] => SNet: Task 18, Epoch 82/130 => Loss 31.642,  Loss1 0.774, Train_accy 61.45
2024-08-31 23:35:10,802 [foster.py] => SNet: Task 18, Epoch 83/130 => Loss 31.672,  Loss1 0.774, Train_accy 62.39
2024-08-31 23:35:18,272 [foster.py] => SNet: Task 18, Epoch 84/130 => Loss 31.654,  Loss1 0.774, Train_accy 62.81
2024-08-31 23:35:25,602 [foster.py] => SNet: Task 18, Epoch 85/130 => Loss 31.666,  Loss1 0.774, Train_accy 62.50
2024-08-31 23:35:35,673 [foster.py] => SNet: Task 18, Epoch 86/130 => Loss 31.680,  Loss1 0.774, Train_accy 61.94, Test_accy 60.28
2024-08-31 23:35:43,159 [foster.py] => SNet: Task 18, Epoch 87/130 => Loss 31.663,  Loss1 0.774, Train_accy 62.90
2024-08-31 23:35:50,323 [foster.py] => SNet: Task 18, Epoch 88/130 => Loss 31.665,  Loss1 0.774, Train_accy 62.30
2024-08-31 23:35:57,617 [foster.py] => SNet: Task 18, Epoch 89/130 => Loss 31.644,  Loss1 0.774, Train_accy 62.43
2024-08-31 23:36:05,008 [foster.py] => SNet: Task 18, Epoch 90/130 => Loss 31.671,  Loss1 0.774, Train_accy 63.71
2024-08-31 23:36:14,922 [foster.py] => SNet: Task 18, Epoch 91/130 => Loss 31.666,  Loss1 0.774, Train_accy 62.10, Test_accy 60.19
2024-08-31 23:36:22,527 [foster.py] => SNet: Task 18, Epoch 92/130 => Loss 31.678,  Loss1 0.774, Train_accy 62.50
2024-08-31 23:36:29,689 [foster.py] => SNet: Task 18, Epoch 93/130 => Loss 31.660,  Loss1 0.774, Train_accy 63.04
2024-08-31 23:36:36,762 [foster.py] => SNet: Task 18, Epoch 94/130 => Loss 31.672,  Loss1 0.774, Train_accy 61.72
2024-08-31 23:36:44,537 [foster.py] => SNet: Task 18, Epoch 95/130 => Loss 31.634,  Loss1 0.774, Train_accy 62.10
2024-08-31 23:36:54,256 [foster.py] => SNet: Task 18, Epoch 96/130 => Loss 31.669,  Loss1 0.774, Train_accy 62.83, Test_accy 60.01
2024-08-31 23:37:01,728 [foster.py] => SNet: Task 18, Epoch 97/130 => Loss 31.647,  Loss1 0.774, Train_accy 63.04
2024-08-31 23:37:08,912 [foster.py] => SNet: Task 18, Epoch 98/130 => Loss 31.701,  Loss1 0.774, Train_accy 62.57
2024-08-31 23:37:16,218 [foster.py] => SNet: Task 18, Epoch 99/130 => Loss 31.682,  Loss1 0.774, Train_accy 62.79
2024-08-31 23:37:23,384 [foster.py] => SNet: Task 18, Epoch 100/130 => Loss 31.651,  Loss1 0.774, Train_accy 62.52
2024-08-31 23:37:33,135 [foster.py] => SNet: Task 18, Epoch 101/130 => Loss 31.666,  Loss1 0.774, Train_accy 62.77, Test_accy 60.08
2024-08-31 23:37:40,356 [foster.py] => SNet: Task 18, Epoch 102/130 => Loss 31.643,  Loss1 0.774, Train_accy 62.83
2024-08-31 23:37:47,526 [foster.py] => SNet: Task 18, Epoch 103/130 => Loss 31.681,  Loss1 0.774, Train_accy 63.06
2024-08-31 23:37:54,617 [foster.py] => SNet: Task 18, Epoch 104/130 => Loss 31.662,  Loss1 0.774, Train_accy 61.70
2024-08-31 23:38:02,160 [foster.py] => SNet: Task 18, Epoch 105/130 => Loss 31.685,  Loss1 0.774, Train_accy 62.05
2024-08-31 23:38:12,064 [foster.py] => SNet: Task 18, Epoch 106/130 => Loss 31.694,  Loss1 0.774, Train_accy 62.46, Test_accy 60.21
2024-08-31 23:38:19,311 [foster.py] => SNet: Task 18, Epoch 107/130 => Loss 31.643,  Loss1 0.774, Train_accy 62.72
2024-08-31 23:38:26,698 [foster.py] => SNet: Task 18, Epoch 108/130 => Loss 31.672,  Loss1 0.774, Train_accy 62.72
2024-08-31 23:38:33,828 [foster.py] => SNet: Task 18, Epoch 109/130 => Loss 31.656,  Loss1 0.774, Train_accy 62.30
2024-08-31 23:38:41,309 [foster.py] => SNet: Task 18, Epoch 110/130 => Loss 31.669,  Loss1 0.774, Train_accy 61.83
2024-08-31 23:38:51,073 [foster.py] => SNet: Task 18, Epoch 111/130 => Loss 31.687,  Loss1 0.774, Train_accy 62.48, Test_accy 60.16
2024-08-31 23:38:58,463 [foster.py] => SNet: Task 18, Epoch 112/130 => Loss 31.671,  Loss1 0.774, Train_accy 62.68
2024-08-31 23:39:05,887 [foster.py] => SNet: Task 18, Epoch 113/130 => Loss 31.655,  Loss1 0.774, Train_accy 63.42
2024-08-31 23:39:13,240 [foster.py] => SNet: Task 18, Epoch 114/130 => Loss 31.670,  Loss1 0.774, Train_accy 62.41
2024-08-31 23:39:20,364 [foster.py] => SNet: Task 18, Epoch 115/130 => Loss 31.650,  Loss1 0.774, Train_accy 62.92
2024-08-31 23:39:30,384 [foster.py] => SNet: Task 18, Epoch 116/130 => Loss 31.663,  Loss1 0.774, Train_accy 62.43, Test_accy 60.12
2024-08-31 23:39:37,456 [foster.py] => SNet: Task 18, Epoch 117/130 => Loss 31.650,  Loss1 0.774, Train_accy 63.59
2024-08-31 23:39:45,012 [foster.py] => SNet: Task 18, Epoch 118/130 => Loss 31.656,  Loss1 0.774, Train_accy 61.74
2024-08-31 23:39:52,352 [foster.py] => SNet: Task 18, Epoch 119/130 => Loss 31.652,  Loss1 0.774, Train_accy 62.57
2024-08-31 23:39:59,831 [foster.py] => SNet: Task 18, Epoch 120/130 => Loss 31.671,  Loss1 0.774, Train_accy 62.34
2024-08-31 23:40:09,844 [foster.py] => SNet: Task 18, Epoch 121/130 => Loss 31.674,  Loss1 0.774, Train_accy 62.10, Test_accy 60.13
2024-08-31 23:40:17,018 [foster.py] => SNet: Task 18, Epoch 122/130 => Loss 31.671,  Loss1 0.774, Train_accy 62.66
2024-08-31 23:40:24,351 [foster.py] => SNet: Task 18, Epoch 123/130 => Loss 31.692,  Loss1 0.774, Train_accy 63.10
2024-08-31 23:40:31,975 [foster.py] => SNet: Task 18, Epoch 124/130 => Loss 31.667,  Loss1 0.774, Train_accy 63.82
2024-08-31 23:40:39,503 [foster.py] => SNet: Task 18, Epoch 125/130 => Loss 31.687,  Loss1 0.774, Train_accy 61.56
2024-08-31 23:40:49,190 [foster.py] => SNet: Task 18, Epoch 126/130 => Loss 31.674,  Loss1 0.774, Train_accy 63.15, Test_accy 60.05
2024-08-31 23:40:56,356 [foster.py] => SNet: Task 18, Epoch 127/130 => Loss 31.688,  Loss1 0.774, Train_accy 62.63
2024-08-31 23:41:04,131 [foster.py] => SNet: Task 18, Epoch 128/130 => Loss 31.660,  Loss1 0.774, Train_accy 62.86
2024-08-31 23:41:11,541 [foster.py] => SNet: Task 18, Epoch 129/130 => Loss 31.651,  Loss1 0.774, Train_accy 62.86
2024-08-31 23:41:19,093 [foster.py] => SNet: Task 18, Epoch 130/130 => Loss 31.682,  Loss1 0.774, Train_accy 62.77
2024-08-31 23:41:19,093 [foster.py] => do not weight align student!
2024-08-31 23:41:21,685 [foster.py] => darknet eval: 
2024-08-31 23:41:21,686 [foster.py] => CNN top1 curve: 60.23
2024-08-31 23:41:21,686 [foster.py] => CNN top5 curve: 86.77
2024-08-31 23:41:21,686 [foster.py] => CNN top1 平均值: 60.23
2024-08-31 23:41:21,691 [foster.py] => timees : 2314.627806663513
2024-08-31 23:41:21,693 [base.py] => Reducing exemplars...(21 per classes)
2024-08-31 23:41:53,191 [base.py] => Constructing exemplars...(21 per classes)
2024-08-31 23:42:04,394 [foster.py] => Exemplar size: 1995
2024-08-31 23:42:04,395 [trainer.py] => CNN: {'total': 60.4, '00-09': 58.4, '10-19': 42.3, '20-29': 60.5, '30-39': 55.3, '40-49': 65.4, '50-59': 55.2, '60-69': 67.7, '70-79': 61.5, '80-89': 71.3, '90-99': 72.4, 'old': 59.73, 'new': 72.4}
2024-08-31 23:42:04,395 [trainer.py] => NME: {'total': 54.56, '00-09': 47.8, '10-19': 34.8, '20-29': 53.7, '30-39': 48.6, '40-49': 61.1, '50-59': 51.1, '60-69': 62.4, '70-79': 61.1, '80-89': 61.5, '90-99': 72.4, 'old': 53.57, 'new': 72.4}
2024-08-31 23:42:04,396 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85, 63.39, 62.78, 61.57, 60.4]
2024-08-31 23:42:04,396 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96, 88.72, 88.04, 87.48, 86.41]
2024-08-31 23:42:04,396 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17, 56.89, 56.42, 55.28, 54.56]
2024-08-31 23:42:04,397 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84, 84.65, 84.15, 82.79, 82.0]

2024-08-31 23:42:04,397 [trainer.py] => CNN top1 平均值: 74.44
2024-08-31 23:42:04,400 [trainer.py] => All params: 1306828
2024-08-31 23:42:04,403 [trainer.py] => Trainable params: 659704
2024-08-31 23:42:04,467 [foster.py] => Learning on 95-100
2024-08-31 23:42:04,471 [foster.py] => All params: 1308123
2024-08-31 23:42:04,473 [foster.py] => Trainable params: 660674
2024-08-31 23:42:04,528 [foster.py] => per cls weights : [1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666
 1.01874666 1.01874666 1.01874666 1.01874666 1.01874666 0.64381343
 0.64381343 0.64381343 0.64381343 0.64381343]
2024-08-31 23:42:09,951 [foster.py] => Task 19, Epoch 1/170 => Loss 9.479, Loss_clf 4.065, Loss_fe 1.946, Loss_kd 3.285, Train_accy 51.32
2024-08-31 23:42:18,450 [foster.py] => Task 19, Epoch 2/170 => Loss 6.521, Loss_clf 1.575, Loss_fe 1.491, Loss_kd 3.274, Train_accy 62.36, Test_accy 54.58
2024-08-31 23:42:26,803 [foster.py] => Task 19, Epoch 3/170 => Loss 6.002, Loss_clf 1.281, Loss_fe 1.299, Loss_kd 3.243, Train_accy 63.87, Test_accy 54.56
2024-08-31 23:42:35,141 [foster.py] => Task 19, Epoch 4/170 => Loss 5.972, Loss_clf 1.297, Loss_fe 1.237, Loss_kd 3.258, Train_accy 64.14, Test_accy 53.50
2024-08-31 23:42:43,499 [foster.py] => Task 19, Epoch 5/170 => Loss 5.827, Loss_clf 1.221, Loss_fe 1.147, Loss_kd 3.278, Train_accy 62.91, Test_accy 54.68
2024-08-31 23:42:48,928 [foster.py] => Task 19, Epoch 6/170 => Loss 5.841, Loss_clf 1.275, Loss_fe 1.129, Loss_kd 3.257, Train_accy 63.27
2024-08-31 23:42:57,294 [foster.py] => Task 19, Epoch 7/170 => Loss 5.691, Loss_clf 1.179, Loss_fe 1.077, Loss_kd 3.256, Train_accy 64.87, Test_accy 54.66
2024-08-31 23:43:05,635 [foster.py] => Task 19, Epoch 8/170 => Loss 5.768, Loss_clf 1.271, Loss_fe 1.053, Loss_kd 3.264, Train_accy 63.89, Test_accy 57.92
2024-08-31 23:43:13,973 [foster.py] => Task 19, Epoch 9/170 => Loss 5.642, Loss_clf 1.138, Loss_fe 1.040, Loss_kd 3.284, Train_accy 65.18, Test_accy 57.04
2024-08-31 23:43:22,363 [foster.py] => Task 19, Epoch 10/170 => Loss 5.425, Loss_clf 1.018, Loss_fe 0.963, Loss_kd 3.264, Train_accy 67.21, Test_accy 48.85
2024-08-31 23:43:27,856 [foster.py] => Task 19, Epoch 11/170 => Loss 5.831, Loss_clf 1.349, Loss_fe 1.036, Loss_kd 3.267, Train_accy 63.03
2024-08-31 23:43:36,243 [foster.py] => Task 19, Epoch 12/170 => Loss 5.801, Loss_clf 1.312, Loss_fe 1.039, Loss_kd 3.270, Train_accy 65.01, Test_accy 55.10
2024-08-31 23:43:44,584 [foster.py] => Task 19, Epoch 13/170 => Loss 5.699, Loss_clf 1.234, Loss_fe 1.022, Loss_kd 3.264, Train_accy 65.72, Test_accy 53.78
2024-08-31 23:43:52,946 [foster.py] => Task 19, Epoch 14/170 => Loss 5.640, Loss_clf 1.231, Loss_fe 0.964, Loss_kd 3.267, Train_accy 65.43, Test_accy 56.39
2024-08-31 23:44:01,337 [foster.py] => Task 19, Epoch 15/170 => Loss 5.681, Loss_clf 1.245, Loss_fe 0.997, Loss_kd 3.261, Train_accy 65.56, Test_accy 56.07
2024-08-31 23:44:06,763 [foster.py] => Task 19, Epoch 16/170 => Loss 5.561, Loss_clf 1.123, Loss_fe 1.004, Loss_kd 3.255, Train_accy 65.72
2024-08-31 23:44:15,074 [foster.py] => Task 19, Epoch 17/170 => Loss 5.377, Loss_clf 1.004, Loss_fe 0.937, Loss_kd 3.258, Train_accy 66.87, Test_accy 56.38
2024-08-31 23:44:23,477 [foster.py] => Task 19, Epoch 18/170 => Loss 5.585, Loss_clf 1.152, Loss_fe 0.990, Loss_kd 3.265, Train_accy 65.07, Test_accy 54.20
2024-08-31 23:44:31,841 [foster.py] => Task 19, Epoch 19/170 => Loss 5.620, Loss_clf 1.213, Loss_fe 0.967, Loss_kd 3.262, Train_accy 65.18, Test_accy 53.59
2024-08-31 23:44:40,239 [foster.py] => Task 19, Epoch 20/170 => Loss 5.663, Loss_clf 1.243, Loss_fe 0.969, Loss_kd 3.272, Train_accy 65.94, Test_accy 50.74
2024-08-31 23:44:45,730 [foster.py] => Task 19, Epoch 21/170 => Loss 5.743, Loss_clf 1.291, Loss_fe 1.001, Loss_kd 3.273, Train_accy 64.32
2024-08-31 23:44:54,087 [foster.py] => Task 19, Epoch 22/170 => Loss 5.638, Loss_clf 1.173, Loss_fe 1.021, Loss_kd 3.266, Train_accy 64.36, Test_accy 57.64
2024-08-31 23:45:02,538 [foster.py] => Task 19, Epoch 23/170 => Loss 5.510, Loss_clf 1.114, Loss_fe 0.949, Loss_kd 3.268, Train_accy 66.32, Test_accy 55.59
2024-08-31 23:45:10,939 [foster.py] => Task 19, Epoch 24/170 => Loss 5.537, Loss_clf 1.118, Loss_fe 0.970, Loss_kd 3.270, Train_accy 66.32, Test_accy 56.43
2024-08-31 23:45:19,433 [foster.py] => Task 19, Epoch 25/170 => Loss 5.427, Loss_clf 1.057, Loss_fe 0.923, Loss_kd 3.269, Train_accy 65.78, Test_accy 56.84
2024-08-31 23:45:24,862 [foster.py] => Task 19, Epoch 26/170 => Loss 5.451, Loss_clf 1.079, Loss_fe 0.932, Loss_kd 3.263, Train_accy 66.16
2024-08-31 23:45:33,279 [foster.py] => Task 19, Epoch 27/170 => Loss 5.492, Loss_clf 1.105, Loss_fe 0.958, Loss_kd 3.251, Train_accy 65.05, Test_accy 53.09
2024-08-31 23:45:41,619 [foster.py] => Task 19, Epoch 28/170 => Loss 5.658, Loss_clf 1.259, Loss_fe 0.949, Loss_kd 3.271, Train_accy 64.74, Test_accy 56.04
2024-08-31 23:45:49,958 [foster.py] => Task 19, Epoch 29/170 => Loss 5.712, Loss_clf 1.301, Loss_fe 0.965, Loss_kd 3.268, Train_accy 65.18, Test_accy 56.57
2024-08-31 23:45:58,329 [foster.py] => Task 19, Epoch 30/170 => Loss 5.517, Loss_clf 1.107, Loss_fe 0.967, Loss_kd 3.265, Train_accy 65.87, Test_accy 55.19
2024-08-31 23:46:03,771 [foster.py] => Task 19, Epoch 31/170 => Loss 5.480, Loss_clf 1.063, Loss_fe 0.965, Loss_kd 3.274, Train_accy 66.14
2024-08-31 23:46:12,111 [foster.py] => Task 19, Epoch 32/170 => Loss 5.480, Loss_clf 1.100, Loss_fe 0.939, Loss_kd 3.263, Train_accy 65.41, Test_accy 56.21
2024-08-31 23:46:20,423 [foster.py] => Task 19, Epoch 33/170 => Loss 5.537, Loss_clf 1.168, Loss_fe 0.929, Loss_kd 3.262, Train_accy 66.54, Test_accy 57.74
2024-08-31 23:46:28,795 [foster.py] => Task 19, Epoch 34/170 => Loss 5.708, Loss_clf 1.260, Loss_fe 1.001, Loss_kd 3.269, Train_accy 63.14, Test_accy 55.68
2024-08-31 23:46:37,200 [foster.py] => Task 19, Epoch 35/170 => Loss 5.511, Loss_clf 1.107, Loss_fe 0.957, Loss_kd 3.269, Train_accy 65.81, Test_accy 56.52
2024-08-31 23:46:42,677 [foster.py] => Task 19, Epoch 36/170 => Loss 5.444, Loss_clf 1.067, Loss_fe 0.931, Loss_kd 3.269, Train_accy 66.45
2024-08-31 23:46:50,998 [foster.py] => Task 19, Epoch 37/170 => Loss 5.555, Loss_clf 1.198, Loss_fe 0.907, Loss_kd 3.272, Train_accy 65.52, Test_accy 52.74
2024-08-31 23:46:59,407 [foster.py] => Task 19, Epoch 38/170 => Loss 5.498, Loss_clf 1.105, Loss_fe 0.942, Loss_kd 3.273, Train_accy 66.61, Test_accy 57.63
2024-08-31 23:47:07,742 [foster.py] => Task 19, Epoch 39/170 => Loss 5.446, Loss_clf 1.072, Loss_fe 0.938, Loss_kd 3.259, Train_accy 65.90, Test_accy 57.08
2024-08-31 23:47:16,153 [foster.py] => Task 19, Epoch 40/170 => Loss 5.557, Loss_clf 1.175, Loss_fe 0.941, Loss_kd 3.264, Train_accy 65.01, Test_accy 55.26
2024-08-31 23:47:21,541 [foster.py] => Task 19, Epoch 41/170 => Loss 5.433, Loss_clf 1.032, Loss_fe 0.961, Loss_kd 3.262, Train_accy 66.14
2024-08-31 23:47:29,948 [foster.py] => Task 19, Epoch 42/170 => Loss 5.397, Loss_clf 1.034, Loss_fe 0.913, Loss_kd 3.272, Train_accy 66.41, Test_accy 56.16
2024-08-31 23:47:38,350 [foster.py] => Task 19, Epoch 43/170 => Loss 5.428, Loss_clf 1.091, Loss_fe 0.888, Loss_kd 3.271, Train_accy 66.41, Test_accy 53.70
2024-08-31 23:47:46,798 [foster.py] => Task 19, Epoch 44/170 => Loss 5.444, Loss_clf 1.075, Loss_fe 0.923, Loss_kd 3.268, Train_accy 67.36, Test_accy 55.18
2024-08-31 23:47:55,230 [foster.py] => Task 19, Epoch 45/170 => Loss 5.513, Loss_clf 1.065, Loss_fe 0.991, Loss_kd 3.279, Train_accy 64.38, Test_accy 57.09
2024-08-31 23:48:00,617 [foster.py] => Task 19, Epoch 46/170 => Loss 5.366, Loss_clf 0.990, Loss_fe 0.935, Loss_kd 3.262, Train_accy 66.43
2024-08-31 23:48:08,894 [foster.py] => Task 19, Epoch 47/170 => Loss 5.483, Loss_clf 1.146, Loss_fe 0.895, Loss_kd 3.264, Train_accy 66.05, Test_accy 56.73
2024-08-31 23:48:17,276 [foster.py] => Task 19, Epoch 48/170 => Loss 5.480, Loss_clf 1.111, Loss_fe 0.916, Loss_kd 3.275, Train_accy 64.56, Test_accy 57.31
2024-08-31 23:48:25,616 [foster.py] => Task 19, Epoch 49/170 => Loss 5.417, Loss_clf 1.051, Loss_fe 0.922, Loss_kd 3.266, Train_accy 65.65, Test_accy 53.67
2024-08-31 23:48:34,090 [foster.py] => Task 19, Epoch 50/170 => Loss 5.379, Loss_clf 1.015, Loss_fe 0.944, Loss_kd 3.243, Train_accy 66.96, Test_accy 54.04
2024-08-31 23:48:39,638 [foster.py] => Task 19, Epoch 51/170 => Loss 5.513, Loss_clf 1.145, Loss_fe 0.908, Loss_kd 3.281, Train_accy 65.23
2024-08-31 23:48:48,059 [foster.py] => Task 19, Epoch 52/170 => Loss 5.414, Loss_clf 1.038, Loss_fe 0.932, Loss_kd 3.266, Train_accy 65.83, Test_accy 57.19
2024-08-31 23:48:56,400 [foster.py] => Task 19, Epoch 53/170 => Loss 5.290, Loss_clf 0.982, Loss_fe 0.869, Loss_kd 3.262, Train_accy 67.52, Test_accy 56.90
2024-08-31 23:49:04,759 [foster.py] => Task 19, Epoch 54/170 => Loss 5.333, Loss_clf 1.007, Loss_fe 0.874, Loss_kd 3.274, Train_accy 66.94, Test_accy 57.31
2024-08-31 23:49:13,201 [foster.py] => Task 19, Epoch 55/170 => Loss 5.493, Loss_clf 1.147, Loss_fe 0.908, Loss_kd 3.261, Train_accy 65.67, Test_accy 57.02
2024-08-31 23:49:18,590 [foster.py] => Task 19, Epoch 56/170 => Loss 5.397, Loss_clf 1.045, Loss_fe 0.887, Loss_kd 3.286, Train_accy 66.10
2024-08-31 23:49:26,960 [foster.py] => Task 19, Epoch 57/170 => Loss 5.440, Loss_clf 1.093, Loss_fe 0.897, Loss_kd 3.272, Train_accy 65.21, Test_accy 48.39
2024-08-31 23:49:35,285 [foster.py] => Task 19, Epoch 58/170 => Loss 5.439, Loss_clf 1.112, Loss_fe 0.873, Loss_kd 3.276, Train_accy 67.36, Test_accy 57.58
2024-08-31 23:49:43,618 [foster.py] => Task 19, Epoch 59/170 => Loss 5.511, Loss_clf 1.104, Loss_fe 0.971, Loss_kd 3.258, Train_accy 65.56, Test_accy 52.75
2024-08-31 23:49:51,968 [foster.py] => Task 19, Epoch 60/170 => Loss 5.448, Loss_clf 1.113, Loss_fe 0.883, Loss_kd 3.273, Train_accy 65.85, Test_accy 56.23
2024-08-31 23:49:57,479 [foster.py] => Task 19, Epoch 61/170 => Loss 5.263, Loss_clf 0.970, Loss_fe 0.852, Loss_kd 3.263, Train_accy 67.43
2024-08-31 23:50:05,920 [foster.py] => Task 19, Epoch 62/170 => Loss 5.353, Loss_clf 1.078, Loss_fe 0.838, Loss_kd 3.259, Train_accy 66.56, Test_accy 55.48
2024-08-31 23:50:14,269 [foster.py] => Task 19, Epoch 63/170 => Loss 5.204, Loss_clf 0.962, Loss_fe 0.814, Loss_kd 3.251, Train_accy 68.88, Test_accy 57.91
2024-08-31 23:50:22,676 [foster.py] => Task 19, Epoch 64/170 => Loss 5.223, Loss_clf 0.958, Loss_fe 0.834, Loss_kd 3.254, Train_accy 68.16, Test_accy 56.26
2024-08-31 23:50:31,028 [foster.py] => Task 19, Epoch 65/170 => Loss 5.294, Loss_clf 1.003, Loss_fe 0.849, Loss_kd 3.265, Train_accy 67.03, Test_accy 56.42
2024-08-31 23:50:36,545 [foster.py] => Task 19, Epoch 66/170 => Loss 5.221, Loss_clf 0.981, Loss_fe 0.804, Loss_kd 3.258, Train_accy 66.32
2024-08-31 23:50:44,950 [foster.py] => Task 19, Epoch 67/170 => Loss 5.400, Loss_clf 1.066, Loss_fe 0.889, Loss_kd 3.267, Train_accy 67.27, Test_accy 56.53
2024-08-31 23:50:53,256 [foster.py] => Task 19, Epoch 68/170 => Loss 5.478, Loss_clf 1.150, Loss_fe 0.854, Loss_kd 3.295, Train_accy 65.54, Test_accy 57.81
2024-08-31 23:51:01,619 [foster.py] => Task 19, Epoch 69/170 => Loss 5.267, Loss_clf 0.996, Loss_fe 0.834, Loss_kd 3.260, Train_accy 68.70, Test_accy 57.55
2024-08-31 23:51:09,933 [foster.py] => Task 19, Epoch 70/170 => Loss 5.306, Loss_clf 1.007, Loss_fe 0.860, Loss_kd 3.262, Train_accy 67.27, Test_accy 56.35
2024-08-31 23:51:15,357 [foster.py] => Task 19, Epoch 71/170 => Loss 5.244, Loss_clf 0.973, Loss_fe 0.831, Loss_kd 3.263, Train_accy 68.23
2024-08-31 23:51:23,669 [foster.py] => Task 19, Epoch 72/170 => Loss 5.259, Loss_clf 0.965, Loss_fe 0.858, Loss_kd 3.258, Train_accy 66.50, Test_accy 56.59
2024-08-31 23:51:31,961 [foster.py] => Task 19, Epoch 73/170 => Loss 5.324, Loss_clf 1.002, Loss_fe 0.896, Loss_kd 3.249, Train_accy 66.41, Test_accy 57.85
2024-08-31 23:51:40,315 [foster.py] => Task 19, Epoch 74/170 => Loss 5.273, Loss_clf 0.974, Loss_fe 0.852, Loss_kd 3.270, Train_accy 66.74, Test_accy 57.21
2024-08-31 23:51:48,719 [foster.py] => Task 19, Epoch 75/170 => Loss 5.224, Loss_clf 0.932, Loss_fe 0.848, Loss_kd 3.266, Train_accy 67.47, Test_accy 57.45
2024-08-31 23:51:54,178 [foster.py] => Task 19, Epoch 76/170 => Loss 5.287, Loss_clf 1.022, Loss_fe 0.830, Loss_kd 3.258, Train_accy 66.61
2024-08-31 23:52:02,484 [foster.py] => Task 19, Epoch 77/170 => Loss 5.307, Loss_clf 1.045, Loss_fe 0.824, Loss_kd 3.260, Train_accy 67.39, Test_accy 58.37
2024-08-31 23:52:10,923 [foster.py] => Task 19, Epoch 78/170 => Loss 5.350, Loss_clf 1.065, Loss_fe 0.837, Loss_kd 3.269, Train_accy 67.68, Test_accy 55.77
2024-08-31 23:52:19,192 [foster.py] => Task 19, Epoch 79/170 => Loss 5.233, Loss_clf 0.956, Loss_fe 0.821, Loss_kd 3.277, Train_accy 68.48, Test_accy 56.26
2024-08-31 23:52:27,512 [foster.py] => Task 19, Epoch 80/170 => Loss 5.235, Loss_clf 0.985, Loss_fe 0.804, Loss_kd 3.268, Train_accy 68.12, Test_accy 57.47
2024-08-31 23:52:32,934 [foster.py] => Task 19, Epoch 81/170 => Loss 5.276, Loss_clf 1.005, Loss_fe 0.839, Loss_kd 3.254, Train_accy 66.70
2024-08-31 23:52:41,310 [foster.py] => Task 19, Epoch 82/170 => Loss 5.385, Loss_clf 1.088, Loss_fe 0.857, Loss_kd 3.262, Train_accy 66.96, Test_accy 57.50
2024-08-31 23:52:49,790 [foster.py] => Task 19, Epoch 83/170 => Loss 5.184, Loss_clf 0.926, Loss_fe 0.822, Loss_kd 3.259, Train_accy 68.77, Test_accy 56.57
2024-08-31 23:52:58,169 [foster.py] => Task 19, Epoch 84/170 => Loss 5.162, Loss_clf 0.940, Loss_fe 0.779, Loss_kd 3.266, Train_accy 68.39, Test_accy 57.61
2024-08-31 23:53:06,480 [foster.py] => Task 19, Epoch 85/170 => Loss 5.138, Loss_clf 0.911, Loss_fe 0.784, Loss_kd 3.265, Train_accy 67.45, Test_accy 57.13
2024-08-31 23:53:11,891 [foster.py] => Task 19, Epoch 86/170 => Loss 5.235, Loss_clf 0.959, Loss_fe 0.831, Loss_kd 3.268, Train_accy 67.23
2024-08-31 23:53:20,328 [foster.py] => Task 19, Epoch 87/170 => Loss 5.130, Loss_clf 0.938, Loss_fe 0.763, Loss_kd 3.252, Train_accy 67.94, Test_accy 57.69
2024-08-31 23:53:28,676 [foster.py] => Task 19, Epoch 88/170 => Loss 5.113, Loss_clf 0.921, Loss_fe 0.763, Loss_kd 3.253, Train_accy 68.48, Test_accy 58.23
2024-08-31 23:53:37,089 [foster.py] => Task 19, Epoch 89/170 => Loss 5.081, Loss_clf 0.907, Loss_fe 0.748, Loss_kd 3.249, Train_accy 68.99, Test_accy 57.62
2024-08-31 23:53:45,482 [foster.py] => Task 19, Epoch 90/170 => Loss 5.325, Loss_clf 1.022, Loss_fe 0.866, Loss_kd 3.260, Train_accy 67.12, Test_accy 56.94
2024-08-31 23:53:50,948 [foster.py] => Task 19, Epoch 91/170 => Loss 5.156, Loss_clf 0.952, Loss_fe 0.760, Loss_kd 3.267, Train_accy 67.79
2024-08-31 23:53:59,349 [foster.py] => Task 19, Epoch 92/170 => Loss 5.085, Loss_clf 0.899, Loss_fe 0.760, Loss_kd 3.249, Train_accy 69.03, Test_accy 57.10
2024-08-31 23:54:07,715 [foster.py] => Task 19, Epoch 93/170 => Loss 5.160, Loss_clf 0.922, Loss_fe 0.799, Loss_kd 3.261, Train_accy 68.65, Test_accy 56.88
2024-08-31 23:54:16,136 [foster.py] => Task 19, Epoch 94/170 => Loss 5.153, Loss_clf 0.949, Loss_fe 0.776, Loss_kd 3.251, Train_accy 68.16, Test_accy 57.88
2024-08-31 23:54:24,518 [foster.py] => Task 19, Epoch 95/170 => Loss 5.074, Loss_clf 0.917, Loss_fe 0.737, Loss_kd 3.243, Train_accy 69.12, Test_accy 57.74
2024-08-31 23:54:29,960 [foster.py] => Task 19, Epoch 96/170 => Loss 5.112, Loss_clf 0.917, Loss_fe 0.756, Loss_kd 3.261, Train_accy 68.85
2024-08-31 23:54:38,374 [foster.py] => Task 19, Epoch 97/170 => Loss 5.195, Loss_clf 0.988, Loss_fe 0.752, Loss_kd 3.277, Train_accy 68.74, Test_accy 58.16
2024-08-31 23:54:46,737 [foster.py] => Task 19, Epoch 98/170 => Loss 5.142, Loss_clf 0.958, Loss_fe 0.755, Loss_kd 3.252, Train_accy 68.81, Test_accy 57.03
2024-08-31 23:54:55,077 [foster.py] => Task 19, Epoch 99/170 => Loss 5.134, Loss_clf 0.957, Loss_fe 0.745, Loss_kd 3.255, Train_accy 68.45, Test_accy 57.85
2024-08-31 23:55:03,435 [foster.py] => Task 19, Epoch 100/170 => Loss 5.089, Loss_clf 0.910, Loss_fe 0.742, Loss_kd 3.259, Train_accy 70.66, Test_accy 58.02
2024-08-31 23:55:08,936 [foster.py] => Task 19, Epoch 101/170 => Loss 5.166, Loss_clf 0.956, Loss_fe 0.766, Loss_kd 3.266, Train_accy 69.25
2024-08-31 23:55:17,331 [foster.py] => Task 19, Epoch 102/170 => Loss 5.092, Loss_clf 0.931, Loss_fe 0.725, Loss_kd 3.258, Train_accy 69.41, Test_accy 57.72
2024-08-31 23:55:25,739 [foster.py] => Task 19, Epoch 103/170 => Loss 5.078, Loss_clf 0.913, Loss_fe 0.715, Loss_kd 3.273, Train_accy 70.12, Test_accy 58.14
2024-08-31 23:55:34,127 [foster.py] => Task 19, Epoch 104/170 => Loss 4.963, Loss_clf 0.866, Loss_fe 0.674, Loss_kd 3.247, Train_accy 70.50, Test_accy 58.15
2024-08-31 23:55:42,562 [foster.py] => Task 19, Epoch 105/170 => Loss 5.031, Loss_clf 0.887, Loss_fe 0.715, Loss_kd 3.252, Train_accy 70.72, Test_accy 58.03
2024-08-31 23:55:47,948 [foster.py] => Task 19, Epoch 106/170 => Loss 4.983, Loss_clf 0.856, Loss_fe 0.698, Loss_kd 3.252, Train_accy 71.48
2024-08-31 23:55:56,353 [foster.py] => Task 19, Epoch 107/170 => Loss 4.974, Loss_clf 0.855, Loss_fe 0.684, Loss_kd 3.257, Train_accy 70.34, Test_accy 57.16
2024-08-31 23:56:04,759 [foster.py] => Task 19, Epoch 108/170 => Loss 5.042, Loss_clf 0.895, Loss_fe 0.697, Loss_kd 3.272, Train_accy 69.92, Test_accy 58.31
2024-08-31 23:56:13,115 [foster.py] => Task 19, Epoch 109/170 => Loss 5.024, Loss_clf 0.870, Loss_fe 0.721, Loss_kd 3.255, Train_accy 70.06, Test_accy 58.37
2024-08-31 23:56:21,612 [foster.py] => Task 19, Epoch 110/170 => Loss 5.032, Loss_clf 0.899, Loss_fe 0.710, Loss_kd 3.245, Train_accy 69.77, Test_accy 58.19
2024-08-31 23:56:27,018 [foster.py] => Task 19, Epoch 111/170 => Loss 4.983, Loss_clf 0.875, Loss_fe 0.667, Loss_kd 3.263, Train_accy 70.81
2024-08-31 23:56:35,356 [foster.py] => Task 19, Epoch 112/170 => Loss 4.973, Loss_clf 0.867, Loss_fe 0.662, Loss_kd 3.266, Train_accy 70.43, Test_accy 58.89
2024-08-31 23:56:43,688 [foster.py] => Task 19, Epoch 113/170 => Loss 4.934, Loss_clf 0.836, Loss_fe 0.662, Loss_kd 3.258, Train_accy 71.57, Test_accy 58.92
2024-08-31 23:56:52,005 [foster.py] => Task 19, Epoch 114/170 => Loss 4.913, Loss_clf 0.848, Loss_fe 0.649, Loss_kd 3.240, Train_accy 71.79, Test_accy 58.36
2024-08-31 23:57:00,338 [foster.py] => Task 19, Epoch 115/170 => Loss 4.993, Loss_clf 0.884, Loss_fe 0.665, Loss_kd 3.266, Train_accy 71.15, Test_accy 58.70
2024-08-31 23:57:05,846 [foster.py] => Task 19, Epoch 116/170 => Loss 4.882, Loss_clf 0.810, Loss_fe 0.646, Loss_kd 3.250, Train_accy 71.46
2024-08-31 23:57:14,279 [foster.py] => Task 19, Epoch 117/170 => Loss 4.854, Loss_clf 0.813, Loss_fe 0.630, Loss_kd 3.236, Train_accy 72.26, Test_accy 58.60
2024-08-31 23:57:22,765 [foster.py] => Task 19, Epoch 118/170 => Loss 4.839, Loss_clf 0.813, Loss_fe 0.599, Loss_kd 3.250, Train_accy 73.10, Test_accy 58.55
2024-08-31 23:57:31,104 [foster.py] => Task 19, Epoch 119/170 => Loss 4.853, Loss_clf 0.798, Loss_fe 0.618, Loss_kd 3.259, Train_accy 72.59, Test_accy 59.05
2024-08-31 23:57:39,463 [foster.py] => Task 19, Epoch 120/170 => Loss 4.810, Loss_clf 0.782, Loss_fe 0.610, Loss_kd 3.242, Train_accy 72.77, Test_accy 58.61
2024-08-31 23:57:44,909 [foster.py] => Task 19, Epoch 121/170 => Loss 4.916, Loss_clf 0.843, Loss_fe 0.639, Loss_kd 3.256, Train_accy 71.77
2024-08-31 23:57:53,320 [foster.py] => Task 19, Epoch 122/170 => Loss 4.885, Loss_clf 0.834, Loss_fe 0.615, Loss_kd 3.259, Train_accy 71.48, Test_accy 58.71
2024-08-31 23:58:01,680 [foster.py] => Task 19, Epoch 123/170 => Loss 4.883, Loss_clf 0.841, Loss_fe 0.603, Loss_kd 3.262, Train_accy 72.95, Test_accy 58.90
2024-08-31 23:58:10,075 [foster.py] => Task 19, Epoch 124/170 => Loss 4.860, Loss_clf 0.821, Loss_fe 0.605, Loss_kd 3.257, Train_accy 72.50, Test_accy 59.08
2024-08-31 23:58:18,494 [foster.py] => Task 19, Epoch 125/170 => Loss 4.832, Loss_clf 0.807, Loss_fe 0.602, Loss_kd 3.246, Train_accy 73.17, Test_accy 59.07
2024-08-31 23:58:23,929 [foster.py] => Task 19, Epoch 126/170 => Loss 4.812, Loss_clf 0.796, Loss_fe 0.587, Loss_kd 3.252, Train_accy 73.08
2024-08-31 23:58:32,276 [foster.py] => Task 19, Epoch 127/170 => Loss 4.900, Loss_clf 0.839, Loss_fe 0.612, Loss_kd 3.271, Train_accy 71.81, Test_accy 58.87
2024-08-31 23:58:40,654 [foster.py] => Task 19, Epoch 128/170 => Loss 4.814, Loss_clf 0.804, Loss_fe 0.584, Loss_kd 3.249, Train_accy 72.35, Test_accy 59.14
2024-08-31 23:58:48,925 [foster.py] => Task 19, Epoch 129/170 => Loss 4.816, Loss_clf 0.792, Loss_fe 0.593, Loss_kd 3.253, Train_accy 73.19, Test_accy 58.75
2024-08-31 23:58:57,239 [foster.py] => Task 19, Epoch 130/170 => Loss 4.797, Loss_clf 0.792, Loss_fe 0.586, Loss_kd 3.243, Train_accy 73.08, Test_accy 59.27
2024-08-31 23:59:02,688 [foster.py] => Task 19, Epoch 131/170 => Loss 4.771, Loss_clf 0.776, Loss_fe 0.562, Loss_kd 3.257, Train_accy 74.99
2024-08-31 23:59:11,007 [foster.py] => Task 19, Epoch 132/170 => Loss 4.676, Loss_clf 0.736, Loss_fe 0.539, Loss_kd 3.226, Train_accy 73.57, Test_accy 58.91
2024-08-31 23:59:19,503 [foster.py] => Task 19, Epoch 133/170 => Loss 4.669, Loss_clf 0.736, Loss_fe 0.515, Loss_kd 3.242, Train_accy 76.00, Test_accy 58.89
2024-08-31 23:59:27,874 [foster.py] => Task 19, Epoch 134/170 => Loss 4.746, Loss_clf 0.782, Loss_fe 0.534, Loss_kd 3.252, Train_accy 73.53, Test_accy 59.32
2024-08-31 23:59:36,227 [foster.py] => Task 19, Epoch 135/170 => Loss 4.722, Loss_clf 0.755, Loss_fe 0.547, Loss_kd 3.244, Train_accy 74.08, Test_accy 58.81
2024-08-31 23:59:41,630 [foster.py] => Task 19, Epoch 136/170 => Loss 4.715, Loss_clf 0.753, Loss_fe 0.531, Loss_kd 3.253, Train_accy 74.28
2024-08-31 23:59:49,973 [foster.py] => Task 19, Epoch 137/170 => Loss 4.728, Loss_clf 0.770, Loss_fe 0.526, Loss_kd 3.256, Train_accy 74.99, Test_accy 59.15
2024-08-31 23:59:58,351 [foster.py] => Task 19, Epoch 138/170 => Loss 4.704, Loss_clf 0.741, Loss_fe 0.526, Loss_kd 3.259, Train_accy 75.08, Test_accy 58.90
2024-09-01 00:00:06,710 [foster.py] => Task 19, Epoch 139/170 => Loss 4.717, Loss_clf 0.768, Loss_fe 0.532, Loss_kd 3.240, Train_accy 75.02, Test_accy 59.08
2024-09-01 00:00:15,042 [foster.py] => Task 19, Epoch 140/170 => Loss 4.661, Loss_clf 0.753, Loss_fe 0.495, Loss_kd 3.237, Train_accy 75.13, Test_accy 59.33
2024-09-01 00:00:20,530 [foster.py] => Task 19, Epoch 141/170 => Loss 4.694, Loss_clf 0.768, Loss_fe 0.496, Loss_kd 3.253, Train_accy 75.22
2024-09-01 00:00:28,884 [foster.py] => Task 19, Epoch 142/170 => Loss 4.716, Loss_clf 0.767, Loss_fe 0.519, Loss_kd 3.254, Train_accy 74.73, Test_accy 58.97
2024-09-01 00:00:37,281 [foster.py] => Task 19, Epoch 143/170 => Loss 4.632, Loss_clf 0.718, Loss_fe 0.490, Loss_kd 3.248, Train_accy 74.68, Test_accy 59.15
2024-09-01 00:00:45,662 [foster.py] => Task 19, Epoch 144/170 => Loss 4.627, Loss_clf 0.725, Loss_fe 0.477, Loss_kd 3.248, Train_accy 76.04, Test_accy 59.00
2024-09-01 00:00:54,073 [foster.py] => Task 19, Epoch 145/170 => Loss 4.635, Loss_clf 0.716, Loss_fe 0.494, Loss_kd 3.249, Train_accy 76.15, Test_accy 59.27
2024-09-01 00:00:59,491 [foster.py] => Task 19, Epoch 146/170 => Loss 4.593, Loss_clf 0.700, Loss_fe 0.459, Loss_kd 3.258, Train_accy 76.08
2024-09-01 00:01:07,872 [foster.py] => Task 19, Epoch 147/170 => Loss 4.599, Loss_clf 0.700, Loss_fe 0.470, Loss_kd 3.253, Train_accy 76.13, Test_accy 59.37
2024-09-01 00:01:16,157 [foster.py] => Task 19, Epoch 148/170 => Loss 4.584, Loss_clf 0.700, Loss_fe 0.446, Loss_kd 3.260, Train_accy 76.44, Test_accy 59.18
2024-09-01 00:01:24,487 [foster.py] => Task 19, Epoch 149/170 => Loss 4.589, Loss_clf 0.704, Loss_fe 0.454, Loss_kd 3.255, Train_accy 77.64, Test_accy 59.39
2024-09-01 00:01:32,843 [foster.py] => Task 19, Epoch 150/170 => Loss 4.562, Loss_clf 0.680, Loss_fe 0.463, Loss_kd 3.242, Train_accy 77.62, Test_accy 59.57
2024-09-01 00:01:38,314 [foster.py] => Task 19, Epoch 151/170 => Loss 4.591, Loss_clf 0.704, Loss_fe 0.445, Loss_kd 3.264, Train_accy 76.93
2024-09-01 00:01:46,647 [foster.py] => Task 19, Epoch 152/170 => Loss 4.560, Loss_clf 0.686, Loss_fe 0.432, Loss_kd 3.264, Train_accy 77.04, Test_accy 59.64
2024-09-01 00:01:54,991 [foster.py] => Task 19, Epoch 153/170 => Loss 4.587, Loss_clf 0.711, Loss_fe 0.434, Loss_kd 3.265, Train_accy 76.37, Test_accy 59.54
2024-09-01 00:02:03,383 [foster.py] => Task 19, Epoch 154/170 => Loss 4.638, Loss_clf 0.727, Loss_fe 0.452, Loss_kd 3.281, Train_accy 76.53, Test_accy 59.52
2024-09-01 00:02:11,760 [foster.py] => Task 19, Epoch 155/170 => Loss 4.493, Loss_clf 0.654, Loss_fe 0.420, Loss_kd 3.243, Train_accy 78.93, Test_accy 59.59
2024-09-01 00:02:17,219 [foster.py] => Task 19, Epoch 156/170 => Loss 4.509, Loss_clf 0.663, Loss_fe 0.425, Loss_kd 3.245, Train_accy 78.02
2024-09-01 00:02:25,597 [foster.py] => Task 19, Epoch 157/170 => Loss 4.573, Loss_clf 0.701, Loss_fe 0.426, Loss_kd 3.269, Train_accy 77.58, Test_accy 59.59
2024-09-01 00:02:33,980 [foster.py] => Task 19, Epoch 158/170 => Loss 4.521, Loss_clf 0.666, Loss_fe 0.433, Loss_kd 3.246, Train_accy 78.51, Test_accy 59.82
2024-09-01 00:02:42,381 [foster.py] => Task 19, Epoch 159/170 => Loss 4.523, Loss_clf 0.671, Loss_fe 0.428, Loss_kd 3.247, Train_accy 77.06, Test_accy 59.46
2024-09-01 00:02:50,748 [foster.py] => Task 19, Epoch 160/170 => Loss 4.487, Loss_clf 0.668, Loss_fe 0.396, Loss_kd 3.247, Train_accy 76.71, Test_accy 59.56
2024-09-01 00:02:56,282 [foster.py] => Task 19, Epoch 161/170 => Loss 4.494, Loss_clf 0.650, Loss_fe 0.406, Loss_kd 3.260, Train_accy 79.53
2024-09-01 00:03:04,762 [foster.py] => Task 19, Epoch 162/170 => Loss 4.563, Loss_clf 0.705, Loss_fe 0.413, Loss_kd 3.268, Train_accy 77.58, Test_accy 59.77
2024-09-01 00:03:13,208 [foster.py] => Task 19, Epoch 163/170 => Loss 4.436, Loss_clf 0.638, Loss_fe 0.393, Loss_kd 3.229, Train_accy 78.35, Test_accy 59.69
2024-09-01 00:03:21,608 [foster.py] => Task 19, Epoch 164/170 => Loss 4.488, Loss_clf 0.657, Loss_fe 0.408, Loss_kd 3.247, Train_accy 77.62, Test_accy 59.50
2024-09-01 00:03:29,977 [foster.py] => Task 19, Epoch 165/170 => Loss 4.481, Loss_clf 0.664, Loss_fe 0.401, Loss_kd 3.240, Train_accy 78.15, Test_accy 59.57
2024-09-01 00:03:35,467 [foster.py] => Task 19, Epoch 166/170 => Loss 4.538, Loss_clf 0.681, Loss_fe 0.408, Loss_kd 3.271, Train_accy 78.73
2024-09-01 00:03:43,820 [foster.py] => Task 19, Epoch 167/170 => Loss 4.512, Loss_clf 0.665, Loss_fe 0.408, Loss_kd 3.262, Train_accy 78.78, Test_accy 59.58
2024-09-01 00:03:52,180 [foster.py] => Task 19, Epoch 168/170 => Loss 4.535, Loss_clf 0.689, Loss_fe 0.417, Loss_kd 3.253, Train_accy 78.38, Test_accy 59.56
2024-09-01 00:04:00,525 [foster.py] => Task 19, Epoch 169/170 => Loss 4.536, Loss_clf 0.688, Loss_fe 0.406, Loss_kd 3.265, Train_accy 78.55, Test_accy 59.57
2024-09-01 00:04:08,953 [foster.py] => Task 19, Epoch 170/170 => Loss 4.489, Loss_clf 0.663, Loss_fe 0.395, Loss_kd 3.254, Train_accy 79.27, Test_accy 59.63
2024-09-01 00:04:08,957 [foster.py] => do not weight align teacher!
2024-09-01 00:04:08,960 [foster.py] => per cls weights : [1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921
 1.02935921 1.02935921 1.02935921 1.02935921 1.02935921 0.44217492
 0.44217492 0.44217492 0.44217492 0.44217492]
2024-09-01 00:04:19,121 [foster.py] => SNet: Task 19, Epoch 1/130 => Loss 32.218,  Loss1 0.787, Train_accy 38.82, Test_accy 56.33
2024-09-01 00:04:26,623 [foster.py] => SNet: Task 19, Epoch 2/130 => Loss 32.147,  Loss1 0.786, Train_accy 42.18
2024-09-01 00:04:33,929 [foster.py] => SNet: Task 19, Epoch 3/130 => Loss 32.132,  Loss1 0.786, Train_accy 46.70
2024-09-01 00:04:41,249 [foster.py] => SNet: Task 19, Epoch 4/130 => Loss 32.136,  Loss1 0.786, Train_accy 48.50
2024-09-01 00:04:48,708 [foster.py] => SNet: Task 19, Epoch 5/130 => Loss 32.117,  Loss1 0.786, Train_accy 50.59
2024-09-01 00:04:59,021 [foster.py] => SNet: Task 19, Epoch 6/130 => Loss 32.116,  Loss1 0.786, Train_accy 51.17, Test_accy 58.55
2024-09-01 00:05:06,301 [foster.py] => SNet: Task 19, Epoch 7/130 => Loss 32.089,  Loss1 0.786, Train_accy 53.37
2024-09-01 00:05:13,857 [foster.py] => SNet: Task 19, Epoch 8/130 => Loss 32.108,  Loss1 0.786, Train_accy 54.10
2024-09-01 00:05:21,573 [foster.py] => SNet: Task 19, Epoch 9/130 => Loss 32.116,  Loss1 0.786, Train_accy 54.10
2024-09-01 00:05:28,874 [foster.py] => SNet: Task 19, Epoch 10/130 => Loss 32.095,  Loss1 0.786, Train_accy 55.95
2024-09-01 00:05:39,074 [foster.py] => SNet: Task 19, Epoch 11/130 => Loss 32.130,  Loss1 0.786, Train_accy 55.17, Test_accy 58.30
2024-09-01 00:05:46,650 [foster.py] => SNet: Task 19, Epoch 12/130 => Loss 32.099,  Loss1 0.786, Train_accy 56.51
2024-09-01 00:05:54,113 [foster.py] => SNet: Task 19, Epoch 13/130 => Loss 32.115,  Loss1 0.786, Train_accy 57.35
2024-09-01 00:06:01,586 [foster.py] => SNet: Task 19, Epoch 14/130 => Loss 32.080,  Loss1 0.786, Train_accy 56.84
2024-09-01 00:06:09,096 [foster.py] => SNet: Task 19, Epoch 15/130 => Loss 32.107,  Loss1 0.786, Train_accy 55.77
2024-09-01 00:06:19,039 [foster.py] => SNet: Task 19, Epoch 16/130 => Loss 32.120,  Loss1 0.786, Train_accy 57.24, Test_accy 58.16
2024-09-01 00:06:26,874 [foster.py] => SNet: Task 19, Epoch 17/130 => Loss 32.071,  Loss1 0.786, Train_accy 58.04
2024-09-01 00:06:34,358 [foster.py] => SNet: Task 19, Epoch 18/130 => Loss 32.080,  Loss1 0.786, Train_accy 58.00
2024-09-01 00:06:41,996 [foster.py] => SNet: Task 19, Epoch 19/130 => Loss 32.110,  Loss1 0.786, Train_accy 57.86
2024-09-01 00:06:49,531 [foster.py] => SNet: Task 19, Epoch 20/130 => Loss 32.113,  Loss1 0.786, Train_accy 57.58
2024-09-01 00:06:59,452 [foster.py] => SNet: Task 19, Epoch 21/130 => Loss 32.093,  Loss1 0.786, Train_accy 57.98, Test_accy 58.32
2024-09-01 00:07:06,880 [foster.py] => SNet: Task 19, Epoch 22/130 => Loss 32.092,  Loss1 0.786, Train_accy 58.26
2024-09-01 00:07:14,155 [foster.py] => SNet: Task 19, Epoch 23/130 => Loss 32.099,  Loss1 0.786, Train_accy 58.18
2024-09-01 00:07:21,851 [foster.py] => SNet: Task 19, Epoch 24/130 => Loss 32.104,  Loss1 0.786, Train_accy 58.31
2024-09-01 00:07:29,168 [foster.py] => SNet: Task 19, Epoch 25/130 => Loss 32.102,  Loss1 0.786, Train_accy 58.33
2024-09-01 00:07:39,076 [foster.py] => SNet: Task 19, Epoch 26/130 => Loss 32.111,  Loss1 0.786, Train_accy 59.04, Test_accy 58.30
2024-09-01 00:07:46,396 [foster.py] => SNet: Task 19, Epoch 27/130 => Loss 32.092,  Loss1 0.786, Train_accy 58.75
2024-09-01 00:07:54,176 [foster.py] => SNet: Task 19, Epoch 28/130 => Loss 32.117,  Loss1 0.786, Train_accy 59.62
2024-09-01 00:08:01,687 [foster.py] => SNet: Task 19, Epoch 29/130 => Loss 32.109,  Loss1 0.786, Train_accy 58.38
2024-09-01 00:08:08,966 [foster.py] => SNet: Task 19, Epoch 30/130 => Loss 32.107,  Loss1 0.786, Train_accy 60.13
2024-09-01 00:08:19,967 [foster.py] => SNet: Task 19, Epoch 31/130 => Loss 32.095,  Loss1 0.786, Train_accy 60.02, Test_accy 58.26
2024-09-01 00:08:27,206 [foster.py] => SNet: Task 19, Epoch 32/130 => Loss 32.077,  Loss1 0.786, Train_accy 59.71
2024-09-01 00:08:34,578 [foster.py] => SNet: Task 19, Epoch 33/130 => Loss 32.104,  Loss1 0.786, Train_accy 59.07
2024-09-01 00:08:42,586 [foster.py] => SNet: Task 19, Epoch 34/130 => Loss 32.109,  Loss1 0.786, Train_accy 59.49
2024-09-01 00:08:49,884 [foster.py] => SNet: Task 19, Epoch 35/130 => Loss 32.106,  Loss1 0.786, Train_accy 60.24
2024-09-01 00:08:59,930 [foster.py] => SNet: Task 19, Epoch 36/130 => Loss 32.079,  Loss1 0.786, Train_accy 60.60, Test_accy 58.85
2024-09-01 00:09:07,359 [foster.py] => SNet: Task 19, Epoch 37/130 => Loss 32.113,  Loss1 0.786, Train_accy 60.24
2024-09-01 00:09:15,339 [foster.py] => SNet: Task 19, Epoch 38/130 => Loss 32.098,  Loss1 0.786, Train_accy 60.47
2024-09-01 00:09:22,592 [foster.py] => SNet: Task 19, Epoch 39/130 => Loss 32.112,  Loss1 0.786, Train_accy 60.85
2024-09-01 00:09:29,994 [foster.py] => SNet: Task 19, Epoch 40/130 => Loss 32.110,  Loss1 0.786, Train_accy 60.29
2024-09-01 00:09:39,882 [foster.py] => SNet: Task 19, Epoch 41/130 => Loss 32.117,  Loss1 0.786, Train_accy 61.54, Test_accy 58.70
2024-09-01 00:09:47,129 [foster.py] => SNet: Task 19, Epoch 42/130 => Loss 32.087,  Loss1 0.786, Train_accy 61.54
2024-09-01 00:09:54,348 [foster.py] => SNet: Task 19, Epoch 43/130 => Loss 32.094,  Loss1 0.786, Train_accy 61.45
2024-09-01 00:10:01,596 [foster.py] => SNet: Task 19, Epoch 44/130 => Loss 32.110,  Loss1 0.786, Train_accy 61.13
2024-09-01 00:10:09,022 [foster.py] => SNet: Task 19, Epoch 45/130 => Loss 32.099,  Loss1 0.786, Train_accy 61.56
2024-09-01 00:10:19,063 [foster.py] => SNet: Task 19, Epoch 46/130 => Loss 32.098,  Loss1 0.786, Train_accy 60.80, Test_accy 58.49
2024-09-01 00:10:26,338 [foster.py] => SNet: Task 19, Epoch 47/130 => Loss 32.090,  Loss1 0.786, Train_accy 61.02
2024-09-01 00:10:33,618 [foster.py] => SNet: Task 19, Epoch 48/130 => Loss 32.082,  Loss1 0.786, Train_accy 61.13
2024-09-01 00:10:40,984 [foster.py] => SNet: Task 19, Epoch 49/130 => Loss 32.099,  Loss1 0.786, Train_accy 60.91
2024-09-01 00:10:48,231 [foster.py] => SNet: Task 19, Epoch 50/130 => Loss 32.083,  Loss1 0.786, Train_accy 61.20
2024-09-01 00:10:58,467 [foster.py] => SNet: Task 19, Epoch 51/130 => Loss 32.096,  Loss1 0.786, Train_accy 60.62, Test_accy 58.89
2024-09-01 00:11:06,034 [foster.py] => SNet: Task 19, Epoch 52/130 => Loss 32.077,  Loss1 0.786, Train_accy 60.24
2024-09-01 00:11:13,729 [foster.py] => SNet: Task 19, Epoch 53/130 => Loss 32.111,  Loss1 0.786, Train_accy 60.22
2024-09-01 00:11:21,011 [foster.py] => SNet: Task 19, Epoch 54/130 => Loss 32.076,  Loss1 0.786, Train_accy 60.73
2024-09-01 00:11:28,462 [foster.py] => SNet: Task 19, Epoch 55/130 => Loss 32.095,  Loss1 0.786, Train_accy 61.00
2024-09-01 00:11:38,470 [foster.py] => SNet: Task 19, Epoch 56/130 => Loss 32.102,  Loss1 0.786, Train_accy 60.38, Test_accy 58.14
2024-09-01 00:11:45,991 [foster.py] => SNet: Task 19, Epoch 57/130 => Loss 32.119,  Loss1 0.786, Train_accy 60.13
2024-09-01 00:11:53,273 [foster.py] => SNet: Task 19, Epoch 58/130 => Loss 32.121,  Loss1 0.786, Train_accy 60.38
2024-09-01 00:12:00,660 [foster.py] => SNet: Task 19, Epoch 59/130 => Loss 32.062,  Loss1 0.786, Train_accy 60.71
2024-09-01 00:12:08,132 [foster.py] => SNet: Task 19, Epoch 60/130 => Loss 32.088,  Loss1 0.786, Train_accy 60.87
2024-09-01 00:12:18,132 [foster.py] => SNet: Task 19, Epoch 61/130 => Loss 32.078,  Loss1 0.786, Train_accy 60.44, Test_accy 58.45
2024-09-01 00:12:25,463 [foster.py] => SNet: Task 19, Epoch 62/130 => Loss 32.077,  Loss1 0.786, Train_accy 60.80
2024-09-01 00:12:32,912 [foster.py] => SNet: Task 19, Epoch 63/130 => Loss 32.095,  Loss1 0.786, Train_accy 60.65
2024-09-01 00:12:40,395 [foster.py] => SNet: Task 19, Epoch 64/130 => Loss 32.077,  Loss1 0.786, Train_accy 62.22
2024-09-01 00:12:47,670 [foster.py] => SNet: Task 19, Epoch 65/130 => Loss 32.081,  Loss1 0.786, Train_accy 61.22
2024-09-01 00:12:58,000 [foster.py] => SNet: Task 19, Epoch 66/130 => Loss 32.083,  Loss1 0.786, Train_accy 61.09, Test_accy 58.74
2024-09-01 00:13:05,342 [foster.py] => SNet: Task 19, Epoch 67/130 => Loss 32.093,  Loss1 0.786, Train_accy 60.85
2024-09-01 00:13:12,681 [foster.py] => SNet: Task 19, Epoch 68/130 => Loss 32.109,  Loss1 0.786, Train_accy 61.16
2024-09-01 00:13:19,941 [foster.py] => SNet: Task 19, Epoch 69/130 => Loss 32.109,  Loss1 0.786, Train_accy 60.16
2024-09-01 00:13:27,283 [foster.py] => SNet: Task 19, Epoch 70/130 => Loss 32.095,  Loss1 0.786, Train_accy 61.16
2024-09-01 00:13:37,178 [foster.py] => SNet: Task 19, Epoch 71/130 => Loss 32.101,  Loss1 0.786, Train_accy 60.67, Test_accy 58.62
2024-09-01 00:13:44,672 [foster.py] => SNet: Task 19, Epoch 72/130 => Loss 32.104,  Loss1 0.786, Train_accy 61.36
2024-09-01 00:13:52,184 [foster.py] => SNet: Task 19, Epoch 73/130 => Loss 32.088,  Loss1 0.786, Train_accy 63.16
2024-09-01 00:13:59,863 [foster.py] => SNet: Task 19, Epoch 74/130 => Loss 32.071,  Loss1 0.786, Train_accy 62.07
2024-09-01 00:14:07,310 [foster.py] => SNet: Task 19, Epoch 75/130 => Loss 32.096,  Loss1 0.786, Train_accy 61.96
2024-09-01 00:14:17,433 [foster.py] => SNet: Task 19, Epoch 76/130 => Loss 32.057,  Loss1 0.786, Train_accy 62.07, Test_accy 58.51
2024-09-01 00:14:24,918 [foster.py] => SNet: Task 19, Epoch 77/130 => Loss 32.107,  Loss1 0.786, Train_accy 62.00
2024-09-01 00:14:32,257 [foster.py] => SNet: Task 19, Epoch 78/130 => Loss 32.081,  Loss1 0.786, Train_accy 62.16
2024-09-01 00:14:39,713 [foster.py] => SNet: Task 19, Epoch 79/130 => Loss 32.113,  Loss1 0.786, Train_accy 61.27
2024-09-01 00:14:47,191 [foster.py] => SNet: Task 19, Epoch 80/130 => Loss 32.091,  Loss1 0.786, Train_accy 61.09
2024-09-01 00:14:57,074 [foster.py] => SNet: Task 19, Epoch 81/130 => Loss 32.095,  Loss1 0.786, Train_accy 61.11, Test_accy 58.79
2024-09-01 00:15:04,846 [foster.py] => SNet: Task 19, Epoch 82/130 => Loss 32.064,  Loss1 0.786, Train_accy 61.54
2024-09-01 00:15:12,309 [foster.py] => SNet: Task 19, Epoch 83/130 => Loss 32.109,  Loss1 0.786, Train_accy 61.31
2024-09-01 00:15:19,904 [foster.py] => SNet: Task 19, Epoch 84/130 => Loss 32.104,  Loss1 0.786, Train_accy 62.89
2024-09-01 00:15:27,078 [foster.py] => SNet: Task 19, Epoch 85/130 => Loss 32.096,  Loss1 0.786, Train_accy 61.89
2024-09-01 00:15:36,930 [foster.py] => SNet: Task 19, Epoch 86/130 => Loss 32.110,  Loss1 0.786, Train_accy 61.27, Test_accy 59.20
2024-09-01 00:15:44,222 [foster.py] => SNet: Task 19, Epoch 87/130 => Loss 32.083,  Loss1 0.786, Train_accy 61.91
2024-09-01 00:15:51,750 [foster.py] => SNet: Task 19, Epoch 88/130 => Loss 32.072,  Loss1 0.786, Train_accy 60.71
2024-09-01 00:15:59,017 [foster.py] => SNet: Task 19, Epoch 89/130 => Loss 32.077,  Loss1 0.786, Train_accy 61.18
2024-09-01 00:16:06,613 [foster.py] => SNet: Task 19, Epoch 90/130 => Loss 32.094,  Loss1 0.786, Train_accy 61.71
2024-09-01 00:16:16,592 [foster.py] => SNet: Task 19, Epoch 91/130 => Loss 32.104,  Loss1 0.786, Train_accy 61.78, Test_accy 58.70
2024-09-01 00:16:23,835 [foster.py] => SNet: Task 19, Epoch 92/130 => Loss 32.094,  Loss1 0.786, Train_accy 61.58
2024-09-01 00:16:31,408 [foster.py] => SNet: Task 19, Epoch 93/130 => Loss 32.081,  Loss1 0.786, Train_accy 61.82
2024-09-01 00:16:38,706 [foster.py] => SNet: Task 19, Epoch 94/130 => Loss 32.073,  Loss1 0.786, Train_accy 61.85
2024-09-01 00:16:46,329 [foster.py] => SNet: Task 19, Epoch 95/130 => Loss 32.086,  Loss1 0.786, Train_accy 62.07
2024-09-01 00:16:56,292 [foster.py] => SNet: Task 19, Epoch 96/130 => Loss 32.087,  Loss1 0.786, Train_accy 62.25, Test_accy 58.89
2024-09-01 00:17:03,642 [foster.py] => SNet: Task 19, Epoch 97/130 => Loss 32.104,  Loss1 0.786, Train_accy 61.96
2024-09-01 00:17:10,847 [foster.py] => SNet: Task 19, Epoch 98/130 => Loss 32.091,  Loss1 0.786, Train_accy 61.60
2024-09-01 00:17:18,570 [foster.py] => SNet: Task 19, Epoch 99/130 => Loss 32.082,  Loss1 0.786, Train_accy 62.49
2024-09-01 00:17:26,052 [foster.py] => SNet: Task 19, Epoch 100/130 => Loss 32.097,  Loss1 0.786, Train_accy 62.98
2024-09-01 00:17:36,133 [foster.py] => SNet: Task 19, Epoch 101/130 => Loss 32.052,  Loss1 0.786, Train_accy 61.67, Test_accy 58.95
2024-09-01 00:17:43,630 [foster.py] => SNet: Task 19, Epoch 102/130 => Loss 32.082,  Loss1 0.786, Train_accy 61.09
2024-09-01 00:17:51,122 [foster.py] => SNet: Task 19, Epoch 103/130 => Loss 32.088,  Loss1 0.786, Train_accy 62.42
2024-09-01 00:17:58,323 [foster.py] => SNet: Task 19, Epoch 104/130 => Loss 32.106,  Loss1 0.786, Train_accy 61.42
2024-09-01 00:18:05,888 [foster.py] => SNet: Task 19, Epoch 105/130 => Loss 32.074,  Loss1 0.786, Train_accy 62.11
2024-09-01 00:18:16,110 [foster.py] => SNet: Task 19, Epoch 106/130 => Loss 32.077,  Loss1 0.786, Train_accy 61.54, Test_accy 58.83
2024-09-01 00:18:23,380 [foster.py] => SNet: Task 19, Epoch 107/130 => Loss 32.093,  Loss1 0.786, Train_accy 62.36
2024-09-01 00:18:30,677 [foster.py] => SNet: Task 19, Epoch 108/130 => Loss 32.085,  Loss1 0.786, Train_accy 61.02
2024-09-01 00:18:38,018 [foster.py] => SNet: Task 19, Epoch 109/130 => Loss 32.069,  Loss1 0.786, Train_accy 61.74
2024-09-01 00:18:45,330 [foster.py] => SNet: Task 19, Epoch 110/130 => Loss 32.078,  Loss1 0.786, Train_accy 62.63
2024-09-01 00:18:55,436 [foster.py] => SNet: Task 19, Epoch 111/130 => Loss 32.089,  Loss1 0.786, Train_accy 61.76, Test_accy 58.92
2024-09-01 00:19:02,737 [foster.py] => SNet: Task 19, Epoch 112/130 => Loss 32.088,  Loss1 0.786, Train_accy 62.42
2024-09-01 00:19:10,179 [foster.py] => SNet: Task 19, Epoch 113/130 => Loss 32.119,  Loss1 0.786, Train_accy 62.54
2024-09-01 00:19:17,615 [foster.py] => SNet: Task 19, Epoch 114/130 => Loss 32.115,  Loss1 0.786, Train_accy 62.58
2024-09-01 00:19:24,918 [foster.py] => SNet: Task 19, Epoch 115/130 => Loss 32.085,  Loss1 0.786, Train_accy 61.51
2024-09-01 00:19:34,892 [foster.py] => SNet: Task 19, Epoch 116/130 => Loss 32.075,  Loss1 0.786, Train_accy 61.65, Test_accy 58.82
2024-09-01 00:19:42,557 [foster.py] => SNet: Task 19, Epoch 117/130 => Loss 32.090,  Loss1 0.786, Train_accy 61.20
2024-09-01 00:19:49,861 [foster.py] => SNet: Task 19, Epoch 118/130 => Loss 32.095,  Loss1 0.786, Train_accy 61.82
2024-09-01 00:19:57,488 [foster.py] => SNet: Task 19, Epoch 119/130 => Loss 32.085,  Loss1 0.786, Train_accy 61.40
2024-09-01 00:20:04,834 [foster.py] => SNet: Task 19, Epoch 120/130 => Loss 32.097,  Loss1 0.786, Train_accy 62.65
2024-09-01 00:20:14,981 [foster.py] => SNet: Task 19, Epoch 121/130 => Loss 32.118,  Loss1 0.786, Train_accy 61.49, Test_accy 58.66
2024-09-01 00:20:22,499 [foster.py] => SNet: Task 19, Epoch 122/130 => Loss 32.075,  Loss1 0.786, Train_accy 62.56
2024-09-01 00:20:29,997 [foster.py] => SNet: Task 19, Epoch 123/130 => Loss 32.077,  Loss1 0.786, Train_accy 62.22
2024-09-01 00:20:37,652 [foster.py] => SNet: Task 19, Epoch 124/130 => Loss 32.087,  Loss1 0.786, Train_accy 62.14
2024-09-01 00:20:45,017 [foster.py] => SNet: Task 19, Epoch 125/130 => Loss 32.101,  Loss1 0.786, Train_accy 61.62
2024-09-01 00:20:55,037 [foster.py] => SNet: Task 19, Epoch 126/130 => Loss 32.075,  Loss1 0.786, Train_accy 62.42, Test_accy 58.63
2024-09-01 00:21:02,552 [foster.py] => SNet: Task 19, Epoch 127/130 => Loss 32.099,  Loss1 0.786, Train_accy 62.56
2024-09-01 00:21:09,994 [foster.py] => SNet: Task 19, Epoch 128/130 => Loss 32.081,  Loss1 0.786, Train_accy 63.56
2024-09-01 00:21:17,405 [foster.py] => SNet: Task 19, Epoch 129/130 => Loss 32.060,  Loss1 0.786, Train_accy 62.22
2024-09-01 00:21:24,706 [foster.py] => SNet: Task 19, Epoch 130/130 => Loss 32.065,  Loss1 0.786, Train_accy 62.22
2024-09-01 00:21:24,706 [foster.py] => do not weight align student!
2024-09-01 00:21:27,388 [foster.py] => darknet eval: 
2024-09-01 00:21:27,389 [foster.py] => CNN top1 curve: 58.77
2024-09-01 00:21:27,389 [foster.py] => CNN top5 curve: 86.11
2024-09-01 00:21:27,389 [foster.py] => CNN top1 平均值: 58.77
2024-09-01 00:21:27,392 [foster.py] => timees : 2362.8841252326965
2024-09-01 00:21:27,393 [base.py] => Reducing exemplars...(20 per classes)
2024-09-01 00:22:00,634 [base.py] => Constructing exemplars...(20 per classes)
2024-09-01 00:22:11,979 [foster.py] => Exemplar size: 2000
2024-09-01 00:22:11,980 [trainer.py] => CNN: {'total': 59.63, '00-09': 58.5, '10-19': 41.7, '20-29': 58.8, '30-39': 53.8, '40-49': 64.3, '50-59': 52.7, '60-69': 67.5, '70-79': 61.8, '80-89': 69.7, '90-99': 67.5, 'old': 59.15, 'new': 68.8}
2024-09-01 00:22:11,980 [trainer.py] => NME: {'total': 53.17, '00-09': 45.4, '10-19': 31.8, '20-29': 52.2, '30-39': 46.2, '40-49': 59.4, '50-59': 48.3, '60-69': 60.9, '70-79': 58.9, '80-89': 63.8, '90-99': 64.8, 'old': 52.12, 'new': 73.2}
2024-09-01 00:22:11,980 [trainer.py] => CNN top1 curve: [98.8, 93.9, 88.6, 83.4, 83.2, 79.87, 77.89, 74.5, 73.22, 72.68, 71.04, 69.45, 67.8, 67.11, 64.85, 63.39, 62.78, 61.57, 60.4, 59.63]
2024-09-01 00:22:11,980 [trainer.py] => CNN top5 curve: [100.0, 99.8, 99.13, 97.35, 97.16, 96.4, 95.86, 94.2, 93.6, 93.28, 92.73, 91.43, 90.48, 89.87, 88.96, 88.72, 88.04, 87.48, 86.41, 85.85]
2024-09-01 00:22:11,980 [trainer.py] => NME top1 curve: [99.0, 94.1, 88.67, 81.85, 80.12, 78.27, 75.09, 72.15, 70.36, 68.62, 66.42, 64.53, 62.46, 61.64, 59.17, 56.89, 56.42, 55.28, 54.56, 53.17]
2024-09-01 00:22:11,980 [trainer.py] => NME top5 curve: [100.0, 99.7, 98.87, 97.2, 95.68, 94.87, 93.97, 93.68, 92.13, 90.94, 89.98, 89.28, 87.62, 86.44, 85.84, 84.65, 84.15, 82.79, 82.0, 80.94]

2024-09-01 00:22:11,980 [trainer.py] => CNN top1 平均值: 73.70