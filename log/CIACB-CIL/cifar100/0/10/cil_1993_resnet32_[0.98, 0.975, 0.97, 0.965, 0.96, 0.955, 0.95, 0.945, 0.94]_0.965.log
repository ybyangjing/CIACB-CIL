2024-08-07 12:35:58,030 [trainer.py] => config: ./configs/cifar/b0inc10.json
2024-08-07 12:35:58,033 [trainer.py] => prefix: cil
2024-08-07 12:35:58,034 [trainer.py] => dataset: cifar100
2024-08-07 12:35:58,034 [trainer.py] => memory_size: 2000
2024-08-07 12:35:58,034 [trainer.py] => memory_per_class: 20
2024-08-07 12:35:58,035 [trainer.py] => fixed_memory: False
2024-08-07 12:35:58,035 [trainer.py] => shuffle: True
2024-08-07 12:35:58,036 [trainer.py] => init_cls: 10
2024-08-07 12:35:58,036 [trainer.py] => increment: 10
2024-08-07 12:35:58,036 [trainer.py] => model_name: foster
2024-08-07 12:35:58,037 [trainer.py] => convnet_type: resnet32
2024-08-07 12:35:58,037 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-07 12:35:58,037 [trainer.py] => seed: 1993
2024-08-07 12:35:58,038 [trainer.py] => beta1: [0.98, 0.975, 0.97, 0.965, 0.96, 0.955, 0.95, 0.945, 0.94]
2024-08-07 12:35:58,038 [trainer.py] => beta2: 0.965
2024-08-07 12:35:58,038 [trainer.py] => oofc: ft
2024-08-07 12:35:58,039 [trainer.py] => is_teacher_wa: False
2024-08-07 12:35:58,039 [trainer.py] => is_student_wa: False
2024-08-07 12:35:58,039 [trainer.py] => lambda_okd: 1
2024-08-07 12:35:58,040 [trainer.py] => wa_value: 1
2024-08-07 12:35:58,040 [trainer.py] => init_epochs: 200
2024-08-07 12:35:58,040 [trainer.py] => init_lr: 0.1
2024-08-07 12:35:58,040 [trainer.py] => init_weight_decay: 0.0005
2024-08-07 12:35:58,041 [trainer.py] => boosting_epochs: 170
2024-08-07 12:35:58,045 [trainer.py] => compression_epochs: 130
2024-08-07 12:35:58,045 [trainer.py] => lr: 0.1
2024-08-07 12:35:58,045 [trainer.py] => batch_size: 128
2024-08-07 12:35:58,045 [trainer.py] => weight_decay: 0.0005
2024-08-07 12:35:58,045 [trainer.py] => num_workers: 8
2024-08-07 12:35:58,045 [trainer.py] => T: 2
2024-08-07 12:36:00,607 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-07 12:36:00,725 [trainer.py] => All params: 0
2024-08-07 12:36:00,725 [trainer.py] => Trainable params: 0
2024-08-07 12:36:03,288 [foster.py] => Learning on 0-10
2024-08-07 12:36:03,289 [foster.py] => All params: 642574
2024-08-07 12:36:03,290 [foster.py] => Trainable params: 642574
2024-08-07 12:36:28,738 [foster.py] => Task 0, Epoch 1/200 => Loss 2.241, Train_accy 16.52, Test_accy 24.30
2024-08-07 12:36:33,124 [foster.py] => Task 0, Epoch 2/200 => Loss 2.071, Loss1 2.071,Train_accy 24.54
2024-08-07 12:36:37,461 [foster.py] => Task 0, Epoch 3/200 => Loss 1.976, Loss1 1.976,Train_accy 27.80
2024-08-07 12:36:41,815 [foster.py] => Task 0, Epoch 4/200 => Loss 1.885, Loss1 1.885,Train_accy 32.28
2024-08-07 12:36:46,176 [foster.py] => Task 0, Epoch 5/200 => Loss 1.834, Loss1 1.834,Train_accy 34.86
2024-08-07 12:36:51,415 [foster.py] => Task 0, Epoch 6/200 => Loss 1.743, Train_accy 38.22, Test_accy 48.00
2024-08-07 12:36:55,799 [foster.py] => Task 0, Epoch 7/200 => Loss 1.716, Loss1 1.716,Train_accy 39.38
2024-08-07 12:37:00,133 [foster.py] => Task 0, Epoch 8/200 => Loss 1.659, Loss1 1.659,Train_accy 41.54
2024-08-07 12:37:04,472 [foster.py] => Task 0, Epoch 9/200 => Loss 1.580, Loss1 1.580,Train_accy 44.62
2024-08-07 12:37:08,868 [foster.py] => Task 0, Epoch 10/200 => Loss 1.582, Loss1 1.582,Train_accy 44.90
2024-08-07 12:37:14,126 [foster.py] => Task 0, Epoch 11/200 => Loss 1.543, Train_accy 46.12, Test_accy 48.70
2024-08-07 12:37:18,514 [foster.py] => Task 0, Epoch 12/200 => Loss 1.455, Loss1 1.455,Train_accy 49.42
2024-08-07 12:37:22,913 [foster.py] => Task 0, Epoch 13/200 => Loss 1.432, Loss1 1.432,Train_accy 50.18
2024-08-07 12:37:27,274 [foster.py] => Task 0, Epoch 14/200 => Loss 1.402, Loss1 1.402,Train_accy 51.44
2024-08-07 12:37:31,639 [foster.py] => Task 0, Epoch 15/200 => Loss 1.363, Loss1 1.363,Train_accy 52.34
2024-08-07 12:37:36,894 [foster.py] => Task 0, Epoch 16/200 => Loss 1.392, Train_accy 53.02, Test_accy 51.60
2024-08-07 12:37:41,288 [foster.py] => Task 0, Epoch 17/200 => Loss 1.349, Loss1 1.349,Train_accy 54.38
2024-08-07 12:37:45,712 [foster.py] => Task 0, Epoch 18/200 => Loss 1.289, Loss1 1.289,Train_accy 55.68
2024-08-07 12:37:50,105 [foster.py] => Task 0, Epoch 19/200 => Loss 1.295, Loss1 1.295,Train_accy 56.56
2024-08-07 12:37:54,477 [foster.py] => Task 0, Epoch 20/200 => Loss 1.266, Loss1 1.266,Train_accy 56.40
2024-08-07 12:37:59,748 [foster.py] => Task 0, Epoch 21/200 => Loss 1.229, Train_accy 58.32, Test_accy 68.20
2024-08-07 12:38:04,156 [foster.py] => Task 0, Epoch 22/200 => Loss 1.176, Loss1 1.176,Train_accy 59.68
2024-08-07 12:38:08,540 [foster.py] => Task 0, Epoch 23/200 => Loss 1.108, Loss1 1.108,Train_accy 62.02
2024-08-07 12:38:12,912 [foster.py] => Task 0, Epoch 24/200 => Loss 1.149, Loss1 1.149,Train_accy 61.38
2024-08-07 12:38:17,290 [foster.py] => Task 0, Epoch 25/200 => Loss 1.234, Loss1 1.234,Train_accy 58.66
2024-08-07 12:38:22,549 [foster.py] => Task 0, Epoch 26/200 => Loss 1.140, Train_accy 61.54, Test_accy 68.10
2024-08-07 12:38:26,906 [foster.py] => Task 0, Epoch 27/200 => Loss 1.069, Loss1 1.069,Train_accy 63.18
2024-08-07 12:38:31,250 [foster.py] => Task 0, Epoch 28/200 => Loss 1.075, Loss1 1.075,Train_accy 62.90
2024-08-07 12:38:35,654 [foster.py] => Task 0, Epoch 29/200 => Loss 1.108, Loss1 1.108,Train_accy 62.48
2024-08-07 12:38:40,060 [foster.py] => Task 0, Epoch 30/200 => Loss 1.108, Loss1 1.108,Train_accy 63.18
2024-08-07 12:38:45,288 [foster.py] => Task 0, Epoch 31/200 => Loss 1.066, Train_accy 64.12, Test_accy 77.80
2024-08-07 12:38:49,646 [foster.py] => Task 0, Epoch 32/200 => Loss 1.006, Loss1 1.006,Train_accy 67.34
2024-08-07 12:38:54,054 [foster.py] => Task 0, Epoch 33/200 => Loss 1.002, Loss1 1.002,Train_accy 65.68
2024-08-07 12:38:58,422 [foster.py] => Task 0, Epoch 34/200 => Loss 0.960, Loss1 0.960,Train_accy 67.46
2024-08-07 12:39:02,818 [foster.py] => Task 0, Epoch 35/200 => Loss 0.908, Loss1 0.908,Train_accy 69.36
2024-08-07 12:39:08,092 [foster.py] => Task 0, Epoch 36/200 => Loss 0.875, Train_accy 69.50, Test_accy 70.90
2024-08-07 12:39:12,469 [foster.py] => Task 0, Epoch 37/200 => Loss 0.886, Loss1 0.886,Train_accy 70.34
2024-08-07 12:39:16,862 [foster.py] => Task 0, Epoch 38/200 => Loss 0.940, Loss1 0.940,Train_accy 68.34
2024-08-07 12:39:21,237 [foster.py] => Task 0, Epoch 39/200 => Loss 0.931, Loss1 0.931,Train_accy 69.84
2024-08-07 12:39:25,582 [foster.py] => Task 0, Epoch 40/200 => Loss 0.943, Loss1 0.943,Train_accy 67.94
2024-08-07 12:39:30,851 [foster.py] => Task 0, Epoch 41/200 => Loss 0.856, Train_accy 70.74, Test_accy 75.60
2024-08-07 12:39:35,219 [foster.py] => Task 0, Epoch 42/200 => Loss 0.973, Loss1 0.973,Train_accy 67.64
2024-08-07 12:39:39,607 [foster.py] => Task 0, Epoch 43/200 => Loss 0.897, Loss1 0.897,Train_accy 68.82
2024-08-07 12:39:43,984 [foster.py] => Task 0, Epoch 44/200 => Loss 0.909, Loss1 0.909,Train_accy 69.94
2024-08-07 12:39:48,353 [foster.py] => Task 0, Epoch 45/200 => Loss 0.915, Loss1 0.915,Train_accy 69.66
2024-08-07 12:39:53,609 [foster.py] => Task 0, Epoch 46/200 => Loss 0.881, Train_accy 69.90, Test_accy 79.10
2024-08-07 12:39:57,982 [foster.py] => Task 0, Epoch 47/200 => Loss 0.856, Loss1 0.856,Train_accy 71.12
2024-08-07 12:40:02,364 [foster.py] => Task 0, Epoch 48/200 => Loss 0.867, Loss1 0.867,Train_accy 71.20
2024-08-07 12:40:06,705 [foster.py] => Task 0, Epoch 49/200 => Loss 0.815, Loss1 0.815,Train_accy 72.26
2024-08-07 12:40:11,101 [foster.py] => Task 0, Epoch 50/200 => Loss 0.871, Loss1 0.871,Train_accy 71.40
2024-08-07 12:40:16,360 [foster.py] => Task 0, Epoch 51/200 => Loss 0.851, Train_accy 72.00, Test_accy 80.50
2024-08-07 12:40:20,725 [foster.py] => Task 0, Epoch 52/200 => Loss 0.853, Loss1 0.853,Train_accy 71.32
2024-08-07 12:40:25,077 [foster.py] => Task 0, Epoch 53/200 => Loss 0.796, Loss1 0.796,Train_accy 75.20
2024-08-07 12:40:29,459 [foster.py] => Task 0, Epoch 54/200 => Loss 0.895, Loss1 0.895,Train_accy 71.24
2024-08-07 12:40:33,867 [foster.py] => Task 0, Epoch 55/200 => Loss 0.886, Loss1 0.886,Train_accy 70.28
2024-08-07 12:40:39,132 [foster.py] => Task 0, Epoch 56/200 => Loss 0.826, Train_accy 72.62, Test_accy 84.50
2024-08-07 12:40:43,520 [foster.py] => Task 0, Epoch 57/200 => Loss 0.757, Loss1 0.757,Train_accy 74.34
2024-08-07 12:40:47,908 [foster.py] => Task 0, Epoch 58/200 => Loss 0.734, Loss1 0.734,Train_accy 75.18
2024-08-07 12:40:52,321 [foster.py] => Task 0, Epoch 59/200 => Loss 0.771, Loss1 0.771,Train_accy 74.04
2024-08-07 12:40:56,697 [foster.py] => Task 0, Epoch 60/200 => Loss 0.793, Loss1 0.793,Train_accy 74.08
2024-08-07 12:41:01,943 [foster.py] => Task 0, Epoch 61/200 => Loss 0.784, Train_accy 74.10, Test_accy 82.80
2024-08-07 12:41:06,354 [foster.py] => Task 0, Epoch 62/200 => Loss 0.697, Loss1 0.697,Train_accy 75.86
2024-08-07 12:41:10,750 [foster.py] => Task 0, Epoch 63/200 => Loss 0.668, Loss1 0.668,Train_accy 77.76
2024-08-07 12:41:15,138 [foster.py] => Task 0, Epoch 64/200 => Loss 0.774, Loss1 0.774,Train_accy 74.36
2024-08-07 12:41:19,517 [foster.py] => Task 0, Epoch 65/200 => Loss 0.776, Loss1 0.776,Train_accy 73.80
2024-08-07 12:41:24,751 [foster.py] => Task 0, Epoch 66/200 => Loss 0.688, Train_accy 77.00, Test_accy 82.50
2024-08-07 12:41:29,154 [foster.py] => Task 0, Epoch 67/200 => Loss 0.719, Loss1 0.719,Train_accy 75.24
2024-08-07 12:41:33,521 [foster.py] => Task 0, Epoch 68/200 => Loss 0.756, Loss1 0.756,Train_accy 74.18
2024-08-07 12:41:37,897 [foster.py] => Task 0, Epoch 69/200 => Loss 0.715, Loss1 0.715,Train_accy 76.44
2024-08-07 12:41:42,276 [foster.py] => Task 0, Epoch 70/200 => Loss 0.689, Loss1 0.689,Train_accy 76.88
2024-08-07 12:41:47,518 [foster.py] => Task 0, Epoch 71/200 => Loss 0.708, Train_accy 76.56, Test_accy 80.00
2024-08-07 12:41:51,925 [foster.py] => Task 0, Epoch 72/200 => Loss 0.721, Loss1 0.721,Train_accy 75.56
2024-08-07 12:41:56,312 [foster.py] => Task 0, Epoch 73/200 => Loss 0.702, Loss1 0.702,Train_accy 76.62
2024-08-07 12:42:00,730 [foster.py] => Task 0, Epoch 74/200 => Loss 0.715, Loss1 0.715,Train_accy 75.60
2024-08-07 12:42:05,109 [foster.py] => Task 0, Epoch 75/200 => Loss 0.687, Loss1 0.687,Train_accy 77.22
2024-08-07 12:42:10,323 [foster.py] => Task 0, Epoch 76/200 => Loss 0.644, Train_accy 77.64, Test_accy 86.70
2024-08-07 12:42:14,726 [foster.py] => Task 0, Epoch 77/200 => Loss 0.635, Loss1 0.635,Train_accy 78.36
2024-08-07 12:42:19,132 [foster.py] => Task 0, Epoch 78/200 => Loss 0.621, Loss1 0.621,Train_accy 79.60
2024-08-07 12:42:23,522 [foster.py] => Task 0, Epoch 79/200 => Loss 0.684, Loss1 0.684,Train_accy 77.02
2024-08-07 12:42:27,859 [foster.py] => Task 0, Epoch 80/200 => Loss 0.647, Loss1 0.647,Train_accy 78.22
2024-08-07 12:42:33,122 [foster.py] => Task 0, Epoch 81/200 => Loss 0.690, Train_accy 77.68, Test_accy 80.30
2024-08-07 12:42:37,529 [foster.py] => Task 0, Epoch 82/200 => Loss 0.713, Loss1 0.713,Train_accy 76.78
2024-08-07 12:42:41,870 [foster.py] => Task 0, Epoch 83/200 => Loss 0.641, Loss1 0.641,Train_accy 78.38
2024-08-07 12:42:46,270 [foster.py] => Task 0, Epoch 84/200 => Loss 0.628, Loss1 0.628,Train_accy 79.48
2024-08-07 12:42:50,655 [foster.py] => Task 0, Epoch 85/200 => Loss 0.691, Loss1 0.691,Train_accy 78.14
2024-08-07 12:42:55,917 [foster.py] => Task 0, Epoch 86/200 => Loss 0.755, Train_accy 75.58, Test_accy 84.40
2024-08-07 12:43:00,268 [foster.py] => Task 0, Epoch 87/200 => Loss 0.629, Loss1 0.629,Train_accy 79.00
2024-08-07 12:43:04,614 [foster.py] => Task 0, Epoch 88/200 => Loss 0.624, Loss1 0.624,Train_accy 78.86
2024-08-07 12:43:09,001 [foster.py] => Task 0, Epoch 89/200 => Loss 0.619, Loss1 0.619,Train_accy 79.02
2024-08-07 12:43:13,379 [foster.py] => Task 0, Epoch 90/200 => Loss 0.700, Loss1 0.700,Train_accy 76.94
2024-08-07 12:43:18,629 [foster.py] => Task 0, Epoch 91/200 => Loss 0.608, Train_accy 80.32, Test_accy 83.10
2024-08-07 12:43:23,056 [foster.py] => Task 0, Epoch 92/200 => Loss 0.618, Loss1 0.618,Train_accy 79.24
2024-08-07 12:43:27,416 [foster.py] => Task 0, Epoch 93/200 => Loss 0.567, Loss1 0.567,Train_accy 81.08
2024-08-07 12:43:31,815 [foster.py] => Task 0, Epoch 94/200 => Loss 0.668, Loss1 0.668,Train_accy 77.60
2024-08-07 12:43:36,213 [foster.py] => Task 0, Epoch 95/200 => Loss 0.644, Loss1 0.644,Train_accy 78.34
2024-08-07 12:43:41,462 [foster.py] => Task 0, Epoch 96/200 => Loss 0.611, Train_accy 80.56, Test_accy 82.70
2024-08-07 12:43:45,864 [foster.py] => Task 0, Epoch 97/200 => Loss 0.670, Loss1 0.670,Train_accy 77.82
2024-08-07 12:43:50,244 [foster.py] => Task 0, Epoch 98/200 => Loss 0.614, Loss1 0.614,Train_accy 79.52
2024-08-07 12:43:54,610 [foster.py] => Task 0, Epoch 99/200 => Loss 0.561, Loss1 0.561,Train_accy 80.80
2024-08-07 12:43:58,930 [foster.py] => Task 0, Epoch 100/200 => Loss 0.612, Loss1 0.612,Train_accy 78.64
2024-08-07 12:44:04,194 [foster.py] => Task 0, Epoch 101/200 => Loss 0.570, Train_accy 80.78, Test_accy 85.50
2024-08-07 12:44:08,627 [foster.py] => Task 0, Epoch 102/200 => Loss 0.543, Loss1 0.543,Train_accy 81.20
2024-08-07 12:44:13,009 [foster.py] => Task 0, Epoch 103/200 => Loss 0.538, Loss1 0.538,Train_accy 82.42
2024-08-07 12:44:17,374 [foster.py] => Task 0, Epoch 104/200 => Loss 0.584, Loss1 0.584,Train_accy 81.62
2024-08-07 12:44:21,768 [foster.py] => Task 0, Epoch 105/200 => Loss 0.659, Loss1 0.659,Train_accy 78.24
2024-08-07 12:44:26,980 [foster.py] => Task 0, Epoch 106/200 => Loss 0.583, Train_accy 80.72, Test_accy 88.90
2024-08-07 12:44:31,343 [foster.py] => Task 0, Epoch 107/200 => Loss 0.588, Loss1 0.588,Train_accy 80.22
2024-08-07 12:44:35,741 [foster.py] => Task 0, Epoch 108/200 => Loss 0.575, Loss1 0.575,Train_accy 80.58
2024-08-07 12:44:40,084 [foster.py] => Task 0, Epoch 109/200 => Loss 0.548, Loss1 0.548,Train_accy 81.88
2024-08-07 12:44:44,482 [foster.py] => Task 0, Epoch 110/200 => Loss 0.551, Loss1 0.551,Train_accy 82.26
2024-08-07 12:44:49,786 [foster.py] => Task 0, Epoch 111/200 => Loss 0.531, Train_accy 82.58, Test_accy 84.90
2024-08-07 12:44:54,200 [foster.py] => Task 0, Epoch 112/200 => Loss 0.654, Loss1 0.654,Train_accy 78.16
2024-08-07 12:44:58,526 [foster.py] => Task 0, Epoch 113/200 => Loss 0.515, Loss1 0.515,Train_accy 82.74
2024-08-07 12:45:02,904 [foster.py] => Task 0, Epoch 114/200 => Loss 0.501, Loss1 0.501,Train_accy 83.80
2024-08-07 12:45:07,290 [foster.py] => Task 0, Epoch 115/200 => Loss 0.598, Loss1 0.598,Train_accy 79.70
2024-08-07 12:45:12,491 [foster.py] => Task 0, Epoch 116/200 => Loss 0.593, Train_accy 81.74, Test_accy 86.50
2024-08-07 12:45:16,815 [foster.py] => Task 0, Epoch 117/200 => Loss 0.581, Loss1 0.581,Train_accy 80.96
2024-08-07 12:45:21,197 [foster.py] => Task 0, Epoch 118/200 => Loss 0.479, Loss1 0.479,Train_accy 83.30
2024-08-07 12:45:25,584 [foster.py] => Task 0, Epoch 119/200 => Loss 0.468, Loss1 0.468,Train_accy 83.90
2024-08-07 12:45:29,928 [foster.py] => Task 0, Epoch 120/200 => Loss 0.486, Loss1 0.486,Train_accy 83.12
2024-08-07 12:45:35,174 [foster.py] => Task 0, Epoch 121/200 => Loss 0.507, Train_accy 83.16, Test_accy 89.10
2024-08-07 12:45:39,542 [foster.py] => Task 0, Epoch 122/200 => Loss 0.543, Loss1 0.543,Train_accy 81.64
2024-08-07 12:45:43,919 [foster.py] => Task 0, Epoch 123/200 => Loss 0.527, Loss1 0.527,Train_accy 83.10
2024-08-07 12:45:48,283 [foster.py] => Task 0, Epoch 124/200 => Loss 0.543, Loss1 0.543,Train_accy 81.74
2024-08-07 12:45:52,671 [foster.py] => Task 0, Epoch 125/200 => Loss 0.544, Loss1 0.544,Train_accy 81.22
2024-08-07 12:45:57,888 [foster.py] => Task 0, Epoch 126/200 => Loss 0.477, Train_accy 84.30, Test_accy 87.10
2024-08-07 12:46:02,246 [foster.py] => Task 0, Epoch 127/200 => Loss 0.513, Loss1 0.513,Train_accy 82.66
2024-08-07 12:46:06,646 [foster.py] => Task 0, Epoch 128/200 => Loss 0.434, Loss1 0.434,Train_accy 85.22
2024-08-07 12:46:11,014 [foster.py] => Task 0, Epoch 129/200 => Loss 0.478, Loss1 0.478,Train_accy 84.60
2024-08-07 12:46:15,382 [foster.py] => Task 0, Epoch 130/200 => Loss 0.440, Loss1 0.440,Train_accy 84.88
2024-08-07 12:46:20,658 [foster.py] => Task 0, Epoch 131/200 => Loss 0.429, Train_accy 85.72, Test_accy 90.00
2024-08-07 12:46:25,067 [foster.py] => Task 0, Epoch 132/200 => Loss 0.454, Loss1 0.454,Train_accy 84.62
2024-08-07 12:46:29,434 [foster.py] => Task 0, Epoch 133/200 => Loss 0.430, Loss1 0.430,Train_accy 86.00
2024-08-07 12:46:33,781 [foster.py] => Task 0, Epoch 134/200 => Loss 0.494, Loss1 0.494,Train_accy 83.36
2024-08-07 12:46:38,141 [foster.py] => Task 0, Epoch 135/200 => Loss 0.448, Loss1 0.448,Train_accy 85.90
2024-08-07 12:46:43,404 [foster.py] => Task 0, Epoch 136/200 => Loss 0.474, Train_accy 84.12, Test_accy 91.00
2024-08-07 12:46:47,763 [foster.py] => Task 0, Epoch 137/200 => Loss 0.435, Loss1 0.435,Train_accy 85.56
2024-08-07 12:46:52,132 [foster.py] => Task 0, Epoch 138/200 => Loss 0.403, Loss1 0.403,Train_accy 86.90
2024-08-07 12:46:56,509 [foster.py] => Task 0, Epoch 139/200 => Loss 0.470, Loss1 0.470,Train_accy 85.00
2024-08-07 12:47:00,898 [foster.py] => Task 0, Epoch 140/200 => Loss 0.448, Loss1 0.448,Train_accy 85.04
2024-08-07 12:47:06,173 [foster.py] => Task 0, Epoch 141/200 => Loss 0.414, Train_accy 85.48, Test_accy 91.40
2024-08-07 12:47:10,544 [foster.py] => Task 0, Epoch 142/200 => Loss 0.412, Loss1 0.412,Train_accy 86.68
2024-08-07 12:47:14,922 [foster.py] => Task 0, Epoch 143/200 => Loss 0.416, Loss1 0.416,Train_accy 86.12
2024-08-07 12:47:19,275 [foster.py] => Task 0, Epoch 144/200 => Loss 0.447, Loss1 0.447,Train_accy 85.02
2024-08-07 12:47:23,635 [foster.py] => Task 0, Epoch 145/200 => Loss 0.425, Loss1 0.425,Train_accy 86.80
2024-08-07 12:47:28,885 [foster.py] => Task 0, Epoch 146/200 => Loss 0.424, Train_accy 86.44, Test_accy 91.00
2024-08-07 12:47:33,277 [foster.py] => Task 0, Epoch 147/200 => Loss 0.404, Loss1 0.404,Train_accy 86.38
2024-08-07 12:47:37,653 [foster.py] => Task 0, Epoch 148/200 => Loss 0.397, Loss1 0.397,Train_accy 86.62
2024-08-07 12:47:42,037 [foster.py] => Task 0, Epoch 149/200 => Loss 0.367, Loss1 0.367,Train_accy 88.02
2024-08-07 12:47:46,396 [foster.py] => Task 0, Epoch 150/200 => Loss 0.369, Loss1 0.369,Train_accy 87.78
2024-08-07 12:47:51,584 [foster.py] => Task 0, Epoch 151/200 => Loss 0.418, Train_accy 86.86, Test_accy 92.60
2024-08-07 12:47:55,978 [foster.py] => Task 0, Epoch 152/200 => Loss 0.388, Loss1 0.388,Train_accy 87.38
2024-08-07 12:48:00,353 [foster.py] => Task 0, Epoch 153/200 => Loss 0.363, Loss1 0.363,Train_accy 87.68
2024-08-07 12:48:04,732 [foster.py] => Task 0, Epoch 154/200 => Loss 0.331, Loss1 0.331,Train_accy 88.76
2024-08-07 12:48:09,115 [foster.py] => Task 0, Epoch 155/200 => Loss 0.384, Loss1 0.384,Train_accy 87.58
2024-08-07 12:48:14,386 [foster.py] => Task 0, Epoch 156/200 => Loss 0.338, Train_accy 88.40, Test_accy 92.70
2024-08-07 12:48:18,765 [foster.py] => Task 0, Epoch 157/200 => Loss 0.361, Loss1 0.361,Train_accy 88.62
2024-08-07 12:48:23,137 [foster.py] => Task 0, Epoch 158/200 => Loss 0.352, Loss1 0.352,Train_accy 88.54
2024-08-07 12:48:27,474 [foster.py] => Task 0, Epoch 159/200 => Loss 0.362, Loss1 0.362,Train_accy 87.88
2024-08-07 12:48:31,832 [foster.py] => Task 0, Epoch 160/200 => Loss 0.340, Loss1 0.340,Train_accy 88.78
2024-08-07 12:48:37,041 [foster.py] => Task 0, Epoch 161/200 => Loss 0.331, Train_accy 89.12, Test_accy 93.00
2024-08-07 12:48:41,427 [foster.py] => Task 0, Epoch 162/200 => Loss 0.328, Loss1 0.328,Train_accy 89.54
2024-08-07 12:48:45,811 [foster.py] => Task 0, Epoch 163/200 => Loss 0.343, Loss1 0.343,Train_accy 88.54
2024-08-07 12:48:50,137 [foster.py] => Task 0, Epoch 164/200 => Loss 0.347, Loss1 0.347,Train_accy 88.96
2024-08-07 12:48:54,490 [foster.py] => Task 0, Epoch 165/200 => Loss 0.328, Loss1 0.328,Train_accy 88.54
2024-08-07 12:48:59,731 [foster.py] => Task 0, Epoch 166/200 => Loss 0.314, Train_accy 89.94, Test_accy 93.70
2024-08-07 12:49:04,138 [foster.py] => Task 0, Epoch 167/200 => Loss 0.330, Loss1 0.330,Train_accy 89.38
2024-08-07 12:49:08,524 [foster.py] => Task 0, Epoch 168/200 => Loss 0.338, Loss1 0.338,Train_accy 89.14
2024-08-07 12:49:12,934 [foster.py] => Task 0, Epoch 169/200 => Loss 0.328, Loss1 0.328,Train_accy 89.18
2024-08-07 12:49:17,288 [foster.py] => Task 0, Epoch 170/200 => Loss 0.314, Loss1 0.314,Train_accy 89.92
2024-08-07 12:49:22,535 [foster.py] => Task 0, Epoch 171/200 => Loss 0.364, Train_accy 89.82, Test_accy 93.00
2024-08-07 12:49:26,920 [foster.py] => Task 0, Epoch 172/200 => Loss 0.322, Loss1 0.322,Train_accy 89.34
2024-08-07 12:49:31,306 [foster.py] => Task 0, Epoch 173/200 => Loss 0.285, Loss1 0.285,Train_accy 90.56
2024-08-07 12:49:35,676 [foster.py] => Task 0, Epoch 174/200 => Loss 0.278, Loss1 0.278,Train_accy 90.84
2024-08-07 12:49:40,111 [foster.py] => Task 0, Epoch 175/200 => Loss 0.285, Loss1 0.285,Train_accy 90.58
2024-08-07 12:49:45,348 [foster.py] => Task 0, Epoch 176/200 => Loss 0.303, Train_accy 90.84, Test_accy 93.10
2024-08-07 12:49:49,716 [foster.py] => Task 0, Epoch 177/200 => Loss 0.281, Loss1 0.281,Train_accy 90.62
2024-08-07 12:49:54,052 [foster.py] => Task 0, Epoch 178/200 => Loss 0.273, Loss1 0.273,Train_accy 91.02
2024-08-07 12:49:58,448 [foster.py] => Task 0, Epoch 179/200 => Loss 0.293, Loss1 0.293,Train_accy 90.62
2024-08-07 12:50:02,862 [foster.py] => Task 0, Epoch 180/200 => Loss 0.281, Loss1 0.281,Train_accy 91.28
2024-08-07 12:50:08,140 [foster.py] => Task 0, Epoch 181/200 => Loss 0.285, Train_accy 90.78, Test_accy 93.60
2024-08-07 12:50:12,543 [foster.py] => Task 0, Epoch 182/200 => Loss 0.262, Loss1 0.262,Train_accy 91.06
2024-08-07 12:50:16,934 [foster.py] => Task 0, Epoch 183/200 => Loss 0.301, Loss1 0.301,Train_accy 90.58
2024-08-07 12:50:21,327 [foster.py] => Task 0, Epoch 184/200 => Loss 0.296, Loss1 0.296,Train_accy 90.58
2024-08-07 12:50:25,714 [foster.py] => Task 0, Epoch 185/200 => Loss 0.269, Loss1 0.269,Train_accy 90.52
2024-08-07 12:50:30,983 [foster.py] => Task 0, Epoch 186/200 => Loss 0.266, Train_accy 91.02, Test_accy 94.10
2024-08-07 12:50:35,331 [foster.py] => Task 0, Epoch 187/200 => Loss 0.278, Loss1 0.278,Train_accy 90.94
2024-08-07 12:50:39,707 [foster.py] => Task 0, Epoch 188/200 => Loss 0.271, Loss1 0.271,Train_accy 91.48
2024-08-07 12:50:44,079 [foster.py] => Task 0, Epoch 189/200 => Loss 0.260, Loss1 0.260,Train_accy 91.88
2024-08-07 12:50:48,459 [foster.py] => Task 0, Epoch 190/200 => Loss 0.238, Loss1 0.238,Train_accy 91.80
2024-08-07 12:50:53,712 [foster.py] => Task 0, Epoch 191/200 => Loss 0.264, Train_accy 91.02, Test_accy 94.30
2024-08-07 12:50:58,120 [foster.py] => Task 0, Epoch 192/200 => Loss 0.295, Loss1 0.295,Train_accy 91.44
2024-08-07 12:51:02,516 [foster.py] => Task 0, Epoch 193/200 => Loss 0.271, Loss1 0.271,Train_accy 92.16
2024-08-07 12:51:06,904 [foster.py] => Task 0, Epoch 194/200 => Loss 0.260, Loss1 0.260,Train_accy 91.28
2024-08-07 12:51:11,308 [foster.py] => Task 0, Epoch 195/200 => Loss 0.261, Loss1 0.261,Train_accy 91.78
2024-08-07 12:51:16,549 [foster.py] => Task 0, Epoch 196/200 => Loss 0.265, Train_accy 91.26, Test_accy 94.30
2024-08-07 12:51:20,885 [foster.py] => Task 0, Epoch 197/200 => Loss 0.267, Loss1 0.267,Train_accy 91.52
2024-08-07 12:51:25,220 [foster.py] => Task 0, Epoch 198/200 => Loss 0.272, Loss1 0.272,Train_accy 91.74
2024-08-07 12:51:29,592 [foster.py] => Task 0, Epoch 199/200 => Loss 0.270, Loss1 0.270,Train_accy 91.52
2024-08-07 12:51:33,952 [foster.py] => Task 0, Epoch 200/200 => Loss 0.260, Loss1 0.260,Train_accy 91.28
2024-08-07 12:51:33,955 [foster.py] => training time: 930.6569261550903
2024-08-07 12:51:33,957 [base.py] => Reducing exemplars...(200 per classes)
2024-08-07 12:51:33,958 [base.py] => Constructing exemplars...(200 per classes)
2024-08-07 12:51:45,875 [foster.py] => Exemplar size: 2000
2024-08-07 12:51:45,875 [trainer.py] => CNN: {'total': 94.2, '00-09': 94.2, 'old': 0, 'new': 94.2}
2024-08-07 12:51:45,876 [trainer.py] => NME: {'total': 94.2, '00-09': 94.2, 'old': 0, 'new': 94.2}
2024-08-07 12:51:45,876 [trainer.py] => CNN top1 curve: [94.2]
2024-08-07 12:51:45,876 [trainer.py] => CNN top5 curve: [99.7]
2024-08-07 12:51:45,877 [trainer.py] => NME top1 curve: [94.2]
2024-08-07 12:51:45,877 [trainer.py] => NME top5 curve: [99.6]

2024-08-07 12:51:45,877 [trainer.py] => CNN top1 平均值: 94.20
2024-08-07 12:51:45,879 [trainer.py] => All params: 642574
2024-08-07 12:51:45,880 [trainer.py] => Trainable params: 642574
2024-08-07 12:51:46,017 [foster.py] => Learning on 10-20
2024-08-07 12:51:46,020 [foster.py] => All params: 1287078
2024-08-07 12:51:46,022 [foster.py] => Trainable params: 645154
2024-08-07 12:51:46,084 [foster.py] => per cls weights : [1.05644674 1.05644674 1.05644674 1.05644674 1.05644674 1.05644674
 1.05644674 1.05644674 1.05644674 1.05644674 0.94355326 0.94355326
 0.94355326 0.94355326 0.94355326 0.94355326 0.94355326 0.94355326
 0.94355326 0.94355326]
2024-08-07 12:51:54,088 [foster.py] => Task 1, Epoch 1/170 => Loss 5.551, Loss_clf 2.020, Loss_fe 2.209, Loss_kd 0.660, Train_accy 42.39
2024-08-07 12:52:02,881 [foster.py] => Task 1, Epoch 2/170 => Loss 4.895, Loss_clf 1.659, Loss_fe 1.943, Loss_kd 0.646, Train_accy 49.91, Test_accy 63.45
2024-08-07 12:52:11,613 [foster.py] => Task 1, Epoch 3/170 => Loss 4.723, Loss_clf 1.588, Loss_fe 1.839, Loss_kd 0.647, Train_accy 53.53, Test_accy 63.90
2024-08-07 12:52:20,329 [foster.py] => Task 1, Epoch 4/170 => Loss 4.564, Loss_clf 1.512, Loss_fe 1.762, Loss_kd 0.644, Train_accy 55.01, Test_accy 65.65
2024-08-07 12:52:29,132 [foster.py] => Task 1, Epoch 5/170 => Loss 4.553, Loss_clf 1.520, Loss_fe 1.744, Loss_kd 0.643, Train_accy 55.23, Test_accy 58.15
2024-08-07 12:52:36,589 [foster.py] => Task 1, Epoch 6/170 => Loss 4.485, Loss_clf 1.490, Loss_fe 1.695, Loss_kd 0.649, Train_accy 55.54
2024-08-07 12:52:45,309 [foster.py] => Task 1, Epoch 7/170 => Loss 4.412, Loss_clf 1.464, Loss_fe 1.657, Loss_kd 0.644, Train_accy 56.89, Test_accy 64.00
2024-08-07 12:52:54,141 [foster.py] => Task 1, Epoch 8/170 => Loss 4.327, Loss_clf 1.431, Loss_fe 1.603, Loss_kd 0.646, Train_accy 58.01, Test_accy 65.20
2024-08-07 12:53:02,795 [foster.py] => Task 1, Epoch 9/170 => Loss 4.285, Loss_clf 1.399, Loss_fe 1.593, Loss_kd 0.645, Train_accy 58.73, Test_accy 66.45
2024-08-07 12:53:11,533 [foster.py] => Task 1, Epoch 10/170 => Loss 4.241, Loss_clf 1.382, Loss_fe 1.561, Loss_kd 0.648, Train_accy 59.13, Test_accy 69.50
2024-08-07 12:53:18,948 [foster.py] => Task 1, Epoch 11/170 => Loss 4.227, Loss_clf 1.382, Loss_fe 1.555, Loss_kd 0.644, Train_accy 59.24
2024-08-07 12:53:27,733 [foster.py] => Task 1, Epoch 12/170 => Loss 4.156, Loss_clf 1.348, Loss_fe 1.521, Loss_kd 0.643, Train_accy 60.70, Test_accy 71.65
2024-08-07 12:53:36,526 [foster.py] => Task 1, Epoch 13/170 => Loss 4.149, Loss_clf 1.351, Loss_fe 1.500, Loss_kd 0.648, Train_accy 60.41, Test_accy 69.40
2024-08-07 12:53:45,289 [foster.py] => Task 1, Epoch 14/170 => Loss 4.143, Loss_clf 1.338, Loss_fe 1.510, Loss_kd 0.647, Train_accy 60.76, Test_accy 70.45
2024-08-07 12:53:54,111 [foster.py] => Task 1, Epoch 15/170 => Loss 4.107, Loss_clf 1.329, Loss_fe 1.483, Loss_kd 0.647, Train_accy 60.84, Test_accy 72.20
2024-08-07 12:54:01,643 [foster.py] => Task 1, Epoch 16/170 => Loss 4.085, Loss_clf 1.321, Loss_fe 1.473, Loss_kd 0.644, Train_accy 61.57
2024-08-07 12:54:10,545 [foster.py] => Task 1, Epoch 17/170 => Loss 4.076, Loss_clf 1.318, Loss_fe 1.460, Loss_kd 0.648, Train_accy 60.70, Test_accy 66.80
2024-08-07 12:54:19,341 [foster.py] => Task 1, Epoch 18/170 => Loss 4.017, Loss_clf 1.285, Loss_fe 1.439, Loss_kd 0.646, Train_accy 61.89, Test_accy 67.35
2024-08-07 12:54:28,017 [foster.py] => Task 1, Epoch 19/170 => Loss 4.005, Loss_clf 1.279, Loss_fe 1.444, Loss_kd 0.641, Train_accy 62.44, Test_accy 67.00
2024-08-07 12:54:36,763 [foster.py] => Task 1, Epoch 20/170 => Loss 4.048, Loss_clf 1.310, Loss_fe 1.448, Loss_kd 0.644, Train_accy 61.54, Test_accy 71.70
2024-08-07 12:54:44,401 [foster.py] => Task 1, Epoch 21/170 => Loss 3.970, Loss_clf 1.274, Loss_fe 1.400, Loss_kd 0.647, Train_accy 62.84
2024-08-07 12:54:53,240 [foster.py] => Task 1, Epoch 22/170 => Loss 3.945, Loss_clf 1.270, Loss_fe 1.379, Loss_kd 0.647, Train_accy 62.79, Test_accy 66.80
2024-08-07 12:55:02,045 [foster.py] => Task 1, Epoch 23/170 => Loss 3.952, Loss_clf 1.266, Loss_fe 1.395, Loss_kd 0.645, Train_accy 62.96, Test_accy 68.80
2024-08-07 12:55:10,866 [foster.py] => Task 1, Epoch 24/170 => Loss 3.947, Loss_clf 1.267, Loss_fe 1.385, Loss_kd 0.646, Train_accy 62.71, Test_accy 70.10
2024-08-07 12:55:19,614 [foster.py] => Task 1, Epoch 25/170 => Loss 3.947, Loss_clf 1.257, Loss_fe 1.390, Loss_kd 0.649, Train_accy 63.49, Test_accy 65.55
2024-08-07 12:55:27,260 [foster.py] => Task 1, Epoch 26/170 => Loss 3.898, Loss_clf 1.234, Loss_fe 1.365, Loss_kd 0.648, Train_accy 64.09
2024-08-07 12:55:36,344 [foster.py] => Task 1, Epoch 27/170 => Loss 3.887, Loss_clf 1.231, Loss_fe 1.368, Loss_kd 0.643, Train_accy 64.20, Test_accy 73.40
2024-08-07 12:55:45,086 [foster.py] => Task 1, Epoch 28/170 => Loss 3.822, Loss_clf 1.208, Loss_fe 1.319, Loss_kd 0.646, Train_accy 65.01, Test_accy 73.05
2024-08-07 12:55:54,235 [foster.py] => Task 1, Epoch 29/170 => Loss 3.857, Loss_clf 1.234, Loss_fe 1.334, Loss_kd 0.644, Train_accy 64.07, Test_accy 73.55
2024-08-07 12:56:02,920 [foster.py] => Task 1, Epoch 30/170 => Loss 3.817, Loss_clf 1.207, Loss_fe 1.320, Loss_kd 0.644, Train_accy 64.57, Test_accy 69.00
2024-08-07 12:56:10,646 [foster.py] => Task 1, Epoch 31/170 => Loss 3.819, Loss_clf 1.202, Loss_fe 1.327, Loss_kd 0.645, Train_accy 64.96
2024-08-07 12:56:19,439 [foster.py] => Task 1, Epoch 32/170 => Loss 3.839, Loss_clf 1.210, Loss_fe 1.330, Loss_kd 0.649, Train_accy 64.64, Test_accy 70.50
2024-08-07 12:56:28,192 [foster.py] => Task 1, Epoch 33/170 => Loss 3.782, Loss_clf 1.186, Loss_fe 1.304, Loss_kd 0.645, Train_accy 64.89, Test_accy 71.35
2024-08-07 12:56:37,107 [foster.py] => Task 1, Epoch 34/170 => Loss 3.754, Loss_clf 1.180, Loss_fe 1.285, Loss_kd 0.644, Train_accy 65.44, Test_accy 70.55
2024-08-07 12:56:45,924 [foster.py] => Task 1, Epoch 35/170 => Loss 3.794, Loss_clf 1.202, Loss_fe 1.299, Loss_kd 0.645, Train_accy 64.34, Test_accy 70.60
2024-08-07 12:56:53,454 [foster.py] => Task 1, Epoch 36/170 => Loss 3.771, Loss_clf 1.171, Loss_fe 1.302, Loss_kd 0.648, Train_accy 65.63
2024-08-07 12:57:02,141 [foster.py] => Task 1, Epoch 37/170 => Loss 3.706, Loss_clf 1.149, Loss_fe 1.264, Loss_kd 0.646, Train_accy 66.91, Test_accy 72.00
2024-08-07 12:57:10,845 [foster.py] => Task 1, Epoch 38/170 => Loss 3.718, Loss_clf 1.161, Loss_fe 1.262, Loss_kd 0.647, Train_accy 66.24, Test_accy 65.75
2024-08-07 12:57:19,602 [foster.py] => Task 1, Epoch 39/170 => Loss 3.747, Loss_clf 1.187, Loss_fe 1.259, Loss_kd 0.650, Train_accy 65.53, Test_accy 69.45
2024-08-07 12:57:28,591 [foster.py] => Task 1, Epoch 40/170 => Loss 3.689, Loss_clf 1.140, Loss_fe 1.261, Loss_kd 0.643, Train_accy 66.84, Test_accy 71.60
2024-08-07 12:57:36,286 [foster.py] => Task 1, Epoch 41/170 => Loss 3.639, Loss_clf 1.128, Loss_fe 1.219, Loss_kd 0.645, Train_accy 67.17
2024-08-07 12:57:45,142 [foster.py] => Task 1, Epoch 42/170 => Loss 3.650, Loss_clf 1.127, Loss_fe 1.230, Loss_kd 0.646, Train_accy 66.79, Test_accy 72.25
2024-08-07 12:57:53,938 [foster.py] => Task 1, Epoch 43/170 => Loss 3.625, Loss_clf 1.113, Loss_fe 1.225, Loss_kd 0.642, Train_accy 67.76, Test_accy 73.15
2024-08-07 12:58:02,723 [foster.py] => Task 1, Epoch 44/170 => Loss 3.647, Loss_clf 1.119, Loss_fe 1.228, Loss_kd 0.649, Train_accy 67.59, Test_accy 75.65
2024-08-07 12:58:11,519 [foster.py] => Task 1, Epoch 45/170 => Loss 3.585, Loss_clf 1.096, Loss_fe 1.197, Loss_kd 0.645, Train_accy 67.60, Test_accy 74.40
2024-08-07 12:58:19,008 [foster.py] => Task 1, Epoch 46/170 => Loss 3.625, Loss_clf 1.117, Loss_fe 1.214, Loss_kd 0.646, Train_accy 67.51
2024-08-07 12:58:27,757 [foster.py] => Task 1, Epoch 47/170 => Loss 3.618, Loss_clf 1.119, Loss_fe 1.200, Loss_kd 0.649, Train_accy 67.63, Test_accy 72.70
2024-08-07 12:58:36,480 [foster.py] => Task 1, Epoch 48/170 => Loss 3.633, Loss_clf 1.125, Loss_fe 1.217, Loss_kd 0.645, Train_accy 67.34, Test_accy 73.40
2024-08-07 12:58:45,388 [foster.py] => Task 1, Epoch 49/170 => Loss 3.628, Loss_clf 1.116, Loss_fe 1.219, Loss_kd 0.646, Train_accy 68.16, Test_accy 71.00
2024-08-07 12:58:54,296 [foster.py] => Task 1, Epoch 50/170 => Loss 3.587, Loss_clf 1.097, Loss_fe 1.195, Loss_kd 0.647, Train_accy 68.17, Test_accy 68.95
2024-08-07 12:59:01,908 [foster.py] => Task 1, Epoch 51/170 => Loss 3.542, Loss_clf 1.083, Loss_fe 1.168, Loss_kd 0.645, Train_accy 68.80
2024-08-07 12:59:10,912 [foster.py] => Task 1, Epoch 52/170 => Loss 3.546, Loss_clf 1.082, Loss_fe 1.176, Loss_kd 0.643, Train_accy 68.49, Test_accy 73.90
2024-08-07 12:59:19,672 [foster.py] => Task 1, Epoch 53/170 => Loss 3.547, Loss_clf 1.099, Loss_fe 1.158, Loss_kd 0.644, Train_accy 67.81, Test_accy 72.25
2024-08-07 12:59:28,450 [foster.py] => Task 1, Epoch 54/170 => Loss 3.540, Loss_clf 1.075, Loss_fe 1.168, Loss_kd 0.648, Train_accy 68.60, Test_accy 74.00
2024-08-07 12:59:37,256 [foster.py] => Task 1, Epoch 55/170 => Loss 3.488, Loss_clf 1.052, Loss_fe 1.141, Loss_kd 0.647, Train_accy 68.93, Test_accy 74.15
2024-08-07 12:59:44,690 [foster.py] => Task 1, Epoch 56/170 => Loss 3.514, Loss_clf 1.065, Loss_fe 1.164, Loss_kd 0.642, Train_accy 68.87
2024-08-07 12:59:53,542 [foster.py] => Task 1, Epoch 57/170 => Loss 3.520, Loss_clf 1.074, Loss_fe 1.150, Loss_kd 0.647, Train_accy 68.83, Test_accy 75.80
2024-08-07 13:00:02,303 [foster.py] => Task 1, Epoch 58/170 => Loss 3.500, Loss_clf 1.057, Loss_fe 1.142, Loss_kd 0.649, Train_accy 69.61, Test_accy 75.25
2024-08-07 13:00:11,198 [foster.py] => Task 1, Epoch 59/170 => Loss 3.507, Loss_clf 1.067, Loss_fe 1.145, Loss_kd 0.646, Train_accy 69.26, Test_accy 72.80
2024-08-07 13:00:19,957 [foster.py] => Task 1, Epoch 60/170 => Loss 3.505, Loss_clf 1.067, Loss_fe 1.150, Loss_kd 0.643, Train_accy 69.07, Test_accy 74.35
2024-08-07 13:00:27,364 [foster.py] => Task 1, Epoch 61/170 => Loss 3.468, Loss_clf 1.044, Loss_fe 1.134, Loss_kd 0.644, Train_accy 69.43
2024-08-07 13:00:36,160 [foster.py] => Task 1, Epoch 62/170 => Loss 3.454, Loss_clf 1.051, Loss_fe 1.120, Loss_kd 0.640, Train_accy 69.09, Test_accy 73.50
2024-08-07 13:00:44,904 [foster.py] => Task 1, Epoch 63/170 => Loss 3.461, Loss_clf 1.048, Loss_fe 1.113, Loss_kd 0.649, Train_accy 69.27, Test_accy 75.70
2024-08-07 13:00:53,591 [foster.py] => Task 1, Epoch 64/170 => Loss 3.452, Loss_clf 1.054, Loss_fe 1.102, Loss_kd 0.647, Train_accy 69.31, Test_accy 72.20
2024-08-07 13:01:02,470 [foster.py] => Task 1, Epoch 65/170 => Loss 3.447, Loss_clf 1.049, Loss_fe 1.104, Loss_kd 0.646, Train_accy 69.33, Test_accy 73.90
2024-08-07 13:01:10,070 [foster.py] => Task 1, Epoch 66/170 => Loss 3.399, Loss_clf 1.031, Loss_fe 1.082, Loss_kd 0.642, Train_accy 70.07
2024-08-07 13:01:18,829 [foster.py] => Task 1, Epoch 67/170 => Loss 3.375, Loss_clf 1.007, Loss_fe 1.077, Loss_kd 0.645, Train_accy 70.70, Test_accy 77.80
2024-08-07 13:01:27,601 [foster.py] => Task 1, Epoch 68/170 => Loss 3.369, Loss_clf 1.008, Loss_fe 1.069, Loss_kd 0.645, Train_accy 70.39, Test_accy 76.05
2024-08-07 13:01:36,483 [foster.py] => Task 1, Epoch 69/170 => Loss 3.377, Loss_clf 1.008, Loss_fe 1.080, Loss_kd 0.644, Train_accy 70.27, Test_accy 77.90
2024-08-07 13:01:45,278 [foster.py] => Task 1, Epoch 70/170 => Loss 3.342, Loss_clf 0.989, Loss_fe 1.063, Loss_kd 0.644, Train_accy 71.33, Test_accy 74.85
2024-08-07 13:01:52,731 [foster.py] => Task 1, Epoch 71/170 => Loss 3.333, Loss_clf 0.999, Loss_fe 1.051, Loss_kd 0.641, Train_accy 71.03
2024-08-07 13:02:01,594 [foster.py] => Task 1, Epoch 72/170 => Loss 3.352, Loss_clf 1.002, Loss_fe 1.056, Loss_kd 0.646, Train_accy 71.09, Test_accy 79.15
2024-08-07 13:02:10,509 [foster.py] => Task 1, Epoch 73/170 => Loss 3.285, Loss_clf 0.967, Loss_fe 1.033, Loss_kd 0.641, Train_accy 71.99, Test_accy 76.15
2024-08-07 13:02:19,217 [foster.py] => Task 1, Epoch 74/170 => Loss 3.343, Loss_clf 0.998, Loss_fe 1.054, Loss_kd 0.644, Train_accy 71.30, Test_accy 76.95
2024-08-07 13:02:27,973 [foster.py] => Task 1, Epoch 75/170 => Loss 3.320, Loss_clf 0.991, Loss_fe 1.033, Loss_kd 0.647, Train_accy 70.93, Test_accy 78.55
2024-08-07 13:02:35,728 [foster.py] => Task 1, Epoch 76/170 => Loss 3.300, Loss_clf 0.982, Loss_fe 1.022, Loss_kd 0.647, Train_accy 71.37
2024-08-07 13:02:44,759 [foster.py] => Task 1, Epoch 77/170 => Loss 3.307, Loss_clf 0.973, Loss_fe 1.035, Loss_kd 0.648, Train_accy 71.69, Test_accy 74.95
2024-08-07 13:02:53,803 [foster.py] => Task 1, Epoch 78/170 => Loss 3.275, Loss_clf 0.972, Loss_fe 1.009, Loss_kd 0.646, Train_accy 71.56, Test_accy 78.15
2024-08-07 13:03:02,829 [foster.py] => Task 1, Epoch 79/170 => Loss 3.265, Loss_clf 0.969, Loss_fe 1.005, Loss_kd 0.644, Train_accy 73.10, Test_accy 76.10
2024-08-07 13:03:11,812 [foster.py] => Task 1, Epoch 80/170 => Loss 3.240, Loss_clf 0.952, Loss_fe 0.996, Loss_kd 0.645, Train_accy 72.87, Test_accy 76.25
2024-08-07 13:03:19,499 [foster.py] => Task 1, Epoch 81/170 => Loss 3.270, Loss_clf 0.966, Loss_fe 1.007, Loss_kd 0.647, Train_accy 71.73
2024-08-07 13:03:28,351 [foster.py] => Task 1, Epoch 82/170 => Loss 3.244, Loss_clf 0.951, Loss_fe 1.005, Loss_kd 0.643, Train_accy 72.73, Test_accy 76.30
2024-08-07 13:03:37,177 [foster.py] => Task 1, Epoch 83/170 => Loss 3.223, Loss_clf 0.946, Loss_fe 0.984, Loss_kd 0.645, Train_accy 72.50, Test_accy 78.85
2024-08-07 13:03:45,934 [foster.py] => Task 1, Epoch 84/170 => Loss 3.240, Loss_clf 0.945, Loss_fe 0.993, Loss_kd 0.650, Train_accy 72.93, Test_accy 78.50
2024-08-07 13:03:54,715 [foster.py] => Task 1, Epoch 85/170 => Loss 3.193, Loss_clf 0.934, Loss_fe 0.968, Loss_kd 0.644, Train_accy 73.40, Test_accy 78.80
2024-08-07 13:04:02,210 [foster.py] => Task 1, Epoch 86/170 => Loss 3.200, Loss_clf 0.940, Loss_fe 0.974, Loss_kd 0.643, Train_accy 73.00
2024-08-07 13:04:11,000 [foster.py] => Task 1, Epoch 87/170 => Loss 3.118, Loss_clf 0.897, Loss_fe 0.928, Loss_kd 0.645, Train_accy 73.80, Test_accy 78.85
2024-08-07 13:04:19,726 [foster.py] => Task 1, Epoch 88/170 => Loss 3.185, Loss_clf 0.927, Loss_fe 0.961, Loss_kd 0.648, Train_accy 72.64, Test_accy 79.20
2024-08-07 13:04:28,531 [foster.py] => Task 1, Epoch 89/170 => Loss 3.115, Loss_clf 0.892, Loss_fe 0.936, Loss_kd 0.643, Train_accy 74.13, Test_accy 74.60
2024-08-07 13:04:37,352 [foster.py] => Task 1, Epoch 90/170 => Loss 3.170, Loss_clf 0.925, Loss_fe 0.952, Loss_kd 0.645, Train_accy 73.27, Test_accy 77.15
2024-08-07 13:04:44,801 [foster.py] => Task 1, Epoch 91/170 => Loss 3.101, Loss_clf 0.885, Loss_fe 0.923, Loss_kd 0.645, Train_accy 74.51
2024-08-07 13:04:53,581 [foster.py] => Task 1, Epoch 92/170 => Loss 3.099, Loss_clf 0.883, Loss_fe 0.919, Loss_kd 0.648, Train_accy 74.41, Test_accy 79.20
2024-08-07 13:05:02,312 [foster.py] => Task 1, Epoch 93/170 => Loss 3.090, Loss_clf 0.888, Loss_fe 0.912, Loss_kd 0.644, Train_accy 74.31, Test_accy 78.25
2024-08-07 13:05:11,164 [foster.py] => Task 1, Epoch 94/170 => Loss 3.064, Loss_clf 0.876, Loss_fe 0.893, Loss_kd 0.647, Train_accy 74.67, Test_accy 76.35
2024-08-07 13:05:19,951 [foster.py] => Task 1, Epoch 95/170 => Loss 3.056, Loss_clf 0.872, Loss_fe 0.896, Loss_kd 0.643, Train_accy 75.06, Test_accy 75.40
2024-08-07 13:05:27,450 [foster.py] => Task 1, Epoch 96/170 => Loss 3.062, Loss_clf 0.865, Loss_fe 0.900, Loss_kd 0.648, Train_accy 74.90
2024-08-07 13:05:36,148 [foster.py] => Task 1, Epoch 97/170 => Loss 3.033, Loss_clf 0.850, Loss_fe 0.884, Loss_kd 0.649, Train_accy 74.99, Test_accy 79.95
2024-08-07 13:05:44,906 [foster.py] => Task 1, Epoch 98/170 => Loss 3.100, Loss_clf 0.889, Loss_fe 0.909, Loss_kd 0.650, Train_accy 74.63, Test_accy 77.85
2024-08-07 13:05:53,799 [foster.py] => Task 1, Epoch 99/170 => Loss 3.005, Loss_clf 0.845, Loss_fe 0.867, Loss_kd 0.646, Train_accy 75.86, Test_accy 76.15
2024-08-07 13:06:02,760 [foster.py] => Task 1, Epoch 100/170 => Loss 2.979, Loss_clf 0.830, Loss_fe 0.858, Loss_kd 0.645, Train_accy 75.60, Test_accy 80.30
2024-08-07 13:06:10,252 [foster.py] => Task 1, Epoch 101/170 => Loss 2.939, Loss_clf 0.817, Loss_fe 0.835, Loss_kd 0.643, Train_accy 76.26
2024-08-07 13:06:18,999 [foster.py] => Task 1, Epoch 102/170 => Loss 2.953, Loss_clf 0.820, Loss_fe 0.842, Loss_kd 0.645, Train_accy 76.41, Test_accy 77.00
2024-08-07 13:06:27,778 [foster.py] => Task 1, Epoch 103/170 => Loss 2.962, Loss_clf 0.826, Loss_fe 0.839, Loss_kd 0.647, Train_accy 76.11, Test_accy 79.35
2024-08-07 13:06:36,822 [foster.py] => Task 1, Epoch 104/170 => Loss 2.978, Loss_clf 0.839, Loss_fe 0.853, Loss_kd 0.643, Train_accy 75.59, Test_accy 80.35
2024-08-07 13:06:45,559 [foster.py] => Task 1, Epoch 105/170 => Loss 2.896, Loss_clf 0.790, Loss_fe 0.812, Loss_kd 0.646, Train_accy 76.67, Test_accy 77.45
2024-08-07 13:06:53,133 [foster.py] => Task 1, Epoch 106/170 => Loss 2.839, Loss_clf 0.762, Loss_fe 0.779, Loss_kd 0.648, Train_accy 77.94
2024-08-07 13:07:01,907 [foster.py] => Task 1, Epoch 107/170 => Loss 2.847, Loss_clf 0.772, Loss_fe 0.787, Loss_kd 0.643, Train_accy 77.47, Test_accy 80.95
2024-08-07 13:07:10,790 [foster.py] => Task 1, Epoch 108/170 => Loss 2.857, Loss_clf 0.780, Loss_fe 0.786, Loss_kd 0.645, Train_accy 77.34, Test_accy 80.50
2024-08-07 13:07:19,555 [foster.py] => Task 1, Epoch 109/170 => Loss 2.872, Loss_clf 0.784, Loss_fe 0.796, Loss_kd 0.645, Train_accy 77.80, Test_accy 79.25
2024-08-07 13:07:28,447 [foster.py] => Task 1, Epoch 110/170 => Loss 2.869, Loss_clf 0.781, Loss_fe 0.788, Loss_kd 0.649, Train_accy 77.23, Test_accy 79.65
2024-08-07 13:07:35,926 [foster.py] => Task 1, Epoch 111/170 => Loss 2.808, Loss_clf 0.756, Loss_fe 0.763, Loss_kd 0.644, Train_accy 77.94
2024-08-07 13:07:44,659 [foster.py] => Task 1, Epoch 112/170 => Loss 2.851, Loss_clf 0.768, Loss_fe 0.780, Loss_kd 0.651, Train_accy 78.10, Test_accy 80.60
2024-08-07 13:07:53,496 [foster.py] => Task 1, Epoch 113/170 => Loss 2.781, Loss_clf 0.741, Loss_fe 0.745, Loss_kd 0.646, Train_accy 78.56, Test_accy 81.75
2024-08-07 13:08:02,270 [foster.py] => Task 1, Epoch 114/170 => Loss 2.743, Loss_clf 0.719, Loss_fe 0.729, Loss_kd 0.646, Train_accy 79.36, Test_accy 80.25
2024-08-07 13:08:11,046 [foster.py] => Task 1, Epoch 115/170 => Loss 2.752, Loss_clf 0.723, Loss_fe 0.729, Loss_kd 0.649, Train_accy 79.14, Test_accy 82.70
2024-08-07 13:08:18,639 [foster.py] => Task 1, Epoch 116/170 => Loss 2.751, Loss_clf 0.730, Loss_fe 0.727, Loss_kd 0.646, Train_accy 78.81
2024-08-07 13:08:27,432 [foster.py] => Task 1, Epoch 117/170 => Loss 2.768, Loss_clf 0.743, Loss_fe 0.734, Loss_kd 0.645, Train_accy 79.11, Test_accy 81.20
2024-08-07 13:08:36,307 [foster.py] => Task 1, Epoch 118/170 => Loss 2.721, Loss_clf 0.716, Loss_fe 0.706, Loss_kd 0.649, Train_accy 78.94, Test_accy 81.80
2024-08-07 13:08:45,052 [foster.py] => Task 1, Epoch 119/170 => Loss 2.732, Loss_clf 0.720, Loss_fe 0.719, Loss_kd 0.646, Train_accy 79.03, Test_accy 81.80
2024-08-07 13:08:53,882 [foster.py] => Task 1, Epoch 120/170 => Loss 2.661, Loss_clf 0.690, Loss_fe 0.683, Loss_kd 0.643, Train_accy 80.13, Test_accy 78.70
2024-08-07 13:09:01,469 [foster.py] => Task 1, Epoch 121/170 => Loss 2.714, Loss_clf 0.715, Loss_fe 0.709, Loss_kd 0.644, Train_accy 78.91
2024-08-07 13:09:10,274 [foster.py] => Task 1, Epoch 122/170 => Loss 2.676, Loss_clf 0.696, Loss_fe 0.685, Loss_kd 0.647, Train_accy 80.06, Test_accy 82.60
2024-08-07 13:09:18,991 [foster.py] => Task 1, Epoch 123/170 => Loss 2.640, Loss_clf 0.676, Loss_fe 0.669, Loss_kd 0.646, Train_accy 80.14, Test_accy 80.40
2024-08-07 13:09:27,886 [foster.py] => Task 1, Epoch 124/170 => Loss 2.620, Loss_clf 0.665, Loss_fe 0.662, Loss_kd 0.646, Train_accy 80.86, Test_accy 83.05
2024-08-07 13:09:36,780 [foster.py] => Task 1, Epoch 125/170 => Loss 2.562, Loss_clf 0.646, Loss_fe 0.631, Loss_kd 0.642, Train_accy 81.43, Test_accy 82.35
2024-08-07 13:09:44,238 [foster.py] => Task 1, Epoch 126/170 => Loss 2.537, Loss_clf 0.630, Loss_fe 0.619, Loss_kd 0.643, Train_accy 81.73
2024-08-07 13:09:52,977 [foster.py] => Task 1, Epoch 127/170 => Loss 2.583, Loss_clf 0.649, Loss_fe 0.640, Loss_kd 0.646, Train_accy 81.64, Test_accy 81.20
2024-08-07 13:10:01,819 [foster.py] => Task 1, Epoch 128/170 => Loss 2.566, Loss_clf 0.645, Loss_fe 0.635, Loss_kd 0.642, Train_accy 81.66, Test_accy 82.55
2024-08-07 13:10:10,673 [foster.py] => Task 1, Epoch 129/170 => Loss 2.520, Loss_clf 0.621, Loss_fe 0.606, Loss_kd 0.646, Train_accy 81.94, Test_accy 83.80
2024-08-07 13:10:19,608 [foster.py] => Task 1, Epoch 130/170 => Loss 2.540, Loss_clf 0.630, Loss_fe 0.614, Loss_kd 0.647, Train_accy 82.03, Test_accy 83.40
2024-08-07 13:10:27,395 [foster.py] => Task 1, Epoch 131/170 => Loss 2.532, Loss_clf 0.627, Loss_fe 0.601, Loss_kd 0.651, Train_accy 81.69
2024-08-07 13:10:36,383 [foster.py] => Task 1, Epoch 132/170 => Loss 2.512, Loss_clf 0.616, Loss_fe 0.600, Loss_kd 0.647, Train_accy 82.61, Test_accy 83.10
2024-08-07 13:10:45,388 [foster.py] => Task 1, Epoch 133/170 => Loss 2.470, Loss_clf 0.596, Loss_fe 0.586, Loss_kd 0.643, Train_accy 82.76, Test_accy 83.20
2024-08-07 13:10:54,566 [foster.py] => Task 1, Epoch 134/170 => Loss 2.484, Loss_clf 0.606, Loss_fe 0.582, Loss_kd 0.647, Train_accy 82.67, Test_accy 83.10
2024-08-07 13:11:03,356 [foster.py] => Task 1, Epoch 135/170 => Loss 2.473, Loss_clf 0.598, Loss_fe 0.581, Loss_kd 0.646, Train_accy 82.80, Test_accy 83.25
2024-08-07 13:11:10,909 [foster.py] => Task 1, Epoch 136/170 => Loss 2.467, Loss_clf 0.599, Loss_fe 0.575, Loss_kd 0.646, Train_accy 82.96
2024-08-07 13:11:19,720 [foster.py] => Task 1, Epoch 137/170 => Loss 2.417, Loss_clf 0.570, Loss_fe 0.551, Loss_kd 0.647, Train_accy 83.46, Test_accy 84.20
2024-08-07 13:11:28,551 [foster.py] => Task 1, Epoch 138/170 => Loss 2.435, Loss_clf 0.586, Loss_fe 0.557, Loss_kd 0.646, Train_accy 83.34, Test_accy 84.20
2024-08-07 13:11:37,416 [foster.py] => Task 1, Epoch 139/170 => Loss 2.421, Loss_clf 0.576, Loss_fe 0.545, Loss_kd 0.649, Train_accy 83.53, Test_accy 85.10
2024-08-07 13:11:46,247 [foster.py] => Task 1, Epoch 140/170 => Loss 2.348, Loss_clf 0.539, Loss_fe 0.514, Loss_kd 0.647, Train_accy 84.77, Test_accy 84.40
2024-08-07 13:11:53,732 [foster.py] => Task 1, Epoch 141/170 => Loss 2.346, Loss_clf 0.545, Loss_fe 0.513, Loss_kd 0.644, Train_accy 84.70
2024-08-07 13:12:02,472 [foster.py] => Task 1, Epoch 142/170 => Loss 2.348, Loss_clf 0.543, Loss_fe 0.509, Loss_kd 0.647, Train_accy 84.19, Test_accy 84.00
2024-08-07 13:12:11,313 [foster.py] => Task 1, Epoch 143/170 => Loss 2.324, Loss_clf 0.530, Loss_fe 0.501, Loss_kd 0.646, Train_accy 85.07, Test_accy 84.15
2024-08-07 13:12:19,957 [foster.py] => Task 1, Epoch 144/170 => Loss 2.329, Loss_clf 0.536, Loss_fe 0.498, Loss_kd 0.647, Train_accy 84.54, Test_accy 85.10
2024-08-07 13:12:28,657 [foster.py] => Task 1, Epoch 145/170 => Loss 2.308, Loss_clf 0.520, Loss_fe 0.489, Loss_kd 0.648, Train_accy 85.04, Test_accy 84.25
2024-08-07 13:12:36,075 [foster.py] => Task 1, Epoch 146/170 => Loss 2.311, Loss_clf 0.526, Loss_fe 0.491, Loss_kd 0.646, Train_accy 85.29
2024-08-07 13:12:44,974 [foster.py] => Task 1, Epoch 147/170 => Loss 2.262, Loss_clf 0.505, Loss_fe 0.469, Loss_kd 0.643, Train_accy 85.60, Test_accy 85.45
2024-08-07 13:12:53,723 [foster.py] => Task 1, Epoch 148/170 => Loss 2.275, Loss_clf 0.512, Loss_fe 0.474, Loss_kd 0.644, Train_accy 85.36, Test_accy 85.10
2024-08-07 13:13:02,501 [foster.py] => Task 1, Epoch 149/170 => Loss 2.277, Loss_clf 0.508, Loss_fe 0.471, Loss_kd 0.648, Train_accy 85.39, Test_accy 84.95
2024-08-07 13:13:11,273 [foster.py] => Task 1, Epoch 150/170 => Loss 2.242, Loss_clf 0.494, Loss_fe 0.452, Loss_kd 0.647, Train_accy 86.26, Test_accy 85.00
2024-08-07 13:13:18,761 [foster.py] => Task 1, Epoch 151/170 => Loss 2.209, Loss_clf 0.475, Loss_fe 0.441, Loss_kd 0.646, Train_accy 86.60
2024-08-07 13:13:27,495 [foster.py] => Task 1, Epoch 152/170 => Loss 2.243, Loss_clf 0.494, Loss_fe 0.450, Loss_kd 0.648, Train_accy 86.19, Test_accy 85.35
2024-08-07 13:13:36,286 [foster.py] => Task 1, Epoch 153/170 => Loss 2.243, Loss_clf 0.496, Loss_fe 0.452, Loss_kd 0.647, Train_accy 86.01, Test_accy 84.75
2024-08-07 13:13:45,074 [foster.py] => Task 1, Epoch 154/170 => Loss 2.223, Loss_clf 0.483, Loss_fe 0.444, Loss_kd 0.647, Train_accy 86.37, Test_accy 85.40
2024-08-07 13:13:53,822 [foster.py] => Task 1, Epoch 155/170 => Loss 2.172, Loss_clf 0.457, Loss_fe 0.422, Loss_kd 0.645, Train_accy 87.53, Test_accy 85.50
2024-08-07 13:14:01,422 [foster.py] => Task 1, Epoch 156/170 => Loss 2.167, Loss_clf 0.458, Loss_fe 0.422, Loss_kd 0.642, Train_accy 87.06
2024-08-07 13:14:10,298 [foster.py] => Task 1, Epoch 157/170 => Loss 2.195, Loss_clf 0.470, Loss_fe 0.427, Loss_kd 0.648, Train_accy 86.66, Test_accy 85.25
2024-08-07 13:14:19,138 [foster.py] => Task 1, Epoch 158/170 => Loss 2.180, Loss_clf 0.462, Loss_fe 0.423, Loss_kd 0.647, Train_accy 87.39, Test_accy 85.10
2024-08-07 13:14:27,970 [foster.py] => Task 1, Epoch 159/170 => Loss 2.147, Loss_clf 0.445, Loss_fe 0.408, Loss_kd 0.646, Train_accy 87.63, Test_accy 85.35
2024-08-07 13:14:36,735 [foster.py] => Task 1, Epoch 160/170 => Loss 2.199, Loss_clf 0.468, Loss_fe 0.430, Loss_kd 0.650, Train_accy 86.40, Test_accy 85.65
2024-08-07 13:14:44,205 [foster.py] => Task 1, Epoch 161/170 => Loss 2.145, Loss_clf 0.447, Loss_fe 0.405, Loss_kd 0.646, Train_accy 87.53
2024-08-07 13:14:53,035 [foster.py] => Task 1, Epoch 162/170 => Loss 2.148, Loss_clf 0.447, Loss_fe 0.410, Loss_kd 0.644, Train_accy 87.67, Test_accy 85.20
2024-08-07 13:15:01,828 [foster.py] => Task 1, Epoch 163/170 => Loss 2.178, Loss_clf 0.459, Loss_fe 0.419, Loss_kd 0.649, Train_accy 87.24, Test_accy 85.30
2024-08-07 13:15:10,570 [foster.py] => Task 1, Epoch 164/170 => Loss 2.149, Loss_clf 0.450, Loss_fe 0.402, Loss_kd 0.648, Train_accy 87.10, Test_accy 85.30
2024-08-07 13:15:19,350 [foster.py] => Task 1, Epoch 165/170 => Loss 2.146, Loss_clf 0.453, Loss_fe 0.405, Loss_kd 0.643, Train_accy 87.23, Test_accy 85.40
2024-08-07 13:15:26,860 [foster.py] => Task 1, Epoch 166/170 => Loss 2.174, Loss_clf 0.461, Loss_fe 0.424, Loss_kd 0.644, Train_accy 87.19
2024-08-07 13:15:35,614 [foster.py] => Task 1, Epoch 167/170 => Loss 2.130, Loss_clf 0.439, Loss_fe 0.407, Loss_kd 0.641, Train_accy 87.84, Test_accy 85.80
2024-08-07 13:15:44,412 [foster.py] => Task 1, Epoch 168/170 => Loss 2.156, Loss_clf 0.450, Loss_fe 0.408, Loss_kd 0.648, Train_accy 87.56, Test_accy 85.45
2024-08-07 13:15:53,168 [foster.py] => Task 1, Epoch 169/170 => Loss 2.133, Loss_clf 0.444, Loss_fe 0.400, Loss_kd 0.643, Train_accy 87.81, Test_accy 85.45
2024-08-07 13:16:02,079 [foster.py] => Task 1, Epoch 170/170 => Loss 2.147, Loss_clf 0.447, Loss_fe 0.405, Loss_kd 0.647, Train_accy 87.31, Test_accy 85.35
2024-08-07 13:16:02,082 [foster.py] => do not weight align teacher!
2024-08-07 13:16:02,084 [foster.py] => per cls weights : [1.04802047 1.04802047 1.04802047 1.04802047 1.04802047 1.04802047
 1.04802047 1.04802047 1.04802047 1.04802047 0.95197953 0.95197953
 0.95197953 0.95197953 0.95197953 0.95197953 0.95197953 0.95197953
 0.95197953 0.95197953]
2024-08-07 13:16:14,747 [foster.py] => SNet: Task 1, Epoch 1/130 => Loss 20.480,  Loss1 0.513, Train_accy 33.54, Test_accy 55.75
2024-08-07 13:16:25,098 [foster.py] => SNet: Task 1, Epoch 2/130 => Loss 20.301,  Loss1 0.512, Train_accy 46.97
2024-08-07 13:16:35,789 [foster.py] => SNet: Task 1, Epoch 3/130 => Loss 20.268,  Loss1 0.512, Train_accy 50.99
2024-08-07 13:16:46,401 [foster.py] => SNet: Task 1, Epoch 4/130 => Loss 20.237,  Loss1 0.511, Train_accy 54.14
2024-08-07 13:16:56,757 [foster.py] => SNet: Task 1, Epoch 5/130 => Loss 20.193,  Loss1 0.511, Train_accy 56.87
2024-08-07 13:17:08,833 [foster.py] => SNet: Task 1, Epoch 6/130 => Loss 20.163,  Loss1 0.511, Train_accy 58.70, Test_accy 67.70
2024-08-07 13:17:19,421 [foster.py] => SNet: Task 1, Epoch 7/130 => Loss 20.154,  Loss1 0.511, Train_accy 60.73
2024-08-07 13:17:30,297 [foster.py] => SNet: Task 1, Epoch 8/130 => Loss 20.134,  Loss1 0.511, Train_accy 61.37
2024-08-07 13:17:40,728 [foster.py] => SNet: Task 1, Epoch 9/130 => Loss 20.124,  Loss1 0.511, Train_accy 62.36
2024-08-07 13:17:51,075 [foster.py] => SNet: Task 1, Epoch 10/130 => Loss 20.120,  Loss1 0.511, Train_accy 63.19
2024-08-07 13:18:02,868 [foster.py] => SNet: Task 1, Epoch 11/130 => Loss 20.114,  Loss1 0.511, Train_accy 64.53, Test_accy 73.40
2024-08-07 13:18:13,295 [foster.py] => SNet: Task 1, Epoch 12/130 => Loss 20.085,  Loss1 0.511, Train_accy 64.74
2024-08-07 13:18:23,610 [foster.py] => SNet: Task 1, Epoch 13/130 => Loss 20.088,  Loss1 0.511, Train_accy 65.29
2024-08-07 13:18:34,172 [foster.py] => SNet: Task 1, Epoch 14/130 => Loss 20.091,  Loss1 0.511, Train_accy 65.96
2024-08-07 13:18:44,492 [foster.py] => SNet: Task 1, Epoch 15/130 => Loss 20.066,  Loss1 0.511, Train_accy 67.37
2024-08-07 13:18:56,079 [foster.py] => SNet: Task 1, Epoch 16/130 => Loss 20.068,  Loss1 0.511, Train_accy 67.56, Test_accy 75.10
2024-08-07 13:19:06,405 [foster.py] => SNet: Task 1, Epoch 17/130 => Loss 20.073,  Loss1 0.511, Train_accy 67.86
2024-08-07 13:19:17,071 [foster.py] => SNet: Task 1, Epoch 18/130 => Loss 20.038,  Loss1 0.511, Train_accy 68.44
2024-08-07 13:19:27,596 [foster.py] => SNet: Task 1, Epoch 19/130 => Loss 20.045,  Loss1 0.511, Train_accy 69.43
2024-08-07 13:19:37,940 [foster.py] => SNet: Task 1, Epoch 20/130 => Loss 20.038,  Loss1 0.511, Train_accy 69.87
2024-08-07 13:19:49,596 [foster.py] => SNet: Task 1, Epoch 21/130 => Loss 20.027,  Loss1 0.511, Train_accy 69.61, Test_accy 76.75
2024-08-07 13:20:00,044 [foster.py] => SNet: Task 1, Epoch 22/130 => Loss 20.029,  Loss1 0.511, Train_accy 69.76
2024-08-07 13:20:10,484 [foster.py] => SNet: Task 1, Epoch 23/130 => Loss 20.019,  Loss1 0.511, Train_accy 70.86
2024-08-07 13:20:20,893 [foster.py] => SNet: Task 1, Epoch 24/130 => Loss 20.020,  Loss1 0.511, Train_accy 71.80
2024-08-07 13:20:31,276 [foster.py] => SNet: Task 1, Epoch 25/130 => Loss 20.026,  Loss1 0.511, Train_accy 70.94
2024-08-07 13:20:42,684 [foster.py] => SNet: Task 1, Epoch 26/130 => Loss 20.008,  Loss1 0.511, Train_accy 71.84, Test_accy 78.15
2024-08-07 13:20:53,254 [foster.py] => SNet: Task 1, Epoch 27/130 => Loss 20.012,  Loss1 0.511, Train_accy 71.80
2024-08-07 13:21:04,020 [foster.py] => SNet: Task 1, Epoch 28/130 => Loss 19.976,  Loss1 0.511, Train_accy 72.96
2024-08-07 13:21:14,394 [foster.py] => SNet: Task 1, Epoch 29/130 => Loss 19.988,  Loss1 0.511, Train_accy 72.99
2024-08-07 13:21:24,705 [foster.py] => SNet: Task 1, Epoch 30/130 => Loss 20.004,  Loss1 0.511, Train_accy 72.53
2024-08-07 13:21:36,245 [foster.py] => SNet: Task 1, Epoch 31/130 => Loss 19.990,  Loss1 0.511, Train_accy 73.43, Test_accy 78.25
2024-08-07 13:21:47,001 [foster.py] => SNet: Task 1, Epoch 32/130 => Loss 19.996,  Loss1 0.511, Train_accy 74.26
2024-08-07 13:21:57,299 [foster.py] => SNet: Task 1, Epoch 33/130 => Loss 19.966,  Loss1 0.511, Train_accy 74.13
2024-08-07 13:22:07,666 [foster.py] => SNet: Task 1, Epoch 34/130 => Loss 19.977,  Loss1 0.511, Train_accy 74.43
2024-08-07 13:22:18,032 [foster.py] => SNet: Task 1, Epoch 35/130 => Loss 19.988,  Loss1 0.511, Train_accy 74.23
2024-08-07 13:22:29,408 [foster.py] => SNet: Task 1, Epoch 36/130 => Loss 19.988,  Loss1 0.511, Train_accy 75.40, Test_accy 80.40
2024-08-07 13:22:39,762 [foster.py] => SNet: Task 1, Epoch 37/130 => Loss 19.971,  Loss1 0.511, Train_accy 75.49
2024-08-07 13:22:50,402 [foster.py] => SNet: Task 1, Epoch 38/130 => Loss 19.965,  Loss1 0.511, Train_accy 75.79
2024-08-07 13:23:00,897 [foster.py] => SNet: Task 1, Epoch 39/130 => Loss 19.959,  Loss1 0.511, Train_accy 75.79
2024-08-07 13:23:11,195 [foster.py] => SNet: Task 1, Epoch 40/130 => Loss 19.967,  Loss1 0.511, Train_accy 76.01
2024-08-07 13:23:22,573 [foster.py] => SNet: Task 1, Epoch 41/130 => Loss 19.970,  Loss1 0.511, Train_accy 75.67, Test_accy 82.25
2024-08-07 13:23:32,944 [foster.py] => SNet: Task 1, Epoch 42/130 => Loss 19.959,  Loss1 0.511, Train_accy 75.40
2024-08-07 13:23:43,250 [foster.py] => SNet: Task 1, Epoch 43/130 => Loss 19.971,  Loss1 0.511, Train_accy 75.99
2024-08-07 13:23:53,712 [foster.py] => SNet: Task 1, Epoch 44/130 => Loss 19.969,  Loss1 0.511, Train_accy 76.90
2024-08-07 13:24:04,243 [foster.py] => SNet: Task 1, Epoch 45/130 => Loss 19.967,  Loss1 0.511, Train_accy 76.20
2024-08-07 13:24:15,752 [foster.py] => SNet: Task 1, Epoch 46/130 => Loss 19.948,  Loss1 0.511, Train_accy 76.77, Test_accy 82.20
2024-08-07 13:24:26,391 [foster.py] => SNet: Task 1, Epoch 47/130 => Loss 19.956,  Loss1 0.511, Train_accy 77.67
2024-08-07 13:24:36,752 [foster.py] => SNet: Task 1, Epoch 48/130 => Loss 19.957,  Loss1 0.511, Train_accy 77.31
2024-08-07 13:24:47,512 [foster.py] => SNet: Task 1, Epoch 49/130 => Loss 19.960,  Loss1 0.511, Train_accy 76.64
2024-08-07 13:24:58,093 [foster.py] => SNet: Task 1, Epoch 50/130 => Loss 19.943,  Loss1 0.511, Train_accy 77.29
2024-08-07 13:25:09,645 [foster.py] => SNet: Task 1, Epoch 51/130 => Loss 19.949,  Loss1 0.511, Train_accy 78.71, Test_accy 82.75
2024-08-07 13:25:20,235 [foster.py] => SNet: Task 1, Epoch 52/130 => Loss 19.951,  Loss1 0.511, Train_accy 77.57
2024-08-07 13:25:31,017 [foster.py] => SNet: Task 1, Epoch 53/130 => Loss 19.950,  Loss1 0.511, Train_accy 78.29
2024-08-07 13:25:41,382 [foster.py] => SNet: Task 1, Epoch 54/130 => Loss 19.956,  Loss1 0.511, Train_accy 77.87
2024-08-07 13:25:51,764 [foster.py] => SNet: Task 1, Epoch 55/130 => Loss 19.947,  Loss1 0.511, Train_accy 77.56
2024-08-07 13:26:03,177 [foster.py] => SNet: Task 1, Epoch 56/130 => Loss 19.952,  Loss1 0.511, Train_accy 78.83, Test_accy 83.55
2024-08-07 13:26:13,602 [foster.py] => SNet: Task 1, Epoch 57/130 => Loss 19.952,  Loss1 0.511, Train_accy 79.09
2024-08-07 13:26:24,108 [foster.py] => SNet: Task 1, Epoch 58/130 => Loss 19.943,  Loss1 0.511, Train_accy 79.23
2024-08-07 13:26:34,583 [foster.py] => SNet: Task 1, Epoch 59/130 => Loss 19.941,  Loss1 0.511, Train_accy 77.86
2024-08-07 13:26:44,900 [foster.py] => SNet: Task 1, Epoch 60/130 => Loss 19.947,  Loss1 0.511, Train_accy 78.41
2024-08-07 13:26:56,501 [foster.py] => SNet: Task 1, Epoch 61/130 => Loss 19.927,  Loss1 0.511, Train_accy 79.49, Test_accy 82.30
2024-08-07 13:27:06,925 [foster.py] => SNet: Task 1, Epoch 62/130 => Loss 19.921,  Loss1 0.511, Train_accy 80.36
2024-08-07 13:27:17,574 [foster.py] => SNet: Task 1, Epoch 63/130 => Loss 19.928,  Loss1 0.511, Train_accy 80.00
2024-08-07 13:27:28,235 [foster.py] => SNet: Task 1, Epoch 64/130 => Loss 19.926,  Loss1 0.511, Train_accy 79.97
2024-08-07 13:27:38,530 [foster.py] => SNet: Task 1, Epoch 65/130 => Loss 19.924,  Loss1 0.511, Train_accy 79.99
2024-08-07 13:27:50,235 [foster.py] => SNet: Task 1, Epoch 66/130 => Loss 19.929,  Loss1 0.511, Train_accy 79.86, Test_accy 83.20
2024-08-07 13:28:00,610 [foster.py] => SNet: Task 1, Epoch 67/130 => Loss 19.940,  Loss1 0.511, Train_accy 80.07
2024-08-07 13:28:11,085 [foster.py] => SNet: Task 1, Epoch 68/130 => Loss 19.914,  Loss1 0.511, Train_accy 80.70
2024-08-07 13:28:21,692 [foster.py] => SNet: Task 1, Epoch 69/130 => Loss 19.927,  Loss1 0.511, Train_accy 79.77
2024-08-07 13:28:32,213 [foster.py] => SNet: Task 1, Epoch 70/130 => Loss 19.915,  Loss1 0.511, Train_accy 80.27
2024-08-07 13:28:43,997 [foster.py] => SNet: Task 1, Epoch 71/130 => Loss 19.917,  Loss1 0.511, Train_accy 80.66, Test_accy 83.65
2024-08-07 13:28:54,678 [foster.py] => SNet: Task 1, Epoch 72/130 => Loss 19.925,  Loss1 0.511, Train_accy 80.39
2024-08-07 13:29:05,124 [foster.py] => SNet: Task 1, Epoch 73/130 => Loss 19.923,  Loss1 0.511, Train_accy 80.77
2024-08-07 13:29:15,414 [foster.py] => SNet: Task 1, Epoch 74/130 => Loss 19.917,  Loss1 0.511, Train_accy 80.97
2024-08-07 13:29:26,633 [foster.py] => SNet: Task 1, Epoch 75/130 => Loss 19.932,  Loss1 0.511, Train_accy 80.90
2024-08-07 13:29:38,498 [foster.py] => SNet: Task 1, Epoch 76/130 => Loss 19.925,  Loss1 0.511, Train_accy 80.81, Test_accy 83.30
2024-08-07 13:29:48,823 [foster.py] => SNet: Task 1, Epoch 77/130 => Loss 19.936,  Loss1 0.511, Train_accy 80.19
2024-08-07 13:29:59,169 [foster.py] => SNet: Task 1, Epoch 78/130 => Loss 19.918,  Loss1 0.511, Train_accy 81.40
2024-08-07 13:30:09,796 [foster.py] => SNet: Task 1, Epoch 79/130 => Loss 19.916,  Loss1 0.511, Train_accy 81.34
2024-08-07 13:30:20,198 [foster.py] => SNet: Task 1, Epoch 80/130 => Loss 19.928,  Loss1 0.511, Train_accy 81.26
2024-08-07 13:30:31,866 [foster.py] => SNet: Task 1, Epoch 81/130 => Loss 19.917,  Loss1 0.511, Train_accy 81.11, Test_accy 84.05
2024-08-07 13:30:42,442 [foster.py] => SNet: Task 1, Epoch 82/130 => Loss 19.934,  Loss1 0.511, Train_accy 81.47
2024-08-07 13:30:52,726 [foster.py] => SNet: Task 1, Epoch 83/130 => Loss 19.912,  Loss1 0.511, Train_accy 81.76
2024-08-07 13:31:03,672 [foster.py] => SNet: Task 1, Epoch 84/130 => Loss 19.906,  Loss1 0.511, Train_accy 82.40
2024-08-07 13:31:14,292 [foster.py] => SNet: Task 1, Epoch 85/130 => Loss 19.914,  Loss1 0.511, Train_accy 82.03
2024-08-07 13:31:25,792 [foster.py] => SNet: Task 1, Epoch 86/130 => Loss 19.912,  Loss1 0.511, Train_accy 82.13, Test_accy 84.35
2024-08-07 13:31:36,374 [foster.py] => SNet: Task 1, Epoch 87/130 => Loss 19.916,  Loss1 0.511, Train_accy 81.73
2024-08-07 13:31:46,783 [foster.py] => SNet: Task 1, Epoch 88/130 => Loss 19.895,  Loss1 0.511, Train_accy 81.84
2024-08-07 13:31:57,603 [foster.py] => SNet: Task 1, Epoch 89/130 => Loss 19.913,  Loss1 0.511, Train_accy 81.66
2024-08-07 13:32:08,655 [foster.py] => SNet: Task 1, Epoch 90/130 => Loss 19.908,  Loss1 0.511, Train_accy 82.14
2024-08-07 13:32:20,146 [foster.py] => SNet: Task 1, Epoch 91/130 => Loss 19.924,  Loss1 0.511, Train_accy 81.66, Test_accy 84.15
2024-08-07 13:32:30,399 [foster.py] => SNet: Task 1, Epoch 92/130 => Loss 19.914,  Loss1 0.511, Train_accy 82.00
2024-08-07 13:32:40,903 [foster.py] => SNet: Task 1, Epoch 93/130 => Loss 19.910,  Loss1 0.511, Train_accy 82.33
2024-08-07 13:32:51,725 [foster.py] => SNet: Task 1, Epoch 94/130 => Loss 19.899,  Loss1 0.511, Train_accy 82.11
2024-08-07 13:33:01,989 [foster.py] => SNet: Task 1, Epoch 95/130 => Loss 19.910,  Loss1 0.511, Train_accy 81.73
2024-08-07 13:33:13,515 [foster.py] => SNet: Task 1, Epoch 96/130 => Loss 19.888,  Loss1 0.511, Train_accy 81.97, Test_accy 84.20
2024-08-07 13:33:23,898 [foster.py] => SNet: Task 1, Epoch 97/130 => Loss 19.908,  Loss1 0.511, Train_accy 82.87
2024-08-07 13:33:34,467 [foster.py] => SNet: Task 1, Epoch 98/130 => Loss 19.912,  Loss1 0.511, Train_accy 82.51
2024-08-07 13:33:44,822 [foster.py] => SNet: Task 1, Epoch 99/130 => Loss 19.890,  Loss1 0.511, Train_accy 83.24
2024-08-07 13:33:55,161 [foster.py] => SNet: Task 1, Epoch 100/130 => Loss 19.923,  Loss1 0.511, Train_accy 82.87
2024-08-07 13:34:06,690 [foster.py] => SNet: Task 1, Epoch 101/130 => Loss 19.892,  Loss1 0.511, Train_accy 83.21, Test_accy 84.20
2024-08-07 13:34:17,444 [foster.py] => SNet: Task 1, Epoch 102/130 => Loss 19.922,  Loss1 0.511, Train_accy 82.36
2024-08-07 13:34:27,743 [foster.py] => SNet: Task 1, Epoch 103/130 => Loss 19.897,  Loss1 0.511, Train_accy 82.46
2024-08-07 13:34:38,087 [foster.py] => SNet: Task 1, Epoch 104/130 => Loss 19.903,  Loss1 0.511, Train_accy 82.90
2024-08-07 13:34:48,593 [foster.py] => SNet: Task 1, Epoch 105/130 => Loss 19.905,  Loss1 0.511, Train_accy 82.61
2024-08-07 13:35:00,099 [foster.py] => SNet: Task 1, Epoch 106/130 => Loss 19.893,  Loss1 0.511, Train_accy 82.97, Test_accy 84.35
2024-08-07 13:35:10,482 [foster.py] => SNet: Task 1, Epoch 107/130 => Loss 19.904,  Loss1 0.511, Train_accy 83.09
2024-08-07 13:35:21,159 [foster.py] => SNet: Task 1, Epoch 108/130 => Loss 19.896,  Loss1 0.511, Train_accy 83.27
2024-08-07 13:35:31,474 [foster.py] => SNet: Task 1, Epoch 109/130 => Loss 19.893,  Loss1 0.511, Train_accy 83.91
2024-08-07 13:35:41,929 [foster.py] => SNet: Task 1, Epoch 110/130 => Loss 19.895,  Loss1 0.511, Train_accy 82.76
2024-08-07 13:35:53,979 [foster.py] => SNet: Task 1, Epoch 111/130 => Loss 19.902,  Loss1 0.511, Train_accy 82.86, Test_accy 84.70
2024-08-07 13:36:04,604 [foster.py] => SNet: Task 1, Epoch 112/130 => Loss 19.899,  Loss1 0.511, Train_accy 82.94
2024-08-07 13:36:15,093 [foster.py] => SNet: Task 1, Epoch 113/130 => Loss 19.905,  Loss1 0.511, Train_accy 83.57
2024-08-07 13:36:25,684 [foster.py] => SNet: Task 1, Epoch 114/130 => Loss 19.914,  Loss1 0.511, Train_accy 82.24
2024-08-07 13:36:36,049 [foster.py] => SNet: Task 1, Epoch 115/130 => Loss 19.910,  Loss1 0.511, Train_accy 82.90
2024-08-07 13:36:47,503 [foster.py] => SNet: Task 1, Epoch 116/130 => Loss 19.894,  Loss1 0.511, Train_accy 83.09, Test_accy 84.55
2024-08-07 13:36:57,813 [foster.py] => SNet: Task 1, Epoch 117/130 => Loss 19.920,  Loss1 0.511, Train_accy 83.06
2024-08-07 13:37:08,655 [foster.py] => SNet: Task 1, Epoch 118/130 => Loss 19.902,  Loss1 0.511, Train_accy 82.69
2024-08-07 13:37:19,274 [foster.py] => SNet: Task 1, Epoch 119/130 => Loss 19.898,  Loss1 0.511, Train_accy 83.36
2024-08-07 13:37:29,889 [foster.py] => SNet: Task 1, Epoch 120/130 => Loss 19.907,  Loss1 0.511, Train_accy 82.87
2024-08-07 13:37:41,402 [foster.py] => SNet: Task 1, Epoch 121/130 => Loss 19.901,  Loss1 0.511, Train_accy 83.74, Test_accy 84.70
2024-08-07 13:37:52,000 [foster.py] => SNet: Task 1, Epoch 122/130 => Loss 19.889,  Loss1 0.511, Train_accy 83.14
2024-08-07 13:38:02,638 [foster.py] => SNet: Task 1, Epoch 123/130 => Loss 19.906,  Loss1 0.511, Train_accy 82.74
2024-08-07 13:38:12,867 [foster.py] => SNet: Task 1, Epoch 124/130 => Loss 19.915,  Loss1 0.511, Train_accy 83.17
2024-08-07 13:38:23,178 [foster.py] => SNet: Task 1, Epoch 125/130 => Loss 19.912,  Loss1 0.511, Train_accy 82.49
2024-08-07 13:38:34,716 [foster.py] => SNet: Task 1, Epoch 126/130 => Loss 19.884,  Loss1 0.511, Train_accy 83.74, Test_accy 84.65
2024-08-07 13:38:45,080 [foster.py] => SNet: Task 1, Epoch 127/130 => Loss 19.906,  Loss1 0.511, Train_accy 83.37
2024-08-07 13:38:55,654 [foster.py] => SNet: Task 1, Epoch 128/130 => Loss 19.896,  Loss1 0.511, Train_accy 84.13
2024-08-07 13:39:06,058 [foster.py] => SNet: Task 1, Epoch 129/130 => Loss 19.902,  Loss1 0.511, Train_accy 83.39
2024-08-07 13:39:16,418 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 19.896,  Loss1 0.511, Train_accy 83.96
2024-08-07 13:39:16,419 [foster.py] => do not weight align student!
2024-08-07 13:39:17,537 [foster.py] => darknet eval: 
2024-08-07 13:39:17,537 [foster.py] => CNN top1 curve: 84.15
2024-08-07 13:39:17,537 [foster.py] => CNN top5 curve: 98.05
2024-08-07 13:39:17,537 [foster.py] => CNN top1 平均值: 84.15
2024-08-07 13:39:17,542 [foster.py] => timees : 2851.476581811905
2024-08-07 13:39:17,544 [base.py] => Reducing exemplars...(100 per classes)
2024-08-07 13:39:21,375 [base.py] => Constructing exemplars...(100 per classes)
2024-08-07 13:39:34,604 [foster.py] => Exemplar size: 2000
2024-08-07 13:39:34,604 [trainer.py] => CNN: {'total': 85.35, '00-09': 87.9, '10-19': 82.8, 'old': 87.9, 'new': 82.8}
2024-08-07 13:39:34,604 [trainer.py] => NME: {'total': 85.95, '00-09': 88.5, '10-19': 83.4, 'old': 88.5, 'new': 83.4}
2024-08-07 13:39:34,604 [trainer.py] => CNN top1 curve: [94.2, 85.35]
2024-08-07 13:39:34,604 [trainer.py] => CNN top5 curve: [99.7, 98.2]
2024-08-07 13:39:34,604 [trainer.py] => NME top1 curve: [94.2, 85.95]
2024-08-07 13:39:34,604 [trainer.py] => NME top5 curve: [99.6, 97.7]

2024-08-07 13:39:34,605 [trainer.py] => CNN top1 平均值: 89.78
2024-08-07 13:39:34,607 [trainer.py] => All params: 1287078
2024-08-07 13:39:34,609 [trainer.py] => Trainable params: 645154
2024-08-07 13:39:34,672 [foster.py] => Learning on 20-30
2024-08-07 13:39:34,675 [foster.py] => All params: 1289668
2024-08-07 13:39:34,678 [foster.py] => Trainable params: 647094
2024-08-07 13:39:34,737 [foster.py] => per cls weights : [1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277
 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277
 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 1.0575277 0.8849446
 0.8849446 0.8849446 0.8849446 0.8849446 0.8849446 0.8849446 0.8849446
 0.8849446 0.8849446]
2024-08-07 13:39:42,430 [foster.py] => Task 2, Epoch 1/170 => Loss 5.530, Loss_clf 1.893, Loss_fe 1.893, Loss_kd 1.161, Train_accy 50.19
2024-08-07 13:39:51,503 [foster.py] => Task 2, Epoch 2/170 => Loss 4.567, Loss_clf 1.321, Loss_fe 1.536, Loss_kd 1.138, Train_accy 60.03, Test_accy 70.60
2024-08-07 13:40:00,557 [foster.py] => Task 2, Epoch 3/170 => Loss 4.411, Loss_clf 1.231, Loss_fe 1.477, Loss_kd 1.133, Train_accy 62.77, Test_accy 74.97
2024-08-07 13:40:09,677 [foster.py] => Task 2, Epoch 4/170 => Loss 4.310, Loss_clf 1.199, Loss_fe 1.407, Loss_kd 1.134, Train_accy 62.87, Test_accy 74.27
2024-08-07 13:40:18,708 [foster.py] => Task 2, Epoch 5/170 => Loss 4.277, Loss_clf 1.189, Loss_fe 1.382, Loss_kd 1.136, Train_accy 64.31, Test_accy 71.23
2024-08-07 13:40:26,148 [foster.py] => Task 2, Epoch 6/170 => Loss 4.179, Loss_clf 1.145, Loss_fe 1.329, Loss_kd 1.135, Train_accy 65.47
2024-08-07 13:40:35,165 [foster.py] => Task 2, Epoch 7/170 => Loss 4.143, Loss_clf 1.144, Loss_fe 1.302, Loss_kd 1.129, Train_accy 66.09, Test_accy 74.63
2024-08-07 13:40:44,142 [foster.py] => Task 2, Epoch 8/170 => Loss 4.097, Loss_clf 1.114, Loss_fe 1.279, Loss_kd 1.134, Train_accy 66.23, Test_accy 72.93
2024-08-07 13:40:53,211 [foster.py] => Task 2, Epoch 9/170 => Loss 4.099, Loss_clf 1.125, Loss_fe 1.266, Loss_kd 1.137, Train_accy 66.70, Test_accy 71.83
2024-08-07 13:41:02,257 [foster.py] => Task 2, Epoch 10/170 => Loss 4.006, Loss_clf 1.075, Loss_fe 1.240, Loss_kd 1.125, Train_accy 67.54, Test_accy 72.50
2024-08-07 13:41:09,743 [foster.py] => Task 2, Epoch 11/170 => Loss 4.104, Loss_clf 1.135, Loss_fe 1.266, Loss_kd 1.134, Train_accy 66.40
2024-08-07 13:41:18,912 [foster.py] => Task 2, Epoch 12/170 => Loss 3.952, Loss_clf 1.053, Loss_fe 1.200, Loss_kd 1.131, Train_accy 68.61, Test_accy 75.67
2024-08-07 13:41:28,010 [foster.py] => Task 2, Epoch 13/170 => Loss 3.965, Loss_clf 1.062, Loss_fe 1.196, Loss_kd 1.137, Train_accy 68.87, Test_accy 72.70
2024-08-07 13:41:37,334 [foster.py] => Task 2, Epoch 14/170 => Loss 4.014, Loss_clf 1.073, Loss_fe 1.242, Loss_kd 1.131, Train_accy 67.80, Test_accy 74.90
2024-08-07 13:41:46,851 [foster.py] => Task 2, Epoch 15/170 => Loss 4.003, Loss_clf 1.090, Loss_fe 1.201, Loss_kd 1.139, Train_accy 67.27, Test_accy 76.10
2024-08-07 13:41:54,419 [foster.py] => Task 2, Epoch 16/170 => Loss 3.977, Loss_clf 1.071, Loss_fe 1.197, Loss_kd 1.138, Train_accy 68.89
2024-08-07 13:42:03,445 [foster.py] => Task 2, Epoch 17/170 => Loss 3.968, Loss_clf 1.071, Loss_fe 1.192, Loss_kd 1.135, Train_accy 68.09, Test_accy 75.13
2024-08-07 13:42:12,564 [foster.py] => Task 2, Epoch 18/170 => Loss 3.921, Loss_clf 1.044, Loss_fe 1.165, Loss_kd 1.139, Train_accy 68.40, Test_accy 70.20
2024-08-07 13:42:21,712 [foster.py] => Task 2, Epoch 19/170 => Loss 4.003, Loss_clf 1.101, Loss_fe 1.202, Loss_kd 1.132, Train_accy 67.26, Test_accy 74.57
2024-08-07 13:42:30,719 [foster.py] => Task 2, Epoch 20/170 => Loss 3.932, Loss_clf 1.061, Loss_fe 1.163, Loss_kd 1.137, Train_accy 68.46, Test_accy 71.20
2024-08-07 13:42:38,306 [foster.py] => Task 2, Epoch 21/170 => Loss 3.854, Loss_clf 1.010, Loss_fe 1.143, Loss_kd 1.132, Train_accy 69.89
2024-08-07 13:42:47,321 [foster.py] => Task 2, Epoch 22/170 => Loss 3.884, Loss_clf 1.029, Loss_fe 1.158, Loss_kd 1.130, Train_accy 68.99, Test_accy 74.63
2024-08-07 13:42:56,397 [foster.py] => Task 2, Epoch 23/170 => Loss 3.837, Loss_clf 1.009, Loss_fe 1.130, Loss_kd 1.130, Train_accy 69.70, Test_accy 72.90
2024-08-07 13:43:05,523 [foster.py] => Task 2, Epoch 24/170 => Loss 3.836, Loss_clf 1.016, Loss_fe 1.113, Loss_kd 1.137, Train_accy 70.06, Test_accy 77.07
2024-08-07 13:43:14,503 [foster.py] => Task 2, Epoch 25/170 => Loss 3.810, Loss_clf 0.996, Loss_fe 1.116, Loss_kd 1.130, Train_accy 70.39, Test_accy 75.97
2024-08-07 13:43:22,243 [foster.py] => Task 2, Epoch 26/170 => Loss 3.882, Loss_clf 1.037, Loss_fe 1.130, Loss_kd 1.142, Train_accy 69.10
2024-08-07 13:43:31,575 [foster.py] => Task 2, Epoch 27/170 => Loss 3.871, Loss_clf 1.030, Loss_fe 1.132, Loss_kd 1.138, Train_accy 69.67, Test_accy 74.73
2024-08-07 13:43:40,735 [foster.py] => Task 2, Epoch 28/170 => Loss 3.779, Loss_clf 0.980, Loss_fe 1.100, Loss_kd 1.131, Train_accy 70.20, Test_accy 75.73
2024-08-07 13:43:50,175 [foster.py] => Task 2, Epoch 29/170 => Loss 3.887, Loss_clf 1.054, Loss_fe 1.126, Loss_kd 1.137, Train_accy 69.17, Test_accy 74.37
2024-08-07 13:43:59,228 [foster.py] => Task 2, Epoch 30/170 => Loss 3.830, Loss_clf 1.019, Loss_fe 1.107, Loss_kd 1.134, Train_accy 69.59, Test_accy 76.23
2024-08-07 13:44:06,817 [foster.py] => Task 2, Epoch 31/170 => Loss 3.750, Loss_clf 0.972, Loss_fe 1.089, Loss_kd 1.125, Train_accy 71.14
2024-08-07 13:44:15,874 [foster.py] => Task 2, Epoch 32/170 => Loss 3.785, Loss_clf 0.982, Loss_fe 1.098, Loss_kd 1.135, Train_accy 70.39, Test_accy 76.63
2024-08-07 13:44:24,912 [foster.py] => Task 2, Epoch 33/170 => Loss 3.834, Loss_clf 1.030, Loss_fe 1.111, Loss_kd 1.127, Train_accy 69.10, Test_accy 71.50
2024-08-07 13:44:34,068 [foster.py] => Task 2, Epoch 34/170 => Loss 3.739, Loss_clf 0.977, Loss_fe 1.056, Loss_kd 1.136, Train_accy 70.97, Test_accy 75.40
2024-08-07 13:44:43,052 [foster.py] => Task 2, Epoch 35/170 => Loss 3.731, Loss_clf 0.977, Loss_fe 1.056, Loss_kd 1.131, Train_accy 71.07, Test_accy 72.40
2024-08-07 13:44:50,502 [foster.py] => Task 2, Epoch 36/170 => Loss 3.773, Loss_clf 0.986, Loss_fe 1.078, Loss_kd 1.137, Train_accy 70.23
2024-08-07 13:44:59,456 [foster.py] => Task 2, Epoch 37/170 => Loss 3.741, Loss_clf 0.975, Loss_fe 1.076, Loss_kd 1.125, Train_accy 70.31, Test_accy 75.83
2024-08-07 13:45:08,842 [foster.py] => Task 2, Epoch 38/170 => Loss 3.697, Loss_clf 0.946, Loss_fe 1.045, Loss_kd 1.136, Train_accy 71.43, Test_accy 77.53
2024-08-07 13:45:18,107 [foster.py] => Task 2, Epoch 39/170 => Loss 3.752, Loss_clf 0.980, Loss_fe 1.079, Loss_kd 1.127, Train_accy 70.54, Test_accy 76.77
2024-08-07 13:45:27,425 [foster.py] => Task 2, Epoch 40/170 => Loss 3.698, Loss_clf 0.944, Loss_fe 1.052, Loss_kd 1.133, Train_accy 71.81, Test_accy 76.57
2024-08-07 13:45:35,108 [foster.py] => Task 2, Epoch 41/170 => Loss 3.737, Loss_clf 0.965, Loss_fe 1.065, Loss_kd 1.137, Train_accy 71.43
2024-08-07 13:45:44,163 [foster.py] => Task 2, Epoch 42/170 => Loss 3.644, Loss_clf 0.924, Loss_fe 1.021, Loss_kd 1.131, Train_accy 72.03, Test_accy 78.17
2024-08-07 13:45:53,303 [foster.py] => Task 2, Epoch 43/170 => Loss 3.665, Loss_clf 0.931, Loss_fe 1.032, Loss_kd 1.132, Train_accy 72.71, Test_accy 75.63
2024-08-07 13:46:02,468 [foster.py] => Task 2, Epoch 44/170 => Loss 3.668, Loss_clf 0.934, Loss_fe 1.035, Loss_kd 1.131, Train_accy 72.16, Test_accy 74.33
2024-08-07 13:46:11,493 [foster.py] => Task 2, Epoch 45/170 => Loss 3.681, Loss_clf 0.951, Loss_fe 1.033, Loss_kd 1.129, Train_accy 71.73, Test_accy 76.20
2024-08-07 13:46:19,034 [foster.py] => Task 2, Epoch 46/170 => Loss 3.633, Loss_clf 0.917, Loss_fe 1.022, Loss_kd 1.127, Train_accy 72.50
2024-08-07 13:46:28,198 [foster.py] => Task 2, Epoch 47/170 => Loss 3.723, Loss_clf 0.963, Loss_fe 1.052, Loss_kd 1.137, Train_accy 71.86, Test_accy 75.70
2024-08-07 13:46:37,251 [foster.py] => Task 2, Epoch 48/170 => Loss 3.626, Loss_clf 0.918, Loss_fe 1.011, Loss_kd 1.129, Train_accy 72.89, Test_accy 76.93
2024-08-07 13:46:46,562 [foster.py] => Task 2, Epoch 49/170 => Loss 3.632, Loss_clf 0.936, Loss_fe 0.999, Loss_kd 1.129, Train_accy 72.81, Test_accy 75.50
2024-08-07 13:46:55,825 [foster.py] => Task 2, Epoch 50/170 => Loss 3.615, Loss_clf 0.913, Loss_fe 1.001, Loss_kd 1.132, Train_accy 72.99, Test_accy 74.83
2024-08-07 13:47:03,276 [foster.py] => Task 2, Epoch 51/170 => Loss 3.611, Loss_clf 0.917, Loss_fe 0.993, Loss_kd 1.132, Train_accy 72.37
2024-08-07 13:47:12,351 [foster.py] => Task 2, Epoch 52/170 => Loss 3.655, Loss_clf 0.935, Loss_fe 1.016, Loss_kd 1.134, Train_accy 71.84, Test_accy 77.33
2024-08-07 13:47:21,463 [foster.py] => Task 2, Epoch 53/170 => Loss 3.618, Loss_clf 0.926, Loss_fe 0.986, Loss_kd 1.136, Train_accy 72.94, Test_accy 77.13
2024-08-07 13:47:30,546 [foster.py] => Task 2, Epoch 54/170 => Loss 3.614, Loss_clf 0.923, Loss_fe 0.982, Loss_kd 1.138, Train_accy 72.49, Test_accy 77.10
2024-08-07 13:47:39,566 [foster.py] => Task 2, Epoch 55/170 => Loss 3.602, Loss_clf 0.918, Loss_fe 0.981, Loss_kd 1.134, Train_accy 72.70, Test_accy 75.47
2024-08-07 13:47:47,071 [foster.py] => Task 2, Epoch 56/170 => Loss 3.589, Loss_clf 0.904, Loss_fe 0.986, Loss_kd 1.131, Train_accy 73.96
2024-08-07 13:47:56,093 [foster.py] => Task 2, Epoch 57/170 => Loss 3.593, Loss_clf 0.912, Loss_fe 0.982, Loss_kd 1.131, Train_accy 72.91, Test_accy 76.87
2024-08-07 13:48:05,127 [foster.py] => Task 2, Epoch 58/170 => Loss 3.574, Loss_clf 0.890, Loss_fe 0.977, Loss_kd 1.136, Train_accy 73.79, Test_accy 75.63
2024-08-07 13:48:14,310 [foster.py] => Task 2, Epoch 59/170 => Loss 3.557, Loss_clf 0.890, Loss_fe 0.957, Loss_kd 1.139, Train_accy 73.44, Test_accy 74.63
2024-08-07 13:48:23,391 [foster.py] => Task 2, Epoch 60/170 => Loss 3.576, Loss_clf 0.915, Loss_fe 0.960, Loss_kd 1.132, Train_accy 72.77, Test_accy 76.70
2024-08-07 13:48:30,948 [foster.py] => Task 2, Epoch 61/170 => Loss 3.598, Loss_clf 0.913, Loss_fe 0.983, Loss_kd 1.133, Train_accy 73.04
2024-08-07 13:48:40,258 [foster.py] => Task 2, Epoch 62/170 => Loss 3.509, Loss_clf 0.870, Loss_fe 0.942, Loss_kd 1.130, Train_accy 73.54, Test_accy 75.67
2024-08-07 13:48:49,381 [foster.py] => Task 2, Epoch 63/170 => Loss 3.511, Loss_clf 0.878, Loss_fe 0.935, Loss_kd 1.130, Train_accy 73.89, Test_accy 79.00
2024-08-07 13:48:58,434 [foster.py] => Task 2, Epoch 64/170 => Loss 3.513, Loss_clf 0.878, Loss_fe 0.945, Loss_kd 1.125, Train_accy 74.10, Test_accy 75.10
2024-08-07 13:49:07,555 [foster.py] => Task 2, Epoch 65/170 => Loss 3.493, Loss_clf 0.862, Loss_fe 0.938, Loss_kd 1.127, Train_accy 74.43, Test_accy 75.97
2024-08-07 13:49:15,118 [foster.py] => Task 2, Epoch 66/170 => Loss 3.451, Loss_clf 0.843, Loss_fe 0.919, Loss_kd 1.124, Train_accy 75.30
2024-08-07 13:49:24,107 [foster.py] => Task 2, Epoch 67/170 => Loss 3.513, Loss_clf 0.877, Loss_fe 0.943, Loss_kd 1.127, Train_accy 74.14, Test_accy 75.43
2024-08-07 13:49:33,237 [foster.py] => Task 2, Epoch 68/170 => Loss 3.498, Loss_clf 0.864, Loss_fe 0.931, Loss_kd 1.133, Train_accy 74.64, Test_accy 74.17
2024-08-07 13:49:42,299 [foster.py] => Task 2, Epoch 69/170 => Loss 3.500, Loss_clf 0.867, Loss_fe 0.933, Loss_kd 1.132, Train_accy 74.14, Test_accy 76.17
2024-08-07 13:49:51,397 [foster.py] => Task 2, Epoch 70/170 => Loss 3.506, Loss_clf 0.869, Loss_fe 0.926, Loss_kd 1.139, Train_accy 74.01, Test_accy 77.77
2024-08-07 13:49:58,874 [foster.py] => Task 2, Epoch 71/170 => Loss 3.497, Loss_clf 0.872, Loss_fe 0.925, Loss_kd 1.132, Train_accy 74.06
2024-08-07 13:50:07,919 [foster.py] => Task 2, Epoch 72/170 => Loss 3.402, Loss_clf 0.827, Loss_fe 0.875, Loss_kd 1.132, Train_accy 75.19, Test_accy 77.67
2024-08-07 13:50:17,051 [foster.py] => Task 2, Epoch 73/170 => Loss 3.448, Loss_clf 0.850, Loss_fe 0.897, Loss_kd 1.132, Train_accy 74.67, Test_accy 72.13
2024-08-07 13:50:26,118 [foster.py] => Task 2, Epoch 74/170 => Loss 3.387, Loss_clf 0.817, Loss_fe 0.879, Loss_kd 1.125, Train_accy 74.97, Test_accy 78.60
2024-08-07 13:50:35,152 [foster.py] => Task 2, Epoch 75/170 => Loss 3.399, Loss_clf 0.826, Loss_fe 0.863, Loss_kd 1.138, Train_accy 75.79, Test_accy 79.20
2024-08-07 13:50:42,615 [foster.py] => Task 2, Epoch 76/170 => Loss 3.431, Loss_clf 0.842, Loss_fe 0.885, Loss_kd 1.135, Train_accy 75.01
2024-08-07 13:50:51,651 [foster.py] => Task 2, Epoch 77/170 => Loss 3.391, Loss_clf 0.823, Loss_fe 0.875, Loss_kd 1.127, Train_accy 75.81, Test_accy 78.40
2024-08-07 13:51:00,726 [foster.py] => Task 2, Epoch 78/170 => Loss 3.450, Loss_clf 0.854, Loss_fe 0.886, Loss_kd 1.138, Train_accy 75.06, Test_accy 76.13
2024-08-07 13:51:09,706 [foster.py] => Task 2, Epoch 79/170 => Loss 3.378, Loss_clf 0.811, Loss_fe 0.861, Loss_kd 1.136, Train_accy 75.37, Test_accy 77.33
2024-08-07 13:51:18,706 [foster.py] => Task 2, Epoch 80/170 => Loss 3.434, Loss_clf 0.853, Loss_fe 0.892, Loss_kd 1.125, Train_accy 74.80, Test_accy 78.83
2024-08-07 13:51:26,224 [foster.py] => Task 2, Epoch 81/170 => Loss 3.410, Loss_clf 0.842, Loss_fe 0.868, Loss_kd 1.131, Train_accy 75.24
2024-08-07 13:51:35,313 [foster.py] => Task 2, Epoch 82/170 => Loss 3.393, Loss_clf 0.821, Loss_fe 0.863, Loss_kd 1.138, Train_accy 76.07, Test_accy 77.70
2024-08-07 13:51:44,333 [foster.py] => Task 2, Epoch 83/170 => Loss 3.352, Loss_clf 0.814, Loss_fe 0.843, Loss_kd 1.128, Train_accy 75.40, Test_accy 75.40
2024-08-07 13:51:53,610 [foster.py] => Task 2, Epoch 84/170 => Loss 3.370, Loss_clf 0.816, Loss_fe 0.846, Loss_kd 1.137, Train_accy 76.50, Test_accy 75.93
2024-08-07 13:52:02,905 [foster.py] => Task 2, Epoch 85/170 => Loss 3.347, Loss_clf 0.807, Loss_fe 0.835, Loss_kd 1.135, Train_accy 75.30, Test_accy 79.80
2024-08-07 13:52:10,680 [foster.py] => Task 2, Epoch 86/170 => Loss 3.301, Loss_clf 0.785, Loss_fe 0.822, Loss_kd 1.128, Train_accy 76.10
2024-08-07 13:52:19,818 [foster.py] => Task 2, Epoch 87/170 => Loss 3.261, Loss_clf 0.772, Loss_fe 0.798, Loss_kd 1.126, Train_accy 76.67, Test_accy 79.87
2024-08-07 13:52:28,929 [foster.py] => Task 2, Epoch 88/170 => Loss 3.343, Loss_clf 0.804, Loss_fe 0.834, Loss_kd 1.136, Train_accy 76.83, Test_accy 78.23
2024-08-07 13:52:38,057 [foster.py] => Task 2, Epoch 89/170 => Loss 3.305, Loss_clf 0.788, Loss_fe 0.811, Loss_kd 1.136, Train_accy 76.30, Test_accy 75.33
2024-08-07 13:52:47,145 [foster.py] => Task 2, Epoch 90/170 => Loss 3.283, Loss_clf 0.782, Loss_fe 0.811, Loss_kd 1.125, Train_accy 77.26, Test_accy 75.67
2024-08-07 13:52:54,598 [foster.py] => Task 2, Epoch 91/170 => Loss 3.292, Loss_clf 0.784, Loss_fe 0.806, Loss_kd 1.133, Train_accy 77.03
2024-08-07 13:53:03,630 [foster.py] => Task 2, Epoch 92/170 => Loss 3.320, Loss_clf 0.799, Loss_fe 0.813, Loss_kd 1.137, Train_accy 76.06, Test_accy 77.87
2024-08-07 13:53:12,796 [foster.py] => Task 2, Epoch 93/170 => Loss 3.237, Loss_clf 0.759, Loss_fe 0.773, Loss_kd 1.135, Train_accy 77.64, Test_accy 78.23
2024-08-07 13:53:21,915 [foster.py] => Task 2, Epoch 94/170 => Loss 3.179, Loss_clf 0.727, Loss_fe 0.766, Loss_kd 1.122, Train_accy 78.53, Test_accy 78.97
2024-08-07 13:53:31,096 [foster.py] => Task 2, Epoch 95/170 => Loss 3.269, Loss_clf 0.770, Loss_fe 0.810, Loss_kd 1.124, Train_accy 76.80, Test_accy 78.93
2024-08-07 13:53:38,623 [foster.py] => Task 2, Epoch 96/170 => Loss 3.284, Loss_clf 0.783, Loss_fe 0.792, Loss_kd 1.138, Train_accy 76.81
2024-08-07 13:53:47,702 [foster.py] => Task 2, Epoch 97/170 => Loss 3.200, Loss_clf 0.735, Loss_fe 0.767, Loss_kd 1.130, Train_accy 78.77, Test_accy 79.27
2024-08-07 13:53:56,852 [foster.py] => Task 2, Epoch 98/170 => Loss 3.221, Loss_clf 0.751, Loss_fe 0.771, Loss_kd 1.131, Train_accy 77.66, Test_accy 79.37
2024-08-07 13:54:06,244 [foster.py] => Task 2, Epoch 99/170 => Loss 3.144, Loss_clf 0.720, Loss_fe 0.729, Loss_kd 1.128, Train_accy 78.13, Test_accy 79.33
2024-08-07 13:54:15,231 [foster.py] => Task 2, Epoch 100/170 => Loss 3.200, Loss_clf 0.744, Loss_fe 0.742, Loss_kd 1.141, Train_accy 78.37, Test_accy 78.90
2024-08-07 13:54:22,829 [foster.py] => Task 2, Epoch 101/170 => Loss 3.266, Loss_clf 0.771, Loss_fe 0.788, Loss_kd 1.136, Train_accy 77.56
2024-08-07 13:54:31,896 [foster.py] => Task 2, Epoch 102/170 => Loss 3.149, Loss_clf 0.719, Loss_fe 0.732, Loss_kd 1.131, Train_accy 79.06, Test_accy 80.10
2024-08-07 13:54:40,900 [foster.py] => Task 2, Epoch 103/170 => Loss 3.175, Loss_clf 0.727, Loss_fe 0.741, Loss_kd 1.136, Train_accy 78.20, Test_accy 79.53
2024-08-07 13:54:50,095 [foster.py] => Task 2, Epoch 104/170 => Loss 3.162, Loss_clf 0.731, Loss_fe 0.737, Loss_kd 1.128, Train_accy 78.10, Test_accy 78.87
2024-08-07 13:54:59,176 [foster.py] => Task 2, Epoch 105/170 => Loss 3.109, Loss_clf 0.701, Loss_fe 0.707, Loss_kd 1.132, Train_accy 79.26, Test_accy 79.73
2024-08-07 13:55:06,631 [foster.py] => Task 2, Epoch 106/170 => Loss 3.103, Loss_clf 0.696, Loss_fe 0.705, Loss_kd 1.133, Train_accy 79.39
2024-08-07 13:55:15,683 [foster.py] => Task 2, Epoch 107/170 => Loss 3.022, Loss_clf 0.659, Loss_fe 0.675, Loss_kd 1.124, Train_accy 80.31, Test_accy 78.33
2024-08-07 13:55:24,899 [foster.py] => Task 2, Epoch 108/170 => Loss 3.112, Loss_clf 0.706, Loss_fe 0.709, Loss_kd 1.130, Train_accy 79.27, Test_accy 77.67
2024-08-07 13:55:34,159 [foster.py] => Task 2, Epoch 109/170 => Loss 3.136, Loss_clf 0.715, Loss_fe 0.715, Loss_kd 1.136, Train_accy 78.67, Test_accy 80.70
2024-08-07 13:55:43,375 [foster.py] => Task 2, Epoch 110/170 => Loss 3.044, Loss_clf 0.672, Loss_fe 0.676, Loss_kd 1.129, Train_accy 80.24, Test_accy 79.63
2024-08-07 13:55:50,914 [foster.py] => Task 2, Epoch 111/170 => Loss 3.050, Loss_clf 0.674, Loss_fe 0.682, Loss_kd 1.127, Train_accy 79.90
2024-08-07 13:56:00,039 [foster.py] => Task 2, Epoch 112/170 => Loss 3.074, Loss_clf 0.684, Loss_fe 0.687, Loss_kd 1.134, Train_accy 80.24, Test_accy 78.53
2024-08-07 13:56:09,189 [foster.py] => Task 2, Epoch 113/170 => Loss 3.025, Loss_clf 0.662, Loss_fe 0.667, Loss_kd 1.130, Train_accy 80.71, Test_accy 78.63
2024-08-07 13:56:18,297 [foster.py] => Task 2, Epoch 114/170 => Loss 3.027, Loss_clf 0.668, Loss_fe 0.660, Loss_kd 1.131, Train_accy 80.33, Test_accy 79.70
2024-08-07 13:56:27,285 [foster.py] => Task 2, Epoch 115/170 => Loss 3.038, Loss_clf 0.674, Loss_fe 0.666, Loss_kd 1.130, Train_accy 80.47, Test_accy 80.63
2024-08-07 13:56:34,745 [foster.py] => Task 2, Epoch 116/170 => Loss 2.970, Loss_clf 0.639, Loss_fe 0.638, Loss_kd 1.127, Train_accy 81.36
2024-08-07 13:56:43,853 [foster.py] => Task 2, Epoch 117/170 => Loss 2.981, Loss_clf 0.638, Loss_fe 0.634, Loss_kd 1.137, Train_accy 81.66, Test_accy 80.47
2024-08-07 13:56:52,876 [foster.py] => Task 2, Epoch 118/170 => Loss 2.985, Loss_clf 0.650, Loss_fe 0.645, Loss_kd 1.125, Train_accy 80.76, Test_accy 80.93
2024-08-07 13:57:01,973 [foster.py] => Task 2, Epoch 119/170 => Loss 2.973, Loss_clf 0.649, Loss_fe 0.626, Loss_kd 1.131, Train_accy 81.44, Test_accy 80.40
2024-08-07 13:57:11,110 [foster.py] => Task 2, Epoch 120/170 => Loss 2.904, Loss_clf 0.608, Loss_fe 0.604, Loss_kd 1.126, Train_accy 82.21, Test_accy 80.40
2024-08-07 13:57:18,676 [foster.py] => Task 2, Epoch 121/170 => Loss 2.915, Loss_clf 0.617, Loss_fe 0.607, Loss_kd 1.126, Train_accy 81.80
2024-08-07 13:57:27,739 [foster.py] => Task 2, Epoch 122/170 => Loss 2.944, Loss_clf 0.630, Loss_fe 0.608, Loss_kd 1.136, Train_accy 81.84, Test_accy 80.93
2024-08-07 13:57:36,936 [foster.py] => Task 2, Epoch 123/170 => Loss 2.920, Loss_clf 0.610, Loss_fe 0.606, Loss_kd 1.134, Train_accy 82.46, Test_accy 80.57
2024-08-07 13:57:45,998 [foster.py] => Task 2, Epoch 124/170 => Loss 2.861, Loss_clf 0.594, Loss_fe 0.575, Loss_kd 1.126, Train_accy 82.49, Test_accy 79.13
2024-08-07 13:57:55,008 [foster.py] => Task 2, Epoch 125/170 => Loss 2.879, Loss_clf 0.609, Loss_fe 0.562, Loss_kd 1.137, Train_accy 82.56, Test_accy 81.33
2024-08-07 13:58:02,729 [foster.py] => Task 2, Epoch 126/170 => Loss 2.863, Loss_clf 0.600, Loss_fe 0.561, Loss_kd 1.133, Train_accy 82.33
2024-08-07 13:58:12,079 [foster.py] => Task 2, Epoch 127/170 => Loss 2.884, Loss_clf 0.607, Loss_fe 0.573, Loss_kd 1.134, Train_accy 82.09, Test_accy 80.80
2024-08-07 13:58:21,383 [foster.py] => Task 2, Epoch 128/170 => Loss 2.818, Loss_clf 0.576, Loss_fe 0.546, Loss_kd 1.129, Train_accy 83.41, Test_accy 80.63
2024-08-07 13:58:30,725 [foster.py] => Task 2, Epoch 129/170 => Loss 2.814, Loss_clf 0.564, Loss_fe 0.543, Loss_kd 1.136, Train_accy 83.70, Test_accy 81.47
2024-08-07 13:58:39,773 [foster.py] => Task 2, Epoch 130/170 => Loss 2.805, Loss_clf 0.572, Loss_fe 0.536, Loss_kd 1.130, Train_accy 83.19, Test_accy 81.77
2024-08-07 13:58:47,241 [foster.py] => Task 2, Epoch 131/170 => Loss 2.780, Loss_clf 0.565, Loss_fe 0.526, Loss_kd 1.125, Train_accy 83.37
2024-08-07 13:58:56,353 [foster.py] => Task 2, Epoch 132/170 => Loss 2.798, Loss_clf 0.564, Loss_fe 0.530, Loss_kd 1.134, Train_accy 83.54, Test_accy 81.73
2024-08-07 13:59:05,517 [foster.py] => Task 2, Epoch 133/170 => Loss 2.750, Loss_clf 0.545, Loss_fe 0.512, Loss_kd 1.127, Train_accy 84.00, Test_accy 81.47
2024-08-07 13:59:14,710 [foster.py] => Task 2, Epoch 134/170 => Loss 2.744, Loss_clf 0.546, Loss_fe 0.505, Loss_kd 1.127, Train_accy 83.97, Test_accy 81.57
2024-08-07 13:59:23,745 [foster.py] => Task 2, Epoch 135/170 => Loss 2.794, Loss_clf 0.566, Loss_fe 0.527, Loss_kd 1.132, Train_accy 83.63, Test_accy 81.50
2024-08-07 13:59:31,215 [foster.py] => Task 2, Epoch 136/170 => Loss 2.765, Loss_clf 0.559, Loss_fe 0.513, Loss_kd 1.128, Train_accy 84.11
2024-08-07 13:59:40,355 [foster.py] => Task 2, Epoch 137/170 => Loss 2.770, Loss_clf 0.555, Loss_fe 0.508, Loss_kd 1.136, Train_accy 84.24, Test_accy 81.70
2024-08-07 13:59:49,348 [foster.py] => Task 2, Epoch 138/170 => Loss 2.708, Loss_clf 0.525, Loss_fe 0.486, Loss_kd 1.130, Train_accy 84.70, Test_accy 82.50
2024-08-07 13:59:58,317 [foster.py] => Task 2, Epoch 139/170 => Loss 2.708, Loss_clf 0.524, Loss_fe 0.478, Loss_kd 1.136, Train_accy 85.23, Test_accy 81.87
2024-08-07 14:00:07,572 [foster.py] => Task 2, Epoch 140/170 => Loss 2.655, Loss_clf 0.503, Loss_fe 0.455, Loss_kd 1.130, Train_accy 85.71, Test_accy 81.53
2024-08-07 14:00:15,353 [foster.py] => Task 2, Epoch 141/170 => Loss 2.663, Loss_clf 0.513, Loss_fe 0.462, Loss_kd 1.124, Train_accy 84.99
2024-08-07 14:00:24,883 [foster.py] => Task 2, Epoch 142/170 => Loss 2.646, Loss_clf 0.501, Loss_fe 0.450, Loss_kd 1.129, Train_accy 86.26, Test_accy 82.37
2024-08-07 14:00:33,971 [foster.py] => Task 2, Epoch 143/170 => Loss 2.648, Loss_clf 0.506, Loss_fe 0.454, Loss_kd 1.124, Train_accy 85.47, Test_accy 81.97
2024-08-07 14:00:43,062 [foster.py] => Task 2, Epoch 144/170 => Loss 2.652, Loss_clf 0.504, Loss_fe 0.447, Loss_kd 1.132, Train_accy 85.61, Test_accy 82.30
2024-08-07 14:00:52,204 [foster.py] => Task 2, Epoch 145/170 => Loss 2.634, Loss_clf 0.500, Loss_fe 0.444, Loss_kd 1.125, Train_accy 85.29, Test_accy 82.43
2024-08-07 14:00:59,704 [foster.py] => Task 2, Epoch 146/170 => Loss 2.610, Loss_clf 0.494, Loss_fe 0.423, Loss_kd 1.127, Train_accy 85.91
2024-08-07 14:01:08,830 [foster.py] => Task 2, Epoch 147/170 => Loss 2.603, Loss_clf 0.487, Loss_fe 0.424, Loss_kd 1.126, Train_accy 86.23, Test_accy 82.30
2024-08-07 14:01:17,899 [foster.py] => Task 2, Epoch 148/170 => Loss 2.591, Loss_clf 0.478, Loss_fe 0.419, Loss_kd 1.127, Train_accy 86.46, Test_accy 82.27
2024-08-07 14:01:27,018 [foster.py] => Task 2, Epoch 149/170 => Loss 2.569, Loss_clf 0.470, Loss_fe 0.413, Loss_kd 1.122, Train_accy 86.54, Test_accy 82.67
2024-08-07 14:01:36,031 [foster.py] => Task 2, Epoch 150/170 => Loss 2.593, Loss_clf 0.481, Loss_fe 0.415, Loss_kd 1.130, Train_accy 85.89, Test_accy 82.70
2024-08-07 14:01:43,519 [foster.py] => Task 2, Epoch 151/170 => Loss 2.585, Loss_clf 0.475, Loss_fe 0.409, Loss_kd 1.132, Train_accy 86.34
2024-08-07 14:01:52,557 [foster.py] => Task 2, Epoch 152/170 => Loss 2.534, Loss_clf 0.453, Loss_fe 0.387, Loss_kd 1.128, Train_accy 86.84, Test_accy 82.33
2024-08-07 14:02:01,475 [foster.py] => Task 2, Epoch 153/170 => Loss 2.549, Loss_clf 0.459, Loss_fe 0.390, Loss_kd 1.132, Train_accy 86.87, Test_accy 82.80
2024-08-07 14:02:10,544 [foster.py] => Task 2, Epoch 154/170 => Loss 2.551, Loss_clf 0.464, Loss_fe 0.395, Loss_kd 1.126, Train_accy 86.93, Test_accy 82.77
2024-08-07 14:02:19,586 [foster.py] => Task 2, Epoch 155/170 => Loss 2.559, Loss_clf 0.463, Loss_fe 0.390, Loss_kd 1.136, Train_accy 86.83, Test_accy 82.53
2024-08-07 14:02:27,060 [foster.py] => Task 2, Epoch 156/170 => Loss 2.553, Loss_clf 0.470, Loss_fe 0.390, Loss_kd 1.128, Train_accy 86.57
2024-08-07 14:02:36,143 [foster.py] => Task 2, Epoch 157/170 => Loss 2.525, Loss_clf 0.454, Loss_fe 0.383, Loss_kd 1.125, Train_accy 86.80, Test_accy 82.67
2024-08-07 14:02:45,211 [foster.py] => Task 2, Epoch 158/170 => Loss 2.504, Loss_clf 0.440, Loss_fe 0.366, Loss_kd 1.130, Train_accy 87.54, Test_accy 82.70
2024-08-07 14:02:54,172 [foster.py] => Task 2, Epoch 159/170 => Loss 2.548, Loss_clf 0.467, Loss_fe 0.382, Loss_kd 1.131, Train_accy 86.70, Test_accy 82.70
2024-08-07 14:03:03,341 [foster.py] => Task 2, Epoch 160/170 => Loss 2.557, Loss_clf 0.466, Loss_fe 0.384, Loss_kd 1.136, Train_accy 86.63, Test_accy 83.03
2024-08-07 14:03:11,171 [foster.py] => Task 2, Epoch 161/170 => Loss 2.537, Loss_clf 0.454, Loss_fe 0.383, Loss_kd 1.132, Train_accy 87.07
2024-08-07 14:03:20,434 [foster.py] => Task 2, Epoch 162/170 => Loss 2.524, Loss_clf 0.453, Loss_fe 0.369, Loss_kd 1.133, Train_accy 87.20, Test_accy 82.77
2024-08-07 14:03:29,548 [foster.py] => Task 2, Epoch 163/170 => Loss 2.564, Loss_clf 0.472, Loss_fe 0.390, Loss_kd 1.133, Train_accy 86.57, Test_accy 82.60
2024-08-07 14:03:38,641 [foster.py] => Task 2, Epoch 164/170 => Loss 2.514, Loss_clf 0.448, Loss_fe 0.365, Loss_kd 1.133, Train_accy 87.47, Test_accy 82.63
2024-08-07 14:03:47,743 [foster.py] => Task 2, Epoch 165/170 => Loss 2.488, Loss_clf 0.438, Loss_fe 0.360, Loss_kd 1.125, Train_accy 88.03, Test_accy 82.83
2024-08-07 14:03:55,236 [foster.py] => Task 2, Epoch 166/170 => Loss 2.498, Loss_clf 0.441, Loss_fe 0.364, Loss_kd 1.127, Train_accy 87.60
2024-08-07 14:04:04,372 [foster.py] => Task 2, Epoch 167/170 => Loss 2.489, Loss_clf 0.433, Loss_fe 0.356, Loss_kd 1.131, Train_accy 87.84, Test_accy 82.90
2024-08-07 14:04:13,434 [foster.py] => Task 2, Epoch 168/170 => Loss 2.500, Loss_clf 0.440, Loss_fe 0.355, Loss_kd 1.135, Train_accy 87.46, Test_accy 82.90
2024-08-07 14:04:22,682 [foster.py] => Task 2, Epoch 169/170 => Loss 2.528, Loss_clf 0.455, Loss_fe 0.375, Loss_kd 1.131, Train_accy 87.03, Test_accy 83.00
2024-08-07 14:04:31,743 [foster.py] => Task 2, Epoch 170/170 => Loss 2.535, Loss_clf 0.463, Loss_fe 0.369, Loss_kd 1.134, Train_accy 87.36, Test_accy 82.97
2024-08-07 14:04:31,747 [foster.py] => do not weight align teacher!
2024-08-07 14:04:31,748 [foster.py] => per cls weights : [1.04047171 1.04047171 1.04047171 1.04047171 1.04047171 1.04047171
 1.04047171 1.04047171 1.04047171 1.04047171 1.04047171 1.04047171
 1.04047171 1.04047171 1.04047171 1.04047171 1.04047171 1.04047171
 1.04047171 1.04047171 0.91905658 0.91905658 0.91905658 0.91905658
 0.91905658 0.91905658 0.91905658 0.91905658 0.91905658 0.91905658]
2024-08-07 14:04:43,769 [foster.py] => SNet: Task 2, Epoch 1/130 => Loss 23.235,  Loss1 0.580, Train_accy 42.13, Test_accy 62.77
2024-08-07 14:04:54,217 [foster.py] => SNet: Task 2, Epoch 2/130 => Loss 22.953,  Loss1 0.580, Train_accy 61.36
2024-08-07 14:05:04,549 [foster.py] => SNet: Task 2, Epoch 3/130 => Loss 22.902,  Loss1 0.579, Train_accy 63.94
2024-08-07 14:05:14,930 [foster.py] => SNet: Task 2, Epoch 4/130 => Loss 22.871,  Loss1 0.579, Train_accy 68.63
2024-08-07 14:05:25,758 [foster.py] => SNet: Task 2, Epoch 5/130 => Loss 22.854,  Loss1 0.580, Train_accy 68.26
2024-08-07 14:05:37,746 [foster.py] => SNet: Task 2, Epoch 6/130 => Loss 22.857,  Loss1 0.579, Train_accy 70.06, Test_accy 73.03
2024-08-07 14:05:48,211 [foster.py] => SNet: Task 2, Epoch 7/130 => Loss 22.853,  Loss1 0.579, Train_accy 70.13
2024-08-07 14:05:58,648 [foster.py] => SNet: Task 2, Epoch 8/130 => Loss 22.859,  Loss1 0.579, Train_accy 71.27
2024-08-07 14:06:09,347 [foster.py] => SNet: Task 2, Epoch 9/130 => Loss 22.819,  Loss1 0.579, Train_accy 71.31
2024-08-07 14:06:19,703 [foster.py] => SNet: Task 2, Epoch 10/130 => Loss 22.821,  Loss1 0.579, Train_accy 72.39
2024-08-07 14:06:31,679 [foster.py] => SNet: Task 2, Epoch 11/130 => Loss 22.830,  Loss1 0.579, Train_accy 72.93, Test_accy 73.30
2024-08-07 14:06:42,272 [foster.py] => SNet: Task 2, Epoch 12/130 => Loss 22.823,  Loss1 0.579, Train_accy 72.97
2024-08-07 14:06:52,725 [foster.py] => SNet: Task 2, Epoch 13/130 => Loss 22.807,  Loss1 0.579, Train_accy 73.49
2024-08-07 14:07:03,145 [foster.py] => SNet: Task 2, Epoch 14/130 => Loss 22.809,  Loss1 0.579, Train_accy 74.31
2024-08-07 14:07:13,800 [foster.py] => SNet: Task 2, Epoch 15/130 => Loss 22.801,  Loss1 0.579, Train_accy 75.30
2024-08-07 14:07:25,728 [foster.py] => SNet: Task 2, Epoch 16/130 => Loss 22.783,  Loss1 0.579, Train_accy 74.94, Test_accy 74.90
2024-08-07 14:07:36,114 [foster.py] => SNet: Task 2, Epoch 17/130 => Loss 22.781,  Loss1 0.579, Train_accy 75.31
2024-08-07 14:07:46,673 [foster.py] => SNet: Task 2, Epoch 18/130 => Loss 22.772,  Loss1 0.579, Train_accy 75.43
2024-08-07 14:07:57,062 [foster.py] => SNet: Task 2, Epoch 19/130 => Loss 22.787,  Loss1 0.579, Train_accy 75.10
2024-08-07 14:08:07,691 [foster.py] => SNet: Task 2, Epoch 20/130 => Loss 22.779,  Loss1 0.579, Train_accy 76.20
2024-08-07 14:08:19,688 [foster.py] => SNet: Task 2, Epoch 21/130 => Loss 22.780,  Loss1 0.579, Train_accy 75.71, Test_accy 76.13
2024-08-07 14:08:30,017 [foster.py] => SNet: Task 2, Epoch 22/130 => Loss 22.794,  Loss1 0.579, Train_accy 75.87
2024-08-07 14:08:40,297 [foster.py] => SNet: Task 2, Epoch 23/130 => Loss 22.777,  Loss1 0.579, Train_accy 77.16
2024-08-07 14:08:50,631 [foster.py] => SNet: Task 2, Epoch 24/130 => Loss 22.776,  Loss1 0.579, Train_accy 76.21
2024-08-07 14:09:01,289 [foster.py] => SNet: Task 2, Epoch 25/130 => Loss 22.779,  Loss1 0.579, Train_accy 76.96
2024-08-07 14:09:13,168 [foster.py] => SNet: Task 2, Epoch 26/130 => Loss 22.777,  Loss1 0.579, Train_accy 77.69, Test_accy 77.30
2024-08-07 14:09:23,471 [foster.py] => SNet: Task 2, Epoch 27/130 => Loss 22.783,  Loss1 0.579, Train_accy 77.40
2024-08-07 14:09:33,908 [foster.py] => SNet: Task 2, Epoch 28/130 => Loss 22.764,  Loss1 0.579, Train_accy 77.89
2024-08-07 14:09:44,772 [foster.py] => SNet: Task 2, Epoch 29/130 => Loss 22.781,  Loss1 0.579, Train_accy 78.24
2024-08-07 14:09:55,211 [foster.py] => SNet: Task 2, Epoch 30/130 => Loss 22.763,  Loss1 0.579, Train_accy 78.46
2024-08-07 14:10:06,969 [foster.py] => SNet: Task 2, Epoch 31/130 => Loss 22.740,  Loss1 0.579, Train_accy 78.40, Test_accy 78.07
2024-08-07 14:10:17,328 [foster.py] => SNet: Task 2, Epoch 32/130 => Loss 22.763,  Loss1 0.579, Train_accy 78.26
2024-08-07 14:10:27,915 [foster.py] => SNet: Task 2, Epoch 33/130 => Loss 22.743,  Loss1 0.579, Train_accy 78.89
2024-08-07 14:10:38,478 [foster.py] => SNet: Task 2, Epoch 34/130 => Loss 22.762,  Loss1 0.579, Train_accy 78.94
2024-08-07 14:10:48,880 [foster.py] => SNet: Task 2, Epoch 35/130 => Loss 22.761,  Loss1 0.579, Train_accy 78.84
2024-08-07 14:11:00,851 [foster.py] => SNet: Task 2, Epoch 36/130 => Loss 22.749,  Loss1 0.579, Train_accy 79.46, Test_accy 78.07
2024-08-07 14:11:11,378 [foster.py] => SNet: Task 2, Epoch 37/130 => Loss 22.738,  Loss1 0.579, Train_accy 77.80
2024-08-07 14:11:21,786 [foster.py] => SNet: Task 2, Epoch 38/130 => Loss 22.775,  Loss1 0.579, Train_accy 78.53
2024-08-07 14:11:32,307 [foster.py] => SNet: Task 2, Epoch 39/130 => Loss 22.739,  Loss1 0.579, Train_accy 79.13
2024-08-07 14:11:43,038 [foster.py] => SNet: Task 2, Epoch 40/130 => Loss 22.734,  Loss1 0.579, Train_accy 79.10
2024-08-07 14:11:54,732 [foster.py] => SNet: Task 2, Epoch 41/130 => Loss 22.734,  Loss1 0.579, Train_accy 79.61, Test_accy 78.83
2024-08-07 14:12:05,127 [foster.py] => SNet: Task 2, Epoch 42/130 => Loss 22.739,  Loss1 0.579, Train_accy 79.80
2024-08-07 14:12:15,535 [foster.py] => SNet: Task 2, Epoch 43/130 => Loss 22.742,  Loss1 0.579, Train_accy 79.97
2024-08-07 14:12:25,906 [foster.py] => SNet: Task 2, Epoch 44/130 => Loss 22.741,  Loss1 0.579, Train_accy 80.31
2024-08-07 14:12:36,348 [foster.py] => SNet: Task 2, Epoch 45/130 => Loss 22.747,  Loss1 0.579, Train_accy 79.77
2024-08-07 14:12:48,236 [foster.py] => SNet: Task 2, Epoch 46/130 => Loss 22.734,  Loss1 0.579, Train_accy 80.19, Test_accy 79.20
2024-08-07 14:12:58,604 [foster.py] => SNet: Task 2, Epoch 47/130 => Loss 22.741,  Loss1 0.579, Train_accy 80.53
2024-08-07 14:13:08,890 [foster.py] => SNet: Task 2, Epoch 48/130 => Loss 22.721,  Loss1 0.579, Train_accy 80.59
2024-08-07 14:13:19,198 [foster.py] => SNet: Task 2, Epoch 49/130 => Loss 22.743,  Loss1 0.579, Train_accy 80.04
2024-08-07 14:13:29,542 [foster.py] => SNet: Task 2, Epoch 50/130 => Loss 22.739,  Loss1 0.579, Train_accy 80.70
2024-08-07 14:13:41,453 [foster.py] => SNet: Task 2, Epoch 51/130 => Loss 22.723,  Loss1 0.579, Train_accy 80.41, Test_accy 78.63
2024-08-07 14:13:51,920 [foster.py] => SNet: Task 2, Epoch 52/130 => Loss 22.725,  Loss1 0.579, Train_accy 80.79
2024-08-07 14:14:02,587 [foster.py] => SNet: Task 2, Epoch 53/130 => Loss 22.730,  Loss1 0.579, Train_accy 80.59
2024-08-07 14:14:13,283 [foster.py] => SNet: Task 2, Epoch 54/130 => Loss 22.733,  Loss1 0.579, Train_accy 80.51
2024-08-07 14:14:23,866 [foster.py] => SNet: Task 2, Epoch 55/130 => Loss 22.729,  Loss1 0.579, Train_accy 80.87
2024-08-07 14:14:35,847 [foster.py] => SNet: Task 2, Epoch 56/130 => Loss 22.718,  Loss1 0.579, Train_accy 81.04, Test_accy 79.63
2024-08-07 14:14:46,399 [foster.py] => SNet: Task 2, Epoch 57/130 => Loss 22.738,  Loss1 0.579, Train_accy 80.81
2024-08-07 14:14:56,850 [foster.py] => SNet: Task 2, Epoch 58/130 => Loss 22.725,  Loss1 0.579, Train_accy 81.96
2024-08-07 14:15:07,607 [foster.py] => SNet: Task 2, Epoch 59/130 => Loss 22.723,  Loss1 0.579, Train_accy 80.96
2024-08-07 14:15:18,283 [foster.py] => SNet: Task 2, Epoch 60/130 => Loss 22.719,  Loss1 0.579, Train_accy 82.21
2024-08-07 14:15:30,262 [foster.py] => SNet: Task 2, Epoch 61/130 => Loss 22.725,  Loss1 0.579, Train_accy 81.70, Test_accy 80.73
2024-08-07 14:15:40,708 [foster.py] => SNet: Task 2, Epoch 62/130 => Loss 22.724,  Loss1 0.579, Train_accy 81.79
2024-08-07 14:15:51,280 [foster.py] => SNet: Task 2, Epoch 63/130 => Loss 22.697,  Loss1 0.579, Train_accy 82.27
2024-08-07 14:16:01,854 [foster.py] => SNet: Task 2, Epoch 64/130 => Loss 22.706,  Loss1 0.579, Train_accy 80.83
2024-08-07 14:16:12,562 [foster.py] => SNet: Task 2, Epoch 65/130 => Loss 22.733,  Loss1 0.579, Train_accy 82.61
2024-08-07 14:16:24,368 [foster.py] => SNet: Task 2, Epoch 66/130 => Loss 22.724,  Loss1 0.579, Train_accy 81.49, Test_accy 79.73
2024-08-07 14:16:35,303 [foster.py] => SNet: Task 2, Epoch 67/130 => Loss 22.717,  Loss1 0.579, Train_accy 81.66
2024-08-07 14:16:45,803 [foster.py] => SNet: Task 2, Epoch 68/130 => Loss 22.720,  Loss1 0.579, Train_accy 81.96
2024-08-07 14:16:56,560 [foster.py] => SNet: Task 2, Epoch 69/130 => Loss 22.732,  Loss1 0.579, Train_accy 81.99
2024-08-07 14:17:07,290 [foster.py] => SNet: Task 2, Epoch 70/130 => Loss 22.714,  Loss1 0.579, Train_accy 81.99
2024-08-07 14:17:18,936 [foster.py] => SNet: Task 2, Epoch 71/130 => Loss 22.697,  Loss1 0.579, Train_accy 82.91, Test_accy 80.70
2024-08-07 14:17:29,422 [foster.py] => SNet: Task 2, Epoch 72/130 => Loss 22.706,  Loss1 0.579, Train_accy 82.26
2024-08-07 14:17:39,841 [foster.py] => SNet: Task 2, Epoch 73/130 => Loss 22.700,  Loss1 0.579, Train_accy 82.51
2024-08-07 14:17:50,735 [foster.py] => SNet: Task 2, Epoch 74/130 => Loss 22.717,  Loss1 0.579, Train_accy 81.93
2024-08-07 14:18:01,448 [foster.py] => SNet: Task 2, Epoch 75/130 => Loss 22.717,  Loss1 0.579, Train_accy 83.30
2024-08-07 14:18:13,268 [foster.py] => SNet: Task 2, Epoch 76/130 => Loss 22.713,  Loss1 0.579, Train_accy 82.31, Test_accy 80.53
2024-08-07 14:18:23,604 [foster.py] => SNet: Task 2, Epoch 77/130 => Loss 22.716,  Loss1 0.579, Train_accy 82.07
2024-08-07 14:18:33,954 [foster.py] => SNet: Task 2, Epoch 78/130 => Loss 22.697,  Loss1 0.579, Train_accy 83.37
2024-08-07 14:18:44,353 [foster.py] => SNet: Task 2, Epoch 79/130 => Loss 22.711,  Loss1 0.579, Train_accy 82.97
2024-08-07 14:18:55,102 [foster.py] => SNet: Task 2, Epoch 80/130 => Loss 22.707,  Loss1 0.579, Train_accy 82.77
2024-08-07 14:19:06,776 [foster.py] => SNet: Task 2, Epoch 81/130 => Loss 22.705,  Loss1 0.579, Train_accy 82.20, Test_accy 80.03
2024-08-07 14:19:17,270 [foster.py] => SNet: Task 2, Epoch 82/130 => Loss 22.693,  Loss1 0.579, Train_accy 83.36
2024-08-07 14:19:27,633 [foster.py] => SNet: Task 2, Epoch 83/130 => Loss 22.715,  Loss1 0.579, Train_accy 82.19
2024-08-07 14:19:38,225 [foster.py] => SNet: Task 2, Epoch 84/130 => Loss 22.694,  Loss1 0.579, Train_accy 82.43
2024-08-07 14:19:48,546 [foster.py] => SNet: Task 2, Epoch 85/130 => Loss 22.700,  Loss1 0.579, Train_accy 82.76
2024-08-07 14:20:00,227 [foster.py] => SNet: Task 2, Epoch 86/130 => Loss 22.703,  Loss1 0.579, Train_accy 82.97, Test_accy 80.63
2024-08-07 14:20:10,818 [foster.py] => SNet: Task 2, Epoch 87/130 => Loss 22.697,  Loss1 0.579, Train_accy 83.86
2024-08-07 14:20:21,193 [foster.py] => SNet: Task 2, Epoch 88/130 => Loss 22.688,  Loss1 0.579, Train_accy 83.29
2024-08-07 14:20:31,520 [foster.py] => SNet: Task 2, Epoch 89/130 => Loss 22.694,  Loss1 0.579, Train_accy 83.31
2024-08-07 14:20:41,912 [foster.py] => SNet: Task 2, Epoch 90/130 => Loss 22.685,  Loss1 0.579, Train_accy 83.23
2024-08-07 14:20:53,893 [foster.py] => SNet: Task 2, Epoch 91/130 => Loss 22.681,  Loss1 0.579, Train_accy 83.63, Test_accy 81.00
2024-08-07 14:21:04,479 [foster.py] => SNet: Task 2, Epoch 92/130 => Loss 22.704,  Loss1 0.579, Train_accy 82.96
2024-08-07 14:21:14,913 [foster.py] => SNet: Task 2, Epoch 93/130 => Loss 22.704,  Loss1 0.579, Train_accy 82.17
2024-08-07 14:21:25,245 [foster.py] => SNet: Task 2, Epoch 94/130 => Loss 22.695,  Loss1 0.579, Train_accy 83.14
2024-08-07 14:21:35,613 [foster.py] => SNet: Task 2, Epoch 95/130 => Loss 22.697,  Loss1 0.579, Train_accy 83.43
2024-08-07 14:21:47,288 [foster.py] => SNet: Task 2, Epoch 96/130 => Loss 22.704,  Loss1 0.579, Train_accy 83.99, Test_accy 80.93
2024-08-07 14:21:57,826 [foster.py] => SNet: Task 2, Epoch 97/130 => Loss 22.683,  Loss1 0.579, Train_accy 83.29
2024-08-07 14:22:08,122 [foster.py] => SNet: Task 2, Epoch 98/130 => Loss 22.702,  Loss1 0.579, Train_accy 83.43
2024-08-07 14:22:18,521 [foster.py] => SNet: Task 2, Epoch 99/130 => Loss 22.685,  Loss1 0.579, Train_accy 83.73
2024-08-07 14:22:29,514 [foster.py] => SNet: Task 2, Epoch 100/130 => Loss 22.699,  Loss1 0.579, Train_accy 83.33
2024-08-07 14:22:41,113 [foster.py] => SNet: Task 2, Epoch 101/130 => Loss 22.697,  Loss1 0.579, Train_accy 83.67, Test_accy 80.97
2024-08-07 14:22:51,727 [foster.py] => SNet: Task 2, Epoch 102/130 => Loss 22.680,  Loss1 0.579, Train_accy 83.74
2024-08-07 14:23:02,291 [foster.py] => SNet: Task 2, Epoch 103/130 => Loss 22.689,  Loss1 0.579, Train_accy 82.97
2024-08-07 14:23:12,790 [foster.py] => SNet: Task 2, Epoch 104/130 => Loss 22.702,  Loss1 0.579, Train_accy 83.34
2024-08-07 14:23:23,453 [foster.py] => SNet: Task 2, Epoch 105/130 => Loss 22.707,  Loss1 0.579, Train_accy 82.86
2024-08-07 14:23:35,658 [foster.py] => SNet: Task 2, Epoch 106/130 => Loss 22.706,  Loss1 0.579, Train_accy 83.43, Test_accy 80.83
2024-08-07 14:23:46,059 [foster.py] => SNet: Task 2, Epoch 107/130 => Loss 22.698,  Loss1 0.579, Train_accy 82.96
2024-08-07 14:23:56,846 [foster.py] => SNet: Task 2, Epoch 108/130 => Loss 22.692,  Loss1 0.579, Train_accy 83.17
2024-08-07 14:24:07,317 [foster.py] => SNet: Task 2, Epoch 109/130 => Loss 22.695,  Loss1 0.579, Train_accy 83.66
2024-08-07 14:24:17,761 [foster.py] => SNet: Task 2, Epoch 110/130 => Loss 22.697,  Loss1 0.579, Train_accy 84.11
2024-08-07 14:24:29,724 [foster.py] => SNet: Task 2, Epoch 111/130 => Loss 22.684,  Loss1 0.579, Train_accy 83.86, Test_accy 80.83
2024-08-07 14:24:40,411 [foster.py] => SNet: Task 2, Epoch 112/130 => Loss 22.696,  Loss1 0.579, Train_accy 83.64
2024-08-07 14:24:50,932 [foster.py] => SNet: Task 2, Epoch 113/130 => Loss 22.709,  Loss1 0.579, Train_accy 83.91
2024-08-07 14:25:01,491 [foster.py] => SNet: Task 2, Epoch 114/130 => Loss 22.692,  Loss1 0.579, Train_accy 83.83
2024-08-07 14:25:11,878 [foster.py] => SNet: Task 2, Epoch 115/130 => Loss 22.700,  Loss1 0.579, Train_accy 83.39
2024-08-07 14:25:23,657 [foster.py] => SNet: Task 2, Epoch 116/130 => Loss 22.697,  Loss1 0.579, Train_accy 83.94, Test_accy 81.07
2024-08-07 14:25:34,251 [foster.py] => SNet: Task 2, Epoch 117/130 => Loss 22.708,  Loss1 0.579, Train_accy 82.91
2024-08-07 14:25:44,842 [foster.py] => SNet: Task 2, Epoch 118/130 => Loss 22.711,  Loss1 0.579, Train_accy 84.21
2024-08-07 14:25:55,497 [foster.py] => SNet: Task 2, Epoch 119/130 => Loss 22.685,  Loss1 0.579, Train_accy 83.87
2024-08-07 14:26:05,823 [foster.py] => SNet: Task 2, Epoch 120/130 => Loss 22.694,  Loss1 0.579, Train_accy 83.70
2024-08-07 14:26:17,547 [foster.py] => SNet: Task 2, Epoch 121/130 => Loss 22.695,  Loss1 0.579, Train_accy 84.06, Test_accy 81.17
2024-08-07 14:26:27,963 [foster.py] => SNet: Task 2, Epoch 122/130 => Loss 22.704,  Loss1 0.579, Train_accy 83.64
2024-08-07 14:26:38,427 [foster.py] => SNet: Task 2, Epoch 123/130 => Loss 22.705,  Loss1 0.579, Train_accy 83.66
2024-08-07 14:26:49,216 [foster.py] => SNet: Task 2, Epoch 124/130 => Loss 22.708,  Loss1 0.579, Train_accy 83.11
2024-08-07 14:26:59,601 [foster.py] => SNet: Task 2, Epoch 125/130 => Loss 22.700,  Loss1 0.579, Train_accy 83.60
2024-08-07 14:27:11,325 [foster.py] => SNet: Task 2, Epoch 126/130 => Loss 22.687,  Loss1 0.579, Train_accy 83.51, Test_accy 80.80
2024-08-07 14:27:21,704 [foster.py] => SNet: Task 2, Epoch 127/130 => Loss 22.672,  Loss1 0.579, Train_accy 83.64
2024-08-07 14:27:32,090 [foster.py] => SNet: Task 2, Epoch 128/130 => Loss 22.701,  Loss1 0.579, Train_accy 84.03
2024-08-07 14:27:42,558 [foster.py] => SNet: Task 2, Epoch 129/130 => Loss 22.705,  Loss1 0.579, Train_accy 84.27
2024-08-07 14:27:53,647 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 22.708,  Loss1 0.579, Train_accy 83.47
2024-08-07 14:27:53,647 [foster.py] => do not weight align student!
2024-08-07 14:27:55,019 [foster.py] => darknet eval: 
2024-08-07 14:27:55,019 [foster.py] => CNN top1 curve: 81.37
2024-08-07 14:27:55,019 [foster.py] => CNN top5 curve: 96.47
2024-08-07 14:27:55,019 [foster.py] => CNN top1 平均值: 81.37
2024-08-07 14:27:55,025 [foster.py] => timees : 2900.3062043190002
2024-08-07 14:27:55,026 [base.py] => Reducing exemplars...(66 per classes)
2024-08-07 14:28:02,579 [base.py] => Constructing exemplars...(66 per classes)
2024-08-07 14:28:16,348 [foster.py] => Exemplar size: 1980
2024-08-07 14:28:16,348 [trainer.py] => CNN: {'total': 82.97, '00-09': 82.9, '10-19': 79.0, '20-29': 87.0, 'old': 80.95, 'new': 87.0}
2024-08-07 14:28:16,348 [trainer.py] => NME: {'total': 81.7, '00-09': 82.5, '10-19': 74.8, '20-29': 87.8, 'old': 78.65, 'new': 87.8}
2024-08-07 14:28:16,348 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97]
2024-08-07 14:28:16,348 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1]
2024-08-07 14:28:16,348 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7]
2024-08-07 14:28:16,348 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23]

2024-08-07 14:28:16,348 [trainer.py] => CNN top1 平均值: 87.51
2024-08-07 14:28:16,351 [trainer.py] => All params: 1289668
2024-08-07 14:28:16,353 [trainer.py] => Trainable params: 647094
2024-08-07 14:28:16,416 [foster.py] => Learning on 30-40
2024-08-07 14:28:16,419 [foster.py] => All params: 1292258
2024-08-07 14:28:16,421 [foster.py] => Trainable params: 649034
2024-08-07 14:28:16,482 [foster.py] => per cls weights : [1.05615561 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561
 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561
 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561
 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561
 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561 1.05615561
 0.83153316 0.83153316 0.83153316 0.83153316 0.83153316 0.83153316
 0.83153316 0.83153316 0.83153316 0.83153316]
2024-08-07 14:28:24,510 [foster.py] => Task 3, Epoch 1/170 => Loss 5.878, Loss_clf 1.992, Loss_fe 1.847, Loss_kd 1.527, Train_accy 47.39
2024-08-07 14:28:33,929 [foster.py] => Task 3, Epoch 2/170 => Loss 4.903, Loss_clf 1.386, Loss_fe 1.510, Loss_kd 1.503, Train_accy 55.30, Test_accy 68.60
2024-08-07 14:28:43,247 [foster.py] => Task 3, Epoch 3/170 => Loss 4.803, Loss_clf 1.365, Loss_fe 1.431, Loss_kd 1.503, Train_accy 56.72, Test_accy 66.80
2024-08-07 14:28:52,535 [foster.py] => Task 3, Epoch 4/170 => Loss 4.771, Loss_clf 1.362, Loss_fe 1.397, Loss_kd 1.507, Train_accy 57.81, Test_accy 71.18
2024-08-07 14:29:01,824 [foster.py] => Task 3, Epoch 5/170 => Loss 4.706, Loss_clf 1.328, Loss_fe 1.373, Loss_kd 1.502, Train_accy 57.49, Test_accy 68.70
2024-08-07 14:29:09,346 [foster.py] => Task 3, Epoch 6/170 => Loss 4.692, Loss_clf 1.345, Loss_fe 1.339, Loss_kd 1.503, Train_accy 58.05
2024-08-07 14:29:18,539 [foster.py] => Task 3, Epoch 7/170 => Loss 4.661, Loss_clf 1.283, Loss_fe 1.367, Loss_kd 1.506, Train_accy 59.73, Test_accy 72.62
2024-08-07 14:29:27,893 [foster.py] => Task 3, Epoch 8/170 => Loss 4.578, Loss_clf 1.263, Loss_fe 1.310, Loss_kd 1.501, Train_accy 60.82, Test_accy 69.42
2024-08-07 14:29:37,215 [foster.py] => Task 3, Epoch 9/170 => Loss 4.601, Loss_clf 1.263, Loss_fe 1.320, Loss_kd 1.512, Train_accy 60.37, Test_accy 70.60
2024-08-07 14:29:46,576 [foster.py] => Task 3, Epoch 10/170 => Loss 4.508, Loss_clf 1.223, Loss_fe 1.276, Loss_kd 1.504, Train_accy 61.13, Test_accy 69.65
2024-08-07 14:29:54,155 [foster.py] => Task 3, Epoch 11/170 => Loss 4.588, Loss_clf 1.304, Loss_fe 1.275, Loss_kd 1.504, Train_accy 60.10
2024-08-07 14:30:03,639 [foster.py] => Task 3, Epoch 12/170 => Loss 4.540, Loss_clf 1.248, Loss_fe 1.281, Loss_kd 1.506, Train_accy 60.80, Test_accy 71.88
2024-08-07 14:30:12,912 [foster.py] => Task 3, Epoch 13/170 => Loss 4.447, Loss_clf 1.199, Loss_fe 1.252, Loss_kd 1.495, Train_accy 61.82, Test_accy 70.97
2024-08-07 14:30:22,157 [foster.py] => Task 3, Epoch 14/170 => Loss 4.500, Loss_clf 1.235, Loss_fe 1.252, Loss_kd 1.507, Train_accy 61.39, Test_accy 68.60
2024-08-07 14:30:31,407 [foster.py] => Task 3, Epoch 15/170 => Loss 4.487, Loss_clf 1.213, Loss_fe 1.267, Loss_kd 1.503, Train_accy 61.63, Test_accy 72.08
2024-08-07 14:30:38,989 [foster.py] => Task 3, Epoch 16/170 => Loss 4.462, Loss_clf 1.234, Loss_fe 1.232, Loss_kd 1.495, Train_accy 61.13
2024-08-07 14:30:48,284 [foster.py] => Task 3, Epoch 17/170 => Loss 4.481, Loss_clf 1.241, Loss_fe 1.225, Loss_kd 1.509, Train_accy 61.75, Test_accy 68.42
2024-08-07 14:30:57,578 [foster.py] => Task 3, Epoch 18/170 => Loss 4.400, Loss_clf 1.180, Loss_fe 1.219, Loss_kd 1.498, Train_accy 62.65, Test_accy 71.03
2024-08-07 14:31:06,747 [foster.py] => Task 3, Epoch 19/170 => Loss 4.462, Loss_clf 1.225, Loss_fe 1.229, Loss_kd 1.505, Train_accy 62.41, Test_accy 71.70
2024-08-07 14:31:16,065 [foster.py] => Task 3, Epoch 20/170 => Loss 4.518, Loss_clf 1.257, Loss_fe 1.236, Loss_kd 1.516, Train_accy 61.07, Test_accy 69.92
2024-08-07 14:31:23,569 [foster.py] => Task 3, Epoch 21/170 => Loss 4.395, Loss_clf 1.189, Loss_fe 1.194, Loss_kd 1.507, Train_accy 63.34
2024-08-07 14:31:32,765 [foster.py] => Task 3, Epoch 22/170 => Loss 4.369, Loss_clf 1.172, Loss_fe 1.195, Loss_kd 1.500, Train_accy 63.83, Test_accy 72.40
2024-08-07 14:31:41,924 [foster.py] => Task 3, Epoch 23/170 => Loss 4.326, Loss_clf 1.143, Loss_fe 1.175, Loss_kd 1.503, Train_accy 63.93, Test_accy 72.05
2024-08-07 14:31:51,123 [foster.py] => Task 3, Epoch 24/170 => Loss 4.351, Loss_clf 1.151, Loss_fe 1.195, Loss_kd 1.502, Train_accy 63.34, Test_accy 68.72
2024-08-07 14:32:00,365 [foster.py] => Task 3, Epoch 25/170 => Loss 4.375, Loss_clf 1.173, Loss_fe 1.187, Loss_kd 1.509, Train_accy 63.35, Test_accy 71.32
2024-08-07 14:32:07,981 [foster.py] => Task 3, Epoch 26/170 => Loss 4.463, Loss_clf 1.229, Loss_fe 1.219, Loss_kd 1.510, Train_accy 62.16
2024-08-07 14:32:17,263 [foster.py] => Task 3, Epoch 27/170 => Loss 4.323, Loss_clf 1.156, Loss_fe 1.152, Loss_kd 1.509, Train_accy 64.04, Test_accy 73.40
2024-08-07 14:32:26,526 [foster.py] => Task 3, Epoch 28/170 => Loss 4.279, Loss_clf 1.133, Loss_fe 1.139, Loss_kd 1.503, Train_accy 64.51, Test_accy 71.15
2024-08-07 14:32:36,163 [foster.py] => Task 3, Epoch 29/170 => Loss 4.293, Loss_clf 1.132, Loss_fe 1.154, Loss_kd 1.503, Train_accy 64.41, Test_accy 73.05
2024-08-07 14:32:45,648 [foster.py] => Task 3, Epoch 30/170 => Loss 4.281, Loss_clf 1.129, Loss_fe 1.143, Loss_kd 1.504, Train_accy 64.73, Test_accy 71.58
2024-08-07 14:32:53,510 [foster.py] => Task 3, Epoch 31/170 => Loss 4.317, Loss_clf 1.140, Loss_fe 1.158, Loss_kd 1.512, Train_accy 64.61
2024-08-07 14:33:03,221 [foster.py] => Task 3, Epoch 32/170 => Loss 4.376, Loss_clf 1.204, Loss_fe 1.172, Loss_kd 1.498, Train_accy 63.61, Test_accy 70.00
2024-08-07 14:33:12,526 [foster.py] => Task 3, Epoch 33/170 => Loss 4.285, Loss_clf 1.120, Loss_fe 1.152, Loss_kd 1.507, Train_accy 64.74, Test_accy 70.97
2024-08-07 14:33:21,786 [foster.py] => Task 3, Epoch 34/170 => Loss 4.353, Loss_clf 1.178, Loss_fe 1.153, Loss_kd 1.514, Train_accy 63.62, Test_accy 72.30
2024-08-07 14:33:31,045 [foster.py] => Task 3, Epoch 35/170 => Loss 4.295, Loss_clf 1.159, Loss_fe 1.120, Loss_kd 1.509, Train_accy 64.15, Test_accy 73.42
2024-08-07 14:33:38,578 [foster.py] => Task 3, Epoch 36/170 => Loss 4.282, Loss_clf 1.130, Loss_fe 1.150, Loss_kd 1.499, Train_accy 65.13
2024-08-07 14:33:47,867 [foster.py] => Task 3, Epoch 37/170 => Loss 4.254, Loss_clf 1.110, Loss_fe 1.129, Loss_kd 1.509, Train_accy 64.93, Test_accy 72.08
2024-08-07 14:33:57,186 [foster.py] => Task 3, Epoch 38/170 => Loss 4.208, Loss_clf 1.095, Loss_fe 1.115, Loss_kd 1.497, Train_accy 65.50, Test_accy 72.30
2024-08-07 14:34:06,509 [foster.py] => Task 3, Epoch 39/170 => Loss 4.226, Loss_clf 1.096, Loss_fe 1.126, Loss_kd 1.500, Train_accy 65.10, Test_accy 72.70
2024-08-07 14:34:15,794 [foster.py] => Task 3, Epoch 40/170 => Loss 4.261, Loss_clf 1.127, Loss_fe 1.129, Loss_kd 1.501, Train_accy 64.94, Test_accy 72.35
2024-08-07 14:34:23,346 [foster.py] => Task 3, Epoch 41/170 => Loss 4.283, Loss_clf 1.141, Loss_fe 1.129, Loss_kd 1.508, Train_accy 65.32
2024-08-07 14:34:32,612 [foster.py] => Task 3, Epoch 42/170 => Loss 4.262, Loss_clf 1.125, Loss_fe 1.118, Loss_kd 1.512, Train_accy 64.74, Test_accy 74.32
2024-08-07 14:34:41,867 [foster.py] => Task 3, Epoch 43/170 => Loss 4.225, Loss_clf 1.111, Loss_fe 1.099, Loss_kd 1.509, Train_accy 65.52, Test_accy 72.47
2024-08-07 14:34:51,160 [foster.py] => Task 3, Epoch 44/170 => Loss 4.206, Loss_clf 1.113, Loss_fe 1.092, Loss_kd 1.499, Train_accy 65.03, Test_accy 70.90
2024-08-07 14:35:00,438 [foster.py] => Task 3, Epoch 45/170 => Loss 4.320, Loss_clf 1.168, Loss_fe 1.136, Loss_kd 1.510, Train_accy 63.84, Test_accy 70.75
2024-08-07 14:35:07,912 [foster.py] => Task 3, Epoch 46/170 => Loss 4.182, Loss_clf 1.087, Loss_fe 1.093, Loss_kd 1.499, Train_accy 65.52
2024-08-07 14:35:17,183 [foster.py] => Task 3, Epoch 47/170 => Loss 4.222, Loss_clf 1.117, Loss_fe 1.099, Loss_kd 1.502, Train_accy 65.19, Test_accy 70.28
2024-08-07 14:35:26,597 [foster.py] => Task 3, Epoch 48/170 => Loss 4.177, Loss_clf 1.091, Loss_fe 1.083, Loss_kd 1.500, Train_accy 65.06, Test_accy 72.53
2024-08-07 14:35:35,861 [foster.py] => Task 3, Epoch 49/170 => Loss 4.138, Loss_clf 1.056, Loss_fe 1.075, Loss_kd 1.503, Train_accy 66.82, Test_accy 73.53
2024-08-07 14:35:45,126 [foster.py] => Task 3, Epoch 50/170 => Loss 4.110, Loss_clf 1.060, Loss_fe 1.050, Loss_kd 1.497, Train_accy 67.21, Test_accy 70.35
2024-08-07 14:35:52,666 [foster.py] => Task 3, Epoch 51/170 => Loss 4.121, Loss_clf 1.054, Loss_fe 1.070, Loss_kd 1.495, Train_accy 66.79
2024-08-07 14:36:01,938 [foster.py] => Task 3, Epoch 52/170 => Loss 4.134, Loss_clf 1.074, Loss_fe 1.064, Loss_kd 1.494, Train_accy 66.42, Test_accy 73.78
2024-08-07 14:36:11,160 [foster.py] => Task 3, Epoch 53/170 => Loss 4.156, Loss_clf 1.097, Loss_fe 1.052, Loss_kd 1.504, Train_accy 66.09, Test_accy 72.35
2024-08-07 14:36:20,479 [foster.py] => Task 3, Epoch 54/170 => Loss 4.253, Loss_clf 1.141, Loss_fe 1.094, Loss_kd 1.511, Train_accy 64.37, Test_accy 71.40
2024-08-07 14:36:29,719 [foster.py] => Task 3, Epoch 55/170 => Loss 4.129, Loss_clf 1.085, Loss_fe 1.037, Loss_kd 1.503, Train_accy 65.95, Test_accy 72.95
2024-08-07 14:36:37,293 [foster.py] => Task 3, Epoch 56/170 => Loss 4.138, Loss_clf 1.088, Loss_fe 1.051, Loss_kd 1.497, Train_accy 66.26
2024-08-07 14:36:46,521 [foster.py] => Task 3, Epoch 57/170 => Loss 4.078, Loss_clf 1.039, Loss_fe 1.035, Loss_kd 1.500, Train_accy 67.49, Test_accy 73.58
2024-08-07 14:36:55,929 [foster.py] => Task 3, Epoch 58/170 => Loss 4.126, Loss_clf 1.060, Loss_fe 1.049, Loss_kd 1.510, Train_accy 66.93, Test_accy 74.10
2024-08-07 14:37:05,288 [foster.py] => Task 3, Epoch 59/170 => Loss 4.095, Loss_clf 1.065, Loss_fe 1.026, Loss_kd 1.501, Train_accy 66.91, Test_accy 73.82
2024-08-07 14:37:14,574 [foster.py] => Task 3, Epoch 60/170 => Loss 4.071, Loss_clf 1.045, Loss_fe 1.024, Loss_kd 1.499, Train_accy 67.71, Test_accy 72.88
2024-08-07 14:37:22,078 [foster.py] => Task 3, Epoch 61/170 => Loss 4.092, Loss_clf 1.074, Loss_fe 1.020, Loss_kd 1.496, Train_accy 67.11
2024-08-07 14:37:31,348 [foster.py] => Task 3, Epoch 62/170 => Loss 4.042, Loss_clf 1.035, Loss_fe 1.013, Loss_kd 1.493, Train_accy 68.32, Test_accy 74.05
2024-08-07 14:37:40,625 [foster.py] => Task 3, Epoch 63/170 => Loss 4.023, Loss_clf 1.025, Loss_fe 0.994, Loss_kd 1.501, Train_accy 68.21, Test_accy 72.47
2024-08-07 14:37:49,859 [foster.py] => Task 3, Epoch 64/170 => Loss 4.045, Loss_clf 1.024, Loss_fe 1.025, Loss_kd 1.495, Train_accy 67.97, Test_accy 71.60
2024-08-07 14:37:59,179 [foster.py] => Task 3, Epoch 65/170 => Loss 4.065, Loss_clf 1.043, Loss_fe 1.012, Loss_kd 1.506, Train_accy 66.89, Test_accy 70.60
2024-08-07 14:38:06,692 [foster.py] => Task 3, Epoch 66/170 => Loss 4.074, Loss_clf 1.049, Loss_fe 1.015, Loss_kd 1.505, Train_accy 67.69
2024-08-07 14:38:15,986 [foster.py] => Task 3, Epoch 67/170 => Loss 4.064, Loss_clf 1.041, Loss_fe 1.009, Loss_kd 1.508, Train_accy 67.15, Test_accy 73.65
2024-08-07 14:38:25,197 [foster.py] => Task 3, Epoch 68/170 => Loss 3.976, Loss_clf 1.000, Loss_fe 0.978, Loss_kd 1.496, Train_accy 68.44, Test_accy 74.42
2024-08-07 14:38:34,429 [foster.py] => Task 3, Epoch 69/170 => Loss 4.089, Loss_clf 1.087, Loss_fe 0.995, Loss_kd 1.503, Train_accy 66.96, Test_accy 73.60
2024-08-07 14:38:43,760 [foster.py] => Task 3, Epoch 70/170 => Loss 4.040, Loss_clf 1.045, Loss_fe 0.990, Loss_kd 1.501, Train_accy 67.58, Test_accy 72.90
2024-08-07 14:38:51,234 [foster.py] => Task 3, Epoch 71/170 => Loss 4.006, Loss_clf 1.011, Loss_fe 0.991, Loss_kd 1.501, Train_accy 68.34
2024-08-07 14:39:00,564 [foster.py] => Task 3, Epoch 72/170 => Loss 3.965, Loss_clf 0.991, Loss_fe 0.974, Loss_kd 1.497, Train_accy 68.14, Test_accy 74.68
2024-08-07 14:39:09,825 [foster.py] => Task 3, Epoch 73/170 => Loss 3.901, Loss_clf 0.962, Loss_fe 0.934, Loss_kd 1.501, Train_accy 69.68, Test_accy 74.05
2024-08-07 14:39:19,174 [foster.py] => Task 3, Epoch 74/170 => Loss 3.980, Loss_clf 1.000, Loss_fe 0.974, Loss_kd 1.502, Train_accy 69.11, Test_accy 74.03
2024-08-07 14:39:28,536 [foster.py] => Task 3, Epoch 75/170 => Loss 3.944, Loss_clf 0.997, Loss_fe 0.950, Loss_kd 1.495, Train_accy 69.24, Test_accy 72.60
2024-08-07 14:39:36,154 [foster.py] => Task 3, Epoch 76/170 => Loss 3.958, Loss_clf 1.000, Loss_fe 0.958, Loss_kd 1.498, Train_accy 68.98
2024-08-07 14:39:45,403 [foster.py] => Task 3, Epoch 77/170 => Loss 3.901, Loss_clf 0.970, Loss_fe 0.936, Loss_kd 1.494, Train_accy 69.81, Test_accy 72.90
2024-08-07 14:39:54,686 [foster.py] => Task 3, Epoch 78/170 => Loss 3.947, Loss_clf 0.990, Loss_fe 0.950, Loss_kd 1.503, Train_accy 69.31, Test_accy 74.30
2024-08-07 14:40:03,941 [foster.py] => Task 3, Epoch 79/170 => Loss 3.869, Loss_clf 0.941, Loss_fe 0.928, Loss_kd 1.497, Train_accy 71.07, Test_accy 70.97
2024-08-07 14:40:13,247 [foster.py] => Task 3, Epoch 80/170 => Loss 3.834, Loss_clf 0.917, Loss_fe 0.924, Loss_kd 1.492, Train_accy 70.89, Test_accy 74.32
2024-08-07 14:40:20,734 [foster.py] => Task 3, Epoch 81/170 => Loss 3.931, Loss_clf 0.987, Loss_fe 0.931, Loss_kd 1.508, Train_accy 69.73
2024-08-07 14:40:30,082 [foster.py] => Task 3, Epoch 82/170 => Loss 3.800, Loss_clf 0.911, Loss_fe 0.893, Loss_kd 1.495, Train_accy 71.52, Test_accy 72.50
2024-08-07 14:40:39,397 [foster.py] => Task 3, Epoch 83/170 => Loss 3.840, Loss_clf 0.930, Loss_fe 0.908, Loss_kd 1.500, Train_accy 70.32, Test_accy 72.68
2024-08-07 14:40:48,672 [foster.py] => Task 3, Epoch 84/170 => Loss 3.834, Loss_clf 0.945, Loss_fe 0.885, Loss_kd 1.502, Train_accy 70.79, Test_accy 71.82
2024-08-07 14:40:57,929 [foster.py] => Task 3, Epoch 85/170 => Loss 3.859, Loss_clf 0.946, Loss_fe 0.909, Loss_kd 1.501, Train_accy 70.63, Test_accy 72.78
2024-08-07 14:41:05,512 [foster.py] => Task 3, Epoch 86/170 => Loss 3.785, Loss_clf 0.902, Loss_fe 0.883, Loss_kd 1.498, Train_accy 72.25
2024-08-07 14:41:14,866 [foster.py] => Task 3, Epoch 87/170 => Loss 3.846, Loss_clf 0.942, Loss_fe 0.898, Loss_kd 1.502, Train_accy 70.34, Test_accy 74.50
2024-08-07 14:41:24,217 [foster.py] => Task 3, Epoch 88/170 => Loss 3.810, Loss_clf 0.937, Loss_fe 0.878, Loss_kd 1.494, Train_accy 70.57, Test_accy 72.92
2024-08-07 14:41:33,479 [foster.py] => Task 3, Epoch 89/170 => Loss 3.771, Loss_clf 0.904, Loss_fe 0.862, Loss_kd 1.501, Train_accy 72.13, Test_accy 75.05
2024-08-07 14:41:42,831 [foster.py] => Task 3, Epoch 90/170 => Loss 3.798, Loss_clf 0.925, Loss_fe 0.877, Loss_kd 1.494, Train_accy 71.40, Test_accy 73.40
2024-08-07 14:41:50,393 [foster.py] => Task 3, Epoch 91/170 => Loss 3.827, Loss_clf 0.923, Loss_fe 0.893, Loss_kd 1.506, Train_accy 70.95
2024-08-07 14:41:59,628 [foster.py] => Task 3, Epoch 92/170 => Loss 3.700, Loss_clf 0.874, Loss_fe 0.834, Loss_kd 1.492, Train_accy 71.93, Test_accy 75.53
2024-08-07 14:42:08,914 [foster.py] => Task 3, Epoch 93/170 => Loss 3.721, Loss_clf 0.880, Loss_fe 0.829, Loss_kd 1.507, Train_accy 72.55, Test_accy 74.42
2024-08-07 14:42:18,213 [foster.py] => Task 3, Epoch 94/170 => Loss 3.746, Loss_clf 0.885, Loss_fe 0.858, Loss_kd 1.500, Train_accy 72.42, Test_accy 75.40
2024-08-07 14:42:27,575 [foster.py] => Task 3, Epoch 95/170 => Loss 3.680, Loss_clf 0.856, Loss_fe 0.822, Loss_kd 1.500, Train_accy 72.72, Test_accy 73.97
2024-08-07 14:42:35,144 [foster.py] => Task 3, Epoch 96/170 => Loss 3.664, Loss_clf 0.850, Loss_fe 0.809, Loss_kd 1.501, Train_accy 73.95
2024-08-07 14:42:44,475 [foster.py] => Task 3, Epoch 97/170 => Loss 3.774, Loss_clf 0.905, Loss_fe 0.857, Loss_kd 1.507, Train_accy 71.03, Test_accy 74.78
2024-08-07 14:42:53,697 [foster.py] => Task 3, Epoch 98/170 => Loss 3.660, Loss_clf 0.859, Loss_fe 0.796, Loss_kd 1.502, Train_accy 72.45, Test_accy 74.85
2024-08-07 14:43:02,909 [foster.py] => Task 3, Epoch 99/170 => Loss 3.623, Loss_clf 0.837, Loss_fe 0.787, Loss_kd 1.497, Train_accy 73.95, Test_accy 74.90
2024-08-07 14:43:12,189 [foster.py] => Task 3, Epoch 100/170 => Loss 3.655, Loss_clf 0.845, Loss_fe 0.808, Loss_kd 1.499, Train_accy 73.27, Test_accy 75.15
2024-08-07 14:43:19,640 [foster.py] => Task 3, Epoch 101/170 => Loss 3.600, Loss_clf 0.817, Loss_fe 0.789, Loss_kd 1.493, Train_accy 74.36
2024-08-07 14:43:28,884 [foster.py] => Task 3, Epoch 102/170 => Loss 3.657, Loss_clf 0.857, Loss_fe 0.790, Loss_kd 1.506, Train_accy 73.11, Test_accy 74.62
2024-08-07 14:43:38,289 [foster.py] => Task 3, Epoch 103/170 => Loss 3.657, Loss_clf 0.859, Loss_fe 0.786, Loss_kd 1.506, Train_accy 73.90, Test_accy 76.00
2024-08-07 14:43:47,587 [foster.py] => Task 3, Epoch 104/170 => Loss 3.610, Loss_clf 0.825, Loss_fe 0.779, Loss_kd 1.502, Train_accy 74.56, Test_accy 75.58
2024-08-07 14:43:56,913 [foster.py] => Task 3, Epoch 105/170 => Loss 3.606, Loss_clf 0.832, Loss_fe 0.776, Loss_kd 1.496, Train_accy 74.03, Test_accy 74.25
2024-08-07 14:44:04,671 [foster.py] => Task 3, Epoch 106/170 => Loss 3.567, Loss_clf 0.808, Loss_fe 0.755, Loss_kd 1.500, Train_accy 74.83
2024-08-07 14:44:14,164 [foster.py] => Task 3, Epoch 107/170 => Loss 3.556, Loss_clf 0.809, Loss_fe 0.745, Loss_kd 1.499, Train_accy 75.00, Test_accy 75.20
2024-08-07 14:44:23,517 [foster.py] => Task 3, Epoch 108/170 => Loss 3.600, Loss_clf 0.832, Loss_fe 0.757, Loss_kd 1.506, Train_accy 74.27, Test_accy 73.00
2024-08-07 14:44:32,839 [foster.py] => Task 3, Epoch 109/170 => Loss 3.540, Loss_clf 0.808, Loss_fe 0.732, Loss_kd 1.498, Train_accy 74.73, Test_accy 75.82
2024-08-07 14:44:42,134 [foster.py] => Task 3, Epoch 110/170 => Loss 3.512, Loss_clf 0.786, Loss_fe 0.720, Loss_kd 1.502, Train_accy 75.53, Test_accy 76.28
2024-08-07 14:44:49,658 [foster.py] => Task 3, Epoch 111/170 => Loss 3.533, Loss_clf 0.802, Loss_fe 0.729, Loss_kd 1.500, Train_accy 75.00
2024-08-07 14:44:58,962 [foster.py] => Task 3, Epoch 112/170 => Loss 3.469, Loss_clf 0.769, Loss_fe 0.705, Loss_kd 1.494, Train_accy 75.95, Test_accy 74.78
2024-08-07 14:45:08,316 [foster.py] => Task 3, Epoch 113/170 => Loss 3.463, Loss_clf 0.767, Loss_fe 0.699, Loss_kd 1.495, Train_accy 76.36, Test_accy 76.08
2024-08-07 14:45:17,726 [foster.py] => Task 3, Epoch 114/170 => Loss 3.501, Loss_clf 0.788, Loss_fe 0.702, Loss_kd 1.506, Train_accy 75.04, Test_accy 75.72
2024-08-07 14:45:26,962 [foster.py] => Task 3, Epoch 115/170 => Loss 3.447, Loss_clf 0.762, Loss_fe 0.686, Loss_kd 1.497, Train_accy 76.42, Test_accy 75.15
2024-08-07 14:45:34,451 [foster.py] => Task 3, Epoch 116/170 => Loss 3.444, Loss_clf 0.755, Loss_fe 0.686, Loss_kd 1.500, Train_accy 76.62
2024-08-07 14:45:43,742 [foster.py] => Task 3, Epoch 117/170 => Loss 3.464, Loss_clf 0.768, Loss_fe 0.686, Loss_kd 1.505, Train_accy 75.76, Test_accy 77.00
2024-08-07 14:45:53,033 [foster.py] => Task 3, Epoch 118/170 => Loss 3.364, Loss_clf 0.724, Loss_fe 0.645, Loss_kd 1.494, Train_accy 77.55, Test_accy 76.92
2024-08-07 14:46:02,315 [foster.py] => Task 3, Epoch 119/170 => Loss 3.425, Loss_clf 0.744, Loss_fe 0.670, Loss_kd 1.506, Train_accy 77.11, Test_accy 76.75
2024-08-07 14:46:11,563 [foster.py] => Task 3, Epoch 120/170 => Loss 3.410, Loss_clf 0.747, Loss_fe 0.660, Loss_kd 1.500, Train_accy 76.63, Test_accy 75.30
2024-08-07 14:46:19,097 [foster.py] => Task 3, Epoch 121/170 => Loss 3.350, Loss_clf 0.720, Loss_fe 0.642, Loss_kd 1.489, Train_accy 77.89
2024-08-07 14:46:28,336 [foster.py] => Task 3, Epoch 122/170 => Loss 3.334, Loss_clf 0.707, Loss_fe 0.623, Loss_kd 1.501, Train_accy 77.92, Test_accy 76.32
2024-08-07 14:46:37,640 [foster.py] => Task 3, Epoch 123/170 => Loss 3.409, Loss_clf 0.741, Loss_fe 0.663, Loss_kd 1.502, Train_accy 77.25, Test_accy 76.95
2024-08-07 14:46:46,886 [foster.py] => Task 3, Epoch 124/170 => Loss 3.353, Loss_clf 0.722, Loss_fe 0.630, Loss_kd 1.498, Train_accy 76.85, Test_accy 77.12
2024-08-07 14:46:56,194 [foster.py] => Task 3, Epoch 125/170 => Loss 3.298, Loss_clf 0.694, Loss_fe 0.604, Loss_kd 1.498, Train_accy 78.57, Test_accy 77.22
2024-08-07 14:47:03,916 [foster.py] => Task 3, Epoch 126/170 => Loss 3.267, Loss_clf 0.680, Loss_fe 0.592, Loss_kd 1.493, Train_accy 78.93
2024-08-07 14:47:13,377 [foster.py] => Task 3, Epoch 127/170 => Loss 3.267, Loss_clf 0.680, Loss_fe 0.594, Loss_kd 1.493, Train_accy 79.05, Test_accy 76.10
2024-08-07 14:47:22,922 [foster.py] => Task 3, Epoch 128/170 => Loss 3.293, Loss_clf 0.698, Loss_fe 0.598, Loss_kd 1.497, Train_accy 78.48, Test_accy 75.68
2024-08-07 14:47:32,307 [foster.py] => Task 3, Epoch 129/170 => Loss 3.243, Loss_clf 0.674, Loss_fe 0.575, Loss_kd 1.493, Train_accy 79.11, Test_accy 77.12
2024-08-07 14:47:41,607 [foster.py] => Task 3, Epoch 130/170 => Loss 3.191, Loss_clf 0.642, Loss_fe 0.555, Loss_kd 1.493, Train_accy 80.32, Test_accy 77.80
2024-08-07 14:47:49,108 [foster.py] => Task 3, Epoch 131/170 => Loss 3.179, Loss_clf 0.635, Loss_fe 0.550, Loss_kd 1.494, Train_accy 80.33
2024-08-07 14:47:58,413 [foster.py] => Task 3, Epoch 132/170 => Loss 3.249, Loss_clf 0.675, Loss_fe 0.581, Loss_kd 1.492, Train_accy 79.51, Test_accy 77.03
2024-08-07 14:48:08,016 [foster.py] => Task 3, Epoch 133/170 => Loss 3.165, Loss_clf 0.625, Loss_fe 0.542, Loss_kd 1.497, Train_accy 81.02, Test_accy 77.72
2024-08-07 14:48:17,352 [foster.py] => Task 3, Epoch 134/170 => Loss 3.214, Loss_clf 0.657, Loss_fe 0.546, Loss_kd 1.506, Train_accy 80.23, Test_accy 77.97
2024-08-07 14:48:26,793 [foster.py] => Task 3, Epoch 135/170 => Loss 3.170, Loss_clf 0.638, Loss_fe 0.527, Loss_kd 1.502, Train_accy 80.21, Test_accy 77.65
2024-08-07 14:48:34,410 [foster.py] => Task 3, Epoch 136/170 => Loss 3.211, Loss_clf 0.662, Loss_fe 0.542, Loss_kd 1.503, Train_accy 79.57
2024-08-07 14:48:43,767 [foster.py] => Task 3, Epoch 137/170 => Loss 3.185, Loss_clf 0.648, Loss_fe 0.543, Loss_kd 1.494, Train_accy 80.34, Test_accy 77.10
2024-08-07 14:48:52,995 [foster.py] => Task 3, Epoch 138/170 => Loss 3.193, Loss_clf 0.649, Loss_fe 0.536, Loss_kd 1.504, Train_accy 80.16, Test_accy 77.95
2024-08-07 14:49:02,419 [foster.py] => Task 3, Epoch 139/170 => Loss 3.110, Loss_clf 0.608, Loss_fe 0.505, Loss_kd 1.496, Train_accy 81.07, Test_accy 77.75
2024-08-07 14:49:11,874 [foster.py] => Task 3, Epoch 140/170 => Loss 3.112, Loss_clf 0.614, Loss_fe 0.504, Loss_kd 1.493, Train_accy 81.99, Test_accy 77.50
2024-08-07 14:49:19,508 [foster.py] => Task 3, Epoch 141/170 => Loss 3.073, Loss_clf 0.593, Loss_fe 0.480, Loss_kd 1.498, Train_accy 82.09
2024-08-07 14:49:29,013 [foster.py] => Task 3, Epoch 142/170 => Loss 3.043, Loss_clf 0.576, Loss_fe 0.475, Loss_kd 1.492, Train_accy 83.02, Test_accy 77.62
2024-08-07 14:49:38,354 [foster.py] => Task 3, Epoch 143/170 => Loss 3.042, Loss_clf 0.571, Loss_fe 0.477, Loss_kd 1.494, Train_accy 82.36, Test_accy 78.00
2024-08-07 14:49:47,718 [foster.py] => Task 3, Epoch 144/170 => Loss 3.042, Loss_clf 0.579, Loss_fe 0.469, Loss_kd 1.494, Train_accy 82.11, Test_accy 77.60
2024-08-07 14:49:57,035 [foster.py] => Task 3, Epoch 145/170 => Loss 3.032, Loss_clf 0.575, Loss_fe 0.458, Loss_kd 1.497, Train_accy 82.21, Test_accy 77.92
2024-08-07 14:50:04,564 [foster.py] => Task 3, Epoch 146/170 => Loss 3.022, Loss_clf 0.573, Loss_fe 0.460, Loss_kd 1.490, Train_accy 82.91
2024-08-07 14:50:13,790 [foster.py] => Task 3, Epoch 147/170 => Loss 3.015, Loss_clf 0.565, Loss_fe 0.449, Loss_kd 1.499, Train_accy 83.15, Test_accy 77.78
2024-08-07 14:50:23,015 [foster.py] => Task 3, Epoch 148/170 => Loss 2.986, Loss_clf 0.554, Loss_fe 0.436, Loss_kd 1.495, Train_accy 82.78, Test_accy 78.15
2024-08-07 14:50:32,221 [foster.py] => Task 3, Epoch 149/170 => Loss 3.000, Loss_clf 0.562, Loss_fe 0.444, Loss_kd 1.494, Train_accy 83.68, Test_accy 78.12
2024-08-07 14:50:41,510 [foster.py] => Task 3, Epoch 150/170 => Loss 2.964, Loss_clf 0.542, Loss_fe 0.427, Loss_kd 1.494, Train_accy 83.54, Test_accy 78.03
2024-08-07 14:50:49,102 [foster.py] => Task 3, Epoch 151/170 => Loss 3.010, Loss_clf 0.560, Loss_fe 0.441, Loss_kd 1.505, Train_accy 82.52
2024-08-07 14:50:58,372 [foster.py] => Task 3, Epoch 152/170 => Loss 2.994, Loss_clf 0.557, Loss_fe 0.431, Loss_kd 1.502, Train_accy 83.09, Test_accy 78.45
2024-08-07 14:51:07,886 [foster.py] => Task 3, Epoch 153/170 => Loss 2.959, Loss_clf 0.536, Loss_fe 0.421, Loss_kd 1.499, Train_accy 83.65, Test_accy 78.12
2024-08-07 14:51:17,284 [foster.py] => Task 3, Epoch 154/170 => Loss 2.950, Loss_clf 0.538, Loss_fe 0.410, Loss_kd 1.500, Train_accy 83.77, Test_accy 78.40
2024-08-07 14:51:26,582 [foster.py] => Task 3, Epoch 155/170 => Loss 2.926, Loss_clf 0.524, Loss_fe 0.409, Loss_kd 1.493, Train_accy 83.93, Test_accy 78.40
2024-08-07 14:51:34,108 [foster.py] => Task 3, Epoch 156/170 => Loss 2.956, Loss_clf 0.541, Loss_fe 0.413, Loss_kd 1.499, Train_accy 84.15
2024-08-07 14:51:43,319 [foster.py] => Task 3, Epoch 157/170 => Loss 2.910, Loss_clf 0.518, Loss_fe 0.397, Loss_kd 1.494, Train_accy 84.38, Test_accy 78.05
2024-08-07 14:51:52,683 [foster.py] => Task 3, Epoch 158/170 => Loss 2.961, Loss_clf 0.542, Loss_fe 0.408, Loss_kd 1.506, Train_accy 83.45, Test_accy 78.40
2024-08-07 14:52:01,992 [foster.py] => Task 3, Epoch 159/170 => Loss 2.907, Loss_clf 0.512, Loss_fe 0.391, Loss_kd 1.501, Train_accy 84.79, Test_accy 78.58
2024-08-07 14:52:11,342 [foster.py] => Task 3, Epoch 160/170 => Loss 2.873, Loss_clf 0.499, Loss_fe 0.385, Loss_kd 1.490, Train_accy 85.20, Test_accy 78.38
2024-08-07 14:52:19,020 [foster.py] => Task 3, Epoch 161/170 => Loss 2.867, Loss_clf 0.502, Loss_fe 0.382, Loss_kd 1.485, Train_accy 84.93
2024-08-07 14:52:28,342 [foster.py] => Task 3, Epoch 162/170 => Loss 2.923, Loss_clf 0.532, Loss_fe 0.386, Loss_kd 1.502, Train_accy 84.15, Test_accy 78.40
2024-08-07 14:52:37,736 [foster.py] => Task 3, Epoch 163/170 => Loss 2.923, Loss_clf 0.531, Loss_fe 0.391, Loss_kd 1.499, Train_accy 84.31, Test_accy 78.55
2024-08-07 14:52:47,106 [foster.py] => Task 3, Epoch 164/170 => Loss 2.928, Loss_clf 0.526, Loss_fe 0.397, Loss_kd 1.502, Train_accy 84.23, Test_accy 78.30
2024-08-07 14:52:56,366 [foster.py] => Task 3, Epoch 165/170 => Loss 2.918, Loss_clf 0.519, Loss_fe 0.394, Loss_kd 1.501, Train_accy 84.48, Test_accy 78.40
2024-08-07 14:53:03,890 [foster.py] => Task 3, Epoch 166/170 => Loss 2.915, Loss_clf 0.524, Loss_fe 0.393, Loss_kd 1.496, Train_accy 84.31
2024-08-07 14:53:13,189 [foster.py] => Task 3, Epoch 167/170 => Loss 2.909, Loss_clf 0.518, Loss_fe 0.396, Loss_kd 1.494, Train_accy 84.18, Test_accy 78.38
2024-08-07 14:53:22,603 [foster.py] => Task 3, Epoch 168/170 => Loss 2.925, Loss_clf 0.530, Loss_fe 0.400, Loss_kd 1.494, Train_accy 84.64, Test_accy 78.62
2024-08-07 14:53:31,957 [foster.py] => Task 3, Epoch 169/170 => Loss 2.923, Loss_clf 0.525, Loss_fe 0.392, Loss_kd 1.502, Train_accy 84.34, Test_accy 78.53
2024-08-07 14:53:41,277 [foster.py] => Task 3, Epoch 170/170 => Loss 2.882, Loss_clf 0.504, Loss_fe 0.382, Loss_kd 1.495, Train_accy 84.86, Test_accy 78.60
2024-08-07 14:53:41,278 [foster.py] => do not weight align teacher!
2024-08-07 14:53:41,279 [foster.py] => per cls weights : [1.04643217 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217
 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217
 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217
 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217
 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217 1.04643217
 0.86070348 0.86070348 0.86070348 0.86070348 0.86070348 0.86070348
 0.86070348 0.86070348 0.86070348 0.86070348]
2024-08-07 14:53:53,580 [foster.py] => SNet: Task 3, Epoch 1/130 => Loss 25.270,  Loss1 0.632, Train_accy 38.78, Test_accy 66.18
2024-08-07 14:54:04,142 [foster.py] => SNet: Task 3, Epoch 2/130 => Loss 25.022,  Loss1 0.632, Train_accy 58.52
2024-08-07 14:54:14,739 [foster.py] => SNet: Task 3, Epoch 3/130 => Loss 24.984,  Loss1 0.632, Train_accy 61.96
2024-08-07 14:54:25,396 [foster.py] => SNet: Task 3, Epoch 4/130 => Loss 24.967,  Loss1 0.632, Train_accy 63.91
2024-08-07 14:54:36,467 [foster.py] => SNet: Task 3, Epoch 5/130 => Loss 24.944,  Loss1 0.632, Train_accy 66.00
2024-08-07 14:54:48,396 [foster.py] => SNet: Task 3, Epoch 6/130 => Loss 24.948,  Loss1 0.631, Train_accy 66.52, Test_accy 68.88
2024-08-07 14:54:59,506 [foster.py] => SNet: Task 3, Epoch 7/130 => Loss 24.917,  Loss1 0.632, Train_accy 67.44
2024-08-07 14:55:09,824 [foster.py] => SNet: Task 3, Epoch 8/130 => Loss 24.942,  Loss1 0.632, Train_accy 68.02
2024-08-07 14:55:20,135 [foster.py] => SNet: Task 3, Epoch 9/130 => Loss 24.945,  Loss1 0.632, Train_accy 68.22
2024-08-07 14:55:30,476 [foster.py] => SNet: Task 3, Epoch 10/130 => Loss 24.938,  Loss1 0.632, Train_accy 69.04
2024-08-07 14:55:42,424 [foster.py] => SNet: Task 3, Epoch 11/130 => Loss 24.914,  Loss1 0.632, Train_accy 69.56, Test_accy 71.08
2024-08-07 14:55:52,953 [foster.py] => SNet: Task 3, Epoch 12/130 => Loss 24.924,  Loss1 0.631, Train_accy 70.13
2024-08-07 14:56:03,331 [foster.py] => SNet: Task 3, Epoch 13/130 => Loss 24.901,  Loss1 0.631, Train_accy 69.94
2024-08-07 14:56:13,832 [foster.py] => SNet: Task 3, Epoch 14/130 => Loss 24.902,  Loss1 0.631, Train_accy 70.79
2024-08-07 14:56:24,463 [foster.py] => SNet: Task 3, Epoch 15/130 => Loss 24.905,  Loss1 0.632, Train_accy 71.07
2024-08-07 14:56:36,311 [foster.py] => SNet: Task 3, Epoch 16/130 => Loss 24.896,  Loss1 0.631, Train_accy 71.13, Test_accy 71.95
2024-08-07 14:56:46,974 [foster.py] => SNet: Task 3, Epoch 17/130 => Loss 24.899,  Loss1 0.632, Train_accy 71.40
2024-08-07 14:56:57,409 [foster.py] => SNet: Task 3, Epoch 18/130 => Loss 24.903,  Loss1 0.632, Train_accy 71.45
2024-08-07 14:57:07,969 [foster.py] => SNet: Task 3, Epoch 19/130 => Loss 24.904,  Loss1 0.632, Train_accy 71.76
2024-08-07 14:57:18,329 [foster.py] => SNet: Task 3, Epoch 20/130 => Loss 24.899,  Loss1 0.631, Train_accy 71.53
2024-08-07 14:57:30,188 [foster.py] => SNet: Task 3, Epoch 21/130 => Loss 24.903,  Loss1 0.632, Train_accy 71.85, Test_accy 73.45
2024-08-07 14:57:40,577 [foster.py] => SNet: Task 3, Epoch 22/130 => Loss 24.894,  Loss1 0.632, Train_accy 71.68
2024-08-07 14:57:51,051 [foster.py] => SNet: Task 3, Epoch 23/130 => Loss 24.891,  Loss1 0.632, Train_accy 71.88
2024-08-07 14:58:01,456 [foster.py] => SNet: Task 3, Epoch 24/130 => Loss 24.884,  Loss1 0.631, Train_accy 72.31
2024-08-07 14:58:12,262 [foster.py] => SNet: Task 3, Epoch 25/130 => Loss 24.879,  Loss1 0.632, Train_accy 73.44
2024-08-07 14:58:24,331 [foster.py] => SNet: Task 3, Epoch 26/130 => Loss 24.866,  Loss1 0.632, Train_accy 73.61, Test_accy 73.03
2024-08-07 14:58:35,175 [foster.py] => SNet: Task 3, Epoch 27/130 => Loss 24.896,  Loss1 0.632, Train_accy 73.07
2024-08-07 14:58:45,581 [foster.py] => SNet: Task 3, Epoch 28/130 => Loss 24.875,  Loss1 0.632, Train_accy 73.34
2024-08-07 14:58:55,959 [foster.py] => SNet: Task 3, Epoch 29/130 => Loss 24.858,  Loss1 0.632, Train_accy 74.04
2024-08-07 14:59:06,725 [foster.py] => SNet: Task 3, Epoch 30/130 => Loss 24.860,  Loss1 0.632, Train_accy 75.23
2024-08-07 14:59:18,961 [foster.py] => SNet: Task 3, Epoch 31/130 => Loss 24.866,  Loss1 0.632, Train_accy 74.54, Test_accy 73.88
2024-08-07 14:59:29,528 [foster.py] => SNet: Task 3, Epoch 32/130 => Loss 24.884,  Loss1 0.632, Train_accy 74.38
2024-08-07 14:59:40,300 [foster.py] => SNet: Task 3, Epoch 33/130 => Loss 24.858,  Loss1 0.632, Train_accy 74.54
2024-08-07 14:59:50,712 [foster.py] => SNet: Task 3, Epoch 34/130 => Loss 24.889,  Loss1 0.632, Train_accy 73.91
2024-08-07 15:00:01,127 [foster.py] => SNet: Task 3, Epoch 35/130 => Loss 24.870,  Loss1 0.632, Train_accy 74.58
2024-08-07 15:00:12,995 [foster.py] => SNet: Task 3, Epoch 36/130 => Loss 24.867,  Loss1 0.632, Train_accy 74.33, Test_accy 74.30
2024-08-07 15:00:23,349 [foster.py] => SNet: Task 3, Epoch 37/130 => Loss 24.888,  Loss1 0.631, Train_accy 75.00
2024-08-07 15:00:33,686 [foster.py] => SNet: Task 3, Epoch 38/130 => Loss 24.863,  Loss1 0.632, Train_accy 74.77
2024-08-07 15:00:44,078 [foster.py] => SNet: Task 3, Epoch 39/130 => Loss 24.879,  Loss1 0.632, Train_accy 74.89
2024-08-07 15:00:54,536 [foster.py] => SNet: Task 3, Epoch 40/130 => Loss 24.851,  Loss1 0.632, Train_accy 75.73
2024-08-07 15:01:07,045 [foster.py] => SNet: Task 3, Epoch 41/130 => Loss 24.873,  Loss1 0.632, Train_accy 75.11, Test_accy 74.78
2024-08-07 15:01:17,510 [foster.py] => SNet: Task 3, Epoch 42/130 => Loss 24.862,  Loss1 0.632, Train_accy 75.46
2024-08-07 15:01:27,861 [foster.py] => SNet: Task 3, Epoch 43/130 => Loss 24.862,  Loss1 0.631, Train_accy 75.70
2024-08-07 15:01:38,325 [foster.py] => SNet: Task 3, Epoch 44/130 => Loss 24.847,  Loss1 0.632, Train_accy 75.54
2024-08-07 15:01:48,739 [foster.py] => SNet: Task 3, Epoch 45/130 => Loss 24.865,  Loss1 0.631, Train_accy 75.34
2024-08-07 15:02:00,650 [foster.py] => SNet: Task 3, Epoch 46/130 => Loss 24.868,  Loss1 0.632, Train_accy 75.79, Test_accy 75.12
2024-08-07 15:02:11,077 [foster.py] => SNet: Task 3, Epoch 47/130 => Loss 24.843,  Loss1 0.632, Train_accy 76.03
2024-08-07 15:02:21,601 [foster.py] => SNet: Task 3, Epoch 48/130 => Loss 24.857,  Loss1 0.632, Train_accy 76.42
2024-08-07 15:02:31,985 [foster.py] => SNet: Task 3, Epoch 49/130 => Loss 24.854,  Loss1 0.632, Train_accy 75.83
2024-08-07 15:02:42,664 [foster.py] => SNet: Task 3, Epoch 50/130 => Loss 24.854,  Loss1 0.632, Train_accy 76.42
2024-08-07 15:02:54,576 [foster.py] => SNet: Task 3, Epoch 51/130 => Loss 24.853,  Loss1 0.632, Train_accy 76.46, Test_accy 75.18
2024-08-07 15:03:05,134 [foster.py] => SNet: Task 3, Epoch 52/130 => Loss 24.854,  Loss1 0.632, Train_accy 76.81
2024-08-07 15:03:15,892 [foster.py] => SNet: Task 3, Epoch 53/130 => Loss 24.861,  Loss1 0.632, Train_accy 75.80
2024-08-07 15:03:26,356 [foster.py] => SNet: Task 3, Epoch 54/130 => Loss 24.857,  Loss1 0.632, Train_accy 76.39
2024-08-07 15:03:36,766 [foster.py] => SNet: Task 3, Epoch 55/130 => Loss 24.855,  Loss1 0.632, Train_accy 77.15
2024-08-07 15:03:48,711 [foster.py] => SNet: Task 3, Epoch 56/130 => Loss 24.857,  Loss1 0.632, Train_accy 77.56, Test_accy 75.20
2024-08-07 15:03:59,196 [foster.py] => SNet: Task 3, Epoch 57/130 => Loss 24.832,  Loss1 0.632, Train_accy 77.54
2024-08-07 15:04:10,008 [foster.py] => SNet: Task 3, Epoch 58/130 => Loss 24.869,  Loss1 0.632, Train_accy 76.52
2024-08-07 15:04:20,300 [foster.py] => SNet: Task 3, Epoch 59/130 => Loss 24.830,  Loss1 0.632, Train_accy 77.99
2024-08-07 15:04:30,782 [foster.py] => SNet: Task 3, Epoch 60/130 => Loss 24.828,  Loss1 0.632, Train_accy 76.52
2024-08-07 15:04:42,712 [foster.py] => SNet: Task 3, Epoch 61/130 => Loss 24.853,  Loss1 0.632, Train_accy 77.34, Test_accy 75.58
2024-08-07 15:04:53,523 [foster.py] => SNet: Task 3, Epoch 62/130 => Loss 24.857,  Loss1 0.632, Train_accy 77.81
2024-08-07 15:05:04,230 [foster.py] => SNet: Task 3, Epoch 63/130 => Loss 24.830,  Loss1 0.632, Train_accy 77.85
2024-08-07 15:05:14,953 [foster.py] => SNet: Task 3, Epoch 64/130 => Loss 24.835,  Loss1 0.632, Train_accy 78.08
2024-08-07 15:05:25,350 [foster.py] => SNet: Task 3, Epoch 65/130 => Loss 24.841,  Loss1 0.632, Train_accy 78.15
2024-08-07 15:05:37,222 [foster.py] => SNet: Task 3, Epoch 66/130 => Loss 24.855,  Loss1 0.632, Train_accy 77.05, Test_accy 75.88
2024-08-07 15:05:47,582 [foster.py] => SNet: Task 3, Epoch 67/130 => Loss 24.833,  Loss1 0.632, Train_accy 77.59
2024-08-07 15:05:58,215 [foster.py] => SNet: Task 3, Epoch 68/130 => Loss 24.842,  Loss1 0.632, Train_accy 77.44
2024-08-07 15:06:08,599 [foster.py] => SNet: Task 3, Epoch 69/130 => Loss 24.862,  Loss1 0.632, Train_accy 77.38
2024-08-07 15:06:19,212 [foster.py] => SNet: Task 3, Epoch 70/130 => Loss 24.838,  Loss1 0.632, Train_accy 77.56
2024-08-07 15:06:31,168 [foster.py] => SNet: Task 3, Epoch 71/130 => Loss 24.826,  Loss1 0.632, Train_accy 78.77, Test_accy 76.42
2024-08-07 15:06:41,609 [foster.py] => SNet: Task 3, Epoch 72/130 => Loss 24.851,  Loss1 0.632, Train_accy 78.54
2024-08-07 15:06:51,940 [foster.py] => SNet: Task 3, Epoch 73/130 => Loss 24.838,  Loss1 0.632, Train_accy 78.31
2024-08-07 15:07:02,742 [foster.py] => SNet: Task 3, Epoch 74/130 => Loss 24.843,  Loss1 0.632, Train_accy 77.71
2024-08-07 15:07:13,291 [foster.py] => SNet: Task 3, Epoch 75/130 => Loss 24.861,  Loss1 0.632, Train_accy 77.77
2024-08-07 15:07:25,169 [foster.py] => SNet: Task 3, Epoch 76/130 => Loss 24.836,  Loss1 0.632, Train_accy 77.69, Test_accy 76.03
2024-08-07 15:07:35,913 [foster.py] => SNet: Task 3, Epoch 77/130 => Loss 24.839,  Loss1 0.632, Train_accy 77.88
2024-08-07 15:07:46,617 [foster.py] => SNet: Task 3, Epoch 78/130 => Loss 24.831,  Loss1 0.632, Train_accy 78.72
2024-08-07 15:07:57,265 [foster.py] => SNet: Task 3, Epoch 79/130 => Loss 24.850,  Loss1 0.632, Train_accy 77.77
2024-08-07 15:08:07,622 [foster.py] => SNet: Task 3, Epoch 80/130 => Loss 24.831,  Loss1 0.632, Train_accy 77.85
2024-08-07 15:08:19,850 [foster.py] => SNet: Task 3, Epoch 81/130 => Loss 24.848,  Loss1 0.632, Train_accy 78.37, Test_accy 76.18
2024-08-07 15:08:30,569 [foster.py] => SNet: Task 3, Epoch 82/130 => Loss 24.850,  Loss1 0.632, Train_accy 78.81
2024-08-07 15:08:40,997 [foster.py] => SNet: Task 3, Epoch 83/130 => Loss 24.832,  Loss1 0.632, Train_accy 78.01
2024-08-07 15:08:51,558 [foster.py] => SNet: Task 3, Epoch 84/130 => Loss 24.818,  Loss1 0.632, Train_accy 79.37
2024-08-07 15:09:02,018 [foster.py] => SNet: Task 3, Epoch 85/130 => Loss 24.837,  Loss1 0.632, Train_accy 78.04
2024-08-07 15:09:14,114 [foster.py] => SNet: Task 3, Epoch 86/130 => Loss 24.824,  Loss1 0.632, Train_accy 79.03, Test_accy 76.10
2024-08-07 15:09:24,591 [foster.py] => SNet: Task 3, Epoch 87/130 => Loss 24.843,  Loss1 0.632, Train_accy 78.60
2024-08-07 15:09:34,980 [foster.py] => SNet: Task 3, Epoch 88/130 => Loss 24.842,  Loss1 0.632, Train_accy 79.33
2024-08-07 15:09:45,709 [foster.py] => SNet: Task 3, Epoch 89/130 => Loss 24.833,  Loss1 0.632, Train_accy 78.22
2024-08-07 15:09:56,115 [foster.py] => SNet: Task 3, Epoch 90/130 => Loss 24.825,  Loss1 0.632, Train_accy 79.18
2024-08-07 15:10:08,385 [foster.py] => SNet: Task 3, Epoch 91/130 => Loss 24.833,  Loss1 0.632, Train_accy 78.78, Test_accy 76.75
2024-08-07 15:10:19,003 [foster.py] => SNet: Task 3, Epoch 92/130 => Loss 24.843,  Loss1 0.632, Train_accy 79.46
2024-08-07 15:10:29,507 [foster.py] => SNet: Task 3, Epoch 93/130 => Loss 24.827,  Loss1 0.632, Train_accy 79.18
2024-08-07 15:10:39,911 [foster.py] => SNet: Task 3, Epoch 94/130 => Loss 24.833,  Loss1 0.632, Train_accy 79.07
2024-08-07 15:10:50,354 [foster.py] => SNet: Task 3, Epoch 95/130 => Loss 24.827,  Loss1 0.632, Train_accy 77.95
2024-08-07 15:11:02,266 [foster.py] => SNet: Task 3, Epoch 96/130 => Loss 24.823,  Loss1 0.632, Train_accy 78.90, Test_accy 77.15
2024-08-07 15:11:12,695 [foster.py] => SNet: Task 3, Epoch 97/130 => Loss 24.837,  Loss1 0.632, Train_accy 78.71
2024-08-07 15:11:23,379 [foster.py] => SNet: Task 3, Epoch 98/130 => Loss 24.823,  Loss1 0.632, Train_accy 79.30
2024-08-07 15:11:33,735 [foster.py] => SNet: Task 3, Epoch 99/130 => Loss 24.832,  Loss1 0.632, Train_accy 79.27
2024-08-07 15:11:44,092 [foster.py] => SNet: Task 3, Epoch 100/130 => Loss 24.833,  Loss1 0.631, Train_accy 78.28
2024-08-07 15:11:56,333 [foster.py] => SNet: Task 3, Epoch 101/130 => Loss 24.863,  Loss1 0.632, Train_accy 78.47, Test_accy 76.62
2024-08-07 15:12:06,727 [foster.py] => SNet: Task 3, Epoch 102/130 => Loss 24.821,  Loss1 0.632, Train_accy 78.50
2024-08-07 15:12:17,165 [foster.py] => SNet: Task 3, Epoch 103/130 => Loss 24.831,  Loss1 0.632, Train_accy 79.87
2024-08-07 15:12:27,674 [foster.py] => SNet: Task 3, Epoch 104/130 => Loss 24.829,  Loss1 0.632, Train_accy 78.54
2024-08-07 15:12:38,368 [foster.py] => SNet: Task 3, Epoch 105/130 => Loss 24.825,  Loss1 0.631, Train_accy 79.18
2024-08-07 15:12:50,249 [foster.py] => SNet: Task 3, Epoch 106/130 => Loss 24.831,  Loss1 0.632, Train_accy 78.98, Test_accy 76.58
2024-08-07 15:13:00,653 [foster.py] => SNet: Task 3, Epoch 107/130 => Loss 24.829,  Loss1 0.632, Train_accy 79.24
2024-08-07 15:13:11,075 [foster.py] => SNet: Task 3, Epoch 108/130 => Loss 24.830,  Loss1 0.632, Train_accy 79.70
2024-08-07 15:13:21,644 [foster.py] => SNet: Task 3, Epoch 109/130 => Loss 24.816,  Loss1 0.632, Train_accy 79.64
2024-08-07 15:13:32,035 [foster.py] => SNet: Task 3, Epoch 110/130 => Loss 24.828,  Loss1 0.632, Train_accy 78.32
2024-08-07 15:13:43,865 [foster.py] => SNet: Task 3, Epoch 111/130 => Loss 24.826,  Loss1 0.632, Train_accy 79.47, Test_accy 76.45
2024-08-07 15:13:54,610 [foster.py] => SNet: Task 3, Epoch 112/130 => Loss 24.804,  Loss1 0.632, Train_accy 78.98
2024-08-07 15:14:05,049 [foster.py] => SNet: Task 3, Epoch 113/130 => Loss 24.804,  Loss1 0.632, Train_accy 79.64
2024-08-07 15:14:15,432 [foster.py] => SNet: Task 3, Epoch 114/130 => Loss 24.806,  Loss1 0.632, Train_accy 79.43
2024-08-07 15:14:25,962 [foster.py] => SNet: Task 3, Epoch 115/130 => Loss 24.800,  Loss1 0.631, Train_accy 80.07
2024-08-07 15:14:38,126 [foster.py] => SNet: Task 3, Epoch 116/130 => Loss 24.809,  Loss1 0.632, Train_accy 79.67, Test_accy 76.80
2024-08-07 15:14:48,730 [foster.py] => SNet: Task 3, Epoch 117/130 => Loss 24.840,  Loss1 0.632, Train_accy 79.44
2024-08-07 15:14:59,469 [foster.py] => SNet: Task 3, Epoch 118/130 => Loss 24.822,  Loss1 0.632, Train_accy 79.68
2024-08-07 15:15:09,831 [foster.py] => SNet: Task 3, Epoch 119/130 => Loss 24.818,  Loss1 0.632, Train_accy 79.57
2024-08-07 15:15:20,226 [foster.py] => SNet: Task 3, Epoch 120/130 => Loss 24.816,  Loss1 0.632, Train_accy 78.85
2024-08-07 15:15:32,131 [foster.py] => SNet: Task 3, Epoch 121/130 => Loss 24.838,  Loss1 0.632, Train_accy 79.04, Test_accy 77.15
2024-08-07 15:15:42,576 [foster.py] => SNet: Task 3, Epoch 122/130 => Loss 24.826,  Loss1 0.632, Train_accy 79.07
2024-08-07 15:15:52,953 [foster.py] => SNet: Task 3, Epoch 123/130 => Loss 24.814,  Loss1 0.632, Train_accy 78.97
2024-08-07 15:16:03,366 [foster.py] => SNet: Task 3, Epoch 124/130 => Loss 24.837,  Loss1 0.632, Train_accy 79.08
2024-08-07 15:16:13,780 [foster.py] => SNet: Task 3, Epoch 125/130 => Loss 24.841,  Loss1 0.632, Train_accy 79.00
2024-08-07 15:16:25,650 [foster.py] => SNet: Task 3, Epoch 126/130 => Loss 24.823,  Loss1 0.632, Train_accy 79.36, Test_accy 76.88
2024-08-07 15:16:36,324 [foster.py] => SNet: Task 3, Epoch 127/130 => Loss 24.811,  Loss1 0.632, Train_accy 79.73
2024-08-07 15:16:46,978 [foster.py] => SNet: Task 3, Epoch 128/130 => Loss 24.826,  Loss1 0.632, Train_accy 80.60
2024-08-07 15:16:57,762 [foster.py] => SNet: Task 3, Epoch 129/130 => Loss 24.822,  Loss1 0.632, Train_accy 79.47
2024-08-07 15:17:08,120 [foster.py] => SNet: Task 3, Epoch 130/130 => Loss 24.813,  Loss1 0.631, Train_accy 79.70
2024-08-07 15:17:08,121 [foster.py] => do not weight align student!
2024-08-07 15:17:09,604 [foster.py] => darknet eval: 
2024-08-07 15:17:09,605 [foster.py] => CNN top1 curve: 76.97
2024-08-07 15:17:09,605 [foster.py] => CNN top5 curve: 95.48
2024-08-07 15:17:09,605 [foster.py] => CNN top1 平均值: 76.97
2024-08-07 15:17:09,612 [foster.py] => timees : 2933.1487143039703
2024-08-07 15:17:09,612 [base.py] => Reducing exemplars...(50 per classes)
2024-08-07 15:17:20,028 [base.py] => Constructing exemplars...(50 per classes)
2024-08-07 15:17:33,900 [foster.py] => Exemplar size: 2000
2024-08-07 15:17:33,900 [trainer.py] => CNN: {'total': 78.6, '00-09': 78.2, '10-19': 71.6, '20-29': 82.3, '30-39': 82.3, 'old': 77.37, 'new': 82.3}
2024-08-07 15:17:33,900 [trainer.py] => NME: {'total': 75.8, '00-09': 75.5, '10-19': 69.5, '20-29': 76.1, '30-39': 82.1, 'old': 73.7, 'new': 82.1}
2024-08-07 15:17:33,900 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6]
2024-08-07 15:17:33,900 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58]
2024-08-07 15:17:33,900 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8]
2024-08-07 15:17:33,900 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55]

2024-08-07 15:17:33,900 [trainer.py] => CNN top1 平均值: 85.28
2024-08-07 15:17:33,903 [trainer.py] => All params: 1292258
2024-08-07 15:17:33,905 [trainer.py] => Trainable params: 649034
2024-08-07 15:17:33,968 [foster.py] => Learning on 40-50
2024-08-07 15:17:33,971 [foster.py] => All params: 1294848
2024-08-07 15:17:33,973 [foster.py] => Trainable params: 650974
2024-08-07 15:17:34,035 [foster.py] => per cls weights : [1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 0.7947782  0.7947782
 0.7947782  0.7947782  0.7947782  0.7947782  0.7947782  0.7947782
 0.7947782  0.7947782 ]
2024-08-07 15:17:41,591 [foster.py] => Task 4, Epoch 1/170 => Loss 5.905, Loss_clf 1.956, Loss_fe 1.688, Loss_kd 1.806, Train_accy 52.93
2024-08-07 15:17:51,161 [foster.py] => Task 4, Epoch 2/170 => Loss 4.693, Loss_clf 1.192, Loss_fe 1.280, Loss_kd 1.773, Train_accy 61.06, Test_accy 70.32
2024-08-07 15:18:00,778 [foster.py] => Task 4, Epoch 3/170 => Loss 4.474, Loss_clf 1.090, Loss_fe 1.168, Loss_kd 1.770, Train_accy 63.96, Test_accy 69.48
2024-08-07 15:18:10,297 [foster.py] => Task 4, Epoch 4/170 => Loss 4.474, Loss_clf 1.121, Loss_fe 1.137, Loss_kd 1.771, Train_accy 63.31, Test_accy 69.34
2024-08-07 15:18:19,790 [foster.py] => Task 4, Epoch 5/170 => Loss 4.518, Loss_clf 1.152, Loss_fe 1.148, Loss_kd 1.772, Train_accy 63.07, Test_accy 70.42
2024-08-07 15:18:27,320 [foster.py] => Task 4, Epoch 6/170 => Loss 4.447, Loss_clf 1.115, Loss_fe 1.113, Loss_kd 1.772, Train_accy 64.73
2024-08-07 15:18:36,731 [foster.py] => Task 4, Epoch 7/170 => Loss 4.449, Loss_clf 1.118, Loss_fe 1.112, Loss_kd 1.772, Train_accy 64.10, Test_accy 70.54
2024-08-07 15:18:46,291 [foster.py] => Task 4, Epoch 8/170 => Loss 4.333, Loss_clf 1.041, Loss_fe 1.070, Loss_kd 1.775, Train_accy 65.63, Test_accy 68.72
2024-08-07 15:18:55,771 [foster.py] => Task 4, Epoch 9/170 => Loss 4.318, Loss_clf 1.052, Loss_fe 1.052, Loss_kd 1.768, Train_accy 65.74, Test_accy 69.16
2024-08-07 15:19:05,235 [foster.py] => Task 4, Epoch 10/170 => Loss 4.384, Loss_clf 1.087, Loss_fe 1.075, Loss_kd 1.774, Train_accy 65.43, Test_accy 70.88
2024-08-07 15:19:12,857 [foster.py] => Task 4, Epoch 11/170 => Loss 4.290, Loss_clf 1.023, Loss_fe 1.050, Loss_kd 1.770, Train_accy 66.16
2024-08-07 15:19:22,558 [foster.py] => Task 4, Epoch 12/170 => Loss 4.365, Loss_clf 1.086, Loss_fe 1.065, Loss_kd 1.769, Train_accy 65.47, Test_accy 70.46
2024-08-07 15:19:32,188 [foster.py] => Task 4, Epoch 13/170 => Loss 4.291, Loss_clf 1.025, Loss_fe 1.056, Loss_kd 1.765, Train_accy 66.07, Test_accy 69.62
2024-08-07 15:19:41,673 [foster.py] => Task 4, Epoch 14/170 => Loss 4.288, Loss_clf 1.009, Loss_fe 1.048, Loss_kd 1.782, Train_accy 66.94, Test_accy 70.68
2024-08-07 15:19:51,143 [foster.py] => Task 4, Epoch 15/170 => Loss 4.300, Loss_clf 1.043, Loss_fe 1.035, Loss_kd 1.775, Train_accy 66.19, Test_accy 71.32
2024-08-07 15:19:58,721 [foster.py] => Task 4, Epoch 16/170 => Loss 4.300, Loss_clf 1.037, Loss_fe 1.035, Loss_kd 1.780, Train_accy 66.53
2024-08-07 15:20:08,224 [foster.py] => Task 4, Epoch 17/170 => Loss 4.336, Loss_clf 1.055, Loss_fe 1.055, Loss_kd 1.778, Train_accy 66.06, Test_accy 71.22
2024-08-07 15:20:17,757 [foster.py] => Task 4, Epoch 18/170 => Loss 4.268, Loss_clf 1.024, Loss_fe 1.026, Loss_kd 1.771, Train_accy 67.09, Test_accy 71.16
2024-08-07 15:20:27,261 [foster.py] => Task 4, Epoch 19/170 => Loss 4.266, Loss_clf 0.992, Loss_fe 1.050, Loss_kd 1.777, Train_accy 66.56, Test_accy 68.04
2024-08-07 15:20:36,762 [foster.py] => Task 4, Epoch 20/170 => Loss 4.281, Loss_clf 1.036, Loss_fe 1.032, Loss_kd 1.768, Train_accy 66.49, Test_accy 70.56
2024-08-07 15:20:44,247 [foster.py] => Task 4, Epoch 21/170 => Loss 4.275, Loss_clf 1.027, Loss_fe 1.019, Loss_kd 1.780, Train_accy 66.86
2024-08-07 15:20:53,762 [foster.py] => Task 4, Epoch 22/170 => Loss 4.243, Loss_clf 1.011, Loss_fe 1.019, Loss_kd 1.768, Train_accy 66.13, Test_accy 71.48
2024-08-07 15:21:03,277 [foster.py] => Task 4, Epoch 23/170 => Loss 4.213, Loss_clf 0.977, Loss_fe 1.012, Loss_kd 1.777, Train_accy 66.80, Test_accy 71.40
2024-08-07 15:21:12,771 [foster.py] => Task 4, Epoch 24/170 => Loss 4.234, Loss_clf 0.998, Loss_fe 1.013, Loss_kd 1.776, Train_accy 66.66, Test_accy 70.58
2024-08-07 15:21:22,412 [foster.py] => Task 4, Epoch 25/170 => Loss 4.205, Loss_clf 0.999, Loss_fe 0.991, Loss_kd 1.770, Train_accy 66.80, Test_accy 70.32
2024-08-07 15:21:30,044 [foster.py] => Task 4, Epoch 26/170 => Loss 4.171, Loss_clf 0.954, Loss_fe 0.999, Loss_kd 1.771, Train_accy 68.21
2024-08-07 15:21:39,546 [foster.py] => Task 4, Epoch 27/170 => Loss 4.270, Loss_clf 1.017, Loss_fe 1.030, Loss_kd 1.775, Train_accy 67.60, Test_accy 70.74
2024-08-07 15:21:49,111 [foster.py] => Task 4, Epoch 28/170 => Loss 4.195, Loss_clf 0.988, Loss_fe 0.994, Loss_kd 1.768, Train_accy 67.66, Test_accy 70.52
2024-08-07 15:21:58,644 [foster.py] => Task 4, Epoch 29/170 => Loss 4.224, Loss_clf 1.028, Loss_fe 0.981, Loss_kd 1.769, Train_accy 66.46, Test_accy 70.34
2024-08-07 15:22:08,139 [foster.py] => Task 4, Epoch 30/170 => Loss 4.235, Loss_clf 0.998, Loss_fe 1.021, Loss_kd 1.771, Train_accy 67.24, Test_accy 69.44
2024-08-07 15:22:15,699 [foster.py] => Task 4, Epoch 31/170 => Loss 4.209, Loss_clf 0.992, Loss_fe 1.004, Loss_kd 1.768, Train_accy 67.34
2024-08-07 15:22:25,358 [foster.py] => Task 4, Epoch 32/170 => Loss 4.198, Loss_clf 0.985, Loss_fe 0.995, Loss_kd 1.772, Train_accy 67.83, Test_accy 72.56
2024-08-07 15:22:34,930 [foster.py] => Task 4, Epoch 33/170 => Loss 4.155, Loss_clf 0.964, Loss_fe 0.970, Loss_kd 1.774, Train_accy 67.54, Test_accy 72.10
2024-08-07 15:22:44,564 [foster.py] => Task 4, Epoch 34/170 => Loss 4.138, Loss_clf 0.970, Loss_fe 0.947, Loss_kd 1.774, Train_accy 67.56, Test_accy 72.64
2024-08-07 15:22:54,120 [foster.py] => Task 4, Epoch 35/170 => Loss 4.116, Loss_clf 0.943, Loss_fe 0.964, Loss_kd 1.764, Train_accy 68.63, Test_accy 71.40
2024-08-07 15:23:01,673 [foster.py] => Task 4, Epoch 36/170 => Loss 4.144, Loss_clf 0.956, Loss_fe 0.971, Loss_kd 1.771, Train_accy 68.16
2024-08-07 15:23:11,215 [foster.py] => Task 4, Epoch 37/170 => Loss 4.164, Loss_clf 0.998, Loss_fe 0.944, Loss_kd 1.775, Train_accy 67.61, Test_accy 68.68
2024-08-07 15:23:20,639 [foster.py] => Task 4, Epoch 38/170 => Loss 4.178, Loss_clf 0.996, Loss_fe 0.963, Loss_kd 1.772, Train_accy 68.30, Test_accy 70.48
2024-08-07 15:23:30,201 [foster.py] => Task 4, Epoch 39/170 => Loss 4.143, Loss_clf 0.958, Loss_fe 0.966, Loss_kd 1.772, Train_accy 68.41, Test_accy 71.38
2024-08-07 15:23:39,760 [foster.py] => Task 4, Epoch 40/170 => Loss 4.112, Loss_clf 0.957, Loss_fe 0.943, Loss_kd 1.767, Train_accy 67.17, Test_accy 68.98
2024-08-07 15:23:47,295 [foster.py] => Task 4, Epoch 41/170 => Loss 4.122, Loss_clf 0.953, Loss_fe 0.951, Loss_kd 1.771, Train_accy 68.73
2024-08-07 15:23:56,845 [foster.py] => Task 4, Epoch 42/170 => Loss 4.160, Loss_clf 0.998, Loss_fe 0.950, Loss_kd 1.767, Train_accy 68.06, Test_accy 71.64
2024-08-07 15:24:06,404 [foster.py] => Task 4, Epoch 43/170 => Loss 4.114, Loss_clf 0.947, Loss_fe 0.960, Loss_kd 1.764, Train_accy 68.83, Test_accy 72.34
2024-08-07 15:24:15,892 [foster.py] => Task 4, Epoch 44/170 => Loss 4.174, Loss_clf 0.983, Loss_fe 0.975, Loss_kd 1.770, Train_accy 67.67, Test_accy 70.14
2024-08-07 15:24:25,392 [foster.py] => Task 4, Epoch 45/170 => Loss 4.078, Loss_clf 0.938, Loss_fe 0.926, Loss_kd 1.768, Train_accy 69.07, Test_accy 71.38
2024-08-07 15:24:32,903 [foster.py] => Task 4, Epoch 46/170 => Loss 4.004, Loss_clf 0.899, Loss_fe 0.902, Loss_kd 1.760, Train_accy 70.04
2024-08-07 15:24:42,404 [foster.py] => Task 4, Epoch 47/170 => Loss 4.072, Loss_clf 0.933, Loss_fe 0.921, Loss_kd 1.772, Train_accy 68.61, Test_accy 70.70
2024-08-07 15:24:52,073 [foster.py] => Task 4, Epoch 48/170 => Loss 4.077, Loss_clf 0.937, Loss_fe 0.917, Loss_kd 1.776, Train_accy 68.84, Test_accy 72.04
2024-08-07 15:25:01,607 [foster.py] => Task 4, Epoch 49/170 => Loss 4.084, Loss_clf 0.946, Loss_fe 0.925, Loss_kd 1.768, Train_accy 68.39, Test_accy 72.28
2024-08-07 15:25:11,121 [foster.py] => Task 4, Epoch 50/170 => Loss 4.104, Loss_clf 0.959, Loss_fe 0.937, Loss_kd 1.764, Train_accy 68.70, Test_accy 71.08
2024-08-07 15:25:18,875 [foster.py] => Task 4, Epoch 51/170 => Loss 4.037, Loss_clf 0.914, Loss_fe 0.910, Loss_kd 1.768, Train_accy 69.51
2024-08-07 15:25:28,511 [foster.py] => Task 4, Epoch 52/170 => Loss 4.040, Loss_clf 0.928, Loss_fe 0.894, Loss_kd 1.772, Train_accy 68.73, Test_accy 70.96
2024-08-07 15:25:38,039 [foster.py] => Task 4, Epoch 53/170 => Loss 4.119, Loss_clf 0.976, Loss_fe 0.924, Loss_kd 1.773, Train_accy 68.04, Test_accy 70.38
2024-08-07 15:25:47,524 [foster.py] => Task 4, Epoch 54/170 => Loss 4.082, Loss_clf 0.951, Loss_fe 0.908, Loss_kd 1.775, Train_accy 69.31, Test_accy 72.12
2024-08-07 15:25:57,120 [foster.py] => Task 4, Epoch 55/170 => Loss 4.031, Loss_clf 0.925, Loss_fe 0.892, Loss_kd 1.769, Train_accy 69.86, Test_accy 70.08
2024-08-07 15:26:04,760 [foster.py] => Task 4, Epoch 56/170 => Loss 4.017, Loss_clf 0.909, Loss_fe 0.891, Loss_kd 1.770, Train_accy 70.24
2024-08-07 15:26:14,238 [foster.py] => Task 4, Epoch 57/170 => Loss 4.121, Loss_clf 0.964, Loss_fe 0.929, Loss_kd 1.780, Train_accy 68.54, Test_accy 71.56
2024-08-07 15:26:23,903 [foster.py] => Task 4, Epoch 58/170 => Loss 4.034, Loss_clf 0.925, Loss_fe 0.891, Loss_kd 1.772, Train_accy 69.14, Test_accy 72.10
2024-08-07 15:26:33,399 [foster.py] => Task 4, Epoch 59/170 => Loss 3.957, Loss_clf 0.872, Loss_fe 0.870, Loss_kd 1.770, Train_accy 70.34, Test_accy 71.34
2024-08-07 15:26:42,916 [foster.py] => Task 4, Epoch 60/170 => Loss 4.062, Loss_clf 0.946, Loss_fe 0.900, Loss_kd 1.770, Train_accy 68.37, Test_accy 71.64
2024-08-07 15:26:50,541 [foster.py] => Task 4, Epoch 61/170 => Loss 4.057, Loss_clf 0.947, Loss_fe 0.890, Loss_kd 1.774, Train_accy 69.30
2024-08-07 15:27:00,036 [foster.py] => Task 4, Epoch 62/170 => Loss 3.992, Loss_clf 0.901, Loss_fe 0.880, Loss_kd 1.767, Train_accy 69.97, Test_accy 71.40
2024-08-07 15:27:09,560 [foster.py] => Task 4, Epoch 63/170 => Loss 4.028, Loss_clf 0.919, Loss_fe 0.895, Loss_kd 1.769, Train_accy 69.06, Test_accy 71.74
2024-08-07 15:27:19,077 [foster.py] => Task 4, Epoch 64/170 => Loss 3.990, Loss_clf 0.907, Loss_fe 0.870, Loss_kd 1.768, Train_accy 69.66, Test_accy 72.42
2024-08-07 15:27:28,604 [foster.py] => Task 4, Epoch 65/170 => Loss 3.984, Loss_clf 0.904, Loss_fe 0.862, Loss_kd 1.771, Train_accy 69.07, Test_accy 72.38
2024-08-07 15:27:36,217 [foster.py] => Task 4, Epoch 66/170 => Loss 3.962, Loss_clf 0.893, Loss_fe 0.862, Loss_kd 1.763, Train_accy 70.34
2024-08-07 15:27:45,774 [foster.py] => Task 4, Epoch 67/170 => Loss 3.984, Loss_clf 0.909, Loss_fe 0.871, Loss_kd 1.761, Train_accy 69.29, Test_accy 71.52
2024-08-07 15:27:55,297 [foster.py] => Task 4, Epoch 68/170 => Loss 3.950, Loss_clf 0.875, Loss_fe 0.859, Loss_kd 1.770, Train_accy 70.90, Test_accy 71.52
2024-08-07 15:28:04,836 [foster.py] => Task 4, Epoch 69/170 => Loss 3.966, Loss_clf 0.893, Loss_fe 0.856, Loss_kd 1.771, Train_accy 70.01, Test_accy 71.88
2024-08-07 15:28:14,449 [foster.py] => Task 4, Epoch 70/170 => Loss 3.891, Loss_clf 0.854, Loss_fe 0.828, Loss_kd 1.765, Train_accy 71.36, Test_accy 72.18
2024-08-07 15:28:22,191 [foster.py] => Task 4, Epoch 71/170 => Loss 3.911, Loss_clf 0.854, Loss_fe 0.840, Loss_kd 1.771, Train_accy 71.40
2024-08-07 15:28:31,953 [foster.py] => Task 4, Epoch 72/170 => Loss 3.968, Loss_clf 0.897, Loss_fe 0.855, Loss_kd 1.771, Train_accy 70.59, Test_accy 72.42
2024-08-07 15:28:41,767 [foster.py] => Task 4, Epoch 73/170 => Loss 3.891, Loss_clf 0.866, Loss_fe 0.819, Loss_kd 1.762, Train_accy 71.43, Test_accy 72.44
2024-08-07 15:28:51,541 [foster.py] => Task 4, Epoch 74/170 => Loss 3.916, Loss_clf 0.867, Loss_fe 0.830, Loss_kd 1.773, Train_accy 71.27, Test_accy 71.02
2024-08-07 15:29:01,290 [foster.py] => Task 4, Epoch 75/170 => Loss 3.925, Loss_clf 0.882, Loss_fe 0.830, Loss_kd 1.768, Train_accy 70.57, Test_accy 72.42
2024-08-07 15:29:08,999 [foster.py] => Task 4, Epoch 76/170 => Loss 3.923, Loss_clf 0.879, Loss_fe 0.831, Loss_kd 1.768, Train_accy 70.74
2024-08-07 15:29:18,634 [foster.py] => Task 4, Epoch 77/170 => Loss 3.846, Loss_clf 0.850, Loss_fe 0.794, Loss_kd 1.759, Train_accy 71.60, Test_accy 71.62
2024-08-07 15:29:28,278 [foster.py] => Task 4, Epoch 78/170 => Loss 3.859, Loss_clf 0.842, Loss_fe 0.799, Loss_kd 1.772, Train_accy 71.20, Test_accy 72.54
2024-08-07 15:29:38,081 [foster.py] => Task 4, Epoch 79/170 => Loss 3.861, Loss_clf 0.845, Loss_fe 0.799, Loss_kd 1.771, Train_accy 72.20, Test_accy 72.40
2024-08-07 15:29:47,597 [foster.py] => Task 4, Epoch 80/170 => Loss 3.863, Loss_clf 0.854, Loss_fe 0.791, Loss_kd 1.772, Train_accy 70.83, Test_accy 72.74
2024-08-07 15:29:55,110 [foster.py] => Task 4, Epoch 81/170 => Loss 3.849, Loss_clf 0.860, Loss_fe 0.776, Loss_kd 1.768, Train_accy 71.69
2024-08-07 15:30:04,638 [foster.py] => Task 4, Epoch 82/170 => Loss 3.841, Loss_clf 0.836, Loss_fe 0.797, Loss_kd 1.764, Train_accy 71.86, Test_accy 72.32
2024-08-07 15:30:14,123 [foster.py] => Task 4, Epoch 83/170 => Loss 3.834, Loss_clf 0.833, Loss_fe 0.784, Loss_kd 1.771, Train_accy 71.60, Test_accy 73.44
2024-08-07 15:30:23,596 [foster.py] => Task 4, Epoch 84/170 => Loss 3.755, Loss_clf 0.787, Loss_fe 0.760, Loss_kd 1.764, Train_accy 73.11, Test_accy 70.92
2024-08-07 15:30:33,014 [foster.py] => Task 4, Epoch 85/170 => Loss 3.832, Loss_clf 0.848, Loss_fe 0.772, Loss_kd 1.768, Train_accy 72.30, Test_accy 72.80
2024-08-07 15:30:40,651 [foster.py] => Task 4, Epoch 86/170 => Loss 3.852, Loss_clf 0.854, Loss_fe 0.778, Loss_kd 1.774, Train_accy 71.16
2024-08-07 15:30:50,082 [foster.py] => Task 4, Epoch 87/170 => Loss 3.786, Loss_clf 0.815, Loss_fe 0.767, Loss_kd 1.761, Train_accy 72.60, Test_accy 72.66
2024-08-07 15:30:59,720 [foster.py] => Task 4, Epoch 88/170 => Loss 3.767, Loss_clf 0.810, Loss_fe 0.749, Loss_kd 1.763, Train_accy 72.07, Test_accy 73.22
2024-08-07 15:31:09,255 [foster.py] => Task 4, Epoch 89/170 => Loss 3.786, Loss_clf 0.816, Loss_fe 0.770, Loss_kd 1.758, Train_accy 72.87, Test_accy 72.56
2024-08-07 15:31:18,698 [foster.py] => Task 4, Epoch 90/170 => Loss 3.813, Loss_clf 0.847, Loss_fe 0.755, Loss_kd 1.766, Train_accy 71.70, Test_accy 73.46
2024-08-07 15:31:26,265 [foster.py] => Task 4, Epoch 91/170 => Loss 3.705, Loss_clf 0.793, Loss_fe 0.720, Loss_kd 1.751, Train_accy 73.66
2024-08-07 15:31:35,754 [foster.py] => Task 4, Epoch 92/170 => Loss 3.720, Loss_clf 0.780, Loss_fe 0.732, Loss_kd 1.764, Train_accy 73.83, Test_accy 70.36
2024-08-07 15:31:45,286 [foster.py] => Task 4, Epoch 93/170 => Loss 3.738, Loss_clf 0.797, Loss_fe 0.724, Loss_kd 1.771, Train_accy 73.83, Test_accy 73.56
2024-08-07 15:31:54,778 [foster.py] => Task 4, Epoch 94/170 => Loss 3.708, Loss_clf 0.783, Loss_fe 0.718, Loss_kd 1.764, Train_accy 73.50, Test_accy 73.10
2024-08-07 15:32:04,298 [foster.py] => Task 4, Epoch 95/170 => Loss 3.676, Loss_clf 0.754, Loss_fe 0.720, Loss_kd 1.759, Train_accy 73.93, Test_accy 72.90
2024-08-07 15:32:11,922 [foster.py] => Task 4, Epoch 96/170 => Loss 3.714, Loss_clf 0.784, Loss_fe 0.706, Loss_kd 1.777, Train_accy 73.96
2024-08-07 15:32:21,560 [foster.py] => Task 4, Epoch 97/170 => Loss 3.759, Loss_clf 0.799, Loss_fe 0.733, Loss_kd 1.779, Train_accy 73.07, Test_accy 73.62
2024-08-07 15:32:31,275 [foster.py] => Task 4, Epoch 98/170 => Loss 3.691, Loss_clf 0.765, Loss_fe 0.714, Loss_kd 1.767, Train_accy 73.57, Test_accy 71.34
2024-08-07 15:32:40,810 [foster.py] => Task 4, Epoch 99/170 => Loss 3.738, Loss_clf 0.794, Loss_fe 0.728, Loss_kd 1.771, Train_accy 73.97, Test_accy 73.26
2024-08-07 15:32:50,340 [foster.py] => Task 4, Epoch 100/170 => Loss 3.698, Loss_clf 0.776, Loss_fe 0.707, Loss_kd 1.770, Train_accy 74.17, Test_accy 72.70
2024-08-07 15:32:57,870 [foster.py] => Task 4, Epoch 101/170 => Loss 3.679, Loss_clf 0.780, Loss_fe 0.687, Loss_kd 1.767, Train_accy 73.31
2024-08-07 15:33:07,539 [foster.py] => Task 4, Epoch 102/170 => Loss 3.662, Loss_clf 0.758, Loss_fe 0.688, Loss_kd 1.770, Train_accy 75.66, Test_accy 73.36
2024-08-07 15:33:16,998 [foster.py] => Task 4, Epoch 103/170 => Loss 3.683, Loss_clf 0.773, Loss_fe 0.700, Loss_kd 1.765, Train_accy 74.06, Test_accy 73.74
2024-08-07 15:33:26,489 [foster.py] => Task 4, Epoch 104/170 => Loss 3.610, Loss_clf 0.740, Loss_fe 0.665, Loss_kd 1.761, Train_accy 75.03, Test_accy 73.36
2024-08-07 15:33:36,063 [foster.py] => Task 4, Epoch 105/170 => Loss 3.607, Loss_clf 0.736, Loss_fe 0.659, Loss_kd 1.767, Train_accy 75.84, Test_accy 72.74
2024-08-07 15:33:43,598 [foster.py] => Task 4, Epoch 106/170 => Loss 3.650, Loss_clf 0.772, Loss_fe 0.679, Loss_kd 1.757, Train_accy 74.33
2024-08-07 15:33:53,122 [foster.py] => Task 4, Epoch 107/170 => Loss 3.646, Loss_clf 0.756, Loss_fe 0.677, Loss_kd 1.768, Train_accy 75.46, Test_accy 73.76
2024-08-07 15:34:02,555 [foster.py] => Task 4, Epoch 108/170 => Loss 3.650, Loss_clf 0.759, Loss_fe 0.682, Loss_kd 1.764, Train_accy 74.61, Test_accy 73.36
2024-08-07 15:34:12,052 [foster.py] => Task 4, Epoch 109/170 => Loss 3.583, Loss_clf 0.730, Loss_fe 0.654, Loss_kd 1.757, Train_accy 75.20, Test_accy 73.86
2024-08-07 15:34:21,529 [foster.py] => Task 4, Epoch 110/170 => Loss 3.530, Loss_clf 0.702, Loss_fe 0.629, Loss_kd 1.757, Train_accy 75.86, Test_accy 73.80
2024-08-07 15:34:29,045 [foster.py] => Task 4, Epoch 111/170 => Loss 3.523, Loss_clf 0.700, Loss_fe 0.613, Loss_kd 1.766, Train_accy 75.83
2024-08-07 15:34:38,518 [foster.py] => Task 4, Epoch 112/170 => Loss 3.514, Loss_clf 0.694, Loss_fe 0.615, Loss_kd 1.762, Train_accy 76.84, Test_accy 73.58
2024-08-07 15:34:48,062 [foster.py] => Task 4, Epoch 113/170 => Loss 3.527, Loss_clf 0.710, Loss_fe 0.612, Loss_kd 1.762, Train_accy 76.04, Test_accy 73.92
2024-08-07 15:34:57,663 [foster.py] => Task 4, Epoch 114/170 => Loss 3.564, Loss_clf 0.710, Loss_fe 0.633, Loss_kd 1.774, Train_accy 76.44, Test_accy 74.34
2024-08-07 15:35:07,178 [foster.py] => Task 4, Epoch 115/170 => Loss 3.519, Loss_clf 0.699, Loss_fe 0.614, Loss_kd 1.762, Train_accy 76.34, Test_accy 74.82
2024-08-07 15:35:14,707 [foster.py] => Task 4, Epoch 116/170 => Loss 3.502, Loss_clf 0.692, Loss_fe 0.599, Loss_kd 1.766, Train_accy 76.41
2024-08-07 15:35:24,250 [foster.py] => Task 4, Epoch 117/170 => Loss 3.487, Loss_clf 0.691, Loss_fe 0.589, Loss_kd 1.763, Train_accy 77.59, Test_accy 74.20
2024-08-07 15:35:33,796 [foster.py] => Task 4, Epoch 118/170 => Loss 3.455, Loss_clf 0.671, Loss_fe 0.580, Loss_kd 1.760, Train_accy 78.11, Test_accy 74.18
2024-08-07 15:35:43,298 [foster.py] => Task 4, Epoch 119/170 => Loss 3.414, Loss_clf 0.656, Loss_fe 0.556, Loss_kd 1.760, Train_accy 77.91, Test_accy 74.26
2024-08-07 15:35:52,781 [foster.py] => Task 4, Epoch 120/170 => Loss 3.451, Loss_clf 0.668, Loss_fe 0.573, Loss_kd 1.766, Train_accy 77.70, Test_accy 74.54
2024-08-07 15:36:00,325 [foster.py] => Task 4, Epoch 121/170 => Loss 3.443, Loss_clf 0.668, Loss_fe 0.564, Loss_kd 1.766, Train_accy 77.30
2024-08-07 15:36:10,053 [foster.py] => Task 4, Epoch 122/170 => Loss 3.416, Loss_clf 0.660, Loss_fe 0.554, Loss_kd 1.759, Train_accy 77.70, Test_accy 74.28
2024-08-07 15:36:19,760 [foster.py] => Task 4, Epoch 123/170 => Loss 3.424, Loss_clf 0.663, Loss_fe 0.558, Loss_kd 1.760, Train_accy 78.04, Test_accy 73.16
2024-08-07 15:36:29,352 [foster.py] => Task 4, Epoch 124/170 => Loss 3.404, Loss_clf 0.656, Loss_fe 0.550, Loss_kd 1.756, Train_accy 77.69, Test_accy 73.68
2024-08-07 15:36:38,900 [foster.py] => Task 4, Epoch 125/170 => Loss 3.425, Loss_clf 0.667, Loss_fe 0.546, Loss_kd 1.767, Train_accy 78.27, Test_accy 73.72
2024-08-07 15:36:46,427 [foster.py] => Task 4, Epoch 126/170 => Loss 3.351, Loss_clf 0.623, Loss_fe 0.520, Loss_kd 1.763, Train_accy 79.24
2024-08-07 15:36:55,990 [foster.py] => Task 4, Epoch 127/170 => Loss 3.339, Loss_clf 0.623, Loss_fe 0.511, Loss_kd 1.761, Train_accy 79.03, Test_accy 74.20
2024-08-07 15:37:05,501 [foster.py] => Task 4, Epoch 128/170 => Loss 3.379, Loss_clf 0.647, Loss_fe 0.526, Loss_kd 1.763, Train_accy 78.84, Test_accy 73.82
2024-08-07 15:37:15,440 [foster.py] => Task 4, Epoch 129/170 => Loss 3.393, Loss_clf 0.645, Loss_fe 0.529, Loss_kd 1.773, Train_accy 78.74, Test_accy 74.12
2024-08-07 15:37:25,023 [foster.py] => Task 4, Epoch 130/170 => Loss 3.331, Loss_clf 0.625, Loss_fe 0.497, Loss_kd 1.765, Train_accy 78.99, Test_accy 75.18
2024-08-07 15:37:32,555 [foster.py] => Task 4, Epoch 131/170 => Loss 3.322, Loss_clf 0.616, Loss_fe 0.500, Loss_kd 1.763, Train_accy 79.39
2024-08-07 15:37:42,089 [foster.py] => Task 4, Epoch 132/170 => Loss 3.310, Loss_clf 0.611, Loss_fe 0.488, Loss_kd 1.766, Train_accy 79.99, Test_accy 75.24
2024-08-07 15:37:51,655 [foster.py] => Task 4, Epoch 133/170 => Loss 3.291, Loss_clf 0.603, Loss_fe 0.483, Loss_kd 1.762, Train_accy 80.27, Test_accy 74.90
2024-08-07 15:38:01,128 [foster.py] => Task 4, Epoch 134/170 => Loss 3.305, Loss_clf 0.614, Loss_fe 0.481, Loss_kd 1.766, Train_accy 79.93, Test_accy 74.94
2024-08-07 15:38:10,746 [foster.py] => Task 4, Epoch 135/170 => Loss 3.299, Loss_clf 0.603, Loss_fe 0.479, Loss_kd 1.772, Train_accy 80.11, Test_accy 75.24
2024-08-07 15:38:18,274 [foster.py] => Task 4, Epoch 136/170 => Loss 3.280, Loss_clf 0.594, Loss_fe 0.472, Loss_kd 1.769, Train_accy 80.01
2024-08-07 15:38:27,781 [foster.py] => Task 4, Epoch 137/170 => Loss 3.236, Loss_clf 0.577, Loss_fe 0.458, Loss_kd 1.759, Train_accy 80.00, Test_accy 75.16
2024-08-07 15:38:37,280 [foster.py] => Task 4, Epoch 138/170 => Loss 3.225, Loss_clf 0.572, Loss_fe 0.443, Loss_kd 1.767, Train_accy 81.41, Test_accy 74.96
2024-08-07 15:38:46,938 [foster.py] => Task 4, Epoch 139/170 => Loss 3.190, Loss_clf 0.556, Loss_fe 0.436, Loss_kd 1.756, Train_accy 81.24, Test_accy 75.10
2024-08-07 15:38:56,566 [foster.py] => Task 4, Epoch 140/170 => Loss 3.167, Loss_clf 0.546, Loss_fe 0.419, Loss_kd 1.760, Train_accy 81.97, Test_accy 74.74
2024-08-07 15:39:04,143 [foster.py] => Task 4, Epoch 141/170 => Loss 3.169, Loss_clf 0.548, Loss_fe 0.421, Loss_kd 1.758, Train_accy 81.51
2024-08-07 15:39:13,625 [foster.py] => Task 4, Epoch 142/170 => Loss 3.112, Loss_clf 0.523, Loss_fe 0.393, Loss_kd 1.754, Train_accy 83.01, Test_accy 75.50
2024-08-07 15:39:23,144 [foster.py] => Task 4, Epoch 143/170 => Loss 3.177, Loss_clf 0.556, Loss_fe 0.416, Loss_kd 1.761, Train_accy 81.81, Test_accy 74.82
2024-08-07 15:39:32,629 [foster.py] => Task 4, Epoch 144/170 => Loss 3.164, Loss_clf 0.545, Loss_fe 0.415, Loss_kd 1.761, Train_accy 81.77, Test_accy 75.54
2024-08-07 15:39:42,225 [foster.py] => Task 4, Epoch 145/170 => Loss 3.144, Loss_clf 0.534, Loss_fe 0.400, Loss_kd 1.766, Train_accy 82.34, Test_accy 75.72
2024-08-07 15:39:50,020 [foster.py] => Task 4, Epoch 146/170 => Loss 3.155, Loss_clf 0.544, Loss_fe 0.403, Loss_kd 1.764, Train_accy 82.40
2024-08-07 15:39:59,719 [foster.py] => Task 4, Epoch 147/170 => Loss 3.083, Loss_clf 0.508, Loss_fe 0.376, Loss_kd 1.757, Train_accy 83.53, Test_accy 75.62
2024-08-07 15:40:09,379 [foster.py] => Task 4, Epoch 148/170 => Loss 3.114, Loss_clf 0.518, Loss_fe 0.396, Loss_kd 1.757, Train_accy 82.57, Test_accy 75.38
2024-08-07 15:40:18,900 [foster.py] => Task 4, Epoch 149/170 => Loss 3.114, Loss_clf 0.527, Loss_fe 0.384, Loss_kd 1.760, Train_accy 83.00, Test_accy 75.24
2024-08-07 15:40:28,390 [foster.py] => Task 4, Epoch 150/170 => Loss 3.070, Loss_clf 0.504, Loss_fe 0.379, Loss_kd 1.748, Train_accy 82.83, Test_accy 75.84
2024-08-07 15:40:35,945 [foster.py] => Task 4, Epoch 151/170 => Loss 3.105, Loss_clf 0.519, Loss_fe 0.372, Loss_kd 1.769, Train_accy 82.93
2024-08-07 15:40:45,506 [foster.py] => Task 4, Epoch 152/170 => Loss 3.080, Loss_clf 0.507, Loss_fe 0.361, Loss_kd 1.767, Train_accy 83.84, Test_accy 75.66
2024-08-07 15:40:55,019 [foster.py] => Task 4, Epoch 153/170 => Loss 3.103, Loss_clf 0.524, Loss_fe 0.373, Loss_kd 1.763, Train_accy 83.30, Test_accy 75.54
2024-08-07 15:41:04,634 [foster.py] => Task 4, Epoch 154/170 => Loss 3.045, Loss_clf 0.488, Loss_fe 0.356, Loss_kd 1.758, Train_accy 83.41, Test_accy 75.68
2024-08-07 15:41:14,157 [foster.py] => Task 4, Epoch 155/170 => Loss 3.081, Loss_clf 0.508, Loss_fe 0.366, Loss_kd 1.763, Train_accy 83.74, Test_accy 75.80
2024-08-07 15:41:21,682 [foster.py] => Task 4, Epoch 156/170 => Loss 3.041, Loss_clf 0.497, Loss_fe 0.344, Loss_kd 1.757, Train_accy 83.94
2024-08-07 15:41:31,203 [foster.py] => Task 4, Epoch 157/170 => Loss 3.027, Loss_clf 0.492, Loss_fe 0.338, Loss_kd 1.756, Train_accy 84.20, Test_accy 75.84
2024-08-07 15:41:40,790 [foster.py] => Task 4, Epoch 158/170 => Loss 3.045, Loss_clf 0.501, Loss_fe 0.346, Loss_kd 1.756, Train_accy 83.64, Test_accy 75.52
2024-08-07 15:41:50,325 [foster.py] => Task 4, Epoch 159/170 => Loss 3.085, Loss_clf 0.508, Loss_fe 0.372, Loss_kd 1.761, Train_accy 83.60, Test_accy 75.52
2024-08-07 15:41:59,745 [foster.py] => Task 4, Epoch 160/170 => Loss 3.069, Loss_clf 0.512, Loss_fe 0.346, Loss_kd 1.766, Train_accy 84.04, Test_accy 75.38
2024-08-07 15:42:07,295 [foster.py] => Task 4, Epoch 161/170 => Loss 3.061, Loss_clf 0.505, Loss_fe 0.340, Loss_kd 1.771, Train_accy 84.20
2024-08-07 15:42:16,867 [foster.py] => Task 4, Epoch 162/170 => Loss 3.044, Loss_clf 0.495, Loss_fe 0.348, Loss_kd 1.759, Train_accy 83.94, Test_accy 75.60
2024-08-07 15:42:26,455 [foster.py] => Task 4, Epoch 163/170 => Loss 3.014, Loss_clf 0.480, Loss_fe 0.335, Loss_kd 1.757, Train_accy 84.83, Test_accy 75.46
2024-08-07 15:42:36,124 [foster.py] => Task 4, Epoch 164/170 => Loss 3.042, Loss_clf 0.493, Loss_fe 0.343, Loss_kd 1.763, Train_accy 84.14, Test_accy 75.56
2024-08-07 15:42:45,753 [foster.py] => Task 4, Epoch 165/170 => Loss 3.025, Loss_clf 0.487, Loss_fe 0.336, Loss_kd 1.759, Train_accy 84.13, Test_accy 75.56
2024-08-07 15:42:53,340 [foster.py] => Task 4, Epoch 166/170 => Loss 3.014, Loss_clf 0.482, Loss_fe 0.331, Loss_kd 1.759, Train_accy 84.39
2024-08-07 15:43:02,859 [foster.py] => Task 4, Epoch 167/170 => Loss 3.020, Loss_clf 0.484, Loss_fe 0.324, Loss_kd 1.768, Train_accy 84.43, Test_accy 75.50
2024-08-07 15:43:12,395 [foster.py] => Task 4, Epoch 168/170 => Loss 3.031, Loss_clf 0.496, Loss_fe 0.334, Loss_kd 1.759, Train_accy 84.04, Test_accy 75.54
2024-08-07 15:43:21,912 [foster.py] => Task 4, Epoch 169/170 => Loss 3.048, Loss_clf 0.493, Loss_fe 0.338, Loss_kd 1.770, Train_accy 84.23, Test_accy 75.60
2024-08-07 15:43:31,469 [foster.py] => Task 4, Epoch 170/170 => Loss 3.003, Loss_clf 0.479, Loss_fe 0.321, Loss_kd 1.760, Train_accy 84.69, Test_accy 75.54
2024-08-07 15:43:31,472 [foster.py] => do not weight align teacher!
2024-08-07 15:43:31,475 [foster.py] => per cls weights : [1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545 1.05130545
 1.05130545 1.05130545 1.05130545 1.05130545 0.7947782  0.7947782
 0.7947782  0.7947782  0.7947782  0.7947782  0.7947782  0.7947782
 0.7947782  0.7947782 ]
2024-08-07 15:43:43,888 [foster.py] => SNet: Task 4, Epoch 1/130 => Loss 26.769,  Loss1 0.670, Train_accy 43.99, Test_accy 65.98
2024-08-07 15:43:54,259 [foster.py] => SNet: Task 4, Epoch 2/130 => Loss 26.526,  Loss1 0.670, Train_accy 63.94
2024-08-07 15:44:05,199 [foster.py] => SNet: Task 4, Epoch 3/130 => Loss 26.522,  Loss1 0.670, Train_accy 66.99
2024-08-07 15:44:15,615 [foster.py] => SNet: Task 4, Epoch 4/130 => Loss 26.486,  Loss1 0.671, Train_accy 68.60
2024-08-07 15:44:26,025 [foster.py] => SNet: Task 4, Epoch 5/130 => Loss 26.485,  Loss1 0.671, Train_accy 69.16
2024-08-07 15:44:38,174 [foster.py] => SNet: Task 4, Epoch 6/130 => Loss 26.497,  Loss1 0.671, Train_accy 69.47, Test_accy 70.04
2024-08-07 15:44:48,699 [foster.py] => SNet: Task 4, Epoch 7/130 => Loss 26.461,  Loss1 0.671, Train_accy 70.51
2024-08-07 15:44:59,388 [foster.py] => SNet: Task 4, Epoch 8/130 => Loss 26.472,  Loss1 0.671, Train_accy 70.76
2024-08-07 15:45:09,900 [foster.py] => SNet: Task 4, Epoch 9/130 => Loss 26.481,  Loss1 0.671, Train_accy 70.94
2024-08-07 15:45:20,958 [foster.py] => SNet: Task 4, Epoch 10/130 => Loss 26.480,  Loss1 0.671, Train_accy 70.91
2024-08-07 15:45:33,020 [foster.py] => SNet: Task 4, Epoch 11/130 => Loss 26.457,  Loss1 0.671, Train_accy 71.59, Test_accy 71.58
2024-08-07 15:45:43,446 [foster.py] => SNet: Task 4, Epoch 12/130 => Loss 26.484,  Loss1 0.671, Train_accy 72.79
2024-08-07 15:45:54,102 [foster.py] => SNet: Task 4, Epoch 13/130 => Loss 26.457,  Loss1 0.671, Train_accy 72.07
2024-08-07 15:46:04,698 [foster.py] => SNet: Task 4, Epoch 14/130 => Loss 26.461,  Loss1 0.671, Train_accy 73.03
2024-08-07 15:46:15,092 [foster.py] => SNet: Task 4, Epoch 15/130 => Loss 26.453,  Loss1 0.671, Train_accy 73.27
2024-08-07 15:46:27,285 [foster.py] => SNet: Task 4, Epoch 16/130 => Loss 26.462,  Loss1 0.671, Train_accy 73.13, Test_accy 71.76
2024-08-07 15:46:37,638 [foster.py] => SNet: Task 4, Epoch 17/130 => Loss 26.424,  Loss1 0.672, Train_accy 73.40
2024-08-07 15:46:48,037 [foster.py] => SNet: Task 4, Epoch 18/130 => Loss 26.445,  Loss1 0.671, Train_accy 73.67
2024-08-07 15:46:58,906 [foster.py] => SNet: Task 4, Epoch 19/130 => Loss 26.438,  Loss1 0.671, Train_accy 72.80
2024-08-07 15:47:09,385 [foster.py] => SNet: Task 4, Epoch 20/130 => Loss 26.442,  Loss1 0.671, Train_accy 73.94
2024-08-07 15:47:21,480 [foster.py] => SNet: Task 4, Epoch 21/130 => Loss 26.440,  Loss1 0.671, Train_accy 74.04, Test_accy 71.18
2024-08-07 15:47:31,821 [foster.py] => SNet: Task 4, Epoch 22/130 => Loss 26.446,  Loss1 0.671, Train_accy 74.01
2024-08-07 15:47:42,314 [foster.py] => SNet: Task 4, Epoch 23/130 => Loss 26.443,  Loss1 0.671, Train_accy 74.21
2024-08-07 15:47:52,754 [foster.py] => SNet: Task 4, Epoch 24/130 => Loss 26.436,  Loss1 0.672, Train_accy 74.26
2024-08-07 15:48:03,318 [foster.py] => SNet: Task 4, Epoch 25/130 => Loss 26.451,  Loss1 0.671, Train_accy 74.03
2024-08-07 15:48:15,427 [foster.py] => SNet: Task 4, Epoch 26/130 => Loss 26.444,  Loss1 0.671, Train_accy 75.24, Test_accy 72.22
2024-08-07 15:48:26,229 [foster.py] => SNet: Task 4, Epoch 27/130 => Loss 26.421,  Loss1 0.671, Train_accy 74.86
2024-08-07 15:48:36,693 [foster.py] => SNet: Task 4, Epoch 28/130 => Loss 26.467,  Loss1 0.671, Train_accy 74.76
2024-08-07 15:48:47,417 [foster.py] => SNet: Task 4, Epoch 29/130 => Loss 26.440,  Loss1 0.671, Train_accy 74.94
2024-08-07 15:48:57,884 [foster.py] => SNet: Task 4, Epoch 30/130 => Loss 26.456,  Loss1 0.671, Train_accy 74.54
2024-08-07 15:49:10,528 [foster.py] => SNet: Task 4, Epoch 31/130 => Loss 26.428,  Loss1 0.671, Train_accy 75.34, Test_accy 72.64
2024-08-07 15:49:21,326 [foster.py] => SNet: Task 4, Epoch 32/130 => Loss 26.451,  Loss1 0.671, Train_accy 75.69
2024-08-07 15:49:31,903 [foster.py] => SNet: Task 4, Epoch 33/130 => Loss 26.462,  Loss1 0.671, Train_accy 74.83
2024-08-07 15:49:42,581 [foster.py] => SNet: Task 4, Epoch 34/130 => Loss 26.443,  Loss1 0.671, Train_accy 74.91
2024-08-07 15:49:53,129 [foster.py] => SNet: Task 4, Epoch 35/130 => Loss 26.423,  Loss1 0.671, Train_accy 75.19
2024-08-07 15:50:05,286 [foster.py] => SNet: Task 4, Epoch 36/130 => Loss 26.425,  Loss1 0.671, Train_accy 75.83, Test_accy 72.32
2024-08-07 15:50:15,671 [foster.py] => SNet: Task 4, Epoch 37/130 => Loss 26.414,  Loss1 0.671, Train_accy 75.84
2024-08-07 15:50:26,039 [foster.py] => SNet: Task 4, Epoch 38/130 => Loss 26.468,  Loss1 0.671, Train_accy 75.03
2024-08-07 15:50:36,771 [foster.py] => SNet: Task 4, Epoch 39/130 => Loss 26.419,  Loss1 0.671, Train_accy 76.86
2024-08-07 15:50:47,576 [foster.py] => SNet: Task 4, Epoch 40/130 => Loss 26.433,  Loss1 0.671, Train_accy 75.79
2024-08-07 15:50:59,637 [foster.py] => SNet: Task 4, Epoch 41/130 => Loss 26.416,  Loss1 0.671, Train_accy 75.87, Test_accy 72.70
2024-08-07 15:51:10,081 [foster.py] => SNet: Task 4, Epoch 42/130 => Loss 26.440,  Loss1 0.671, Train_accy 75.21
2024-08-07 15:51:20,809 [foster.py] => SNet: Task 4, Epoch 43/130 => Loss 26.431,  Loss1 0.672, Train_accy 76.34
2024-08-07 15:51:31,260 [foster.py] => SNet: Task 4, Epoch 44/130 => Loss 26.412,  Loss1 0.671, Train_accy 76.24
2024-08-07 15:51:41,639 [foster.py] => SNet: Task 4, Epoch 45/130 => Loss 26.426,  Loss1 0.672, Train_accy 76.36
2024-08-07 15:51:53,645 [foster.py] => SNet: Task 4, Epoch 46/130 => Loss 26.412,  Loss1 0.671, Train_accy 76.86, Test_accy 73.92
2024-08-07 15:52:04,078 [foster.py] => SNet: Task 4, Epoch 47/130 => Loss 26.427,  Loss1 0.671, Train_accy 76.87
2024-08-07 15:52:14,406 [foster.py] => SNet: Task 4, Epoch 48/130 => Loss 26.431,  Loss1 0.671, Train_accy 77.03
2024-08-07 15:52:24,961 [foster.py] => SNet: Task 4, Epoch 49/130 => Loss 26.434,  Loss1 0.672, Train_accy 76.59
2024-08-07 15:52:35,478 [foster.py] => SNet: Task 4, Epoch 50/130 => Loss 26.410,  Loss1 0.671, Train_accy 77.69
2024-08-07 15:52:47,542 [foster.py] => SNet: Task 4, Epoch 51/130 => Loss 26.425,  Loss1 0.672, Train_accy 76.79, Test_accy 73.20
2024-08-07 15:52:57,937 [foster.py] => SNet: Task 4, Epoch 52/130 => Loss 26.414,  Loss1 0.671, Train_accy 76.76
2024-08-07 15:53:08,497 [foster.py] => SNet: Task 4, Epoch 53/130 => Loss 26.415,  Loss1 0.671, Train_accy 77.49
2024-08-07 15:53:19,005 [foster.py] => SNet: Task 4, Epoch 54/130 => Loss 26.423,  Loss1 0.672, Train_accy 76.76
2024-08-07 15:53:29,671 [foster.py] => SNet: Task 4, Epoch 55/130 => Loss 26.426,  Loss1 0.671, Train_accy 76.40
2024-08-07 15:53:41,819 [foster.py] => SNet: Task 4, Epoch 56/130 => Loss 26.443,  Loss1 0.671, Train_accy 76.89, Test_accy 73.50
2024-08-07 15:53:52,428 [foster.py] => SNet: Task 4, Epoch 57/130 => Loss 26.448,  Loss1 0.671, Train_accy 77.19
2024-08-07 15:54:02,824 [foster.py] => SNet: Task 4, Epoch 58/130 => Loss 26.432,  Loss1 0.672, Train_accy 78.10
2024-08-07 15:54:13,327 [foster.py] => SNet: Task 4, Epoch 59/130 => Loss 26.421,  Loss1 0.671, Train_accy 76.56
2024-08-07 15:54:24,151 [foster.py] => SNet: Task 4, Epoch 60/130 => Loss 26.412,  Loss1 0.672, Train_accy 77.74
2024-08-07 15:54:36,267 [foster.py] => SNet: Task 4, Epoch 61/130 => Loss 26.429,  Loss1 0.671, Train_accy 77.29, Test_accy 74.04
2024-08-07 15:54:46,624 [foster.py] => SNet: Task 4, Epoch 62/130 => Loss 26.408,  Loss1 0.672, Train_accy 77.49
2024-08-07 15:54:57,087 [foster.py] => SNet: Task 4, Epoch 63/130 => Loss 26.423,  Loss1 0.671, Train_accy 77.60
2024-08-07 15:55:07,583 [foster.py] => SNet: Task 4, Epoch 64/130 => Loss 26.409,  Loss1 0.671, Train_accy 77.03
2024-08-07 15:55:18,057 [foster.py] => SNet: Task 4, Epoch 65/130 => Loss 26.425,  Loss1 0.671, Train_accy 76.31
2024-08-07 15:55:30,522 [foster.py] => SNet: Task 4, Epoch 66/130 => Loss 26.425,  Loss1 0.671, Train_accy 77.47, Test_accy 73.32
2024-08-07 15:55:41,071 [foster.py] => SNet: Task 4, Epoch 67/130 => Loss 26.424,  Loss1 0.671, Train_accy 77.53
2024-08-07 15:55:51,827 [foster.py] => SNet: Task 4, Epoch 68/130 => Loss 26.422,  Loss1 0.672, Train_accy 76.87
2024-08-07 15:56:02,273 [foster.py] => SNet: Task 4, Epoch 69/130 => Loss 26.413,  Loss1 0.672, Train_accy 77.26
2024-08-07 15:56:12,668 [foster.py] => SNet: Task 4, Epoch 70/130 => Loss 26.413,  Loss1 0.671, Train_accy 78.06
2024-08-07 15:56:25,035 [foster.py] => SNet: Task 4, Epoch 71/130 => Loss 26.412,  Loss1 0.671, Train_accy 77.71, Test_accy 73.92
2024-08-07 15:56:35,332 [foster.py] => SNet: Task 4, Epoch 72/130 => Loss 26.411,  Loss1 0.672, Train_accy 77.56
2024-08-07 15:56:45,691 [foster.py] => SNet: Task 4, Epoch 73/130 => Loss 26.402,  Loss1 0.671, Train_accy 77.34
2024-08-07 15:56:56,163 [foster.py] => SNet: Task 4, Epoch 74/130 => Loss 26.432,  Loss1 0.671, Train_accy 78.23
2024-08-07 15:57:06,519 [foster.py] => SNet: Task 4, Epoch 75/130 => Loss 26.425,  Loss1 0.671, Train_accy 77.86
2024-08-07 15:57:18,656 [foster.py] => SNet: Task 4, Epoch 76/130 => Loss 26.421,  Loss1 0.671, Train_accy 78.04, Test_accy 74.14
2024-08-07 15:57:29,082 [foster.py] => SNet: Task 4, Epoch 77/130 => Loss 26.420,  Loss1 0.672, Train_accy 77.81
2024-08-07 15:57:39,821 [foster.py] => SNet: Task 4, Epoch 78/130 => Loss 26.396,  Loss1 0.672, Train_accy 77.87
2024-08-07 15:57:50,221 [foster.py] => SNet: Task 4, Epoch 79/130 => Loss 26.404,  Loss1 0.671, Train_accy 77.96
2024-08-07 15:58:01,066 [foster.py] => SNet: Task 4, Epoch 80/130 => Loss 26.393,  Loss1 0.672, Train_accy 79.01
2024-08-07 15:58:13,175 [foster.py] => SNet: Task 4, Epoch 81/130 => Loss 26.420,  Loss1 0.672, Train_accy 77.71, Test_accy 73.60
2024-08-07 15:58:23,477 [foster.py] => SNet: Task 4, Epoch 82/130 => Loss 26.420,  Loss1 0.671, Train_accy 78.13
2024-08-07 15:58:33,877 [foster.py] => SNet: Task 4, Epoch 83/130 => Loss 26.408,  Loss1 0.671, Train_accy 78.14
2024-08-07 15:58:44,407 [foster.py] => SNet: Task 4, Epoch 84/130 => Loss 26.406,  Loss1 0.672, Train_accy 77.81
2024-08-07 15:58:54,801 [foster.py] => SNet: Task 4, Epoch 85/130 => Loss 26.405,  Loss1 0.671, Train_accy 78.11
2024-08-07 15:59:07,019 [foster.py] => SNet: Task 4, Epoch 86/130 => Loss 26.407,  Loss1 0.672, Train_accy 77.76, Test_accy 73.66
2024-08-07 15:59:17,442 [foster.py] => SNet: Task 4, Epoch 87/130 => Loss 26.414,  Loss1 0.671, Train_accy 78.41
2024-08-07 15:59:27,941 [foster.py] => SNet: Task 4, Epoch 88/130 => Loss 26.401,  Loss1 0.672, Train_accy 78.94
2024-08-07 15:59:38,619 [foster.py] => SNet: Task 4, Epoch 89/130 => Loss 26.406,  Loss1 0.671, Train_accy 78.56
2024-08-07 15:59:49,212 [foster.py] => SNet: Task 4, Epoch 90/130 => Loss 26.406,  Loss1 0.671, Train_accy 77.60
2024-08-07 16:00:01,771 [foster.py] => SNet: Task 4, Epoch 91/130 => Loss 26.426,  Loss1 0.671, Train_accy 77.79, Test_accy 74.42
2024-08-07 16:00:12,291 [foster.py] => SNet: Task 4, Epoch 92/130 => Loss 26.408,  Loss1 0.672, Train_accy 78.19
2024-08-07 16:00:23,016 [foster.py] => SNet: Task 4, Epoch 93/130 => Loss 26.417,  Loss1 0.671, Train_accy 77.71
2024-08-07 16:00:33,823 [foster.py] => SNet: Task 4, Epoch 94/130 => Loss 26.410,  Loss1 0.671, Train_accy 78.16
2024-08-07 16:00:44,600 [foster.py] => SNet: Task 4, Epoch 95/130 => Loss 26.421,  Loss1 0.671, Train_accy 78.00
2024-08-07 16:00:56,925 [foster.py] => SNet: Task 4, Epoch 96/130 => Loss 26.423,  Loss1 0.671, Train_accy 78.30, Test_accy 73.72
2024-08-07 16:01:07,623 [foster.py] => SNet: Task 4, Epoch 97/130 => Loss 26.395,  Loss1 0.672, Train_accy 78.39
2024-08-07 16:01:18,064 [foster.py] => SNet: Task 4, Epoch 98/130 => Loss 26.417,  Loss1 0.671, Train_accy 78.59
2024-08-07 16:01:28,473 [foster.py] => SNet: Task 4, Epoch 99/130 => Loss 26.410,  Loss1 0.671, Train_accy 78.41
2024-08-07 16:01:38,866 [foster.py] => SNet: Task 4, Epoch 100/130 => Loss 26.397,  Loss1 0.672, Train_accy 77.84
2024-08-07 16:01:50,953 [foster.py] => SNet: Task 4, Epoch 101/130 => Loss 26.403,  Loss1 0.671, Train_accy 78.21, Test_accy 73.98
2024-08-07 16:02:01,497 [foster.py] => SNet: Task 4, Epoch 102/130 => Loss 26.381,  Loss1 0.672, Train_accy 78.80
2024-08-07 16:02:12,074 [foster.py] => SNet: Task 4, Epoch 103/130 => Loss 26.401,  Loss1 0.671, Train_accy 78.76
2024-08-07 16:02:22,904 [foster.py] => SNet: Task 4, Epoch 104/130 => Loss 26.417,  Loss1 0.672, Train_accy 78.17
2024-08-07 16:02:33,267 [foster.py] => SNet: Task 4, Epoch 105/130 => Loss 26.407,  Loss1 0.672, Train_accy 79.27
2024-08-07 16:02:45,426 [foster.py] => SNet: Task 4, Epoch 106/130 => Loss 26.395,  Loss1 0.672, Train_accy 78.33, Test_accy 74.32
2024-08-07 16:02:55,831 [foster.py] => SNet: Task 4, Epoch 107/130 => Loss 26.427,  Loss1 0.671, Train_accy 78.51
2024-08-07 16:03:06,441 [foster.py] => SNet: Task 4, Epoch 108/130 => Loss 26.388,  Loss1 0.671, Train_accy 78.87
2024-08-07 16:03:16,860 [foster.py] => SNet: Task 4, Epoch 109/130 => Loss 26.404,  Loss1 0.671, Train_accy 77.77
2024-08-07 16:03:27,702 [foster.py] => SNet: Task 4, Epoch 110/130 => Loss 26.396,  Loss1 0.671, Train_accy 78.51
2024-08-07 16:03:39,794 [foster.py] => SNet: Task 4, Epoch 111/130 => Loss 26.412,  Loss1 0.671, Train_accy 78.49, Test_accy 74.08
2024-08-07 16:03:50,217 [foster.py] => SNet: Task 4, Epoch 112/130 => Loss 26.400,  Loss1 0.671, Train_accy 78.84
2024-08-07 16:04:00,763 [foster.py] => SNet: Task 4, Epoch 113/130 => Loss 26.409,  Loss1 0.672, Train_accy 78.67
2024-08-07 16:04:11,208 [foster.py] => SNet: Task 4, Epoch 114/130 => Loss 26.400,  Loss1 0.672, Train_accy 78.57
2024-08-07 16:04:21,959 [foster.py] => SNet: Task 4, Epoch 115/130 => Loss 26.412,  Loss1 0.672, Train_accy 78.56
2024-08-07 16:04:33,979 [foster.py] => SNet: Task 4, Epoch 116/130 => Loss 26.422,  Loss1 0.672, Train_accy 78.94, Test_accy 74.34
2024-08-07 16:04:44,418 [foster.py] => SNet: Task 4, Epoch 117/130 => Loss 26.406,  Loss1 0.672, Train_accy 78.31
2024-08-07 16:04:54,894 [foster.py] => SNet: Task 4, Epoch 118/130 => Loss 26.385,  Loss1 0.671, Train_accy 78.74
2024-08-07 16:05:05,518 [foster.py] => SNet: Task 4, Epoch 119/130 => Loss 26.397,  Loss1 0.671, Train_accy 77.94
2024-08-07 16:05:16,358 [foster.py] => SNet: Task 4, Epoch 120/130 => Loss 26.403,  Loss1 0.671, Train_accy 78.94
2024-08-07 16:05:28,476 [foster.py] => SNet: Task 4, Epoch 121/130 => Loss 26.406,  Loss1 0.671, Train_accy 78.50, Test_accy 74.34
2024-08-07 16:05:39,049 [foster.py] => SNet: Task 4, Epoch 122/130 => Loss 26.419,  Loss1 0.671, Train_accy 78.90
2024-08-07 16:05:49,644 [foster.py] => SNet: Task 4, Epoch 123/130 => Loss 26.417,  Loss1 0.671, Train_accy 78.30
2024-08-07 16:06:00,082 [foster.py] => SNet: Task 4, Epoch 124/130 => Loss 26.389,  Loss1 0.672, Train_accy 79.53
2024-08-07 16:06:10,478 [foster.py] => SNet: Task 4, Epoch 125/130 => Loss 26.407,  Loss1 0.672, Train_accy 78.87
2024-08-07 16:06:22,938 [foster.py] => SNet: Task 4, Epoch 126/130 => Loss 26.421,  Loss1 0.671, Train_accy 79.43, Test_accy 74.50
2024-08-07 16:06:33,580 [foster.py] => SNet: Task 4, Epoch 127/130 => Loss 26.394,  Loss1 0.671, Train_accy 78.61
2024-08-07 16:06:43,986 [foster.py] => SNet: Task 4, Epoch 128/130 => Loss 26.409,  Loss1 0.671, Train_accy 77.97
2024-08-07 16:06:54,885 [foster.py] => SNet: Task 4, Epoch 129/130 => Loss 26.388,  Loss1 0.671, Train_accy 79.11
2024-08-07 16:07:05,257 [foster.py] => SNet: Task 4, Epoch 130/130 => Loss 26.390,  Loss1 0.671, Train_accy 78.94
2024-08-07 16:07:05,258 [foster.py] => do not weight align student!
2024-08-07 16:07:06,997 [foster.py] => darknet eval: 
2024-08-07 16:07:06,997 [foster.py] => CNN top1 curve: 74.18
2024-08-07 16:07:06,998 [foster.py] => CNN top5 curve: 94.48
2024-08-07 16:07:06,998 [foster.py] => CNN top1 平均值: 74.18
2024-08-07 16:07:07,001 [foster.py] => timees : 2972.9851377010345
2024-08-07 16:07:07,002 [base.py] => Reducing exemplars...(40 per classes)
2024-08-07 16:07:20,938 [base.py] => Constructing exemplars...(40 per classes)
2024-08-07 16:07:35,229 [foster.py] => Exemplar size: 2000
2024-08-07 16:07:35,230 [trainer.py] => CNN: {'total': 75.54, '00-09': 75.5, '10-19': 68.5, '20-29': 76.4, '30-39': 78.4, '40-49': 78.9, 'old': 74.7, 'new': 78.9}
2024-08-07 16:07:35,230 [trainer.py] => NME: {'total': 72.1, '00-09': 71.1, '10-19': 64.4, '20-29': 74.1, '30-39': 67.6, '40-49': 83.3, 'old': 69.3, 'new': 83.3}
2024-08-07 16:07:35,230 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54]
2024-08-07 16:07:35,233 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64]
2024-08-07 16:07:35,233 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1]
2024-08-07 16:07:35,233 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06]

2024-08-07 16:07:35,233 [trainer.py] => CNN top1 平均值: 83.33
2024-08-07 16:07:35,236 [trainer.py] => All params: 1294848
2024-08-07 16:07:35,239 [trainer.py] => Trainable params: 650974
2024-08-07 16:07:35,303 [foster.py] => Learning on 50-60
2024-08-07 16:07:35,306 [foster.py] => All params: 1297438
2024-08-07 16:07:35,308 [foster.py] => Trainable params: 652914
2024-08-07 16:07:35,373 [foster.py] => per cls weights : [1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906 1.04684906
 1.04684906 1.04684906 0.76575472 0.76575472 0.76575472 0.76575472
 0.76575472 0.76575472 0.76575472 0.76575472 0.76575472 0.76575472]
2024-08-07 16:07:42,893 [foster.py] => Task 5, Epoch 1/170 => Loss 8.978, Loss_clf 4.333, Loss_fe 2.038, Loss_kd 2.169, Train_accy 39.24
2024-08-07 16:07:52,553 [foster.py] => Task 5, Epoch 2/170 => Loss 5.741, Loss_clf 1.686, Loss_fe 1.509, Loss_kd 2.118, Train_accy 50.49, Test_accy 65.98
2024-08-07 16:08:02,495 [foster.py] => Task 5, Epoch 3/170 => Loss 5.409, Loss_clf 1.463, Loss_fe 1.414, Loss_kd 2.107, Train_accy 54.37, Test_accy 64.45
2024-08-07 16:08:12,466 [foster.py] => Task 5, Epoch 4/170 => Loss 5.263, Loss_clf 1.378, Loss_fe 1.351, Loss_kd 2.109, Train_accy 55.97, Test_accy 66.18
2024-08-07 16:08:22,277 [foster.py] => Task 5, Epoch 5/170 => Loss 5.289, Loss_clf 1.408, Loss_fe 1.336, Loss_kd 2.117, Train_accy 55.87, Test_accy 66.97
2024-08-07 16:08:29,798 [foster.py] => Task 5, Epoch 6/170 => Loss 5.352, Loss_clf 1.491, Loss_fe 1.316, Loss_kd 2.117, Train_accy 54.99
2024-08-07 16:08:39,528 [foster.py] => Task 5, Epoch 7/170 => Loss 5.302, Loss_clf 1.451, Loss_fe 1.313, Loss_kd 2.111, Train_accy 56.46, Test_accy 64.65
2024-08-07 16:08:49,224 [foster.py] => Task 5, Epoch 8/170 => Loss 5.274, Loss_clf 1.461, Loss_fe 1.271, Loss_kd 2.115, Train_accy 56.21, Test_accy 65.82
2024-08-07 16:08:58,866 [foster.py] => Task 5, Epoch 9/170 => Loss 5.262, Loss_clf 1.423, Loss_fe 1.293, Loss_kd 2.119, Train_accy 56.64, Test_accy 65.92
2024-08-07 16:09:08,664 [foster.py] => Task 5, Epoch 10/170 => Loss 5.250, Loss_clf 1.424, Loss_fe 1.271, Loss_kd 2.126, Train_accy 57.41, Test_accy 65.85
2024-08-07 16:09:16,208 [foster.py] => Task 5, Epoch 11/170 => Loss 5.219, Loss_clf 1.396, Loss_fe 1.263, Loss_kd 2.130, Train_accy 57.26
2024-08-07 16:09:25,998 [foster.py] => Task 5, Epoch 12/170 => Loss 5.173, Loss_clf 1.385, Loss_fe 1.244, Loss_kd 2.116, Train_accy 57.34, Test_accy 66.03
2024-08-07 16:09:35,751 [foster.py] => Task 5, Epoch 13/170 => Loss 5.160, Loss_clf 1.379, Loss_fe 1.231, Loss_kd 2.121, Train_accy 57.96, Test_accy 62.90
2024-08-07 16:09:45,433 [foster.py] => Task 5, Epoch 14/170 => Loss 5.221, Loss_clf 1.420, Loss_fe 1.252, Loss_kd 2.121, Train_accy 58.24, Test_accy 67.03
2024-08-07 16:09:55,194 [foster.py] => Task 5, Epoch 15/170 => Loss 5.092, Loss_clf 1.326, Loss_fe 1.219, Loss_kd 2.119, Train_accy 58.20, Test_accy 62.22
2024-08-07 16:10:02,704 [foster.py] => Task 5, Epoch 16/170 => Loss 5.156, Loss_clf 1.394, Loss_fe 1.206, Loss_kd 2.127, Train_accy 58.04
2024-08-07 16:10:12,347 [foster.py] => Task 5, Epoch 17/170 => Loss 5.072, Loss_clf 1.327, Loss_fe 1.198, Loss_kd 2.119, Train_accy 59.23, Test_accy 68.05
2024-08-07 16:10:22,046 [foster.py] => Task 5, Epoch 18/170 => Loss 4.993, Loss_clf 1.269, Loss_fe 1.186, Loss_kd 2.112, Train_accy 59.21, Test_accy 68.02
2024-08-07 16:10:31,660 [foster.py] => Task 5, Epoch 19/170 => Loss 5.047, Loss_clf 1.325, Loss_fe 1.190, Loss_kd 2.107, Train_accy 59.16, Test_accy 63.83
2024-08-07 16:10:41,245 [foster.py] => Task 5, Epoch 20/170 => Loss 5.079, Loss_clf 1.348, Loss_fe 1.176, Loss_kd 2.126, Train_accy 58.87, Test_accy 65.38
2024-08-07 16:10:48,834 [foster.py] => Task 5, Epoch 21/170 => Loss 5.036, Loss_clf 1.313, Loss_fe 1.174, Loss_kd 2.121, Train_accy 60.07
2024-08-07 16:10:58,634 [foster.py] => Task 5, Epoch 22/170 => Loss 5.116, Loss_clf 1.369, Loss_fe 1.196, Loss_kd 2.123, Train_accy 58.09, Test_accy 67.42
2024-08-07 16:11:08,464 [foster.py] => Task 5, Epoch 23/170 => Loss 5.110, Loss_clf 1.384, Loss_fe 1.166, Loss_kd 2.129, Train_accy 58.54, Test_accy 68.47
2024-08-07 16:11:18,238 [foster.py] => Task 5, Epoch 24/170 => Loss 5.019, Loss_clf 1.301, Loss_fe 1.167, Loss_kd 2.123, Train_accy 59.43, Test_accy 66.15
2024-08-07 16:11:28,045 [foster.py] => Task 5, Epoch 25/170 => Loss 4.995, Loss_clf 1.300, Loss_fe 1.152, Loss_kd 2.117, Train_accy 60.97, Test_accy 66.48
2024-08-07 16:11:35,539 [foster.py] => Task 5, Epoch 26/170 => Loss 5.081, Loss_clf 1.382, Loss_fe 1.155, Loss_kd 2.117, Train_accy 59.11
2024-08-07 16:11:45,237 [foster.py] => Task 5, Epoch 27/170 => Loss 5.039, Loss_clf 1.314, Loss_fe 1.178, Loss_kd 2.120, Train_accy 59.66, Test_accy 67.92
2024-08-07 16:11:54,957 [foster.py] => Task 5, Epoch 28/170 => Loss 4.956, Loss_clf 1.256, Loss_fe 1.153, Loss_kd 2.119, Train_accy 61.00, Test_accy 62.95
2024-08-07 16:12:04,796 [foster.py] => Task 5, Epoch 29/170 => Loss 4.932, Loss_clf 1.265, Loss_fe 1.125, Loss_kd 2.116, Train_accy 62.17, Test_accy 68.60
2024-08-07 16:12:14,648 [foster.py] => Task 5, Epoch 30/170 => Loss 4.903, Loss_clf 1.237, Loss_fe 1.117, Loss_kd 2.121, Train_accy 61.24, Test_accy 68.30
2024-08-07 16:12:22,283 [foster.py] => Task 5, Epoch 31/170 => Loss 5.004, Loss_clf 1.303, Loss_fe 1.155, Loss_kd 2.118, Train_accy 60.34
2024-08-07 16:12:31,906 [foster.py] => Task 5, Epoch 32/170 => Loss 5.058, Loss_clf 1.335, Loss_fe 1.166, Loss_kd 2.127, Train_accy 59.86, Test_accy 67.50
2024-08-07 16:12:41,638 [foster.py] => Task 5, Epoch 33/170 => Loss 4.937, Loss_clf 1.263, Loss_fe 1.133, Loss_kd 2.115, Train_accy 61.73, Test_accy 66.92
2024-08-07 16:12:51,298 [foster.py] => Task 5, Epoch 34/170 => Loss 4.964, Loss_clf 1.307, Loss_fe 1.109, Loss_kd 2.120, Train_accy 60.87, Test_accy 67.08
2024-08-07 16:13:01,035 [foster.py] => Task 5, Epoch 35/170 => Loss 4.912, Loss_clf 1.246, Loss_fe 1.120, Loss_kd 2.119, Train_accy 61.46, Test_accy 68.25
2024-08-07 16:13:08,549 [foster.py] => Task 5, Epoch 36/170 => Loss 4.937, Loss_clf 1.278, Loss_fe 1.107, Loss_kd 2.124, Train_accy 61.31
2024-08-07 16:13:18,219 [foster.py] => Task 5, Epoch 37/170 => Loss 4.875, Loss_clf 1.222, Loss_fe 1.115, Loss_kd 2.112, Train_accy 61.44, Test_accy 67.07
2024-08-07 16:13:27,890 [foster.py] => Task 5, Epoch 38/170 => Loss 4.759, Loss_clf 1.161, Loss_fe 1.062, Loss_kd 2.109, Train_accy 61.73, Test_accy 66.32
2024-08-07 16:13:37,519 [foster.py] => Task 5, Epoch 39/170 => Loss 4.899, Loss_clf 1.230, Loss_fe 1.113, Loss_kd 2.128, Train_accy 61.16, Test_accy 67.75
2024-08-07 16:13:47,154 [foster.py] => Task 5, Epoch 40/170 => Loss 4.787, Loss_clf 1.154, Loss_fe 1.091, Loss_kd 2.115, Train_accy 62.90, Test_accy 67.77
2024-08-07 16:13:54,702 [foster.py] => Task 5, Epoch 41/170 => Loss 4.855, Loss_clf 1.239, Loss_fe 1.075, Loss_kd 2.115, Train_accy 62.83
2024-08-07 16:14:04,396 [foster.py] => Task 5, Epoch 42/170 => Loss 4.870, Loss_clf 1.239, Loss_fe 1.094, Loss_kd 2.112, Train_accy 62.39, Test_accy 68.72
2024-08-07 16:14:14,060 [foster.py] => Task 5, Epoch 43/170 => Loss 4.773, Loss_clf 1.170, Loss_fe 1.051, Loss_kd 2.124, Train_accy 62.90, Test_accy 67.50
2024-08-07 16:14:23,801 [foster.py] => Task 5, Epoch 44/170 => Loss 4.789, Loss_clf 1.186, Loss_fe 1.067, Loss_kd 2.111, Train_accy 62.14, Test_accy 66.90
2024-08-07 16:14:33,481 [foster.py] => Task 5, Epoch 45/170 => Loss 4.966, Loss_clf 1.335, Loss_fe 1.092, Loss_kd 2.113, Train_accy 61.07, Test_accy 68.17
2024-08-07 16:14:41,208 [foster.py] => Task 5, Epoch 46/170 => Loss 4.847, Loss_clf 1.230, Loss_fe 1.073, Loss_kd 2.117, Train_accy 62.94
2024-08-07 16:14:51,152 [foster.py] => Task 5, Epoch 47/170 => Loss 4.811, Loss_clf 1.218, Loss_fe 1.049, Loss_kd 2.118, Train_accy 63.00, Test_accy 69.37
2024-08-07 16:15:00,886 [foster.py] => Task 5, Epoch 48/170 => Loss 4.764, Loss_clf 1.158, Loss_fe 1.061, Loss_kd 2.118, Train_accy 63.54, Test_accy 68.05
2024-08-07 16:15:10,616 [foster.py] => Task 5, Epoch 49/170 => Loss 4.811, Loss_clf 1.195, Loss_fe 1.077, Loss_kd 2.113, Train_accy 62.33, Test_accy 67.37
2024-08-07 16:15:20,324 [foster.py] => Task 5, Epoch 50/170 => Loss 4.743, Loss_clf 1.151, Loss_fe 1.049, Loss_kd 2.116, Train_accy 63.44, Test_accy 67.92
2024-08-07 16:15:27,918 [foster.py] => Task 5, Epoch 51/170 => Loss 4.722, Loss_clf 1.133, Loss_fe 1.044, Loss_kd 2.117, Train_accy 63.43
2024-08-07 16:15:37,662 [foster.py] => Task 5, Epoch 52/170 => Loss 4.801, Loss_clf 1.211, Loss_fe 1.053, Loss_kd 2.112, Train_accy 62.36, Test_accy 67.68
2024-08-07 16:15:47,401 [foster.py] => Task 5, Epoch 53/170 => Loss 4.803, Loss_clf 1.211, Loss_fe 1.044, Loss_kd 2.121, Train_accy 63.01, Test_accy 68.82
2024-08-07 16:15:57,225 [foster.py] => Task 5, Epoch 54/170 => Loss 4.723, Loss_clf 1.140, Loss_fe 1.040, Loss_kd 2.116, Train_accy 63.99, Test_accy 69.23
2024-08-07 16:16:06,931 [foster.py] => Task 5, Epoch 55/170 => Loss 4.715, Loss_clf 1.165, Loss_fe 1.017, Loss_kd 2.108, Train_accy 63.63, Test_accy 69.40
2024-08-07 16:16:14,486 [foster.py] => Task 5, Epoch 56/170 => Loss 4.725, Loss_clf 1.165, Loss_fe 1.019, Loss_kd 2.114, Train_accy 63.80
2024-08-07 16:16:24,212 [foster.py] => Task 5, Epoch 57/170 => Loss 4.710, Loss_clf 1.150, Loss_fe 1.016, Loss_kd 2.117, Train_accy 63.41, Test_accy 68.85
2024-08-07 16:16:33,985 [foster.py] => Task 5, Epoch 58/170 => Loss 4.687, Loss_clf 1.125, Loss_fe 1.016, Loss_kd 2.118, Train_accy 63.46, Test_accy 68.95
2024-08-07 16:16:43,672 [foster.py] => Task 5, Epoch 59/170 => Loss 4.730, Loss_clf 1.188, Loss_fe 0.999, Loss_kd 2.116, Train_accy 62.66, Test_accy 68.25
2024-08-07 16:16:53,306 [foster.py] => Task 5, Epoch 60/170 => Loss 4.670, Loss_clf 1.123, Loss_fe 1.004, Loss_kd 2.116, Train_accy 64.26, Test_accy 69.88
2024-08-07 16:17:00,872 [foster.py] => Task 5, Epoch 61/170 => Loss 4.603, Loss_clf 1.092, Loss_fe 0.968, Loss_kd 2.116, Train_accy 64.74
2024-08-07 16:17:10,517 [foster.py] => Task 5, Epoch 62/170 => Loss 4.594, Loss_clf 1.082, Loss_fe 0.982, Loss_kd 2.105, Train_accy 64.69, Test_accy 67.70
2024-08-07 16:17:20,359 [foster.py] => Task 5, Epoch 63/170 => Loss 4.726, Loss_clf 1.198, Loss_fe 0.989, Loss_kd 2.113, Train_accy 64.14, Test_accy 69.25
2024-08-07 16:17:30,296 [foster.py] => Task 5, Epoch 64/170 => Loss 4.669, Loss_clf 1.134, Loss_fe 0.995, Loss_kd 2.113, Train_accy 64.61, Test_accy 69.15
2024-08-07 16:17:39,941 [foster.py] => Task 5, Epoch 65/170 => Loss 4.687, Loss_clf 1.142, Loss_fe 1.004, Loss_kd 2.114, Train_accy 63.96, Test_accy 69.57
2024-08-07 16:17:47,507 [foster.py] => Task 5, Epoch 66/170 => Loss 4.647, Loss_clf 1.123, Loss_fe 0.977, Loss_kd 2.119, Train_accy 64.87
2024-08-07 16:17:57,277 [foster.py] => Task 5, Epoch 67/170 => Loss 4.702, Loss_clf 1.161, Loss_fe 0.997, Loss_kd 2.116, Train_accy 63.89, Test_accy 69.33
2024-08-07 16:18:07,126 [foster.py] => Task 5, Epoch 68/170 => Loss 4.543, Loss_clf 1.050, Loss_fe 0.952, Loss_kd 2.114, Train_accy 65.67, Test_accy 66.72
2024-08-07 16:18:16,737 [foster.py] => Task 5, Epoch 69/170 => Loss 4.578, Loss_clf 1.075, Loss_fe 0.964, Loss_kd 2.113, Train_accy 64.81, Test_accy 67.88
2024-08-07 16:18:26,417 [foster.py] => Task 5, Epoch 70/170 => Loss 4.570, Loss_clf 1.087, Loss_fe 0.947, Loss_kd 2.110, Train_accy 65.76, Test_accy 68.33
2024-08-07 16:18:33,969 [foster.py] => Task 5, Epoch 71/170 => Loss 4.627, Loss_clf 1.130, Loss_fe 0.962, Loss_kd 2.110, Train_accy 64.44
2024-08-07 16:18:43,696 [foster.py] => Task 5, Epoch 72/170 => Loss 4.627, Loss_clf 1.110, Loss_fe 0.976, Loss_kd 2.114, Train_accy 65.17, Test_accy 70.23
2024-08-07 16:18:53,447 [foster.py] => Task 5, Epoch 73/170 => Loss 4.523, Loss_clf 1.052, Loss_fe 0.923, Loss_kd 2.120, Train_accy 65.36, Test_accy 68.85
2024-08-07 16:19:03,111 [foster.py] => Task 5, Epoch 74/170 => Loss 4.522, Loss_clf 1.051, Loss_fe 0.918, Loss_kd 2.125, Train_accy 67.36, Test_accy 68.83
2024-08-07 16:19:12,836 [foster.py] => Task 5, Epoch 75/170 => Loss 4.512, Loss_clf 1.055, Loss_fe 0.925, Loss_kd 2.108, Train_accy 66.11, Test_accy 68.50
2024-08-07 16:19:20,510 [foster.py] => Task 5, Epoch 76/170 => Loss 4.529, Loss_clf 1.052, Loss_fe 0.930, Loss_kd 2.120, Train_accy 65.66
2024-08-07 16:19:30,312 [foster.py] => Task 5, Epoch 77/170 => Loss 4.543, Loss_clf 1.078, Loss_fe 0.916, Loss_kd 2.121, Train_accy 65.71, Test_accy 69.62
2024-08-07 16:19:40,047 [foster.py] => Task 5, Epoch 78/170 => Loss 4.543, Loss_clf 1.085, Loss_fe 0.924, Loss_kd 2.109, Train_accy 65.70, Test_accy 68.55
2024-08-07 16:19:49,902 [foster.py] => Task 5, Epoch 79/170 => Loss 4.501, Loss_clf 1.051, Loss_fe 0.917, Loss_kd 2.108, Train_accy 66.09, Test_accy 69.60
2024-08-07 16:19:59,726 [foster.py] => Task 5, Epoch 80/170 => Loss 4.510, Loss_clf 1.051, Loss_fe 0.923, Loss_kd 2.110, Train_accy 66.93, Test_accy 69.53
2024-08-07 16:20:07,539 [foster.py] => Task 5, Epoch 81/170 => Loss 4.521, Loss_clf 1.077, Loss_fe 0.916, Loss_kd 2.104, Train_accy 66.01
2024-08-07 16:20:17,636 [foster.py] => Task 5, Epoch 82/170 => Loss 4.467, Loss_clf 1.042, Loss_fe 0.889, Loss_kd 2.111, Train_accy 66.99, Test_accy 70.28
2024-08-07 16:20:27,396 [foster.py] => Task 5, Epoch 83/170 => Loss 4.431, Loss_clf 0.995, Loss_fe 0.895, Loss_kd 2.115, Train_accy 67.59, Test_accy 69.32
2024-08-07 16:20:37,219 [foster.py] => Task 5, Epoch 84/170 => Loss 4.403, Loss_clf 1.002, Loss_fe 0.860, Loss_kd 2.115, Train_accy 67.57, Test_accy 70.07
2024-08-07 16:20:46,890 [foster.py] => Task 5, Epoch 85/170 => Loss 4.406, Loss_clf 0.996, Loss_fe 0.867, Loss_kd 2.117, Train_accy 67.79, Test_accy 69.23
2024-08-07 16:20:54,441 [foster.py] => Task 5, Epoch 86/170 => Loss 4.371, Loss_clf 0.971, Loss_fe 0.853, Loss_kd 2.120, Train_accy 68.74
2024-08-07 16:21:04,177 [foster.py] => Task 5, Epoch 87/170 => Loss 4.393, Loss_clf 0.991, Loss_fe 0.864, Loss_kd 2.112, Train_accy 67.40, Test_accy 69.07
2024-08-07 16:21:13,898 [foster.py] => Task 5, Epoch 88/170 => Loss 4.314, Loss_clf 0.954, Loss_fe 0.832, Loss_kd 2.104, Train_accy 69.50, Test_accy 69.87
2024-08-07 16:21:23,590 [foster.py] => Task 5, Epoch 89/170 => Loss 4.403, Loss_clf 1.003, Loss_fe 0.861, Loss_kd 2.113, Train_accy 67.60, Test_accy 69.62
2024-08-07 16:21:33,210 [foster.py] => Task 5, Epoch 90/170 => Loss 4.281, Loss_clf 0.935, Loss_fe 0.816, Loss_kd 2.106, Train_accy 69.36, Test_accy 70.32
2024-08-07 16:21:40,786 [foster.py] => Task 5, Epoch 91/170 => Loss 4.331, Loss_clf 0.972, Loss_fe 0.827, Loss_kd 2.107, Train_accy 68.57
2024-08-07 16:21:50,469 [foster.py] => Task 5, Epoch 92/170 => Loss 4.368, Loss_clf 0.988, Loss_fe 0.838, Loss_kd 2.115, Train_accy 68.66, Test_accy 69.27
2024-08-07 16:22:00,232 [foster.py] => Task 5, Epoch 93/170 => Loss 4.383, Loss_clf 0.996, Loss_fe 0.836, Loss_kd 2.123, Train_accy 68.34, Test_accy 69.73
2024-08-07 16:22:10,007 [foster.py] => Task 5, Epoch 94/170 => Loss 4.301, Loss_clf 0.946, Loss_fe 0.820, Loss_kd 2.109, Train_accy 69.20, Test_accy 70.12
2024-08-07 16:22:19,739 [foster.py] => Task 5, Epoch 95/170 => Loss 4.318, Loss_clf 0.957, Loss_fe 0.827, Loss_kd 2.109, Train_accy 68.63, Test_accy 69.58
2024-08-07 16:22:27,410 [foster.py] => Task 5, Epoch 96/170 => Loss 4.284, Loss_clf 0.932, Loss_fe 0.813, Loss_kd 2.112, Train_accy 69.53
2024-08-07 16:22:37,163 [foster.py] => Task 5, Epoch 97/170 => Loss 4.273, Loss_clf 0.927, Loss_fe 0.810, Loss_kd 2.111, Train_accy 69.67, Test_accy 70.02
2024-08-07 16:22:46,815 [foster.py] => Task 5, Epoch 98/170 => Loss 4.233, Loss_clf 0.911, Loss_fe 0.784, Loss_kd 2.112, Train_accy 70.79, Test_accy 68.22
2024-08-07 16:22:56,506 [foster.py] => Task 5, Epoch 99/170 => Loss 4.269, Loss_clf 0.935, Loss_fe 0.792, Loss_kd 2.115, Train_accy 69.23, Test_accy 69.78
2024-08-07 16:23:06,228 [foster.py] => Task 5, Epoch 100/170 => Loss 4.262, Loss_clf 0.933, Loss_fe 0.794, Loss_kd 2.109, Train_accy 70.30, Test_accy 70.43
2024-08-07 16:23:13,772 [foster.py] => Task 5, Epoch 101/170 => Loss 4.276, Loss_clf 0.940, Loss_fe 0.789, Loss_kd 2.120, Train_accy 68.90
2024-08-07 16:23:23,582 [foster.py] => Task 5, Epoch 102/170 => Loss 4.197, Loss_clf 0.899, Loss_fe 0.765, Loss_kd 2.108, Train_accy 71.17, Test_accy 68.78
2024-08-07 16:23:33,318 [foster.py] => Task 5, Epoch 103/170 => Loss 4.195, Loss_clf 0.888, Loss_fe 0.759, Loss_kd 2.120, Train_accy 70.63, Test_accy 70.68
2024-08-07 16:23:43,241 [foster.py] => Task 5, Epoch 104/170 => Loss 4.174, Loss_clf 0.885, Loss_fe 0.759, Loss_kd 2.105, Train_accy 71.00, Test_accy 71.10
2024-08-07 16:23:53,040 [foster.py] => Task 5, Epoch 105/170 => Loss 4.189, Loss_clf 0.892, Loss_fe 0.759, Loss_kd 2.112, Train_accy 70.56, Test_accy 70.17
2024-08-07 16:24:00,633 [foster.py] => Task 5, Epoch 106/170 => Loss 4.174, Loss_clf 0.890, Loss_fe 0.741, Loss_kd 2.116, Train_accy 70.93
2024-08-07 16:24:10,380 [foster.py] => Task 5, Epoch 107/170 => Loss 4.212, Loss_clf 0.911, Loss_fe 0.761, Loss_kd 2.114, Train_accy 70.27, Test_accy 71.32
2024-08-07 16:24:20,161 [foster.py] => Task 5, Epoch 108/170 => Loss 4.123, Loss_clf 0.855, Loss_fe 0.731, Loss_kd 2.111, Train_accy 71.81, Test_accy 70.97
2024-08-07 16:24:29,906 [foster.py] => Task 5, Epoch 109/170 => Loss 4.188, Loss_clf 0.898, Loss_fe 0.746, Loss_kd 2.117, Train_accy 71.24, Test_accy 70.00
2024-08-07 16:24:39,655 [foster.py] => Task 5, Epoch 110/170 => Loss 4.114, Loss_clf 0.851, Loss_fe 0.718, Loss_kd 2.117, Train_accy 71.67, Test_accy 71.02
2024-08-07 16:24:47,395 [foster.py] => Task 5, Epoch 111/170 => Loss 4.060, Loss_clf 0.834, Loss_fe 0.691, Loss_kd 2.110, Train_accy 72.66
2024-08-07 16:24:57,382 [foster.py] => Task 5, Epoch 112/170 => Loss 4.089, Loss_clf 0.848, Loss_fe 0.699, Loss_kd 2.115, Train_accy 72.06, Test_accy 70.63
2024-08-07 16:25:07,170 [foster.py] => Task 5, Epoch 113/170 => Loss 4.137, Loss_clf 0.882, Loss_fe 0.721, Loss_kd 2.109, Train_accy 71.30, Test_accy 70.73
2024-08-07 16:25:16,926 [foster.py] => Task 5, Epoch 114/170 => Loss 4.039, Loss_clf 0.825, Loss_fe 0.681, Loss_kd 2.108, Train_accy 73.23, Test_accy 70.68
2024-08-07 16:25:26,595 [foster.py] => Task 5, Epoch 115/170 => Loss 3.984, Loss_clf 0.789, Loss_fe 0.652, Loss_kd 2.115, Train_accy 74.21, Test_accy 71.58
2024-08-07 16:25:34,198 [foster.py] => Task 5, Epoch 116/170 => Loss 4.073, Loss_clf 0.843, Loss_fe 0.691, Loss_kd 2.113, Train_accy 72.73
2024-08-07 16:25:43,888 [foster.py] => Task 5, Epoch 117/170 => Loss 3.998, Loss_clf 0.797, Loss_fe 0.662, Loss_kd 2.113, Train_accy 73.87, Test_accy 71.62
2024-08-07 16:25:53,591 [foster.py] => Task 5, Epoch 118/170 => Loss 3.985, Loss_clf 0.799, Loss_fe 0.655, Loss_kd 2.106, Train_accy 73.26, Test_accy 70.05
2024-08-07 16:26:03,262 [foster.py] => Task 5, Epoch 119/170 => Loss 3.991, Loss_clf 0.798, Loss_fe 0.645, Loss_kd 2.120, Train_accy 74.01, Test_accy 71.07
2024-08-07 16:26:12,992 [foster.py] => Task 5, Epoch 120/170 => Loss 3.915, Loss_clf 0.761, Loss_fe 0.627, Loss_kd 2.103, Train_accy 74.97, Test_accy 71.30
2024-08-07 16:26:20,573 [foster.py] => Task 5, Epoch 121/170 => Loss 3.977, Loss_clf 0.793, Loss_fe 0.640, Loss_kd 2.117, Train_accy 73.89
2024-08-07 16:26:30,418 [foster.py] => Task 5, Epoch 122/170 => Loss 3.935, Loss_clf 0.780, Loss_fe 0.632, Loss_kd 2.100, Train_accy 74.33, Test_accy 71.35
2024-08-07 16:26:40,463 [foster.py] => Task 5, Epoch 123/170 => Loss 3.890, Loss_clf 0.759, Loss_fe 0.606, Loss_kd 2.102, Train_accy 74.36, Test_accy 70.85
2024-08-07 16:26:50,423 [foster.py] => Task 5, Epoch 124/170 => Loss 3.957, Loss_clf 0.791, Loss_fe 0.629, Loss_kd 2.111, Train_accy 73.76, Test_accy 70.37
2024-08-07 16:27:00,249 [foster.py] => Task 5, Epoch 125/170 => Loss 3.931, Loss_clf 0.783, Loss_fe 0.612, Loss_kd 2.110, Train_accy 74.84, Test_accy 71.83
2024-08-07 16:27:07,996 [foster.py] => Task 5, Epoch 126/170 => Loss 3.881, Loss_clf 0.752, Loss_fe 0.590, Loss_kd 2.113, Train_accy 75.77
2024-08-07 16:27:17,640 [foster.py] => Task 5, Epoch 127/170 => Loss 3.834, Loss_clf 0.733, Loss_fe 0.574, Loss_kd 2.103, Train_accy 76.16, Test_accy 71.13
2024-08-07 16:27:27,362 [foster.py] => Task 5, Epoch 128/170 => Loss 3.870, Loss_clf 0.745, Loss_fe 0.593, Loss_kd 2.107, Train_accy 75.67, Test_accy 71.20
2024-08-07 16:27:37,268 [foster.py] => Task 5, Epoch 129/170 => Loss 3.870, Loss_clf 0.740, Loss_fe 0.580, Loss_kd 2.123, Train_accy 76.10, Test_accy 72.28
2024-08-07 16:27:46,992 [foster.py] => Task 5, Epoch 130/170 => Loss 3.859, Loss_clf 0.734, Loss_fe 0.581, Loss_kd 2.118, Train_accy 75.89, Test_accy 71.97
2024-08-07 16:27:54,598 [foster.py] => Task 5, Epoch 131/170 => Loss 3.853, Loss_clf 0.738, Loss_fe 0.571, Loss_kd 2.116, Train_accy 76.73
2024-08-07 16:28:04,324 [foster.py] => Task 5, Epoch 132/170 => Loss 3.749, Loss_clf 0.682, Loss_fe 0.541, Loss_kd 2.103, Train_accy 77.03, Test_accy 72.32
2024-08-07 16:28:14,025 [foster.py] => Task 5, Epoch 133/170 => Loss 3.811, Loss_clf 0.719, Loss_fe 0.559, Loss_kd 2.108, Train_accy 76.71, Test_accy 72.55
2024-08-07 16:28:23,831 [foster.py] => Task 5, Epoch 134/170 => Loss 3.760, Loss_clf 0.691, Loss_fe 0.535, Loss_kd 2.110, Train_accy 77.34, Test_accy 71.93
2024-08-07 16:28:33,846 [foster.py] => Task 5, Epoch 135/170 => Loss 3.737, Loss_clf 0.680, Loss_fe 0.519, Loss_kd 2.111, Train_accy 77.67, Test_accy 71.67
2024-08-07 16:28:41,544 [foster.py] => Task 5, Epoch 136/170 => Loss 3.755, Loss_clf 0.691, Loss_fe 0.523, Loss_kd 2.115, Train_accy 76.81
2024-08-07 16:28:51,198 [foster.py] => Task 5, Epoch 137/170 => Loss 3.704, Loss_clf 0.674, Loss_fe 0.500, Loss_kd 2.105, Train_accy 78.14, Test_accy 72.52
2024-08-07 16:29:00,838 [foster.py] => Task 5, Epoch 138/170 => Loss 3.730, Loss_clf 0.684, Loss_fe 0.513, Loss_kd 2.108, Train_accy 77.77, Test_accy 72.52
2024-08-07 16:29:10,549 [foster.py] => Task 5, Epoch 139/170 => Loss 3.700, Loss_clf 0.664, Loss_fe 0.499, Loss_kd 2.112, Train_accy 78.13, Test_accy 72.50
2024-08-07 16:29:20,250 [foster.py] => Task 5, Epoch 140/170 => Loss 3.703, Loss_clf 0.666, Loss_fe 0.502, Loss_kd 2.109, Train_accy 79.07, Test_accy 72.32
2024-08-07 16:29:27,771 [foster.py] => Task 5, Epoch 141/170 => Loss 3.660, Loss_clf 0.650, Loss_fe 0.476, Loss_kd 2.109, Train_accy 78.90
2024-08-07 16:29:37,427 [foster.py] => Task 5, Epoch 142/170 => Loss 3.705, Loss_clf 0.666, Loss_fe 0.494, Loss_kd 2.118, Train_accy 78.73, Test_accy 72.48
2024-08-07 16:29:47,120 [foster.py] => Task 5, Epoch 143/170 => Loss 3.646, Loss_clf 0.643, Loss_fe 0.473, Loss_kd 2.106, Train_accy 79.39, Test_accy 72.80
2024-08-07 16:29:56,787 [foster.py] => Task 5, Epoch 144/170 => Loss 3.633, Loss_clf 0.640, Loss_fe 0.464, Loss_kd 2.105, Train_accy 79.61, Test_accy 72.90
2024-08-07 16:30:06,467 [foster.py] => Task 5, Epoch 145/170 => Loss 3.642, Loss_clf 0.635, Loss_fe 0.467, Loss_kd 2.114, Train_accy 79.60, Test_accy 73.12
2024-08-07 16:30:13,990 [foster.py] => Task 5, Epoch 146/170 => Loss 3.668, Loss_clf 0.658, Loss_fe 0.481, Loss_kd 2.105, Train_accy 79.27
2024-08-07 16:30:23,622 [foster.py] => Task 5, Epoch 147/170 => Loss 3.606, Loss_clf 0.614, Loss_fe 0.458, Loss_kd 2.108, Train_accy 80.70, Test_accy 72.72
2024-08-07 16:30:33,293 [foster.py] => Task 5, Epoch 148/170 => Loss 3.605, Loss_clf 0.632, Loss_fe 0.446, Loss_kd 2.103, Train_accy 79.96, Test_accy 72.58
2024-08-07 16:30:42,943 [foster.py] => Task 5, Epoch 149/170 => Loss 3.629, Loss_clf 0.631, Loss_fe 0.455, Loss_kd 2.117, Train_accy 79.50, Test_accy 72.97
2024-08-07 16:30:52,571 [foster.py] => Task 5, Epoch 150/170 => Loss 3.602, Loss_clf 0.617, Loss_fe 0.437, Loss_kd 2.121, Train_accy 80.26, Test_accy 73.18
2024-08-07 16:31:00,035 [foster.py] => Task 5, Epoch 151/170 => Loss 3.555, Loss_clf 0.600, Loss_fe 0.422, Loss_kd 2.108, Train_accy 80.57
2024-08-07 16:31:10,137 [foster.py] => Task 5, Epoch 152/170 => Loss 3.488, Loss_clf 0.563, Loss_fe 0.404, Loss_kd 2.098, Train_accy 81.83, Test_accy 72.92
2024-08-07 16:31:19,862 [foster.py] => Task 5, Epoch 153/170 => Loss 3.556, Loss_clf 0.598, Loss_fe 0.425, Loss_kd 2.108, Train_accy 80.20, Test_accy 73.22
2024-08-07 16:31:29,761 [foster.py] => Task 5, Epoch 154/170 => Loss 3.532, Loss_clf 0.596, Loss_fe 0.404, Loss_kd 2.107, Train_accy 80.73, Test_accy 73.20
2024-08-07 16:31:39,489 [foster.py] => Task 5, Epoch 155/170 => Loss 3.527, Loss_clf 0.588, Loss_fe 0.415, Loss_kd 2.100, Train_accy 81.27, Test_accy 73.08
2024-08-07 16:31:47,117 [foster.py] => Task 5, Epoch 156/170 => Loss 3.523, Loss_clf 0.582, Loss_fe 0.416, Loss_kd 2.102, Train_accy 81.70
2024-08-07 16:31:56,745 [foster.py] => Task 5, Epoch 157/170 => Loss 3.507, Loss_clf 0.582, Loss_fe 0.399, Loss_kd 2.102, Train_accy 81.74, Test_accy 73.37
2024-08-07 16:32:06,420 [foster.py] => Task 5, Epoch 158/170 => Loss 3.506, Loss_clf 0.575, Loss_fe 0.398, Loss_kd 2.108, Train_accy 82.23, Test_accy 73.48
2024-08-07 16:32:16,172 [foster.py] => Task 5, Epoch 159/170 => Loss 3.503, Loss_clf 0.569, Loss_fe 0.405, Loss_kd 2.105, Train_accy 82.14, Test_accy 73.20
2024-08-07 16:32:25,870 [foster.py] => Task 5, Epoch 160/170 => Loss 3.514, Loss_clf 0.586, Loss_fe 0.405, Loss_kd 2.100, Train_accy 81.16, Test_accy 73.35
2024-08-07 16:32:33,533 [foster.py] => Task 5, Epoch 161/170 => Loss 3.510, Loss_clf 0.584, Loss_fe 0.394, Loss_kd 2.107, Train_accy 81.30
2024-08-07 16:32:43,250 [foster.py] => Task 5, Epoch 162/170 => Loss 3.470, Loss_clf 0.562, Loss_fe 0.384, Loss_kd 2.101, Train_accy 82.09, Test_accy 73.48
2024-08-07 16:32:52,985 [foster.py] => Task 5, Epoch 163/170 => Loss 3.449, Loss_clf 0.542, Loss_fe 0.374, Loss_kd 2.108, Train_accy 82.64, Test_accy 73.43
2024-08-07 16:33:02,669 [foster.py] => Task 5, Epoch 164/170 => Loss 3.516, Loss_clf 0.581, Loss_fe 0.402, Loss_kd 2.108, Train_accy 81.66, Test_accy 73.53
2024-08-07 16:33:12,379 [foster.py] => Task 5, Epoch 165/170 => Loss 3.483, Loss_clf 0.564, Loss_fe 0.387, Loss_kd 2.107, Train_accy 82.27, Test_accy 73.38
2024-08-07 16:33:19,891 [foster.py] => Task 5, Epoch 166/170 => Loss 3.498, Loss_clf 0.575, Loss_fe 0.388, Loss_kd 2.110, Train_accy 81.34
2024-08-07 16:33:29,620 [foster.py] => Task 5, Epoch 167/170 => Loss 3.530, Loss_clf 0.592, Loss_fe 0.406, Loss_kd 2.107, Train_accy 80.80, Test_accy 73.48
2024-08-07 16:33:39,453 [foster.py] => Task 5, Epoch 168/170 => Loss 3.460, Loss_clf 0.560, Loss_fe 0.367, Loss_kd 2.109, Train_accy 82.24, Test_accy 73.42
2024-08-07 16:33:49,490 [foster.py] => Task 5, Epoch 169/170 => Loss 3.455, Loss_clf 0.553, Loss_fe 0.374, Loss_kd 2.104, Train_accy 82.07, Test_accy 73.43
2024-08-07 16:33:59,245 [foster.py] => Task 5, Epoch 170/170 => Loss 3.496, Loss_clf 0.575, Loss_fe 0.386, Loss_kd 2.110, Train_accy 81.60, Test_accy 73.43
2024-08-07 16:33:59,250 [foster.py] => do not weight align teacher!
2024-08-07 16:33:59,253 [foster.py] => per cls weights : [1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521 1.05439521
 1.05439521 1.05439521 0.72802395 0.72802395 0.72802395 0.72802395
 0.72802395 0.72802395 0.72802395 0.72802395 0.72802395 0.72802395]
2024-08-07 16:34:12,034 [foster.py] => SNet: Task 5, Epoch 1/130 => Loss 28.213,  Loss1 0.701, Train_accy 35.74, Test_accy 62.43
2024-08-07 16:34:22,532 [foster.py] => SNet: Task 5, Epoch 2/130 => Loss 28.053,  Loss1 0.701, Train_accy 52.56
2024-08-07 16:34:33,358 [foster.py] => SNet: Task 5, Epoch 3/130 => Loss 28.035,  Loss1 0.701, Train_accy 57.20
2024-08-07 16:34:44,008 [foster.py] => SNet: Task 5, Epoch 4/130 => Loss 28.010,  Loss1 0.701, Train_accy 59.17
2024-08-07 16:34:54,396 [foster.py] => SNet: Task 5, Epoch 5/130 => Loss 28.000,  Loss1 0.701, Train_accy 60.60
2024-08-07 16:35:06,931 [foster.py] => SNet: Task 5, Epoch 6/130 => Loss 27.987,  Loss1 0.701, Train_accy 61.27, Test_accy 66.03
2024-08-07 16:35:17,410 [foster.py] => SNet: Task 5, Epoch 7/130 => Loss 28.016,  Loss1 0.701, Train_accy 62.57
2024-08-07 16:35:27,870 [foster.py] => SNet: Task 5, Epoch 8/130 => Loss 27.999,  Loss1 0.701, Train_accy 62.43
2024-08-07 16:35:38,396 [foster.py] => SNet: Task 5, Epoch 9/130 => Loss 27.990,  Loss1 0.701, Train_accy 64.49
2024-08-07 16:35:49,283 [foster.py] => SNet: Task 5, Epoch 10/130 => Loss 27.994,  Loss1 0.701, Train_accy 64.86
2024-08-07 16:36:01,636 [foster.py] => SNet: Task 5, Epoch 11/130 => Loss 27.972,  Loss1 0.701, Train_accy 65.71, Test_accy 66.83
2024-08-07 16:36:12,057 [foster.py] => SNet: Task 5, Epoch 12/130 => Loss 27.987,  Loss1 0.701, Train_accy 65.43
2024-08-07 16:36:22,454 [foster.py] => SNet: Task 5, Epoch 13/130 => Loss 27.987,  Loss1 0.701, Train_accy 65.06
2024-08-07 16:36:32,908 [foster.py] => SNet: Task 5, Epoch 14/130 => Loss 27.988,  Loss1 0.701, Train_accy 66.30
2024-08-07 16:36:43,339 [foster.py] => SNet: Task 5, Epoch 15/130 => Loss 27.970,  Loss1 0.701, Train_accy 66.30
2024-08-07 16:36:55,611 [foster.py] => SNet: Task 5, Epoch 16/130 => Loss 27.982,  Loss1 0.701, Train_accy 66.16, Test_accy 66.97
2024-08-07 16:37:06,128 [foster.py] => SNet: Task 5, Epoch 17/130 => Loss 27.950,  Loss1 0.701, Train_accy 67.36
2024-08-07 16:37:16,830 [foster.py] => SNet: Task 5, Epoch 18/130 => Loss 27.951,  Loss1 0.701, Train_accy 68.10
2024-08-07 16:37:27,272 [foster.py] => SNet: Task 5, Epoch 19/130 => Loss 27.957,  Loss1 0.701, Train_accy 67.64
2024-08-07 16:37:37,979 [foster.py] => SNet: Task 5, Epoch 20/130 => Loss 27.949,  Loss1 0.701, Train_accy 68.06
2024-08-07 16:37:50,255 [foster.py] => SNet: Task 5, Epoch 21/130 => Loss 27.946,  Loss1 0.701, Train_accy 68.44, Test_accy 68.32
2024-08-07 16:38:00,720 [foster.py] => SNet: Task 5, Epoch 22/130 => Loss 27.937,  Loss1 0.701, Train_accy 68.61
2024-08-07 16:38:11,140 [foster.py] => SNet: Task 5, Epoch 23/130 => Loss 27.961,  Loss1 0.701, Train_accy 68.61
2024-08-07 16:38:21,725 [foster.py] => SNet: Task 5, Epoch 24/130 => Loss 27.960,  Loss1 0.701, Train_accy 68.60
2024-08-07 16:38:32,062 [foster.py] => SNet: Task 5, Epoch 25/130 => Loss 27.951,  Loss1 0.701, Train_accy 69.20
2024-08-07 16:38:44,637 [foster.py] => SNet: Task 5, Epoch 26/130 => Loss 27.948,  Loss1 0.701, Train_accy 69.33, Test_accy 69.62
2024-08-07 16:38:55,058 [foster.py] => SNet: Task 5, Epoch 27/130 => Loss 27.946,  Loss1 0.701, Train_accy 69.39
2024-08-07 16:39:05,632 [foster.py] => SNet: Task 5, Epoch 28/130 => Loss 27.956,  Loss1 0.701, Train_accy 70.00
2024-08-07 16:39:16,055 [foster.py] => SNet: Task 5, Epoch 29/130 => Loss 27.946,  Loss1 0.701, Train_accy 68.99
2024-08-07 16:39:26,683 [foster.py] => SNet: Task 5, Epoch 30/130 => Loss 27.959,  Loss1 0.701, Train_accy 69.26
2024-08-07 16:39:39,161 [foster.py] => SNet: Task 5, Epoch 31/130 => Loss 27.925,  Loss1 0.701, Train_accy 70.40, Test_accy 69.33
2024-08-07 16:39:49,657 [foster.py] => SNet: Task 5, Epoch 32/130 => Loss 27.943,  Loss1 0.701, Train_accy 69.69
2024-08-07 16:40:00,260 [foster.py] => SNet: Task 5, Epoch 33/130 => Loss 27.926,  Loss1 0.701, Train_accy 68.86
2024-08-07 16:40:10,896 [foster.py] => SNet: Task 5, Epoch 34/130 => Loss 27.935,  Loss1 0.701, Train_accy 70.11
2024-08-07 16:40:21,295 [foster.py] => SNet: Task 5, Epoch 35/130 => Loss 27.951,  Loss1 0.701, Train_accy 69.31
2024-08-07 16:40:33,631 [foster.py] => SNet: Task 5, Epoch 36/130 => Loss 27.949,  Loss1 0.701, Train_accy 69.99, Test_accy 67.82
2024-08-07 16:40:44,222 [foster.py] => SNet: Task 5, Epoch 37/130 => Loss 27.956,  Loss1 0.701, Train_accy 69.36
2024-08-07 16:40:54,694 [foster.py] => SNet: Task 5, Epoch 38/130 => Loss 27.926,  Loss1 0.701, Train_accy 70.73
2024-08-07 16:41:05,123 [foster.py] => SNet: Task 5, Epoch 39/130 => Loss 27.941,  Loss1 0.701, Train_accy 71.26
2024-08-07 16:41:15,944 [foster.py] => SNet: Task 5, Epoch 40/130 => Loss 27.948,  Loss1 0.701, Train_accy 69.50
2024-08-07 16:41:28,471 [foster.py] => SNet: Task 5, Epoch 41/130 => Loss 27.928,  Loss1 0.701, Train_accy 70.91, Test_accy 69.88
2024-08-07 16:41:38,944 [foster.py] => SNet: Task 5, Epoch 42/130 => Loss 27.943,  Loss1 0.701, Train_accy 70.13
2024-08-07 16:41:49,330 [foster.py] => SNet: Task 5, Epoch 43/130 => Loss 27.935,  Loss1 0.701, Train_accy 71.17
2024-08-07 16:41:59,849 [foster.py] => SNet: Task 5, Epoch 44/130 => Loss 27.935,  Loss1 0.701, Train_accy 71.39
2024-08-07 16:42:10,470 [foster.py] => SNet: Task 5, Epoch 45/130 => Loss 27.933,  Loss1 0.701, Train_accy 71.21
2024-08-07 16:42:22,798 [foster.py] => SNet: Task 5, Epoch 46/130 => Loss 27.942,  Loss1 0.701, Train_accy 70.63, Test_accy 70.18
2024-08-07 16:42:33,509 [foster.py] => SNet: Task 5, Epoch 47/130 => Loss 27.913,  Loss1 0.701, Train_accy 71.01
2024-08-07 16:42:44,115 [foster.py] => SNet: Task 5, Epoch 48/130 => Loss 27.941,  Loss1 0.701, Train_accy 71.54
2024-08-07 16:42:54,645 [foster.py] => SNet: Task 5, Epoch 49/130 => Loss 27.915,  Loss1 0.701, Train_accy 71.96
2024-08-07 16:43:05,065 [foster.py] => SNet: Task 5, Epoch 50/130 => Loss 27.921,  Loss1 0.701, Train_accy 71.23
2024-08-07 16:43:17,557 [foster.py] => SNet: Task 5, Epoch 51/130 => Loss 27.932,  Loss1 0.701, Train_accy 71.89, Test_accy 70.35
2024-08-07 16:43:27,990 [foster.py] => SNet: Task 5, Epoch 52/130 => Loss 27.936,  Loss1 0.701, Train_accy 71.39
2024-08-07 16:43:38,478 [foster.py] => SNet: Task 5, Epoch 53/130 => Loss 27.941,  Loss1 0.701, Train_accy 71.97
2024-08-07 16:43:49,179 [foster.py] => SNet: Task 5, Epoch 54/130 => Loss 27.909,  Loss1 0.701, Train_accy 71.83
2024-08-07 16:43:59,903 [foster.py] => SNet: Task 5, Epoch 55/130 => Loss 27.943,  Loss1 0.701, Train_accy 70.83
2024-08-07 16:44:12,461 [foster.py] => SNet: Task 5, Epoch 56/130 => Loss 27.897,  Loss1 0.701, Train_accy 72.34, Test_accy 70.62
2024-08-07 16:44:22,990 [foster.py] => SNet: Task 5, Epoch 57/130 => Loss 27.901,  Loss1 0.701, Train_accy 73.04
2024-08-07 16:44:33,657 [foster.py] => SNet: Task 5, Epoch 58/130 => Loss 27.918,  Loss1 0.701, Train_accy 71.63
2024-08-07 16:44:44,024 [foster.py] => SNet: Task 5, Epoch 59/130 => Loss 27.908,  Loss1 0.701, Train_accy 71.97
2024-08-07 16:44:54,568 [foster.py] => SNet: Task 5, Epoch 60/130 => Loss 27.916,  Loss1 0.701, Train_accy 72.33
2024-08-07 16:45:06,889 [foster.py] => SNet: Task 5, Epoch 61/130 => Loss 27.930,  Loss1 0.701, Train_accy 72.64, Test_accy 70.70
2024-08-07 16:45:17,203 [foster.py] => SNet: Task 5, Epoch 62/130 => Loss 27.909,  Loss1 0.701, Train_accy 72.63
2024-08-07 16:45:27,887 [foster.py] => SNet: Task 5, Epoch 63/130 => Loss 27.926,  Loss1 0.701, Train_accy 72.94
2024-08-07 16:45:38,911 [foster.py] => SNet: Task 5, Epoch 64/130 => Loss 27.925,  Loss1 0.701, Train_accy 73.26
2024-08-07 16:45:49,471 [foster.py] => SNet: Task 5, Epoch 65/130 => Loss 27.927,  Loss1 0.701, Train_accy 73.27
2024-08-07 16:46:02,177 [foster.py] => SNet: Task 5, Epoch 66/130 => Loss 27.932,  Loss1 0.701, Train_accy 72.99, Test_accy 70.60
2024-08-07 16:46:12,906 [foster.py] => SNet: Task 5, Epoch 67/130 => Loss 27.934,  Loss1 0.701, Train_accy 72.07
2024-08-07 16:46:23,461 [foster.py] => SNet: Task 5, Epoch 68/130 => Loss 27.932,  Loss1 0.701, Train_accy 73.40
2024-08-07 16:46:34,286 [foster.py] => SNet: Task 5, Epoch 69/130 => Loss 27.920,  Loss1 0.701, Train_accy 72.87
2024-08-07 16:46:44,764 [foster.py] => SNet: Task 5, Epoch 70/130 => Loss 27.930,  Loss1 0.701, Train_accy 72.46
2024-08-07 16:46:57,127 [foster.py] => SNet: Task 5, Epoch 71/130 => Loss 27.899,  Loss1 0.701, Train_accy 73.27, Test_accy 70.45
2024-08-07 16:47:07,647 [foster.py] => SNet: Task 5, Epoch 72/130 => Loss 27.903,  Loss1 0.701, Train_accy 73.10
2024-08-07 16:47:18,285 [foster.py] => SNet: Task 5, Epoch 73/130 => Loss 27.935,  Loss1 0.701, Train_accy 73.37
2024-08-07 16:47:29,018 [foster.py] => SNet: Task 5, Epoch 74/130 => Loss 27.891,  Loss1 0.701, Train_accy 72.60
2024-08-07 16:47:39,568 [foster.py] => SNet: Task 5, Epoch 75/130 => Loss 27.911,  Loss1 0.701, Train_accy 73.11
2024-08-07 16:47:51,859 [foster.py] => SNet: Task 5, Epoch 76/130 => Loss 27.890,  Loss1 0.701, Train_accy 73.26, Test_accy 70.48
2024-08-07 16:48:02,379 [foster.py] => SNet: Task 5, Epoch 77/130 => Loss 27.915,  Loss1 0.701, Train_accy 73.94
2024-08-07 16:48:12,867 [foster.py] => SNet: Task 5, Epoch 78/130 => Loss 27.914,  Loss1 0.701, Train_accy 72.91
2024-08-07 16:48:23,379 [foster.py] => SNet: Task 5, Epoch 79/130 => Loss 27.921,  Loss1 0.701, Train_accy 73.94
2024-08-07 16:48:34,116 [foster.py] => SNet: Task 5, Epoch 80/130 => Loss 27.918,  Loss1 0.701, Train_accy 73.51
2024-08-07 16:48:46,393 [foster.py] => SNet: Task 5, Epoch 81/130 => Loss 27.919,  Loss1 0.701, Train_accy 73.66, Test_accy 70.72
2024-08-07 16:48:57,055 [foster.py] => SNet: Task 5, Epoch 82/130 => Loss 27.901,  Loss1 0.701, Train_accy 73.77
2024-08-07 16:49:07,607 [foster.py] => SNet: Task 5, Epoch 83/130 => Loss 27.906,  Loss1 0.701, Train_accy 74.61
2024-08-07 16:49:18,077 [foster.py] => SNet: Task 5, Epoch 84/130 => Loss 27.925,  Loss1 0.701, Train_accy 73.20
2024-08-07 16:49:28,797 [foster.py] => SNet: Task 5, Epoch 85/130 => Loss 27.919,  Loss1 0.701, Train_accy 73.70
2024-08-07 16:49:41,070 [foster.py] => SNet: Task 5, Epoch 86/130 => Loss 27.910,  Loss1 0.701, Train_accy 73.97, Test_accy 70.98
2024-08-07 16:49:51,571 [foster.py] => SNet: Task 5, Epoch 87/130 => Loss 27.904,  Loss1 0.701, Train_accy 72.94
2024-08-07 16:50:02,071 [foster.py] => SNet: Task 5, Epoch 88/130 => Loss 27.910,  Loss1 0.701, Train_accy 74.16
2024-08-07 16:50:12,568 [foster.py] => SNet: Task 5, Epoch 89/130 => Loss 27.898,  Loss1 0.701, Train_accy 74.24
2024-08-07 16:50:23,005 [foster.py] => SNet: Task 5, Epoch 90/130 => Loss 27.907,  Loss1 0.701, Train_accy 74.54
2024-08-07 16:50:35,558 [foster.py] => SNet: Task 5, Epoch 91/130 => Loss 27.920,  Loss1 0.701, Train_accy 72.87, Test_accy 70.90
2024-08-07 16:50:46,337 [foster.py] => SNet: Task 5, Epoch 92/130 => Loss 27.891,  Loss1 0.701, Train_accy 74.66
2024-08-07 16:50:57,065 [foster.py] => SNet: Task 5, Epoch 93/130 => Loss 27.901,  Loss1 0.701, Train_accy 73.61
2024-08-07 16:51:07,444 [foster.py] => SNet: Task 5, Epoch 94/130 => Loss 27.896,  Loss1 0.701, Train_accy 74.07
2024-08-07 16:51:17,930 [foster.py] => SNet: Task 5, Epoch 95/130 => Loss 27.902,  Loss1 0.701, Train_accy 73.84
2024-08-07 16:51:30,266 [foster.py] => SNet: Task 5, Epoch 96/130 => Loss 27.907,  Loss1 0.701, Train_accy 74.47, Test_accy 71.07
2024-08-07 16:51:41,001 [foster.py] => SNet: Task 5, Epoch 97/130 => Loss 27.905,  Loss1 0.701, Train_accy 73.60
2024-08-07 16:51:51,455 [foster.py] => SNet: Task 5, Epoch 98/130 => Loss 27.902,  Loss1 0.701, Train_accy 73.39
2024-08-07 16:52:01,852 [foster.py] => SNet: Task 5, Epoch 99/130 => Loss 27.907,  Loss1 0.701, Train_accy 73.44
2024-08-07 16:52:12,413 [foster.py] => SNet: Task 5, Epoch 100/130 => Loss 27.923,  Loss1 0.701, Train_accy 73.91
2024-08-07 16:52:24,724 [foster.py] => SNet: Task 5, Epoch 101/130 => Loss 27.933,  Loss1 0.701, Train_accy 73.97, Test_accy 71.27
2024-08-07 16:52:35,451 [foster.py] => SNet: Task 5, Epoch 102/130 => Loss 27.933,  Loss1 0.701, Train_accy 73.09
2024-08-07 16:52:45,956 [foster.py] => SNet: Task 5, Epoch 103/130 => Loss 27.889,  Loss1 0.701, Train_accy 74.36
2024-08-07 16:52:56,556 [foster.py] => SNet: Task 5, Epoch 104/130 => Loss 27.920,  Loss1 0.701, Train_accy 74.57
2024-08-07 16:53:07,269 [foster.py] => SNet: Task 5, Epoch 105/130 => Loss 27.916,  Loss1 0.701, Train_accy 74.51
2024-08-07 16:53:19,603 [foster.py] => SNet: Task 5, Epoch 106/130 => Loss 27.913,  Loss1 0.701, Train_accy 74.07, Test_accy 71.35
2024-08-07 16:53:30,166 [foster.py] => SNet: Task 5, Epoch 107/130 => Loss 27.909,  Loss1 0.701, Train_accy 74.36
2024-08-07 16:53:40,522 [foster.py] => SNet: Task 5, Epoch 108/130 => Loss 27.903,  Loss1 0.701, Train_accy 74.60
2024-08-07 16:53:51,000 [foster.py] => SNet: Task 5, Epoch 109/130 => Loss 27.928,  Loss1 0.701, Train_accy 73.40
2024-08-07 16:54:01,616 [foster.py] => SNet: Task 5, Epoch 110/130 => Loss 27.901,  Loss1 0.701, Train_accy 74.56
2024-08-07 16:54:14,065 [foster.py] => SNet: Task 5, Epoch 111/130 => Loss 27.894,  Loss1 0.701, Train_accy 74.00, Test_accy 71.43
2024-08-07 16:54:24,534 [foster.py] => SNet: Task 5, Epoch 112/130 => Loss 27.895,  Loss1 0.701, Train_accy 74.50
2024-08-07 16:54:34,928 [foster.py] => SNet: Task 5, Epoch 113/130 => Loss 27.900,  Loss1 0.701, Train_accy 73.99
2024-08-07 16:54:45,368 [foster.py] => SNet: Task 5, Epoch 114/130 => Loss 27.894,  Loss1 0.701, Train_accy 74.51
2024-08-07 16:54:56,228 [foster.py] => SNet: Task 5, Epoch 115/130 => Loss 27.897,  Loss1 0.701, Train_accy 74.53
2024-08-07 16:55:08,594 [foster.py] => SNet: Task 5, Epoch 116/130 => Loss 27.932,  Loss1 0.701, Train_accy 74.41, Test_accy 71.32
2024-08-07 16:55:19,279 [foster.py] => SNet: Task 5, Epoch 117/130 => Loss 27.914,  Loss1 0.701, Train_accy 73.14
2024-08-07 16:55:29,738 [foster.py] => SNet: Task 5, Epoch 118/130 => Loss 27.901,  Loss1 0.701, Train_accy 74.66
2024-08-07 16:55:40,546 [foster.py] => SNet: Task 5, Epoch 119/130 => Loss 27.939,  Loss1 0.701, Train_accy 73.94
2024-08-07 16:55:51,192 [foster.py] => SNet: Task 5, Epoch 120/130 => Loss 27.911,  Loss1 0.701, Train_accy 74.80
2024-08-07 16:56:03,701 [foster.py] => SNet: Task 5, Epoch 121/130 => Loss 27.912,  Loss1 0.701, Train_accy 74.21, Test_accy 71.35
2024-08-07 16:56:14,437 [foster.py] => SNet: Task 5, Epoch 122/130 => Loss 27.926,  Loss1 0.701, Train_accy 74.73
2024-08-07 16:56:24,882 [foster.py] => SNet: Task 5, Epoch 123/130 => Loss 27.933,  Loss1 0.701, Train_accy 73.70
2024-08-07 16:56:35,413 [foster.py] => SNet: Task 5, Epoch 124/130 => Loss 27.904,  Loss1 0.701, Train_accy 74.54
2024-08-07 16:56:46,298 [foster.py] => SNet: Task 5, Epoch 125/130 => Loss 27.904,  Loss1 0.701, Train_accy 74.04
2024-08-07 16:56:58,869 [foster.py] => SNet: Task 5, Epoch 126/130 => Loss 27.906,  Loss1 0.701, Train_accy 74.57, Test_accy 71.48
2024-08-07 16:57:09,508 [foster.py] => SNet: Task 5, Epoch 127/130 => Loss 27.894,  Loss1 0.701, Train_accy 74.29
2024-08-07 16:57:19,930 [foster.py] => SNet: Task 5, Epoch 128/130 => Loss 27.924,  Loss1 0.701, Train_accy 74.67
2024-08-07 16:57:30,385 [foster.py] => SNet: Task 5, Epoch 129/130 => Loss 27.907,  Loss1 0.701, Train_accy 74.74
2024-08-07 16:57:41,050 [foster.py] => SNet: Task 5, Epoch 130/130 => Loss 27.905,  Loss1 0.701, Train_accy 73.67
2024-08-07 16:57:41,050 [foster.py] => do not weight align student!
2024-08-07 16:57:42,894 [foster.py] => darknet eval: 
2024-08-07 16:57:42,895 [foster.py] => CNN top1 curve: 71.37
2024-08-07 16:57:42,896 [foster.py] => CNN top5 curve: 92.75
2024-08-07 16:57:42,896 [foster.py] => CNN top1 平均值: 71.37
2024-08-07 16:57:42,901 [foster.py] => timees : 3007.5481283664703
2024-08-07 16:57:42,903 [base.py] => Reducing exemplars...(33 per classes)
2024-08-07 16:58:00,278 [base.py] => Constructing exemplars...(33 per classes)
2024-08-07 16:58:14,964 [foster.py] => Exemplar size: 1980
2024-08-07 16:58:14,965 [trainer.py] => CNN: {'total': 73.43, '00-09': 72.9, '10-19': 64.5, '20-29': 74.5, '30-39': 73.0, '40-49': 77.3, '50-59': 78.4, 'old': 72.44, 'new': 78.4}
2024-08-07 16:58:14,965 [trainer.py] => NME: {'total': 69.15, '00-09': 66.0, '10-19': 61.5, '20-29': 69.6, '30-39': 68.5, '40-49': 67.7, '50-59': 81.6, 'old': 66.66, 'new': 81.6}
2024-08-07 16:58:14,966 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54, 73.43]
2024-08-07 16:58:14,966 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64, 93.48]
2024-08-07 16:58:14,966 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1, 69.15]
2024-08-07 16:58:14,967 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06, 91.73]

2024-08-07 16:58:14,967 [trainer.py] => CNN top1 平均值: 81.68
2024-08-07 16:58:14,970 [trainer.py] => All params: 1297438
2024-08-07 16:58:14,973 [trainer.py] => Trainable params: 652914
2024-08-07 16:58:15,036 [foster.py] => Learning on 60-70
2024-08-07 16:58:15,039 [foster.py] => All params: 1300028
2024-08-07 16:58:15,042 [foster.py] => Trainable params: 654854
2024-08-07 16:58:15,106 [foster.py] => per cls weights : [1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536 1.04319536
 0.74082783 0.74082783 0.74082783 0.74082783 0.74082783 0.74082783
 0.74082783 0.74082783 0.74082783 0.74082783]
2024-08-07 16:58:22,979 [foster.py] => Task 6, Epoch 1/170 => Loss 9.569, Loss_clf 4.865, Loss_fe 1.982, Loss_kd 2.329, Train_accy 42.81
2024-08-07 16:58:32,938 [foster.py] => Task 6, Epoch 2/170 => Loss 5.793, Loss_clf 1.631, Loss_fe 1.488, Loss_kd 2.288, Train_accy 56.52, Test_accy 65.63
2024-08-07 16:58:42,862 [foster.py] => Task 6, Epoch 3/170 => Loss 5.525, Loss_clf 1.498, Loss_fe 1.347, Loss_kd 2.293, Train_accy 57.23, Test_accy 63.89
2024-08-07 16:58:52,854 [foster.py] => Task 6, Epoch 4/170 => Loss 5.501, Loss_clf 1.507, Loss_fe 1.314, Loss_kd 2.294, Train_accy 57.15, Test_accy 62.47
2024-08-07 16:59:02,719 [foster.py] => Task 6, Epoch 5/170 => Loss 5.293, Loss_clf 1.375, Loss_fe 1.233, Loss_kd 2.297, Train_accy 58.80, Test_accy 65.21
2024-08-07 16:59:10,262 [foster.py] => Task 6, Epoch 6/170 => Loss 5.452, Loss_clf 1.482, Loss_fe 1.272, Loss_kd 2.309, Train_accy 57.85
2024-08-07 16:59:20,178 [foster.py] => Task 6, Epoch 7/170 => Loss 5.319, Loss_clf 1.447, Loss_fe 1.196, Loss_kd 2.291, Train_accy 58.94, Test_accy 64.79
2024-08-07 16:59:30,094 [foster.py] => Task 6, Epoch 8/170 => Loss 5.332, Loss_clf 1.431, Loss_fe 1.210, Loss_kd 2.302, Train_accy 60.36, Test_accy 65.71
2024-08-07 16:59:39,974 [foster.py] => Task 6, Epoch 9/170 => Loss 5.235, Loss_clf 1.386, Loss_fe 1.165, Loss_kd 2.297, Train_accy 60.36, Test_accy 64.03
2024-08-07 16:59:50,025 [foster.py] => Task 6, Epoch 10/170 => Loss 5.254, Loss_clf 1.362, Loss_fe 1.199, Loss_kd 2.305, Train_accy 60.69, Test_accy 67.03
2024-08-07 16:59:57,761 [foster.py] => Task 6, Epoch 11/170 => Loss 5.119, Loss_clf 1.269, Loss_fe 1.162, Loss_kd 2.300, Train_accy 61.00
2024-08-07 17:00:07,688 [foster.py] => Task 6, Epoch 12/170 => Loss 5.041, Loss_clf 1.225, Loss_fe 1.124, Loss_kd 2.304, Train_accy 61.35, Test_accy 66.26
2024-08-07 17:00:17,534 [foster.py] => Task 6, Epoch 13/170 => Loss 5.153, Loss_clf 1.336, Loss_fe 1.143, Loss_kd 2.289, Train_accy 60.82, Test_accy 63.97
2024-08-07 17:00:27,370 [foster.py] => Task 6, Epoch 14/170 => Loss 5.134, Loss_clf 1.286, Loss_fe 1.143, Loss_kd 2.315, Train_accy 60.64, Test_accy 65.53
2024-08-07 17:00:37,200 [foster.py] => Task 6, Epoch 15/170 => Loss 5.104, Loss_clf 1.294, Loss_fe 1.126, Loss_kd 2.298, Train_accy 61.65, Test_accy 64.43
2024-08-07 17:00:44,863 [foster.py] => Task 6, Epoch 16/170 => Loss 5.093, Loss_clf 1.257, Loss_fe 1.157, Loss_kd 2.293, Train_accy 62.12
2024-08-07 17:00:54,789 [foster.py] => Task 6, Epoch 17/170 => Loss 5.138, Loss_clf 1.317, Loss_fe 1.124, Loss_kd 2.308, Train_accy 61.16, Test_accy 66.14
2024-08-07 17:01:04,686 [foster.py] => Task 6, Epoch 18/170 => Loss 5.213, Loss_clf 1.352, Loss_fe 1.179, Loss_kd 2.295, Train_accy 60.23, Test_accy 65.74
2024-08-07 17:01:14,570 [foster.py] => Task 6, Epoch 19/170 => Loss 5.082, Loss_clf 1.266, Loss_fe 1.127, Loss_kd 2.302, Train_accy 61.69, Test_accy 66.77
2024-08-07 17:01:24,522 [foster.py] => Task 6, Epoch 20/170 => Loss 5.041, Loss_clf 1.269, Loss_fe 1.083, Loss_kd 2.302, Train_accy 62.26, Test_accy 65.64
2024-08-07 17:01:32,155 [foster.py] => Task 6, Epoch 21/170 => Loss 5.073, Loss_clf 1.295, Loss_fe 1.089, Loss_kd 2.302, Train_accy 61.35
2024-08-07 17:01:42,013 [foster.py] => Task 6, Epoch 22/170 => Loss 5.030, Loss_clf 1.255, Loss_fe 1.094, Loss_kd 2.295, Train_accy 62.09, Test_accy 65.46
2024-08-07 17:01:51,977 [foster.py] => Task 6, Epoch 23/170 => Loss 4.948, Loss_clf 1.189, Loss_fe 1.069, Loss_kd 2.301, Train_accy 62.52, Test_accy 66.34
2024-08-07 17:02:01,852 [foster.py] => Task 6, Epoch 24/170 => Loss 5.045, Loss_clf 1.275, Loss_fe 1.083, Loss_kd 2.299, Train_accy 61.68, Test_accy 66.84
2024-08-07 17:02:11,783 [foster.py] => Task 6, Epoch 25/170 => Loss 5.028, Loss_clf 1.249, Loss_fe 1.081, Loss_kd 2.309, Train_accy 62.03, Test_accy 66.53
2024-08-07 17:02:19,332 [foster.py] => Task 6, Epoch 26/170 => Loss 5.063, Loss_clf 1.290, Loss_fe 1.096, Loss_kd 2.291, Train_accy 61.65
2024-08-07 17:02:29,171 [foster.py] => Task 6, Epoch 27/170 => Loss 4.931, Loss_clf 1.202, Loss_fe 1.050, Loss_kd 2.293, Train_accy 63.97, Test_accy 67.80
2024-08-07 17:02:39,056 [foster.py] => Task 6, Epoch 28/170 => Loss 4.968, Loss_clf 1.201, Loss_fe 1.081, Loss_kd 2.299, Train_accy 61.93, Test_accy 65.94
2024-08-07 17:02:49,016 [foster.py] => Task 6, Epoch 29/170 => Loss 4.964, Loss_clf 1.207, Loss_fe 1.066, Loss_kd 2.303, Train_accy 62.45, Test_accy 67.89
2024-08-07 17:02:58,908 [foster.py] => Task 6, Epoch 30/170 => Loss 4.866, Loss_clf 1.175, Loss_fe 1.014, Loss_kd 2.292, Train_accy 64.10, Test_accy 64.60
2024-08-07 17:03:06,456 [foster.py] => Task 6, Epoch 31/170 => Loss 5.144, Loss_clf 1.319, Loss_fe 1.113, Loss_kd 2.320, Train_accy 61.38
2024-08-07 17:03:16,454 [foster.py] => Task 6, Epoch 32/170 => Loss 5.019, Loss_clf 1.263, Loss_fe 1.070, Loss_kd 2.299, Train_accy 62.99, Test_accy 66.83
2024-08-07 17:03:26,315 [foster.py] => Task 6, Epoch 33/170 => Loss 4.971, Loss_clf 1.217, Loss_fe 1.062, Loss_kd 2.305, Train_accy 62.64, Test_accy 66.91
2024-08-07 17:03:36,223 [foster.py] => Task 6, Epoch 34/170 => Loss 4.862, Loss_clf 1.173, Loss_fe 1.018, Loss_kd 2.286, Train_accy 63.04, Test_accy 63.13
2024-08-07 17:03:46,080 [foster.py] => Task 6, Epoch 35/170 => Loss 4.947, Loss_clf 1.211, Loss_fe 1.043, Loss_kd 2.304, Train_accy 62.08, Test_accy 64.96
2024-08-07 17:03:53,673 [foster.py] => Task 6, Epoch 36/170 => Loss 4.871, Loss_clf 1.135, Loss_fe 1.037, Loss_kd 2.310, Train_accy 64.53
2024-08-07 17:04:03,510 [foster.py] => Task 6, Epoch 37/170 => Loss 4.956, Loss_clf 1.233, Loss_fe 1.038, Loss_kd 2.297, Train_accy 62.36, Test_accy 66.27
2024-08-07 17:04:13,477 [foster.py] => Task 6, Epoch 38/170 => Loss 4.856, Loss_clf 1.155, Loss_fe 1.019, Loss_kd 2.295, Train_accy 64.17, Test_accy 62.89
2024-08-07 17:04:23,365 [foster.py] => Task 6, Epoch 39/170 => Loss 4.887, Loss_clf 1.170, Loss_fe 1.033, Loss_kd 2.297, Train_accy 63.62, Test_accy 66.09
2024-08-07 17:04:33,327 [foster.py] => Task 6, Epoch 40/170 => Loss 4.888, Loss_clf 1.183, Loss_fe 1.020, Loss_kd 2.298, Train_accy 63.08, Test_accy 67.73
2024-08-07 17:04:40,940 [foster.py] => Task 6, Epoch 41/170 => Loss 4.846, Loss_clf 1.136, Loss_fe 1.020, Loss_kd 2.303, Train_accy 62.82
2024-08-07 17:04:50,959 [foster.py] => Task 6, Epoch 42/170 => Loss 4.978, Loss_clf 1.267, Loss_fe 1.022, Loss_kd 2.302, Train_accy 62.36, Test_accy 66.59
2024-08-07 17:05:00,867 [foster.py] => Task 6, Epoch 43/170 => Loss 4.785, Loss_clf 1.129, Loss_fe 0.985, Loss_kd 2.286, Train_accy 64.67, Test_accy 66.26
2024-08-07 17:05:10,699 [foster.py] => Task 6, Epoch 44/170 => Loss 4.770, Loss_clf 1.110, Loss_fe 0.979, Loss_kd 2.295, Train_accy 64.47, Test_accy 66.80
2024-08-07 17:05:20,640 [foster.py] => Task 6, Epoch 45/170 => Loss 4.833, Loss_clf 1.151, Loss_fe 0.999, Loss_kd 2.296, Train_accy 64.23, Test_accy 65.70
2024-08-07 17:05:28,203 [foster.py] => Task 6, Epoch 46/170 => Loss 4.759, Loss_clf 1.102, Loss_fe 0.975, Loss_kd 2.295, Train_accy 64.74
2024-08-07 17:05:38,114 [foster.py] => Task 6, Epoch 47/170 => Loss 4.767, Loss_clf 1.119, Loss_fe 0.977, Loss_kd 2.286, Train_accy 65.03, Test_accy 64.10
2024-08-07 17:05:47,955 [foster.py] => Task 6, Epoch 48/170 => Loss 4.770, Loss_clf 1.112, Loss_fe 0.978, Loss_kd 2.294, Train_accy 64.61, Test_accy 67.07
2024-08-07 17:05:57,860 [foster.py] => Task 6, Epoch 49/170 => Loss 4.751, Loss_clf 1.096, Loss_fe 0.970, Loss_kd 2.298, Train_accy 64.91, Test_accy 67.90
2024-08-07 17:06:07,679 [foster.py] => Task 6, Epoch 50/170 => Loss 4.745, Loss_clf 1.095, Loss_fe 0.970, Loss_kd 2.293, Train_accy 64.57, Test_accy 66.69
2024-08-07 17:06:15,380 [foster.py] => Task 6, Epoch 51/170 => Loss 4.733, Loss_clf 1.086, Loss_fe 0.944, Loss_kd 2.313, Train_accy 64.87
2024-08-07 17:06:25,570 [foster.py] => Task 6, Epoch 52/170 => Loss 4.759, Loss_clf 1.105, Loss_fe 0.965, Loss_kd 2.301, Train_accy 64.23, Test_accy 64.09
2024-08-07 17:06:35,705 [foster.py] => Task 6, Epoch 53/170 => Loss 4.783, Loss_clf 1.125, Loss_fe 0.979, Loss_kd 2.293, Train_accy 63.88, Test_accy 67.71
2024-08-07 17:06:45,605 [foster.py] => Task 6, Epoch 54/170 => Loss 4.747, Loss_clf 1.111, Loss_fe 0.954, Loss_kd 2.296, Train_accy 64.13, Test_accy 66.94
2024-08-07 17:06:55,545 [foster.py] => Task 6, Epoch 55/170 => Loss 4.764, Loss_clf 1.121, Loss_fe 0.956, Loss_kd 2.299, Train_accy 64.58, Test_accy 65.19
2024-08-07 17:07:03,081 [foster.py] => Task 6, Epoch 56/170 => Loss 4.790, Loss_clf 1.151, Loss_fe 0.948, Loss_kd 2.303, Train_accy 63.78
2024-08-07 17:07:13,038 [foster.py] => Task 6, Epoch 57/170 => Loss 4.779, Loss_clf 1.095, Loss_fe 0.993, Loss_kd 2.303, Train_accy 64.71, Test_accy 67.84
2024-08-07 17:07:22,919 [foster.py] => Task 6, Epoch 58/170 => Loss 4.768, Loss_clf 1.112, Loss_fe 0.975, Loss_kd 2.294, Train_accy 64.96, Test_accy 66.19
2024-08-07 17:07:32,763 [foster.py] => Task 6, Epoch 59/170 => Loss 4.732, Loss_clf 1.101, Loss_fe 0.951, Loss_kd 2.294, Train_accy 64.66, Test_accy 67.87
2024-08-07 17:07:42,738 [foster.py] => Task 6, Epoch 60/170 => Loss 4.732, Loss_clf 1.102, Loss_fe 0.954, Loss_kd 2.290, Train_accy 64.70, Test_accy 67.91
2024-08-07 17:07:50,467 [foster.py] => Task 6, Epoch 61/170 => Loss 4.636, Loss_clf 1.047, Loss_fe 0.906, Loss_kd 2.296, Train_accy 64.89
2024-08-07 17:08:00,392 [foster.py] => Task 6, Epoch 62/170 => Loss 4.650, Loss_clf 1.073, Loss_fe 0.901, Loss_kd 2.290, Train_accy 66.06, Test_accy 67.89
2024-08-07 17:08:10,579 [foster.py] => Task 6, Epoch 63/170 => Loss 4.789, Loss_clf 1.150, Loss_fe 0.945, Loss_kd 2.306, Train_accy 64.36, Test_accy 66.61
2024-08-07 17:08:20,477 [foster.py] => Task 6, Epoch 64/170 => Loss 4.685, Loss_clf 1.064, Loss_fe 0.934, Loss_kd 2.299, Train_accy 65.86, Test_accy 68.20
2024-08-07 17:08:30,382 [foster.py] => Task 6, Epoch 65/170 => Loss 4.667, Loss_clf 1.068, Loss_fe 0.913, Loss_kd 2.300, Train_accy 66.59, Test_accy 68.36
2024-08-07 17:08:38,020 [foster.py] => Task 6, Epoch 66/170 => Loss 4.559, Loss_clf 0.997, Loss_fe 0.886, Loss_kd 2.291, Train_accy 66.96
2024-08-07 17:08:47,926 [foster.py] => Task 6, Epoch 67/170 => Loss 4.693, Loss_clf 1.084, Loss_fe 0.923, Loss_kd 2.299, Train_accy 65.69, Test_accy 67.47
2024-08-07 17:08:57,908 [foster.py] => Task 6, Epoch 68/170 => Loss 4.652, Loss_clf 1.077, Loss_fe 0.901, Loss_kd 2.289, Train_accy 64.87, Test_accy 66.76
2024-08-07 17:09:07,776 [foster.py] => Task 6, Epoch 69/170 => Loss 4.657, Loss_clf 1.066, Loss_fe 0.916, Loss_kd 2.290, Train_accy 65.64, Test_accy 67.76
2024-08-07 17:09:17,678 [foster.py] => Task 6, Epoch 70/170 => Loss 4.603, Loss_clf 1.024, Loss_fe 0.905, Loss_kd 2.288, Train_accy 66.53, Test_accy 65.80
2024-08-07 17:09:25,206 [foster.py] => Task 6, Epoch 71/170 => Loss 4.608, Loss_clf 1.036, Loss_fe 0.892, Loss_kd 2.294, Train_accy 66.53
2024-08-07 17:09:35,146 [foster.py] => Task 6, Epoch 72/170 => Loss 4.544, Loss_clf 0.995, Loss_fe 0.872, Loss_kd 2.292, Train_accy 66.75, Test_accy 68.33
2024-08-07 17:09:45,217 [foster.py] => Task 6, Epoch 73/170 => Loss 4.518, Loss_clf 0.974, Loss_fe 0.871, Loss_kd 2.288, Train_accy 66.75, Test_accy 67.19
2024-08-07 17:09:55,414 [foster.py] => Task 6, Epoch 74/170 => Loss 4.489, Loss_clf 0.983, Loss_fe 0.838, Loss_kd 2.284, Train_accy 66.35, Test_accy 66.64
2024-08-07 17:10:05,644 [foster.py] => Task 6, Epoch 75/170 => Loss 4.569, Loss_clf 1.029, Loss_fe 0.871, Loss_kd 2.284, Train_accy 66.46, Test_accy 66.87
2024-08-07 17:10:13,312 [foster.py] => Task 6, Epoch 76/170 => Loss 4.499, Loss_clf 0.983, Loss_fe 0.850, Loss_kd 2.282, Train_accy 66.82
2024-08-07 17:10:23,278 [foster.py] => Task 6, Epoch 77/170 => Loss 4.516, Loss_clf 0.990, Loss_fe 0.849, Loss_kd 2.291, Train_accy 66.66, Test_accy 63.90
2024-08-07 17:10:33,185 [foster.py] => Task 6, Epoch 78/170 => Loss 4.528, Loss_clf 0.993, Loss_fe 0.859, Loss_kd 2.290, Train_accy 67.34, Test_accy 67.04
2024-08-07 17:10:43,134 [foster.py] => Task 6, Epoch 79/170 => Loss 4.581, Loss_clf 1.032, Loss_fe 0.863, Loss_kd 2.298, Train_accy 66.49, Test_accy 67.61
2024-08-07 17:10:53,038 [foster.py] => Task 6, Epoch 80/170 => Loss 4.493, Loss_clf 0.994, Loss_fe 0.816, Loss_kd 2.296, Train_accy 67.02, Test_accy 66.70
2024-08-07 17:11:00,639 [foster.py] => Task 6, Epoch 81/170 => Loss 4.468, Loss_clf 0.955, Loss_fe 0.832, Loss_kd 2.295, Train_accy 68.05
2024-08-07 17:11:10,605 [foster.py] => Task 6, Epoch 82/170 => Loss 4.471, Loss_clf 0.954, Loss_fe 0.839, Loss_kd 2.293, Train_accy 68.07, Test_accy 67.96
2024-08-07 17:11:20,577 [foster.py] => Task 6, Epoch 83/170 => Loss 4.485, Loss_clf 0.971, Loss_fe 0.832, Loss_kd 2.296, Train_accy 67.34, Test_accy 66.49
2024-08-07 17:11:30,484 [foster.py] => Task 6, Epoch 84/170 => Loss 4.430, Loss_clf 0.940, Loss_fe 0.809, Loss_kd 2.294, Train_accy 67.95, Test_accy 68.56
2024-08-07 17:11:40,361 [foster.py] => Task 6, Epoch 85/170 => Loss 4.336, Loss_clf 0.897, Loss_fe 0.773, Loss_kd 2.282, Train_accy 68.80, Test_accy 67.60
2024-08-07 17:11:47,894 [foster.py] => Task 6, Epoch 86/170 => Loss 4.375, Loss_clf 0.914, Loss_fe 0.783, Loss_kd 2.293, Train_accy 68.90
2024-08-07 17:11:57,770 [foster.py] => Task 6, Epoch 87/170 => Loss 4.425, Loss_clf 0.942, Loss_fe 0.805, Loss_kd 2.292, Train_accy 68.27, Test_accy 67.47
2024-08-07 17:12:07,731 [foster.py] => Task 6, Epoch 88/170 => Loss 4.389, Loss_clf 0.933, Loss_fe 0.781, Loss_kd 2.290, Train_accy 68.97, Test_accy 68.31
2024-08-07 17:12:17,621 [foster.py] => Task 6, Epoch 89/170 => Loss 4.404, Loss_clf 0.934, Loss_fe 0.794, Loss_kd 2.291, Train_accy 69.04, Test_accy 67.64
2024-08-07 17:12:27,575 [foster.py] => Task 6, Epoch 90/170 => Loss 4.376, Loss_clf 0.914, Loss_fe 0.772, Loss_kd 2.302, Train_accy 69.04, Test_accy 68.11
2024-08-07 17:12:35,120 [foster.py] => Task 6, Epoch 91/170 => Loss 4.369, Loss_clf 0.903, Loss_fe 0.790, Loss_kd 2.291, Train_accy 68.28
2024-08-07 17:12:45,012 [foster.py] => Task 6, Epoch 92/170 => Loss 4.359, Loss_clf 0.920, Loss_fe 0.766, Loss_kd 2.288, Train_accy 68.67, Test_accy 66.49
2024-08-07 17:12:54,916 [foster.py] => Task 6, Epoch 93/170 => Loss 4.414, Loss_clf 0.950, Loss_fe 0.778, Loss_kd 2.298, Train_accy 69.20, Test_accy 69.49
2024-08-07 17:13:04,872 [foster.py] => Task 6, Epoch 94/170 => Loss 4.287, Loss_clf 0.892, Loss_fe 0.728, Loss_kd 2.283, Train_accy 70.21, Test_accy 66.63
2024-08-07 17:13:14,986 [foster.py] => Task 6, Epoch 95/170 => Loss 4.363, Loss_clf 0.919, Loss_fe 0.762, Loss_kd 2.296, Train_accy 69.33, Test_accy 69.74
2024-08-07 17:13:22,902 [foster.py] => Task 6, Epoch 96/170 => Loss 4.284, Loss_clf 0.877, Loss_fe 0.742, Loss_kd 2.281, Train_accy 70.01
2024-08-07 17:13:33,039 [foster.py] => Task 6, Epoch 97/170 => Loss 4.348, Loss_clf 0.922, Loss_fe 0.751, Loss_kd 2.289, Train_accy 69.37, Test_accy 67.79
2024-08-07 17:13:43,077 [foster.py] => Task 6, Epoch 98/170 => Loss 4.285, Loss_clf 0.881, Loss_fe 0.727, Loss_kd 2.291, Train_accy 70.10, Test_accy 68.53
2024-08-07 17:13:52,912 [foster.py] => Task 6, Epoch 99/170 => Loss 4.304, Loss_clf 0.879, Loss_fe 0.747, Loss_kd 2.292, Train_accy 70.50, Test_accy 67.87
2024-08-07 17:14:02,727 [foster.py] => Task 6, Epoch 100/170 => Loss 4.248, Loss_clf 0.855, Loss_fe 0.729, Loss_kd 2.280, Train_accy 70.33, Test_accy 69.03
2024-08-07 17:14:10,316 [foster.py] => Task 6, Epoch 101/170 => Loss 4.235, Loss_clf 0.852, Loss_fe 0.707, Loss_kd 2.291, Train_accy 70.66
2024-08-07 17:14:20,239 [foster.py] => Task 6, Epoch 102/170 => Loss 4.225, Loss_clf 0.837, Loss_fe 0.715, Loss_kd 2.288, Train_accy 71.03, Test_accy 69.67
2024-08-07 17:14:30,083 [foster.py] => Task 6, Epoch 103/170 => Loss 4.201, Loss_clf 0.828, Loss_fe 0.705, Loss_kd 2.283, Train_accy 71.15, Test_accy 69.86
2024-08-07 17:14:39,934 [foster.py] => Task 6, Epoch 104/170 => Loss 4.123, Loss_clf 0.795, Loss_fe 0.665, Loss_kd 2.280, Train_accy 71.62, Test_accy 69.89
2024-08-07 17:14:49,826 [foster.py] => Task 6, Epoch 105/170 => Loss 4.290, Loss_clf 0.898, Loss_fe 0.709, Loss_kd 2.297, Train_accy 70.79, Test_accy 68.70
2024-08-07 17:14:57,461 [foster.py] => Task 6, Epoch 106/170 => Loss 4.258, Loss_clf 0.877, Loss_fe 0.703, Loss_kd 2.293, Train_accy 70.74
2024-08-07 17:15:07,412 [foster.py] => Task 6, Epoch 107/170 => Loss 4.193, Loss_clf 0.832, Loss_fe 0.692, Loss_kd 2.285, Train_accy 71.81, Test_accy 69.19
2024-08-07 17:15:17,394 [foster.py] => Task 6, Epoch 108/170 => Loss 4.134, Loss_clf 0.799, Loss_fe 0.660, Loss_kd 2.289, Train_accy 72.49, Test_accy 69.40
2024-08-07 17:15:27,309 [foster.py] => Task 6, Epoch 109/170 => Loss 4.130, Loss_clf 0.804, Loss_fe 0.650, Loss_kd 2.290, Train_accy 71.50, Test_accy 69.46
2024-08-07 17:15:37,164 [foster.py] => Task 6, Epoch 110/170 => Loss 4.169, Loss_clf 0.826, Loss_fe 0.668, Loss_kd 2.289, Train_accy 71.92, Test_accy 69.79
2024-08-07 17:15:44,737 [foster.py] => Task 6, Epoch 111/170 => Loss 4.162, Loss_clf 0.822, Loss_fe 0.669, Loss_kd 2.286, Train_accy 72.82
2024-08-07 17:15:54,653 [foster.py] => Task 6, Epoch 112/170 => Loss 4.106, Loss_clf 0.803, Loss_fe 0.635, Loss_kd 2.283, Train_accy 72.02, Test_accy 68.36
2024-08-07 17:16:04,586 [foster.py] => Task 6, Epoch 113/170 => Loss 4.088, Loss_clf 0.789, Loss_fe 0.638, Loss_kd 2.277, Train_accy 72.56, Test_accy 69.31
2024-08-07 17:16:14,545 [foster.py] => Task 6, Epoch 114/170 => Loss 4.062, Loss_clf 0.766, Loss_fe 0.625, Loss_kd 2.286, Train_accy 73.02, Test_accy 69.84
2024-08-07 17:16:24,507 [foster.py] => Task 6, Epoch 115/170 => Loss 4.065, Loss_clf 0.766, Loss_fe 0.625, Loss_kd 2.288, Train_accy 73.81, Test_accy 69.57
2024-08-07 17:16:32,054 [foster.py] => Task 6, Epoch 116/170 => Loss 4.038, Loss_clf 0.756, Loss_fe 0.619, Loss_kd 2.279, Train_accy 73.72
2024-08-07 17:16:41,983 [foster.py] => Task 6, Epoch 117/170 => Loss 4.107, Loss_clf 0.792, Loss_fe 0.629, Loss_kd 2.299, Train_accy 72.72, Test_accy 69.76
2024-08-07 17:16:51,810 [foster.py] => Task 6, Epoch 118/170 => Loss 4.021, Loss_clf 0.760, Loss_fe 0.596, Loss_kd 2.281, Train_accy 73.54, Test_accy 69.56
2024-08-07 17:17:01,939 [foster.py] => Task 6, Epoch 119/170 => Loss 4.006, Loss_clf 0.741, Loss_fe 0.589, Loss_kd 2.291, Train_accy 74.18, Test_accy 69.69
2024-08-07 17:17:11,997 [foster.py] => Task 6, Epoch 120/170 => Loss 3.988, Loss_clf 0.741, Loss_fe 0.582, Loss_kd 2.281, Train_accy 74.13, Test_accy 69.97
2024-08-07 17:17:19,694 [foster.py] => Task 6, Epoch 121/170 => Loss 3.994, Loss_clf 0.742, Loss_fe 0.585, Loss_kd 2.283, Train_accy 74.10
2024-08-07 17:17:29,598 [foster.py] => Task 6, Epoch 122/170 => Loss 3.977, Loss_clf 0.725, Loss_fe 0.590, Loss_kd 2.279, Train_accy 74.80, Test_accy 69.74
2024-08-07 17:17:39,562 [foster.py] => Task 6, Epoch 123/170 => Loss 4.005, Loss_clf 0.750, Loss_fe 0.584, Loss_kd 2.286, Train_accy 74.01, Test_accy 69.96
2024-08-07 17:17:49,419 [foster.py] => Task 6, Epoch 124/170 => Loss 3.942, Loss_clf 0.715, Loss_fe 0.558, Loss_kd 2.285, Train_accy 76.09, Test_accy 70.00
2024-08-07 17:17:59,390 [foster.py] => Task 6, Epoch 125/170 => Loss 3.919, Loss_clf 0.703, Loss_fe 0.550, Loss_kd 2.282, Train_accy 74.79, Test_accy 70.84
2024-08-07 17:18:06,983 [foster.py] => Task 6, Epoch 126/170 => Loss 3.969, Loss_clf 0.729, Loss_fe 0.571, Loss_kd 2.284, Train_accy 75.16
2024-08-07 17:18:16,822 [foster.py] => Task 6, Epoch 127/170 => Loss 3.922, Loss_clf 0.703, Loss_fe 0.541, Loss_kd 2.292, Train_accy 76.07, Test_accy 70.47
2024-08-07 17:18:26,759 [foster.py] => Task 6, Epoch 128/170 => Loss 3.902, Loss_clf 0.696, Loss_fe 0.530, Loss_kd 2.291, Train_accy 76.38, Test_accy 69.99
2024-08-07 17:18:36,664 [foster.py] => Task 6, Epoch 129/170 => Loss 3.925, Loss_clf 0.711, Loss_fe 0.551, Loss_kd 2.280, Train_accy 75.77, Test_accy 70.57
2024-08-07 17:18:46,581 [foster.py] => Task 6, Epoch 130/170 => Loss 3.864, Loss_clf 0.679, Loss_fe 0.521, Loss_kd 2.280, Train_accy 76.17, Test_accy 70.21
2024-08-07 17:18:54,125 [foster.py] => Task 6, Epoch 131/170 => Loss 3.826, Loss_clf 0.662, Loss_fe 0.494, Loss_kd 2.286, Train_accy 76.65
2024-08-07 17:19:04,020 [foster.py] => Task 6, Epoch 132/170 => Loss 3.846, Loss_clf 0.661, Loss_fe 0.514, Loss_kd 2.287, Train_accy 76.16, Test_accy 70.17
2024-08-07 17:19:13,904 [foster.py] => Task 6, Epoch 133/170 => Loss 3.805, Loss_clf 0.652, Loss_fe 0.489, Loss_kd 2.280, Train_accy 76.40, Test_accy 70.23
2024-08-07 17:19:23,893 [foster.py] => Task 6, Epoch 134/170 => Loss 3.830, Loss_clf 0.666, Loss_fe 0.501, Loss_kd 2.280, Train_accy 77.05, Test_accy 70.53
2024-08-07 17:19:33,794 [foster.py] => Task 6, Epoch 135/170 => Loss 3.792, Loss_clf 0.647, Loss_fe 0.482, Loss_kd 2.280, Train_accy 76.78, Test_accy 70.61
2024-08-07 17:19:41,479 [foster.py] => Task 6, Epoch 136/170 => Loss 3.819, Loss_clf 0.664, Loss_fe 0.480, Loss_kd 2.290, Train_accy 77.58
2024-08-07 17:19:51,536 [foster.py] => Task 6, Epoch 137/170 => Loss 3.757, Loss_clf 0.631, Loss_fe 0.465, Loss_kd 2.278, Train_accy 78.38, Test_accy 70.90
2024-08-07 17:20:01,455 [foster.py] => Task 6, Epoch 138/170 => Loss 3.738, Loss_clf 0.621, Loss_fe 0.460, Loss_kd 2.275, Train_accy 78.78, Test_accy 70.23
2024-08-07 17:20:11,364 [foster.py] => Task 6, Epoch 139/170 => Loss 3.744, Loss_clf 0.614, Loss_fe 0.462, Loss_kd 2.284, Train_accy 78.84, Test_accy 70.89
2024-08-07 17:20:21,231 [foster.py] => Task 6, Epoch 140/170 => Loss 3.730, Loss_clf 0.619, Loss_fe 0.449, Loss_kd 2.279, Train_accy 78.38, Test_accy 71.21
2024-08-07 17:20:28,750 [foster.py] => Task 6, Epoch 141/170 => Loss 3.740, Loss_clf 0.626, Loss_fe 0.445, Loss_kd 2.285, Train_accy 78.45
2024-08-07 17:20:38,796 [foster.py] => Task 6, Epoch 142/170 => Loss 3.772, Loss_clf 0.641, Loss_fe 0.454, Loss_kd 2.292, Train_accy 78.38, Test_accy 71.17
2024-08-07 17:20:48,704 [foster.py] => Task 6, Epoch 143/170 => Loss 3.739, Loss_clf 0.624, Loss_fe 0.441, Loss_kd 2.289, Train_accy 78.51, Test_accy 71.26
2024-08-07 17:20:58,806 [foster.py] => Task 6, Epoch 144/170 => Loss 3.692, Loss_clf 0.608, Loss_fe 0.410, Loss_kd 2.289, Train_accy 79.61, Test_accy 71.21
2024-08-07 17:21:08,822 [foster.py] => Task 6, Epoch 145/170 => Loss 3.722, Loss_clf 0.612, Loss_fe 0.436, Loss_kd 2.289, Train_accy 79.47, Test_accy 71.27
2024-08-07 17:21:16,419 [foster.py] => Task 6, Epoch 146/170 => Loss 3.702, Loss_clf 0.606, Loss_fe 0.423, Loss_kd 2.287, Train_accy 79.26
2024-08-07 17:21:26,471 [foster.py] => Task 6, Epoch 147/170 => Loss 3.689, Loss_clf 0.593, Loss_fe 0.421, Loss_kd 2.290, Train_accy 79.64, Test_accy 71.17
2024-08-07 17:21:36,363 [foster.py] => Task 6, Epoch 148/170 => Loss 3.646, Loss_clf 0.578, Loss_fe 0.402, Loss_kd 2.282, Train_accy 80.79, Test_accy 70.71
2024-08-07 17:21:46,349 [foster.py] => Task 6, Epoch 149/170 => Loss 3.651, Loss_clf 0.586, Loss_fe 0.399, Loss_kd 2.282, Train_accy 79.33, Test_accy 71.24
2024-08-07 17:21:56,305 [foster.py] => Task 6, Epoch 150/170 => Loss 3.606, Loss_clf 0.556, Loss_fe 0.396, Loss_kd 2.272, Train_accy 80.14, Test_accy 71.17
2024-08-07 17:22:03,832 [foster.py] => Task 6, Epoch 151/170 => Loss 3.657, Loss_clf 0.585, Loss_fe 0.409, Loss_kd 2.279, Train_accy 79.46
2024-08-07 17:22:13,800 [foster.py] => Task 6, Epoch 152/170 => Loss 3.637, Loss_clf 0.574, Loss_fe 0.396, Loss_kd 2.283, Train_accy 79.96, Test_accy 71.16
2024-08-07 17:22:23,645 [foster.py] => Task 6, Epoch 153/170 => Loss 3.610, Loss_clf 0.562, Loss_fe 0.379, Loss_kd 2.284, Train_accy 81.35, Test_accy 71.14
2024-08-07 17:22:33,689 [foster.py] => Task 6, Epoch 154/170 => Loss 3.612, Loss_clf 0.553, Loss_fe 0.384, Loss_kd 2.289, Train_accy 81.32, Test_accy 71.39
2024-08-07 17:22:43,879 [foster.py] => Task 6, Epoch 155/170 => Loss 3.610, Loss_clf 0.566, Loss_fe 0.373, Loss_kd 2.287, Train_accy 81.07, Test_accy 71.40
2024-08-07 17:22:51,370 [foster.py] => Task 6, Epoch 156/170 => Loss 3.621, Loss_clf 0.572, Loss_fe 0.376, Loss_kd 2.288, Train_accy 80.53
2024-08-07 17:23:01,223 [foster.py] => Task 6, Epoch 157/170 => Loss 3.597, Loss_clf 0.557, Loss_fe 0.376, Loss_kd 2.281, Train_accy 80.85, Test_accy 71.41
2024-08-07 17:23:11,113 [foster.py] => Task 6, Epoch 158/170 => Loss 3.590, Loss_clf 0.555, Loss_fe 0.373, Loss_kd 2.278, Train_accy 80.85, Test_accy 71.40
2024-08-07 17:23:21,029 [foster.py] => Task 6, Epoch 159/170 => Loss 3.588, Loss_clf 0.550, Loss_fe 0.365, Loss_kd 2.288, Train_accy 81.68, Test_accy 71.50
2024-08-07 17:23:30,964 [foster.py] => Task 6, Epoch 160/170 => Loss 3.607, Loss_clf 0.564, Loss_fe 0.378, Loss_kd 2.281, Train_accy 80.92, Test_accy 71.40
2024-08-07 17:23:38,538 [foster.py] => Task 6, Epoch 161/170 => Loss 3.565, Loss_clf 0.546, Loss_fe 0.352, Loss_kd 2.283, Train_accy 81.63
2024-08-07 17:23:48,411 [foster.py] => Task 6, Epoch 162/170 => Loss 3.584, Loss_clf 0.555, Loss_fe 0.364, Loss_kd 2.281, Train_accy 80.82, Test_accy 71.39
2024-08-07 17:23:58,416 [foster.py] => Task 6, Epoch 163/170 => Loss 3.559, Loss_clf 0.538, Loss_fe 0.362, Loss_kd 2.277, Train_accy 80.80, Test_accy 71.50
2024-08-07 17:24:08,357 [foster.py] => Task 6, Epoch 164/170 => Loss 3.575, Loss_clf 0.536, Loss_fe 0.355, Loss_kd 2.298, Train_accy 82.13, Test_accy 71.47
2024-08-07 17:24:18,310 [foster.py] => Task 6, Epoch 165/170 => Loss 3.583, Loss_clf 0.556, Loss_fe 0.359, Loss_kd 2.284, Train_accy 80.82, Test_accy 71.51
2024-08-07 17:24:25,904 [foster.py] => Task 6, Epoch 166/170 => Loss 3.538, Loss_clf 0.528, Loss_fe 0.348, Loss_kd 2.279, Train_accy 81.79
2024-08-07 17:24:35,885 [foster.py] => Task 6, Epoch 167/170 => Loss 3.547, Loss_clf 0.527, Loss_fe 0.345, Loss_kd 2.290, Train_accy 81.76, Test_accy 71.49
2024-08-07 17:24:45,799 [foster.py] => Task 6, Epoch 168/170 => Loss 3.566, Loss_clf 0.547, Loss_fe 0.354, Loss_kd 2.282, Train_accy 80.62, Test_accy 71.47
2024-08-07 17:24:55,703 [foster.py] => Task 6, Epoch 169/170 => Loss 3.573, Loss_clf 0.545, Loss_fe 0.359, Loss_kd 2.285, Train_accy 81.88, Test_accy 71.46
2024-08-07 17:25:05,614 [foster.py] => Task 6, Epoch 170/170 => Loss 3.593, Loss_clf 0.552, Loss_fe 0.372, Loss_kd 2.284, Train_accy 81.25, Test_accy 71.44
2024-08-07 17:25:05,618 [foster.py] => do not weight align teacher!
2024-08-07 17:25:05,620 [foster.py] => per cls weights : [1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918 1.05603918
 0.66376494 0.66376494 0.66376494 0.66376494 0.66376494 0.66376494
 0.66376494 0.66376494 0.66376494 0.66376494]
2024-08-07 17:25:18,437 [foster.py] => SNet: Task 6, Epoch 1/130 => Loss 29.303,  Loss1 0.728, Train_accy 37.23, Test_accy 63.67
2024-08-07 17:25:28,945 [foster.py] => SNet: Task 6, Epoch 2/130 => Loss 29.148,  Loss1 0.729, Train_accy 53.77
2024-08-07 17:25:39,606 [foster.py] => SNet: Task 6, Epoch 3/130 => Loss 29.118,  Loss1 0.730, Train_accy 58.74
2024-08-07 17:25:50,244 [foster.py] => SNet: Task 6, Epoch 4/130 => Loss 29.068,  Loss1 0.730, Train_accy 60.66
2024-08-07 17:26:00,695 [foster.py] => SNet: Task 6, Epoch 5/130 => Loss 29.074,  Loss1 0.730, Train_accy 61.96
2024-08-07 17:26:13,190 [foster.py] => SNet: Task 6, Epoch 6/130 => Loss 29.069,  Loss1 0.731, Train_accy 62.52, Test_accy 66.39
2024-08-07 17:26:23,837 [foster.py] => SNet: Task 6, Epoch 7/130 => Loss 29.087,  Loss1 0.730, Train_accy 63.62
2024-08-07 17:26:34,306 [foster.py] => SNet: Task 6, Epoch 8/130 => Loss 29.065,  Loss1 0.730, Train_accy 63.24
2024-08-07 17:26:44,929 [foster.py] => SNet: Task 6, Epoch 9/130 => Loss 29.084,  Loss1 0.731, Train_accy 62.87
2024-08-07 17:26:55,491 [foster.py] => SNet: Task 6, Epoch 10/130 => Loss 29.057,  Loss1 0.730, Train_accy 64.27
2024-08-07 17:27:08,222 [foster.py] => SNet: Task 6, Epoch 11/130 => Loss 29.051,  Loss1 0.731, Train_accy 64.84, Test_accy 67.40
2024-08-07 17:27:18,702 [foster.py] => SNet: Task 6, Epoch 12/130 => Loss 29.064,  Loss1 0.731, Train_accy 63.88
2024-08-07 17:27:29,404 [foster.py] => SNet: Task 6, Epoch 13/130 => Loss 29.057,  Loss1 0.731, Train_accy 65.13
2024-08-07 17:27:39,803 [foster.py] => SNet: Task 6, Epoch 14/130 => Loss 29.046,  Loss1 0.730, Train_accy 65.95
2024-08-07 17:27:50,281 [foster.py] => SNet: Task 6, Epoch 15/130 => Loss 29.078,  Loss1 0.731, Train_accy 65.43
2024-08-07 17:28:02,965 [foster.py] => SNet: Task 6, Epoch 16/130 => Loss 29.060,  Loss1 0.731, Train_accy 66.83, Test_accy 67.06
2024-08-07 17:28:13,502 [foster.py] => SNet: Task 6, Epoch 17/130 => Loss 29.052,  Loss1 0.731, Train_accy 66.58
2024-08-07 17:28:24,005 [foster.py] => SNet: Task 6, Epoch 18/130 => Loss 29.048,  Loss1 0.731, Train_accy 67.15
2024-08-07 17:28:34,793 [foster.py] => SNet: Task 6, Epoch 19/130 => Loss 29.035,  Loss1 0.731, Train_accy 66.48
2024-08-07 17:28:45,221 [foster.py] => SNet: Task 6, Epoch 20/130 => Loss 29.053,  Loss1 0.731, Train_accy 66.91
2024-08-07 17:28:57,940 [foster.py] => SNet: Task 6, Epoch 21/130 => Loss 29.051,  Loss1 0.731, Train_accy 66.78, Test_accy 67.96
2024-08-07 17:29:08,408 [foster.py] => SNet: Task 6, Epoch 22/130 => Loss 29.032,  Loss1 0.731, Train_accy 66.88
2024-08-07 17:29:19,070 [foster.py] => SNet: Task 6, Epoch 23/130 => Loss 29.045,  Loss1 0.731, Train_accy 67.39
2024-08-07 17:29:29,774 [foster.py] => SNet: Task 6, Epoch 24/130 => Loss 29.062,  Loss1 0.731, Train_accy 67.54
2024-08-07 17:29:40,582 [foster.py] => SNet: Task 6, Epoch 25/130 => Loss 29.042,  Loss1 0.731, Train_accy 67.64
2024-08-07 17:29:53,071 [foster.py] => SNet: Task 6, Epoch 26/130 => Loss 29.044,  Loss1 0.731, Train_accy 67.58, Test_accy 67.41
2024-08-07 17:30:03,695 [foster.py] => SNet: Task 6, Epoch 27/130 => Loss 29.039,  Loss1 0.731, Train_accy 67.44
2024-08-07 17:30:14,131 [foster.py] => SNet: Task 6, Epoch 28/130 => Loss 29.042,  Loss1 0.731, Train_accy 68.68
2024-08-07 17:30:24,547 [foster.py] => SNet: Task 6, Epoch 29/130 => Loss 29.025,  Loss1 0.731, Train_accy 68.81
2024-08-07 17:30:35,319 [foster.py] => SNet: Task 6, Epoch 30/130 => Loss 29.034,  Loss1 0.731, Train_accy 68.32
2024-08-07 17:30:48,045 [foster.py] => SNet: Task 6, Epoch 31/130 => Loss 29.026,  Loss1 0.731, Train_accy 68.60, Test_accy 68.07
2024-08-07 17:30:58,681 [foster.py] => SNet: Task 6, Epoch 32/130 => Loss 29.029,  Loss1 0.731, Train_accy 68.27
2024-08-07 17:31:09,273 [foster.py] => SNet: Task 6, Epoch 33/130 => Loss 29.024,  Loss1 0.731, Train_accy 68.51
2024-08-07 17:31:19,732 [foster.py] => SNet: Task 6, Epoch 34/130 => Loss 29.021,  Loss1 0.731, Train_accy 69.53
2024-08-07 17:31:30,164 [foster.py] => SNet: Task 6, Epoch 35/130 => Loss 29.014,  Loss1 0.731, Train_accy 68.90
2024-08-07 17:31:42,684 [foster.py] => SNet: Task 6, Epoch 36/130 => Loss 29.023,  Loss1 0.731, Train_accy 69.13, Test_accy 67.79
2024-08-07 17:31:53,066 [foster.py] => SNet: Task 6, Epoch 37/130 => Loss 29.024,  Loss1 0.731, Train_accy 69.51
2024-08-07 17:32:03,912 [foster.py] => SNet: Task 6, Epoch 38/130 => Loss 29.018,  Loss1 0.731, Train_accy 69.36
2024-08-07 17:32:14,342 [foster.py] => SNet: Task 6, Epoch 39/130 => Loss 29.034,  Loss1 0.731, Train_accy 70.34
2024-08-07 17:32:25,138 [foster.py] => SNet: Task 6, Epoch 40/130 => Loss 29.040,  Loss1 0.731, Train_accy 69.87
2024-08-07 17:32:37,798 [foster.py] => SNet: Task 6, Epoch 41/130 => Loss 29.013,  Loss1 0.731, Train_accy 68.98, Test_accy 68.37
2024-08-07 17:32:48,193 [foster.py] => SNet: Task 6, Epoch 42/130 => Loss 29.012,  Loss1 0.731, Train_accy 69.56
2024-08-07 17:32:58,812 [foster.py] => SNet: Task 6, Epoch 43/130 => Loss 29.018,  Loss1 0.731, Train_accy 68.95
2024-08-07 17:33:09,515 [foster.py] => SNet: Task 6, Epoch 44/130 => Loss 29.028,  Loss1 0.731, Train_accy 70.42
2024-08-07 17:33:19,883 [foster.py] => SNet: Task 6, Epoch 45/130 => Loss 29.024,  Loss1 0.731, Train_accy 69.93
2024-08-07 17:33:32,386 [foster.py] => SNet: Task 6, Epoch 46/130 => Loss 29.032,  Loss1 0.731, Train_accy 69.67, Test_accy 68.27
2024-08-07 17:33:43,047 [foster.py] => SNet: Task 6, Epoch 47/130 => Loss 29.033,  Loss1 0.731, Train_accy 70.96
2024-08-07 17:33:53,936 [foster.py] => SNet: Task 6, Epoch 48/130 => Loss 29.049,  Loss1 0.731, Train_accy 69.60
2024-08-07 17:34:04,688 [foster.py] => SNet: Task 6, Epoch 49/130 => Loss 29.009,  Loss1 0.731, Train_accy 70.33
2024-08-07 17:34:15,450 [foster.py] => SNet: Task 6, Epoch 50/130 => Loss 29.037,  Loss1 0.731, Train_accy 70.07
2024-08-07 17:34:27,957 [foster.py] => SNet: Task 6, Epoch 51/130 => Loss 29.028,  Loss1 0.731, Train_accy 70.00, Test_accy 68.77
2024-08-07 17:34:38,410 [foster.py] => SNet: Task 6, Epoch 52/130 => Loss 29.043,  Loss1 0.731, Train_accy 69.58
2024-08-07 17:34:48,889 [foster.py] => SNet: Task 6, Epoch 53/130 => Loss 29.032,  Loss1 0.731, Train_accy 70.56
2024-08-07 17:34:59,371 [foster.py] => SNet: Task 6, Epoch 54/130 => Loss 29.012,  Loss1 0.731, Train_accy 69.76
2024-08-07 17:35:09,808 [foster.py] => SNet: Task 6, Epoch 55/130 => Loss 29.034,  Loss1 0.731, Train_accy 70.82
2024-08-07 17:35:22,665 [foster.py] => SNet: Task 6, Epoch 56/130 => Loss 29.023,  Loss1 0.731, Train_accy 69.94, Test_accy 68.90
2024-08-07 17:35:33,095 [foster.py] => SNet: Task 6, Epoch 57/130 => Loss 29.032,  Loss1 0.731, Train_accy 69.70
2024-08-07 17:35:43,595 [foster.py] => SNet: Task 6, Epoch 58/130 => Loss 29.018,  Loss1 0.731, Train_accy 70.07
2024-08-07 17:35:53,939 [foster.py] => SNet: Task 6, Epoch 59/130 => Loss 29.017,  Loss1 0.731, Train_accy 71.72
2024-08-07 17:36:04,318 [foster.py] => SNet: Task 6, Epoch 60/130 => Loss 29.038,  Loss1 0.731, Train_accy 70.21
2024-08-07 17:36:16,734 [foster.py] => SNet: Task 6, Epoch 61/130 => Loss 29.032,  Loss1 0.731, Train_accy 70.82, Test_accy 68.86
2024-08-07 17:36:27,164 [foster.py] => SNet: Task 6, Epoch 62/130 => Loss 29.035,  Loss1 0.731, Train_accy 70.49
2024-08-07 17:36:37,575 [foster.py] => SNet: Task 6, Epoch 63/130 => Loss 29.023,  Loss1 0.731, Train_accy 71.33
2024-08-07 17:36:48,414 [foster.py] => SNet: Task 6, Epoch 64/130 => Loss 29.032,  Loss1 0.731, Train_accy 70.96
2024-08-07 17:36:58,818 [foster.py] => SNet: Task 6, Epoch 65/130 => Loss 29.025,  Loss1 0.731, Train_accy 71.40
2024-08-07 17:37:11,408 [foster.py] => SNet: Task 6, Epoch 66/130 => Loss 29.020,  Loss1 0.731, Train_accy 70.72, Test_accy 69.11
2024-08-07 17:37:21,816 [foster.py] => SNet: Task 6, Epoch 67/130 => Loss 28.990,  Loss1 0.731, Train_accy 71.86
2024-08-07 17:37:32,199 [foster.py] => SNet: Task 6, Epoch 68/130 => Loss 29.032,  Loss1 0.732, Train_accy 71.20
2024-08-07 17:37:42,592 [foster.py] => SNet: Task 6, Epoch 69/130 => Loss 28.993,  Loss1 0.731, Train_accy 71.85
2024-08-07 17:37:53,239 [foster.py] => SNet: Task 6, Epoch 70/130 => Loss 29.026,  Loss1 0.731, Train_accy 71.26
2024-08-07 17:38:05,600 [foster.py] => SNet: Task 6, Epoch 71/130 => Loss 29.032,  Loss1 0.731, Train_accy 71.15, Test_accy 69.27
2024-08-07 17:38:16,081 [foster.py] => SNet: Task 6, Epoch 72/130 => Loss 29.015,  Loss1 0.731, Train_accy 71.75
2024-08-07 17:38:26,663 [foster.py] => SNet: Task 6, Epoch 73/130 => Loss 29.008,  Loss1 0.731, Train_accy 71.62
2024-08-07 17:38:37,377 [foster.py] => SNet: Task 6, Epoch 74/130 => Loss 29.006,  Loss1 0.731, Train_accy 70.87
2024-08-07 17:38:47,822 [foster.py] => SNet: Task 6, Epoch 75/130 => Loss 29.016,  Loss1 0.731, Train_accy 71.68
2024-08-07 17:39:00,547 [foster.py] => SNet: Task 6, Epoch 76/130 => Loss 28.997,  Loss1 0.731, Train_accy 71.19, Test_accy 69.30
2024-08-07 17:39:11,158 [foster.py] => SNet: Task 6, Epoch 77/130 => Loss 29.021,  Loss1 0.731, Train_accy 70.95
2024-08-07 17:39:21,635 [foster.py] => SNet: Task 6, Epoch 78/130 => Loss 29.003,  Loss1 0.731, Train_accy 71.56
2024-08-07 17:39:32,367 [foster.py] => SNet: Task 6, Epoch 79/130 => Loss 29.012,  Loss1 0.731, Train_accy 71.79
2024-08-07 17:39:43,000 [foster.py] => SNet: Task 6, Epoch 80/130 => Loss 28.997,  Loss1 0.731, Train_accy 71.91
2024-08-07 17:39:55,830 [foster.py] => SNet: Task 6, Epoch 81/130 => Loss 29.023,  Loss1 0.731, Train_accy 71.48, Test_accy 69.46
2024-08-07 17:40:06,273 [foster.py] => SNet: Task 6, Epoch 82/130 => Loss 29.020,  Loss1 0.731, Train_accy 71.66
2024-08-07 17:40:16,958 [foster.py] => SNet: Task 6, Epoch 83/130 => Loss 29.013,  Loss1 0.731, Train_accy 71.28
2024-08-07 17:40:27,363 [foster.py] => SNet: Task 6, Epoch 84/130 => Loss 29.016,  Loss1 0.731, Train_accy 71.62
2024-08-07 17:40:37,901 [foster.py] => SNet: Task 6, Epoch 85/130 => Loss 29.005,  Loss1 0.731, Train_accy 71.43
2024-08-07 17:40:50,491 [foster.py] => SNet: Task 6, Epoch 86/130 => Loss 29.001,  Loss1 0.731, Train_accy 72.85, Test_accy 69.21
2024-08-07 17:41:01,099 [foster.py] => SNet: Task 6, Epoch 87/130 => Loss 28.997,  Loss1 0.731, Train_accy 72.51
2024-08-07 17:41:11,638 [foster.py] => SNet: Task 6, Epoch 88/130 => Loss 29.011,  Loss1 0.731, Train_accy 71.82
2024-08-07 17:41:22,191 [foster.py] => SNet: Task 6, Epoch 89/130 => Loss 29.001,  Loss1 0.731, Train_accy 73.42
2024-08-07 17:41:32,550 [foster.py] => SNet: Task 6, Epoch 90/130 => Loss 29.007,  Loss1 0.731, Train_accy 72.26
2024-08-07 17:41:45,562 [foster.py] => SNet: Task 6, Epoch 91/130 => Loss 29.015,  Loss1 0.731, Train_accy 71.43, Test_accy 69.40
2024-08-07 17:41:55,972 [foster.py] => SNet: Task 6, Epoch 92/130 => Loss 29.022,  Loss1 0.731, Train_accy 72.48
2024-08-07 17:42:06,602 [foster.py] => SNet: Task 6, Epoch 93/130 => Loss 29.001,  Loss1 0.731, Train_accy 72.02
2024-08-07 17:42:17,073 [foster.py] => SNet: Task 6, Epoch 94/130 => Loss 29.015,  Loss1 0.731, Train_accy 71.73
2024-08-07 17:42:27,492 [foster.py] => SNet: Task 6, Epoch 95/130 => Loss 29.004,  Loss1 0.731, Train_accy 71.76
2024-08-07 17:42:40,568 [foster.py] => SNet: Task 6, Epoch 96/130 => Loss 28.998,  Loss1 0.731, Train_accy 72.38, Test_accy 69.21
2024-08-07 17:42:50,988 [foster.py] => SNet: Task 6, Epoch 97/130 => Loss 29.005,  Loss1 0.731, Train_accy 72.52
2024-08-07 17:43:01,396 [foster.py] => SNet: Task 6, Epoch 98/130 => Loss 28.993,  Loss1 0.731, Train_accy 71.52
2024-08-07 17:43:12,102 [foster.py] => SNet: Task 6, Epoch 99/130 => Loss 29.010,  Loss1 0.731, Train_accy 72.85
2024-08-07 17:43:22,535 [foster.py] => SNet: Task 6, Epoch 100/130 => Loss 28.999,  Loss1 0.731, Train_accy 72.18
2024-08-07 17:43:34,965 [foster.py] => SNet: Task 6, Epoch 101/130 => Loss 28.996,  Loss1 0.731, Train_accy 72.42, Test_accy 69.33
2024-08-07 17:43:45,434 [foster.py] => SNet: Task 6, Epoch 102/130 => Loss 29.020,  Loss1 0.731, Train_accy 71.79
2024-08-07 17:43:56,402 [foster.py] => SNet: Task 6, Epoch 103/130 => Loss 28.990,  Loss1 0.731, Train_accy 72.58
2024-08-07 17:44:06,970 [foster.py] => SNet: Task 6, Epoch 104/130 => Loss 29.016,  Loss1 0.731, Train_accy 71.83
2024-08-07 17:44:17,674 [foster.py] => SNet: Task 6, Epoch 105/130 => Loss 29.012,  Loss1 0.731, Train_accy 71.28
2024-08-07 17:44:30,288 [foster.py] => SNet: Task 6, Epoch 106/130 => Loss 29.000,  Loss1 0.731, Train_accy 72.58, Test_accy 69.39
2024-08-07 17:44:40,717 [foster.py] => SNet: Task 6, Epoch 107/130 => Loss 28.999,  Loss1 0.731, Train_accy 72.05
2024-08-07 17:44:51,330 [foster.py] => SNet: Task 6, Epoch 108/130 => Loss 28.998,  Loss1 0.731, Train_accy 72.68
2024-08-07 17:45:01,760 [foster.py] => SNet: Task 6, Epoch 109/130 => Loss 29.036,  Loss1 0.731, Train_accy 71.30
2024-08-07 17:45:12,368 [foster.py] => SNet: Task 6, Epoch 110/130 => Loss 29.010,  Loss1 0.731, Train_accy 72.55
2024-08-07 17:45:25,200 [foster.py] => SNet: Task 6, Epoch 111/130 => Loss 28.995,  Loss1 0.731, Train_accy 71.92, Test_accy 69.39
2024-08-07 17:45:36,176 [foster.py] => SNet: Task 6, Epoch 112/130 => Loss 28.985,  Loss1 0.731, Train_accy 72.62
2024-08-07 17:45:46,545 [foster.py] => SNet: Task 6, Epoch 113/130 => Loss 29.023,  Loss1 0.731, Train_accy 72.42
2024-08-07 17:45:57,102 [foster.py] => SNet: Task 6, Epoch 114/130 => Loss 29.001,  Loss1 0.731, Train_accy 71.17
2024-08-07 17:46:07,551 [foster.py] => SNet: Task 6, Epoch 115/130 => Loss 29.020,  Loss1 0.731, Train_accy 71.89
2024-08-07 17:46:20,039 [foster.py] => SNet: Task 6, Epoch 116/130 => Loss 28.981,  Loss1 0.731, Train_accy 72.58, Test_accy 69.46
2024-08-07 17:46:30,470 [foster.py] => SNet: Task 6, Epoch 117/130 => Loss 29.005,  Loss1 0.731, Train_accy 71.82
2024-08-07 17:46:41,095 [foster.py] => SNet: Task 6, Epoch 118/130 => Loss 29.005,  Loss1 0.731, Train_accy 72.08
2024-08-07 17:46:51,642 [foster.py] => SNet: Task 6, Epoch 119/130 => Loss 29.027,  Loss1 0.731, Train_accy 71.76
2024-08-07 17:47:02,038 [foster.py] => SNet: Task 6, Epoch 120/130 => Loss 29.017,  Loss1 0.731, Train_accy 72.46
2024-08-07 17:47:14,710 [foster.py] => SNet: Task 6, Epoch 121/130 => Loss 29.009,  Loss1 0.731, Train_accy 71.48, Test_accy 69.50
2024-08-07 17:47:25,087 [foster.py] => SNet: Task 6, Epoch 122/130 => Loss 29.013,  Loss1 0.731, Train_accy 72.66
2024-08-07 17:47:35,497 [foster.py] => SNet: Task 6, Epoch 123/130 => Loss 29.012,  Loss1 0.731, Train_accy 71.86
2024-08-07 17:47:46,251 [foster.py] => SNet: Task 6, Epoch 124/130 => Loss 28.999,  Loss1 0.731, Train_accy 71.28
2024-08-07 17:47:57,137 [foster.py] => SNet: Task 6, Epoch 125/130 => Loss 29.021,  Loss1 0.731, Train_accy 72.36
2024-08-07 17:48:09,564 [foster.py] => SNet: Task 6, Epoch 126/130 => Loss 29.009,  Loss1 0.731, Train_accy 72.45, Test_accy 69.39
2024-08-07 17:48:20,272 [foster.py] => SNet: Task 6, Epoch 127/130 => Loss 28.993,  Loss1 0.731, Train_accy 72.35
2024-08-07 17:48:30,677 [foster.py] => SNet: Task 6, Epoch 128/130 => Loss 29.003,  Loss1 0.731, Train_accy 71.85
2024-08-07 17:48:41,094 [foster.py] => SNet: Task 6, Epoch 129/130 => Loss 29.005,  Loss1 0.731, Train_accy 72.46
2024-08-07 17:48:51,497 [foster.py] => SNet: Task 6, Epoch 130/130 => Loss 29.011,  Loss1 0.731, Train_accy 72.78
2024-08-07 17:48:51,498 [foster.py] => do not weight align student!
2024-08-07 17:48:53,637 [foster.py] => darknet eval: 
2024-08-07 17:48:53,637 [foster.py] => CNN top1 curve: 69.39
2024-08-07 17:48:53,637 [foster.py] => CNN top5 curve: 91.91
2024-08-07 17:48:53,637 [foster.py] => CNN top1 平均值: 69.39
2024-08-07 17:48:53,641 [foster.py] => timees : 3038.5544328689575
2024-08-07 17:48:53,642 [base.py] => Reducing exemplars...(28 per classes)
2024-08-07 17:49:14,477 [base.py] => Constructing exemplars...(28 per classes)
2024-08-07 17:49:29,627 [foster.py] => Exemplar size: 1960
2024-08-07 17:49:29,628 [trainer.py] => CNN: {'total': 71.44, '00-09': 72.2, '10-19': 61.1, '20-29': 73.7, '30-39': 70.7, '40-49': 75.1, '50-59': 70.8, '60-69': 76.5, 'old': 70.6, 'new': 76.5}
2024-08-07 17:49:29,628 [trainer.py] => NME: {'total': 67.06, '00-09': 64.0, '10-19': 56.6, '20-29': 69.9, '30-39': 63.9, '40-49': 70.4, '50-59': 62.2, '60-69': 82.4, 'old': 64.5, 'new': 82.4}
2024-08-07 17:49:29,628 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54, 73.43, 71.44]
2024-08-07 17:49:29,628 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64, 93.48, 92.6]
2024-08-07 17:49:29,628 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1, 69.15, 67.06]
2024-08-07 17:49:29,628 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06, 91.73, 90.39]

2024-08-07 17:49:29,628 [trainer.py] => CNN top1 平均值: 80.22
2024-08-07 17:49:29,631 [trainer.py] => All params: 1300028
2024-08-07 17:49:29,633 [trainer.py] => Trainable params: 654854
2024-08-07 17:49:29,696 [foster.py] => Learning on 70-80
2024-08-07 17:49:29,700 [foster.py] => All params: 1302618
2024-08-07 17:49:29,702 [foster.py] => Trainable params: 656794
2024-08-07 17:49:29,769 [foster.py] => per cls weights : [1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   1.039922   1.039922
 1.039922   1.039922   1.039922   1.039922   0.72054599 0.72054599
 0.72054599 0.72054599 0.72054599 0.72054599 0.72054599 0.72054599
 0.72054599 0.72054599]
2024-08-07 17:49:37,445 [foster.py] => Task 7, Epoch 1/170 => Loss 8.480, Loss_clf 3.454, Loss_fe 2.127, Loss_kd 2.532, Train_accy 45.20
2024-08-07 17:49:47,692 [foster.py] => Task 7, Epoch 2/170 => Loss 6.028, Loss_clf 1.623, Loss_fe 1.532, Loss_kd 2.509, Train_accy 54.96, Test_accy 61.49
2024-08-07 17:49:58,087 [foster.py] => Task 7, Epoch 3/170 => Loss 5.676, Loss_clf 1.445, Loss_fe 1.372, Loss_kd 2.497, Train_accy 55.34, Test_accy 62.32
2024-08-07 17:50:08,429 [foster.py] => Task 7, Epoch 4/170 => Loss 5.699, Loss_clf 1.508, Loss_fe 1.319, Loss_kd 2.509, Train_accy 55.01, Test_accy 59.65
2024-08-07 17:50:18,892 [foster.py] => Task 7, Epoch 5/170 => Loss 5.546, Loss_clf 1.387, Loss_fe 1.300, Loss_kd 2.497, Train_accy 56.41, Test_accy 61.51
2024-08-07 17:50:26,494 [foster.py] => Task 7, Epoch 6/170 => Loss 5.550, Loss_clf 1.424, Loss_fe 1.265, Loss_kd 2.499, Train_accy 55.32
2024-08-07 17:50:36,665 [foster.py] => Task 7, Epoch 7/170 => Loss 5.571, Loss_clf 1.455, Loss_fe 1.236, Loss_kd 2.515, Train_accy 56.47, Test_accy 61.45
2024-08-07 17:50:46,901 [foster.py] => Task 7, Epoch 8/170 => Loss 5.428, Loss_clf 1.318, Loss_fe 1.247, Loss_kd 2.501, Train_accy 57.63, Test_accy 62.49
2024-08-07 17:50:56,969 [foster.py] => Task 7, Epoch 9/170 => Loss 5.397, Loss_clf 1.318, Loss_fe 1.215, Loss_kd 2.503, Train_accy 57.10, Test_accy 60.11
2024-08-07 17:51:07,030 [foster.py] => Task 7, Epoch 10/170 => Loss 5.713, Loss_clf 1.587, Loss_fe 1.254, Loss_kd 2.510, Train_accy 56.48, Test_accy 62.92
2024-08-07 17:51:14,552 [foster.py] => Task 7, Epoch 11/170 => Loss 5.605, Loss_clf 1.516, Loss_fe 1.220, Loss_kd 2.507, Train_accy 55.52
2024-08-07 17:51:24,678 [foster.py] => Task 7, Epoch 12/170 => Loss 5.464, Loss_clf 1.406, Loss_fe 1.197, Loss_kd 2.500, Train_accy 56.90, Test_accy 64.11
2024-08-07 17:51:34,866 [foster.py] => Task 7, Epoch 13/170 => Loss 5.560, Loss_clf 1.509, Loss_fe 1.191, Loss_kd 2.498, Train_accy 57.47, Test_accy 58.55
2024-08-07 17:51:45,038 [foster.py] => Task 7, Epoch 14/170 => Loss 5.457, Loss_clf 1.413, Loss_fe 1.181, Loss_kd 2.501, Train_accy 57.59, Test_accy 63.26
2024-08-07 17:51:55,186 [foster.py] => Task 7, Epoch 15/170 => Loss 5.646, Loss_clf 1.598, Loss_fe 1.185, Loss_kd 2.501, Train_accy 57.07, Test_accy 61.78
2024-08-07 17:52:02,785 [foster.py] => Task 7, Epoch 16/170 => Loss 5.471, Loss_clf 1.416, Loss_fe 1.185, Loss_kd 2.508, Train_accy 57.56
2024-08-07 17:52:12,853 [foster.py] => Task 7, Epoch 17/170 => Loss 5.425, Loss_clf 1.384, Loss_fe 1.170, Loss_kd 2.509, Train_accy 58.23, Test_accy 61.60
2024-08-07 17:52:22,844 [foster.py] => Task 7, Epoch 18/170 => Loss 5.395, Loss_clf 1.361, Loss_fe 1.158, Loss_kd 2.513, Train_accy 58.48, Test_accy 64.19
2024-08-07 17:52:32,975 [foster.py] => Task 7, Epoch 19/170 => Loss 5.393, Loss_clf 1.369, Loss_fe 1.152, Loss_kd 2.509, Train_accy 57.14, Test_accy 62.11
2024-08-07 17:52:43,085 [foster.py] => Task 7, Epoch 20/170 => Loss 5.528, Loss_clf 1.492, Loss_fe 1.157, Loss_kd 2.516, Train_accy 56.45, Test_accy 60.60
2024-08-07 17:52:50,589 [foster.py] => Task 7, Epoch 21/170 => Loss 5.396, Loss_clf 1.356, Loss_fe 1.170, Loss_kd 2.508, Train_accy 58.13
2024-08-07 17:53:00,731 [foster.py] => Task 7, Epoch 22/170 => Loss 5.527, Loss_clf 1.483, Loss_fe 1.174, Loss_kd 2.508, Train_accy 55.80, Test_accy 63.25
2024-08-07 17:53:10,869 [foster.py] => Task 7, Epoch 23/170 => Loss 5.575, Loss_clf 1.541, Loss_fe 1.173, Loss_kd 2.500, Train_accy 58.10, Test_accy 62.31
2024-08-07 17:53:20,978 [foster.py] => Task 7, Epoch 24/170 => Loss 5.473, Loss_clf 1.466, Loss_fe 1.136, Loss_kd 2.508, Train_accy 57.96, Test_accy 59.80
2024-08-07 17:53:31,103 [foster.py] => Task 7, Epoch 25/170 => Loss 5.452, Loss_clf 1.413, Loss_fe 1.163, Loss_kd 2.514, Train_accy 56.98, Test_accy 59.26
2024-08-07 17:53:38,785 [foster.py] => Task 7, Epoch 26/170 => Loss 5.277, Loss_clf 1.293, Loss_fe 1.117, Loss_kd 2.506, Train_accy 58.51
2024-08-07 17:53:48,839 [foster.py] => Task 7, Epoch 27/170 => Loss 5.561, Loss_clf 1.531, Loss_fe 1.163, Loss_kd 2.505, Train_accy 55.78, Test_accy 60.90
2024-08-07 17:53:58,942 [foster.py] => Task 7, Epoch 28/170 => Loss 5.373, Loss_clf 1.371, Loss_fe 1.120, Loss_kd 2.517, Train_accy 58.23, Test_accy 63.10
2024-08-07 17:54:09,138 [foster.py] => Task 7, Epoch 29/170 => Loss 5.358, Loss_clf 1.341, Loss_fe 1.152, Loss_kd 2.505, Train_accy 57.53, Test_accy 61.70
2024-08-07 17:54:19,177 [foster.py] => Task 7, Epoch 30/170 => Loss 5.312, Loss_clf 1.330, Loss_fe 1.126, Loss_kd 2.495, Train_accy 57.51, Test_accy 61.86
2024-08-07 17:54:26,766 [foster.py] => Task 7, Epoch 31/170 => Loss 5.295, Loss_clf 1.302, Loss_fe 1.126, Loss_kd 2.504, Train_accy 57.76
2024-08-07 17:54:36,867 [foster.py] => Task 7, Epoch 32/170 => Loss 5.552, Loss_clf 1.551, Loss_fe 1.131, Loss_kd 2.508, Train_accy 56.48, Test_accy 62.52
2024-08-07 17:54:46,982 [foster.py] => Task 7, Epoch 33/170 => Loss 5.521, Loss_clf 1.476, Loss_fe 1.163, Loss_kd 2.518, Train_accy 57.08, Test_accy 63.08
2024-08-07 17:54:57,060 [foster.py] => Task 7, Epoch 34/170 => Loss 5.254, Loss_clf 1.302, Loss_fe 1.090, Loss_kd 2.500, Train_accy 59.60, Test_accy 62.70
2024-08-07 17:55:07,315 [foster.py] => Task 7, Epoch 35/170 => Loss 5.210, Loss_clf 1.249, Loss_fe 1.101, Loss_kd 2.499, Train_accy 58.45, Test_accy 62.41
2024-08-07 17:55:14,900 [foster.py] => Task 7, Epoch 36/170 => Loss 5.164, Loss_clf 1.215, Loss_fe 1.088, Loss_kd 2.500, Train_accy 57.54
2024-08-07 17:55:25,097 [foster.py] => Task 7, Epoch 37/170 => Loss 5.226, Loss_clf 1.281, Loss_fe 1.083, Loss_kd 2.501, Train_accy 59.28, Test_accy 62.42
2024-08-07 17:55:35,192 [foster.py] => Task 7, Epoch 38/170 => Loss 5.332, Loss_clf 1.342, Loss_fe 1.115, Loss_kd 2.513, Train_accy 57.74, Test_accy 63.05
2024-08-07 17:55:45,310 [foster.py] => Task 7, Epoch 39/170 => Loss 5.275, Loss_clf 1.296, Loss_fe 1.102, Loss_kd 2.514, Train_accy 58.89, Test_accy 62.80
2024-08-07 17:55:55,494 [foster.py] => Task 7, Epoch 40/170 => Loss 5.217, Loss_clf 1.237, Loss_fe 1.119, Loss_kd 2.499, Train_accy 58.88, Test_accy 64.29
2024-08-07 17:56:03,013 [foster.py] => Task 7, Epoch 41/170 => Loss 5.234, Loss_clf 1.265, Loss_fe 1.103, Loss_kd 2.505, Train_accy 57.86
2024-08-07 17:56:13,108 [foster.py] => Task 7, Epoch 42/170 => Loss 5.211, Loss_clf 1.260, Loss_fe 1.093, Loss_kd 2.497, Train_accy 58.71, Test_accy 61.39
2024-08-07 17:56:23,169 [foster.py] => Task 7, Epoch 43/170 => Loss 5.200, Loss_clf 1.248, Loss_fe 1.075, Loss_kd 2.514, Train_accy 58.12, Test_accy 63.79
2024-08-07 17:56:33,253 [foster.py] => Task 7, Epoch 44/170 => Loss 5.228, Loss_clf 1.278, Loss_fe 1.084, Loss_kd 2.504, Train_accy 58.68, Test_accy 63.49
2024-08-07 17:56:43,386 [foster.py] => Task 7, Epoch 45/170 => Loss 5.150, Loss_clf 1.226, Loss_fe 1.076, Loss_kd 2.489, Train_accy 58.86, Test_accy 63.89
2024-08-07 17:56:51,021 [foster.py] => Task 7, Epoch 46/170 => Loss 5.219, Loss_clf 1.275, Loss_fe 1.074, Loss_kd 2.507, Train_accy 58.49
2024-08-07 17:57:01,118 [foster.py] => Task 7, Epoch 47/170 => Loss 5.257, Loss_clf 1.325, Loss_fe 1.070, Loss_kd 2.501, Train_accy 58.82, Test_accy 62.75
2024-08-07 17:57:11,337 [foster.py] => Task 7, Epoch 48/170 => Loss 5.177, Loss_clf 1.232, Loss_fe 1.077, Loss_kd 2.505, Train_accy 59.50, Test_accy 63.84
2024-08-07 17:57:21,462 [foster.py] => Task 7, Epoch 49/170 => Loss 5.203, Loss_clf 1.253, Loss_fe 1.078, Loss_kd 2.509, Train_accy 58.07, Test_accy 61.69
2024-08-07 17:57:31,518 [foster.py] => Task 7, Epoch 50/170 => Loss 5.089, Loss_clf 1.199, Loss_fe 1.042, Loss_kd 2.490, Train_accy 59.71, Test_accy 63.62
2024-08-07 17:57:39,101 [foster.py] => Task 7, Epoch 51/170 => Loss 5.192, Loss_clf 1.271, Loss_fe 1.056, Loss_kd 2.504, Train_accy 58.85
2024-08-07 17:57:49,203 [foster.py] => Task 7, Epoch 52/170 => Loss 5.178, Loss_clf 1.242, Loss_fe 1.077, Loss_kd 2.498, Train_accy 58.97, Test_accy 63.49
2024-08-07 17:57:59,283 [foster.py] => Task 7, Epoch 53/170 => Loss 5.064, Loss_clf 1.158, Loss_fe 1.047, Loss_kd 2.499, Train_accy 60.22, Test_accy 61.44
2024-08-07 17:58:09,331 [foster.py] => Task 7, Epoch 54/170 => Loss 5.219, Loss_clf 1.325, Loss_fe 1.023, Loss_kd 2.509, Train_accy 58.75, Test_accy 61.96
2024-08-07 17:58:19,490 [foster.py] => Task 7, Epoch 55/170 => Loss 5.242, Loss_clf 1.301, Loss_fe 1.078, Loss_kd 2.502, Train_accy 58.26, Test_accy 63.51
2024-08-07 17:58:26,991 [foster.py] => Task 7, Epoch 56/170 => Loss 5.136, Loss_clf 1.235, Loss_fe 1.035, Loss_kd 2.504, Train_accy 60.20
2024-08-07 17:58:37,039 [foster.py] => Task 7, Epoch 57/170 => Loss 5.124, Loss_clf 1.207, Loss_fe 1.048, Loss_kd 2.507, Train_accy 59.41, Test_accy 63.60
2024-08-07 17:58:47,043 [foster.py] => Task 7, Epoch 58/170 => Loss 5.086, Loss_clf 1.203, Loss_fe 1.013, Loss_kd 2.508, Train_accy 60.09, Test_accy 63.32
2024-08-07 17:58:57,278 [foster.py] => Task 7, Epoch 59/170 => Loss 5.061, Loss_clf 1.210, Loss_fe 1.003, Loss_kd 2.488, Train_accy 59.90, Test_accy 64.62
2024-08-07 17:59:07,644 [foster.py] => Task 7, Epoch 60/170 => Loss 5.092, Loss_clf 1.195, Loss_fe 1.036, Loss_kd 2.500, Train_accy 60.03, Test_accy 64.10
2024-08-07 17:59:15,244 [foster.py] => Task 7, Epoch 61/170 => Loss 5.035, Loss_clf 1.172, Loss_fe 1.003, Loss_kd 2.499, Train_accy 59.66
2024-08-07 17:59:25,338 [foster.py] => Task 7, Epoch 62/170 => Loss 4.971, Loss_clf 1.113, Loss_fe 1.005, Loss_kd 2.493, Train_accy 60.73, Test_accy 64.90
2024-08-07 17:59:35,444 [foster.py] => Task 7, Epoch 63/170 => Loss 5.050, Loss_clf 1.187, Loss_fe 1.008, Loss_kd 2.495, Train_accy 60.50, Test_accy 64.99
2024-08-07 17:59:45,496 [foster.py] => Task 7, Epoch 64/170 => Loss 4.999, Loss_clf 1.142, Loss_fe 0.990, Loss_kd 2.506, Train_accy 60.10, Test_accy 64.05
2024-08-07 17:59:55,807 [foster.py] => Task 7, Epoch 65/170 => Loss 5.078, Loss_clf 1.190, Loss_fe 1.018, Loss_kd 2.507, Train_accy 59.90, Test_accy 61.82
2024-08-07 18:00:03,533 [foster.py] => Task 7, Epoch 66/170 => Loss 5.063, Loss_clf 1.220, Loss_fe 1.000, Loss_kd 2.484, Train_accy 60.53
2024-08-07 18:00:13,848 [foster.py] => Task 7, Epoch 67/170 => Loss 4.984, Loss_clf 1.132, Loss_fe 0.988, Loss_kd 2.503, Train_accy 59.57, Test_accy 64.75
2024-08-07 18:00:23,954 [foster.py] => Task 7, Epoch 68/170 => Loss 5.030, Loss_clf 1.195, Loss_fe 0.973, Loss_kd 2.502, Train_accy 59.31, Test_accy 64.84
2024-08-07 18:00:34,367 [foster.py] => Task 7, Epoch 69/170 => Loss 5.048, Loss_clf 1.185, Loss_fe 1.007, Loss_kd 2.496, Train_accy 59.91, Test_accy 63.74
2024-08-07 18:00:44,779 [foster.py] => Task 7, Epoch 70/170 => Loss 4.966, Loss_clf 1.119, Loss_fe 0.986, Loss_kd 2.500, Train_accy 61.82, Test_accy 64.35
2024-08-07 18:00:52,373 [foster.py] => Task 7, Epoch 71/170 => Loss 4.967, Loss_clf 1.121, Loss_fe 0.985, Loss_kd 2.500, Train_accy 60.82
2024-08-07 18:01:02,473 [foster.py] => Task 7, Epoch 72/170 => Loss 4.932, Loss_clf 1.136, Loss_fe 0.943, Loss_kd 2.493, Train_accy 60.79, Test_accy 64.54
2024-08-07 18:01:12,660 [foster.py] => Task 7, Epoch 73/170 => Loss 5.012, Loss_clf 1.167, Loss_fe 0.979, Loss_kd 2.505, Train_accy 61.11, Test_accy 63.94
2024-08-07 18:01:22,732 [foster.py] => Task 7, Epoch 74/170 => Loss 4.864, Loss_clf 1.070, Loss_fe 0.927, Loss_kd 2.505, Train_accy 61.75, Test_accy 63.48
2024-08-07 18:01:32,775 [foster.py] => Task 7, Epoch 75/170 => Loss 4.855, Loss_clf 1.068, Loss_fe 0.934, Loss_kd 2.493, Train_accy 62.33, Test_accy 63.98
2024-08-07 18:01:40,496 [foster.py] => Task 7, Epoch 76/170 => Loss 4.935, Loss_clf 1.110, Loss_fe 0.965, Loss_kd 2.499, Train_accy 60.75
2024-08-07 18:01:50,675 [foster.py] => Task 7, Epoch 77/170 => Loss 4.859, Loss_clf 1.064, Loss_fe 0.929, Loss_kd 2.505, Train_accy 62.14, Test_accy 63.51
2024-08-07 18:02:00,713 [foster.py] => Task 7, Epoch 78/170 => Loss 4.932, Loss_clf 1.153, Loss_fe 0.928, Loss_kd 2.491, Train_accy 61.22, Test_accy 64.53
2024-08-07 18:02:10,870 [foster.py] => Task 7, Epoch 79/170 => Loss 4.971, Loss_clf 1.167, Loss_fe 0.943, Loss_kd 2.500, Train_accy 61.06, Test_accy 63.51
2024-08-07 18:02:20,959 [foster.py] => Task 7, Epoch 80/170 => Loss 4.821, Loss_clf 1.072, Loss_fe 0.912, Loss_kd 2.479, Train_accy 63.16, Test_accy 64.50
2024-08-07 18:02:28,562 [foster.py] => Task 7, Epoch 81/170 => Loss 4.925, Loss_clf 1.124, Loss_fe 0.941, Loss_kd 2.500, Train_accy 61.90
2024-08-07 18:02:38,674 [foster.py] => Task 7, Epoch 82/170 => Loss 4.864, Loss_clf 1.075, Loss_fe 0.934, Loss_kd 2.495, Train_accy 62.18, Test_accy 65.82
2024-08-07 18:02:48,787 [foster.py] => Task 7, Epoch 83/170 => Loss 4.839, Loss_clf 1.081, Loss_fe 0.909, Loss_kd 2.489, Train_accy 62.13, Test_accy 65.75
2024-08-07 18:02:58,797 [foster.py] => Task 7, Epoch 84/170 => Loss 4.866, Loss_clf 1.089, Loss_fe 0.917, Loss_kd 2.499, Train_accy 62.04, Test_accy 64.58
2024-08-07 18:03:08,971 [foster.py] => Task 7, Epoch 85/170 => Loss 4.739, Loss_clf 1.012, Loss_fe 0.872, Loss_kd 2.494, Train_accy 63.06, Test_accy 63.32
2024-08-07 18:03:16,505 [foster.py] => Task 7, Epoch 86/170 => Loss 4.844, Loss_clf 1.088, Loss_fe 0.903, Loss_kd 2.493, Train_accy 62.57
2024-08-07 18:03:26,737 [foster.py] => Task 7, Epoch 87/170 => Loss 4.749, Loss_clf 1.007, Loss_fe 0.891, Loss_kd 2.492, Train_accy 63.29, Test_accy 64.56
2024-08-07 18:03:36,894 [foster.py] => Task 7, Epoch 88/170 => Loss 4.834, Loss_clf 1.072, Loss_fe 0.899, Loss_kd 2.501, Train_accy 62.17, Test_accy 65.19
2024-08-07 18:03:47,021 [foster.py] => Task 7, Epoch 89/170 => Loss 4.835, Loss_clf 1.091, Loss_fe 0.878, Loss_kd 2.504, Train_accy 62.90, Test_accy 64.21
2024-08-07 18:03:57,118 [foster.py] => Task 7, Epoch 90/170 => Loss 4.710, Loss_clf 0.997, Loss_fe 0.864, Loss_kd 2.490, Train_accy 64.24, Test_accy 65.68
2024-08-07 18:04:04,775 [foster.py] => Task 7, Epoch 91/170 => Loss 4.732, Loss_clf 1.006, Loss_fe 0.868, Loss_kd 2.498, Train_accy 63.76
2024-08-07 18:04:14,827 [foster.py] => Task 7, Epoch 92/170 => Loss 4.736, Loss_clf 1.017, Loss_fe 0.863, Loss_kd 2.495, Train_accy 62.96, Test_accy 65.46
2024-08-07 18:04:24,977 [foster.py] => Task 7, Epoch 93/170 => Loss 4.752, Loss_clf 1.043, Loss_fe 0.854, Loss_kd 2.495, Train_accy 62.83, Test_accy 65.46
2024-08-07 18:04:35,116 [foster.py] => Task 7, Epoch 94/170 => Loss 4.706, Loss_clf 1.006, Loss_fe 0.844, Loss_kd 2.497, Train_accy 64.41, Test_accy 62.11
2024-08-07 18:04:45,241 [foster.py] => Task 7, Epoch 95/170 => Loss 4.736, Loss_clf 1.029, Loss_fe 0.848, Loss_kd 2.498, Train_accy 63.39, Test_accy 65.19
2024-08-07 18:04:52,850 [foster.py] => Task 7, Epoch 96/170 => Loss 4.681, Loss_clf 0.993, Loss_fe 0.824, Loss_kd 2.503, Train_accy 63.52
2024-08-07 18:05:02,986 [foster.py] => Task 7, Epoch 97/170 => Loss 4.638, Loss_clf 0.968, Loss_fe 0.815, Loss_kd 2.495, Train_accy 64.05, Test_accy 65.81
2024-08-07 18:05:13,224 [foster.py] => Task 7, Epoch 98/170 => Loss 4.697, Loss_clf 1.005, Loss_fe 0.841, Loss_kd 2.491, Train_accy 64.01, Test_accy 65.08
2024-08-07 18:05:23,345 [foster.py] => Task 7, Epoch 99/170 => Loss 4.567, Loss_clf 0.924, Loss_fe 0.790, Loss_kd 2.493, Train_accy 65.46, Test_accy 65.79
2024-08-07 18:05:33,425 [foster.py] => Task 7, Epoch 100/170 => Loss 4.600, Loss_clf 0.951, Loss_fe 0.789, Loss_kd 2.499, Train_accy 64.93, Test_accy 65.84
2024-08-07 18:05:41,186 [foster.py] => Task 7, Epoch 101/170 => Loss 4.624, Loss_clf 0.960, Loss_fe 0.796, Loss_kd 2.506, Train_accy 64.67
2024-08-07 18:05:51,296 [foster.py] => Task 7, Epoch 102/170 => Loss 4.633, Loss_clf 0.964, Loss_fe 0.815, Loss_kd 2.493, Train_accy 64.40, Test_accy 65.82
2024-08-07 18:06:01,395 [foster.py] => Task 7, Epoch 103/170 => Loss 4.566, Loss_clf 0.933, Loss_fe 0.785, Loss_kd 2.488, Train_accy 65.11, Test_accy 65.41
2024-08-07 18:06:11,555 [foster.py] => Task 7, Epoch 104/170 => Loss 4.527, Loss_clf 0.907, Loss_fe 0.766, Loss_kd 2.494, Train_accy 66.22, Test_accy 65.18
2024-08-07 18:06:21,685 [foster.py] => Task 7, Epoch 105/170 => Loss 4.545, Loss_clf 0.919, Loss_fe 0.776, Loss_kd 2.490, Train_accy 66.09, Test_accy 66.14
2024-08-07 18:06:29,257 [foster.py] => Task 7, Epoch 106/170 => Loss 4.587, Loss_clf 0.943, Loss_fe 0.780, Loss_kd 2.503, Train_accy 65.45
2024-08-07 18:06:39,388 [foster.py] => Task 7, Epoch 107/170 => Loss 4.463, Loss_clf 0.881, Loss_fe 0.733, Loss_kd 2.489, Train_accy 66.91, Test_accy 65.59
2024-08-07 18:06:49,506 [foster.py] => Task 7, Epoch 108/170 => Loss 4.584, Loss_clf 0.953, Loss_fe 0.788, Loss_kd 2.485, Train_accy 64.90, Test_accy 64.59
2024-08-07 18:06:59,617 [foster.py] => Task 7, Epoch 109/170 => Loss 4.509, Loss_clf 0.908, Loss_fe 0.746, Loss_kd 2.495, Train_accy 66.34, Test_accy 65.82
2024-08-07 18:07:09,728 [foster.py] => Task 7, Epoch 110/170 => Loss 4.458, Loss_clf 0.877, Loss_fe 0.729, Loss_kd 2.492, Train_accy 67.13, Test_accy 66.06
2024-08-07 18:07:17,252 [foster.py] => Task 7, Epoch 111/170 => Loss 4.491, Loss_clf 0.894, Loss_fe 0.744, Loss_kd 2.493, Train_accy 67.11
2024-08-07 18:07:27,424 [foster.py] => Task 7, Epoch 112/170 => Loss 4.505, Loss_clf 0.914, Loss_fe 0.742, Loss_kd 2.490, Train_accy 66.54, Test_accy 65.94
2024-08-07 18:07:37,511 [foster.py] => Task 7, Epoch 113/170 => Loss 4.433, Loss_clf 0.868, Loss_fe 0.716, Loss_kd 2.489, Train_accy 67.95, Test_accy 65.90
2024-08-07 18:07:47,520 [foster.py] => Task 7, Epoch 114/170 => Loss 4.449, Loss_clf 0.880, Loss_fe 0.720, Loss_kd 2.490, Train_accy 67.74, Test_accy 66.28
2024-08-07 18:07:57,642 [foster.py] => Task 7, Epoch 115/170 => Loss 4.442, Loss_clf 0.870, Loss_fe 0.718, Loss_kd 2.495, Train_accy 68.28, Test_accy 66.29
2024-08-07 18:08:05,272 [foster.py] => Task 7, Epoch 116/170 => Loss 4.455, Loss_clf 0.889, Loss_fe 0.707, Loss_kd 2.498, Train_accy 67.89
2024-08-07 18:08:15,367 [foster.py] => Task 7, Epoch 117/170 => Loss 4.426, Loss_clf 0.870, Loss_fe 0.702, Loss_kd 2.494, Train_accy 67.92, Test_accy 65.29
2024-08-07 18:08:25,448 [foster.py] => Task 7, Epoch 118/170 => Loss 4.460, Loss_clf 0.888, Loss_fe 0.711, Loss_kd 2.500, Train_accy 67.79, Test_accy 65.85
2024-08-07 18:08:35,551 [foster.py] => Task 7, Epoch 119/170 => Loss 4.366, Loss_clf 0.846, Loss_fe 0.668, Loss_kd 2.492, Train_accy 69.01, Test_accy 66.31
2024-08-07 18:08:45,581 [foster.py] => Task 7, Epoch 120/170 => Loss 4.381, Loss_clf 0.836, Loss_fe 0.684, Loss_kd 2.499, Train_accy 69.31, Test_accy 65.97
2024-08-07 18:08:53,044 [foster.py] => Task 7, Epoch 121/170 => Loss 4.371, Loss_clf 0.849, Loss_fe 0.671, Loss_kd 2.492, Train_accy 68.49
2024-08-07 18:09:03,116 [foster.py] => Task 7, Epoch 122/170 => Loss 4.321, Loss_clf 0.830, Loss_fe 0.655, Loss_kd 2.478, Train_accy 68.68, Test_accy 66.46
2024-08-07 18:09:13,259 [foster.py] => Task 7, Epoch 123/170 => Loss 4.339, Loss_clf 0.842, Loss_fe 0.650, Loss_kd 2.488, Train_accy 68.82, Test_accy 66.75
2024-08-07 18:09:23,324 [foster.py] => Task 7, Epoch 124/170 => Loss 4.292, Loss_clf 0.815, Loss_fe 0.635, Loss_kd 2.483, Train_accy 68.94, Test_accy 66.31
2024-08-07 18:09:33,353 [foster.py] => Task 7, Epoch 125/170 => Loss 4.237, Loss_clf 0.777, Loss_fe 0.611, Loss_kd 2.490, Train_accy 71.18, Test_accy 66.99
2024-08-07 18:09:40,991 [foster.py] => Task 7, Epoch 126/170 => Loss 4.253, Loss_clf 0.786, Loss_fe 0.621, Loss_kd 2.487, Train_accy 70.60
2024-08-07 18:09:50,979 [foster.py] => Task 7, Epoch 127/170 => Loss 4.231, Loss_clf 0.777, Loss_fe 0.602, Loss_kd 2.493, Train_accy 71.18, Test_accy 66.84
2024-08-07 18:10:00,982 [foster.py] => Task 7, Epoch 128/170 => Loss 4.237, Loss_clf 0.786, Loss_fe 0.600, Loss_kd 2.491, Train_accy 70.49, Test_accy 66.58
2024-08-07 18:10:11,126 [foster.py] => Task 7, Epoch 129/170 => Loss 4.158, Loss_clf 0.745, Loss_fe 0.575, Loss_kd 2.480, Train_accy 71.59, Test_accy 66.89
2024-08-07 18:10:21,378 [foster.py] => Task 7, Epoch 130/170 => Loss 4.199, Loss_clf 0.766, Loss_fe 0.588, Loss_kd 2.486, Train_accy 71.28, Test_accy 66.41
2024-08-07 18:10:28,966 [foster.py] => Task 7, Epoch 131/170 => Loss 4.171, Loss_clf 0.745, Loss_fe 0.586, Loss_kd 2.481, Train_accy 72.14
2024-08-07 18:10:39,044 [foster.py] => Task 7, Epoch 132/170 => Loss 4.181, Loss_clf 0.750, Loss_fe 0.580, Loss_kd 2.492, Train_accy 71.78, Test_accy 67.31
2024-08-07 18:10:49,132 [foster.py] => Task 7, Epoch 133/170 => Loss 4.194, Loss_clf 0.766, Loss_fe 0.579, Loss_kd 2.489, Train_accy 72.95, Test_accy 65.97
2024-08-07 18:10:59,211 [foster.py] => Task 7, Epoch 134/170 => Loss 4.175, Loss_clf 0.754, Loss_fe 0.557, Loss_kd 2.503, Train_accy 72.14, Test_accy 66.79
2024-08-07 18:11:09,333 [foster.py] => Task 7, Epoch 135/170 => Loss 4.121, Loss_clf 0.730, Loss_fe 0.549, Loss_kd 2.483, Train_accy 72.73, Test_accy 66.68
2024-08-07 18:11:16,860 [foster.py] => Task 7, Epoch 136/170 => Loss 4.115, Loss_clf 0.723, Loss_fe 0.539, Loss_kd 2.494, Train_accy 73.41
2024-08-07 18:11:27,094 [foster.py] => Task 7, Epoch 137/170 => Loss 4.109, Loss_clf 0.720, Loss_fe 0.541, Loss_kd 2.489, Train_accy 73.29, Test_accy 67.16
2024-08-07 18:11:37,211 [foster.py] => Task 7, Epoch 138/170 => Loss 4.115, Loss_clf 0.733, Loss_fe 0.536, Loss_kd 2.487, Train_accy 73.71, Test_accy 67.03
2024-08-07 18:11:47,309 [foster.py] => Task 7, Epoch 139/170 => Loss 4.081, Loss_clf 0.718, Loss_fe 0.516, Loss_kd 2.488, Train_accy 73.39, Test_accy 67.08
2024-08-07 18:11:57,386 [foster.py] => Task 7, Epoch 140/170 => Loss 4.040, Loss_clf 0.687, Loss_fe 0.513, Loss_kd 2.481, Train_accy 74.97, Test_accy 66.95
2024-08-07 18:12:04,896 [foster.py] => Task 7, Epoch 141/170 => Loss 4.047, Loss_clf 0.695, Loss_fe 0.507, Loss_kd 2.486, Train_accy 74.25
2024-08-07 18:12:14,968 [foster.py] => Task 7, Epoch 142/170 => Loss 4.082, Loss_clf 0.717, Loss_fe 0.512, Loss_kd 2.493, Train_accy 74.02, Test_accy 67.28
2024-08-07 18:12:25,104 [foster.py] => Task 7, Epoch 143/170 => Loss 4.026, Loss_clf 0.684, Loss_fe 0.493, Loss_kd 2.490, Train_accy 75.13, Test_accy 67.47
2024-08-07 18:12:35,261 [foster.py] => Task 7, Epoch 144/170 => Loss 3.935, Loss_clf 0.639, Loss_fe 0.462, Loss_kd 2.477, Train_accy 75.70, Test_accy 67.64
2024-08-07 18:12:45,319 [foster.py] => Task 7, Epoch 145/170 => Loss 3.980, Loss_clf 0.661, Loss_fe 0.468, Loss_kd 2.491, Train_accy 76.71, Test_accy 67.44
2024-08-07 18:12:52,924 [foster.py] => Task 7, Epoch 146/170 => Loss 4.037, Loss_clf 0.694, Loss_fe 0.491, Loss_kd 2.492, Train_accy 75.17
2024-08-07 18:13:03,085 [foster.py] => Task 7, Epoch 147/170 => Loss 3.981, Loss_clf 0.664, Loss_fe 0.466, Loss_kd 2.492, Train_accy 75.37, Test_accy 67.61
2024-08-07 18:13:13,248 [foster.py] => Task 7, Epoch 148/170 => Loss 3.990, Loss_clf 0.669, Loss_fe 0.473, Loss_kd 2.488, Train_accy 76.02, Test_accy 67.36
2024-08-07 18:13:23,259 [foster.py] => Task 7, Epoch 149/170 => Loss 3.991, Loss_clf 0.670, Loss_fe 0.473, Loss_kd 2.489, Train_accy 76.48, Test_accy 67.31
2024-08-07 18:13:33,337 [foster.py] => Task 7, Epoch 150/170 => Loss 3.958, Loss_clf 0.649, Loss_fe 0.457, Loss_kd 2.492, Train_accy 77.27, Test_accy 67.21
2024-08-07 18:13:40,875 [foster.py] => Task 7, Epoch 151/170 => Loss 3.971, Loss_clf 0.652, Loss_fe 0.464, Loss_kd 2.495, Train_accy 76.09
2024-08-07 18:13:51,070 [foster.py] => Task 7, Epoch 152/170 => Loss 3.942, Loss_clf 0.641, Loss_fe 0.447, Loss_kd 2.495, Train_accy 77.36, Test_accy 67.53
2024-08-07 18:14:01,244 [foster.py] => Task 7, Epoch 153/170 => Loss 3.946, Loss_clf 0.647, Loss_fe 0.446, Loss_kd 2.493, Train_accy 77.16, Test_accy 67.24
2024-08-07 18:14:11,417 [foster.py] => Task 7, Epoch 154/170 => Loss 3.904, Loss_clf 0.630, Loss_fe 0.437, Loss_kd 2.479, Train_accy 76.15, Test_accy 67.54
2024-08-07 18:14:21,553 [foster.py] => Task 7, Epoch 155/170 => Loss 3.908, Loss_clf 0.630, Loss_fe 0.426, Loss_kd 2.493, Train_accy 77.31, Test_accy 67.29
2024-08-07 18:14:29,102 [foster.py] => Task 7, Epoch 156/170 => Loss 3.926, Loss_clf 0.641, Loss_fe 0.437, Loss_kd 2.488, Train_accy 77.17
2024-08-07 18:14:39,414 [foster.py] => Task 7, Epoch 157/170 => Loss 3.873, Loss_clf 0.599, Loss_fe 0.418, Loss_kd 2.495, Train_accy 77.89, Test_accy 67.49
2024-08-07 18:14:49,693 [foster.py] => Task 7, Epoch 158/170 => Loss 3.872, Loss_clf 0.615, Loss_fe 0.414, Loss_kd 2.485, Train_accy 77.51, Test_accy 67.56
2024-08-07 18:14:59,991 [foster.py] => Task 7, Epoch 159/170 => Loss 3.867, Loss_clf 0.601, Loss_fe 0.411, Loss_kd 2.495, Train_accy 78.07, Test_accy 67.45
2024-08-07 18:15:10,108 [foster.py] => Task 7, Epoch 160/170 => Loss 3.838, Loss_clf 0.606, Loss_fe 0.395, Loss_kd 2.479, Train_accy 77.47, Test_accy 67.46
2024-08-07 18:15:17,657 [foster.py] => Task 7, Epoch 161/170 => Loss 3.889, Loss_clf 0.627, Loss_fe 0.415, Loss_kd 2.488, Train_accy 77.50
2024-08-07 18:15:27,842 [foster.py] => Task 7, Epoch 162/170 => Loss 3.865, Loss_clf 0.613, Loss_fe 0.401, Loss_kd 2.492, Train_accy 78.49, Test_accy 67.61
2024-08-07 18:15:38,081 [foster.py] => Task 7, Epoch 163/170 => Loss 3.806, Loss_clf 0.588, Loss_fe 0.389, Loss_kd 2.472, Train_accy 78.74, Test_accy 67.58
2024-08-07 18:15:48,153 [foster.py] => Task 7, Epoch 164/170 => Loss 3.856, Loss_clf 0.607, Loss_fe 0.399, Loss_kd 2.490, Train_accy 77.73, Test_accy 67.58
2024-08-07 18:15:58,207 [foster.py] => Task 7, Epoch 165/170 => Loss 3.848, Loss_clf 0.595, Loss_fe 0.405, Loss_kd 2.489, Train_accy 78.58, Test_accy 67.55
2024-08-07 18:16:05,876 [foster.py] => Task 7, Epoch 166/170 => Loss 3.840, Loss_clf 0.602, Loss_fe 0.392, Loss_kd 2.488, Train_accy 78.30
2024-08-07 18:16:16,079 [foster.py] => Task 7, Epoch 167/170 => Loss 3.877, Loss_clf 0.620, Loss_fe 0.409, Loss_kd 2.489, Train_accy 77.56, Test_accy 67.49
2024-08-07 18:16:26,160 [foster.py] => Task 7, Epoch 168/170 => Loss 3.832, Loss_clf 0.600, Loss_fe 0.389, Loss_kd 2.484, Train_accy 78.30, Test_accy 67.58
2024-08-07 18:16:36,304 [foster.py] => Task 7, Epoch 169/170 => Loss 3.842, Loss_clf 0.600, Loss_fe 0.402, Loss_kd 2.482, Train_accy 77.70, Test_accy 67.42
2024-08-07 18:16:46,378 [foster.py] => Task 7, Epoch 170/170 => Loss 3.800, Loss_clf 0.570, Loss_fe 0.385, Loss_kd 2.486, Train_accy 78.69, Test_accy 67.55
2024-08-07 18:16:46,380 [foster.py] => do not weight align teacher!
2024-08-07 18:16:46,381 [foster.py] => per cls weights : [1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759 1.05626759
 1.05626759 1.05626759 1.05626759 1.05626759 0.60612687 0.60612687
 0.60612687 0.60612687 0.60612687 0.60612687 0.60612687 0.60612687
 0.60612687 0.60612687]
2024-08-07 18:16:59,608 [foster.py] => SNet: Task 7, Epoch 1/130 => Loss 30.271,  Loss1 0.749, Train_accy 32.80, Test_accy 62.12
2024-08-07 18:17:10,334 [foster.py] => SNet: Task 7, Epoch 2/130 => Loss 30.151,  Loss1 0.748, Train_accy 46.14
2024-08-07 18:17:20,914 [foster.py] => SNet: Task 7, Epoch 3/130 => Loss 30.137,  Loss1 0.748, Train_accy 49.87
2024-08-07 18:17:31,326 [foster.py] => SNet: Task 7, Epoch 4/130 => Loss 30.115,  Loss1 0.748, Train_accy 52.73
2024-08-07 18:17:41,728 [foster.py] => SNet: Task 7, Epoch 5/130 => Loss 30.107,  Loss1 0.748, Train_accy 53.81
2024-08-07 18:17:54,394 [foster.py] => SNet: Task 7, Epoch 6/130 => Loss 30.122,  Loss1 0.748, Train_accy 56.32, Test_accy 64.24
2024-08-07 18:18:05,118 [foster.py] => SNet: Task 7, Epoch 7/130 => Loss 30.093,  Loss1 0.748, Train_accy 55.82
2024-08-07 18:18:15,674 [foster.py] => SNet: Task 7, Epoch 8/130 => Loss 30.093,  Loss1 0.748, Train_accy 56.70
2024-08-07 18:18:26,437 [foster.py] => SNet: Task 7, Epoch 9/130 => Loss 30.096,  Loss1 0.748, Train_accy 58.07
2024-08-07 18:18:36,812 [foster.py] => SNet: Task 7, Epoch 10/130 => Loss 30.084,  Loss1 0.748, Train_accy 57.69
2024-08-07 18:18:49,789 [foster.py] => SNet: Task 7, Epoch 11/130 => Loss 30.103,  Loss1 0.748, Train_accy 57.33, Test_accy 64.92
2024-08-07 18:19:00,274 [foster.py] => SNet: Task 7, Epoch 12/130 => Loss 30.102,  Loss1 0.748, Train_accy 58.49
2024-08-07 18:19:10,633 [foster.py] => SNet: Task 7, Epoch 13/130 => Loss 30.098,  Loss1 0.748, Train_accy 59.01
2024-08-07 18:19:21,019 [foster.py] => SNet: Task 7, Epoch 14/130 => Loss 30.081,  Loss1 0.748, Train_accy 58.58
2024-08-07 18:19:31,711 [foster.py] => SNet: Task 7, Epoch 15/130 => Loss 30.076,  Loss1 0.748, Train_accy 60.26
2024-08-07 18:19:44,751 [foster.py] => SNet: Task 7, Epoch 16/130 => Loss 30.081,  Loss1 0.748, Train_accy 59.24, Test_accy 64.70
2024-08-07 18:19:55,343 [foster.py] => SNet: Task 7, Epoch 17/130 => Loss 30.099,  Loss1 0.748, Train_accy 59.70
2024-08-07 18:20:06,041 [foster.py] => SNet: Task 7, Epoch 18/130 => Loss 30.085,  Loss1 0.748, Train_accy 59.67
2024-08-07 18:20:16,445 [foster.py] => SNet: Task 7, Epoch 19/130 => Loss 30.080,  Loss1 0.748, Train_accy 59.77
2024-08-07 18:20:26,894 [foster.py] => SNet: Task 7, Epoch 20/130 => Loss 30.100,  Loss1 0.748, Train_accy 60.70
2024-08-07 18:20:39,566 [foster.py] => SNet: Task 7, Epoch 21/130 => Loss 30.061,  Loss1 0.748, Train_accy 60.22, Test_accy 65.04
2024-08-07 18:20:50,233 [foster.py] => SNet: Task 7, Epoch 22/130 => Loss 30.082,  Loss1 0.748, Train_accy 60.53
2024-08-07 18:21:00,635 [foster.py] => SNet: Task 7, Epoch 23/130 => Loss 30.070,  Loss1 0.748, Train_accy 60.66
2024-08-07 18:21:11,192 [foster.py] => SNet: Task 7, Epoch 24/130 => Loss 30.073,  Loss1 0.748, Train_accy 59.81
2024-08-07 18:21:21,642 [foster.py] => SNet: Task 7, Epoch 25/130 => Loss 30.080,  Loss1 0.748, Train_accy 60.83
2024-08-07 18:21:34,365 [foster.py] => SNet: Task 7, Epoch 26/130 => Loss 30.085,  Loss1 0.748, Train_accy 61.64, Test_accy 65.28
2024-08-07 18:21:44,979 [foster.py] => SNet: Task 7, Epoch 27/130 => Loss 30.065,  Loss1 0.748, Train_accy 61.98
2024-08-07 18:21:55,401 [foster.py] => SNet: Task 7, Epoch 28/130 => Loss 30.084,  Loss1 0.748, Train_accy 61.18
2024-08-07 18:22:05,874 [foster.py] => SNet: Task 7, Epoch 29/130 => Loss 30.076,  Loss1 0.748, Train_accy 61.42
2024-08-07 18:22:16,532 [foster.py] => SNet: Task 7, Epoch 30/130 => Loss 30.078,  Loss1 0.748, Train_accy 61.31
2024-08-07 18:22:29,345 [foster.py] => SNet: Task 7, Epoch 31/130 => Loss 30.080,  Loss1 0.748, Train_accy 61.58, Test_accy 65.21
2024-08-07 18:22:39,911 [foster.py] => SNet: Task 7, Epoch 32/130 => Loss 30.078,  Loss1 0.748, Train_accy 62.03
2024-08-07 18:22:50,264 [foster.py] => SNet: Task 7, Epoch 33/130 => Loss 30.074,  Loss1 0.748, Train_accy 61.57
2024-08-07 18:23:00,897 [foster.py] => SNet: Task 7, Epoch 34/130 => Loss 30.060,  Loss1 0.748, Train_accy 61.98
2024-08-07 18:23:11,305 [foster.py] => SNet: Task 7, Epoch 35/130 => Loss 30.097,  Loss1 0.748, Train_accy 62.03
2024-08-07 18:23:24,317 [foster.py] => SNet: Task 7, Epoch 36/130 => Loss 30.067,  Loss1 0.748, Train_accy 62.30, Test_accy 65.45
2024-08-07 18:23:34,932 [foster.py] => SNet: Task 7, Epoch 37/130 => Loss 30.068,  Loss1 0.748, Train_accy 61.84
2024-08-07 18:23:45,611 [foster.py] => SNet: Task 7, Epoch 38/130 => Loss 30.049,  Loss1 0.748, Train_accy 61.81
2024-08-07 18:23:56,122 [foster.py] => SNet: Task 7, Epoch 39/130 => Loss 30.056,  Loss1 0.748, Train_accy 63.61
2024-08-07 18:24:07,013 [foster.py] => SNet: Task 7, Epoch 40/130 => Loss 30.061,  Loss1 0.748, Train_accy 61.88
2024-08-07 18:24:19,893 [foster.py] => SNet: Task 7, Epoch 41/130 => Loss 30.091,  Loss1 0.748, Train_accy 62.96, Test_accy 65.24
2024-08-07 18:24:30,293 [foster.py] => SNet: Task 7, Epoch 42/130 => Loss 30.077,  Loss1 0.748, Train_accy 62.82
2024-08-07 18:24:40,951 [foster.py] => SNet: Task 7, Epoch 43/130 => Loss 30.061,  Loss1 0.748, Train_accy 62.31
2024-08-07 18:24:52,129 [foster.py] => SNet: Task 7, Epoch 44/130 => Loss 30.059,  Loss1 0.748, Train_accy 62.99
2024-08-07 18:25:02,479 [foster.py] => SNet: Task 7, Epoch 45/130 => Loss 30.054,  Loss1 0.748, Train_accy 63.10
2024-08-07 18:25:15,259 [foster.py] => SNet: Task 7, Epoch 46/130 => Loss 30.073,  Loss1 0.748, Train_accy 63.10, Test_accy 65.19
2024-08-07 18:25:26,017 [foster.py] => SNet: Task 7, Epoch 47/130 => Loss 30.085,  Loss1 0.748, Train_accy 63.61
2024-08-07 18:25:36,511 [foster.py] => SNet: Task 7, Epoch 48/130 => Loss 30.059,  Loss1 0.748, Train_accy 63.76
2024-08-07 18:25:46,890 [foster.py] => SNet: Task 7, Epoch 49/130 => Loss 30.058,  Loss1 0.748, Train_accy 62.80
2024-08-07 18:25:58,235 [foster.py] => SNet: Task 7, Epoch 50/130 => Loss 30.069,  Loss1 0.748, Train_accy 63.62
2024-08-07 18:26:11,193 [foster.py] => SNet: Task 7, Epoch 51/130 => Loss 30.078,  Loss1 0.748, Train_accy 63.98, Test_accy 65.38
2024-08-07 18:26:22,078 [foster.py] => SNet: Task 7, Epoch 52/130 => Loss 30.063,  Loss1 0.748, Train_accy 62.74
2024-08-07 18:26:32,523 [foster.py] => SNet: Task 7, Epoch 53/130 => Loss 30.060,  Loss1 0.748, Train_accy 63.35
2024-08-07 18:26:42,995 [foster.py] => SNet: Task 7, Epoch 54/130 => Loss 30.055,  Loss1 0.748, Train_accy 64.44
2024-08-07 18:26:53,522 [foster.py] => SNet: Task 7, Epoch 55/130 => Loss 30.064,  Loss1 0.748, Train_accy 63.88
2024-08-07 18:27:06,533 [foster.py] => SNet: Task 7, Epoch 56/130 => Loss 30.068,  Loss1 0.748, Train_accy 64.60, Test_accy 65.36
2024-08-07 18:27:16,933 [foster.py] => SNet: Task 7, Epoch 57/130 => Loss 30.070,  Loss1 0.748, Train_accy 63.35
2024-08-07 18:27:27,540 [foster.py] => SNet: Task 7, Epoch 58/130 => Loss 30.075,  Loss1 0.748, Train_accy 63.88
2024-08-07 18:27:37,858 [foster.py] => SNet: Task 7, Epoch 59/130 => Loss 30.057,  Loss1 0.748, Train_accy 63.59
2024-08-07 18:27:48,579 [foster.py] => SNet: Task 7, Epoch 60/130 => Loss 30.059,  Loss1 0.748, Train_accy 63.85
2024-08-07 18:28:01,193 [foster.py] => SNet: Task 7, Epoch 61/130 => Loss 30.075,  Loss1 0.748, Train_accy 64.81, Test_accy 66.14
2024-08-07 18:28:11,801 [foster.py] => SNet: Task 7, Epoch 62/130 => Loss 30.062,  Loss1 0.748, Train_accy 64.93
2024-08-07 18:28:22,307 [foster.py] => SNet: Task 7, Epoch 63/130 => Loss 30.061,  Loss1 0.748, Train_accy 64.51
2024-08-07 18:28:32,877 [foster.py] => SNet: Task 7, Epoch 64/130 => Loss 30.080,  Loss1 0.748, Train_accy 64.41
2024-08-07 18:28:43,497 [foster.py] => SNet: Task 7, Epoch 65/130 => Loss 30.080,  Loss1 0.748, Train_accy 64.47
2024-08-07 18:28:56,404 [foster.py] => SNet: Task 7, Epoch 66/130 => Loss 30.044,  Loss1 0.748, Train_accy 64.45, Test_accy 65.88
2024-08-07 18:29:06,902 [foster.py] => SNet: Task 7, Epoch 67/130 => Loss 30.085,  Loss1 0.748, Train_accy 64.04
2024-08-07 18:29:17,421 [foster.py] => SNet: Task 7, Epoch 68/130 => Loss 30.059,  Loss1 0.748, Train_accy 64.21
2024-08-07 18:29:27,908 [foster.py] => SNet: Task 7, Epoch 69/130 => Loss 30.068,  Loss1 0.748, Train_accy 64.34
2024-08-07 18:29:38,802 [foster.py] => SNet: Task 7, Epoch 70/130 => Loss 30.063,  Loss1 0.748, Train_accy 65.55
2024-08-07 18:29:51,635 [foster.py] => SNet: Task 7, Epoch 71/130 => Loss 30.059,  Loss1 0.748, Train_accy 63.95, Test_accy 66.18
2024-08-07 18:30:02,027 [foster.py] => SNet: Task 7, Epoch 72/130 => Loss 30.061,  Loss1 0.748, Train_accy 64.01
2024-08-07 18:30:12,729 [foster.py] => SNet: Task 7, Epoch 73/130 => Loss 30.072,  Loss1 0.748, Train_accy 63.98
2024-08-07 18:30:23,142 [foster.py] => SNet: Task 7, Epoch 74/130 => Loss 30.063,  Loss1 0.748, Train_accy 64.77
2024-08-07 18:30:33,616 [foster.py] => SNet: Task 7, Epoch 75/130 => Loss 30.061,  Loss1 0.748, Train_accy 64.93
2024-08-07 18:30:46,453 [foster.py] => SNet: Task 7, Epoch 76/130 => Loss 30.038,  Loss1 0.748, Train_accy 64.37, Test_accy 66.31
2024-08-07 18:30:57,084 [foster.py] => SNet: Task 7, Epoch 77/130 => Loss 30.067,  Loss1 0.748, Train_accy 65.92
2024-08-07 18:31:07,507 [foster.py] => SNet: Task 7, Epoch 78/130 => Loss 30.056,  Loss1 0.748, Train_accy 65.60
2024-08-07 18:31:17,969 [foster.py] => SNet: Task 7, Epoch 79/130 => Loss 30.065,  Loss1 0.748, Train_accy 65.13
2024-08-07 18:31:28,560 [foster.py] => SNet: Task 7, Epoch 80/130 => Loss 30.066,  Loss1 0.748, Train_accy 64.90
2024-08-07 18:31:41,390 [foster.py] => SNet: Task 7, Epoch 81/130 => Loss 30.054,  Loss1 0.748, Train_accy 64.41, Test_accy 66.25
2024-08-07 18:31:51,889 [foster.py] => SNet: Task 7, Epoch 82/130 => Loss 30.047,  Loss1 0.748, Train_accy 64.51
2024-08-07 18:32:02,265 [foster.py] => SNet: Task 7, Epoch 83/130 => Loss 30.037,  Loss1 0.748, Train_accy 65.62
2024-08-07 18:32:13,268 [foster.py] => SNet: Task 7, Epoch 84/130 => Loss 30.052,  Loss1 0.748, Train_accy 64.87
2024-08-07 18:32:23,826 [foster.py] => SNet: Task 7, Epoch 85/130 => Loss 30.054,  Loss1 0.748, Train_accy 65.06
2024-08-07 18:32:36,888 [foster.py] => SNet: Task 7, Epoch 86/130 => Loss 30.059,  Loss1 0.748, Train_accy 65.33, Test_accy 66.70
2024-08-07 18:32:47,328 [foster.py] => SNet: Task 7, Epoch 87/130 => Loss 30.047,  Loss1 0.748, Train_accy 65.65
2024-08-07 18:32:57,945 [foster.py] => SNet: Task 7, Epoch 88/130 => Loss 30.045,  Loss1 0.748, Train_accy 65.75
2024-08-07 18:33:08,601 [foster.py] => SNet: Task 7, Epoch 89/130 => Loss 30.068,  Loss1 0.748, Train_accy 65.26
2024-08-07 18:33:18,944 [foster.py] => SNet: Task 7, Epoch 90/130 => Loss 30.040,  Loss1 0.748, Train_accy 65.32
2024-08-07 18:33:31,577 [foster.py] => SNet: Task 7, Epoch 91/130 => Loss 30.034,  Loss1 0.748, Train_accy 65.30, Test_accy 66.65
2024-08-07 18:33:42,041 [foster.py] => SNet: Task 7, Epoch 92/130 => Loss 30.029,  Loss1 0.748, Train_accy 64.77
2024-08-07 18:33:52,465 [foster.py] => SNet: Task 7, Epoch 93/130 => Loss 30.070,  Loss1 0.748, Train_accy 65.13
2024-08-07 18:34:03,438 [foster.py] => SNet: Task 7, Epoch 94/130 => Loss 30.051,  Loss1 0.748, Train_accy 65.60
2024-08-07 18:34:13,944 [foster.py] => SNet: Task 7, Epoch 95/130 => Loss 30.044,  Loss1 0.748, Train_accy 65.06
2024-08-07 18:34:26,560 [foster.py] => SNet: Task 7, Epoch 96/130 => Loss 30.048,  Loss1 0.748, Train_accy 64.47, Test_accy 66.34
2024-08-07 18:34:37,265 [foster.py] => SNet: Task 7, Epoch 97/130 => Loss 30.054,  Loss1 0.748, Train_accy 65.83
2024-08-07 18:34:47,658 [foster.py] => SNet: Task 7, Epoch 98/130 => Loss 30.067,  Loss1 0.748, Train_accy 65.20
2024-08-07 18:34:58,273 [foster.py] => SNet: Task 7, Epoch 99/130 => Loss 30.040,  Loss1 0.748, Train_accy 65.82
2024-08-07 18:35:08,918 [foster.py] => SNet: Task 7, Epoch 100/130 => Loss 30.076,  Loss1 0.748, Train_accy 64.55
2024-08-07 18:35:21,502 [foster.py] => SNet: Task 7, Epoch 101/130 => Loss 30.052,  Loss1 0.748, Train_accy 66.03, Test_accy 66.78
2024-08-07 18:35:32,294 [foster.py] => SNet: Task 7, Epoch 102/130 => Loss 30.023,  Loss1 0.748, Train_accy 65.10
2024-08-07 18:35:42,962 [foster.py] => SNet: Task 7, Epoch 103/130 => Loss 30.054,  Loss1 0.748, Train_accy 65.98
2024-08-07 18:35:53,557 [foster.py] => SNet: Task 7, Epoch 104/130 => Loss 30.066,  Loss1 0.748, Train_accy 65.65
2024-08-07 18:36:04,033 [foster.py] => SNet: Task 7, Epoch 105/130 => Loss 30.040,  Loss1 0.748, Train_accy 66.03
2024-08-07 18:36:17,266 [foster.py] => SNet: Task 7, Epoch 106/130 => Loss 30.040,  Loss1 0.748, Train_accy 66.59, Test_accy 66.56
2024-08-07 18:36:28,068 [foster.py] => SNet: Task 7, Epoch 107/130 => Loss 30.067,  Loss1 0.748, Train_accy 64.74
2024-08-07 18:36:38,481 [foster.py] => SNet: Task 7, Epoch 108/130 => Loss 30.057,  Loss1 0.748, Train_accy 65.80
2024-08-07 18:36:48,895 [foster.py] => SNet: Task 7, Epoch 109/130 => Loss 30.059,  Loss1 0.748, Train_accy 65.49
2024-08-07 18:36:59,583 [foster.py] => SNet: Task 7, Epoch 110/130 => Loss 30.038,  Loss1 0.748, Train_accy 65.75
2024-08-07 18:37:12,858 [foster.py] => SNet: Task 7, Epoch 111/130 => Loss 30.069,  Loss1 0.748, Train_accy 64.66, Test_accy 66.42
2024-08-07 18:37:23,505 [foster.py] => SNet: Task 7, Epoch 112/130 => Loss 30.066,  Loss1 0.748, Train_accy 65.47
2024-08-07 18:37:34,079 [foster.py] => SNet: Task 7, Epoch 113/130 => Loss 30.043,  Loss1 0.748, Train_accy 65.32
2024-08-07 18:37:45,001 [foster.py] => SNet: Task 7, Epoch 114/130 => Loss 30.047,  Loss1 0.748, Train_accy 64.64
2024-08-07 18:37:55,485 [foster.py] => SNet: Task 7, Epoch 115/130 => Loss 30.065,  Loss1 0.748, Train_accy 65.42
2024-08-07 18:38:08,358 [foster.py] => SNet: Task 7, Epoch 116/130 => Loss 30.056,  Loss1 0.748, Train_accy 65.59, Test_accy 66.84
2024-08-07 18:38:18,788 [foster.py] => SNet: Task 7, Epoch 117/130 => Loss 30.039,  Loss1 0.748, Train_accy 65.86
2024-08-07 18:38:29,426 [foster.py] => SNet: Task 7, Epoch 118/130 => Loss 30.027,  Loss1 0.748, Train_accy 65.16
2024-08-07 18:38:40,043 [foster.py] => SNet: Task 7, Epoch 119/130 => Loss 30.035,  Loss1 0.748, Train_accy 65.91
2024-08-07 18:38:50,918 [foster.py] => SNet: Task 7, Epoch 120/130 => Loss 30.078,  Loss1 0.748, Train_accy 64.76
2024-08-07 18:39:03,587 [foster.py] => SNet: Task 7, Epoch 121/130 => Loss 30.054,  Loss1 0.748, Train_accy 65.68, Test_accy 66.71
2024-08-07 18:39:14,310 [foster.py] => SNet: Task 7, Epoch 122/130 => Loss 30.038,  Loss1 0.748, Train_accy 65.79
2024-08-07 18:39:25,100 [foster.py] => SNet: Task 7, Epoch 123/130 => Loss 30.051,  Loss1 0.748, Train_accy 65.91
2024-08-07 18:39:35,699 [foster.py] => SNet: Task 7, Epoch 124/130 => Loss 30.062,  Loss1 0.748, Train_accy 65.09
2024-08-07 18:39:46,090 [foster.py] => SNet: Task 7, Epoch 125/130 => Loss 30.039,  Loss1 0.748, Train_accy 65.60
2024-08-07 18:39:58,965 [foster.py] => SNet: Task 7, Epoch 126/130 => Loss 30.045,  Loss1 0.748, Train_accy 64.84, Test_accy 66.34
2024-08-07 18:40:09,361 [foster.py] => SNet: Task 7, Epoch 127/130 => Loss 30.043,  Loss1 0.748, Train_accy 64.86
2024-08-07 18:40:20,021 [foster.py] => SNet: Task 7, Epoch 128/130 => Loss 30.043,  Loss1 0.748, Train_accy 65.98
2024-08-07 18:40:30,764 [foster.py] => SNet: Task 7, Epoch 129/130 => Loss 30.059,  Loss1 0.748, Train_accy 65.68
2024-08-07 18:40:41,177 [foster.py] => SNet: Task 7, Epoch 130/130 => Loss 30.061,  Loss1 0.748, Train_accy 65.40
2024-08-07 18:40:41,177 [foster.py] => do not weight align student!
2024-08-07 18:40:43,496 [foster.py] => darknet eval: 
2024-08-07 18:40:43,496 [foster.py] => CNN top1 curve: 66.49
2024-08-07 18:40:43,497 [foster.py] => CNN top5 curve: 91.06
2024-08-07 18:40:43,497 [foster.py] => CNN top1 平均值: 66.49
2024-08-07 18:40:43,503 [foster.py] => timees : 3073.7529952526093
2024-08-07 18:40:43,504 [base.py] => Reducing exemplars...(25 per classes)
2024-08-07 18:41:07,982 [base.py] => Constructing exemplars...(25 per classes)
2024-08-07 18:41:23,595 [foster.py] => Exemplar size: 2000
2024-08-07 18:41:23,595 [trainer.py] => CNN: {'total': 67.55, '00-09': 69.7, '10-19': 59.5, '20-29': 70.9, '30-39': 65.7, '40-49': 71.1, '50-59': 62.9, '60-69': 71.2, '70-79': 69.4, 'old': 67.29, 'new': 69.4}
2024-08-07 18:41:23,595 [trainer.py] => NME: {'total': 62.95, '00-09': 62.0, '10-19': 53.2, '20-29': 66.8, '30-39': 59.9, '40-49': 65.5, '50-59': 57.1, '60-69': 64.4, '70-79': 74.7, 'old': 61.27, 'new': 74.7}
2024-08-07 18:41:23,595 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54, 73.43, 71.44, 67.55]
2024-08-07 18:41:23,595 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64, 93.48, 92.6, 91.38]
2024-08-07 18:41:23,595 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1, 69.15, 67.06, 62.95]
2024-08-07 18:41:23,595 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06, 91.73, 90.39, 88.68]

2024-08-07 18:41:23,595 [trainer.py] => CNN top1 平均值: 78.64
2024-08-07 18:41:23,598 [trainer.py] => All params: 1302618
2024-08-07 18:41:23,600 [trainer.py] => Trainable params: 656794
2024-08-07 18:41:23,663 [foster.py] => Learning on 80-90
2024-08-07 18:41:23,667 [foster.py] => All params: 1305208
2024-08-07 18:41:23,669 [foster.py] => Trainable params: 658734
2024-08-07 18:41:23,741 [foster.py] => per cls weights : [1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138 1.03590138
 1.03590138 1.03590138 0.71278892 0.71278892 0.71278892 0.71278892
 0.71278892 0.71278892 0.71278892 0.71278892 0.71278892 0.71278892]
2024-08-07 18:41:31,246 [foster.py] => Task 8, Epoch 1/170 => Loss 12.175, Loss_clf 6.698, Loss_fe 2.343, Loss_kd 2.781, Train_accy 40.11
2024-08-07 18:41:41,538 [foster.py] => Task 8, Epoch 2/170 => Loss 6.964, Loss_clf 1.954, Loss_fe 1.919, Loss_kd 2.742, Train_accy 53.39, Test_accy 58.89
2024-08-07 18:41:51,754 [foster.py] => Task 8, Epoch 3/170 => Loss 6.416, Loss_clf 1.702, Loss_fe 1.630, Loss_kd 2.737, Train_accy 53.83, Test_accy 61.03
2024-08-07 18:42:02,135 [foster.py] => Task 8, Epoch 4/170 => Loss 6.401, Loss_clf 1.774, Loss_fe 1.536, Loss_kd 2.742, Train_accy 53.14, Test_accy 59.40
2024-08-07 18:42:12,579 [foster.py] => Task 8, Epoch 5/170 => Loss 6.190, Loss_clf 1.646, Loss_fe 1.452, Loss_kd 2.744, Train_accy 55.14, Test_accy 58.20
2024-08-07 18:42:20,169 [foster.py] => Task 8, Epoch 6/170 => Loss 6.248, Loss_clf 1.751, Loss_fe 1.407, Loss_kd 2.742, Train_accy 53.96
2024-08-07 18:42:30,494 [foster.py] => Task 8, Epoch 7/170 => Loss 6.071, Loss_clf 1.625, Loss_fe 1.359, Loss_kd 2.740, Train_accy 55.17, Test_accy 61.41
2024-08-07 18:42:41,016 [foster.py] => Task 8, Epoch 8/170 => Loss 5.968, Loss_clf 1.532, Loss_fe 1.340, Loss_kd 2.747, Train_accy 56.41, Test_accy 61.62
2024-08-07 18:42:51,429 [foster.py] => Task 8, Epoch 9/170 => Loss 5.950, Loss_clf 1.560, Loss_fe 1.298, Loss_kd 2.744, Train_accy 56.39, Test_accy 60.73
2024-08-07 18:43:01,790 [foster.py] => Task 8, Epoch 10/170 => Loss 5.812, Loss_clf 1.437, Loss_fe 1.284, Loss_kd 2.744, Train_accy 57.83, Test_accy 61.48
2024-08-07 18:43:09,287 [foster.py] => Task 8, Epoch 11/170 => Loss 6.132, Loss_clf 1.702, Loss_fe 1.338, Loss_kd 2.744, Train_accy 55.06
2024-08-07 18:43:19,619 [foster.py] => Task 8, Epoch 12/170 => Loss 5.976, Loss_clf 1.575, Loss_fe 1.314, Loss_kd 2.740, Train_accy 56.60, Test_accy 61.12
2024-08-07 18:43:30,028 [foster.py] => Task 8, Epoch 13/170 => Loss 5.810, Loss_clf 1.468, Loss_fe 1.253, Loss_kd 2.741, Train_accy 56.74, Test_accy 58.98
2024-08-07 18:43:40,314 [foster.py] => Task 8, Epoch 14/170 => Loss 6.161, Loss_clf 1.807, Loss_fe 1.273, Loss_kd 2.735, Train_accy 55.41, Test_accy 59.78
2024-08-07 18:43:50,662 [foster.py] => Task 8, Epoch 15/170 => Loss 5.817, Loss_clf 1.475, Loss_fe 1.258, Loss_kd 2.738, Train_accy 57.69, Test_accy 61.33
2024-08-07 18:43:58,151 [foster.py] => Task 8, Epoch 16/170 => Loss 5.679, Loss_clf 1.376, Loss_fe 1.218, Loss_kd 2.738, Train_accy 58.31
2024-08-07 18:44:08,548 [foster.py] => Task 8, Epoch 17/170 => Loss 5.925, Loss_clf 1.603, Loss_fe 1.233, Loss_kd 2.742, Train_accy 57.06, Test_accy 60.50
2024-08-07 18:44:18,945 [foster.py] => Task 8, Epoch 18/170 => Loss 5.758, Loss_clf 1.449, Loss_fe 1.226, Loss_kd 2.736, Train_accy 57.41, Test_accy 59.84
2024-08-07 18:44:29,292 [foster.py] => Task 8, Epoch 19/170 => Loss 5.903, Loss_clf 1.576, Loss_fe 1.241, Loss_kd 2.739, Train_accy 56.90, Test_accy 60.22
2024-08-07 18:44:39,576 [foster.py] => Task 8, Epoch 20/170 => Loss 5.728, Loss_clf 1.457, Loss_fe 1.182, Loss_kd 2.741, Train_accy 58.29, Test_accy 59.09
2024-08-07 18:44:47,110 [foster.py] => Task 8, Epoch 21/170 => Loss 5.736, Loss_clf 1.453, Loss_fe 1.189, Loss_kd 2.747, Train_accy 57.24
2024-08-07 18:44:57,499 [foster.py] => Task 8, Epoch 22/170 => Loss 5.823, Loss_clf 1.520, Loss_fe 1.223, Loss_kd 2.734, Train_accy 56.66, Test_accy 60.92
2024-08-07 18:45:07,863 [foster.py] => Task 8, Epoch 23/170 => Loss 5.721, Loss_clf 1.451, Loss_fe 1.183, Loss_kd 2.740, Train_accy 57.81, Test_accy 61.24
2024-08-07 18:45:18,222 [foster.py] => Task 8, Epoch 24/170 => Loss 5.610, Loss_clf 1.371, Loss_fe 1.166, Loss_kd 2.728, Train_accy 57.70, Test_accy 61.58
2024-08-07 18:45:28,563 [foster.py] => Task 8, Epoch 25/170 => Loss 5.729, Loss_clf 1.463, Loss_fe 1.175, Loss_kd 2.744, Train_accy 58.60, Test_accy 58.41
2024-08-07 18:45:36,164 [foster.py] => Task 8, Epoch 26/170 => Loss 5.752, Loss_clf 1.475, Loss_fe 1.192, Loss_kd 2.738, Train_accy 57.73
2024-08-07 18:45:46,514 [foster.py] => Task 8, Epoch 27/170 => Loss 5.628, Loss_clf 1.414, Loss_fe 1.140, Loss_kd 2.729, Train_accy 58.30, Test_accy 58.63
2024-08-07 18:45:56,844 [foster.py] => Task 8, Epoch 28/170 => Loss 5.701, Loss_clf 1.467, Loss_fe 1.140, Loss_kd 2.746, Train_accy 58.23, Test_accy 60.59
2024-08-07 18:46:07,242 [foster.py] => Task 8, Epoch 29/170 => Loss 5.708, Loss_clf 1.458, Loss_fe 1.166, Loss_kd 2.738, Train_accy 57.76, Test_accy 60.24
2024-08-07 18:46:17,615 [foster.py] => Task 8, Epoch 30/170 => Loss 5.599, Loss_clf 1.376, Loss_fe 1.142, Loss_kd 2.735, Train_accy 58.94, Test_accy 59.14
2024-08-07 18:46:25,189 [foster.py] => Task 8, Epoch 31/170 => Loss 5.547, Loss_clf 1.336, Loss_fe 1.129, Loss_kd 2.736, Train_accy 59.17
2024-08-07 18:46:35,577 [foster.py] => Task 8, Epoch 32/170 => Loss 5.653, Loss_clf 1.428, Loss_fe 1.128, Loss_kd 2.749, Train_accy 58.54, Test_accy 61.70
2024-08-07 18:46:45,839 [foster.py] => Task 8, Epoch 33/170 => Loss 5.622, Loss_clf 1.384, Loss_fe 1.152, Loss_kd 2.739, Train_accy 58.93, Test_accy 61.12
2024-08-07 18:46:56,195 [foster.py] => Task 8, Epoch 34/170 => Loss 5.525, Loss_clf 1.329, Loss_fe 1.115, Loss_kd 2.735, Train_accy 59.69, Test_accy 61.10
2024-08-07 18:47:06,566 [foster.py] => Task 8, Epoch 35/170 => Loss 5.515, Loss_clf 1.301, Loss_fe 1.126, Loss_kd 2.741, Train_accy 59.21, Test_accy 61.00
2024-08-07 18:47:14,275 [foster.py] => Task 8, Epoch 36/170 => Loss 5.703, Loss_clf 1.492, Loss_fe 1.135, Loss_kd 2.730, Train_accy 57.39
2024-08-07 18:47:24,674 [foster.py] => Task 8, Epoch 37/170 => Loss 5.563, Loss_clf 1.352, Loss_fe 1.132, Loss_kd 2.733, Train_accy 60.81, Test_accy 61.50
2024-08-07 18:47:35,034 [foster.py] => Task 8, Epoch 38/170 => Loss 5.499, Loss_clf 1.305, Loss_fe 1.109, Loss_kd 2.738, Train_accy 59.91, Test_accy 61.23
2024-08-07 18:47:45,298 [foster.py] => Task 8, Epoch 39/170 => Loss 5.597, Loss_clf 1.410, Loss_fe 1.105, Loss_kd 2.736, Train_accy 58.64, Test_accy 60.10
2024-08-07 18:47:55,896 [foster.py] => Task 8, Epoch 40/170 => Loss 5.577, Loss_clf 1.392, Loss_fe 1.094, Loss_kd 2.743, Train_accy 59.53, Test_accy 59.83
2024-08-07 18:48:03,692 [foster.py] => Task 8, Epoch 41/170 => Loss 5.520, Loss_clf 1.322, Loss_fe 1.106, Loss_kd 2.745, Train_accy 59.19
2024-08-07 18:48:14,428 [foster.py] => Task 8, Epoch 42/170 => Loss 5.492, Loss_clf 1.320, Loss_fe 1.090, Loss_kd 2.735, Train_accy 58.89, Test_accy 62.93
2024-08-07 18:48:25,182 [foster.py] => Task 8, Epoch 43/170 => Loss 5.488, Loss_clf 1.319, Loss_fe 1.095, Loss_kd 2.729, Train_accy 59.49, Test_accy 61.88
2024-08-07 18:48:35,655 [foster.py] => Task 8, Epoch 44/170 => Loss 5.473, Loss_clf 1.306, Loss_fe 1.080, Loss_kd 2.741, Train_accy 59.31, Test_accy 61.36
2024-08-07 18:48:45,999 [foster.py] => Task 8, Epoch 45/170 => Loss 5.500, Loss_clf 1.337, Loss_fe 1.075, Loss_kd 2.742, Train_accy 59.97, Test_accy 62.87
2024-08-07 18:48:53,468 [foster.py] => Task 8, Epoch 46/170 => Loss 5.560, Loss_clf 1.378, Loss_fe 1.093, Loss_kd 2.742, Train_accy 59.39
2024-08-07 18:49:03,892 [foster.py] => Task 8, Epoch 47/170 => Loss 5.517, Loss_clf 1.358, Loss_fe 1.078, Loss_kd 2.735, Train_accy 58.86, Test_accy 61.93
2024-08-07 18:49:14,227 [foster.py] => Task 8, Epoch 48/170 => Loss 5.428, Loss_clf 1.272, Loss_fe 1.067, Loss_kd 2.741, Train_accy 60.80, Test_accy 61.67
2024-08-07 18:49:24,539 [foster.py] => Task 8, Epoch 49/170 => Loss 5.451, Loss_clf 1.320, Loss_fe 1.054, Loss_kd 2.732, Train_accy 59.89, Test_accy 60.28
2024-08-07 18:49:34,970 [foster.py] => Task 8, Epoch 50/170 => Loss 5.454, Loss_clf 1.308, Loss_fe 1.061, Loss_kd 2.739, Train_accy 59.67, Test_accy 59.93
2024-08-07 18:49:42,553 [foster.py] => Task 8, Epoch 51/170 => Loss 5.434, Loss_clf 1.293, Loss_fe 1.055, Loss_kd 2.740, Train_accy 60.84
2024-08-07 18:49:52,866 [foster.py] => Task 8, Epoch 52/170 => Loss 5.363, Loss_clf 1.229, Loss_fe 1.050, Loss_kd 2.738, Train_accy 60.64, Test_accy 56.83
2024-08-07 18:50:03,207 [foster.py] => Task 8, Epoch 53/170 => Loss 5.406, Loss_clf 1.276, Loss_fe 1.044, Loss_kd 2.739, Train_accy 59.41, Test_accy 62.41
2024-08-07 18:50:13,623 [foster.py] => Task 8, Epoch 54/170 => Loss 5.376, Loss_clf 1.263, Loss_fe 1.034, Loss_kd 2.733, Train_accy 59.80, Test_accy 60.92
2024-08-07 18:50:23,995 [foster.py] => Task 8, Epoch 55/170 => Loss 5.352, Loss_clf 1.225, Loss_fe 1.039, Loss_kd 2.741, Train_accy 60.73, Test_accy 62.17
2024-08-07 18:50:31,531 [foster.py] => Task 8, Epoch 56/170 => Loss 5.370, Loss_clf 1.265, Loss_fe 1.014, Loss_kd 2.744, Train_accy 60.66
2024-08-07 18:50:41,989 [foster.py] => Task 8, Epoch 57/170 => Loss 5.253, Loss_clf 1.166, Loss_fe 1.007, Loss_kd 2.734, Train_accy 61.73, Test_accy 63.59
2024-08-07 18:50:52,620 [foster.py] => Task 8, Epoch 58/170 => Loss 5.361, Loss_clf 1.237, Loss_fe 1.028, Loss_kd 2.748, Train_accy 60.84, Test_accy 62.97
2024-08-07 18:51:03,045 [foster.py] => Task 8, Epoch 59/170 => Loss 5.378, Loss_clf 1.264, Loss_fe 1.025, Loss_kd 2.741, Train_accy 60.50, Test_accy 61.04
2024-08-07 18:51:13,367 [foster.py] => Task 8, Epoch 60/170 => Loss 5.310, Loss_clf 1.227, Loss_fe 0.998, Loss_kd 2.738, Train_accy 61.49, Test_accy 61.34
2024-08-07 18:51:20,986 [foster.py] => Task 8, Epoch 61/170 => Loss 5.431, Loss_clf 1.296, Loss_fe 1.046, Loss_kd 2.742, Train_accy 60.01
2024-08-07 18:51:31,348 [foster.py] => Task 8, Epoch 62/170 => Loss 5.398, Loss_clf 1.319, Loss_fe 0.995, Loss_kd 2.738, Train_accy 61.37, Test_accy 61.33
2024-08-07 18:51:41,629 [foster.py] => Task 8, Epoch 63/170 => Loss 5.351, Loss_clf 1.225, Loss_fe 1.038, Loss_kd 2.741, Train_accy 60.79, Test_accy 61.99
2024-08-07 18:51:51,926 [foster.py] => Task 8, Epoch 64/170 => Loss 5.239, Loss_clf 1.170, Loss_fe 0.991, Loss_kd 2.732, Train_accy 61.80, Test_accy 62.63
2024-08-07 18:52:02,204 [foster.py] => Task 8, Epoch 65/170 => Loss 5.215, Loss_clf 1.167, Loss_fe 0.969, Loss_kd 2.733, Train_accy 62.37, Test_accy 62.88
2024-08-07 18:52:09,819 [foster.py] => Task 8, Epoch 66/170 => Loss 5.248, Loss_clf 1.199, Loss_fe 0.973, Loss_kd 2.731, Train_accy 62.43
2024-08-07 18:52:20,169 [foster.py] => Task 8, Epoch 67/170 => Loss 5.281, Loss_clf 1.221, Loss_fe 0.983, Loss_kd 2.731, Train_accy 61.31, Test_accy 61.41
2024-08-07 18:52:30,549 [foster.py] => Task 8, Epoch 68/170 => Loss 5.187, Loss_clf 1.149, Loss_fe 0.954, Loss_kd 2.738, Train_accy 61.91, Test_accy 62.08
2024-08-07 18:52:41,004 [foster.py] => Task 8, Epoch 69/170 => Loss 5.209, Loss_clf 1.164, Loss_fe 0.974, Loss_kd 2.727, Train_accy 62.83, Test_accy 62.22
2024-08-07 18:52:51,388 [foster.py] => Task 8, Epoch 70/170 => Loss 5.230, Loss_clf 1.191, Loss_fe 0.957, Loss_kd 2.736, Train_accy 61.41, Test_accy 61.98
2024-08-07 18:52:58,905 [foster.py] => Task 8, Epoch 71/170 => Loss 5.173, Loss_clf 1.140, Loss_fe 0.954, Loss_kd 2.733, Train_accy 62.33
2024-08-07 18:53:09,240 [foster.py] => Task 8, Epoch 72/170 => Loss 5.140, Loss_clf 1.124, Loss_fe 0.941, Loss_kd 2.730, Train_accy 61.99, Test_accy 63.17
2024-08-07 18:53:19,547 [foster.py] => Task 8, Epoch 73/170 => Loss 5.161, Loss_clf 1.139, Loss_fe 0.937, Loss_kd 2.738, Train_accy 62.51, Test_accy 62.21
2024-08-07 18:53:29,956 [foster.py] => Task 8, Epoch 74/170 => Loss 5.188, Loss_clf 1.171, Loss_fe 0.934, Loss_kd 2.736, Train_accy 63.54, Test_accy 62.26
2024-08-07 18:53:40,570 [foster.py] => Task 8, Epoch 75/170 => Loss 5.174, Loss_clf 1.144, Loss_fe 0.942, Loss_kd 2.741, Train_accy 63.34, Test_accy 62.38
2024-08-07 18:53:48,257 [foster.py] => Task 8, Epoch 76/170 => Loss 5.125, Loss_clf 1.129, Loss_fe 0.921, Loss_kd 2.730, Train_accy 63.01
2024-08-07 18:53:58,660 [foster.py] => Task 8, Epoch 77/170 => Loss 5.150, Loss_clf 1.160, Loss_fe 0.920, Loss_kd 2.726, Train_accy 62.24, Test_accy 62.37
2024-08-07 18:54:09,051 [foster.py] => Task 8, Epoch 78/170 => Loss 5.095, Loss_clf 1.108, Loss_fe 0.913, Loss_kd 2.728, Train_accy 63.04, Test_accy 62.89
2024-08-07 18:54:19,328 [foster.py] => Task 8, Epoch 79/170 => Loss 5.115, Loss_clf 1.123, Loss_fe 0.918, Loss_kd 2.729, Train_accy 63.81, Test_accy 61.34
2024-08-07 18:54:29,620 [foster.py] => Task 8, Epoch 80/170 => Loss 5.074, Loss_clf 1.094, Loss_fe 0.897, Loss_kd 2.737, Train_accy 63.53, Test_accy 62.32
2024-08-07 18:54:37,183 [foster.py] => Task 8, Epoch 81/170 => Loss 5.005, Loss_clf 1.050, Loss_fe 0.885, Loss_kd 2.725, Train_accy 65.16
2024-08-07 18:54:47,598 [foster.py] => Task 8, Epoch 82/170 => Loss 5.039, Loss_clf 1.088, Loss_fe 0.886, Loss_kd 2.721, Train_accy 63.79, Test_accy 63.39
2024-08-07 18:54:57,973 [foster.py] => Task 8, Epoch 83/170 => Loss 5.068, Loss_clf 1.092, Loss_fe 0.898, Loss_kd 2.733, Train_accy 63.66, Test_accy 63.22
2024-08-07 18:55:08,266 [foster.py] => Task 8, Epoch 84/170 => Loss 5.001, Loss_clf 1.052, Loss_fe 0.870, Loss_kd 2.733, Train_accy 64.40, Test_accy 62.22
2024-08-07 18:55:18,819 [foster.py] => Task 8, Epoch 85/170 => Loss 4.983, Loss_clf 1.068, Loss_fe 0.855, Loss_kd 2.716, Train_accy 64.29, Test_accy 62.97
2024-08-07 18:55:26,702 [foster.py] => Task 8, Epoch 86/170 => Loss 5.027, Loss_clf 1.085, Loss_fe 0.864, Loss_kd 2.733, Train_accy 64.07
2024-08-07 18:55:37,118 [foster.py] => Task 8, Epoch 87/170 => Loss 5.011, Loss_clf 1.071, Loss_fe 0.861, Loss_kd 2.733, Train_accy 64.87, Test_accy 64.01
2024-08-07 18:55:47,472 [foster.py] => Task 8, Epoch 88/170 => Loss 5.003, Loss_clf 1.057, Loss_fe 0.864, Loss_kd 2.736, Train_accy 65.67, Test_accy 63.54
2024-08-07 18:55:57,758 [foster.py] => Task 8, Epoch 89/170 => Loss 4.941, Loss_clf 1.023, Loss_fe 0.840, Loss_kd 2.732, Train_accy 65.41, Test_accy 64.21
2024-08-07 18:56:08,100 [foster.py] => Task 8, Epoch 90/170 => Loss 4.963, Loss_clf 1.040, Loss_fe 0.843, Loss_kd 2.735, Train_accy 65.04, Test_accy 62.79
2024-08-07 18:56:15,646 [foster.py] => Task 8, Epoch 91/170 => Loss 5.039, Loss_clf 1.092, Loss_fe 0.862, Loss_kd 2.738, Train_accy 64.61
2024-08-07 18:56:26,018 [foster.py] => Task 8, Epoch 92/170 => Loss 4.898, Loss_clf 1.000, Loss_fe 0.829, Loss_kd 2.724, Train_accy 65.80, Test_accy 64.11
2024-08-07 18:56:36,318 [foster.py] => Task 8, Epoch 93/170 => Loss 4.956, Loss_clf 1.038, Loss_fe 0.838, Loss_kd 2.734, Train_accy 65.03, Test_accy 62.61
2024-08-07 18:56:46,627 [foster.py] => Task 8, Epoch 94/170 => Loss 4.934, Loss_clf 1.024, Loss_fe 0.825, Loss_kd 2.739, Train_accy 66.41, Test_accy 64.09
2024-08-07 18:56:56,904 [foster.py] => Task 8, Epoch 95/170 => Loss 4.937, Loss_clf 1.027, Loss_fe 0.830, Loss_kd 2.735, Train_accy 65.71, Test_accy 62.82
2024-08-07 18:57:04,517 [foster.py] => Task 8, Epoch 96/170 => Loss 4.909, Loss_clf 1.009, Loss_fe 0.826, Loss_kd 2.729, Train_accy 65.40
2024-08-07 18:57:14,836 [foster.py] => Task 8, Epoch 97/170 => Loss 4.864, Loss_clf 0.977, Loss_fe 0.806, Loss_kd 2.735, Train_accy 66.71, Test_accy 64.43
2024-08-07 18:57:25,273 [foster.py] => Task 8, Epoch 98/170 => Loss 4.927, Loss_clf 1.043, Loss_fe 0.813, Loss_kd 2.727, Train_accy 66.03, Test_accy 63.76
2024-08-07 18:57:35,825 [foster.py] => Task 8, Epoch 99/170 => Loss 4.814, Loss_clf 0.959, Loss_fe 0.792, Loss_kd 2.720, Train_accy 66.83, Test_accy 64.39
2024-08-07 18:57:46,444 [foster.py] => Task 8, Epoch 100/170 => Loss 4.847, Loss_clf 0.979, Loss_fe 0.801, Loss_kd 2.722, Train_accy 66.90, Test_accy 63.52
2024-08-07 18:57:54,134 [foster.py] => Task 8, Epoch 101/170 => Loss 4.836, Loss_clf 0.998, Loss_fe 0.760, Loss_kd 2.733, Train_accy 67.04
2024-08-07 18:58:04,535 [foster.py] => Task 8, Epoch 102/170 => Loss 4.797, Loss_clf 0.964, Loss_fe 0.764, Loss_kd 2.725, Train_accy 67.04, Test_accy 64.59
2024-08-07 18:58:14,878 [foster.py] => Task 8, Epoch 103/170 => Loss 4.874, Loss_clf 1.004, Loss_fe 0.790, Loss_kd 2.735, Train_accy 67.07, Test_accy 63.82
2024-08-07 18:58:25,233 [foster.py] => Task 8, Epoch 104/170 => Loss 4.786, Loss_clf 0.953, Loss_fe 0.760, Loss_kd 2.727, Train_accy 67.40, Test_accy 64.46
2024-08-07 18:58:35,523 [foster.py] => Task 8, Epoch 105/170 => Loss 4.778, Loss_clf 0.944, Loss_fe 0.763, Loss_kd 2.725, Train_accy 67.81, Test_accy 64.40
2024-08-07 18:58:43,171 [foster.py] => Task 8, Epoch 106/170 => Loss 4.779, Loss_clf 0.951, Loss_fe 0.760, Loss_kd 2.724, Train_accy 68.50
2024-08-07 18:58:53,648 [foster.py] => Task 8, Epoch 107/170 => Loss 4.768, Loss_clf 0.952, Loss_fe 0.741, Loss_kd 2.730, Train_accy 68.43, Test_accy 64.46
2024-08-07 18:59:04,122 [foster.py] => Task 8, Epoch 108/170 => Loss 4.788, Loss_clf 0.960, Loss_fe 0.747, Loss_kd 2.734, Train_accy 68.19, Test_accy 64.62
2024-08-07 18:59:14,583 [foster.py] => Task 8, Epoch 109/170 => Loss 4.760, Loss_clf 0.940, Loss_fe 0.751, Loss_kd 2.725, Train_accy 67.26, Test_accy 64.11
2024-08-07 18:59:24,934 [foster.py] => Task 8, Epoch 110/170 => Loss 4.779, Loss_clf 0.960, Loss_fe 0.741, Loss_kd 2.733, Train_accy 68.01, Test_accy 64.54
2024-08-07 18:59:32,450 [foster.py] => Task 8, Epoch 111/170 => Loss 4.710, Loss_clf 0.926, Loss_fe 0.710, Loss_kd 2.728, Train_accy 68.84
2024-08-07 18:59:42,824 [foster.py] => Task 8, Epoch 112/170 => Loss 4.686, Loss_clf 0.896, Loss_fe 0.709, Loss_kd 2.735, Train_accy 69.23, Test_accy 64.66
2024-08-07 18:59:53,149 [foster.py] => Task 8, Epoch 113/170 => Loss 4.668, Loss_clf 0.892, Loss_fe 0.699, Loss_kd 2.732, Train_accy 69.14, Test_accy 64.72
2024-08-07 19:00:03,529 [foster.py] => Task 8, Epoch 114/170 => Loss 4.614, Loss_clf 0.874, Loss_fe 0.675, Loss_kd 2.721, Train_accy 70.06, Test_accy 64.90
2024-08-07 19:00:13,886 [foster.py] => Task 8, Epoch 115/170 => Loss 4.652, Loss_clf 0.887, Loss_fe 0.689, Loss_kd 2.731, Train_accy 69.54, Test_accy 65.00
2024-08-07 19:00:21,448 [foster.py] => Task 8, Epoch 116/170 => Loss 4.612, Loss_clf 0.871, Loss_fe 0.672, Loss_kd 2.724, Train_accy 69.76
2024-08-07 19:00:31,775 [foster.py] => Task 8, Epoch 117/170 => Loss 4.592, Loss_clf 0.860, Loss_fe 0.664, Loss_kd 2.724, Train_accy 70.04, Test_accy 64.31
2024-08-07 19:00:42,073 [foster.py] => Task 8, Epoch 118/170 => Loss 4.613, Loss_clf 0.871, Loss_fe 0.667, Loss_kd 2.730, Train_accy 70.67, Test_accy 65.08
2024-08-07 19:00:52,471 [foster.py] => Task 8, Epoch 119/170 => Loss 4.577, Loss_clf 0.854, Loss_fe 0.666, Loss_kd 2.713, Train_accy 70.31, Test_accy 64.67
2024-08-07 19:01:02,803 [foster.py] => Task 8, Epoch 120/170 => Loss 4.580, Loss_clf 0.861, Loss_fe 0.647, Loss_kd 2.727, Train_accy 70.84, Test_accy 64.82
2024-08-07 19:01:10,380 [foster.py] => Task 8, Epoch 121/170 => Loss 4.576, Loss_clf 0.858, Loss_fe 0.649, Loss_kd 2.725, Train_accy 70.86
2024-08-07 19:01:20,731 [foster.py] => Task 8, Epoch 122/170 => Loss 4.562, Loss_clf 0.844, Loss_fe 0.657, Loss_kd 2.718, Train_accy 71.09, Test_accy 64.92
2024-08-07 19:01:31,212 [foster.py] => Task 8, Epoch 123/170 => Loss 4.540, Loss_clf 0.837, Loss_fe 0.633, Loss_kd 2.726, Train_accy 72.14, Test_accy 65.21
2024-08-07 19:01:41,539 [foster.py] => Task 8, Epoch 124/170 => Loss 4.496, Loss_clf 0.811, Loss_fe 0.612, Loss_kd 2.728, Train_accy 72.43, Test_accy 65.31
2024-08-07 19:01:51,854 [foster.py] => Task 8, Epoch 125/170 => Loss 4.469, Loss_clf 0.809, Loss_fe 0.602, Loss_kd 2.715, Train_accy 72.26, Test_accy 65.32
2024-08-07 19:01:59,571 [foster.py] => Task 8, Epoch 126/170 => Loss 4.493, Loss_clf 0.815, Loss_fe 0.608, Loss_kd 2.726, Train_accy 71.64
2024-08-07 19:02:09,978 [foster.py] => Task 8, Epoch 127/170 => Loss 4.497, Loss_clf 0.818, Loss_fe 0.606, Loss_kd 2.729, Train_accy 71.99, Test_accy 65.57
2024-08-07 19:02:20,314 [foster.py] => Task 8, Epoch 128/170 => Loss 4.463, Loss_clf 0.800, Loss_fe 0.588, Loss_kd 2.729, Train_accy 72.54, Test_accy 65.28
2024-08-07 19:02:30,797 [foster.py] => Task 8, Epoch 129/170 => Loss 4.408, Loss_clf 0.767, Loss_fe 0.577, Loss_kd 2.720, Train_accy 73.57, Test_accy 65.19
2024-08-07 19:02:41,244 [foster.py] => Task 8, Epoch 130/170 => Loss 4.408, Loss_clf 0.770, Loss_fe 0.569, Loss_kd 2.725, Train_accy 73.56, Test_accy 65.33
2024-08-07 19:02:48,999 [foster.py] => Task 8, Epoch 131/170 => Loss 4.381, Loss_clf 0.764, Loss_fe 0.552, Loss_kd 2.721, Train_accy 73.91
2024-08-07 19:02:59,278 [foster.py] => Task 8, Epoch 132/170 => Loss 4.398, Loss_clf 0.772, Loss_fe 0.563, Loss_kd 2.719, Train_accy 74.64, Test_accy 65.71
2024-08-07 19:03:09,653 [foster.py] => Task 8, Epoch 133/170 => Loss 4.445, Loss_clf 0.795, Loss_fe 0.574, Loss_kd 2.730, Train_accy 73.11, Test_accy 64.82
2024-08-07 19:03:19,991 [foster.py] => Task 8, Epoch 134/170 => Loss 4.346, Loss_clf 0.746, Loss_fe 0.538, Loss_kd 2.718, Train_accy 75.11, Test_accy 66.12
2024-08-07 19:03:30,414 [foster.py] => Task 8, Epoch 135/170 => Loss 4.314, Loss_clf 0.726, Loss_fe 0.520, Loss_kd 2.723, Train_accy 75.16, Test_accy 66.30
2024-08-07 19:03:38,024 [foster.py] => Task 8, Epoch 136/170 => Loss 4.298, Loss_clf 0.717, Loss_fe 0.522, Loss_kd 2.716, Train_accy 75.66
2024-08-07 19:03:48,370 [foster.py] => Task 8, Epoch 137/170 => Loss 4.425, Loss_clf 0.782, Loss_fe 0.565, Loss_kd 2.733, Train_accy 74.30, Test_accy 65.89
2024-08-07 19:03:58,681 [foster.py] => Task 8, Epoch 138/170 => Loss 4.349, Loss_clf 0.741, Loss_fe 0.529, Loss_kd 2.734, Train_accy 74.93, Test_accy 66.13
2024-08-07 19:04:09,108 [foster.py] => Task 8, Epoch 139/170 => Loss 4.278, Loss_clf 0.706, Loss_fe 0.511, Loss_kd 2.717, Train_accy 76.14, Test_accy 65.93
2024-08-07 19:04:19,433 [foster.py] => Task 8, Epoch 140/170 => Loss 4.296, Loss_clf 0.722, Loss_fe 0.507, Loss_kd 2.723, Train_accy 75.93, Test_accy 65.60
2024-08-07 19:04:26,996 [foster.py] => Task 8, Epoch 141/170 => Loss 4.248, Loss_clf 0.690, Loss_fe 0.493, Loss_kd 2.721, Train_accy 76.64
2024-08-07 19:04:37,303 [foster.py] => Task 8, Epoch 142/170 => Loss 4.261, Loss_clf 0.697, Loss_fe 0.495, Loss_kd 2.724, Train_accy 75.91, Test_accy 65.81
2024-08-07 19:04:47,585 [foster.py] => Task 8, Epoch 143/170 => Loss 4.231, Loss_clf 0.683, Loss_fe 0.477, Loss_kd 2.726, Train_accy 76.96, Test_accy 66.10
2024-08-07 19:04:58,078 [foster.py] => Task 8, Epoch 144/170 => Loss 4.243, Loss_clf 0.690, Loss_fe 0.478, Loss_kd 2.730, Train_accy 76.51, Test_accy 66.00
2024-08-07 19:05:08,591 [foster.py] => Task 8, Epoch 145/170 => Loss 4.266, Loss_clf 0.708, Loss_fe 0.487, Loss_kd 2.726, Train_accy 76.64, Test_accy 66.17
2024-08-07 19:05:16,376 [foster.py] => Task 8, Epoch 146/170 => Loss 4.194, Loss_clf 0.673, Loss_fe 0.452, Loss_kd 2.724, Train_accy 77.84
2024-08-07 19:05:26,779 [foster.py] => Task 8, Epoch 147/170 => Loss 4.183, Loss_clf 0.669, Loss_fe 0.454, Loss_kd 2.716, Train_accy 78.31, Test_accy 65.90
2024-08-07 19:05:37,146 [foster.py] => Task 8, Epoch 148/170 => Loss 4.230, Loss_clf 0.691, Loss_fe 0.470, Loss_kd 2.724, Train_accy 76.10, Test_accy 66.00
2024-08-07 19:05:47,464 [foster.py] => Task 8, Epoch 149/170 => Loss 4.161, Loss_clf 0.667, Loss_fe 0.436, Loss_kd 2.715, Train_accy 77.34, Test_accy 65.89
2024-08-07 19:05:57,967 [foster.py] => Task 8, Epoch 150/170 => Loss 4.199, Loss_clf 0.680, Loss_fe 0.441, Loss_kd 2.732, Train_accy 76.74, Test_accy 65.90
2024-08-07 19:06:05,521 [foster.py] => Task 8, Epoch 151/170 => Loss 4.154, Loss_clf 0.650, Loss_fe 0.430, Loss_kd 2.729, Train_accy 77.96
2024-08-07 19:06:15,919 [foster.py] => Task 8, Epoch 152/170 => Loss 4.123, Loss_clf 0.638, Loss_fe 0.422, Loss_kd 2.719, Train_accy 78.81, Test_accy 66.29
2024-08-07 19:06:26,219 [foster.py] => Task 8, Epoch 153/170 => Loss 4.104, Loss_clf 0.626, Loss_fe 0.412, Loss_kd 2.721, Train_accy 79.13, Test_accy 66.27
2024-08-07 19:06:36,577 [foster.py] => Task 8, Epoch 154/170 => Loss 4.170, Loss_clf 0.666, Loss_fe 0.438, Loss_kd 2.722, Train_accy 78.50, Test_accy 66.32
2024-08-07 19:06:46,860 [foster.py] => Task 8, Epoch 155/170 => Loss 4.143, Loss_clf 0.647, Loss_fe 0.430, Loss_kd 2.722, Train_accy 78.53, Test_accy 66.29
2024-08-07 19:06:54,522 [foster.py] => Task 8, Epoch 156/170 => Loss 4.102, Loss_clf 0.632, Loss_fe 0.411, Loss_kd 2.715, Train_accy 79.36
2024-08-07 19:07:05,169 [foster.py] => Task 8, Epoch 157/170 => Loss 4.113, Loss_clf 0.638, Loss_fe 0.406, Loss_kd 2.724, Train_accy 78.54, Test_accy 66.08
2024-08-07 19:07:15,928 [foster.py] => Task 8, Epoch 158/170 => Loss 4.095, Loss_clf 0.628, Loss_fe 0.408, Loss_kd 2.715, Train_accy 79.76, Test_accy 66.10
2024-08-07 19:07:26,277 [foster.py] => Task 8, Epoch 159/170 => Loss 4.163, Loss_clf 0.662, Loss_fe 0.428, Loss_kd 2.728, Train_accy 78.41, Test_accy 66.23
2024-08-07 19:07:36,586 [foster.py] => Task 8, Epoch 160/170 => Loss 4.084, Loss_clf 0.621, Loss_fe 0.390, Loss_kd 2.728, Train_accy 78.93, Test_accy 66.24
2024-08-07 19:07:44,112 [foster.py] => Task 8, Epoch 161/170 => Loss 4.085, Loss_clf 0.622, Loss_fe 0.397, Loss_kd 2.722, Train_accy 79.30
2024-08-07 19:07:54,444 [foster.py] => Task 8, Epoch 162/170 => Loss 4.075, Loss_clf 0.610, Loss_fe 0.397, Loss_kd 2.724, Train_accy 80.03, Test_accy 66.17
2024-08-07 19:08:04,832 [foster.py] => Task 8, Epoch 163/170 => Loss 4.114, Loss_clf 0.636, Loss_fe 0.405, Loss_kd 2.729, Train_accy 79.87, Test_accy 66.23
2024-08-07 19:08:15,344 [foster.py] => Task 8, Epoch 164/170 => Loss 4.060, Loss_clf 0.608, Loss_fe 0.385, Loss_kd 2.723, Train_accy 79.83, Test_accy 66.20
2024-08-07 19:08:25,664 [foster.py] => Task 8, Epoch 165/170 => Loss 4.117, Loss_clf 0.629, Loss_fe 0.407, Loss_kd 2.734, Train_accy 79.79, Test_accy 66.20
2024-08-07 19:08:33,271 [foster.py] => Task 8, Epoch 166/170 => Loss 4.106, Loss_clf 0.638, Loss_fe 0.399, Loss_kd 2.725, Train_accy 79.11
2024-08-07 19:08:43,573 [foster.py] => Task 8, Epoch 167/170 => Loss 4.071, Loss_clf 0.625, Loss_fe 0.383, Loss_kd 2.720, Train_accy 79.60, Test_accy 66.17
2024-08-07 19:08:53,894 [foster.py] => Task 8, Epoch 168/170 => Loss 4.088, Loss_clf 0.629, Loss_fe 0.393, Loss_kd 2.722, Train_accy 78.59, Test_accy 66.16
2024-08-07 19:09:04,323 [foster.py] => Task 8, Epoch 169/170 => Loss 4.094, Loss_clf 0.625, Loss_fe 0.390, Loss_kd 2.733, Train_accy 79.36, Test_accy 66.19
2024-08-07 19:09:14,751 [foster.py] => Task 8, Epoch 170/170 => Loss 4.067, Loss_clf 0.616, Loss_fe 0.384, Loss_kd 2.723, Train_accy 79.71, Test_accy 66.17
2024-08-07 19:09:14,754 [foster.py] => do not weight align teacher!
2024-08-07 19:09:14,757 [foster.py] => per cls weights : [1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541 1.05435541
 1.05435541 1.05435541 0.56515672 0.56515672 0.56515672 0.56515672
 0.56515672 0.56515672 0.56515672 0.56515672 0.56515672 0.56515672]
2024-08-07 19:09:28,201 [foster.py] => SNet: Task 8, Epoch 1/130 => Loss 31.230,  Loss1 0.768, Train_accy 29.06, Test_accy 60.00
2024-08-07 19:09:38,615 [foster.py] => SNet: Task 8, Epoch 2/130 => Loss 31.132,  Loss1 0.768, Train_accy 42.14
2024-08-07 19:09:48,960 [foster.py] => SNet: Task 8, Epoch 3/130 => Loss 31.126,  Loss1 0.768, Train_accy 47.73
2024-08-07 19:09:59,583 [foster.py] => SNet: Task 8, Epoch 4/130 => Loss 31.119,  Loss1 0.768, Train_accy 49.96
2024-08-07 19:10:10,402 [foster.py] => SNet: Task 8, Epoch 5/130 => Loss 31.091,  Loss1 0.768, Train_accy 52.83
2024-08-07 19:10:23,535 [foster.py] => SNet: Task 8, Epoch 6/130 => Loss 31.092,  Loss1 0.768, Train_accy 54.59, Test_accy 62.13
2024-08-07 19:10:34,478 [foster.py] => SNet: Task 8, Epoch 7/130 => Loss 31.071,  Loss1 0.768, Train_accy 55.24
2024-08-07 19:10:44,864 [foster.py] => SNet: Task 8, Epoch 8/130 => Loss 31.067,  Loss1 0.768, Train_accy 56.26
2024-08-07 19:10:55,881 [foster.py] => SNet: Task 8, Epoch 9/130 => Loss 31.056,  Loss1 0.768, Train_accy 56.37
2024-08-07 19:11:06,550 [foster.py] => SNet: Task 8, Epoch 10/130 => Loss 31.061,  Loss1 0.768, Train_accy 56.87
2024-08-07 19:11:19,817 [foster.py] => SNet: Task 8, Epoch 11/130 => Loss 31.063,  Loss1 0.768, Train_accy 58.23, Test_accy 62.00
2024-08-07 19:11:30,271 [foster.py] => SNet: Task 8, Epoch 12/130 => Loss 31.043,  Loss1 0.768, Train_accy 58.44
2024-08-07 19:11:40,782 [foster.py] => SNet: Task 8, Epoch 13/130 => Loss 31.060,  Loss1 0.768, Train_accy 59.21
2024-08-07 19:11:51,521 [foster.py] => SNet: Task 8, Epoch 14/130 => Loss 31.063,  Loss1 0.768, Train_accy 59.21
2024-08-07 19:12:02,055 [foster.py] => SNet: Task 8, Epoch 15/130 => Loss 31.043,  Loss1 0.768, Train_accy 59.41
2024-08-07 19:12:14,962 [foster.py] => SNet: Task 8, Epoch 16/130 => Loss 31.057,  Loss1 0.768, Train_accy 59.61, Test_accy 62.83
2024-08-07 19:12:25,517 [foster.py] => SNet: Task 8, Epoch 17/130 => Loss 31.042,  Loss1 0.768, Train_accy 60.69
2024-08-07 19:12:36,167 [foster.py] => SNet: Task 8, Epoch 18/130 => Loss 31.063,  Loss1 0.768, Train_accy 60.14
2024-08-07 19:12:46,541 [foster.py] => SNet: Task 8, Epoch 19/130 => Loss 31.039,  Loss1 0.768, Train_accy 59.87
2024-08-07 19:12:56,904 [foster.py] => SNet: Task 8, Epoch 20/130 => Loss 31.058,  Loss1 0.768, Train_accy 60.96
2024-08-07 19:13:09,800 [foster.py] => SNet: Task 8, Epoch 21/130 => Loss 31.037,  Loss1 0.768, Train_accy 60.94, Test_accy 63.26
2024-08-07 19:13:20,255 [foster.py] => SNet: Task 8, Epoch 22/130 => Loss 31.059,  Loss1 0.768, Train_accy 61.07
2024-08-07 19:13:30,985 [foster.py] => SNet: Task 8, Epoch 23/130 => Loss 31.025,  Loss1 0.768, Train_accy 61.80
2024-08-07 19:13:41,524 [foster.py] => SNet: Task 8, Epoch 24/130 => Loss 31.065,  Loss1 0.767, Train_accy 62.30
2024-08-07 19:13:52,025 [foster.py] => SNet: Task 8, Epoch 25/130 => Loss 31.037,  Loss1 0.767, Train_accy 60.80
2024-08-07 19:14:04,878 [foster.py] => SNet: Task 8, Epoch 26/130 => Loss 31.059,  Loss1 0.768, Train_accy 62.43, Test_accy 62.51
2024-08-07 19:14:15,348 [foster.py] => SNet: Task 8, Epoch 27/130 => Loss 31.062,  Loss1 0.768, Train_accy 61.83
2024-08-07 19:14:26,061 [foster.py] => SNet: Task 8, Epoch 28/130 => Loss 31.036,  Loss1 0.768, Train_accy 62.13
2024-08-07 19:14:36,419 [foster.py] => SNet: Task 8, Epoch 29/130 => Loss 31.038,  Loss1 0.768, Train_accy 61.26
2024-08-07 19:14:46,943 [foster.py] => SNet: Task 8, Epoch 30/130 => Loss 31.053,  Loss1 0.767, Train_accy 62.17
2024-08-07 19:14:59,812 [foster.py] => SNet: Task 8, Epoch 31/130 => Loss 31.051,  Loss1 0.768, Train_accy 61.89, Test_accy 62.78
2024-08-07 19:15:10,756 [foster.py] => SNet: Task 8, Epoch 32/130 => Loss 31.033,  Loss1 0.768, Train_accy 62.81
2024-08-07 19:15:21,256 [foster.py] => SNet: Task 8, Epoch 33/130 => Loss 31.030,  Loss1 0.768, Train_accy 63.27
2024-08-07 19:15:32,017 [foster.py] => SNet: Task 8, Epoch 34/130 => Loss 31.050,  Loss1 0.767, Train_accy 62.63
2024-08-07 19:15:42,458 [foster.py] => SNet: Task 8, Epoch 35/130 => Loss 31.038,  Loss1 0.768, Train_accy 62.47
2024-08-07 19:15:55,653 [foster.py] => SNet: Task 8, Epoch 36/130 => Loss 31.037,  Loss1 0.767, Train_accy 62.26, Test_accy 63.20
2024-08-07 19:16:06,164 [foster.py] => SNet: Task 8, Epoch 37/130 => Loss 31.058,  Loss1 0.767, Train_accy 63.84
2024-08-07 19:16:16,949 [foster.py] => SNet: Task 8, Epoch 38/130 => Loss 31.052,  Loss1 0.768, Train_accy 63.07
2024-08-07 19:16:27,389 [foster.py] => SNet: Task 8, Epoch 39/130 => Loss 31.043,  Loss1 0.768, Train_accy 62.64
2024-08-07 19:16:38,045 [foster.py] => SNet: Task 8, Epoch 40/130 => Loss 31.045,  Loss1 0.768, Train_accy 63.66
2024-08-07 19:16:50,875 [foster.py] => SNet: Task 8, Epoch 41/130 => Loss 31.033,  Loss1 0.767, Train_accy 63.17, Test_accy 63.43
2024-08-07 19:17:01,321 [foster.py] => SNet: Task 8, Epoch 42/130 => Loss 31.070,  Loss1 0.768, Train_accy 63.66
2024-08-07 19:17:11,734 [foster.py] => SNet: Task 8, Epoch 43/130 => Loss 31.021,  Loss1 0.768, Train_accy 62.84
2024-08-07 19:17:22,210 [foster.py] => SNet: Task 8, Epoch 44/130 => Loss 31.033,  Loss1 0.767, Train_accy 62.96
2024-08-07 19:17:32,823 [foster.py] => SNet: Task 8, Epoch 45/130 => Loss 31.037,  Loss1 0.768, Train_accy 64.07
2024-08-07 19:17:45,752 [foster.py] => SNet: Task 8, Epoch 46/130 => Loss 31.013,  Loss1 0.768, Train_accy 64.60, Test_accy 63.59
2024-08-07 19:17:56,416 [foster.py] => SNet: Task 8, Epoch 47/130 => Loss 31.023,  Loss1 0.768, Train_accy 63.44
2024-08-07 19:18:06,912 [foster.py] => SNet: Task 8, Epoch 48/130 => Loss 31.041,  Loss1 0.768, Train_accy 64.66
2024-08-07 19:18:17,471 [foster.py] => SNet: Task 8, Epoch 49/130 => Loss 31.036,  Loss1 0.768, Train_accy 63.40
2024-08-07 19:18:28,061 [foster.py] => SNet: Task 8, Epoch 50/130 => Loss 31.025,  Loss1 0.767, Train_accy 64.36
2024-08-07 19:18:41,026 [foster.py] => SNet: Task 8, Epoch 51/130 => Loss 31.033,  Loss1 0.767, Train_accy 63.70, Test_accy 64.32
2024-08-07 19:18:51,665 [foster.py] => SNet: Task 8, Epoch 52/130 => Loss 31.026,  Loss1 0.768, Train_accy 63.74
2024-08-07 19:19:02,370 [foster.py] => SNet: Task 8, Epoch 53/130 => Loss 31.047,  Loss1 0.767, Train_accy 63.93
2024-08-07 19:19:13,044 [foster.py] => SNet: Task 8, Epoch 54/130 => Loss 31.051,  Loss1 0.768, Train_accy 63.69
2024-08-07 19:19:23,966 [foster.py] => SNet: Task 8, Epoch 55/130 => Loss 31.012,  Loss1 0.768, Train_accy 63.59
2024-08-07 19:19:37,440 [foster.py] => SNet: Task 8, Epoch 56/130 => Loss 31.047,  Loss1 0.768, Train_accy 63.94, Test_accy 63.88
2024-08-07 19:19:47,793 [foster.py] => SNet: Task 8, Epoch 57/130 => Loss 31.042,  Loss1 0.768, Train_accy 63.50
2024-08-07 19:19:58,272 [foster.py] => SNet: Task 8, Epoch 58/130 => Loss 31.041,  Loss1 0.767, Train_accy 65.24
2024-08-07 19:20:08,967 [foster.py] => SNet: Task 8, Epoch 59/130 => Loss 31.043,  Loss1 0.767, Train_accy 63.80
2024-08-07 19:20:19,679 [foster.py] => SNet: Task 8, Epoch 60/130 => Loss 31.023,  Loss1 0.768, Train_accy 63.70
2024-08-07 19:20:32,514 [foster.py] => SNet: Task 8, Epoch 61/130 => Loss 31.030,  Loss1 0.768, Train_accy 64.59, Test_accy 64.26
2024-08-07 19:20:43,015 [foster.py] => SNet: Task 8, Epoch 62/130 => Loss 31.032,  Loss1 0.768, Train_accy 64.43
2024-08-07 19:20:54,001 [foster.py] => SNet: Task 8, Epoch 63/130 => Loss 31.023,  Loss1 0.768, Train_accy 64.40
2024-08-07 19:21:04,575 [foster.py] => SNet: Task 8, Epoch 64/130 => Loss 31.013,  Loss1 0.768, Train_accy 64.76
2024-08-07 19:21:15,542 [foster.py] => SNet: Task 8, Epoch 65/130 => Loss 31.021,  Loss1 0.768, Train_accy 64.66
2024-08-07 19:21:28,425 [foster.py] => SNet: Task 8, Epoch 66/130 => Loss 31.024,  Loss1 0.768, Train_accy 64.87, Test_accy 64.04
2024-08-07 19:21:38,932 [foster.py] => SNet: Task 8, Epoch 67/130 => Loss 30.999,  Loss1 0.768, Train_accy 65.31
2024-08-07 19:21:49,315 [foster.py] => SNet: Task 8, Epoch 68/130 => Loss 31.050,  Loss1 0.768, Train_accy 64.29
2024-08-07 19:22:00,026 [foster.py] => SNet: Task 8, Epoch 69/130 => Loss 31.028,  Loss1 0.767, Train_accy 65.43
2024-08-07 19:22:10,620 [foster.py] => SNet: Task 8, Epoch 70/130 => Loss 31.010,  Loss1 0.768, Train_accy 64.41
2024-08-07 19:22:24,075 [foster.py] => SNet: Task 8, Epoch 71/130 => Loss 31.006,  Loss1 0.767, Train_accy 65.16, Test_accy 64.06
2024-08-07 19:22:34,992 [foster.py] => SNet: Task 8, Epoch 72/130 => Loss 31.016,  Loss1 0.767, Train_accy 65.11
2024-08-07 19:22:45,415 [foster.py] => SNet: Task 8, Epoch 73/130 => Loss 31.001,  Loss1 0.768, Train_accy 64.60
2024-08-07 19:22:55,993 [foster.py] => SNet: Task 8, Epoch 74/130 => Loss 31.024,  Loss1 0.768, Train_accy 64.90
2024-08-07 19:23:06,387 [foster.py] => SNet: Task 8, Epoch 75/130 => Loss 31.021,  Loss1 0.768, Train_accy 65.07
2024-08-07 19:23:19,605 [foster.py] => SNet: Task 8, Epoch 76/130 => Loss 31.018,  Loss1 0.768, Train_accy 64.03, Test_accy 64.01
2024-08-07 19:23:30,051 [foster.py] => SNet: Task 8, Epoch 77/130 => Loss 31.016,  Loss1 0.767, Train_accy 65.23
2024-08-07 19:23:40,458 [foster.py] => SNet: Task 8, Epoch 78/130 => Loss 31.019,  Loss1 0.768, Train_accy 64.57
2024-08-07 19:23:50,894 [foster.py] => SNet: Task 8, Epoch 79/130 => Loss 31.026,  Loss1 0.767, Train_accy 64.04
2024-08-07 19:24:01,709 [foster.py] => SNet: Task 8, Epoch 80/130 => Loss 31.037,  Loss1 0.768, Train_accy 65.23
2024-08-07 19:24:14,796 [foster.py] => SNet: Task 8, Epoch 81/130 => Loss 31.016,  Loss1 0.767, Train_accy 66.16, Test_accy 64.33
2024-08-07 19:24:25,332 [foster.py] => SNet: Task 8, Epoch 82/130 => Loss 31.009,  Loss1 0.767, Train_accy 65.30
2024-08-07 19:24:36,072 [foster.py] => SNet: Task 8, Epoch 83/130 => Loss 31.019,  Loss1 0.768, Train_accy 65.77
2024-08-07 19:24:46,631 [foster.py] => SNet: Task 8, Epoch 84/130 => Loss 31.036,  Loss1 0.767, Train_accy 65.10
2024-08-07 19:24:57,268 [foster.py] => SNet: Task 8, Epoch 85/130 => Loss 31.019,  Loss1 0.768, Train_accy 65.19
2024-08-07 19:25:10,145 [foster.py] => SNet: Task 8, Epoch 86/130 => Loss 31.031,  Loss1 0.767, Train_accy 65.24, Test_accy 64.38
2024-08-07 19:25:20,686 [foster.py] => SNet: Task 8, Epoch 87/130 => Loss 31.012,  Loss1 0.767, Train_accy 66.73
2024-08-07 19:25:31,226 [foster.py] => SNet: Task 8, Epoch 88/130 => Loss 31.017,  Loss1 0.767, Train_accy 65.24
2024-08-07 19:25:41,897 [foster.py] => SNet: Task 8, Epoch 89/130 => Loss 31.035,  Loss1 0.768, Train_accy 65.93
2024-08-07 19:25:52,319 [foster.py] => SNet: Task 8, Epoch 90/130 => Loss 31.014,  Loss1 0.767, Train_accy 64.54
2024-08-07 19:26:05,420 [foster.py] => SNet: Task 8, Epoch 91/130 => Loss 31.004,  Loss1 0.768, Train_accy 65.80, Test_accy 64.54
2024-08-07 19:26:15,909 [foster.py] => SNet: Task 8, Epoch 92/130 => Loss 31.035,  Loss1 0.767, Train_accy 65.36
2024-08-07 19:26:26,608 [foster.py] => SNet: Task 8, Epoch 93/130 => Loss 31.020,  Loss1 0.768, Train_accy 65.90
2024-08-07 19:26:37,299 [foster.py] => SNet: Task 8, Epoch 94/130 => Loss 31.036,  Loss1 0.767, Train_accy 65.11
2024-08-07 19:26:47,805 [foster.py] => SNet: Task 8, Epoch 95/130 => Loss 31.037,  Loss1 0.768, Train_accy 64.59
2024-08-07 19:27:00,758 [foster.py] => SNet: Task 8, Epoch 96/130 => Loss 30.995,  Loss1 0.768, Train_accy 65.46, Test_accy 64.44
2024-08-07 19:27:11,229 [foster.py] => SNet: Task 8, Epoch 97/130 => Loss 31.026,  Loss1 0.767, Train_accy 65.33
2024-08-07 19:27:21,752 [foster.py] => SNet: Task 8, Epoch 98/130 => Loss 31.017,  Loss1 0.767, Train_accy 64.80
2024-08-07 19:27:32,134 [foster.py] => SNet: Task 8, Epoch 99/130 => Loss 31.019,  Loss1 0.767, Train_accy 65.83
2024-08-07 19:27:42,567 [foster.py] => SNet: Task 8, Epoch 100/130 => Loss 30.998,  Loss1 0.768, Train_accy 66.14
2024-08-07 19:27:55,622 [foster.py] => SNet: Task 8, Epoch 101/130 => Loss 31.029,  Loss1 0.768, Train_accy 65.33, Test_accy 64.49
2024-08-07 19:28:06,120 [foster.py] => SNet: Task 8, Epoch 102/130 => Loss 31.010,  Loss1 0.768, Train_accy 65.63
2024-08-07 19:28:16,616 [foster.py] => SNet: Task 8, Epoch 103/130 => Loss 31.012,  Loss1 0.767, Train_accy 66.04
2024-08-07 19:28:27,174 [foster.py] => SNet: Task 8, Epoch 104/130 => Loss 31.016,  Loss1 0.767, Train_accy 65.81
2024-08-07 19:28:37,864 [foster.py] => SNet: Task 8, Epoch 105/130 => Loss 31.046,  Loss1 0.767, Train_accy 65.34
2024-08-07 19:28:51,050 [foster.py] => SNet: Task 8, Epoch 106/130 => Loss 31.022,  Loss1 0.768, Train_accy 65.54, Test_accy 64.49
2024-08-07 19:29:01,552 [foster.py] => SNet: Task 8, Epoch 107/130 => Loss 31.046,  Loss1 0.767, Train_accy 66.06
2024-08-07 19:29:12,179 [foster.py] => SNet: Task 8, Epoch 108/130 => Loss 31.026,  Loss1 0.768, Train_accy 65.30
2024-08-07 19:29:22,610 [foster.py] => SNet: Task 8, Epoch 109/130 => Loss 31.023,  Loss1 0.767, Train_accy 64.87
2024-08-07 19:29:33,263 [foster.py] => SNet: Task 8, Epoch 110/130 => Loss 30.993,  Loss1 0.768, Train_accy 66.29
2024-08-07 19:29:46,466 [foster.py] => SNet: Task 8, Epoch 111/130 => Loss 30.997,  Loss1 0.768, Train_accy 65.43, Test_accy 64.27
2024-08-07 19:29:56,882 [foster.py] => SNet: Task 8, Epoch 112/130 => Loss 31.012,  Loss1 0.768, Train_accy 65.96
2024-08-07 19:30:07,314 [foster.py] => SNet: Task 8, Epoch 113/130 => Loss 30.997,  Loss1 0.768, Train_accy 66.21
2024-08-07 19:30:17,766 [foster.py] => SNet: Task 8, Epoch 114/130 => Loss 30.991,  Loss1 0.767, Train_accy 65.77
2024-08-07 19:30:28,565 [foster.py] => SNet: Task 8, Epoch 115/130 => Loss 31.028,  Loss1 0.767, Train_accy 66.81
2024-08-07 19:30:41,509 [foster.py] => SNet: Task 8, Epoch 116/130 => Loss 31.002,  Loss1 0.767, Train_accy 65.29, Test_accy 64.49
2024-08-07 19:30:52,375 [foster.py] => SNet: Task 8, Epoch 117/130 => Loss 31.014,  Loss1 0.767, Train_accy 65.66
2024-08-07 19:31:02,923 [foster.py] => SNet: Task 8, Epoch 118/130 => Loss 31.024,  Loss1 0.768, Train_accy 64.36
2024-08-07 19:31:13,477 [foster.py] => SNet: Task 8, Epoch 119/130 => Loss 31.003,  Loss1 0.768, Train_accy 66.83
2024-08-07 19:31:24,080 [foster.py] => SNet: Task 8, Epoch 120/130 => Loss 31.026,  Loss1 0.768, Train_accy 65.59
2024-08-07 19:31:37,186 [foster.py] => SNet: Task 8, Epoch 121/130 => Loss 31.027,  Loss1 0.767, Train_accy 65.36, Test_accy 64.63
2024-08-07 19:31:47,856 [foster.py] => SNet: Task 8, Epoch 122/130 => Loss 31.017,  Loss1 0.767, Train_accy 66.21
2024-08-07 19:31:58,767 [foster.py] => SNet: Task 8, Epoch 123/130 => Loss 31.026,  Loss1 0.768, Train_accy 65.76
2024-08-07 19:32:09,497 [foster.py] => SNet: Task 8, Epoch 124/130 => Loss 31.024,  Loss1 0.767, Train_accy 65.73
2024-08-07 19:32:19,974 [foster.py] => SNet: Task 8, Epoch 125/130 => Loss 31.021,  Loss1 0.767, Train_accy 65.67
2024-08-07 19:32:33,267 [foster.py] => SNet: Task 8, Epoch 126/130 => Loss 31.038,  Loss1 0.768, Train_accy 65.76, Test_accy 64.83
2024-08-07 19:32:44,207 [foster.py] => SNet: Task 8, Epoch 127/130 => Loss 31.025,  Loss1 0.767, Train_accy 64.96
2024-08-07 19:32:54,658 [foster.py] => SNet: Task 8, Epoch 128/130 => Loss 31.020,  Loss1 0.767, Train_accy 65.39
2024-08-07 19:33:05,352 [foster.py] => SNet: Task 8, Epoch 129/130 => Loss 31.011,  Loss1 0.767, Train_accy 65.64
2024-08-07 19:33:15,833 [foster.py] => SNet: Task 8, Epoch 130/130 => Loss 31.003,  Loss1 0.768, Train_accy 65.51
2024-08-07 19:33:15,834 [foster.py] => do not weight align student!
2024-08-07 19:33:18,236 [foster.py] => darknet eval: 
2024-08-07 19:33:18,237 [foster.py] => CNN top1 curve: 64.63
2024-08-07 19:33:18,237 [foster.py] => CNN top5 curve: 90.03
2024-08-07 19:33:18,238 [foster.py] => CNN top1 平均值: 64.63
2024-08-07 19:33:18,241 [foster.py] => timees : 3114.520274400711
2024-08-07 19:33:18,243 [base.py] => Reducing exemplars...(22 per classes)
2024-08-07 19:33:46,132 [base.py] => Constructing exemplars...(22 per classes)
2024-08-07 19:34:02,125 [foster.py] => Exemplar size: 1980
2024-08-07 19:34:02,126 [trainer.py] => CNN: {'total': 66.17, '00-09': 68.6, '10-19': 55.3, '20-29': 68.9, '30-39': 64.4, '40-49': 68.4, '50-59': 61.9, '60-69': 69.3, '70-79': 65.1, '80-89': 73.6, 'old': 65.24, 'new': 73.6}
2024-08-07 19:34:02,126 [trainer.py] => NME: {'total': 61.01, '00-09': 59.2, '10-19': 48.2, '20-29': 64.7, '30-39': 56.7, '40-49': 62.2, '50-59': 56.9, '60-69': 62.3, '70-79': 61.6, '80-89': 77.3, 'old': 58.98, 'new': 77.3}
2024-08-07 19:34:02,127 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54, 73.43, 71.44, 67.55, 66.17]
2024-08-07 19:34:02,127 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64, 93.48, 92.6, 91.38, 90.43]
2024-08-07 19:34:02,128 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1, 69.15, 67.06, 62.95, 61.01]
2024-08-07 19:34:02,128 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06, 91.73, 90.39, 88.68, 87.52]

2024-08-07 19:34:02,128 [trainer.py] => CNN top1 平均值: 77.25
2024-08-07 19:34:02,131 [trainer.py] => All params: 1305208
2024-08-07 19:34:02,134 [trainer.py] => Trainable params: 658734
2024-08-07 19:34:02,198 [foster.py] => Learning on 90-100
2024-08-07 19:34:02,202 [foster.py] => All params: 1307798
2024-08-07 19:34:02,204 [foster.py] => Trainable params: 660674
2024-08-07 19:34:02,275 [foster.py] => per cls weights : [1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888 1.03347888
 0.69869009 0.69869009 0.69869009 0.69869009 0.69869009 0.69869009
 0.69869009 0.69869009 0.69869009 0.69869009]
2024-08-07 19:34:09,952 [foster.py] => Task 9, Epoch 1/170 => Loss 11.511, Loss_clf 5.853, Loss_fe 2.311, Loss_kd 3.007, Train_accy 38.21
2024-08-07 19:34:20,555 [foster.py] => Task 9, Epoch 2/170 => Loss 7.215, Loss_clf 2.066, Loss_fe 1.856, Loss_kd 2.958, Train_accy 52.62, Test_accy 55.80
2024-08-07 19:34:31,075 [foster.py] => Task 9, Epoch 3/170 => Loss 6.614, Loss_clf 1.704, Loss_fe 1.609, Loss_kd 2.966, Train_accy 55.14, Test_accy 59.19
2024-08-07 19:34:41,716 [foster.py] => Task 9, Epoch 4/170 => Loss 6.377, Loss_clf 1.617, Loss_fe 1.471, Loss_kd 2.955, Train_accy 55.72, Test_accy 58.99
2024-08-07 19:34:52,347 [foster.py] => Task 9, Epoch 5/170 => Loss 6.641, Loss_clf 1.908, Loss_fe 1.436, Loss_kd 2.962, Train_accy 53.57, Test_accy 57.58
2024-08-07 19:35:00,095 [foster.py] => Task 9, Epoch 6/170 => Loss 6.461, Loss_clf 1.764, Loss_fe 1.391, Loss_kd 2.970, Train_accy 55.80
2024-08-07 19:35:10,727 [foster.py] => Task 9, Epoch 7/170 => Loss 6.342, Loss_clf 1.706, Loss_fe 1.343, Loss_kd 2.960, Train_accy 56.20, Test_accy 58.32
2024-08-07 19:35:21,189 [foster.py] => Task 9, Epoch 8/170 => Loss 6.286, Loss_clf 1.676, Loss_fe 1.310, Loss_kd 2.965, Train_accy 56.32, Test_accy 57.76
2024-08-07 19:35:31,768 [foster.py] => Task 9, Epoch 9/170 => Loss 6.333, Loss_clf 1.692, Loss_fe 1.359, Loss_kd 2.949, Train_accy 57.09, Test_accy 58.26
2024-08-07 19:35:42,267 [foster.py] => Task 9, Epoch 10/170 => Loss 6.267, Loss_clf 1.700, Loss_fe 1.275, Loss_kd 2.958, Train_accy 56.75, Test_accy 57.43
2024-08-07 19:35:49,832 [foster.py] => Task 9, Epoch 11/170 => Loss 6.210, Loss_clf 1.642, Loss_fe 1.272, Loss_kd 2.962, Train_accy 57.71
2024-08-07 19:36:00,349 [foster.py] => Task 9, Epoch 12/170 => Loss 6.065, Loss_clf 1.514, Loss_fe 1.257, Loss_kd 2.960, Train_accy 58.55, Test_accy 59.46
2024-08-07 19:36:10,928 [foster.py] => Task 9, Epoch 13/170 => Loss 6.192, Loss_clf 1.654, Loss_fe 1.243, Loss_kd 2.961, Train_accy 57.79, Test_accy 59.67
2024-08-07 19:36:21,462 [foster.py] => Task 9, Epoch 14/170 => Loss 6.108, Loss_clf 1.566, Loss_fe 1.244, Loss_kd 2.963, Train_accy 57.88, Test_accy 59.51
2024-08-07 19:36:31,940 [foster.py] => Task 9, Epoch 15/170 => Loss 6.035, Loss_clf 1.507, Loss_fe 1.237, Loss_kd 2.958, Train_accy 58.87, Test_accy 56.04
2024-08-07 19:36:39,695 [foster.py] => Task 9, Epoch 16/170 => Loss 6.165, Loss_clf 1.641, Loss_fe 1.236, Loss_kd 2.955, Train_accy 57.78
2024-08-07 19:36:50,166 [foster.py] => Task 9, Epoch 17/170 => Loss 5.999, Loss_clf 1.481, Loss_fe 1.226, Loss_kd 2.958, Train_accy 59.30, Test_accy 59.18
2024-08-07 19:37:00,672 [foster.py] => Task 9, Epoch 18/170 => Loss 6.049, Loss_clf 1.504, Loss_fe 1.243, Loss_kd 2.968, Train_accy 58.40, Test_accy 58.82
2024-08-07 19:37:11,235 [foster.py] => Task 9, Epoch 19/170 => Loss 6.086, Loss_clf 1.574, Loss_fe 1.214, Loss_kd 2.964, Train_accy 58.72, Test_accy 57.49
2024-08-07 19:37:21,738 [foster.py] => Task 9, Epoch 20/170 => Loss 6.017, Loss_clf 1.524, Loss_fe 1.197, Loss_kd 2.962, Train_accy 58.55, Test_accy 56.70
2024-08-07 19:37:29,520 [foster.py] => Task 9, Epoch 21/170 => Loss 5.979, Loss_clf 1.495, Loss_fe 1.186, Loss_kd 2.964, Train_accy 58.98
2024-08-07 19:37:40,205 [foster.py] => Task 9, Epoch 22/170 => Loss 6.030, Loss_clf 1.510, Loss_fe 1.217, Loss_kd 2.969, Train_accy 58.40, Test_accy 59.77
2024-08-07 19:37:50,787 [foster.py] => Task 9, Epoch 23/170 => Loss 5.982, Loss_clf 1.486, Loss_fe 1.203, Loss_kd 2.960, Train_accy 58.54, Test_accy 57.31
2024-08-07 19:38:01,311 [foster.py] => Task 9, Epoch 24/170 => Loss 5.987, Loss_clf 1.529, Loss_fe 1.172, Loss_kd 2.953, Train_accy 58.44, Test_accy 57.83
2024-08-07 19:38:11,791 [foster.py] => Task 9, Epoch 25/170 => Loss 5.861, Loss_clf 1.385, Loss_fe 1.186, Loss_kd 2.957, Train_accy 59.01, Test_accy 57.25
2024-08-07 19:38:19,415 [foster.py] => Task 9, Epoch 26/170 => Loss 5.914, Loss_clf 1.442, Loss_fe 1.176, Loss_kd 2.963, Train_accy 59.33
2024-08-07 19:38:29,900 [foster.py] => Task 9, Epoch 27/170 => Loss 5.803, Loss_clf 1.364, Loss_fe 1.148, Loss_kd 2.958, Train_accy 59.68, Test_accy 59.99
2024-08-07 19:38:40,340 [foster.py] => Task 9, Epoch 28/170 => Loss 5.814, Loss_clf 1.354, Loss_fe 1.165, Loss_kd 2.962, Train_accy 60.26, Test_accy 58.30
2024-08-07 19:38:51,107 [foster.py] => Task 9, Epoch 29/170 => Loss 5.935, Loss_clf 1.474, Loss_fe 1.170, Loss_kd 2.959, Train_accy 58.57, Test_accy 59.78
2024-08-07 19:39:01,701 [foster.py] => Task 9, Epoch 30/170 => Loss 6.027, Loss_clf 1.514, Loss_fe 1.212, Loss_kd 2.966, Train_accy 58.78, Test_accy 60.00
2024-08-07 19:39:09,262 [foster.py] => Task 9, Epoch 31/170 => Loss 6.026, Loss_clf 1.546, Loss_fe 1.199, Loss_kd 2.950, Train_accy 59.24
2024-08-07 19:39:19,847 [foster.py] => Task 9, Epoch 32/170 => Loss 6.011, Loss_clf 1.553, Loss_fe 1.168, Loss_kd 2.957, Train_accy 59.40, Test_accy 59.73
2024-08-07 19:39:30,331 [foster.py] => Task 9, Epoch 33/170 => Loss 5.987, Loss_clf 1.496, Loss_fe 1.196, Loss_kd 2.962, Train_accy 58.60, Test_accy 59.29
2024-08-07 19:39:40,903 [foster.py] => Task 9, Epoch 34/170 => Loss 5.937, Loss_clf 1.493, Loss_fe 1.146, Loss_kd 2.965, Train_accy 60.09, Test_accy 58.06
2024-08-07 19:39:51,355 [foster.py] => Task 9, Epoch 35/170 => Loss 5.910, Loss_clf 1.465, Loss_fe 1.157, Loss_kd 2.956, Train_accy 60.29, Test_accy 56.00
2024-08-07 19:39:59,030 [foster.py] => Task 9, Epoch 36/170 => Loss 5.987, Loss_clf 1.540, Loss_fe 1.157, Loss_kd 2.957, Train_accy 59.31
2024-08-07 19:40:09,598 [foster.py] => Task 9, Epoch 37/170 => Loss 5.930, Loss_clf 1.472, Loss_fe 1.158, Loss_kd 2.966, Train_accy 60.57, Test_accy 58.46
2024-08-07 19:40:20,115 [foster.py] => Task 9, Epoch 38/170 => Loss 6.025, Loss_clf 1.576, Loss_fe 1.163, Loss_kd 2.953, Train_accy 58.84, Test_accy 59.38
2024-08-07 19:40:30,581 [foster.py] => Task 9, Epoch 39/170 => Loss 5.925, Loss_clf 1.466, Loss_fe 1.152, Loss_kd 2.972, Train_accy 58.80, Test_accy 60.62
2024-08-07 19:40:41,087 [foster.py] => Task 9, Epoch 40/170 => Loss 5.776, Loss_clf 1.376, Loss_fe 1.111, Loss_kd 2.955, Train_accy 60.20, Test_accy 59.73
2024-08-07 19:40:49,037 [foster.py] => Task 9, Epoch 41/170 => Loss 5.836, Loss_clf 1.410, Loss_fe 1.125, Loss_kd 2.967, Train_accy 59.89
2024-08-07 19:40:59,586 [foster.py] => Task 9, Epoch 42/170 => Loss 5.895, Loss_clf 1.482, Loss_fe 1.125, Loss_kd 2.955, Train_accy 59.27, Test_accy 58.04
2024-08-07 19:41:10,087 [foster.py] => Task 9, Epoch 43/170 => Loss 5.848, Loss_clf 1.423, Loss_fe 1.130, Loss_kd 2.961, Train_accy 59.86, Test_accy 58.87
2024-08-07 19:41:20,615 [foster.py] => Task 9, Epoch 44/170 => Loss 5.911, Loss_clf 1.490, Loss_fe 1.132, Loss_kd 2.955, Train_accy 59.50, Test_accy 60.02
2024-08-07 19:41:31,170 [foster.py] => Task 9, Epoch 45/170 => Loss 5.978, Loss_clf 1.528, Loss_fe 1.153, Loss_kd 2.963, Train_accy 59.74, Test_accy 51.94
2024-08-07 19:41:38,699 [foster.py] => Task 9, Epoch 46/170 => Loss 5.834, Loss_clf 1.416, Loss_fe 1.120, Loss_kd 2.964, Train_accy 60.03
2024-08-07 19:41:49,202 [foster.py] => Task 9, Epoch 47/170 => Loss 5.712, Loss_clf 1.333, Loss_fe 1.087, Loss_kd 2.959, Train_accy 61.07, Test_accy 57.34
2024-08-07 19:41:59,727 [foster.py] => Task 9, Epoch 48/170 => Loss 5.846, Loss_clf 1.454, Loss_fe 1.099, Loss_kd 2.960, Train_accy 59.23, Test_accy 59.36
2024-08-07 19:42:10,222 [foster.py] => Task 9, Epoch 49/170 => Loss 5.724, Loss_clf 1.336, Loss_fe 1.091, Loss_kd 2.963, Train_accy 60.04, Test_accy 60.55
2024-08-07 19:42:20,803 [foster.py] => Task 9, Epoch 50/170 => Loss 5.711, Loss_clf 1.339, Loss_fe 1.084, Loss_kd 2.955, Train_accy 60.57, Test_accy 57.38
2024-08-07 19:42:28,387 [foster.py] => Task 9, Epoch 51/170 => Loss 5.772, Loss_clf 1.396, Loss_fe 1.099, Loss_kd 2.945, Train_accy 60.40
2024-08-07 19:42:38,958 [foster.py] => Task 9, Epoch 52/170 => Loss 5.604, Loss_clf 1.277, Loss_fe 1.038, Loss_kd 2.956, Train_accy 62.58, Test_accy 61.33
2024-08-07 19:42:49,475 [foster.py] => Task 9, Epoch 53/170 => Loss 5.681, Loss_clf 1.325, Loss_fe 1.074, Loss_kd 2.950, Train_accy 60.56, Test_accy 59.81
2024-08-07 19:43:00,147 [foster.py] => Task 9, Epoch 54/170 => Loss 5.716, Loss_clf 1.352, Loss_fe 1.075, Loss_kd 2.956, Train_accy 60.42, Test_accy 61.42
2024-08-07 19:43:10,873 [foster.py] => Task 9, Epoch 55/170 => Loss 5.717, Loss_clf 1.349, Loss_fe 1.076, Loss_kd 2.959, Train_accy 60.96, Test_accy 60.97
2024-08-07 19:43:18,414 [foster.py] => Task 9, Epoch 56/170 => Loss 5.738, Loss_clf 1.373, Loss_fe 1.081, Loss_kd 2.951, Train_accy 60.87
2024-08-07 19:43:28,926 [foster.py] => Task 9, Epoch 57/170 => Loss 5.692, Loss_clf 1.343, Loss_fe 1.061, Loss_kd 2.955, Train_accy 61.40, Test_accy 60.06
2024-08-07 19:43:39,599 [foster.py] => Task 9, Epoch 58/170 => Loss 5.786, Loss_clf 1.412, Loss_fe 1.074, Loss_kd 2.966, Train_accy 59.66, Test_accy 60.79
2024-08-07 19:43:50,145 [foster.py] => Task 9, Epoch 59/170 => Loss 5.641, Loss_clf 1.290, Loss_fe 1.062, Loss_kd 2.956, Train_accy 62.36, Test_accy 60.89
2024-08-07 19:44:00,860 [foster.py] => Task 9, Epoch 60/170 => Loss 5.593, Loss_clf 1.274, Loss_fe 1.024, Loss_kd 2.961, Train_accy 62.81, Test_accy 60.83
2024-08-07 19:44:08,685 [foster.py] => Task 9, Epoch 61/170 => Loss 5.607, Loss_clf 1.291, Loss_fe 1.034, Loss_kd 2.950, Train_accy 61.76
2024-08-07 19:44:19,264 [foster.py] => Task 9, Epoch 62/170 => Loss 5.546, Loss_clf 1.241, Loss_fe 1.021, Loss_kd 2.951, Train_accy 62.89, Test_accy 61.00
2024-08-07 19:44:29,750 [foster.py] => Task 9, Epoch 63/170 => Loss 5.566, Loss_clf 1.224, Loss_fe 1.048, Loss_kd 2.960, Train_accy 61.98, Test_accy 60.28
2024-08-07 19:44:40,217 [foster.py] => Task 9, Epoch 64/170 => Loss 5.717, Loss_clf 1.395, Loss_fe 1.037, Loss_kd 2.953, Train_accy 61.65, Test_accy 60.34
2024-08-07 19:44:50,684 [foster.py] => Task 9, Epoch 65/170 => Loss 5.581, Loss_clf 1.266, Loss_fe 1.027, Loss_kd 2.955, Train_accy 62.56, Test_accy 61.20
2024-08-07 19:44:58,212 [foster.py] => Task 9, Epoch 66/170 => Loss 5.612, Loss_clf 1.288, Loss_fe 1.034, Loss_kd 2.957, Train_accy 62.29
2024-08-07 19:45:08,702 [foster.py] => Task 9, Epoch 67/170 => Loss 5.545, Loss_clf 1.243, Loss_fe 1.012, Loss_kd 2.957, Train_accy 63.30, Test_accy 60.84
2024-08-07 19:45:19,245 [foster.py] => Task 9, Epoch 68/170 => Loss 5.705, Loss_clf 1.376, Loss_fe 1.039, Loss_kd 2.957, Train_accy 60.93, Test_accy 61.53
2024-08-07 19:45:29,753 [foster.py] => Task 9, Epoch 69/170 => Loss 5.613, Loss_clf 1.302, Loss_fe 1.031, Loss_kd 2.948, Train_accy 61.93, Test_accy 59.06
2024-08-07 19:45:40,268 [foster.py] => Task 9, Epoch 70/170 => Loss 5.548, Loss_clf 1.250, Loss_fe 1.007, Loss_kd 2.958, Train_accy 63.31, Test_accy 60.13
2024-08-07 19:45:47,818 [foster.py] => Task 9, Epoch 71/170 => Loss 5.507, Loss_clf 1.227, Loss_fe 0.990, Loss_kd 2.957, Train_accy 62.88
2024-08-07 19:45:58,322 [foster.py] => Task 9, Epoch 72/170 => Loss 5.514, Loss_clf 1.241, Loss_fe 0.987, Loss_kd 2.953, Train_accy 63.08, Test_accy 59.54
2024-08-07 19:46:08,960 [foster.py] => Task 9, Epoch 73/170 => Loss 5.480, Loss_clf 1.211, Loss_fe 0.984, Loss_kd 2.953, Train_accy 63.51, Test_accy 61.09
2024-08-07 19:46:19,595 [foster.py] => Task 9, Epoch 74/170 => Loss 5.492, Loss_clf 1.229, Loss_fe 0.977, Loss_kd 2.954, Train_accy 63.85, Test_accy 61.19
2024-08-07 19:46:30,045 [foster.py] => Task 9, Epoch 75/170 => Loss 5.407, Loss_clf 1.164, Loss_fe 0.959, Loss_kd 2.951, Train_accy 64.04, Test_accy 61.49
2024-08-07 19:46:37,776 [foster.py] => Task 9, Epoch 76/170 => Loss 5.438, Loss_clf 1.203, Loss_fe 0.960, Loss_kd 2.943, Train_accy 63.37
2024-08-07 19:46:48,333 [foster.py] => Task 9, Epoch 77/170 => Loss 5.483, Loss_clf 1.226, Loss_fe 0.973, Loss_kd 2.952, Train_accy 62.92, Test_accy 61.11
2024-08-07 19:46:58,869 [foster.py] => Task 9, Epoch 78/170 => Loss 5.442, Loss_clf 1.194, Loss_fe 0.962, Loss_kd 2.954, Train_accy 63.84, Test_accy 60.86
2024-08-07 19:47:09,353 [foster.py] => Task 9, Epoch 79/170 => Loss 5.399, Loss_clf 1.167, Loss_fe 0.949, Loss_kd 2.951, Train_accy 64.03, Test_accy 61.04
2024-08-07 19:47:19,897 [foster.py] => Task 9, Epoch 80/170 => Loss 5.330, Loss_clf 1.119, Loss_fe 0.927, Loss_kd 2.952, Train_accy 65.10, Test_accy 60.21
2024-08-07 19:47:27,555 [foster.py] => Task 9, Epoch 81/170 => Loss 5.430, Loss_clf 1.200, Loss_fe 0.953, Loss_kd 2.945, Train_accy 63.74
2024-08-07 19:47:38,106 [foster.py] => Task 9, Epoch 82/170 => Loss 5.489, Loss_clf 1.216, Loss_fe 0.978, Loss_kd 2.962, Train_accy 63.24, Test_accy 59.03
2024-08-07 19:47:48,616 [foster.py] => Task 9, Epoch 83/170 => Loss 5.415, Loss_clf 1.195, Loss_fe 0.927, Loss_kd 2.961, Train_accy 63.24, Test_accy 61.37
2024-08-07 19:47:59,206 [foster.py] => Task 9, Epoch 84/170 => Loss 5.351, Loss_clf 1.121, Loss_fe 0.939, Loss_kd 2.959, Train_accy 65.57, Test_accy 62.01
2024-08-07 19:48:09,754 [foster.py] => Task 9, Epoch 85/170 => Loss 5.321, Loss_clf 1.116, Loss_fe 0.923, Loss_kd 2.950, Train_accy 64.57, Test_accy 60.74
2024-08-07 19:48:17,243 [foster.py] => Task 9, Epoch 86/170 => Loss 5.376, Loss_clf 1.162, Loss_fe 0.935, Loss_kd 2.948, Train_accy 64.58
2024-08-07 19:48:27,789 [foster.py] => Task 9, Epoch 87/170 => Loss 5.383, Loss_clf 1.185, Loss_fe 0.920, Loss_kd 2.947, Train_accy 64.20, Test_accy 61.03
2024-08-07 19:48:38,268 [foster.py] => Task 9, Epoch 88/170 => Loss 5.309, Loss_clf 1.133, Loss_fe 0.894, Loss_kd 2.949, Train_accy 65.77, Test_accy 61.24
2024-08-07 19:48:48,781 [foster.py] => Task 9, Epoch 89/170 => Loss 5.298, Loss_clf 1.106, Loss_fe 0.914, Loss_kd 2.946, Train_accy 65.49, Test_accy 61.28
2024-08-07 19:48:59,436 [foster.py] => Task 9, Epoch 90/170 => Loss 5.310, Loss_clf 1.129, Loss_fe 0.903, Loss_kd 2.947, Train_accy 65.40, Test_accy 62.20
2024-08-07 19:49:07,064 [foster.py] => Task 9, Epoch 91/170 => Loss 5.220, Loss_clf 1.069, Loss_fe 0.876, Loss_kd 2.943, Train_accy 66.58
2024-08-07 19:49:17,621 [foster.py] => Task 9, Epoch 92/170 => Loss 5.245, Loss_clf 1.082, Loss_fe 0.874, Loss_kd 2.956, Train_accy 65.83, Test_accy 61.97
2024-08-07 19:49:28,138 [foster.py] => Task 9, Epoch 93/170 => Loss 5.239, Loss_clf 1.071, Loss_fe 0.881, Loss_kd 2.955, Train_accy 66.13, Test_accy 62.80
2024-08-07 19:49:38,642 [foster.py] => Task 9, Epoch 94/170 => Loss 5.239, Loss_clf 1.098, Loss_fe 0.861, Loss_kd 2.949, Train_accy 65.96, Test_accy 60.18
2024-08-07 19:49:49,123 [foster.py] => Task 9, Epoch 95/170 => Loss 5.213, Loss_clf 1.084, Loss_fe 0.854, Loss_kd 2.944, Train_accy 65.89, Test_accy 61.85
2024-08-07 19:49:56,724 [foster.py] => Task 9, Epoch 96/170 => Loss 5.235, Loss_clf 1.091, Loss_fe 0.858, Loss_kd 2.953, Train_accy 66.02
2024-08-07 19:50:07,288 [foster.py] => Task 9, Epoch 97/170 => Loss 5.180, Loss_clf 1.053, Loss_fe 0.849, Loss_kd 2.946, Train_accy 66.23, Test_accy 61.25
2024-08-07 19:50:17,703 [foster.py] => Task 9, Epoch 98/170 => Loss 5.233, Loss_clf 1.080, Loss_fe 0.866, Loss_kd 2.955, Train_accy 65.90, Test_accy 62.32
2024-08-07 19:50:28,229 [foster.py] => Task 9, Epoch 99/170 => Loss 5.189, Loss_clf 1.066, Loss_fe 0.842, Loss_kd 2.948, Train_accy 66.83, Test_accy 62.44
2024-08-07 19:50:38,774 [foster.py] => Task 9, Epoch 100/170 => Loss 5.142, Loss_clf 1.034, Loss_fe 0.827, Loss_kd 2.949, Train_accy 66.95, Test_accy 61.99
2024-08-07 19:50:46,294 [foster.py] => Task 9, Epoch 101/170 => Loss 5.140, Loss_clf 1.030, Loss_fe 0.830, Loss_kd 2.947, Train_accy 67.23
2024-08-07 19:50:56,796 [foster.py] => Task 9, Epoch 102/170 => Loss 5.150, Loss_clf 1.044, Loss_fe 0.818, Loss_kd 2.956, Train_accy 67.28, Test_accy 62.42
2024-08-07 19:51:07,235 [foster.py] => Task 9, Epoch 103/170 => Loss 5.140, Loss_clf 1.035, Loss_fe 0.824, Loss_kd 2.950, Train_accy 67.11, Test_accy 62.01
2024-08-07 19:51:17,728 [foster.py] => Task 9, Epoch 104/170 => Loss 5.111, Loss_clf 1.005, Loss_fe 0.819, Loss_kd 2.954, Train_accy 67.74, Test_accy 63.09
2024-08-07 19:51:28,310 [foster.py] => Task 9, Epoch 105/170 => Loss 5.084, Loss_clf 1.004, Loss_fe 0.808, Loss_kd 2.941, Train_accy 67.48, Test_accy 62.70
2024-08-07 19:51:35,820 [foster.py] => Task 9, Epoch 106/170 => Loss 5.047, Loss_clf 0.996, Loss_fe 0.777, Loss_kd 2.943, Train_accy 68.80
2024-08-07 19:51:46,377 [foster.py] => Task 9, Epoch 107/170 => Loss 5.028, Loss_clf 0.978, Loss_fe 0.771, Loss_kd 2.947, Train_accy 69.10, Test_accy 62.83
2024-08-07 19:51:57,024 [foster.py] => Task 9, Epoch 108/170 => Loss 5.040, Loss_clf 0.978, Loss_fe 0.779, Loss_kd 2.950, Train_accy 68.52, Test_accy 62.52
2024-08-07 19:52:07,727 [foster.py] => Task 9, Epoch 109/170 => Loss 5.045, Loss_clf 0.969, Loss_fe 0.793, Loss_kd 2.952, Train_accy 69.27, Test_accy 61.62
2024-08-07 19:52:18,234 [foster.py] => Task 9, Epoch 110/170 => Loss 5.058, Loss_clf 0.983, Loss_fe 0.793, Loss_kd 2.950, Train_accy 69.18, Test_accy 62.25
2024-08-07 19:52:25,747 [foster.py] => Task 9, Epoch 111/170 => Loss 4.971, Loss_clf 0.938, Loss_fe 0.768, Loss_kd 2.935, Train_accy 69.31
2024-08-07 19:52:36,204 [foster.py] => Task 9, Epoch 112/170 => Loss 4.977, Loss_clf 0.948, Loss_fe 0.744, Loss_kd 2.952, Train_accy 69.93, Test_accy 63.57
2024-08-07 19:52:46,664 [foster.py] => Task 9, Epoch 113/170 => Loss 4.999, Loss_clf 0.967, Loss_fe 0.756, Loss_kd 2.945, Train_accy 69.11, Test_accy 62.97
2024-08-07 19:52:57,206 [foster.py] => Task 9, Epoch 114/170 => Loss 4.936, Loss_clf 0.937, Loss_fe 0.726, Loss_kd 2.942, Train_accy 70.07, Test_accy 62.42
2024-08-07 19:53:07,732 [foster.py] => Task 9, Epoch 115/170 => Loss 4.946, Loss_clf 0.941, Loss_fe 0.732, Loss_kd 2.943, Train_accy 70.66, Test_accy 63.31
2024-08-07 19:53:15,313 [foster.py] => Task 9, Epoch 116/170 => Loss 4.969, Loss_clf 0.946, Loss_fe 0.744, Loss_kd 2.947, Train_accy 70.06
2024-08-07 19:53:25,792 [foster.py] => Task 9, Epoch 117/170 => Loss 4.919, Loss_clf 0.912, Loss_fe 0.728, Loss_kd 2.947, Train_accy 70.29, Test_accy 62.39
2024-08-07 19:53:36,266 [foster.py] => Task 9, Epoch 118/170 => Loss 4.866, Loss_clf 0.899, Loss_fe 0.699, Loss_kd 2.938, Train_accy 70.82, Test_accy 62.90
2024-08-07 19:53:46,742 [foster.py] => Task 9, Epoch 119/170 => Loss 4.904, Loss_clf 0.913, Loss_fe 0.710, Loss_kd 2.949, Train_accy 70.74, Test_accy 62.73
2024-08-07 19:53:57,555 [foster.py] => Task 9, Epoch 120/170 => Loss 4.895, Loss_clf 0.914, Loss_fe 0.708, Loss_kd 2.942, Train_accy 71.26, Test_accy 63.54
2024-08-07 19:54:05,418 [foster.py] => Task 9, Epoch 121/170 => Loss 4.880, Loss_clf 0.907, Loss_fe 0.695, Loss_kd 2.947, Train_accy 71.22
2024-08-07 19:54:15,961 [foster.py] => Task 9, Epoch 122/170 => Loss 4.840, Loss_clf 0.886, Loss_fe 0.671, Loss_kd 2.951, Train_accy 72.09, Test_accy 62.76
2024-08-07 19:54:26,513 [foster.py] => Task 9, Epoch 123/170 => Loss 4.790, Loss_clf 0.862, Loss_fe 0.658, Loss_kd 2.939, Train_accy 71.83, Test_accy 62.89
2024-08-07 19:54:37,116 [foster.py] => Task 9, Epoch 124/170 => Loss 4.835, Loss_clf 0.879, Loss_fe 0.675, Loss_kd 2.948, Train_accy 71.95, Test_accy 63.57
2024-08-07 19:54:47,589 [foster.py] => Task 9, Epoch 125/170 => Loss 4.817, Loss_clf 0.885, Loss_fe 0.652, Loss_kd 2.948, Train_accy 71.79, Test_accy 63.30
2024-08-07 19:54:55,142 [foster.py] => Task 9, Epoch 126/170 => Loss 4.809, Loss_clf 0.867, Loss_fe 0.668, Loss_kd 2.942, Train_accy 72.82
2024-08-07 19:55:05,645 [foster.py] => Task 9, Epoch 127/170 => Loss 4.738, Loss_clf 0.829, Loss_fe 0.634, Loss_kd 2.944, Train_accy 72.56, Test_accy 63.03
2024-08-07 19:55:16,145 [foster.py] => Task 9, Epoch 128/170 => Loss 4.735, Loss_clf 0.832, Loss_fe 0.631, Loss_kd 2.942, Train_accy 73.60, Test_accy 63.62
2024-08-07 19:55:26,607 [foster.py] => Task 9, Epoch 129/170 => Loss 4.748, Loss_clf 0.840, Loss_fe 0.635, Loss_kd 2.942, Train_accy 73.57, Test_accy 63.66
2024-08-07 19:55:37,086 [foster.py] => Task 9, Epoch 130/170 => Loss 4.739, Loss_clf 0.833, Loss_fe 0.625, Loss_kd 2.949, Train_accy 73.38, Test_accy 63.55
2024-08-07 19:55:44,597 [foster.py] => Task 9, Epoch 131/170 => Loss 4.724, Loss_clf 0.824, Loss_fe 0.617, Loss_kd 2.951, Train_accy 74.10
2024-08-07 19:55:55,269 [foster.py] => Task 9, Epoch 132/170 => Loss 4.666, Loss_clf 0.804, Loss_fe 0.595, Loss_kd 2.937, Train_accy 74.37, Test_accy 62.68
2024-08-07 19:56:06,157 [foster.py] => Task 9, Epoch 133/170 => Loss 4.698, Loss_clf 0.826, Loss_fe 0.602, Loss_kd 2.939, Train_accy 74.41, Test_accy 63.68
2024-08-07 19:56:16,737 [foster.py] => Task 9, Epoch 134/170 => Loss 4.674, Loss_clf 0.811, Loss_fe 0.589, Loss_kd 2.943, Train_accy 74.41, Test_accy 63.24
2024-08-07 19:56:27,233 [foster.py] => Task 9, Epoch 135/170 => Loss 4.668, Loss_clf 0.807, Loss_fe 0.576, Loss_kd 2.952, Train_accy 74.73, Test_accy 63.20
2024-08-07 19:56:34,712 [foster.py] => Task 9, Epoch 136/170 => Loss 4.651, Loss_clf 0.799, Loss_fe 0.579, Loss_kd 2.942, Train_accy 74.70
2024-08-07 19:56:45,239 [foster.py] => Task 9, Epoch 137/170 => Loss 4.643, Loss_clf 0.789, Loss_fe 0.568, Loss_kd 2.953, Train_accy 74.91, Test_accy 63.06
2024-08-07 19:56:55,690 [foster.py] => Task 9, Epoch 138/170 => Loss 4.590, Loss_clf 0.768, Loss_fe 0.549, Loss_kd 2.942, Train_accy 75.86, Test_accy 63.62
2024-08-07 19:57:06,362 [foster.py] => Task 9, Epoch 139/170 => Loss 4.589, Loss_clf 0.763, Loss_fe 0.552, Loss_kd 2.943, Train_accy 75.70, Test_accy 64.08
2024-08-07 19:57:16,945 [foster.py] => Task 9, Epoch 140/170 => Loss 4.546, Loss_clf 0.739, Loss_fe 0.538, Loss_kd 2.938, Train_accy 76.89, Test_accy 63.71
2024-08-07 19:57:24,509 [foster.py] => Task 9, Epoch 141/170 => Loss 4.583, Loss_clf 0.769, Loss_fe 0.536, Loss_kd 2.946, Train_accy 75.72
2024-08-07 19:57:34,969 [foster.py] => Task 9, Epoch 142/170 => Loss 4.560, Loss_clf 0.748, Loss_fe 0.530, Loss_kd 2.950, Train_accy 76.30, Test_accy 63.83
2024-08-07 19:57:45,473 [foster.py] => Task 9, Epoch 143/170 => Loss 4.542, Loss_clf 0.751, Loss_fe 0.525, Loss_kd 2.935, Train_accy 76.83, Test_accy 63.56
2024-08-07 19:57:56,246 [foster.py] => Task 9, Epoch 144/170 => Loss 4.521, Loss_clf 0.733, Loss_fe 0.520, Loss_kd 2.937, Train_accy 76.53, Test_accy 63.96
2024-08-07 19:58:07,089 [foster.py] => Task 9, Epoch 145/170 => Loss 4.523, Loss_clf 0.741, Loss_fe 0.508, Loss_kd 2.942, Train_accy 76.91, Test_accy 63.89
2024-08-07 19:58:14,890 [foster.py] => Task 9, Epoch 146/170 => Loss 4.507, Loss_clf 0.725, Loss_fe 0.504, Loss_kd 2.947, Train_accy 77.25
2024-08-07 19:58:25,377 [foster.py] => Task 9, Epoch 147/170 => Loss 4.438, Loss_clf 0.695, Loss_fe 0.472, Loss_kd 2.940, Train_accy 77.92, Test_accy 63.93
2024-08-07 19:58:35,835 [foster.py] => Task 9, Epoch 148/170 => Loss 4.497, Loss_clf 0.727, Loss_fe 0.497, Loss_kd 2.942, Train_accy 77.61, Test_accy 63.86
2024-08-07 19:58:46,506 [foster.py] => Task 9, Epoch 149/170 => Loss 4.432, Loss_clf 0.685, Loss_fe 0.480, Loss_kd 2.936, Train_accy 78.37, Test_accy 64.05
2024-08-07 19:58:57,005 [foster.py] => Task 9, Epoch 150/170 => Loss 4.442, Loss_clf 0.699, Loss_fe 0.474, Loss_kd 2.939, Train_accy 78.09, Test_accy 63.88
2024-08-07 19:59:04,570 [foster.py] => Task 9, Epoch 151/170 => Loss 4.445, Loss_clf 0.703, Loss_fe 0.479, Loss_kd 2.932, Train_accy 78.17
2024-08-07 19:59:15,136 [foster.py] => Task 9, Epoch 152/170 => Loss 4.464, Loss_clf 0.704, Loss_fe 0.481, Loss_kd 2.947, Train_accy 78.02, Test_accy 64.04
2024-08-07 19:59:25,654 [foster.py] => Task 9, Epoch 153/170 => Loss 4.413, Loss_clf 0.686, Loss_fe 0.455, Loss_kd 2.942, Train_accy 78.50, Test_accy 63.83
2024-08-07 19:59:36,247 [foster.py] => Task 9, Epoch 154/170 => Loss 4.453, Loss_clf 0.702, Loss_fe 0.474, Loss_kd 2.945, Train_accy 78.30, Test_accy 63.91
2024-08-07 19:59:46,705 [foster.py] => Task 9, Epoch 155/170 => Loss 4.428, Loss_clf 0.690, Loss_fe 0.462, Loss_kd 2.945, Train_accy 78.85, Test_accy 63.93
2024-08-07 19:59:54,278 [foster.py] => Task 9, Epoch 156/170 => Loss 4.413, Loss_clf 0.686, Loss_fe 0.456, Loss_kd 2.940, Train_accy 78.21
2024-08-07 20:00:04,774 [foster.py] => Task 9, Epoch 157/170 => Loss 4.355, Loss_clf 0.661, Loss_fe 0.430, Loss_kd 2.935, Train_accy 79.51, Test_accy 63.98
2024-08-07 20:00:15,459 [foster.py] => Task 9, Epoch 158/170 => Loss 4.367, Loss_clf 0.664, Loss_fe 0.438, Loss_kd 2.935, Train_accy 78.98, Test_accy 63.95
2024-08-07 20:00:26,182 [foster.py] => Task 9, Epoch 159/170 => Loss 4.372, Loss_clf 0.655, Loss_fe 0.443, Loss_kd 2.943, Train_accy 79.58, Test_accy 63.94
2024-08-07 20:00:36,757 [foster.py] => Task 9, Epoch 160/170 => Loss 4.360, Loss_clf 0.660, Loss_fe 0.429, Loss_kd 2.941, Train_accy 79.40, Test_accy 64.05
2024-08-07 20:00:44,330 [foster.py] => Task 9, Epoch 161/170 => Loss 4.366, Loss_clf 0.667, Loss_fe 0.423, Loss_kd 2.944, Train_accy 79.54
2024-08-07 20:00:54,906 [foster.py] => Task 9, Epoch 162/170 => Loss 4.373, Loss_clf 0.661, Loss_fe 0.437, Loss_kd 2.944, Train_accy 79.81, Test_accy 63.95
2024-08-07 20:01:05,649 [foster.py] => Task 9, Epoch 163/170 => Loss 4.396, Loss_clf 0.675, Loss_fe 0.441, Loss_kd 2.948, Train_accy 79.83, Test_accy 64.05
2024-08-07 20:01:16,215 [foster.py] => Task 9, Epoch 164/170 => Loss 4.358, Loss_clf 0.661, Loss_fe 0.431, Loss_kd 2.936, Train_accy 79.76, Test_accy 64.07
2024-08-07 20:01:26,717 [foster.py] => Task 9, Epoch 165/170 => Loss 4.356, Loss_clf 0.655, Loss_fe 0.423, Loss_kd 2.947, Train_accy 79.64, Test_accy 63.96
2024-08-07 20:01:34,346 [foster.py] => Task 9, Epoch 166/170 => Loss 4.342, Loss_clf 0.648, Loss_fe 0.421, Loss_kd 2.942, Train_accy 79.30
2024-08-07 20:01:44,990 [foster.py] => Task 9, Epoch 167/170 => Loss 4.349, Loss_clf 0.653, Loss_fe 0.434, Loss_kd 2.933, Train_accy 79.79, Test_accy 64.07
2024-08-07 20:01:55,776 [foster.py] => Task 9, Epoch 168/170 => Loss 4.383, Loss_clf 0.672, Loss_fe 0.426, Loss_kd 2.953, Train_accy 79.41, Test_accy 64.00
2024-08-07 20:02:06,415 [foster.py] => Task 9, Epoch 169/170 => Loss 4.351, Loss_clf 0.657, Loss_fe 0.425, Loss_kd 2.938, Train_accy 79.36, Test_accy 63.97
2024-08-07 20:02:16,898 [foster.py] => Task 9, Epoch 170/170 => Loss 4.350, Loss_clf 0.656, Loss_fe 0.425, Loss_kd 2.939, Train_accy 79.93, Test_accy 64.04
2024-08-07 20:02:16,902 [foster.py] => do not weight align teacher!
2024-08-07 20:02:16,906 [foster.py] => per cls weights : [1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371 1.05330371
 0.52026661 0.52026661 0.52026661 0.52026661 0.52026661 0.52026661
 0.52026661 0.52026661 0.52026661 0.52026661]
2024-08-07 20:02:30,249 [foster.py] => SNet: Task 9, Epoch 1/130 => Loss 32.112,  Loss1 0.787, Train_accy 28.15, Test_accy 58.92
2024-08-07 20:02:40,572 [foster.py] => SNet: Task 9, Epoch 2/130 => Loss 32.004,  Loss1 0.786, Train_accy 41.46
2024-08-07 20:02:51,607 [foster.py] => SNet: Task 9, Epoch 3/130 => Loss 31.959,  Loss1 0.786, Train_accy 47.25
2024-08-07 20:03:02,253 [foster.py] => SNet: Task 9, Epoch 4/130 => Loss 31.954,  Loss1 0.786, Train_accy 50.26
2024-08-07 20:03:12,810 [foster.py] => SNet: Task 9, Epoch 5/130 => Loss 31.953,  Loss1 0.786, Train_accy 52.02
2024-08-07 20:03:25,858 [foster.py] => SNet: Task 9, Epoch 6/130 => Loss 31.949,  Loss1 0.786, Train_accy 52.75, Test_accy 61.66
2024-08-07 20:03:36,376 [foster.py] => SNet: Task 9, Epoch 7/130 => Loss 31.947,  Loss1 0.786, Train_accy 54.13
2024-08-07 20:03:47,017 [foster.py] => SNet: Task 9, Epoch 8/130 => Loss 31.950,  Loss1 0.786, Train_accy 55.03
2024-08-07 20:03:57,562 [foster.py] => SNet: Task 9, Epoch 9/130 => Loss 31.940,  Loss1 0.786, Train_accy 55.56
2024-08-07 20:04:08,026 [foster.py] => SNet: Task 9, Epoch 10/130 => Loss 31.915,  Loss1 0.786, Train_accy 56.10
2024-08-07 20:04:21,173 [foster.py] => SNet: Task 9, Epoch 11/130 => Loss 31.910,  Loss1 0.786, Train_accy 56.69, Test_accy 61.31
2024-08-07 20:04:31,797 [foster.py] => SNet: Task 9, Epoch 12/130 => Loss 31.928,  Loss1 0.786, Train_accy 57.13
2024-08-07 20:04:42,472 [foster.py] => SNet: Task 9, Epoch 13/130 => Loss 31.933,  Loss1 0.786, Train_accy 58.02
2024-08-07 20:04:52,964 [foster.py] => SNet: Task 9, Epoch 14/130 => Loss 31.947,  Loss1 0.786, Train_accy 58.24
2024-08-07 20:05:03,447 [foster.py] => SNet: Task 9, Epoch 15/130 => Loss 31.922,  Loss1 0.786, Train_accy 57.52
2024-08-07 20:05:16,602 [foster.py] => SNet: Task 9, Epoch 16/130 => Loss 31.925,  Loss1 0.786, Train_accy 58.88, Test_accy 61.32
2024-08-07 20:05:27,029 [foster.py] => SNet: Task 9, Epoch 17/130 => Loss 31.926,  Loss1 0.786, Train_accy 59.05
2024-08-07 20:05:37,596 [foster.py] => SNet: Task 9, Epoch 18/130 => Loss 31.939,  Loss1 0.786, Train_accy 59.10
2024-08-07 20:05:48,376 [foster.py] => SNet: Task 9, Epoch 19/130 => Loss 31.937,  Loss1 0.786, Train_accy 59.60
2024-08-07 20:05:58,810 [foster.py] => SNet: Task 9, Epoch 20/130 => Loss 31.903,  Loss1 0.786, Train_accy 59.71
2024-08-07 20:06:12,120 [foster.py] => SNet: Task 9, Epoch 21/130 => Loss 31.915,  Loss1 0.786, Train_accy 58.98, Test_accy 61.64
2024-08-07 20:06:22,708 [foster.py] => SNet: Task 9, Epoch 22/130 => Loss 31.934,  Loss1 0.786, Train_accy 59.97
2024-08-07 20:06:33,077 [foster.py] => SNet: Task 9, Epoch 23/130 => Loss 31.922,  Loss1 0.786, Train_accy 59.71
2024-08-07 20:06:43,630 [foster.py] => SNet: Task 9, Epoch 24/130 => Loss 31.919,  Loss1 0.786, Train_accy 60.06
2024-08-07 20:06:54,235 [foster.py] => SNet: Task 9, Epoch 25/130 => Loss 31.923,  Loss1 0.786, Train_accy 59.67
2024-08-07 20:07:07,294 [foster.py] => SNet: Task 9, Epoch 26/130 => Loss 31.911,  Loss1 0.786, Train_accy 61.23, Test_accy 61.94
2024-08-07 20:07:17,878 [foster.py] => SNet: Task 9, Epoch 27/130 => Loss 31.909,  Loss1 0.786, Train_accy 60.44
2024-08-07 20:07:28,632 [foster.py] => SNet: Task 9, Epoch 28/130 => Loss 31.914,  Loss1 0.786, Train_accy 60.63
2024-08-07 20:07:39,081 [foster.py] => SNet: Task 9, Epoch 29/130 => Loss 31.908,  Loss1 0.786, Train_accy 61.26
2024-08-07 20:07:49,557 [foster.py] => SNet: Task 9, Epoch 30/130 => Loss 31.923,  Loss1 0.786, Train_accy 60.64
2024-08-07 20:08:02,630 [foster.py] => SNet: Task 9, Epoch 31/130 => Loss 31.924,  Loss1 0.786, Train_accy 60.32, Test_accy 61.77
2024-08-07 20:08:13,409 [foster.py] => SNet: Task 9, Epoch 32/130 => Loss 31.900,  Loss1 0.786, Train_accy 60.89
2024-08-07 20:08:24,016 [foster.py] => SNet: Task 9, Epoch 33/130 => Loss 31.903,  Loss1 0.786, Train_accy 62.74
2024-08-07 20:08:34,411 [foster.py] => SNet: Task 9, Epoch 34/130 => Loss 31.927,  Loss1 0.786, Train_accy 61.45
2024-08-07 20:08:45,102 [foster.py] => SNet: Task 9, Epoch 35/130 => Loss 31.913,  Loss1 0.786, Train_accy 62.21
2024-08-07 20:08:58,379 [foster.py] => SNet: Task 9, Epoch 36/130 => Loss 31.900,  Loss1 0.786, Train_accy 61.83, Test_accy 62.32
2024-08-07 20:09:08,875 [foster.py] => SNet: Task 9, Epoch 37/130 => Loss 31.904,  Loss1 0.786, Train_accy 60.96
2024-08-07 20:09:19,362 [foster.py] => SNet: Task 9, Epoch 38/130 => Loss 31.903,  Loss1 0.786, Train_accy 61.78
2024-08-07 20:09:30,029 [foster.py] => SNet: Task 9, Epoch 39/130 => Loss 31.914,  Loss1 0.786, Train_accy 61.81
2024-08-07 20:09:40,773 [foster.py] => SNet: Task 9, Epoch 40/130 => Loss 31.905,  Loss1 0.786, Train_accy 61.89
2024-08-07 20:09:54,066 [foster.py] => SNet: Task 9, Epoch 41/130 => Loss 31.921,  Loss1 0.786, Train_accy 62.28, Test_accy 62.23
2024-08-07 20:10:04,587 [foster.py] => SNet: Task 9, Epoch 42/130 => Loss 31.910,  Loss1 0.786, Train_accy 61.60
2024-08-07 20:10:15,136 [foster.py] => SNet: Task 9, Epoch 43/130 => Loss 31.898,  Loss1 0.786, Train_accy 62.15
2024-08-07 20:10:26,055 [foster.py] => SNet: Task 9, Epoch 44/130 => Loss 31.895,  Loss1 0.786, Train_accy 62.34
2024-08-07 20:10:36,505 [foster.py] => SNet: Task 9, Epoch 45/130 => Loss 31.923,  Loss1 0.786, Train_accy 60.99
2024-08-07 20:10:49,805 [foster.py] => SNet: Task 9, Epoch 46/130 => Loss 31.902,  Loss1 0.786, Train_accy 61.98, Test_accy 61.99
2024-08-07 20:11:00,218 [foster.py] => SNet: Task 9, Epoch 47/130 => Loss 31.883,  Loss1 0.786, Train_accy 62.68
2024-08-07 20:11:11,004 [foster.py] => SNet: Task 9, Epoch 48/130 => Loss 31.900,  Loss1 0.786, Train_accy 61.49
2024-08-07 20:11:21,501 [foster.py] => SNet: Task 9, Epoch 49/130 => Loss 31.906,  Loss1 0.786, Train_accy 62.82
2024-08-07 20:11:32,013 [foster.py] => SNet: Task 9, Epoch 50/130 => Loss 31.898,  Loss1 0.786, Train_accy 62.62
2024-08-07 20:11:45,322 [foster.py] => SNet: Task 9, Epoch 51/130 => Loss 31.877,  Loss1 0.786, Train_accy 62.69, Test_accy 62.27
2024-08-07 20:11:55,757 [foster.py] => SNet: Task 9, Epoch 52/130 => Loss 31.890,  Loss1 0.786, Train_accy 62.95
2024-08-07 20:12:06,179 [foster.py] => SNet: Task 9, Epoch 53/130 => Loss 31.875,  Loss1 0.786, Train_accy 62.89
2024-08-07 20:12:16,926 [foster.py] => SNet: Task 9, Epoch 54/130 => Loss 31.888,  Loss1 0.786, Train_accy 63.55
2024-08-07 20:12:27,644 [foster.py] => SNet: Task 9, Epoch 55/130 => Loss 31.909,  Loss1 0.786, Train_accy 62.31
2024-08-07 20:12:40,758 [foster.py] => SNet: Task 9, Epoch 56/130 => Loss 31.880,  Loss1 0.786, Train_accy 61.69, Test_accy 62.30
2024-08-07 20:12:51,272 [foster.py] => SNet: Task 9, Epoch 57/130 => Loss 31.901,  Loss1 0.786, Train_accy 61.95
2024-08-07 20:13:01,743 [foster.py] => SNet: Task 9, Epoch 58/130 => Loss 31.878,  Loss1 0.786, Train_accy 63.07
2024-08-07 20:13:12,493 [foster.py] => SNet: Task 9, Epoch 59/130 => Loss 31.893,  Loss1 0.786, Train_accy 62.87
2024-08-07 20:13:23,142 [foster.py] => SNet: Task 9, Epoch 60/130 => Loss 31.902,  Loss1 0.786, Train_accy 63.30
2024-08-07 20:13:36,495 [foster.py] => SNet: Task 9, Epoch 61/130 => Loss 31.882,  Loss1 0.786, Train_accy 62.82, Test_accy 62.83
2024-08-07 20:13:46,986 [foster.py] => SNet: Task 9, Epoch 62/130 => Loss 31.898,  Loss1 0.786, Train_accy 63.40
2024-08-07 20:13:57,544 [foster.py] => SNet: Task 9, Epoch 63/130 => Loss 31.883,  Loss1 0.786, Train_accy 63.14
2024-08-07 20:14:08,265 [foster.py] => SNet: Task 9, Epoch 64/130 => Loss 31.914,  Loss1 0.786, Train_accy 63.07
2024-08-07 20:14:18,922 [foster.py] => SNet: Task 9, Epoch 65/130 => Loss 31.895,  Loss1 0.786, Train_accy 64.48
2024-08-07 20:14:32,342 [foster.py] => SNet: Task 9, Epoch 66/130 => Loss 31.913,  Loss1 0.786, Train_accy 64.28, Test_accy 62.69
2024-08-07 20:14:42,815 [foster.py] => SNet: Task 9, Epoch 67/130 => Loss 31.881,  Loss1 0.786, Train_accy 63.05
2024-08-07 20:14:53,509 [foster.py] => SNet: Task 9, Epoch 68/130 => Loss 31.888,  Loss1 0.786, Train_accy 63.74
2024-08-07 20:15:04,281 [foster.py] => SNet: Task 9, Epoch 69/130 => Loss 31.895,  Loss1 0.786, Train_accy 63.90
2024-08-07 20:15:15,032 [foster.py] => SNet: Task 9, Epoch 70/130 => Loss 31.873,  Loss1 0.786, Train_accy 64.31
2024-08-07 20:15:28,111 [foster.py] => SNet: Task 9, Epoch 71/130 => Loss 31.913,  Loss1 0.786, Train_accy 63.45, Test_accy 62.84
2024-08-07 20:15:38,697 [foster.py] => SNet: Task 9, Epoch 72/130 => Loss 31.908,  Loss1 0.786, Train_accy 63.67
2024-08-07 20:15:49,649 [foster.py] => SNet: Task 9, Epoch 73/130 => Loss 31.871,  Loss1 0.786, Train_accy 64.76
2024-08-07 20:16:00,092 [foster.py] => SNet: Task 9, Epoch 74/130 => Loss 31.882,  Loss1 0.786, Train_accy 64.04
2024-08-07 20:16:10,510 [foster.py] => SNet: Task 9, Epoch 75/130 => Loss 31.901,  Loss1 0.786, Train_accy 62.81
2024-08-07 20:16:23,616 [foster.py] => SNet: Task 9, Epoch 76/130 => Loss 31.906,  Loss1 0.786, Train_accy 63.68, Test_accy 62.91
2024-08-07 20:16:33,978 [foster.py] => SNet: Task 9, Epoch 77/130 => Loss 31.891,  Loss1 0.786, Train_accy 63.80
2024-08-07 20:16:44,356 [foster.py] => SNet: Task 9, Epoch 78/130 => Loss 31.878,  Loss1 0.786, Train_accy 63.94
2024-08-07 20:16:55,287 [foster.py] => SNet: Task 9, Epoch 79/130 => Loss 31.899,  Loss1 0.786, Train_accy 63.54
2024-08-07 20:17:05,711 [foster.py] => SNet: Task 9, Epoch 80/130 => Loss 31.910,  Loss1 0.786, Train_accy 63.83
2024-08-07 20:17:18,883 [foster.py] => SNet: Task 9, Epoch 81/130 => Loss 31.904,  Loss1 0.786, Train_accy 63.75, Test_accy 62.90
2024-08-07 20:17:29,506 [foster.py] => SNet: Task 9, Epoch 82/130 => Loss 31.898,  Loss1 0.786, Train_accy 64.07
2024-08-07 20:17:40,224 [foster.py] => SNet: Task 9, Epoch 83/130 => Loss 31.897,  Loss1 0.786, Train_accy 64.21
2024-08-07 20:17:50,719 [foster.py] => SNet: Task 9, Epoch 84/130 => Loss 31.880,  Loss1 0.786, Train_accy 64.36
2024-08-07 20:18:01,232 [foster.py] => SNet: Task 9, Epoch 85/130 => Loss 31.900,  Loss1 0.786, Train_accy 64.18
2024-08-07 20:18:14,319 [foster.py] => SNet: Task 9, Epoch 86/130 => Loss 31.894,  Loss1 0.786, Train_accy 63.72, Test_accy 62.90
2024-08-07 20:18:24,981 [foster.py] => SNet: Task 9, Epoch 87/130 => Loss 31.877,  Loss1 0.786, Train_accy 63.52
2024-08-07 20:18:35,513 [foster.py] => SNet: Task 9, Epoch 88/130 => Loss 31.895,  Loss1 0.786, Train_accy 64.37
2024-08-07 20:18:45,946 [foster.py] => SNet: Task 9, Epoch 89/130 => Loss 31.881,  Loss1 0.786, Train_accy 65.73
2024-08-07 20:18:56,411 [foster.py] => SNet: Task 9, Epoch 90/130 => Loss 31.874,  Loss1 0.786, Train_accy 64.57
2024-08-07 20:19:09,479 [foster.py] => SNet: Task 9, Epoch 91/130 => Loss 31.890,  Loss1 0.786, Train_accy 63.93, Test_accy 62.97
2024-08-07 20:19:20,104 [foster.py] => SNet: Task 9, Epoch 92/130 => Loss 31.894,  Loss1 0.786, Train_accy 64.50
2024-08-07 20:19:30,853 [foster.py] => SNet: Task 9, Epoch 93/130 => Loss 31.878,  Loss1 0.786, Train_accy 64.64
2024-08-07 20:19:41,343 [foster.py] => SNet: Task 9, Epoch 94/130 => Loss 31.887,  Loss1 0.786, Train_accy 64.05
2024-08-07 20:19:51,810 [foster.py] => SNet: Task 9, Epoch 95/130 => Loss 31.875,  Loss1 0.786, Train_accy 64.48
2024-08-07 20:20:04,902 [foster.py] => SNet: Task 9, Epoch 96/130 => Loss 31.911,  Loss1 0.786, Train_accy 64.33, Test_accy 63.00
2024-08-07 20:20:15,623 [foster.py] => SNet: Task 9, Epoch 97/130 => Loss 31.888,  Loss1 0.786, Train_accy 64.11
2024-08-07 20:20:26,062 [foster.py] => SNet: Task 9, Epoch 98/130 => Loss 31.887,  Loss1 0.786, Train_accy 65.69
2024-08-07 20:20:36,587 [foster.py] => SNet: Task 9, Epoch 99/130 => Loss 31.885,  Loss1 0.786, Train_accy 64.13
2024-08-07 20:20:47,303 [foster.py] => SNet: Task 9, Epoch 100/130 => Loss 31.887,  Loss1 0.786, Train_accy 63.19
2024-08-07 20:21:00,316 [foster.py] => SNet: Task 9, Epoch 101/130 => Loss 31.888,  Loss1 0.786, Train_accy 64.53, Test_accy 62.90
2024-08-07 20:21:10,721 [foster.py] => SNet: Task 9, Epoch 102/130 => Loss 31.869,  Loss1 0.786, Train_accy 64.96
2024-08-07 20:21:21,253 [foster.py] => SNet: Task 9, Epoch 103/130 => Loss 31.895,  Loss1 0.786, Train_accy 64.18
2024-08-07 20:21:31,741 [foster.py] => SNet: Task 9, Epoch 104/130 => Loss 31.882,  Loss1 0.786, Train_accy 64.74
2024-08-07 20:21:42,441 [foster.py] => SNet: Task 9, Epoch 105/130 => Loss 31.885,  Loss1 0.786, Train_accy 65.20
2024-08-07 20:21:55,572 [foster.py] => SNet: Task 9, Epoch 106/130 => Loss 31.886,  Loss1 0.786, Train_accy 64.15, Test_accy 62.95
2024-08-07 20:22:05,991 [foster.py] => SNet: Task 9, Epoch 107/130 => Loss 31.879,  Loss1 0.786, Train_accy 64.80
2024-08-07 20:22:16,504 [foster.py] => SNet: Task 9, Epoch 108/130 => Loss 31.879,  Loss1 0.786, Train_accy 64.67
2024-08-07 20:22:26,945 [foster.py] => SNet: Task 9, Epoch 109/130 => Loss 31.877,  Loss1 0.786, Train_accy 64.34
2024-08-07 20:22:37,533 [foster.py] => SNet: Task 9, Epoch 110/130 => Loss 31.877,  Loss1 0.786, Train_accy 64.36
2024-08-07 20:22:50,743 [foster.py] => SNet: Task 9, Epoch 111/130 => Loss 31.906,  Loss1 0.786, Train_accy 64.51, Test_accy 62.99
2024-08-07 20:23:01,352 [foster.py] => SNet: Task 9, Epoch 112/130 => Loss 31.878,  Loss1 0.786, Train_accy 64.61
2024-08-07 20:23:11,788 [foster.py] => SNet: Task 9, Epoch 113/130 => Loss 31.874,  Loss1 0.786, Train_accy 65.72
2024-08-07 20:23:22,246 [foster.py] => SNet: Task 9, Epoch 114/130 => Loss 31.883,  Loss1 0.786, Train_accy 64.54
2024-08-07 20:23:32,881 [foster.py] => SNet: Task 9, Epoch 115/130 => Loss 31.866,  Loss1 0.786, Train_accy 65.14
2024-08-07 20:23:46,257 [foster.py] => SNet: Task 9, Epoch 116/130 => Loss 31.901,  Loss1 0.786, Train_accy 65.47, Test_accy 62.64
2024-08-07 20:23:56,716 [foster.py] => SNet: Task 9, Epoch 117/130 => Loss 31.870,  Loss1 0.786, Train_accy 65.14
2024-08-07 20:24:07,876 [foster.py] => SNet: Task 9, Epoch 118/130 => Loss 31.885,  Loss1 0.786, Train_accy 64.73
2024-08-07 20:24:18,781 [foster.py] => SNet: Task 9, Epoch 119/130 => Loss 31.880,  Loss1 0.786, Train_accy 64.30
2024-08-07 20:24:29,331 [foster.py] => SNet: Task 9, Epoch 120/130 => Loss 31.880,  Loss1 0.786, Train_accy 63.88
2024-08-07 20:24:42,354 [foster.py] => SNet: Task 9, Epoch 121/130 => Loss 31.902,  Loss1 0.786, Train_accy 64.94, Test_accy 62.88
2024-08-07 20:24:53,121 [foster.py] => SNet: Task 9, Epoch 122/130 => Loss 31.883,  Loss1 0.786, Train_accy 64.76
2024-08-07 20:25:03,607 [foster.py] => SNet: Task 9, Epoch 123/130 => Loss 31.872,  Loss1 0.786, Train_accy 64.38
2024-08-07 20:25:14,076 [foster.py] => SNet: Task 9, Epoch 124/130 => Loss 31.882,  Loss1 0.786, Train_accy 65.36
2024-08-07 20:25:24,526 [foster.py] => SNet: Task 9, Epoch 125/130 => Loss 31.890,  Loss1 0.786, Train_accy 64.93
2024-08-07 20:25:38,090 [foster.py] => SNet: Task 9, Epoch 126/130 => Loss 31.883,  Loss1 0.786, Train_accy 64.50, Test_accy 63.01
2024-08-07 20:25:48,667 [foster.py] => SNet: Task 9, Epoch 127/130 => Loss 31.881,  Loss1 0.786, Train_accy 64.61
2024-08-07 20:25:59,110 [foster.py] => SNet: Task 9, Epoch 128/130 => Loss 31.897,  Loss1 0.786, Train_accy 64.30
2024-08-07 20:26:09,774 [foster.py] => SNet: Task 9, Epoch 129/130 => Loss 31.881,  Loss1 0.786, Train_accy 65.03
2024-08-07 20:26:20,401 [foster.py] => SNet: Task 9, Epoch 130/130 => Loss 31.880,  Loss1 0.786, Train_accy 63.78
2024-08-07 20:26:20,401 [foster.py] => do not weight align student!
2024-08-07 20:26:23,076 [foster.py] => darknet eval: 
2024-08-07 20:26:23,077 [foster.py] => CNN top1 curve: 63.0
2024-08-07 20:26:23,077 [foster.py] => CNN top5 curve: 89.02
2024-08-07 20:26:23,077 [foster.py] => CNN top1 平均值: 63.00
2024-08-07 20:26:23,080 [foster.py] => timees : 3140.8245255947113
2024-08-07 20:26:23,081 [base.py] => Reducing exemplars...(20 per classes)
2024-08-07 20:26:54,412 [base.py] => Constructing exemplars...(20 per classes)
2024-08-07 20:27:10,924 [foster.py] => Exemplar size: 2000
2024-08-07 20:27:10,925 [trainer.py] => CNN: {'total': 64.04, '00-09': 65.5, '10-19': 51.1, '20-29': 67.7, '30-39': 61.6, '40-49': 66.8, '50-59': 58.1, '60-69': 66.5, '70-79': 63.2, '80-89': 67.8, '90-99': 72.1, 'old': 63.14, 'new': 72.1}
2024-08-07 20:27:10,925 [trainer.py] => NME: {'total': 58.29, '00-09': 55.8, '10-19': 44.7, '20-29': 61.9, '30-39': 55.0, '40-49': 61.7, '50-59': 53.5, '60-69': 59.6, '70-79': 59.1, '80-89': 60.2, '90-99': 71.4, 'old': 56.83, 'new': 71.4}
2024-08-07 20:27:10,925 [trainer.py] => CNN top1 curve: [94.2, 85.35, 82.97, 78.6, 75.54, 73.43, 71.44, 67.55, 66.17, 64.04]
2024-08-07 20:27:10,925 [trainer.py] => CNN top5 curve: [99.7, 98.2, 97.1, 95.58, 94.64, 93.48, 92.6, 91.38, 90.43, 88.97]
2024-08-07 20:27:10,925 [trainer.py] => NME top1 curve: [94.2, 85.95, 81.7, 75.8, 72.1, 69.15, 67.06, 62.95, 61.01, 58.29]
2024-08-07 20:27:10,925 [trainer.py] => NME top5 curve: [99.6, 97.7, 96.23, 94.55, 93.06, 91.73, 90.39, 88.68, 87.52, 85.16]

2024-08-07 20:27:10,925 [trainer.py] => CNN top1 平均值: 75.93