2025-02-13 18:13:39,368 [trainer.py] => config: ./exps/podnet2.json
2025-02-13 18:13:39,369 [trainer.py] => prefix: reproduce
2025-02-13 18:13:39,370 [trainer.py] => dataset: imagenet100
2025-02-13 18:13:39,370 [trainer.py] => memory_size: 2000
2025-02-13 18:13:39,370 [trainer.py] => memory_per_class: 20
2025-02-13 18:13:39,371 [trainer.py] => fixed_memory: True
2025-02-13 18:13:39,371 [trainer.py] => shuffle: True
2025-02-13 18:13:39,372 [trainer.py] => init_cls: 10
2025-02-13 18:13:39,372 [trainer.py] => increment: 10
2025-02-13 18:13:39,372 [trainer.py] => model_name: podnet
2025-02-13 18:13:39,373 [trainer.py] => convnet_type: cosine_resnet18
2025-02-13 18:13:39,373 [trainer.py] => device: [device(type='cuda', index=0)]
2025-02-13 18:13:39,373 [trainer.py] => seed: 1993
2025-02-13 18:13:42,576 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-02-13 18:13:48,196 [trainer.py] => All params: 11689512
2025-02-13 18:13:48,197 [trainer.py] => Trainable params: 11689512
2025-02-13 18:13:48,198 [podnet.py] => Learning on 0-10
2025-02-13 18:13:48,205 [podnet.py] => Adaptive factor: 0
2025-02-13 18:15:19,580 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 2.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 29.24, Test_acc 25.40
2025-02-13 18:16:21,222 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 1.81, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 42.03, Test_acc 39.00
2025-02-13 18:17:27,869 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 1.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 49.34, Test_acc 52.80
2025-02-13 18:18:37,137 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 1.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 52.98, Test_acc 50.40
2025-02-13 18:19:50,518 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 1.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 57.09, Test_acc 53.00
2025-02-13 18:20:59,535 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 1.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 59.16, Test_acc 58.20
2025-02-13 18:22:08,787 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 1.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.53, Test_acc 58.80
2025-02-13 18:23:17,283 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 1.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 63.36, Test_acc 67.20
2025-02-13 18:24:23,820 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 1.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 64.20, Test_acc 54.80
2025-02-13 18:25:32,570 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 1.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 65.50, Test_acc 62.20
2025-02-13 18:26:43,476 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 1.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 66.20, Test_acc 66.00
2025-02-13 18:27:54,893 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.51, Test_acc 56.00
2025-02-13 18:29:06,597 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 1.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 68.06, Test_acc 70.00
2025-02-13 18:30:16,728 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 1.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 68.21, Test_acc 69.60
2025-02-13 18:31:28,018 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 1.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.32, Test_acc 61.80
2025-02-13 18:32:37,463 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 1.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.08, Test_acc 63.40
2025-02-13 18:33:47,752 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 1.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.17, Test_acc 63.40
2025-02-13 18:34:56,812 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 0.98, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.17, Test_acc 68.40
2025-02-13 18:36:04,544 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 0.96, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.57, Test_acc 69.00
2025-02-13 18:37:14,192 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 0.94, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.36, Test_acc 69.80
2025-02-13 18:38:22,553 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 0.94, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.34, Test_acc 74.40
2025-02-13 18:39:30,180 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 0.93, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.67, Test_acc 74.40
2025-02-13 18:40:35,789 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 0.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.60, Test_acc 73.60
2025-02-13 18:41:45,213 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 0.88, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.06, Test_acc 64.80
2025-02-13 18:42:52,668 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 0.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.59, Test_acc 63.60
2025-02-13 18:44:00,945 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 0.91, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.43, Test_acc 60.60
2025-02-13 18:45:08,231 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 0.89, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.77, Test_acc 77.20
2025-02-13 18:46:11,918 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.84, Test_acc 70.40
2025-02-13 18:47:18,574 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 0.86, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.97, Test_acc 70.20
2025-02-13 18:48:22,270 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 0.87, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.45, Test_acc 73.20
2025-02-13 18:49:30,395 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.06, Test_acc 77.20
2025-02-13 18:50:37,265 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 0.82, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.18, Test_acc 70.20
2025-02-13 18:51:46,417 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 0.83, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.41, Test_acc 68.60
2025-02-13 18:52:51,954 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 0.81, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.77, Test_acc 69.60
2025-02-13 18:53:57,316 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 0.81, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.21, Test_acc 75.40
2025-02-13 18:55:03,831 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 0.80, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.28, Test_acc 78.40
2025-02-13 18:56:05,872 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.23, Test_acc 78.20
2025-02-13 18:57:08,724 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 0.79, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.71, Test_acc 80.40
2025-02-13 18:58:11,228 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.20, Test_acc 75.60
2025-02-13 18:59:13,330 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.11, Test_acc 72.60
2025-02-13 19:00:14,423 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.68, Test_acc 74.60
2025-02-13 19:01:18,165 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 0.77, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.15, Test_acc 79.00
2025-02-13 19:02:23,027 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 0.75, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.18, Test_acc 75.40
2025-02-13 19:03:26,298 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.55, Test_acc 72.60
2025-02-13 19:04:31,232 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.75, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.89, Test_acc 77.00
2025-02-13 19:05:34,060 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.75, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.06, Test_acc 74.80
2025-02-13 19:06:37,475 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.65, Test_acc 73.20
2025-02-13 19:07:42,162 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.71, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.22, Test_acc 78.20
2025-02-13 19:08:45,954 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.74, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.41, Test_acc 76.60
2025-02-13 19:09:51,128 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.88, Test_acc 72.40
2025-02-13 19:10:54,861 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.15, Test_acc 78.80
2025-02-13 19:11:57,118 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.54, Test_acc 78.40
2025-02-13 19:13:01,503 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.22, Test_acc 79.40
2025-02-13 19:14:03,346 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.87, Test_acc 74.80
2025-02-13 19:15:07,322 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.56, Test_acc 80.60
2025-02-13 19:16:10,251 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.60, Test_acc 79.00
2025-02-13 19:17:13,060 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.70, Test_acc 74.00
2025-02-13 19:18:16,079 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.87, Test_acc 80.00
2025-02-13 19:19:16,762 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.83, Test_acc 80.80
2025-02-13 19:20:21,820 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.65, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.73, Test_acc 75.80
2025-02-13 19:21:24,045 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.72, Test_acc 78.60
2025-02-13 19:22:27,717 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.65, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.01, Test_acc 77.60
2025-02-13 19:23:31,369 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.05, Test_acc 78.40
2025-02-13 19:24:34,888 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.66, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.74, Test_acc 79.00
2025-02-13 19:25:41,985 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.95, Test_acc 80.20
2025-02-13 19:26:47,280 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.44, Test_acc 75.00
2025-02-13 19:27:54,031 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.79, Test_acc 76.60
2025-02-13 19:28:59,282 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.77, Test_acc 82.80
2025-02-13 19:30:01,285 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.91, Test_acc 78.80
2025-02-13 19:31:02,571 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.56, Test_acc 82.80
2025-02-13 19:32:07,759 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.42, Test_acc 79.60
2025-02-13 19:33:09,116 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.68, Test_acc 76.80
2025-02-13 19:34:10,926 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.74, Test_acc 76.60
2025-02-13 19:35:14,419 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.12, Test_acc 72.40
2025-02-13 19:36:18,175 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.06, Test_acc 83.00
2025-02-13 19:37:22,568 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.49, Test_acc 82.60
2025-02-13 19:38:27,446 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.20, Test_acc 78.80
2025-02-13 19:39:33,355 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.57, Test_acc 80.40
2025-02-13 19:40:37,110 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.74, Test_acc 82.80
2025-02-13 19:41:40,245 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.21, Test_acc 79.40
2025-02-13 19:42:42,255 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.54, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.01, Test_acc 81.60
2025-02-13 19:43:48,714 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.38, Test_acc 80.00
2025-02-13 19:44:51,496 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.18, Test_acc 84.80
2025-02-13 19:45:52,623 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.90, Test_acc 84.60
2025-02-13 19:46:53,562 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.02, Test_acc 81.40
2025-02-13 19:47:57,119 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.21, Test_acc 80.40
2025-02-13 19:48:56,851 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.99, Test_acc 85.20
2025-02-13 19:49:58,257 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.31, Test_acc 85.80
2025-02-13 19:51:02,301 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.50, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.37, Test_acc 83.00
2025-02-13 19:52:05,434 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.85, Test_acc 80.20
2025-02-13 19:53:06,092 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.19, Test_acc 86.80
2025-02-13 19:54:07,868 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.89, Test_acc 85.20
2025-02-13 19:55:09,368 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.32, Test_acc 83.60
2025-02-13 19:56:11,060 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.83, Test_acc 84.00
2025-02-13 19:57:16,980 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.89, Test_acc 81.80
2025-02-13 19:58:24,825 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.72, Test_acc 79.80
2025-02-13 19:59:27,312 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.45, Test_acc 81.40
2025-02-13 20:00:29,778 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.34, Test_acc 85.60
2025-02-13 20:01:29,110 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.02, Test_acc 84.00
2025-02-13 20:02:30,017 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.50, Test_acc 85.60
2025-02-13 20:03:33,180 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.81, Test_acc 84.40
2025-02-13 20:04:35,798 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.06, Test_acc 87.40
2025-02-13 20:05:38,711 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.40, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.62, Test_acc 83.20
2025-02-13 20:06:42,834 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.86, Test_acc 82.00
2025-02-13 20:07:45,010 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.81, Test_acc 88.60
2025-02-13 20:08:46,941 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.89, Test_acc 84.00
2025-02-13 20:09:49,323 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.14, Test_acc 83.80
2025-02-13 20:10:51,927 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.97, Test_acc 86.00
2025-02-13 20:11:56,312 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.27, Test_acc 86.80
2025-02-13 20:12:59,774 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.44, Test_acc 86.20
2025-02-13 20:14:03,511 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.36, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.81, Test_acc 86.00
2025-02-13 20:15:07,226 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.11, Test_acc 85.60
2025-02-13 20:16:10,881 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.36, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.71, Test_acc 85.80
2025-02-13 20:17:12,361 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.80, Test_acc 89.20
2025-02-13 20:18:18,205 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.66, Test_acc 88.60
2025-02-13 20:19:23,266 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.12, Test_acc 86.80
2025-02-13 20:20:26,860 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.94, Test_acc 85.60
2025-02-13 20:21:30,909 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.32, Test_acc 87.20
2025-02-13 20:22:33,636 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.33, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.59, Test_acc 88.60
2025-02-13 20:23:36,904 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.93, Test_acc 88.00
2025-02-13 20:24:41,050 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.69, Test_acc 84.60
2025-02-13 20:25:50,873 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.74, Test_acc 86.40
2025-02-13 20:26:54,081 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.85, Test_acc 87.60
2025-02-13 20:27:55,964 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.68, Test_acc 87.60
2025-02-13 20:29:01,791 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.25, Test_acc 89.20
2025-02-13 20:30:05,768 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.51, Test_acc 89.80
2025-02-13 20:31:09,844 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.49, Test_acc 88.00
2025-02-13 20:32:16,191 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.28, Test_acc 89.00
2025-02-13 20:33:18,869 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.96, Test_acc 89.00
2025-02-13 20:34:22,457 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.47, Test_acc 87.80
2025-02-13 20:35:29,978 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.40, Test_acc 86.80
2025-02-13 20:36:33,313 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.96, Test_acc 88.40
2025-02-13 20:37:36,281 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.09, Test_acc 89.60
2025-02-13 20:38:42,992 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.23, Test_acc 88.00
2025-02-13 20:39:42,959 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.81, Test_acc 89.00
2025-02-13 20:40:44,251 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.34, Test_acc 90.20
2025-02-13 20:41:46,495 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.74, Test_acc 88.40
2025-02-13 20:42:47,446 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.90, Test_acc 89.80
2025-02-13 20:43:50,360 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.74, Test_acc 88.20
2025-02-13 20:44:50,793 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.92, Test_acc 89.60
2025-02-13 20:45:55,129 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 89.20
2025-02-13 20:46:58,726 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.21, Test_acc 89.60
2025-02-13 20:48:00,811 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.30, Test_acc 88.40
2025-02-13 20:49:04,251 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 89.20
2025-02-13 20:50:06,962 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.22, Test_acc 88.00
2025-02-13 20:51:09,950 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.36, Test_acc 88.20
2025-02-13 20:52:14,324 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.34, Test_acc 89.20
2025-02-13 20:53:13,124 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.70, Test_acc 89.60
2025-02-13 20:54:14,291 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.05, Test_acc 88.80
2025-02-13 20:55:15,729 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.71, Test_acc 89.00
2025-02-13 20:56:22,366 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.93, Test_acc 89.00
2025-02-13 20:57:25,122 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.62, Test_acc 90.00
2025-02-13 20:58:26,320 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.58, Test_acc 89.00
2025-02-13 20:59:29,498 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.68, Test_acc 89.40
2025-02-13 21:00:31,761 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.04, Test_acc 89.60
2025-02-13 21:01:35,064 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.95, Test_acc 89.40
2025-02-13 21:02:39,058 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.04, Test_acc 89.60
2025-02-13 21:03:40,972 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.97, Test_acc 89.40
2025-02-13 21:04:47,155 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.98, Test_acc 89.80
2025-02-13 21:05:52,963 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.93, Test_acc 89.60
2025-02-13 21:05:52,964 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 21:07:12,608 [podnet.py] => Exemplar size: 200
2025-02-13 21:07:12,609 [trainer.py] => CNN: {'total': 89.6, '00-09': 89.6, 'old': 0, 'new': 89.6}
2025-02-13 21:07:12,609 [trainer.py] => NME: {'total': 90.0, '00-09': 90.0, 'old': 0, 'new': 90.0}
2025-02-13 21:07:12,610 [trainer.py] => CNN top1 curve: [89.6]
2025-02-13 21:07:12,610 [trainer.py] => CNN top5 curve: [99.4]
2025-02-13 21:07:12,611 [trainer.py] => NME top1 curve: [90.0]
2025-02-13 21:07:12,611 [trainer.py] => NME top5 curve: [99.4]

2025-02-13 21:07:12,611 [trainer.py] => Average Accuracy (CNN): 89.6
2025-02-13 21:07:12,612 [trainer.py] => Average Accuracy (NME): 90.0
2025-02-13 21:07:12,612 [trainer.py] => All params: 11740713
2025-02-13 21:07:12,613 [trainer.py] => Trainable params: 11740713
2025-02-13 21:07:12,615 [podnet.py] => Learning on 10-20
2025-02-13 21:07:12,622 [podnet.py] => Adaptive factor: 1.4142135623730951
2025-02-13 21:08:17,026 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 1.49, Spatial_loss 2.65, Flat_loss 0.41, Train_acc 58.78, Test_acc 42.60
2025-02-13 21:09:17,354 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 0.92, Spatial_loss 2.45, Flat_loss 0.32, Train_acc 74.33, Test_acc 49.90
2025-02-13 21:10:21,431 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 0.83, Spatial_loss 2.28, Flat_loss 0.29, Train_acc 76.31, Test_acc 57.40
2025-02-13 21:11:28,695 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 0.77, Spatial_loss 2.22, Flat_loss 0.29, Train_acc 78.07, Test_acc 64.10
2025-02-13 21:12:35,289 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 0.70, Spatial_loss 2.08, Flat_loss 0.27, Train_acc 80.13, Test_acc 61.40
2025-02-13 21:13:39,957 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 0.71, Spatial_loss 2.10, Flat_loss 0.27, Train_acc 79.49, Test_acc 60.00
2025-02-13 21:14:43,278 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 0.66, Spatial_loss 2.03, Flat_loss 0.26, Train_acc 81.23, Test_acc 63.90
2025-02-13 21:15:47,779 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 0.65, Spatial_loss 2.01, Flat_loss 0.26, Train_acc 81.59, Test_acc 64.10
2025-02-13 21:16:52,256 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 0.63, Spatial_loss 1.96, Flat_loss 0.25, Train_acc 82.51, Test_acc 66.80
2025-02-13 21:17:56,521 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 0.62, Spatial_loss 1.96, Flat_loss 0.25, Train_acc 82.45, Test_acc 63.40
2025-02-13 21:19:01,773 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 0.62, Spatial_loss 1.94, Flat_loss 0.25, Train_acc 82.42, Test_acc 69.00
2025-02-13 21:20:09,732 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.58, Spatial_loss 1.90, Flat_loss 0.25, Train_acc 83.26, Test_acc 62.50
2025-02-13 21:21:17,724 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.61, Spatial_loss 1.98, Flat_loss 0.25, Train_acc 82.21, Test_acc 66.20
2025-02-13 21:22:28,545 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.60, Spatial_loss 1.97, Flat_loss 0.26, Train_acc 83.17, Test_acc 67.60
2025-02-13 21:23:37,611 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.59, Spatial_loss 1.96, Flat_loss 0.26, Train_acc 83.71, Test_acc 69.20
2025-02-13 21:24:51,255 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.58, Spatial_loss 1.93, Flat_loss 0.25, Train_acc 83.12, Test_acc 65.00
2025-02-13 21:26:01,669 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.55, Spatial_loss 1.86, Flat_loss 0.24, Train_acc 84.78, Test_acc 65.10
2025-02-13 21:27:13,756 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.54, Spatial_loss 1.87, Flat_loss 0.24, Train_acc 84.66, Test_acc 68.50
2025-02-13 21:28:24,294 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.54, Spatial_loss 1.85, Flat_loss 0.24, Train_acc 84.67, Test_acc 69.50
2025-02-13 21:29:32,788 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.53, Spatial_loss 1.89, Flat_loss 0.24, Train_acc 84.90, Test_acc 67.50
2025-02-13 21:30:42,582 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.51, Spatial_loss 1.84, Flat_loss 0.24, Train_acc 86.07, Test_acc 67.00
2025-02-13 21:31:52,680 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.55, Spatial_loss 1.91, Flat_loss 0.25, Train_acc 84.45, Test_acc 67.00
2025-02-13 21:33:00,540 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.52, Spatial_loss 1.85, Flat_loss 0.24, Train_acc 85.03, Test_acc 65.00
2025-02-13 21:34:06,254 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.53, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 85.03, Test_acc 65.40
2025-02-13 21:35:12,718 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.55, Spatial_loss 1.97, Flat_loss 0.26, Train_acc 84.61, Test_acc 63.70
2025-02-13 21:36:17,086 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.51, Spatial_loss 1.83, Flat_loss 0.24, Train_acc 85.80, Test_acc 67.70
2025-02-13 21:37:23,076 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.51, Spatial_loss 1.82, Flat_loss 0.24, Train_acc 85.83, Test_acc 68.00
2025-02-13 21:38:29,906 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.51, Spatial_loss 1.84, Flat_loss 0.24, Train_acc 85.56, Test_acc 65.10
2025-02-13 21:39:35,153 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.49, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 86.24, Test_acc 71.80
2025-02-13 21:40:41,802 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.48, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 86.63, Test_acc 66.20
2025-02-13 21:41:48,984 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.50, Spatial_loss 1.81, Flat_loss 0.24, Train_acc 86.36, Test_acc 66.00
2025-02-13 21:43:01,230 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.52, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 85.01, Test_acc 64.10
2025-02-13 21:44:07,253 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.50, Spatial_loss 1.85, Flat_loss 0.24, Train_acc 86.27, Test_acc 70.00
2025-02-13 21:45:13,651 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.47, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 86.99, Test_acc 69.20
2025-02-13 21:46:21,815 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.50, Spatial_loss 1.88, Flat_loss 0.25, Train_acc 85.65, Test_acc 68.20
2025-02-13 21:47:27,320 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.48, Spatial_loss 1.83, Flat_loss 0.24, Train_acc 87.03, Test_acc 70.10
2025-02-13 21:48:34,507 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.47, Spatial_loss 1.79, Flat_loss 0.24, Train_acc 87.08, Test_acc 68.80
2025-02-13 21:49:39,048 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.48, Spatial_loss 1.79, Flat_loss 0.24, Train_acc 86.69, Test_acc 68.90
2025-02-13 21:50:45,381 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.46, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 87.25, Test_acc 65.80
2025-02-13 21:51:56,032 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.49, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 86.45, Test_acc 69.30
2025-02-13 21:53:06,051 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.46, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 87.07, Test_acc 65.10
2025-02-13 21:54:12,597 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.46, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 87.31, Test_acc 71.50
2025-02-13 21:55:18,759 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.48, Spatial_loss 1.81, Flat_loss 0.24, Train_acc 86.93, Test_acc 69.70
2025-02-13 21:56:26,516 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.45, Spatial_loss 1.76, Flat_loss 0.23, Train_acc 87.56, Test_acc 71.00
2025-02-13 21:57:35,156 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.46, Spatial_loss 1.74, Flat_loss 0.23, Train_acc 87.40, Test_acc 68.80
2025-02-13 21:58:41,566 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.46, Spatial_loss 1.76, Flat_loss 0.24, Train_acc 87.38, Test_acc 66.80
2025-02-13 21:59:49,645 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.47, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 86.85, Test_acc 69.10
2025-02-13 22:00:57,912 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.46, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 87.36, Test_acc 65.70
2025-02-13 22:02:04,717 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.51, Spatial_loss 1.90, Flat_loss 0.25, Train_acc 85.62, Test_acc 70.90
2025-02-13 22:03:11,983 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.44, Spatial_loss 1.75, Flat_loss 0.23, Train_acc 87.85, Test_acc 69.60
2025-02-13 22:04:19,153 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.43, Spatial_loss 1.70, Flat_loss 0.23, Train_acc 88.55, Test_acc 68.30
2025-02-13 22:05:26,639 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.48, Spatial_loss 1.83, Flat_loss 0.24, Train_acc 86.36, Test_acc 69.00
2025-02-13 22:06:33,416 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.43, Spatial_loss 1.72, Flat_loss 0.23, Train_acc 87.59, Test_acc 68.00
2025-02-13 22:07:37,080 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.42, Spatial_loss 1.70, Flat_loss 0.23, Train_acc 88.29, Test_acc 71.70
2025-02-13 22:08:43,786 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.43, Spatial_loss 1.71, Flat_loss 0.23, Train_acc 88.16, Test_acc 67.50
2025-02-13 22:09:50,097 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.46, Spatial_loss 1.75, Flat_loss 0.23, Train_acc 87.36, Test_acc 67.20
2025-02-13 22:10:55,279 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.42, Spatial_loss 1.71, Flat_loss 0.23, Train_acc 88.50, Test_acc 65.60
2025-02-13 22:12:02,645 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.40, Spatial_loss 1.70, Flat_loss 0.23, Train_acc 89.12, Test_acc 70.60
2025-02-13 22:13:11,487 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.41, Spatial_loss 1.69, Flat_loss 0.23, Train_acc 88.59, Test_acc 70.70
2025-02-13 22:14:17,213 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.46, Spatial_loss 1.79, Flat_loss 0.24, Train_acc 87.69, Test_acc 69.80
2025-02-13 22:15:28,816 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.45, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 87.50, Test_acc 70.40
2025-02-13 22:16:37,763 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.42, Spatial_loss 1.71, Flat_loss 0.23, Train_acc 88.29, Test_acc 69.30
2025-02-13 22:17:46,867 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.40, Spatial_loss 1.69, Flat_loss 0.23, Train_acc 88.70, Test_acc 67.70
2025-02-13 22:18:55,658 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.40, Spatial_loss 1.69, Flat_loss 0.23, Train_acc 88.81, Test_acc 68.90
2025-02-13 22:20:05,091 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.41, Spatial_loss 1.72, Flat_loss 0.23, Train_acc 88.88, Test_acc 70.30
2025-02-13 22:21:14,924 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.40, Spatial_loss 1.66, Flat_loss 0.23, Train_acc 89.20, Test_acc 69.30
2025-02-13 22:22:26,626 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.40, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 88.88, Test_acc 69.40
2025-02-13 22:23:37,917 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.39, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 89.55, Test_acc 72.20
2025-02-13 22:24:45,416 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.41, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 88.59, Test_acc 65.00
2025-02-13 22:25:53,075 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.40, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 89.12, Test_acc 71.00
2025-02-13 22:27:01,100 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.41, Spatial_loss 1.67, Flat_loss 0.23, Train_acc 88.76, Test_acc 66.30
2025-02-13 22:28:10,490 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.39, Spatial_loss 1.66, Flat_loss 0.23, Train_acc 89.62, Test_acc 73.30
2025-02-13 22:29:19,506 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.37, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 90.15, Test_acc 72.20
2025-02-13 22:30:25,692 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.40, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 89.35, Test_acc 72.30
2025-02-13 22:31:31,647 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.39, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 89.39, Test_acc 71.00
2025-02-13 22:32:37,502 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.34, Spatial_loss 1.54, Flat_loss 0.21, Train_acc 90.93, Test_acc 70.50
2025-02-13 22:33:43,529 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 90.22, Test_acc 70.50
2025-02-13 22:34:50,568 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.38, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 89.63, Test_acc 73.00
2025-02-13 22:35:56,614 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.36, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 90.49, Test_acc 68.30
2025-02-13 22:37:05,025 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.38, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 90.04, Test_acc 73.20
2025-02-13 22:38:10,703 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 91.12, Test_acc 74.20
2025-02-13 22:39:16,293 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.36, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 90.34, Test_acc 69.30
2025-02-13 22:40:22,999 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.34, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 90.72, Test_acc 72.40
2025-02-13 22:41:27,582 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.35, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 90.82, Test_acc 72.00
2025-02-13 22:42:32,347 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 90.67, Test_acc 73.20
2025-02-13 22:43:38,610 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 91.30, Test_acc 71.40
2025-02-13 22:44:48,265 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 91.16, Test_acc 71.30
2025-02-13 22:45:56,515 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 90.99, Test_acc 71.90
2025-02-13 22:47:05,029 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.34, Spatial_loss 1.50, Flat_loss 0.21, Train_acc 90.93, Test_acc 75.70
2025-02-13 22:48:11,365 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 91.64, Test_acc 74.70
2025-02-13 22:49:16,849 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 90.84, Test_acc 71.60
2025-02-13 22:50:21,694 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.33, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 91.08, Test_acc 74.10
2025-02-13 22:51:29,933 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.34, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 91.10, Test_acc 70.90
2025-02-13 22:52:35,334 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.33, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 91.65, Test_acc 71.60
2025-02-13 22:53:43,681 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 91.38, Test_acc 72.30
2025-02-13 22:54:50,701 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.31, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 91.98, Test_acc 72.10
2025-02-13 22:55:55,833 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.32, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 91.38, Test_acc 73.10
2025-02-13 22:57:03,425 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.31, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 92.26, Test_acc 74.10
2025-02-13 22:58:08,898 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.31, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 91.79, Test_acc 73.70
2025-02-13 22:59:14,907 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.31, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 92.06, Test_acc 74.60
2025-02-13 23:00:21,251 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 92.58, Test_acc 73.60
2025-02-13 23:01:27,739 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 92.57, Test_acc 75.90
2025-02-13 23:02:34,885 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 92.07, Test_acc 74.00
2025-02-13 23:03:39,764 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.29, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 93.10, Test_acc 72.90
2025-02-13 23:04:46,161 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 92.43, Test_acc 74.20
2025-02-13 23:05:50,252 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.28, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 93.31, Test_acc 71.40
2025-02-13 23:06:54,233 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.31, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 92.20, Test_acc 71.00
2025-02-13 23:07:59,861 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.28, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 92.98, Test_acc 71.90
2025-02-13 23:09:06,945 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 92.99, Test_acc 72.00
2025-02-13 23:10:13,738 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 92.56, Test_acc 72.70
2025-02-13 23:11:18,378 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 93.19, Test_acc 74.70
2025-02-13 23:12:25,255 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 93.50, Test_acc 74.80
2025-02-13 23:13:30,686 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 93.80, Test_acc 74.50
2025-02-13 23:14:38,015 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 93.47, Test_acc 73.40
2025-02-13 23:15:44,251 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.19, Train_acc 94.06, Test_acc 73.10
2025-02-13 23:16:48,418 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.19, Train_acc 94.36, Test_acc 74.40
2025-02-13 23:17:55,967 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 93.73, Test_acc 74.80
2025-02-13 23:19:02,286 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 94.56, Test_acc 75.00
2025-02-13 23:20:08,443 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.18, Train_acc 94.06, Test_acc 73.50
2025-02-13 23:21:16,960 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.18, Train_acc 93.89, Test_acc 74.50
2025-02-13 23:22:25,874 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 94.54, Test_acc 75.80
2025-02-13 23:23:32,389 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 94.88, Test_acc 73.20
2025-02-13 23:24:41,779 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 94.76, Test_acc 73.40
2025-02-13 23:25:51,007 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 94.89, Test_acc 72.50
2025-02-13 23:27:02,387 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 94.73, Test_acc 75.70
2025-02-13 23:28:10,315 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 94.90, Test_acc 74.70
2025-02-13 23:29:16,428 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 95.08, Test_acc 75.80
2025-02-13 23:30:23,706 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.18, Train_acc 95.10, Test_acc 74.40
2025-02-13 23:31:31,872 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 95.10, Test_acc 75.00
2025-02-13 23:32:40,842 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.09, Flat_loss 0.18, Train_acc 94.84, Test_acc 75.20
2025-02-13 23:33:50,132 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 94.71, Test_acc 74.50
2025-02-13 23:35:00,531 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 95.29, Test_acc 75.30
2025-02-13 23:36:09,223 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 95.38, Test_acc 74.90
2025-02-13 23:37:17,508 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 95.53, Test_acc 75.70
2025-02-13 23:38:28,967 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 95.16, Test_acc 76.20
2025-02-13 23:39:37,460 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 95.37, Test_acc 75.60
2025-02-13 23:40:43,244 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 95.32, Test_acc 75.10
2025-02-13 23:41:49,094 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 95.66, Test_acc 75.50
2025-02-13 23:42:54,885 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 95.72, Test_acc 76.10
2025-02-13 23:44:01,529 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 95.72, Test_acc 75.70
2025-02-13 23:45:04,923 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 95.72, Test_acc 75.10
2025-02-13 23:46:11,031 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 95.58, Test_acc 76.50
2025-02-13 23:47:18,562 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 96.18, Test_acc 76.00
2025-02-13 23:48:24,120 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 96.07, Test_acc 75.80
2025-02-13 23:49:34,969 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 96.10, Test_acc 75.90
2025-02-13 23:50:39,692 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.18, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 96.12, Test_acc 75.80
2025-02-13 23:51:46,895 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.18, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 96.42, Test_acc 75.80
2025-02-13 23:52:53,480 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 96.16, Test_acc 75.80
2025-02-13 23:53:59,343 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 96.41, Test_acc 76.00
2025-02-13 23:55:05,240 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.41, Test_acc 76.00
2025-02-13 23:56:11,331 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.33, Test_acc 76.10
2025-02-13 23:57:20,233 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.18, Spatial_loss 0.95, Flat_loss 0.16, Train_acc 96.35, Test_acc 76.00
2025-02-13 23:58:27,964 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.33, Test_acc 76.50
2025-02-13 23:59:36,541 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.18, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 96.41, Test_acc 76.50
2025-02-14 00:00:43,475 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.29, Test_acc 75.70
2025-02-14 00:01:54,039 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.00, Test_acc 76.80
2025-02-14 00:03:03,919 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.40, Test_acc 75.20
2025-02-14 00:04:12,594 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.09, Test_acc 76.30
2025-02-14 00:05:19,866 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.29, Test_acc 76.50
2025-02-14 00:06:27,773 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 96.34, Test_acc 76.00
2025-02-14 00:06:27,774 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 00:06:27,776 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 00:07:52,332 [podnet.py] => The size of finetune dataset: 400
2025-02-14 00:08:02,829 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.53, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 90.25, Test_acc 75.50
2025-02-14 00:08:09,976 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.47, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 90.00, Test_acc 76.50
2025-02-14 00:08:16,949 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.38, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 94.00, Test_acc 77.00
2025-02-14 00:08:23,922 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.33, Spatial_loss 1.38, Flat_loss 0.18, Train_acc 93.50, Test_acc 77.50
2025-02-14 00:08:30,988 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.32, Spatial_loss 1.29, Flat_loss 0.17, Train_acc 93.50, Test_acc 78.30
2025-02-14 00:08:38,217 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.33, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 92.00, Test_acc 79.00
2025-02-14 00:08:45,098 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.24, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 92.75, Test_acc 79.40
2025-02-14 00:08:52,127 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.42, Spatial_loss 1.34, Flat_loss 0.17, Train_acc 96.00, Test_acc 79.20
2025-02-14 00:08:59,170 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 94.00, Test_acc 79.30
2025-02-14 00:09:06,272 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.26, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 95.00, Test_acc 79.10
2025-02-14 00:09:14,261 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.17, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 96.00, Test_acc 80.30
2025-02-14 00:09:21,418 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.23, Spatial_loss 1.31, Flat_loss 0.16, Train_acc 96.00, Test_acc 79.80
2025-02-14 00:09:28,406 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.25, Spatial_loss 1.19, Flat_loss 0.17, Train_acc 95.75, Test_acc 80.70
2025-02-14 00:09:35,467 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.26, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 95.00, Test_acc 80.80
2025-02-14 00:09:42,472 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.25, Spatial_loss 1.43, Flat_loss 0.17, Train_acc 96.00, Test_acc 80.60
2025-02-14 00:09:49,414 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.19, Spatial_loss 1.39, Flat_loss 0.18, Train_acc 96.25, Test_acc 81.00
2025-02-14 00:09:56,470 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.23, Spatial_loss 1.26, Flat_loss 0.18, Train_acc 95.50, Test_acc 80.30
2025-02-14 00:10:03,414 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.15, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 96.75, Test_acc 81.10
2025-02-14 00:10:10,393 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.16, Train_acc 96.00, Test_acc 81.10
2025-02-14 00:10:17,333 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.26, Flat_loss 0.17, Train_acc 96.00, Test_acc 81.00
2025-02-14 00:10:17,334 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 00:11:58,770 [podnet.py] => Exemplar size: 400
2025-02-14 00:11:58,771 [trainer.py] => CNN: {'total': 81.0, '00-09': 80.8, '10-19': 81.2, 'old': 80.8, 'new': 81.2}
2025-02-14 00:11:58,772 [trainer.py] => NME: {'total': 79.8, '00-09': 78.8, '10-19': 80.8, 'old': 78.8, 'new': 80.8}
2025-02-14 00:11:58,772 [trainer.py] => CNN top1 curve: [89.6, 81.0]
2025-02-14 00:11:58,773 [trainer.py] => CNN top5 curve: [99.4, 95.7]
2025-02-14 00:11:58,773 [trainer.py] => NME top1 curve: [90.0, 79.8]
2025-02-14 00:11:58,774 [trainer.py] => NME top5 curve: [99.4, 94.7]

2025-02-14 00:11:58,774 [trainer.py] => Average Accuracy (CNN): 85.3
2025-02-14 00:11:58,775 [trainer.py] => Average Accuracy (NME): 84.9
2025-02-14 00:11:58,776 [trainer.py] => All params: 11791913
2025-02-14 00:11:58,776 [trainer.py] => Trainable params: 11791913
2025-02-14 00:11:58,779 [podnet.py] => Learning on 20-30
2025-02-14 00:11:58,785 [podnet.py] => Adaptive factor: 1.7320508075688772
2025-02-14 00:13:17,237 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 1.40, Spatial_loss 2.70, Flat_loss 0.47, Train_acc 64.72, Test_acc 35.27
2025-02-14 00:14:30,788 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 0.88, Spatial_loss 2.31, Flat_loss 0.26, Train_acc 74.90, Test_acc 38.13
2025-02-14 00:15:47,540 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 0.81, Spatial_loss 2.20, Flat_loss 0.22, Train_acc 77.01, Test_acc 43.00
2025-02-14 00:17:05,329 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 0.75, Spatial_loss 2.16, Flat_loss 0.21, Train_acc 79.16, Test_acc 42.20
2025-02-14 00:18:20,628 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 0.73, Spatial_loss 2.11, Flat_loss 0.20, Train_acc 79.54, Test_acc 40.73
2025-02-14 00:19:34,520 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 0.70, Spatial_loss 2.09, Flat_loss 0.19, Train_acc 80.81, Test_acc 47.80
2025-02-14 00:20:46,659 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 0.70, Spatial_loss 2.07, Flat_loss 0.19, Train_acc 80.66, Test_acc 49.27
2025-02-14 00:22:01,638 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 0.66, Spatial_loss 2.02, Flat_loss 0.19, Train_acc 81.65, Test_acc 41.80
2025-02-14 00:23:13,651 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.64, Spatial_loss 1.99, Flat_loss 0.18, Train_acc 82.25, Test_acc 40.80
2025-02-14 00:24:26,812 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.64, Spatial_loss 2.01, Flat_loss 0.18, Train_acc 82.40, Test_acc 46.00
2025-02-14 00:25:41,231 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.63, Spatial_loss 1.98, Flat_loss 0.18, Train_acc 82.93, Test_acc 46.33
2025-02-14 00:26:57,731 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.61, Spatial_loss 1.97, Flat_loss 0.18, Train_acc 83.25, Test_acc 49.53
2025-02-14 00:28:11,189 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.60, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 83.55, Test_acc 48.47
2025-02-14 00:29:25,647 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.60, Spatial_loss 1.97, Flat_loss 0.18, Train_acc 83.69, Test_acc 45.87
2025-02-14 00:30:39,460 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.61, Spatial_loss 2.00, Flat_loss 0.18, Train_acc 83.25, Test_acc 50.33
2025-02-14 00:31:56,635 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.58, Spatial_loss 1.94, Flat_loss 0.18, Train_acc 84.05, Test_acc 49.33
2025-02-14 00:33:09,714 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.58, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 84.00, Test_acc 48.33
2025-02-14 00:34:25,388 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.57, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 84.33, Test_acc 48.33
2025-02-14 00:35:39,557 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.57, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 84.31, Test_acc 52.40
2025-02-14 00:36:51,314 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.55, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 84.62, Test_acc 51.87
2025-02-14 00:38:05,491 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.55, Spatial_loss 1.93, Flat_loss 0.18, Train_acc 84.91, Test_acc 47.47
2025-02-14 00:39:20,951 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.56, Spatial_loss 1.94, Flat_loss 0.18, Train_acc 84.81, Test_acc 50.47
2025-02-14 00:40:35,156 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.54, Spatial_loss 1.90, Flat_loss 0.18, Train_acc 85.34, Test_acc 49.47
2025-02-14 00:41:50,368 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.55, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 85.00, Test_acc 49.40
2025-02-14 00:43:03,176 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.53, Spatial_loss 1.90, Flat_loss 0.18, Train_acc 85.64, Test_acc 53.27
2025-02-14 00:44:18,293 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.53, Spatial_loss 1.88, Flat_loss 0.18, Train_acc 85.97, Test_acc 46.87
2025-02-14 00:45:34,847 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.52, Spatial_loss 1.90, Flat_loss 0.18, Train_acc 85.78, Test_acc 50.87
2025-02-14 00:46:49,136 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.51, Spatial_loss 1.90, Flat_loss 0.18, Train_acc 86.22, Test_acc 50.20
2025-02-14 00:48:05,857 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.52, Spatial_loss 1.89, Flat_loss 0.18, Train_acc 85.71, Test_acc 49.93
2025-02-14 00:49:19,739 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.50, Spatial_loss 1.87, Flat_loss 0.18, Train_acc 86.26, Test_acc 49.20
2025-02-14 00:50:36,031 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.51, Spatial_loss 1.88, Flat_loss 0.18, Train_acc 85.98, Test_acc 45.60
2025-02-14 00:51:49,591 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.52, Spatial_loss 1.89, Flat_loss 0.18, Train_acc 85.81, Test_acc 49.13
2025-02-14 00:53:06,764 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.52, Spatial_loss 1.92, Flat_loss 0.18, Train_acc 86.16, Test_acc 51.67
2025-02-14 00:54:23,738 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.50, Spatial_loss 1.85, Flat_loss 0.18, Train_acc 86.51, Test_acc 49.27
2025-02-14 00:55:39,578 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.50, Spatial_loss 1.89, Flat_loss 0.18, Train_acc 86.21, Test_acc 47.60
2025-02-14 00:56:55,617 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.49, Spatial_loss 1.86, Flat_loss 0.18, Train_acc 86.49, Test_acc 50.40
2025-02-14 00:58:10,774 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.48, Spatial_loss 1.87, Flat_loss 0.18, Train_acc 86.88, Test_acc 49.33
2025-02-14 00:59:26,700 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.48, Spatial_loss 1.85, Flat_loss 0.18, Train_acc 87.50, Test_acc 49.13
2025-02-14 01:00:44,169 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.49, Spatial_loss 1.85, Flat_loss 0.18, Train_acc 86.84, Test_acc 48.73
2025-02-14 01:01:56,422 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.50, Spatial_loss 1.86, Flat_loss 0.18, Train_acc 86.49, Test_acc 54.00
2025-02-14 01:03:08,849 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.47, Spatial_loss 1.83, Flat_loss 0.18, Train_acc 87.19, Test_acc 47.60
2025-02-14 01:04:20,806 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.48, Spatial_loss 1.87, Flat_loss 0.18, Train_acc 87.07, Test_acc 48.40
2025-02-14 01:05:34,481 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.48, Spatial_loss 1.85, Flat_loss 0.18, Train_acc 86.89, Test_acc 50.20
2025-02-14 01:06:45,186 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.47, Spatial_loss 1.84, Flat_loss 0.18, Train_acc 87.04, Test_acc 51.33
2025-02-14 01:07:59,948 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.47, Spatial_loss 1.86, Flat_loss 0.18, Train_acc 87.35, Test_acc 52.53
2025-02-14 01:09:17,283 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.48, Spatial_loss 1.83, Flat_loss 0.18, Train_acc 86.92, Test_acc 51.20
2025-02-14 01:10:29,736 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.48, Spatial_loss 1.83, Flat_loss 0.18, Train_acc 87.10, Test_acc 51.07
2025-02-14 01:11:43,942 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.48, Spatial_loss 1.84, Flat_loss 0.18, Train_acc 86.86, Test_acc 50.00
2025-02-14 01:12:57,104 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.46, Spatial_loss 1.82, Flat_loss 0.18, Train_acc 87.99, Test_acc 47.27
2025-02-14 01:14:13,313 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.48, Spatial_loss 1.81, Flat_loss 0.17, Train_acc 86.91, Test_acc 49.67
2025-02-14 01:15:27,166 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.45, Spatial_loss 1.78, Flat_loss 0.17, Train_acc 88.08, Test_acc 48.53
2025-02-14 01:16:41,190 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.46, Spatial_loss 1.82, Flat_loss 0.18, Train_acc 87.55, Test_acc 47.60
2025-02-14 01:17:55,820 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.46, Spatial_loss 1.79, Flat_loss 0.17, Train_acc 87.93, Test_acc 54.60
2025-02-14 01:19:11,882 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.44, Spatial_loss 1.78, Flat_loss 0.17, Train_acc 88.49, Test_acc 52.40
2025-02-14 01:20:26,249 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.46, Spatial_loss 1.81, Flat_loss 0.18, Train_acc 87.71, Test_acc 47.07
2025-02-14 01:21:43,553 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.46, Spatial_loss 1.80, Flat_loss 0.17, Train_acc 88.08, Test_acc 50.20
2025-02-14 01:22:59,422 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.45, Spatial_loss 1.77, Flat_loss 0.17, Train_acc 87.91, Test_acc 46.87
2025-02-14 01:24:12,780 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.44, Spatial_loss 1.75, Flat_loss 0.17, Train_acc 88.27, Test_acc 47.60
2025-02-14 01:25:26,638 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.44, Spatial_loss 1.78, Flat_loss 0.17, Train_acc 88.17, Test_acc 52.73
2025-02-14 01:26:40,748 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.44, Spatial_loss 1.75, Flat_loss 0.17, Train_acc 88.36, Test_acc 54.00
2025-02-14 01:27:53,994 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.42, Spatial_loss 1.74, Flat_loss 0.17, Train_acc 88.99, Test_acc 53.20
2025-02-14 01:29:06,925 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.42, Spatial_loss 1.76, Flat_loss 0.17, Train_acc 89.00, Test_acc 50.93
2025-02-14 01:30:19,780 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.43, Spatial_loss 1.74, Flat_loss 0.17, Train_acc 88.28, Test_acc 49.87
2025-02-14 01:31:35,391 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.42, Spatial_loss 1.72, Flat_loss 0.17, Train_acc 89.01, Test_acc 50.67
2025-02-14 01:32:50,567 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.43, Spatial_loss 1.74, Flat_loss 0.17, Train_acc 88.68, Test_acc 50.60
2025-02-14 01:34:06,128 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.42, Spatial_loss 1.70, Flat_loss 0.17, Train_acc 88.90, Test_acc 51.27
2025-02-14 01:35:20,026 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.41, Spatial_loss 1.71, Flat_loss 0.17, Train_acc 89.10, Test_acc 52.20
2025-02-14 01:36:32,657 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.17, Train_acc 89.73, Test_acc 54.07
2025-02-14 01:37:50,945 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.41, Spatial_loss 1.68, Flat_loss 0.17, Train_acc 89.72, Test_acc 53.33
2025-02-14 01:39:06,700 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.41, Spatial_loss 1.68, Flat_loss 0.17, Train_acc 89.47, Test_acc 55.80
2025-02-14 01:40:21,738 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.40, Spatial_loss 1.66, Flat_loss 0.17, Train_acc 89.53, Test_acc 51.53
2025-02-14 01:41:37,792 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.40, Spatial_loss 1.64, Flat_loss 0.17, Train_acc 89.72, Test_acc 56.87
2025-02-14 01:42:52,285 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.40, Spatial_loss 1.65, Flat_loss 0.16, Train_acc 89.78, Test_acc 55.20
2025-02-14 01:44:06,134 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.17, Train_acc 89.70, Test_acc 51.67
2025-02-14 01:45:21,321 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.40, Spatial_loss 1.64, Flat_loss 0.16, Train_acc 89.69, Test_acc 49.47
2025-02-14 01:46:34,405 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.16, Train_acc 89.84, Test_acc 50.60
2025-02-14 01:47:50,339 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.41, Spatial_loss 1.62, Flat_loss 0.16, Train_acc 89.43, Test_acc 50.73
2025-02-14 01:49:08,829 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.37, Spatial_loss 1.61, Flat_loss 0.16, Train_acc 90.59, Test_acc 54.07
2025-02-14 01:50:26,519 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.39, Spatial_loss 1.61, Flat_loss 0.16, Train_acc 90.04, Test_acc 52.60
2025-02-14 01:51:40,139 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.38, Spatial_loss 1.60, Flat_loss 0.16, Train_acc 90.19, Test_acc 53.47
2025-02-14 01:52:56,942 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.38, Spatial_loss 1.59, Flat_loss 0.16, Train_acc 89.99, Test_acc 54.40
2025-02-14 01:54:12,253 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.38, Spatial_loss 1.60, Flat_loss 0.16, Train_acc 90.38, Test_acc 55.47
2025-02-14 01:55:25,498 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.37, Spatial_loss 1.59, Flat_loss 0.16, Train_acc 90.69, Test_acc 52.53
2025-02-14 01:56:39,891 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.37, Spatial_loss 1.58, Flat_loss 0.16, Train_acc 90.28, Test_acc 53.00
2025-02-14 01:57:55,381 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.37, Spatial_loss 1.57, Flat_loss 0.16, Train_acc 90.57, Test_acc 55.00
2025-02-14 01:59:12,052 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.16, Train_acc 91.14, Test_acc 52.87
2025-02-14 02:00:27,992 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.37, Spatial_loss 1.54, Flat_loss 0.16, Train_acc 90.82, Test_acc 52.07
2025-02-14 02:01:45,154 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.35, Spatial_loss 1.52, Flat_loss 0.16, Train_acc 90.99, Test_acc 51.87
2025-02-14 02:03:01,620 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.15, Train_acc 91.49, Test_acc 53.47
2025-02-14 02:04:18,419 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.34, Spatial_loss 1.53, Flat_loss 0.16, Train_acc 91.53, Test_acc 52.20
2025-02-14 02:05:35,718 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.15, Train_acc 91.55, Test_acc 55.27
2025-02-14 02:06:51,914 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.35, Spatial_loss 1.50, Flat_loss 0.15, Train_acc 91.32, Test_acc 53.33
2025-02-14 02:08:05,958 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.15, Train_acc 91.49, Test_acc 50.93
2025-02-14 02:09:22,244 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.15, Train_acc 91.47, Test_acc 54.13
2025-02-14 02:10:33,458 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.33, Spatial_loss 1.46, Flat_loss 0.15, Train_acc 91.81, Test_acc 51.73
2025-02-14 02:11:44,271 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.15, Train_acc 91.47, Test_acc 53.27
2025-02-14 02:12:59,011 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.15, Train_acc 91.90, Test_acc 51.93
2025-02-14 02:14:19,470 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.32, Spatial_loss 1.43, Flat_loss 0.15, Train_acc 91.90, Test_acc 56.07
2025-02-14 02:15:33,883 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.15, Train_acc 92.02, Test_acc 54.40
2025-02-14 02:16:45,806 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.15, Train_acc 92.10, Test_acc 53.87
2025-02-14 02:17:59,632 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.39, Flat_loss 0.15, Train_acc 92.38, Test_acc 52.60
2025-02-14 02:19:11,955 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.32, Spatial_loss 1.39, Flat_loss 0.15, Train_acc 92.12, Test_acc 54.33
2025-02-14 02:20:24,671 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.32, Spatial_loss 1.41, Flat_loss 0.15, Train_acc 92.04, Test_acc 52.27
2025-02-14 02:21:37,021 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.14, Train_acc 92.89, Test_acc 53.60
2025-02-14 02:22:49,070 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.14, Train_acc 93.10, Test_acc 54.80
2025-02-14 02:24:05,309 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.15, Train_acc 92.84, Test_acc 55.80
2025-02-14 02:25:21,605 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.14, Train_acc 93.13, Test_acc 57.80
2025-02-14 02:26:34,439 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.29, Spatial_loss 1.32, Flat_loss 0.14, Train_acc 93.02, Test_acc 56.80
2025-02-14 02:27:48,030 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.29, Spatial_loss 1.32, Flat_loss 0.14, Train_acc 93.07, Test_acc 55.13
2025-02-14 02:29:01,914 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.14, Train_acc 93.60, Test_acc 55.80
2025-02-14 02:30:14,471 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 1.29, Flat_loss 0.14, Train_acc 93.38, Test_acc 57.47
2025-02-14 02:31:28,795 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.27, Spatial_loss 1.28, Flat_loss 0.14, Train_acc 93.60, Test_acc 54.40
2025-02-14 02:32:43,072 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 1.27, Flat_loss 0.14, Train_acc 93.16, Test_acc 53.93
2025-02-14 02:33:59,619 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.14, Train_acc 93.81, Test_acc 58.73
2025-02-14 02:35:12,289 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.14, Train_acc 94.05, Test_acc 56.33
2025-02-14 02:36:24,581 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.26, Spatial_loss 1.24, Flat_loss 0.14, Train_acc 94.09, Test_acc 58.00
2025-02-14 02:37:39,800 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.14, Train_acc 93.95, Test_acc 55.73
2025-02-14 02:38:52,196 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.14, Train_acc 93.71, Test_acc 57.00
2025-02-14 02:40:05,447 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.13, Train_acc 94.16, Test_acc 54.93
2025-02-14 02:41:20,276 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.13, Train_acc 94.34, Test_acc 57.87
2025-02-14 02:42:33,892 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.13, Train_acc 94.26, Test_acc 56.53
2025-02-14 02:43:47,046 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.13, Train_acc 94.17, Test_acc 58.93
2025-02-14 02:45:01,315 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.13, Train_acc 94.51, Test_acc 57.87
2025-02-14 02:46:14,640 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.13, Train_acc 94.96, Test_acc 57.13
2025-02-14 02:47:27,698 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.25, Spatial_loss 1.16, Flat_loss 0.13, Train_acc 94.40, Test_acc 57.87
2025-02-14 02:48:40,655 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.24, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 94.60, Test_acc 56.93
2025-02-14 02:49:56,667 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 94.90, Test_acc 58.73
2025-02-14 02:51:13,520 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.13, Train_acc 94.90, Test_acc 56.33
2025-02-14 02:52:28,579 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.13, Train_acc 95.13, Test_acc 58.53
2025-02-14 02:53:42,179 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.08, Flat_loss 0.12, Train_acc 94.92, Test_acc 57.73
2025-02-14 02:54:55,341 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 95.55, Test_acc 58.27
2025-02-14 02:56:10,338 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.08, Flat_loss 0.12, Train_acc 94.98, Test_acc 58.60
2025-02-14 02:57:23,470 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.12, Train_acc 95.27, Test_acc 59.27
2025-02-14 02:58:37,339 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.12, Train_acc 95.56, Test_acc 57.20
2025-02-14 02:59:51,052 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.06, Flat_loss 0.12, Train_acc 95.46, Test_acc 58.47
2025-02-14 03:01:06,726 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.12, Train_acc 95.16, Test_acc 58.33
2025-02-14 03:02:20,732 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.04, Flat_loss 0.12, Train_acc 95.52, Test_acc 59.00
2025-02-14 03:03:34,416 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.03, Flat_loss 0.12, Train_acc 95.61, Test_acc 59.47
2025-02-14 03:04:47,114 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.02, Flat_loss 0.12, Train_acc 95.86, Test_acc 58.87
2025-02-14 03:06:01,144 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.12, Train_acc 96.04, Test_acc 60.67
2025-02-14 03:07:12,612 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.00, Flat_loss 0.12, Train_acc 95.57, Test_acc 59.93
2025-02-14 03:08:24,399 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.12, Train_acc 96.07, Test_acc 60.07
2025-02-14 03:09:35,550 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.12, Train_acc 95.78, Test_acc 60.47
2025-02-14 03:10:49,254 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.20, Spatial_loss 0.97, Flat_loss 0.12, Train_acc 95.94, Test_acc 58.53
2025-02-14 03:12:02,765 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 0.98, Flat_loss 0.12, Train_acc 96.13, Test_acc 59.93
2025-02-14 03:13:15,676 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 0.98, Flat_loss 0.12, Train_acc 96.26, Test_acc 60.07
2025-02-14 03:14:27,860 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 0.97, Flat_loss 0.12, Train_acc 96.00, Test_acc 60.20
2025-02-14 03:15:39,222 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 0.96, Flat_loss 0.12, Train_acc 96.33, Test_acc 60.27
2025-02-14 03:16:52,512 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 0.95, Flat_loss 0.12, Train_acc 95.79, Test_acc 60.27
2025-02-14 03:18:03,496 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 0.96, Flat_loss 0.12, Train_acc 96.03, Test_acc 60.27
2025-02-14 03:19:17,699 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.19, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 96.28, Test_acc 59.93
2025-02-14 03:20:33,485 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.19, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 96.26, Test_acc 60.20
2025-02-14 03:21:45,330 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.19, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 96.10, Test_acc 60.13
2025-02-14 03:22:57,567 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 96.26, Test_acc 60.00
2025-02-14 03:24:11,946 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 0.93, Flat_loss 0.12, Train_acc 96.45, Test_acc 60.87
2025-02-14 03:25:25,820 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 96.35, Test_acc 60.40
2025-02-14 03:26:40,973 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.18, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 96.40, Test_acc 60.07
2025-02-14 03:27:54,237 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.19, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 96.06, Test_acc 60.33
2025-02-14 03:29:08,905 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 96.37, Test_acc 60.47
2025-02-14 03:30:24,067 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 0.93, Flat_loss 0.12, Train_acc 96.24, Test_acc 60.47
2025-02-14 03:30:24,068 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 03:30:24,069 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 03:32:01,604 [podnet.py] => The size of finetune dataset: 600
2025-02-14 03:32:15,883 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.46, Spatial_loss 1.22, Flat_loss 0.13, Train_acc 88.67, Test_acc 61.00
2025-02-14 03:32:26,745 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.45, Spatial_loss 1.06, Flat_loss 0.11, Train_acc 90.00, Test_acc 65.13
2025-02-14 03:32:37,357 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.33, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 92.67, Test_acc 68.67
2025-02-14 03:32:48,277 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.30, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 94.33, Test_acc 69.93
2025-02-14 03:32:58,567 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.23, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 95.33, Test_acc 69.73
2025-02-14 03:33:08,410 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 96.17, Test_acc 69.20
2025-02-14 03:33:18,293 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.10, Train_acc 95.00, Test_acc 69.27
2025-02-14 03:33:28,337 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.24, Spatial_loss 1.00, Flat_loss 0.10, Train_acc 94.67, Test_acc 69.87
2025-02-14 03:33:38,426 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 96.00, Test_acc 69.60
2025-02-14 03:33:49,026 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.23, Spatial_loss 0.93, Flat_loss 0.09, Train_acc 95.33, Test_acc 68.80
2025-02-14 03:33:59,939 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.20, Spatial_loss 0.96, Flat_loss 0.09, Train_acc 95.50, Test_acc 69.20
2025-02-14 03:34:11,076 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 96.83, Test_acc 68.53
2025-02-14 03:34:21,465 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.25, Spatial_loss 0.96, Flat_loss 0.09, Train_acc 94.83, Test_acc 68.60
2025-02-14 03:34:32,387 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.20, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 96.00, Test_acc 68.93
2025-02-14 03:34:43,297 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 96.00, Test_acc 69.13
2025-02-14 03:34:54,170 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.23, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 94.67, Test_acc 69.33
2025-02-14 03:35:04,837 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.22, Spatial_loss 0.90, Flat_loss 0.09, Train_acc 94.83, Test_acc 69.40
2025-02-14 03:35:15,952 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.24, Spatial_loss 0.95, Flat_loss 0.09, Train_acc 94.83, Test_acc 69.53
2025-02-14 03:35:27,926 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.24, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 95.83, Test_acc 69.47
2025-02-14 03:35:39,549 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 0.98, Flat_loss 0.09, Train_acc 95.67, Test_acc 69.20
2025-02-14 03:35:39,551 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 03:37:35,807 [podnet.py] => Exemplar size: 600
2025-02-14 03:37:35,807 [trainer.py] => CNN: {'total': 69.2, '00-09': 72.0, '10-19': 53.4, '20-29': 82.2, 'old': 62.7, 'new': 82.2}
2025-02-14 03:37:35,809 [trainer.py] => NME: {'total': 65.47, '00-09': 73.2, '10-19': 47.0, '20-29': 76.2, 'old': 60.1, 'new': 76.2}
2025-02-14 03:37:35,810 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2]
2025-02-14 03:37:35,810 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33]
2025-02-14 03:37:35,811 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47]
2025-02-14 03:37:35,811 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67]

2025-02-14 03:37:35,811 [trainer.py] => Average Accuracy (CNN): 79.93333333333334
2025-02-14 03:37:35,812 [trainer.py] => Average Accuracy (NME): 78.42333333333333
2025-02-14 03:37:35,813 [trainer.py] => All params: 11843113
2025-02-14 03:37:35,813 [trainer.py] => Trainable params: 11843113
2025-02-14 03:37:35,816 [podnet.py] => Learning on 30-40
2025-02-14 03:37:35,823 [podnet.py] => Adaptive factor: 2.0
2025-02-14 03:38:58,307 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 1.53, Spatial_loss 3.33, Flat_loss 0.60, Train_acc 64.19, Test_acc 24.50
2025-02-14 03:40:16,339 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 0.95, Spatial_loss 2.71, Flat_loss 0.32, Train_acc 74.54, Test_acc 29.40
2025-02-14 03:41:35,191 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 0.85, Spatial_loss 2.58, Flat_loss 0.28, Train_acc 77.24, Test_acc 34.20
2025-02-14 03:42:56,038 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 0.82, Spatial_loss 2.47, Flat_loss 0.25, Train_acc 78.19, Test_acc 32.15
2025-02-14 03:44:15,092 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 0.77, Spatial_loss 2.38, Flat_loss 0.24, Train_acc 79.73, Test_acc 36.30
2025-02-14 03:45:31,684 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 0.74, Spatial_loss 2.38, Flat_loss 0.23, Train_acc 80.67, Test_acc 37.45
2025-02-14 03:46:49,663 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 0.73, Spatial_loss 2.34, Flat_loss 0.23, Train_acc 80.67, Test_acc 35.65
2025-02-14 03:48:05,859 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 0.70, Spatial_loss 2.29, Flat_loss 0.22, Train_acc 81.01, Test_acc 43.75
2025-02-14 03:49:25,273 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 0.68, Spatial_loss 2.29, Flat_loss 0.22, Train_acc 81.47, Test_acc 35.60
2025-02-14 03:50:40,596 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 0.66, Spatial_loss 2.23, Flat_loss 0.21, Train_acc 82.79, Test_acc 36.40
2025-02-14 03:51:57,309 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.66, Spatial_loss 2.25, Flat_loss 0.22, Train_acc 82.42, Test_acc 38.95
2025-02-14 03:53:14,136 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.64, Spatial_loss 2.21, Flat_loss 0.22, Train_acc 83.21, Test_acc 39.05
2025-02-14 03:54:30,875 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.63, Spatial_loss 2.21, Flat_loss 0.21, Train_acc 83.32, Test_acc 35.50
2025-02-14 03:55:48,299 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.62, Spatial_loss 2.19, Flat_loss 0.21, Train_acc 83.51, Test_acc 43.25
2025-02-14 03:57:05,189 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.61, Spatial_loss 2.18, Flat_loss 0.21, Train_acc 83.84, Test_acc 37.10
2025-02-14 03:58:23,101 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.60, Spatial_loss 2.17, Flat_loss 0.21, Train_acc 84.07, Test_acc 39.50
2025-02-14 03:59:40,750 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.61, Spatial_loss 2.15, Flat_loss 0.21, Train_acc 84.15, Test_acc 41.10
2025-02-14 04:00:58,299 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.60, Spatial_loss 2.18, Flat_loss 0.21, Train_acc 84.48, Test_acc 47.05
2025-02-14 04:02:16,406 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.60, Spatial_loss 2.19, Flat_loss 0.21, Train_acc 84.17, Test_acc 38.55
2025-02-14 04:03:33,926 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.58, Spatial_loss 2.19, Flat_loss 0.21, Train_acc 84.84, Test_acc 39.90
2025-02-14 04:04:51,792 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.57, Spatial_loss 2.15, Flat_loss 0.21, Train_acc 85.21, Test_acc 41.45
2025-02-14 04:06:08,462 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.57, Spatial_loss 2.16, Flat_loss 0.21, Train_acc 84.92, Test_acc 34.85
2025-02-14 04:07:25,926 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.57, Spatial_loss 2.17, Flat_loss 0.22, Train_acc 84.85, Test_acc 36.70
2025-02-14 04:08:46,190 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.56, Spatial_loss 2.13, Flat_loss 0.21, Train_acc 85.69, Test_acc 37.50
2025-02-14 04:10:05,520 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.56, Spatial_loss 2.18, Flat_loss 0.21, Train_acc 85.18, Test_acc 40.85
2025-02-14 04:11:21,531 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.55, Spatial_loss 2.12, Flat_loss 0.21, Train_acc 85.64, Test_acc 39.15
2025-02-14 04:12:38,491 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.56, Spatial_loss 2.17, Flat_loss 0.21, Train_acc 85.43, Test_acc 38.65
2025-02-14 04:13:56,316 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.56, Spatial_loss 2.12, Flat_loss 0.21, Train_acc 85.51, Test_acc 42.10
2025-02-14 04:15:15,533 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.56, Spatial_loss 2.16, Flat_loss 0.21, Train_acc 85.54, Test_acc 35.65
2025-02-14 04:16:34,621 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.53, Spatial_loss 2.11, Flat_loss 0.21, Train_acc 86.49, Test_acc 43.60
2025-02-14 04:17:53,576 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.54, Spatial_loss 2.13, Flat_loss 0.21, Train_acc 85.98, Test_acc 40.05
2025-02-14 04:19:11,640 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.55, Spatial_loss 2.14, Flat_loss 0.21, Train_acc 85.69, Test_acc 40.30
2025-02-14 04:20:28,167 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.53, Spatial_loss 2.08, Flat_loss 0.21, Train_acc 86.37, Test_acc 43.90
2025-02-14 04:21:49,026 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.52, Spatial_loss 2.11, Flat_loss 0.21, Train_acc 86.40, Test_acc 41.60
2025-02-14 04:23:04,422 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.53, Spatial_loss 2.11, Flat_loss 0.21, Train_acc 85.99, Test_acc 37.95
2025-02-14 04:24:20,893 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.51, Spatial_loss 2.08, Flat_loss 0.21, Train_acc 86.60, Test_acc 39.50
2025-02-14 04:25:35,811 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.52, Spatial_loss 2.09, Flat_loss 0.21, Train_acc 85.86, Test_acc 44.60
2025-02-14 04:26:52,729 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 2.08, Flat_loss 0.21, Train_acc 87.21, Test_acc 43.25
2025-02-14 04:28:10,104 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.53, Spatial_loss 2.12, Flat_loss 0.21, Train_acc 86.28, Test_acc 40.70
2025-02-14 04:29:30,796 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.51, Spatial_loss 2.06, Flat_loss 0.21, Train_acc 86.85, Test_acc 38.55
2025-02-14 04:30:48,874 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.51, Spatial_loss 2.09, Flat_loss 0.21, Train_acc 86.68, Test_acc 44.80
2025-02-14 04:32:07,217 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.50, Spatial_loss 2.07, Flat_loss 0.21, Train_acc 87.13, Test_acc 44.55
2025-02-14 04:33:23,829 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.50, Spatial_loss 2.05, Flat_loss 0.21, Train_acc 86.92, Test_acc 39.65
2025-02-14 04:34:43,056 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.50, Spatial_loss 2.09, Flat_loss 0.21, Train_acc 87.18, Test_acc 40.70
2025-02-14 04:36:01,472 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.50, Spatial_loss 2.08, Flat_loss 0.21, Train_acc 87.13, Test_acc 40.75
2025-02-14 04:37:19,400 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.51, Spatial_loss 2.05, Flat_loss 0.20, Train_acc 87.02, Test_acc 42.95
2025-02-14 04:38:38,110 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.51, Spatial_loss 2.09, Flat_loss 0.21, Train_acc 86.53, Test_acc 39.55
2025-02-14 04:39:57,268 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.49, Spatial_loss 2.05, Flat_loss 0.21, Train_acc 87.21, Test_acc 42.20
2025-02-14 04:41:15,529 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.49, Spatial_loss 2.04, Flat_loss 0.21, Train_acc 87.48, Test_acc 40.25
2025-02-14 04:42:33,563 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.48, Spatial_loss 2.00, Flat_loss 0.21, Train_acc 87.66, Test_acc 40.75
2025-02-14 04:43:49,755 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.48, Spatial_loss 2.00, Flat_loss 0.20, Train_acc 88.11, Test_acc 48.40
2025-02-14 04:45:07,966 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.48, Spatial_loss 2.00, Flat_loss 0.21, Train_acc 87.78, Test_acc 36.60
2025-02-14 04:46:23,275 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.48, Spatial_loss 2.02, Flat_loss 0.20, Train_acc 87.90, Test_acc 41.00
2025-02-14 04:47:40,433 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.47, Spatial_loss 2.01, Flat_loss 0.20, Train_acc 87.89, Test_acc 42.85
2025-02-14 04:48:59,125 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.48, Spatial_loss 1.99, Flat_loss 0.20, Train_acc 87.96, Test_acc 45.90
2025-02-14 04:50:15,396 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.47, Spatial_loss 1.98, Flat_loss 0.20, Train_acc 88.15, Test_acc 43.00
2025-02-14 04:51:33,026 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.48, Spatial_loss 2.02, Flat_loss 0.20, Train_acc 88.12, Test_acc 43.75
2025-02-14 04:52:49,600 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.47, Spatial_loss 2.00, Flat_loss 0.21, Train_acc 87.97, Test_acc 43.05
2025-02-14 04:54:07,945 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.46, Spatial_loss 1.97, Flat_loss 0.20, Train_acc 88.50, Test_acc 43.50
2025-02-14 04:55:24,978 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.47, Spatial_loss 1.97, Flat_loss 0.20, Train_acc 88.40, Test_acc 41.50
2025-02-14 04:56:40,816 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.45, Spatial_loss 1.95, Flat_loss 0.20, Train_acc 88.85, Test_acc 43.50
2025-02-14 04:57:59,013 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.45, Spatial_loss 1.99, Flat_loss 0.20, Train_acc 88.70, Test_acc 38.65
2025-02-14 04:59:16,361 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.45, Spatial_loss 1.94, Flat_loss 0.20, Train_acc 88.57, Test_acc 42.00
2025-02-14 05:00:34,128 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.45, Spatial_loss 1.92, Flat_loss 0.20, Train_acc 88.69, Test_acc 41.25
2025-02-14 05:01:49,961 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.44, Spatial_loss 1.90, Flat_loss 0.20, Train_acc 89.01, Test_acc 42.80
2025-02-14 05:03:08,541 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.43, Spatial_loss 1.91, Flat_loss 0.20, Train_acc 89.40, Test_acc 40.50
2025-02-14 05:04:24,786 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.44, Spatial_loss 1.93, Flat_loss 0.20, Train_acc 89.02, Test_acc 44.00
2025-02-14 05:05:43,450 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.43, Spatial_loss 1.91, Flat_loss 0.20, Train_acc 89.39, Test_acc 43.25
2025-02-14 05:07:01,065 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.43, Spatial_loss 1.89, Flat_loss 0.20, Train_acc 89.35, Test_acc 41.90
2025-02-14 05:08:16,189 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.45, Spatial_loss 1.89, Flat_loss 0.20, Train_acc 88.57, Test_acc 40.05
2025-02-14 05:09:33,759 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.43, Spatial_loss 1.88, Flat_loss 0.20, Train_acc 89.13, Test_acc 44.00
2025-02-14 05:10:53,846 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.42, Spatial_loss 1.87, Flat_loss 0.20, Train_acc 89.77, Test_acc 40.80
2025-02-14 05:12:10,170 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.44, Spatial_loss 1.89, Flat_loss 0.20, Train_acc 89.20, Test_acc 41.90
2025-02-14 05:13:34,290 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.42, Spatial_loss 1.89, Flat_loss 0.20, Train_acc 89.54, Test_acc 42.20
2025-02-14 05:14:58,581 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.44, Spatial_loss 1.86, Flat_loss 0.19, Train_acc 88.85, Test_acc 46.20
2025-02-14 05:16:24,055 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.41, Spatial_loss 1.83, Flat_loss 0.19, Train_acc 89.91, Test_acc 42.85
2025-02-14 05:17:42,064 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.19, Train_acc 90.24, Test_acc 43.65
2025-02-14 05:19:03,901 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.40, Spatial_loss 1.77, Flat_loss 0.19, Train_acc 90.07, Test_acc 46.40
2025-02-14 05:20:27,365 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.19, Train_acc 90.09, Test_acc 44.50
2025-02-14 05:21:49,322 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.19, Train_acc 90.21, Test_acc 40.10
2025-02-14 05:23:13,790 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.39, Spatial_loss 1.78, Flat_loss 0.19, Train_acc 90.60, Test_acc 42.30
2025-02-14 05:24:38,120 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.19, Train_acc 90.20, Test_acc 42.30
2025-02-14 05:26:01,660 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.40, Spatial_loss 1.76, Flat_loss 0.19, Train_acc 90.11, Test_acc 42.80
2025-02-14 05:27:25,158 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.38, Spatial_loss 1.77, Flat_loss 0.19, Train_acc 90.67, Test_acc 42.40
2025-02-14 05:28:49,988 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.38, Spatial_loss 1.73, Flat_loss 0.18, Train_acc 90.62, Test_acc 41.25
2025-02-14 05:30:12,859 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.38, Spatial_loss 1.73, Flat_loss 0.19, Train_acc 90.90, Test_acc 44.95
2025-02-14 05:31:36,972 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.38, Spatial_loss 1.72, Flat_loss 0.18, Train_acc 90.69, Test_acc 42.30
2025-02-14 05:33:02,072 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.38, Spatial_loss 1.74, Flat_loss 0.18, Train_acc 90.85, Test_acc 43.30
2025-02-14 05:34:25,753 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.37, Spatial_loss 1.70, Flat_loss 0.18, Train_acc 91.12, Test_acc 44.25
2025-02-14 05:35:51,653 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.36, Spatial_loss 1.72, Flat_loss 0.18, Train_acc 91.31, Test_acc 43.25
2025-02-14 05:37:16,593 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.35, Spatial_loss 1.67, Flat_loss 0.18, Train_acc 91.33, Test_acc 45.95
2025-02-14 05:38:40,368 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.35, Spatial_loss 1.65, Flat_loss 0.18, Train_acc 91.55, Test_acc 45.05
2025-02-14 05:40:04,255 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.35, Spatial_loss 1.63, Flat_loss 0.17, Train_acc 91.95, Test_acc 44.85
2025-02-14 05:41:30,987 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.64, Flat_loss 0.18, Train_acc 91.75, Test_acc 43.25
2025-02-14 05:42:55,805 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.36, Spatial_loss 1.66, Flat_loss 0.18, Train_acc 91.32, Test_acc 42.40
2025-02-14 05:44:20,325 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.36, Spatial_loss 1.64, Flat_loss 0.18, Train_acc 91.74, Test_acc 45.40
2025-02-14 05:45:44,201 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.33, Spatial_loss 1.59, Flat_loss 0.18, Train_acc 92.12, Test_acc 47.50
2025-02-14 05:47:09,705 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.61, Flat_loss 0.17, Train_acc 92.47, Test_acc 44.65
2025-02-14 05:48:33,848 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.35, Spatial_loss 1.60, Flat_loss 0.17, Train_acc 91.80, Test_acc 45.75
2025-02-14 05:49:54,867 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.59, Flat_loss 0.17, Train_acc 92.12, Test_acc 44.75
2025-02-14 05:51:18,781 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.56, Flat_loss 0.17, Train_acc 92.60, Test_acc 43.95
2025-02-14 05:52:44,252 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.33, Spatial_loss 1.56, Flat_loss 0.17, Train_acc 92.31, Test_acc 49.45
2025-02-14 05:54:08,646 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.33, Spatial_loss 1.54, Flat_loss 0.17, Train_acc 92.25, Test_acc 45.40
2025-02-14 05:55:35,179 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.32, Spatial_loss 1.56, Flat_loss 0.17, Train_acc 92.64, Test_acc 45.25
2025-02-14 05:56:58,595 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.32, Spatial_loss 1.52, Flat_loss 0.17, Train_acc 92.68, Test_acc 45.55
2025-02-14 05:58:26,286 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.32, Spatial_loss 1.53, Flat_loss 0.17, Train_acc 92.55, Test_acc 44.00
2025-02-14 05:59:50,059 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.33, Spatial_loss 1.54, Flat_loss 0.17, Train_acc 92.48, Test_acc 50.80
2025-02-14 06:01:15,821 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.17, Train_acc 92.85, Test_acc 45.35
2025-02-14 06:02:42,260 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.31, Spatial_loss 1.48, Flat_loss 0.16, Train_acc 93.24, Test_acc 46.95
2025-02-14 06:04:07,005 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.30, Spatial_loss 1.47, Flat_loss 0.17, Train_acc 93.00, Test_acc 45.20
2025-02-14 06:05:31,609 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.16, Train_acc 93.68, Test_acc 47.00
2025-02-14 06:06:59,646 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.16, Train_acc 93.62, Test_acc 47.95
2025-02-14 06:08:24,362 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.29, Spatial_loss 1.41, Flat_loss 0.16, Train_acc 93.47, Test_acc 44.45
2025-02-14 06:09:47,505 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.16, Train_acc 93.41, Test_acc 44.30
2025-02-14 06:11:12,635 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.16, Train_acc 93.72, Test_acc 47.50
2025-02-14 06:12:33,031 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.28, Spatial_loss 1.41, Flat_loss 0.16, Train_acc 93.93, Test_acc 46.25
2025-02-14 06:13:56,233 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.16, Train_acc 93.85, Test_acc 45.95
2025-02-14 06:15:20,273 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.16, Train_acc 94.57, Test_acc 47.90
2025-02-14 06:16:43,247 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.16, Train_acc 94.26, Test_acc 48.75
2025-02-14 06:18:06,361 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 1.35, Flat_loss 0.15, Train_acc 94.40, Test_acc 48.05
2025-02-14 06:19:31,064 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.15, Train_acc 94.25, Test_acc 47.65
2025-02-14 06:20:57,612 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.15, Train_acc 94.52, Test_acc 49.65
2025-02-14 06:22:22,981 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.15, Train_acc 94.30, Test_acc 46.95
2025-02-14 06:23:46,415 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.15, Train_acc 94.46, Test_acc 48.40
2025-02-14 06:25:12,633 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.15, Train_acc 94.56, Test_acc 47.90
2025-02-14 06:26:37,821 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.15, Train_acc 95.04, Test_acc 47.55
2025-02-14 06:28:04,874 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.15, Train_acc 94.65, Test_acc 46.45
2025-02-14 06:29:31,354 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.15, Train_acc 94.96, Test_acc 50.20
2025-02-14 06:30:57,387 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.15, Train_acc 95.18, Test_acc 48.10
2025-02-14 06:32:22,123 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.15, Train_acc 95.12, Test_acc 49.15
2025-02-14 06:33:46,412 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.14, Train_acc 94.93, Test_acc 47.65
2025-02-14 06:35:10,130 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.14, Train_acc 95.19, Test_acc 48.95
2025-02-14 06:36:37,002 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.14, Train_acc 95.32, Test_acc 49.10
2025-02-14 06:38:03,103 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.14, Train_acc 95.82, Test_acc 49.25
2025-02-14 06:39:30,818 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.14, Train_acc 95.80, Test_acc 48.60
2025-02-14 06:40:56,866 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.14, Train_acc 95.73, Test_acc 48.75
2025-02-14 06:42:19,363 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.14, Train_acc 95.70, Test_acc 49.25
2025-02-14 06:43:44,938 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.14, Train_acc 95.67, Test_acc 49.45
2025-02-14 06:45:09,989 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.14, Train_acc 95.91, Test_acc 50.10
2025-02-14 06:46:35,148 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.14, Train_acc 95.92, Test_acc 48.60
2025-02-14 06:48:02,111 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.14, Train_acc 96.12, Test_acc 49.15
2025-02-14 06:49:29,121 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 95.99, Test_acc 49.40
2025-02-14 06:50:55,072 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 95.57, Test_acc 49.55
2025-02-14 06:52:24,776 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 96.00, Test_acc 49.80
2025-02-14 06:53:47,675 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.14, Train_acc 96.12, Test_acc 50.40
2025-02-14 06:55:10,143 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.14, Train_acc 96.04, Test_acc 49.85
2025-02-14 06:56:34,173 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.13, Train_acc 95.93, Test_acc 49.90
2025-02-14 06:57:57,840 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.13, Train_acc 96.12, Test_acc 50.05
2025-02-14 06:59:21,465 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.38, Test_acc 49.70
2025-02-14 07:00:47,711 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.61, Test_acc 49.80
2025-02-14 07:02:13,999 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.34, Test_acc 49.75
2025-02-14 07:03:38,363 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.24, Test_acc 50.85
2025-02-14 07:05:03,525 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.45, Test_acc 49.65
2025-02-14 07:06:31,346 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.13, Train_acc 96.38, Test_acc 50.25
2025-02-14 07:07:58,662 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.13, Train_acc 96.43, Test_acc 50.25
2025-02-14 07:09:22,367 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.13, Train_acc 96.57, Test_acc 49.60
2025-02-14 07:10:45,829 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.13, Train_acc 96.57, Test_acc 49.60
2025-02-14 07:12:10,077 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.13, Train_acc 96.25, Test_acc 49.75
2025-02-14 07:13:37,373 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.13, Train_acc 96.32, Test_acc 50.15
2025-02-14 07:15:07,062 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.13, Train_acc 96.32, Test_acc 50.20
2025-02-14 07:15:07,064 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 07:15:07,064 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 07:16:58,248 [podnet.py] => The size of finetune dataset: 800
2025-02-14 07:17:18,450 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.62, Spatial_loss 1.34, Flat_loss 0.14, Train_acc 87.12, Test_acc 54.15
2025-02-14 07:17:32,924 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.40, Spatial_loss 1.22, Flat_loss 0.11, Train_acc 90.00, Test_acc 59.25
2025-02-14 07:17:46,405 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.31, Spatial_loss 1.24, Flat_loss 0.11, Train_acc 93.50, Test_acc 61.05
2025-02-14 07:17:59,557 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.22, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 94.88, Test_acc 61.45
2025-02-14 07:18:12,247 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 95.25, Test_acc 60.90
2025-02-14 07:18:25,139 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.18, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 96.25, Test_acc 61.05
2025-02-14 07:18:38,592 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.10, Train_acc 95.00, Test_acc 60.95
2025-02-14 07:18:52,454 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 95.12, Test_acc 61.10
2025-02-14 07:19:06,761 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.11, Train_acc 95.88, Test_acc 60.85
2025-02-14 07:19:19,857 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 96.00, Test_acc 60.35
2025-02-14 07:19:34,104 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.11, Train_acc 96.25, Test_acc 61.10
2025-02-14 07:19:48,249 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.23, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 95.50, Test_acc 61.20
2025-02-14 07:20:01,465 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 96.00, Test_acc 61.10
2025-02-14 07:20:15,363 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.10, Train_acc 95.12, Test_acc 61.10
2025-02-14 07:20:30,186 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.10, Train_acc 96.25, Test_acc 61.25
2025-02-14 07:20:44,546 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.19, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 96.62, Test_acc 60.90
2025-02-14 07:20:58,134 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 96.25, Test_acc 61.10
2025-02-14 07:21:11,487 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 96.25, Test_acc 61.05
2025-02-14 07:21:24,734 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.19, Spatial_loss 1.20, Flat_loss 0.10, Train_acc 97.00, Test_acc 61.10
2025-02-14 07:21:38,169 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.25, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 95.50, Test_acc 61.10
2025-02-14 07:21:38,172 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 07:23:50,331 [podnet.py] => Exemplar size: 800
2025-02-14 07:23:50,331 [trainer.py] => CNN: {'total': 61.1, '00-09': 65.6, '10-19': 40.0, '20-29': 56.0, '30-39': 82.8, 'old': 53.87, 'new': 82.8}
2025-02-14 07:23:50,332 [trainer.py] => NME: {'total': 56.5, '00-09': 70.2, '10-19': 31.2, '20-29': 47.2, '30-39': 77.4, 'old': 49.53, 'new': 77.4}
2025-02-14 07:23:50,332 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1]
2025-02-14 07:23:50,333 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7]
2025-02-14 07:23:50,333 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5]
2025-02-14 07:23:50,334 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1]

2025-02-14 07:23:50,334 [trainer.py] => Average Accuracy (CNN): 75.22500000000001
2025-02-14 07:23:50,334 [trainer.py] => Average Accuracy (NME): 72.9425
2025-02-14 07:23:50,335 [trainer.py] => All params: 11894313
2025-02-14 07:23:50,336 [trainer.py] => Trainable params: 11894313
2025-02-14 07:23:50,339 [podnet.py] => Learning on 40-50
2025-02-14 07:23:50,345 [podnet.py] => Adaptive factor: 2.23606797749979
2025-02-14 07:25:22,348 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 1.54, Spatial_loss 3.50, Flat_loss 0.77, Train_acc 64.71, Test_acc 19.84
2025-02-14 07:26:51,595 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 0.99, Spatial_loss 2.92, Flat_loss 0.40, Train_acc 73.77, Test_acc 27.60
2025-02-14 07:28:20,397 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 0.93, Spatial_loss 2.77, Flat_loss 0.34, Train_acc 75.12, Test_acc 30.16
2025-02-14 07:29:46,615 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 0.87, Spatial_loss 2.68, Flat_loss 0.30, Train_acc 77.01, Test_acc 29.44
2025-02-14 07:31:14,940 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 0.82, Spatial_loss 2.55, Flat_loss 0.28, Train_acc 78.68, Test_acc 34.32
2025-02-14 07:32:41,640 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.80, Spatial_loss 2.55, Flat_loss 0.27, Train_acc 79.24, Test_acc 35.44
2025-02-14 07:34:09,736 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.79, Spatial_loss 2.49, Flat_loss 0.26, Train_acc 79.13, Test_acc 31.96
2025-02-14 07:35:39,848 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.76, Spatial_loss 2.52, Flat_loss 0.26, Train_acc 80.18, Test_acc 32.84
2025-02-14 07:37:08,385 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.74, Spatial_loss 2.44, Flat_loss 0.26, Train_acc 80.60, Test_acc 38.08
2025-02-14 07:38:38,585 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.73, Spatial_loss 2.39, Flat_loss 0.25, Train_acc 80.60, Test_acc 38.48
2025-02-14 07:40:07,320 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.71, Spatial_loss 2.44, Flat_loss 0.26, Train_acc 81.42, Test_acc 34.12
2025-02-14 07:41:35,583 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.72, Spatial_loss 2.45, Flat_loss 0.25, Train_acc 81.19, Test_acc 36.20
2025-02-14 07:43:03,845 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.69, Spatial_loss 2.39, Flat_loss 0.25, Train_acc 81.81, Test_acc 36.24
2025-02-14 07:44:34,203 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.69, Spatial_loss 2.39, Flat_loss 0.25, Train_acc 82.24, Test_acc 34.28
2025-02-14 07:46:01,074 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.69, Spatial_loss 2.41, Flat_loss 0.25, Train_acc 82.12, Test_acc 35.60
2025-02-14 07:47:30,975 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.66, Spatial_loss 2.37, Flat_loss 0.25, Train_acc 82.81, Test_acc 39.64
2025-02-14 07:49:00,519 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.67, Spatial_loss 2.36, Flat_loss 0.25, Train_acc 82.47, Test_acc 38.88
2025-02-14 07:50:27,881 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.66, Spatial_loss 2.35, Flat_loss 0.25, Train_acc 83.06, Test_acc 38.60
2025-02-14 07:51:57,475 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.66, Spatial_loss 2.38, Flat_loss 0.25, Train_acc 82.77, Test_acc 34.60
2025-02-14 07:53:25,612 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.64, Spatial_loss 2.35, Flat_loss 0.25, Train_acc 83.77, Test_acc 40.68
2025-02-14 07:54:56,234 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.63, Spatial_loss 2.30, Flat_loss 0.25, Train_acc 83.71, Test_acc 35.48
2025-02-14 07:56:22,815 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.64, Spatial_loss 2.35, Flat_loss 0.25, Train_acc 83.65, Test_acc 41.68
2025-02-14 07:57:47,709 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.63, Spatial_loss 2.34, Flat_loss 0.25, Train_acc 83.28, Test_acc 37.04
2025-02-14 07:59:12,235 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.59, Spatial_loss 2.33, Flat_loss 0.24, Train_acc 84.70, Test_acc 38.36
2025-02-14 08:00:37,317 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.61, Spatial_loss 2.36, Flat_loss 0.25, Train_acc 84.42, Test_acc 36.36
2025-02-14 08:02:08,410 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.62, Spatial_loss 2.33, Flat_loss 0.25, Train_acc 84.25, Test_acc 31.12
2025-02-14 08:03:34,533 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.62, Spatial_loss 2.37, Flat_loss 0.25, Train_acc 83.95, Test_acc 41.20
2025-02-14 08:05:02,333 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.60, Spatial_loss 2.38, Flat_loss 0.25, Train_acc 84.55, Test_acc 34.28
2025-02-14 08:06:28,267 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.60, Spatial_loss 2.33, Flat_loss 0.25, Train_acc 84.68, Test_acc 36.56
2025-02-14 08:07:55,173 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.60, Spatial_loss 2.32, Flat_loss 0.25, Train_acc 84.65, Test_acc 38.56
2025-02-14 08:09:20,655 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.59, Spatial_loss 2.28, Flat_loss 0.25, Train_acc 84.70, Test_acc 35.40
2025-02-14 08:10:48,579 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.59, Spatial_loss 2.27, Flat_loss 0.25, Train_acc 84.87, Test_acc 41.08
2025-02-14 08:12:20,134 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.59, Spatial_loss 2.32, Flat_loss 0.25, Train_acc 85.36, Test_acc 36.72
2025-02-14 08:13:49,054 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.58, Spatial_loss 2.29, Flat_loss 0.25, Train_acc 85.15, Test_acc 38.12
2025-02-14 08:15:15,814 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.60, Spatial_loss 2.28, Flat_loss 0.25, Train_acc 84.93, Test_acc 37.24
2025-02-14 08:16:44,155 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.57, Spatial_loss 2.27, Flat_loss 0.24, Train_acc 85.54, Test_acc 36.56
2025-02-14 08:18:11,879 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.59, Spatial_loss 2.28, Flat_loss 0.24, Train_acc 84.89, Test_acc 40.72
2025-02-14 08:19:42,268 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.57, Spatial_loss 2.28, Flat_loss 0.24, Train_acc 85.74, Test_acc 36.48
2025-02-14 08:21:11,346 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.58, Spatial_loss 2.31, Flat_loss 0.25, Train_acc 85.31, Test_acc 39.84
2025-02-14 08:22:40,249 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.56, Spatial_loss 2.24, Flat_loss 0.24, Train_acc 85.58, Test_acc 36.04
2025-02-14 08:24:08,765 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.57, Spatial_loss 2.27, Flat_loss 0.24, Train_acc 85.66, Test_acc 41.64
2025-02-14 08:25:38,882 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.54, Spatial_loss 2.24, Flat_loss 0.24, Train_acc 86.11, Test_acc 39.88
2025-02-14 08:27:09,565 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.56, Spatial_loss 2.24, Flat_loss 0.24, Train_acc 85.30, Test_acc 36.36
2025-02-14 08:28:35,229 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.54, Spatial_loss 2.23, Flat_loss 0.24, Train_acc 86.32, Test_acc 36.56
2025-02-14 08:30:02,969 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.57, Spatial_loss 2.24, Flat_loss 0.25, Train_acc 85.64, Test_acc 37.52
2025-02-14 08:31:29,431 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.56, Spatial_loss 2.23, Flat_loss 0.24, Train_acc 86.12, Test_acc 40.24
2025-02-14 08:32:52,360 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.56, Spatial_loss 2.21, Flat_loss 0.24, Train_acc 86.42, Test_acc 36.32
2025-02-14 08:34:19,142 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.55, Spatial_loss 2.26, Flat_loss 0.24, Train_acc 86.17, Test_acc 38.04
2025-02-14 08:35:48,693 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.55, Spatial_loss 2.20, Flat_loss 0.24, Train_acc 86.42, Test_acc 38.64
2025-02-14 08:37:15,654 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.55, Spatial_loss 2.20, Flat_loss 0.24, Train_acc 86.17, Test_acc 42.12
2025-02-14 08:38:41,552 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.55, Spatial_loss 2.23, Flat_loss 0.25, Train_acc 86.31, Test_acc 41.36
2025-02-14 08:40:10,079 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.53, Spatial_loss 2.19, Flat_loss 0.24, Train_acc 86.58, Test_acc 38.00
2025-02-14 08:41:37,188 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.54, Spatial_loss 2.18, Flat_loss 0.24, Train_acc 86.26, Test_acc 34.56
2025-02-14 08:43:05,642 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.53, Spatial_loss 2.17, Flat_loss 0.24, Train_acc 86.77, Test_acc 38.24
2025-02-14 08:44:35,174 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.52, Spatial_loss 2.17, Flat_loss 0.24, Train_acc 86.96, Test_acc 40.88
2025-02-14 08:46:05,144 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.52, Spatial_loss 2.19, Flat_loss 0.24, Train_acc 86.67, Test_acc 40.56
2025-02-14 08:47:34,741 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.52, Spatial_loss 2.17, Flat_loss 0.24, Train_acc 87.12, Test_acc 40.24
2025-02-14 08:49:02,013 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.48, Spatial_loss 2.11, Flat_loss 0.23, Train_acc 88.04, Test_acc 38.32
2025-02-14 08:50:31,553 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.51, Spatial_loss 2.14, Flat_loss 0.23, Train_acc 86.96, Test_acc 40.24
2025-02-14 08:52:01,399 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.48, Spatial_loss 2.12, Flat_loss 0.23, Train_acc 88.20, Test_acc 40.28
2025-02-14 08:53:33,640 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.50, Spatial_loss 2.07, Flat_loss 0.23, Train_acc 87.66, Test_acc 41.80
2025-02-14 08:55:03,746 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.50, Spatial_loss 2.13, Flat_loss 0.24, Train_acc 87.45, Test_acc 39.96
2025-02-14 08:56:31,397 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.50, Spatial_loss 2.12, Flat_loss 0.23, Train_acc 87.47, Test_acc 38.28
2025-02-14 08:57:56,564 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.50, Spatial_loss 2.15, Flat_loss 0.24, Train_acc 87.27, Test_acc 41.36
2025-02-14 08:59:26,956 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.51, Spatial_loss 2.12, Flat_loss 0.23, Train_acc 87.24, Test_acc 41.32
2025-02-14 09:00:54,282 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.48, Spatial_loss 2.08, Flat_loss 0.23, Train_acc 87.77, Test_acc 40.08
2025-02-14 09:02:20,994 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.48, Spatial_loss 2.12, Flat_loss 0.23, Train_acc 88.12, Test_acc 40.64
2025-02-14 09:03:47,749 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.47, Spatial_loss 2.06, Flat_loss 0.23, Train_acc 88.39, Test_acc 38.64
2025-02-14 09:05:15,636 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.48, Spatial_loss 2.08, Flat_loss 0.23, Train_acc 88.13, Test_acc 40.36
2025-02-14 09:06:43,633 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.47, Spatial_loss 2.06, Flat_loss 0.23, Train_acc 88.31, Test_acc 42.96
2025-02-14 09:08:10,855 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.47, Spatial_loss 2.03, Flat_loss 0.23, Train_acc 88.44, Test_acc 39.00
2025-02-14 09:09:38,907 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.48, Spatial_loss 2.03, Flat_loss 0.23, Train_acc 88.34, Test_acc 44.84
2025-02-14 09:11:08,283 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.47, Spatial_loss 2.04, Flat_loss 0.23, Train_acc 88.43, Test_acc 42.68
2025-02-14 09:12:39,115 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.48, Spatial_loss 2.04, Flat_loss 0.23, Train_acc 88.39, Test_acc 39.00
2025-02-14 09:14:07,003 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.47, Spatial_loss 2.05, Flat_loss 0.23, Train_acc 88.55, Test_acc 38.68
2025-02-14 09:15:35,771 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.44, Spatial_loss 2.00, Flat_loss 0.22, Train_acc 89.11, Test_acc 43.40
2025-02-14 09:17:03,404 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.45, Spatial_loss 1.98, Flat_loss 0.22, Train_acc 89.00, Test_acc 38.04
2025-02-14 09:18:31,492 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.45, Spatial_loss 1.96, Flat_loss 0.22, Train_acc 89.27, Test_acc 39.60
2025-02-14 09:20:01,297 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.46, Spatial_loss 1.99, Flat_loss 0.22, Train_acc 88.95, Test_acc 40.84
2025-02-14 09:21:30,371 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.45, Spatial_loss 1.97, Flat_loss 0.22, Train_acc 89.14, Test_acc 40.28
2025-02-14 09:22:59,744 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.44, Spatial_loss 1.94, Flat_loss 0.22, Train_acc 89.49, Test_acc 42.24
2025-02-14 09:24:27,823 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.22, Train_acc 89.80, Test_acc 38.68
2025-02-14 09:26:00,011 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.45, Spatial_loss 1.94, Flat_loss 0.22, Train_acc 89.20, Test_acc 39.92
2025-02-14 09:27:28,202 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.43, Spatial_loss 1.89, Flat_loss 0.22, Train_acc 89.73, Test_acc 40.40
2025-02-14 09:28:57,244 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.43, Spatial_loss 1.92, Flat_loss 0.22, Train_acc 89.56, Test_acc 42.64
2025-02-14 09:30:27,764 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.41, Spatial_loss 1.88, Flat_loss 0.21, Train_acc 90.66, Test_acc 43.68
2025-02-14 09:31:58,808 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.42, Spatial_loss 1.88, Flat_loss 0.21, Train_acc 89.95, Test_acc 41.84
2025-02-14 09:33:30,519 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.41, Spatial_loss 1.88, Flat_loss 0.21, Train_acc 90.45, Test_acc 39.68
2025-02-14 09:35:02,266 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.40, Spatial_loss 1.85, Flat_loss 0.22, Train_acc 90.43, Test_acc 41.40
2025-02-14 09:36:30,682 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.40, Spatial_loss 1.87, Flat_loss 0.21, Train_acc 90.44, Test_acc 42.48
2025-02-14 09:38:00,245 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.41, Spatial_loss 1.88, Flat_loss 0.21, Train_acc 90.28, Test_acc 38.76
2025-02-14 09:39:30,309 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.40, Spatial_loss 1.83, Flat_loss 0.21, Train_acc 90.59, Test_acc 43.96
2025-02-14 09:40:59,948 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.40, Spatial_loss 1.83, Flat_loss 0.21, Train_acc 90.68, Test_acc 42.24
2025-02-14 09:42:20,860 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.39, Spatial_loss 1.82, Flat_loss 0.21, Train_acc 90.66, Test_acc 42.28
2025-02-14 09:43:46,425 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.39, Spatial_loss 1.80, Flat_loss 0.21, Train_acc 91.03, Test_acc 44.16
2025-02-14 09:45:13,356 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.21, Train_acc 90.76, Test_acc 40.16
2025-02-14 09:46:38,273 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.37, Spatial_loss 1.76, Flat_loss 0.20, Train_acc 91.54, Test_acc 40.12
2025-02-14 09:48:05,230 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.38, Spatial_loss 1.73, Flat_loss 0.20, Train_acc 91.42, Test_acc 42.64
2025-02-14 09:49:35,288 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.38, Spatial_loss 1.74, Flat_loss 0.21, Train_acc 91.35, Test_acc 42.16
2025-02-14 09:51:02,028 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.38, Spatial_loss 1.75, Flat_loss 0.20, Train_acc 91.19, Test_acc 42.60
2025-02-14 09:52:27,047 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.37, Spatial_loss 1.72, Flat_loss 0.20, Train_acc 91.75, Test_acc 43.64
2025-02-14 09:53:55,017 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.37, Spatial_loss 1.75, Flat_loss 0.20, Train_acc 91.68, Test_acc 43.68
2025-02-14 09:55:24,301 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.36, Spatial_loss 1.72, Flat_loss 0.20, Train_acc 91.78, Test_acc 43.60
2025-02-14 09:56:52,871 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.36, Spatial_loss 1.67, Flat_loss 0.20, Train_acc 91.72, Test_acc 41.40
2025-02-14 09:58:21,689 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.35, Spatial_loss 1.65, Flat_loss 0.19, Train_acc 91.96, Test_acc 43.68
2025-02-14 09:59:46,925 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.35, Spatial_loss 1.65, Flat_loss 0.20, Train_acc 92.08, Test_acc 43.08
2025-02-14 10:01:14,491 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.35, Spatial_loss 1.66, Flat_loss 0.19, Train_acc 92.05, Test_acc 44.32
2025-02-14 10:02:47,135 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.33, Spatial_loss 1.60, Flat_loss 0.19, Train_acc 92.47, Test_acc 43.20
2025-02-14 10:04:17,746 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.35, Spatial_loss 1.65, Flat_loss 0.19, Train_acc 92.16, Test_acc 45.56
2025-02-14 10:05:39,494 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.34, Spatial_loss 1.61, Flat_loss 0.19, Train_acc 92.47, Test_acc 44.44
2025-02-14 10:07:06,728 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.33, Spatial_loss 1.60, Flat_loss 0.19, Train_acc 92.72, Test_acc 42.92
2025-02-14 10:08:32,881 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.34, Spatial_loss 1.58, Flat_loss 0.19, Train_acc 92.66, Test_acc 45.72
2025-02-14 10:09:58,819 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.31, Spatial_loss 1.56, Flat_loss 0.19, Train_acc 93.43, Test_acc 43.16
2025-02-14 10:11:24,918 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.33, Spatial_loss 1.56, Flat_loss 0.19, Train_acc 92.75, Test_acc 41.36
2025-02-14 10:12:53,774 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.32, Spatial_loss 1.54, Flat_loss 0.19, Train_acc 93.21, Test_acc 41.60
2025-02-14 10:14:24,330 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.29, Spatial_loss 1.50, Flat_loss 0.18, Train_acc 93.85, Test_acc 42.20
2025-02-14 10:15:50,182 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.30, Spatial_loss 1.51, Flat_loss 0.18, Train_acc 93.74, Test_acc 43.16
2025-02-14 10:17:14,771 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.31, Spatial_loss 1.51, Flat_loss 0.18, Train_acc 93.38, Test_acc 42.96
2025-02-14 10:18:41,327 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.30, Spatial_loss 1.49, Flat_loss 0.18, Train_acc 93.29, Test_acc 45.92
2025-02-14 10:20:02,167 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.18, Train_acc 93.81, Test_acc 46.08
2025-02-14 10:21:21,179 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.18, Train_acc 93.74, Test_acc 45.76
2025-02-14 10:22:42,018 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.28, Spatial_loss 1.42, Flat_loss 0.18, Train_acc 94.10, Test_acc 44.92
2025-02-14 10:23:59,284 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.17, Train_acc 93.99, Test_acc 46.60
2025-02-14 10:25:22,368 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.17, Train_acc 94.08, Test_acc 45.96
2025-02-14 10:26:39,839 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.28, Spatial_loss 1.40, Flat_loss 0.17, Train_acc 94.18, Test_acc 46.80
2025-02-14 10:28:02,942 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.27, Spatial_loss 1.38, Flat_loss 0.17, Train_acc 94.33, Test_acc 43.56
2025-02-14 10:29:22,358 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.28, Spatial_loss 1.37, Flat_loss 0.17, Train_acc 94.50, Test_acc 47.12
2025-02-14 10:30:37,975 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.17, Train_acc 94.90, Test_acc 46.44
2025-02-14 10:31:55,461 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.17, Train_acc 94.80, Test_acc 45.20
2025-02-14 10:33:14,763 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.17, Train_acc 94.69, Test_acc 45.00
2025-02-14 10:34:33,039 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.17, Train_acc 94.80, Test_acc 45.76
2025-02-14 10:35:50,836 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.25, Spatial_loss 1.29, Flat_loss 0.17, Train_acc 95.17, Test_acc 45.84
2025-02-14 10:37:09,898 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.16, Train_acc 95.00, Test_acc 46.28
2025-02-14 10:38:30,616 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.16, Train_acc 94.97, Test_acc 46.16
2025-02-14 10:39:48,640 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.24, Spatial_loss 1.28, Flat_loss 0.16, Train_acc 95.23, Test_acc 45.60
2025-02-14 10:41:08,192 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.16, Train_acc 95.36, Test_acc 45.80
2025-02-14 10:42:25,537 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.16, Train_acc 95.44, Test_acc 46.24
2025-02-14 10:43:49,317 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 95.42, Test_acc 47.32
2025-02-14 10:45:10,749 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.25, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 95.19, Test_acc 46.12
2025-02-14 10:46:32,590 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 95.47, Test_acc 46.84
2025-02-14 10:47:55,814 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.16, Train_acc 95.65, Test_acc 45.52
2025-02-14 10:49:17,765 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.16, Train_acc 95.72, Test_acc 47.00
2025-02-14 10:50:44,342 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 95.70, Test_acc 45.80
2025-02-14 10:52:17,410 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.16, Train_acc 95.71, Test_acc 47.32
2025-02-14 10:53:47,310 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.16, Train_acc 95.77, Test_acc 47.68
2025-02-14 10:55:19,061 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.16, Train_acc 95.70, Test_acc 47.16
2025-02-14 10:56:55,745 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.15, Train_acc 95.93, Test_acc 46.60
2025-02-14 10:58:25,819 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.15, Train_acc 95.49, Test_acc 46.44
2025-02-14 10:59:58,088 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.16, Train_acc 95.83, Test_acc 46.32
2025-02-14 11:01:28,622 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.15, Train_acc 95.92, Test_acc 46.52
2025-02-14 11:03:00,913 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 96.02, Test_acc 46.56
2025-02-14 11:04:32,476 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.15, Train_acc 95.92, Test_acc 46.76
2025-02-14 11:06:03,004 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.15, Train_acc 96.19, Test_acc 47.52
2025-02-14 11:07:34,568 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.15, Train_acc 96.03, Test_acc 47.24
2025-02-14 11:09:11,849 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.15, Train_acc 96.07, Test_acc 47.68
2025-02-14 11:10:45,562 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.15, Train_acc 96.10, Test_acc 47.00
2025-02-14 11:12:16,380 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.15, Train_acc 96.00, Test_acc 47.40
2025-02-14 11:13:44,758 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.15, Train_acc 96.08, Test_acc 47.44
2025-02-14 11:15:16,030 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.15, Train_acc 96.10, Test_acc 47.24
2025-02-14 11:16:48,766 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.15, Train_acc 96.28, Test_acc 47.28
2025-02-14 11:16:48,767 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 11:16:48,767 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 11:18:49,861 [podnet.py] => The size of finetune dataset: 1000
2025-02-14 11:19:13,824 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.53, Spatial_loss 1.31, Flat_loss 0.13, Train_acc 87.70, Test_acc 50.80
2025-02-14 11:19:34,834 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.32, Spatial_loss 1.25, Flat_loss 0.12, Train_acc 93.80, Test_acc 55.44
2025-02-14 11:19:55,245 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.29, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 94.40, Test_acc 57.56
2025-02-14 11:20:16,093 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 94.80, Test_acc 57.24
2025-02-14 11:20:37,684 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.28, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 94.80, Test_acc 57.40
2025-02-14 11:20:58,796 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.11, Train_acc 94.70, Test_acc 57.32
2025-02-14 11:21:19,786 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.10, Train_acc 95.40, Test_acc 56.80
2025-02-14 11:21:41,016 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.25, Spatial_loss 1.13, Flat_loss 0.10, Train_acc 94.80, Test_acc 57.40
2025-02-14 11:22:03,448 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.18, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 96.50, Test_acc 57.40
2025-02-14 11:22:24,773 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 95.00, Test_acc 57.28
2025-02-14 11:22:46,355 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 95.50, Test_acc 57.76
2025-02-14 11:23:08,176 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 96.70, Test_acc 57.56
2025-02-14 11:23:27,645 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.25, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 94.40, Test_acc 57.52
2025-02-14 11:23:49,670 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.10, Train_acc 96.20, Test_acc 57.32
2025-02-14 11:24:10,369 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 96.00, Test_acc 57.36
2025-02-14 11:24:32,356 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 95.70, Test_acc 57.60
2025-02-14 11:24:54,279 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 95.60, Test_acc 57.32
2025-02-14 11:25:16,365 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.23, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 95.80, Test_acc 57.36
2025-02-14 11:25:34,139 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 95.50, Test_acc 57.52
2025-02-14 11:25:55,658 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.23, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 95.30, Test_acc 57.28
2025-02-14 11:25:55,660 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 11:28:25,737 [podnet.py] => Exemplar size: 1000
2025-02-14 11:28:25,738 [trainer.py] => CNN: {'total': 57.28, '00-09': 63.2, '10-19': 37.0, '20-29': 47.4, '30-39': 58.0, '40-49': 80.8, 'old': 51.4, 'new': 80.8}
2025-02-14 11:28:25,738 [trainer.py] => NME: {'total': 52.6, '00-09': 67.2, '10-19': 28.0, '20-29': 41.0, '30-39': 50.2, '40-49': 76.6, 'old': 46.6, 'new': 76.6}
2025-02-14 11:28:25,739 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28]
2025-02-14 11:28:25,739 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4]
2025-02-14 11:28:25,739 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6]
2025-02-14 11:28:25,740 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6]

2025-02-14 11:28:25,740 [trainer.py] => Average Accuracy (CNN): 71.63600000000001
2025-02-14 11:28:25,740 [trainer.py] => Average Accuracy (NME): 68.874
2025-02-14 11:28:25,741 [trainer.py] => All params: 11945513
2025-02-14 11:28:25,742 [trainer.py] => Trainable params: 11945513
2025-02-14 11:28:25,750 [podnet.py] => Learning on 50-60
2025-02-14 11:28:25,757 [podnet.py] => Adaptive factor: 2.449489742783178
2025-02-14 11:30:21,609 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 1.60, Spatial_loss 3.71, Flat_loss 0.86, Train_acc 63.30, Test_acc 28.17
2025-02-14 11:32:17,576 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 1.00, Spatial_loss 3.00, Flat_loss 0.43, Train_acc 73.35, Test_acc 29.00
2025-02-14 11:34:18,629 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 0.91, Spatial_loss 2.82, Flat_loss 0.35, Train_acc 75.49, Test_acc 30.87
2025-02-14 11:36:17,893 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 0.87, Spatial_loss 2.75, Flat_loss 0.32, Train_acc 76.90, Test_acc 32.60
2025-02-14 11:38:17,236 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 0.82, Spatial_loss 2.68, Flat_loss 0.30, Train_acc 78.42, Test_acc 33.83
2025-02-14 11:40:17,941 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 0.81, Spatial_loss 2.67, Flat_loss 0.30, Train_acc 78.66, Test_acc 33.23
2025-02-14 11:42:15,449 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 0.78, Spatial_loss 2.63, Flat_loss 0.29, Train_acc 79.70, Test_acc 32.67
2025-02-14 11:44:16,286 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 0.76, Spatial_loss 2.62, Flat_loss 0.28, Train_acc 79.99, Test_acc 32.43
2025-02-14 11:46:12,490 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 0.74, Spatial_loss 2.55, Flat_loss 0.28, Train_acc 80.65, Test_acc 32.00
2025-02-14 11:48:08,783 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 0.72, Spatial_loss 2.55, Flat_loss 0.28, Train_acc 81.29, Test_acc 35.20
2025-02-14 11:50:09,059 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 0.71, Spatial_loss 2.48, Flat_loss 0.27, Train_acc 81.49, Test_acc 34.40
2025-02-14 11:52:08,459 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.71, Spatial_loss 2.53, Flat_loss 0.28, Train_acc 80.94, Test_acc 32.97
2025-02-14 11:54:06,354 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.70, Spatial_loss 2.50, Flat_loss 0.27, Train_acc 81.85, Test_acc 32.50
2025-02-14 11:56:02,075 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.66, Spatial_loss 2.46, Flat_loss 0.27, Train_acc 82.91, Test_acc 31.47
2025-02-14 11:58:02,432 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.68, Spatial_loss 2.51, Flat_loss 0.27, Train_acc 82.53, Test_acc 35.50
2025-02-14 12:00:01,464 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.66, Spatial_loss 2.45, Flat_loss 0.27, Train_acc 82.74, Test_acc 31.60
2025-02-14 12:02:03,009 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.65, Spatial_loss 2.46, Flat_loss 0.27, Train_acc 83.46, Test_acc 34.43
2025-02-14 12:03:59,720 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.64, Spatial_loss 2.43, Flat_loss 0.27, Train_acc 83.38, Test_acc 37.40
2025-02-14 12:05:56,273 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.65, Spatial_loss 2.46, Flat_loss 0.27, Train_acc 83.30, Test_acc 32.93
2025-02-14 12:07:53,890 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.63, Spatial_loss 2.46, Flat_loss 0.27, Train_acc 83.48, Test_acc 39.10
2025-02-14 12:09:52,468 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.61, Spatial_loss 2.44, Flat_loss 0.27, Train_acc 84.26, Test_acc 36.43
2025-02-14 12:11:51,116 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.64, Spatial_loss 2.46, Flat_loss 0.27, Train_acc 83.37, Test_acc 37.70
2025-02-14 12:13:48,632 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.63, Spatial_loss 2.43, Flat_loss 0.27, Train_acc 83.59, Test_acc 34.63
2025-02-14 12:15:49,198 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.63, Spatial_loss 2.45, Flat_loss 0.27, Train_acc 83.54, Test_acc 37.60
2025-02-14 12:17:44,705 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.61, Spatial_loss 2.35, Flat_loss 0.27, Train_acc 84.09, Test_acc 36.67
2025-02-14 12:19:45,381 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.61, Spatial_loss 2.40, Flat_loss 0.27, Train_acc 84.44, Test_acc 36.90
2025-02-14 12:21:46,729 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.59, Spatial_loss 2.39, Flat_loss 0.27, Train_acc 84.57, Test_acc 30.40
2025-02-14 12:23:48,230 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.61, Spatial_loss 2.39, Flat_loss 0.26, Train_acc 84.48, Test_acc 41.53
2025-02-14 12:25:48,823 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.61, Spatial_loss 2.42, Flat_loss 0.27, Train_acc 83.99, Test_acc 34.90
2025-02-14 12:27:45,562 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.59, Spatial_loss 2.36, Flat_loss 0.26, Train_acc 85.16, Test_acc 37.43
2025-02-14 12:29:44,750 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.60, Spatial_loss 2.42, Flat_loss 0.27, Train_acc 84.81, Test_acc 36.07
2025-02-14 12:31:46,069 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.60, Spatial_loss 2.42, Flat_loss 0.27, Train_acc 84.41, Test_acc 38.97
2025-02-14 12:33:48,836 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.58, Spatial_loss 2.41, Flat_loss 0.27, Train_acc 84.71, Test_acc 35.13
2025-02-14 12:35:47,194 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.60, Spatial_loss 2.44, Flat_loss 0.27, Train_acc 84.49, Test_acc 37.63
2025-02-14 12:37:45,948 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.57, Spatial_loss 2.41, Flat_loss 0.27, Train_acc 85.65, Test_acc 35.60
2025-02-14 12:39:45,069 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.60, Spatial_loss 2.37, Flat_loss 0.27, Train_acc 84.58, Test_acc 35.00
2025-02-14 12:41:45,999 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.57, Spatial_loss 2.41, Flat_loss 0.27, Train_acc 85.39, Test_acc 32.57
2025-02-14 12:43:43,316 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.57, Spatial_loss 2.34, Flat_loss 0.26, Train_acc 85.77, Test_acc 35.23
2025-02-14 12:45:34,076 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.59, Spatial_loss 2.34, Flat_loss 0.26, Train_acc 85.00, Test_acc 36.20
2025-02-14 12:47:25,323 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.57, Spatial_loss 2.36, Flat_loss 0.26, Train_acc 85.23, Test_acc 38.07
2025-02-14 12:49:20,932 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.55, Spatial_loss 2.37, Flat_loss 0.27, Train_acc 85.87, Test_acc 36.10
2025-02-14 12:51:14,104 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.56, Spatial_loss 2.37, Flat_loss 0.27, Train_acc 85.77, Test_acc 32.27
2025-02-14 12:53:13,183 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.56, Spatial_loss 2.33, Flat_loss 0.26, Train_acc 85.94, Test_acc 34.67
2025-02-14 12:55:07,312 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.54, Spatial_loss 2.30, Flat_loss 0.26, Train_acc 86.02, Test_acc 37.57
2025-02-14 12:56:59,650 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.57, Spatial_loss 2.37, Flat_loss 0.26, Train_acc 85.51, Test_acc 35.60
2025-02-14 12:58:53,210 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.56, Spatial_loss 2.35, Flat_loss 0.26, Train_acc 85.60, Test_acc 38.87
2025-02-14 13:00:49,972 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.56, Spatial_loss 2.33, Flat_loss 0.26, Train_acc 85.79, Test_acc 37.43
2025-02-14 13:02:47,878 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.53, Spatial_loss 2.27, Flat_loss 0.25, Train_acc 86.57, Test_acc 38.40
2025-02-14 13:04:41,662 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.52, Spatial_loss 2.21, Flat_loss 0.25, Train_acc 86.76, Test_acc 37.50
2025-02-14 13:06:34,471 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.54, Spatial_loss 2.28, Flat_loss 0.26, Train_acc 86.44, Test_acc 37.10
2025-02-14 13:08:28,508 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.53, Spatial_loss 2.31, Flat_loss 0.26, Train_acc 86.39, Test_acc 35.93
2025-02-14 13:10:25,199 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.52, Spatial_loss 2.20, Flat_loss 0.25, Train_acc 86.66, Test_acc 40.40
2025-02-14 13:12:21,104 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.53, Spatial_loss 2.25, Flat_loss 0.26, Train_acc 86.64, Test_acc 37.83
2025-02-14 13:14:16,117 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.53, Spatial_loss 2.29, Flat_loss 0.26, Train_acc 86.39, Test_acc 39.33
2025-02-14 13:16:14,802 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.54, Spatial_loss 2.29, Flat_loss 0.26, Train_acc 86.34, Test_acc 36.67
2025-02-14 13:18:13,022 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.53, Spatial_loss 2.28, Flat_loss 0.26, Train_acc 86.74, Test_acc 39.70
2025-02-14 13:20:06,373 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.52, Spatial_loss 2.23, Flat_loss 0.26, Train_acc 87.13, Test_acc 36.80
2025-02-14 13:22:01,082 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.53, Spatial_loss 2.27, Flat_loss 0.26, Train_acc 86.51, Test_acc 35.27
2025-02-14 13:23:58,604 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.50, Spatial_loss 2.18, Flat_loss 0.25, Train_acc 87.94, Test_acc 37.43
2025-02-14 13:25:54,151 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.50, Spatial_loss 2.21, Flat_loss 0.25, Train_acc 87.39, Test_acc 38.43
2025-02-14 13:27:51,396 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.52, Spatial_loss 2.23, Flat_loss 0.25, Train_acc 87.21, Test_acc 35.20
2025-02-14 13:29:43,502 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.50, Spatial_loss 2.21, Flat_loss 0.25, Train_acc 87.69, Test_acc 38.73
2025-02-14 13:31:37,534 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.51, Spatial_loss 2.19, Flat_loss 0.25, Train_acc 87.37, Test_acc 38.83
2025-02-14 13:33:35,639 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.48, Spatial_loss 2.12, Flat_loss 0.25, Train_acc 88.06, Test_acc 32.90
2025-02-14 13:35:27,348 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.49, Spatial_loss 2.19, Flat_loss 0.25, Train_acc 87.80, Test_acc 36.60
2025-02-14 13:37:26,421 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.50, Spatial_loss 2.14, Flat_loss 0.25, Train_acc 87.63, Test_acc 37.90
2025-02-14 13:39:21,409 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.49, Spatial_loss 2.12, Flat_loss 0.25, Train_acc 87.76, Test_acc 41.20
2025-02-14 13:41:12,669 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.49, Spatial_loss 2.11, Flat_loss 0.25, Train_acc 88.23, Test_acc 37.90
2025-02-14 13:43:08,125 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.48, Spatial_loss 2.13, Flat_loss 0.25, Train_acc 88.53, Test_acc 37.10
2025-02-14 13:45:01,200 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.48, Spatial_loss 2.14, Flat_loss 0.24, Train_acc 88.34, Test_acc 38.87
2025-02-14 13:46:54,777 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.48, Spatial_loss 2.15, Flat_loss 0.25, Train_acc 88.05, Test_acc 37.23
2025-02-14 13:48:48,589 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.48, Spatial_loss 2.14, Flat_loss 0.25, Train_acc 87.75, Test_acc 40.80
2025-02-14 13:50:41,772 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.46, Spatial_loss 2.10, Flat_loss 0.24, Train_acc 88.71, Test_acc 36.77
2025-02-14 13:52:32,899 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.46, Spatial_loss 2.06, Flat_loss 0.24, Train_acc 88.21, Test_acc 39.57
2025-02-14 13:54:26,209 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.47, Spatial_loss 2.08, Flat_loss 0.24, Train_acc 88.60, Test_acc 39.30
2025-02-14 13:56:21,380 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.47, Spatial_loss 2.08, Flat_loss 0.24, Train_acc 88.71, Test_acc 35.63
2025-02-14 13:58:14,756 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.46, Spatial_loss 2.09, Flat_loss 0.24, Train_acc 89.04, Test_acc 37.03
2025-02-14 14:00:07,603 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.47, Spatial_loss 2.00, Flat_loss 0.23, Train_acc 88.78, Test_acc 35.83
2025-02-14 14:02:02,964 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.46, Spatial_loss 2.03, Flat_loss 0.24, Train_acc 89.01, Test_acc 38.73
2025-02-14 14:03:58,971 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.46, Spatial_loss 2.04, Flat_loss 0.24, Train_acc 88.92, Test_acc 37.67
2025-02-14 14:05:53,670 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.45, Spatial_loss 2.03, Flat_loss 0.24, Train_acc 89.07, Test_acc 38.97
2025-02-14 14:07:48,803 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.44, Spatial_loss 1.99, Flat_loss 0.23, Train_acc 89.34, Test_acc 38.07
2025-02-14 14:09:40,938 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.44, Spatial_loss 2.02, Flat_loss 0.24, Train_acc 89.66, Test_acc 37.67
2025-02-14 14:11:36,955 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.45, Spatial_loss 2.01, Flat_loss 0.23, Train_acc 89.19, Test_acc 36.40
2025-02-14 14:13:27,777 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.42, Spatial_loss 1.99, Flat_loss 0.23, Train_acc 89.67, Test_acc 43.63
2025-02-14 14:15:23,694 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.23, Train_acc 89.91, Test_acc 37.80
2025-02-14 14:17:17,683 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.23, Train_acc 89.76, Test_acc 40.33
2025-02-14 14:19:14,228 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.42, Spatial_loss 1.97, Flat_loss 0.23, Train_acc 89.82, Test_acc 37.90
2025-02-14 14:21:07,736 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.42, Spatial_loss 1.95, Flat_loss 0.23, Train_acc 90.04, Test_acc 41.83
2025-02-14 14:22:59,372 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.42, Spatial_loss 1.93, Flat_loss 0.23, Train_acc 89.73, Test_acc 36.07
2025-02-14 14:24:53,757 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.42, Spatial_loss 1.92, Flat_loss 0.23, Train_acc 89.86, Test_acc 40.00
2025-02-14 14:26:50,680 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.40, Spatial_loss 1.88, Flat_loss 0.23, Train_acc 90.26, Test_acc 39.60
2025-02-14 14:28:47,434 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.39, Spatial_loss 1.87, Flat_loss 0.22, Train_acc 90.92, Test_acc 38.80
2025-02-14 14:30:45,364 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.39, Spatial_loss 1.86, Flat_loss 0.22, Train_acc 90.99, Test_acc 38.83
2025-02-14 14:32:43,703 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.41, Spatial_loss 1.85, Flat_loss 0.22, Train_acc 90.11, Test_acc 40.47
2025-02-14 14:34:42,332 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.40, Spatial_loss 1.85, Flat_loss 0.22, Train_acc 90.60, Test_acc 36.53
2025-02-14 14:36:37,322 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.38, Spatial_loss 1.87, Flat_loss 0.22, Train_acc 90.78, Test_acc 39.67
2025-02-14 14:38:30,448 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.39, Spatial_loss 1.80, Flat_loss 0.22, Train_acc 90.94, Test_acc 38.50
2025-02-14 14:40:26,420 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.38, Spatial_loss 1.80, Flat_loss 0.22, Train_acc 90.67, Test_acc 41.53
2025-02-14 14:42:20,285 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.38, Spatial_loss 1.80, Flat_loss 0.22, Train_acc 91.21, Test_acc 37.33
2025-02-14 14:44:19,072 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.38, Spatial_loss 1.77, Flat_loss 0.21, Train_acc 91.18, Test_acc 38.23
2025-02-14 14:46:16,269 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.38, Spatial_loss 1.75, Flat_loss 0.21, Train_acc 91.34, Test_acc 38.77
2025-02-14 14:48:17,589 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.37, Spatial_loss 1.77, Flat_loss 0.21, Train_acc 91.54, Test_acc 38.47
2025-02-14 14:50:11,858 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.37, Spatial_loss 1.73, Flat_loss 0.21, Train_acc 91.43, Test_acc 41.87
2025-02-14 14:52:11,472 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.37, Spatial_loss 1.72, Flat_loss 0.21, Train_acc 91.66, Test_acc 40.17
2025-02-14 14:54:06,374 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.35, Spatial_loss 1.75, Flat_loss 0.21, Train_acc 92.11, Test_acc 39.70
2025-02-14 14:56:04,979 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.35, Spatial_loss 1.73, Flat_loss 0.21, Train_acc 92.26, Test_acc 39.97
2025-02-14 14:58:00,307 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.36, Spatial_loss 1.70, Flat_loss 0.21, Train_acc 91.74, Test_acc 42.23
2025-02-14 14:59:56,217 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.35, Spatial_loss 1.65, Flat_loss 0.21, Train_acc 92.49, Test_acc 41.73
2025-02-14 15:01:56,414 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.33, Spatial_loss 1.64, Flat_loss 0.20, Train_acc 92.91, Test_acc 41.90
2025-02-14 15:03:51,067 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.34, Spatial_loss 1.61, Flat_loss 0.20, Train_acc 92.61, Test_acc 39.80
2025-02-14 15:05:48,085 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.33, Spatial_loss 1.61, Flat_loss 0.20, Train_acc 92.48, Test_acc 42.07
2025-02-14 15:07:41,530 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.32, Spatial_loss 1.61, Flat_loss 0.20, Train_acc 92.97, Test_acc 39.90
2025-02-14 15:09:40,079 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.34, Spatial_loss 1.60, Flat_loss 0.20, Train_acc 92.30, Test_acc 41.57
2025-02-14 15:11:35,156 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.33, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 92.77, Test_acc 41.93
2025-02-14 15:13:34,041 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.32, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 93.02, Test_acc 38.50
2025-02-14 15:15:32,547 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.33, Spatial_loss 1.58, Flat_loss 0.20, Train_acc 92.61, Test_acc 38.33
2025-02-14 15:17:28,787 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.32, Spatial_loss 1.56, Flat_loss 0.20, Train_acc 93.02, Test_acc 39.30
2025-02-14 15:19:24,390 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.32, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 93.06, Test_acc 41.60
2025-02-14 15:21:19,843 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.30, Spatial_loss 1.52, Flat_loss 0.19, Train_acc 93.40, Test_acc 42.43
2025-02-14 15:23:15,554 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.31, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 93.24, Test_acc 43.20
2025-02-14 15:25:11,530 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.29, Spatial_loss 1.48, Flat_loss 0.19, Train_acc 93.91, Test_acc 41.90
2025-02-14 15:27:07,773 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.29, Spatial_loss 1.47, Flat_loss 0.19, Train_acc 93.86, Test_acc 43.53
2025-02-14 15:29:06,828 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.19, Train_acc 93.75, Test_acc 41.67
2025-02-14 15:31:01,798 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.29, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 94.14, Test_acc 41.30
2025-02-14 15:32:55,336 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.29, Spatial_loss 1.48, Flat_loss 0.19, Train_acc 93.90, Test_acc 42.67
2025-02-14 15:34:51,129 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.29, Spatial_loss 1.41, Flat_loss 0.19, Train_acc 94.01, Test_acc 43.87
2025-02-14 15:36:46,355 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.18, Train_acc 94.29, Test_acc 42.33
2025-02-14 15:38:38,999 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.28, Spatial_loss 1.40, Flat_loss 0.18, Train_acc 94.21, Test_acc 42.83
2025-02-14 15:40:38,051 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.27, Spatial_loss 1.40, Flat_loss 0.18, Train_acc 94.64, Test_acc 42.33
2025-02-14 15:42:35,223 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.27, Spatial_loss 1.36, Flat_loss 0.18, Train_acc 94.54, Test_acc 41.87
2025-02-14 15:44:31,971 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.18, Train_acc 94.71, Test_acc 42.83
2025-02-14 15:46:27,040 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 94.74, Test_acc 40.97
2025-02-14 15:48:21,206 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.25, Spatial_loss 1.31, Flat_loss 0.18, Train_acc 94.94, Test_acc 42.70
2025-02-14 15:50:15,464 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.18, Train_acc 94.49, Test_acc 43.33
2025-02-14 15:52:13,077 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.18, Train_acc 94.59, Test_acc 43.93
2025-02-14 15:54:11,585 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.25, Spatial_loss 1.31, Flat_loss 0.18, Train_acc 95.16, Test_acc 43.33
2025-02-14 15:56:06,749 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 94.92, Test_acc 44.03
2025-02-14 15:58:03,903 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 95.26, Test_acc 43.03
2025-02-14 16:00:04,209 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.17, Train_acc 95.33, Test_acc 43.77
2025-02-14 16:01:59,243 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.17, Train_acc 95.50, Test_acc 44.57
2025-02-14 16:03:54,512 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.17, Train_acc 95.09, Test_acc 44.30
2025-02-14 16:05:51,095 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.25, Spatial_loss 1.23, Flat_loss 0.17, Train_acc 95.06, Test_acc 44.50
2025-02-14 16:07:44,953 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 95.57, Test_acc 44.23
2025-02-14 16:09:39,287 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.17, Train_acc 95.66, Test_acc 45.40
2025-02-14 16:11:30,323 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 95.49, Test_acc 43.90
2025-02-14 16:13:26,660 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 95.54, Test_acc 44.00
2025-02-14 16:15:19,724 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.17, Train_acc 95.79, Test_acc 44.90
2025-02-14 16:17:15,935 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 95.67, Test_acc 44.90
2025-02-14 16:19:13,195 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 95.54, Test_acc 44.20
2025-02-14 16:21:07,392 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 95.81, Test_acc 44.50
2025-02-14 16:23:07,062 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 95.64, Test_acc 44.77
2025-02-14 16:25:05,635 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.17, Train_acc 95.95, Test_acc 44.43
2025-02-14 16:27:03,102 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.17, Train_acc 95.59, Test_acc 44.33
2025-02-14 16:28:57,006 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.17, Train_acc 96.06, Test_acc 44.30
2025-02-14 16:30:53,793 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.16, Train_acc 95.68, Test_acc 44.10
2025-02-14 16:32:49,792 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.16, Train_acc 95.74, Test_acc 44.63
2025-02-14 16:34:45,241 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.16, Train_acc 95.90, Test_acc 44.13
2025-02-14 16:36:39,892 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.23, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 95.96, Test_acc 44.63
2025-02-14 16:38:36,936 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 95.71, Test_acc 44.73
2025-02-14 16:38:36,937 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 16:38:36,937 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 16:41:03,624 [podnet.py] => The size of finetune dataset: 1200
2025-02-14 16:41:34,760 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.51, Spatial_loss 1.70, Flat_loss 0.18, Train_acc 88.33, Test_acc 49.37
2025-02-14 16:42:01,999 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.31, Spatial_loss 1.45, Flat_loss 0.13, Train_acc 94.00, Test_acc 53.80
2025-02-14 16:42:31,696 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.12, Train_acc 94.33, Test_acc 53.93
2025-02-14 16:43:02,449 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.32, Spatial_loss 1.36, Flat_loss 0.12, Train_acc 93.08, Test_acc 53.90
2025-02-14 16:43:34,914 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.23, Spatial_loss 1.34, Flat_loss 0.12, Train_acc 95.67, Test_acc 52.90
2025-02-14 16:44:01,525 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.32, Spatial_loss 1.34, Flat_loss 0.12, Train_acc 93.17, Test_acc 52.93
2025-02-14 16:44:31,076 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.12, Train_acc 95.75, Test_acc 53.53
2025-02-14 16:45:02,348 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.25, Spatial_loss 1.30, Flat_loss 0.11, Train_acc 94.67, Test_acc 53.77
2025-02-14 16:45:31,968 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 94.67, Test_acc 54.00
2025-02-14 16:45:59,268 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.25, Spatial_loss 1.30, Flat_loss 0.11, Train_acc 95.33, Test_acc 53.93
2025-02-14 16:46:30,455 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.21, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 95.67, Test_acc 54.63
2025-02-14 16:46:59,143 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.22, Spatial_loss 1.30, Flat_loss 0.11, Train_acc 95.67, Test_acc 54.27
2025-02-14 16:47:24,013 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.11, Train_acc 95.33, Test_acc 54.00
2025-02-14 16:47:53,474 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 95.67, Test_acc 53.83
2025-02-14 16:48:23,046 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.11, Train_acc 95.42, Test_acc 54.47
2025-02-14 16:48:51,339 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.26, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 94.33, Test_acc 54.17
2025-02-14 16:49:20,584 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 95.33, Test_acc 54.43
2025-02-14 16:49:50,859 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.20, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 96.50, Test_acc 54.43
2025-02-14 16:50:20,788 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 95.75, Test_acc 54.20
2025-02-14 16:50:50,396 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.10, Train_acc 95.25, Test_acc 54.43
2025-02-14 16:50:50,400 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 16:53:57,171 [podnet.py] => Exemplar size: 1200
2025-02-14 16:53:57,171 [trainer.py] => CNN: {'total': 54.43, '00-09': 60.4, '10-19': 37.2, '20-29': 40.6, '30-39': 51.2, '40-49': 53.0, '50-59': 84.2, 'old': 48.48, 'new': 84.2}
2025-02-14 16:53:57,172 [trainer.py] => NME: {'total': 49.87, '00-09': 68.4, '10-19': 28.0, '20-29': 35.8, '30-39': 41.6, '40-49': 47.6, '50-59': 77.8, 'old': 44.28, 'new': 77.8}
2025-02-14 16:53:57,172 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28, 54.43]
2025-02-14 16:53:57,172 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4, 78.4]
2025-02-14 16:53:57,172 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6, 49.87]
2025-02-14 16:53:57,173 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6, 75.07]

2025-02-14 16:53:57,173 [trainer.py] => Average Accuracy (CNN): 68.76833333333335
2025-02-14 16:53:57,173 [trainer.py] => Average Accuracy (NME): 65.70666666666666
2025-02-14 16:53:57,174 [trainer.py] => All params: 11996713
2025-02-14 16:53:57,174 [trainer.py] => Trainable params: 11996713
2025-02-14 16:53:57,178 [podnet.py] => Learning on 60-70
2025-02-14 16:53:57,184 [podnet.py] => Adaptive factor: 2.6457513110645907
2025-02-14 16:55:59,134 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 1.61, Spatial_loss 3.76, Flat_loss 0.92, Train_acc 64.30, Test_acc 20.97
2025-02-14 16:58:03,356 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 1.02, Spatial_loss 3.15, Flat_loss 0.48, Train_acc 73.42, Test_acc 29.77
2025-02-14 17:00:08,780 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 0.94, Spatial_loss 2.99, Flat_loss 0.40, Train_acc 75.48, Test_acc 28.86
2025-02-14 17:02:12,714 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 0.89, Spatial_loss 2.86, Flat_loss 0.36, Train_acc 77.42, Test_acc 31.83
2025-02-14 17:04:19,175 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 0.85, Spatial_loss 2.77, Flat_loss 0.35, Train_acc 78.42, Test_acc 32.74
2025-02-14 17:06:19,298 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 0.82, Spatial_loss 2.74, Flat_loss 0.34, Train_acc 79.13, Test_acc 27.46
2025-02-14 17:08:25,550 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 0.81, Spatial_loss 2.68, Flat_loss 0.33, Train_acc 79.85, Test_acc 31.51
2025-02-14 17:10:33,221 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 0.78, Spatial_loss 2.68, Flat_loss 0.33, Train_acc 80.27, Test_acc 32.91
2025-02-14 17:12:39,530 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 0.77, Spatial_loss 2.63, Flat_loss 0.32, Train_acc 80.85, Test_acc 31.71
2025-02-14 17:14:47,845 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.74, Spatial_loss 2.59, Flat_loss 0.32, Train_acc 81.18, Test_acc 33.60
2025-02-14 17:16:53,205 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.73, Spatial_loss 2.60, Flat_loss 0.32, Train_acc 81.33, Test_acc 31.20
2025-02-14 17:18:59,641 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.73, Spatial_loss 2.62, Flat_loss 0.32, Train_acc 81.82, Test_acc 31.06
2025-02-14 17:21:04,369 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.71, Spatial_loss 2.56, Flat_loss 0.31, Train_acc 82.24, Test_acc 30.06
2025-02-14 17:23:08,732 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.71, Spatial_loss 2.59, Flat_loss 0.32, Train_acc 82.13, Test_acc 34.00
2025-02-14 17:25:13,095 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.69, Spatial_loss 2.58, Flat_loss 0.32, Train_acc 82.55, Test_acc 31.83
2025-02-14 17:27:19,214 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.69, Spatial_loss 2.55, Flat_loss 0.31, Train_acc 82.42, Test_acc 34.34
2025-02-14 17:29:27,315 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.69, Spatial_loss 2.55, Flat_loss 0.32, Train_acc 82.84, Test_acc 33.09
2025-02-14 17:31:28,823 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.68, Spatial_loss 2.53, Flat_loss 0.31, Train_acc 82.76, Test_acc 33.71
2025-02-14 17:33:32,425 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.66, Spatial_loss 2.52, Flat_loss 0.31, Train_acc 83.65, Test_acc 30.49
2025-02-14 17:35:36,705 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.68, Spatial_loss 2.55, Flat_loss 0.31, Train_acc 82.99, Test_acc 33.34
2025-02-14 17:37:42,059 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.68, Spatial_loss 2.56, Flat_loss 0.32, Train_acc 82.54, Test_acc 31.60
2025-02-14 17:39:47,731 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.66, Spatial_loss 2.54, Flat_loss 0.31, Train_acc 83.71, Test_acc 32.97
2025-02-14 17:41:55,685 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.66, Spatial_loss 2.53, Flat_loss 0.31, Train_acc 83.38, Test_acc 35.06
2025-02-14 17:43:59,363 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.64, Spatial_loss 2.51, Flat_loss 0.31, Train_acc 83.82, Test_acc 34.06
2025-02-14 17:46:02,761 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.64, Spatial_loss 2.47, Flat_loss 0.31, Train_acc 83.89, Test_acc 33.66
2025-02-14 17:48:11,304 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.62, Spatial_loss 2.50, Flat_loss 0.31, Train_acc 84.61, Test_acc 31.34
2025-02-14 17:50:17,767 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.64, Spatial_loss 2.52, Flat_loss 0.31, Train_acc 84.04, Test_acc 32.49
2025-02-14 17:52:23,512 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.64, Spatial_loss 2.54, Flat_loss 0.31, Train_acc 83.96, Test_acc 33.97
2025-02-14 17:54:30,254 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.64, Spatial_loss 2.49, Flat_loss 0.31, Train_acc 84.09, Test_acc 37.14
2025-02-14 17:56:32,084 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.63, Spatial_loss 2.49, Flat_loss 0.31, Train_acc 83.99, Test_acc 32.97
2025-02-14 17:58:38,590 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.63, Spatial_loss 2.44, Flat_loss 0.30, Train_acc 84.50, Test_acc 36.00
2025-02-14 18:00:42,023 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.62, Spatial_loss 2.48, Flat_loss 0.31, Train_acc 84.48, Test_acc 36.20
2025-02-14 18:02:46,969 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.62, Spatial_loss 2.45, Flat_loss 0.31, Train_acc 84.37, Test_acc 38.43
2025-02-14 18:04:47,208 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.61, Spatial_loss 2.45, Flat_loss 0.30, Train_acc 85.04, Test_acc 35.17
2025-02-14 18:06:52,538 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.60, Spatial_loss 2.48, Flat_loss 0.30, Train_acc 85.04, Test_acc 33.57
2025-02-14 18:08:59,168 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.59, Spatial_loss 2.44, Flat_loss 0.31, Train_acc 85.05, Test_acc 34.66
2025-02-14 18:11:06,449 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.62, Spatial_loss 2.47, Flat_loss 0.31, Train_acc 84.35, Test_acc 31.31
2025-02-14 18:13:09,486 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.61, Spatial_loss 2.46, Flat_loss 0.31, Train_acc 84.70, Test_acc 38.57
2025-02-14 18:15:11,806 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.59, Spatial_loss 2.42, Flat_loss 0.30, Train_acc 85.54, Test_acc 33.49
2025-02-14 18:17:17,975 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.61, Spatial_loss 2.41, Flat_loss 0.30, Train_acc 84.97, Test_acc 33.03
2025-02-14 18:19:23,949 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.60, Spatial_loss 2.46, Flat_loss 0.31, Train_acc 85.01, Test_acc 36.34
2025-02-14 18:21:28,916 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.59, Spatial_loss 2.43, Flat_loss 0.30, Train_acc 85.61, Test_acc 34.26
2025-02-14 18:23:33,312 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.58, Spatial_loss 2.45, Flat_loss 0.30, Train_acc 85.75, Test_acc 32.86
2025-02-14 18:25:36,909 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.58, Spatial_loss 2.39, Flat_loss 0.30, Train_acc 85.75, Test_acc 36.49
2025-02-14 18:27:44,200 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.59, Spatial_loss 2.41, Flat_loss 0.30, Train_acc 85.34, Test_acc 34.00
2025-02-14 18:29:51,564 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.58, Spatial_loss 2.40, Flat_loss 0.30, Train_acc 85.62, Test_acc 28.31
2025-02-14 18:31:57,050 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.58, Spatial_loss 2.39, Flat_loss 0.30, Train_acc 85.86, Test_acc 31.17
2025-02-14 18:34:01,625 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.57, Spatial_loss 2.38, Flat_loss 0.30, Train_acc 86.13, Test_acc 32.43
2025-02-14 18:36:08,543 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.57, Spatial_loss 2.35, Flat_loss 0.30, Train_acc 85.73, Test_acc 30.26
2025-02-14 18:38:14,448 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.58, Spatial_loss 2.37, Flat_loss 0.30, Train_acc 85.96, Test_acc 36.80
2025-02-14 18:40:21,376 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.56, Spatial_loss 2.35, Flat_loss 0.30, Train_acc 86.39, Test_acc 37.77
2025-02-14 18:42:24,741 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 2.34, Flat_loss 0.29, Train_acc 85.79, Test_acc 30.74
2025-02-14 18:44:29,076 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.57, Spatial_loss 2.38, Flat_loss 0.30, Train_acc 85.50, Test_acc 33.97
2025-02-14 18:46:30,087 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.56, Spatial_loss 2.32, Flat_loss 0.29, Train_acc 86.24, Test_acc 33.83
2025-02-14 18:48:34,503 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.57, Spatial_loss 2.38, Flat_loss 0.30, Train_acc 85.80, Test_acc 31.26
2025-02-14 18:50:42,006 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.55, Spatial_loss 2.28, Flat_loss 0.29, Train_acc 86.51, Test_acc 36.11
2025-02-14 18:52:48,840 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.55, Spatial_loss 2.27, Flat_loss 0.29, Train_acc 86.48, Test_acc 35.66
2025-02-14 18:54:51,238 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.56, Spatial_loss 2.33, Flat_loss 0.29, Train_acc 86.45, Test_acc 32.40
2025-02-14 18:56:55,149 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.55, Spatial_loss 2.31, Flat_loss 0.29, Train_acc 86.58, Test_acc 35.80
2025-02-14 18:59:01,880 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.54, Spatial_loss 2.28, Flat_loss 0.29, Train_acc 86.83, Test_acc 34.03
2025-02-14 19:01:06,154 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.55, Spatial_loss 2.31, Flat_loss 0.29, Train_acc 86.94, Test_acc 36.80
2025-02-14 19:03:12,085 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.54, Spatial_loss 2.30, Flat_loss 0.29, Train_acc 86.89, Test_acc 35.51
2025-02-14 19:05:19,139 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.54, Spatial_loss 2.24, Flat_loss 0.29, Train_acc 86.92, Test_acc 35.14
2025-02-14 19:07:26,264 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.53, Spatial_loss 2.25, Flat_loss 0.29, Train_acc 87.17, Test_acc 32.66
2025-02-14 19:09:36,145 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.53, Spatial_loss 2.29, Flat_loss 0.29, Train_acc 87.20, Test_acc 34.57
2025-02-14 19:11:41,654 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.52, Spatial_loss 2.25, Flat_loss 0.29, Train_acc 87.51, Test_acc 33.51
2025-02-14 19:13:45,471 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.51, Spatial_loss 2.22, Flat_loss 0.28, Train_acc 87.58, Test_acc 30.46
2025-02-14 19:15:50,396 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.51, Spatial_loss 2.21, Flat_loss 0.28, Train_acc 87.61, Test_acc 34.89
2025-02-14 19:17:56,573 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.51, Spatial_loss 2.17, Flat_loss 0.28, Train_acc 87.73, Test_acc 33.86
2025-02-14 19:20:05,963 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.52, Spatial_loss 2.20, Flat_loss 0.28, Train_acc 87.57, Test_acc 35.97
2025-02-14 19:22:09,437 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.50, Spatial_loss 2.20, Flat_loss 0.28, Train_acc 87.77, Test_acc 33.86
2025-02-14 19:24:13,972 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 2.18, Flat_loss 0.28, Train_acc 88.39, Test_acc 37.71
2025-02-14 19:26:17,142 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.52, Spatial_loss 2.19, Flat_loss 0.28, Train_acc 87.51, Test_acc 35.34
2025-02-14 19:28:18,353 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.51, Spatial_loss 2.16, Flat_loss 0.28, Train_acc 87.77, Test_acc 35.69
2025-02-14 19:30:23,593 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.50, Spatial_loss 2.17, Flat_loss 0.28, Train_acc 87.78, Test_acc 35.69
2025-02-14 19:32:24,991 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.48, Spatial_loss 2.12, Flat_loss 0.28, Train_acc 88.46, Test_acc 34.40
2025-02-14 19:34:26,339 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.51, Spatial_loss 2.14, Flat_loss 0.28, Train_acc 87.61, Test_acc 36.23
2025-02-14 19:36:30,777 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.48, Spatial_loss 2.10, Flat_loss 0.27, Train_acc 88.69, Test_acc 38.60
2025-02-14 19:38:34,018 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.49, Spatial_loss 2.13, Flat_loss 0.28, Train_acc 88.71, Test_acc 35.20
2025-02-14 19:40:36,926 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.49, Spatial_loss 2.11, Flat_loss 0.27, Train_acc 88.45, Test_acc 34.80
2025-02-14 19:42:39,695 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.46, Spatial_loss 2.09, Flat_loss 0.27, Train_acc 89.03, Test_acc 36.00
2025-02-14 19:44:46,513 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.48, Spatial_loss 2.09, Flat_loss 0.27, Train_acc 88.74, Test_acc 36.94
2025-02-14 19:46:53,801 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.47, Spatial_loss 2.08, Flat_loss 0.27, Train_acc 88.69, Test_acc 36.34
2025-02-14 19:48:56,739 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.47, Spatial_loss 2.05, Flat_loss 0.27, Train_acc 88.81, Test_acc 36.89
2025-02-14 19:51:01,129 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.46, Spatial_loss 2.04, Flat_loss 0.26, Train_acc 89.39, Test_acc 35.29
2025-02-14 19:53:03,868 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.47, Spatial_loss 2.00, Flat_loss 0.26, Train_acc 89.20, Test_acc 38.14
2025-02-14 19:55:10,860 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.46, Spatial_loss 2.01, Flat_loss 0.26, Train_acc 89.19, Test_acc 36.00
2025-02-14 19:57:10,299 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.47, Spatial_loss 2.03, Flat_loss 0.27, Train_acc 88.87, Test_acc 38.31
2025-02-14 19:59:15,663 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.46, Spatial_loss 1.99, Flat_loss 0.27, Train_acc 89.42, Test_acc 34.09
2025-02-14 20:01:20,083 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.45, Spatial_loss 2.01, Flat_loss 0.26, Train_acc 89.54, Test_acc 39.11
2025-02-14 20:03:23,789 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.44, Spatial_loss 1.98, Flat_loss 0.26, Train_acc 89.61, Test_acc 36.17
2025-02-14 20:05:29,329 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.44, Spatial_loss 1.94, Flat_loss 0.26, Train_acc 89.82, Test_acc 38.26
2025-02-14 20:07:31,908 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.26, Train_acc 90.32, Test_acc 35.09
2025-02-14 20:09:36,960 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.43, Spatial_loss 1.95, Flat_loss 0.26, Train_acc 89.65, Test_acc 34.23
2025-02-14 20:11:40,579 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.42, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 90.35, Test_acc 36.60
2025-02-14 20:13:46,544 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.43, Spatial_loss 1.92, Flat_loss 0.25, Train_acc 90.00, Test_acc 40.26
2025-02-14 20:15:50,014 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.42, Spatial_loss 1.88, Flat_loss 0.25, Train_acc 90.39, Test_acc 35.57
2025-02-14 20:17:54,460 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.41, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 90.74, Test_acc 36.71
2025-02-14 20:20:02,131 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.42, Spatial_loss 1.83, Flat_loss 0.25, Train_acc 90.43, Test_acc 41.17
2025-02-14 20:22:17,973 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.40, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 90.77, Test_acc 38.69
2025-02-14 20:24:22,362 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.41, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 90.80, Test_acc 39.83
2025-02-14 20:26:34,900 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.39, Spatial_loss 1.79, Flat_loss 0.25, Train_acc 91.44, Test_acc 39.77
2025-02-14 20:28:40,319 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.38, Spatial_loss 1.81, Flat_loss 0.24, Train_acc 91.32, Test_acc 37.74
2025-02-14 20:30:45,367 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.39, Spatial_loss 1.76, Flat_loss 0.24, Train_acc 91.19, Test_acc 36.69
2025-02-14 20:32:51,563 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.38, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 91.39, Test_acc 38.17
2025-02-14 20:34:57,649 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.39, Spatial_loss 1.73, Flat_loss 0.24, Train_acc 91.19, Test_acc 37.00
2025-02-14 20:37:00,415 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.38, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 91.43, Test_acc 37.09
2025-02-14 20:39:05,659 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.39, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 91.19, Test_acc 38.69
2025-02-14 20:41:09,897 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.37, Spatial_loss 1.72, Flat_loss 0.23, Train_acc 91.81, Test_acc 37.26
2025-02-14 20:43:16,096 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.38, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 91.88, Test_acc 38.40
2025-02-14 20:45:20,386 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.37, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 91.69, Test_acc 36.46
2025-02-14 20:47:26,335 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.37, Spatial_loss 1.69, Flat_loss 0.23, Train_acc 91.90, Test_acc 37.23
2025-02-14 20:49:27,775 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.37, Spatial_loss 1.66, Flat_loss 0.23, Train_acc 91.94, Test_acc 35.89
2025-02-14 20:51:34,831 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.35, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 92.27, Test_acc 38.31
2025-02-14 20:53:36,783 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.36, Spatial_loss 1.66, Flat_loss 0.23, Train_acc 92.30, Test_acc 38.20
2025-02-14 20:55:42,033 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.34, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 92.68, Test_acc 41.06
2025-02-14 20:57:46,646 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.33, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 92.89, Test_acc 38.83
2025-02-14 20:59:47,735 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.34, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 92.77, Test_acc 39.29
2025-02-14 21:01:50,887 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.34, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 92.76, Test_acc 38.54
2025-02-14 21:03:54,472 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 92.76, Test_acc 38.69
2025-02-14 21:05:57,072 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.33, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 92.94, Test_acc 37.46
2025-02-14 21:07:59,176 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.33, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 92.87, Test_acc 37.86
2025-02-14 21:10:01,187 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.32, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 93.29, Test_acc 37.83
2025-02-14 21:12:05,047 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 93.14, Test_acc 39.03
2025-02-14 21:14:09,964 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 93.08, Test_acc 41.20
2025-02-14 21:16:14,442 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 93.31, Test_acc 38.80
2025-02-14 21:18:15,863 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.31, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 93.86, Test_acc 39.29
2025-02-14 21:20:20,622 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 93.73, Test_acc 38.86
2025-02-14 21:22:22,650 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 93.93, Test_acc 41.60
2025-02-14 21:24:25,892 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 94.10, Test_acc 38.40
2025-02-14 21:26:31,785 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 93.88, Test_acc 41.34
2025-02-14 21:28:38,335 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 94.02, Test_acc 40.83
2025-02-14 21:30:47,690 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 94.34, Test_acc 40.66
2025-02-14 21:32:53,051 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.30, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 94.07, Test_acc 41.00
2025-02-14 21:34:58,745 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 94.48, Test_acc 40.54
2025-02-14 21:37:05,118 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 94.44, Test_acc 41.26
2025-02-14 21:39:07,722 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.28, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 94.46, Test_acc 41.20
2025-02-14 21:41:12,078 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.28, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 94.41, Test_acc 40.97
2025-02-14 21:43:18,495 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.20, Train_acc 94.39, Test_acc 40.83
2025-02-14 21:45:25,405 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 94.91, Test_acc 41.54
2025-02-14 21:47:28,334 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.20, Train_acc 94.79, Test_acc 40.60
2025-02-14 21:49:31,697 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.20, Train_acc 94.73, Test_acc 40.60
2025-02-14 21:51:36,404 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.20, Train_acc 95.16, Test_acc 41.86
2025-02-14 21:53:42,345 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 94.94, Test_acc 40.57
2025-02-14 21:55:45,235 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.27, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 94.82, Test_acc 41.74
2025-02-14 21:57:48,989 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.27, Spatial_loss 1.21, Flat_loss 0.19, Train_acc 94.97, Test_acc 41.11
2025-02-14 21:59:51,857 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.26, Spatial_loss 1.21, Flat_loss 0.19, Train_acc 95.14, Test_acc 41.31
2025-02-14 22:01:55,773 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 95.15, Test_acc 41.29
2025-02-14 22:04:02,540 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.27, Spatial_loss 1.19, Flat_loss 0.19, Train_acc 94.77, Test_acc 41.09
2025-02-14 22:06:07,022 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.26, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 95.21, Test_acc 41.26
2025-02-14 22:08:13,298 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 95.51, Test_acc 41.74
2025-02-14 22:10:19,711 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.25, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.29, Test_acc 41.29
2025-02-14 22:12:18,970 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.25, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 95.27, Test_acc 41.57
2025-02-14 22:14:21,795 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.26, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.27, Test_acc 41.71
2025-02-14 22:16:24,774 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.26, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.16, Test_acc 41.77
2025-02-14 22:18:30,521 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.25, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.42, Test_acc 41.83
2025-02-14 22:20:32,881 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.25, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.25, Test_acc 42.06
2025-02-14 22:22:38,084 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.25, Spatial_loss 1.15, Flat_loss 0.19, Train_acc 95.51, Test_acc 41.49
2025-02-14 22:24:43,868 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.26, Spatial_loss 1.15, Flat_loss 0.19, Train_acc 94.99, Test_acc 41.60
2025-02-14 22:26:47,382 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.24, Spatial_loss 1.14, Flat_loss 0.19, Train_acc 95.63, Test_acc 41.49
2025-02-14 22:26:47,383 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:26:47,384 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:29:32,226 [podnet.py] => The size of finetune dataset: 1400
2025-02-14 22:30:08,808 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.45, Spatial_loss 1.37, Flat_loss 0.16, Train_acc 90.50, Test_acc 47.86
2025-02-14 22:30:38,869 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.13, Train_acc 94.00, Test_acc 51.57
2025-02-14 22:31:08,643 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.29, Spatial_loss 1.31, Flat_loss 0.12, Train_acc 94.57, Test_acc 50.89
2025-02-14 22:31:39,911 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.12, Train_acc 93.71, Test_acc 50.66
2025-02-14 22:32:12,495 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.12, Train_acc 94.86, Test_acc 50.46
2025-02-14 22:32:45,850 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.11, Train_acc 95.93, Test_acc 50.74
2025-02-14 22:33:18,722 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.11, Train_acc 96.29, Test_acc 50.29
2025-02-14 22:33:52,841 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 95.07, Test_acc 50.06
2025-02-14 22:34:24,906 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.11, Train_acc 94.57, Test_acc 50.63
2025-02-14 22:34:54,242 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.28, Spatial_loss 1.22, Flat_loss 0.11, Train_acc 94.14, Test_acc 50.37
2025-02-14 22:35:28,513 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 94.86, Test_acc 49.89
2025-02-14 22:36:01,434 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.29, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 93.64, Test_acc 49.86
2025-02-14 22:36:35,517 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 95.29, Test_acc 50.11
2025-02-14 22:37:08,778 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 94.50, Test_acc 50.06
2025-02-14 22:37:43,365 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.28, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 94.64, Test_acc 50.14
2025-02-14 22:38:16,326 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.25, Spatial_loss 1.14, Flat_loss 0.10, Train_acc 94.86, Test_acc 50.31
2025-02-14 22:38:48,179 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.25, Spatial_loss 1.15, Flat_loss 0.10, Train_acc 95.07, Test_acc 50.43
2025-02-14 22:39:17,896 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.10, Train_acc 94.93, Test_acc 50.23
2025-02-14 22:39:50,246 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.25, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 95.29, Test_acc 50.40
2025-02-14 22:40:23,514 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.11, Train_acc 96.21, Test_acc 50.29
2025-02-14 22:40:23,516 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:43:43,903 [podnet.py] => Exemplar size: 1400
2025-02-14 22:43:43,904 [trainer.py] => CNN: {'total': 50.29, '00-09': 52.6, '10-19': 33.6, '20-29': 33.8, '30-39': 44.4, '40-49': 45.8, '50-59': 63.2, '60-69': 78.6, 'old': 45.57, 'new': 78.6}
2025-02-14 22:43:43,904 [trainer.py] => NME: {'total': 46.71, '00-09': 60.8, '10-19': 27.0, '20-29': 28.6, '30-39': 36.2, '40-49': 39.8, '50-59': 60.6, '60-69': 74.0, 'old': 42.17, 'new': 74.0}
2025-02-14 22:43:43,904 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28, 54.43, 50.29]
2025-02-14 22:43:43,905 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4, 78.4, 76.91]
2025-02-14 22:43:43,905 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6, 49.87, 46.71]
2025-02-14 22:43:43,905 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6, 75.07, 72.89]

2025-02-14 22:43:43,905 [trainer.py] => Average Accuracy (CNN): 66.12857142857145
2025-02-14 22:43:43,906 [trainer.py] => Average Accuracy (NME): 62.99285714285714
2025-02-14 22:43:43,906 [trainer.py] => All params: 12047913
2025-02-14 22:43:43,907 [trainer.py] => Trainable params: 12047913
2025-02-14 22:43:43,911 [podnet.py] => Learning on 70-80
2025-02-14 22:43:43,919 [podnet.py] => Adaptive factor: 2.8284271247461903
2025-02-14 22:45:51,953 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 1.73, Spatial_loss 4.29, Flat_loss 1.03, Train_acc 59.42, Test_acc 22.02
2025-02-14 22:47:58,409 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 1.10, Spatial_loss 3.40, Flat_loss 0.53, Train_acc 71.31, Test_acc 23.38
2025-02-14 22:50:04,750 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 0.99, Spatial_loss 3.17, Flat_loss 0.45, Train_acc 74.39, Test_acc 25.20
2025-02-14 22:52:12,493 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 0.95, Spatial_loss 3.08, Flat_loss 0.41, Train_acc 75.31, Test_acc 27.05
2025-02-14 22:54:19,251 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 0.89, Spatial_loss 2.98, Flat_loss 0.38, Train_acc 77.31, Test_acc 32.80
2025-02-14 22:56:25,660 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 0.86, Spatial_loss 2.88, Flat_loss 0.37, Train_acc 77.81, Test_acc 30.40
2025-02-14 22:58:30,807 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 0.82, Spatial_loss 2.87, Flat_loss 0.37, Train_acc 79.06, Test_acc 29.82
2025-02-14 23:00:38,034 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 0.81, Spatial_loss 2.85, Flat_loss 0.36, Train_acc 79.24, Test_acc 29.75
2025-02-14 23:02:44,943 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 0.81, Spatial_loss 2.81, Flat_loss 0.36, Train_acc 79.15, Test_acc 28.18
2025-02-14 23:04:55,565 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 0.78, Spatial_loss 2.79, Flat_loss 0.35, Train_acc 79.61, Test_acc 33.98
2025-02-14 23:07:01,355 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 0.77, Spatial_loss 2.78, Flat_loss 0.35, Train_acc 80.58, Test_acc 29.28
2025-02-14 23:09:08,754 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 0.77, Spatial_loss 2.86, Flat_loss 0.35, Train_acc 80.41, Test_acc 37.70
2025-02-14 23:11:17,927 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 0.76, Spatial_loss 2.79, Flat_loss 0.35, Train_acc 80.97, Test_acc 34.10
2025-02-14 23:13:24,533 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.73, Spatial_loss 2.73, Flat_loss 0.34, Train_acc 81.32, Test_acc 32.90
2025-02-14 23:15:31,081 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.73, Spatial_loss 2.74, Flat_loss 0.34, Train_acc 81.15, Test_acc 35.20
2025-02-14 23:17:36,996 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.71, Spatial_loss 2.73, Flat_loss 0.34, Train_acc 82.28, Test_acc 36.50
2025-02-14 23:19:55,018 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.73, Spatial_loss 2.72, Flat_loss 0.35, Train_acc 81.47, Test_acc 32.98
2025-02-14 23:22:14,589 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.71, Spatial_loss 2.74, Flat_loss 0.34, Train_acc 82.19, Test_acc 33.12
2025-02-14 23:24:26,081 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.70, Spatial_loss 2.73, Flat_loss 0.35, Train_acc 82.24, Test_acc 35.12
2025-02-14 23:26:29,462 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.69, Spatial_loss 2.72, Flat_loss 0.34, Train_acc 82.11, Test_acc 34.83
2025-02-14 23:28:39,144 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.68, Spatial_loss 2.66, Flat_loss 0.34, Train_acc 83.01, Test_acc 32.80
2025-02-14 23:30:43,752 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.67, Spatial_loss 2.67, Flat_loss 0.34, Train_acc 83.00, Test_acc 31.02
2025-02-14 23:32:50,883 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.69, Spatial_loss 2.69, Flat_loss 0.34, Train_acc 82.64, Test_acc 32.50
2025-02-14 23:34:57,402 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.69, Spatial_loss 2.68, Flat_loss 0.34, Train_acc 82.89, Test_acc 34.80
2025-02-14 23:37:03,888 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.66, Spatial_loss 2.67, Flat_loss 0.34, Train_acc 83.92, Test_acc 34.80
2025-02-14 23:39:12,585 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.67, Spatial_loss 2.66, Flat_loss 0.34, Train_acc 83.44, Test_acc 36.08
2025-02-14 23:41:16,076 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.65, Spatial_loss 2.63, Flat_loss 0.34, Train_acc 83.53, Test_acc 34.65
2025-02-14 23:43:24,250 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.69, Spatial_loss 2.70, Flat_loss 0.34, Train_acc 82.74, Test_acc 32.65
2025-02-14 23:45:31,255 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.66, Spatial_loss 2.70, Flat_loss 0.34, Train_acc 83.23, Test_acc 35.17
2025-02-14 23:47:39,479 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.63, Spatial_loss 2.61, Flat_loss 0.33, Train_acc 84.01, Test_acc 34.22
2025-02-14 23:49:47,001 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.65, Spatial_loss 2.59, Flat_loss 0.33, Train_acc 83.78, Test_acc 34.58
2025-02-14 23:51:53,977 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.63, Spatial_loss 2.63, Flat_loss 0.33, Train_acc 84.25, Test_acc 33.08
2025-02-14 23:54:02,576 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.65, Spatial_loss 2.64, Flat_loss 0.34, Train_acc 83.61, Test_acc 34.50
2025-02-14 23:56:05,099 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.65, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 83.82, Test_acc 34.30
2025-02-14 23:58:11,519 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.63, Spatial_loss 2.62, Flat_loss 0.34, Train_acc 84.21, Test_acc 32.45
2025-02-15 00:00:19,448 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.65, Spatial_loss 2.62, Flat_loss 0.33, Train_acc 83.88, Test_acc 35.20
2025-02-15 00:02:27,003 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.63, Spatial_loss 2.61, Flat_loss 0.33, Train_acc 84.40, Test_acc 35.55
2025-02-15 00:04:32,655 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.63, Spatial_loss 2.62, Flat_loss 0.33, Train_acc 84.46, Test_acc 29.48
2025-02-15 00:06:38,461 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.63, Spatial_loss 2.61, Flat_loss 0.33, Train_acc 84.32, Test_acc 33.25
2025-02-15 00:08:46,653 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.62, Spatial_loss 2.60, Flat_loss 0.33, Train_acc 84.91, Test_acc 32.10
2025-02-15 00:10:49,442 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.62, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 84.28, Test_acc 32.00
2025-02-15 00:12:54,389 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.63, Spatial_loss 2.61, Flat_loss 0.33, Train_acc 84.23, Test_acc 35.60
2025-02-15 00:14:56,831 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.63, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 84.49, Test_acc 34.45
2025-02-15 00:17:01,966 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.62, Spatial_loss 2.55, Flat_loss 0.33, Train_acc 84.73, Test_acc 31.52
2025-02-15 00:19:08,361 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.61, Spatial_loss 2.56, Flat_loss 0.33, Train_acc 84.78, Test_acc 33.52
2025-02-15 00:21:17,445 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.61, Spatial_loss 2.56, Flat_loss 0.33, Train_acc 84.70, Test_acc 32.55
2025-02-15 00:23:24,440 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.60, Spatial_loss 2.51, Flat_loss 0.32, Train_acc 85.04, Test_acc 35.72
2025-02-15 00:25:31,596 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.60, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 85.05, Test_acc 36.45
2025-02-15 00:27:36,584 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.60, Spatial_loss 2.54, Flat_loss 0.32, Train_acc 84.85, Test_acc 32.80
2025-02-15 00:29:44,434 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.59, Spatial_loss 2.54, Flat_loss 0.32, Train_acc 85.44, Test_acc 35.78
2025-02-15 00:31:47,537 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.58, Spatial_loss 2.52, Flat_loss 0.32, Train_acc 85.88, Test_acc 36.20
2025-02-15 00:33:55,353 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 2.51, Flat_loss 0.32, Train_acc 86.08, Test_acc 31.90
2025-02-15 00:36:02,273 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.58, Spatial_loss 2.48, Flat_loss 0.32, Train_acc 85.50, Test_acc 34.05
2025-02-15 00:38:06,886 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.59, Spatial_loss 2.50, Flat_loss 0.32, Train_acc 85.48, Test_acc 35.52
2025-02-15 00:40:15,724 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.59, Spatial_loss 2.54, Flat_loss 0.32, Train_acc 85.45, Test_acc 35.30
2025-02-15 00:42:20,513 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.60, Spatial_loss 2.47, Flat_loss 0.32, Train_acc 85.47, Test_acc 33.28
2025-02-15 00:44:24,958 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.56, Spatial_loss 2.48, Flat_loss 0.32, Train_acc 86.25, Test_acc 28.42
2025-02-15 00:46:32,688 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.58, Spatial_loss 2.47, Flat_loss 0.32, Train_acc 85.77, Test_acc 36.02
2025-02-15 00:48:39,333 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.57, Spatial_loss 2.47, Flat_loss 0.32, Train_acc 85.98, Test_acc 36.02
2025-02-15 00:50:46,111 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.57, Spatial_loss 2.43, Flat_loss 0.32, Train_acc 85.71, Test_acc 35.33
2025-02-15 00:52:51,094 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.55, Spatial_loss 2.43, Flat_loss 0.31, Train_acc 86.77, Test_acc 30.10
2025-02-15 00:54:54,724 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.56, Spatial_loss 2.43, Flat_loss 0.32, Train_acc 86.25, Test_acc 30.85
2025-02-15 00:57:00,656 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.55, Spatial_loss 2.44, Flat_loss 0.31, Train_acc 86.90, Test_acc 33.22
2025-02-15 00:59:05,252 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.55, Spatial_loss 2.37, Flat_loss 0.31, Train_acc 86.67, Test_acc 33.48
2025-02-15 01:01:07,201 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.54, Spatial_loss 2.40, Flat_loss 0.31, Train_acc 86.82, Test_acc 33.17
2025-02-15 01:03:13,706 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.55, Spatial_loss 2.39, Flat_loss 0.31, Train_acc 86.58, Test_acc 35.88
2025-02-15 01:05:20,776 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.55, Spatial_loss 2.40, Flat_loss 0.31, Train_acc 86.95, Test_acc 36.10
2025-02-15 01:07:29,037 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.54, Spatial_loss 2.37, Flat_loss 0.31, Train_acc 86.63, Test_acc 37.35
2025-02-15 01:09:35,101 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.54, Spatial_loss 2.38, Flat_loss 0.31, Train_acc 86.72, Test_acc 33.45
2025-02-15 01:11:37,969 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.54, Spatial_loss 2.36, Flat_loss 0.31, Train_acc 87.03, Test_acc 36.88
2025-02-15 01:13:44,492 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.54, Spatial_loss 2.35, Flat_loss 0.31, Train_acc 86.94, Test_acc 36.95
2025-02-15 01:15:44,945 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.51, Spatial_loss 2.32, Flat_loss 0.30, Train_acc 88.02, Test_acc 34.20
2025-02-15 01:17:49,096 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.52, Spatial_loss 2.28, Flat_loss 0.30, Train_acc 87.54, Test_acc 35.10
2025-02-15 01:19:53,231 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.52, Spatial_loss 2.33, Flat_loss 0.30, Train_acc 87.15, Test_acc 32.35
2025-02-15 01:21:59,662 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.52, Spatial_loss 2.30, Flat_loss 0.30, Train_acc 87.53, Test_acc 32.75
2025-02-15 01:24:01,156 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.52, Spatial_loss 2.26, Flat_loss 0.30, Train_acc 87.33, Test_acc 38.75
2025-02-15 01:26:07,228 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.51, Spatial_loss 2.27, Flat_loss 0.30, Train_acc 87.91, Test_acc 34.55
2025-02-15 01:28:15,542 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.50, Spatial_loss 2.26, Flat_loss 0.30, Train_acc 87.98, Test_acc 34.88
2025-02-15 01:30:20,778 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.51, Spatial_loss 2.23, Flat_loss 0.29, Train_acc 88.00, Test_acc 38.45
2025-02-15 01:32:23,883 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.50, Spatial_loss 2.25, Flat_loss 0.30, Train_acc 88.06, Test_acc 35.33
2025-02-15 01:34:35,560 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.49, Spatial_loss 2.21, Flat_loss 0.29, Train_acc 88.31, Test_acc 35.78
2025-02-15 01:36:48,394 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.51, Spatial_loss 2.21, Flat_loss 0.29, Train_acc 87.78, Test_acc 35.38
2025-02-15 01:39:10,188 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.49, Spatial_loss 2.22, Flat_loss 0.29, Train_acc 88.16, Test_acc 33.92
2025-02-15 01:41:21,061 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.48, Spatial_loss 2.18, Flat_loss 0.29, Train_acc 88.60, Test_acc 34.88
2025-02-15 01:43:28,518 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.48, Spatial_loss 2.20, Flat_loss 0.29, Train_acc 88.72, Test_acc 37.83
2025-02-15 01:45:36,830 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.50, Spatial_loss 2.16, Flat_loss 0.29, Train_acc 88.30, Test_acc 36.00
2025-02-15 01:47:43,307 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.48, Spatial_loss 2.16, Flat_loss 0.29, Train_acc 88.70, Test_acc 35.50
2025-02-15 01:49:51,124 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.48, Spatial_loss 2.12, Flat_loss 0.28, Train_acc 88.57, Test_acc 35.80
2025-02-15 01:51:59,677 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.49, Spatial_loss 2.12, Flat_loss 0.28, Train_acc 88.36, Test_acc 35.62
2025-02-15 01:54:05,337 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.47, Spatial_loss 2.09, Flat_loss 0.28, Train_acc 88.77, Test_acc 36.78
2025-02-15 01:56:09,320 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.45, Spatial_loss 2.09, Flat_loss 0.28, Train_acc 89.24, Test_acc 36.62
2025-02-15 01:58:14,780 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.46, Spatial_loss 2.08, Flat_loss 0.28, Train_acc 89.04, Test_acc 34.42
2025-02-15 02:00:20,917 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.44, Spatial_loss 2.06, Flat_loss 0.27, Train_acc 89.83, Test_acc 33.65
2025-02-15 02:02:25,551 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.44, Spatial_loss 2.09, Flat_loss 0.28, Train_acc 89.28, Test_acc 35.85
2025-02-15 02:04:31,773 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.46, Spatial_loss 2.02, Flat_loss 0.27, Train_acc 89.51, Test_acc 39.10
2025-02-15 02:06:34,473 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.44, Spatial_loss 2.07, Flat_loss 0.27, Train_acc 89.46, Test_acc 38.75
2025-02-15 02:08:42,762 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.44, Spatial_loss 1.98, Flat_loss 0.27, Train_acc 90.03, Test_acc 36.78
2025-02-15 02:10:51,087 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.42, Spatial_loss 1.97, Flat_loss 0.27, Train_acc 90.35, Test_acc 35.85
2025-02-15 02:12:58,082 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.43, Spatial_loss 2.01, Flat_loss 0.27, Train_acc 90.06, Test_acc 37.70
2025-02-15 02:15:02,580 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.44, Spatial_loss 1.99, Flat_loss 0.26, Train_acc 89.47, Test_acc 37.10
2025-02-15 02:17:10,194 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.41, Spatial_loss 1.95, Flat_loss 0.26, Train_acc 90.89, Test_acc 36.62
2025-02-15 02:19:14,826 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.42, Spatial_loss 1.97, Flat_loss 0.26, Train_acc 90.47, Test_acc 35.28
2025-02-15 02:21:21,277 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.26, Train_acc 90.16, Test_acc 35.83
2025-02-15 02:23:25,618 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.40, Spatial_loss 1.90, Flat_loss 0.26, Train_acc 91.06, Test_acc 36.88
2025-02-15 02:25:29,366 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.40, Spatial_loss 1.89, Flat_loss 0.26, Train_acc 91.43, Test_acc 39.02
2025-02-15 02:27:35,548 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.39, Spatial_loss 1.88, Flat_loss 0.26, Train_acc 91.40, Test_acc 37.00
2025-02-15 02:29:41,140 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.41, Spatial_loss 1.86, Flat_loss 0.26, Train_acc 90.44, Test_acc 37.45
2025-02-15 02:31:47,830 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.38, Spatial_loss 1.86, Flat_loss 0.26, Train_acc 91.49, Test_acc 40.00
2025-02-15 02:33:51,491 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.38, Spatial_loss 1.80, Flat_loss 0.25, Train_acc 91.51, Test_acc 37.55
2025-02-15 02:35:57,941 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.39, Spatial_loss 1.79, Flat_loss 0.25, Train_acc 91.44, Test_acc 39.55
2025-02-15 02:38:04,239 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.39, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 91.59, Test_acc 38.38
2025-02-15 02:40:13,673 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.38, Spatial_loss 1.79, Flat_loss 0.25, Train_acc 91.84, Test_acc 36.60
2025-02-15 02:42:20,416 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.37, Spatial_loss 1.78, Flat_loss 0.25, Train_acc 91.80, Test_acc 38.80
2025-02-15 02:44:25,868 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.37, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 92.08, Test_acc 39.17
2025-02-15 02:46:31,943 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.37, Spatial_loss 1.74, Flat_loss 0.24, Train_acc 91.83, Test_acc 38.75
2025-02-15 02:48:36,484 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.38, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 91.64, Test_acc 38.72
2025-02-15 02:50:41,717 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.36, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 92.41, Test_acc 39.20
2025-02-15 02:52:51,003 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.35, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 92.35, Test_acc 38.88
2025-02-15 02:54:56,287 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.36, Spatial_loss 1.67, Flat_loss 0.24, Train_acc 92.42, Test_acc 39.02
2025-02-15 02:57:02,208 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.34, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 92.71, Test_acc 38.50
2025-02-15 02:59:06,589 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.35, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 92.83, Test_acc 40.62
2025-02-15 03:01:11,277 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.34, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 92.98, Test_acc 39.02
2025-02-15 03:03:15,017 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.33, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 93.04, Test_acc 38.10
2025-02-15 03:05:17,909 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.34, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 93.08, Test_acc 39.17
2025-02-15 03:07:22,919 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.33, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 93.34, Test_acc 40.20
2025-02-15 03:09:24,197 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.32, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 93.63, Test_acc 40.15
2025-02-15 03:11:31,105 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.32, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 93.38, Test_acc 39.62
2025-02-15 03:13:32,543 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.32, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 93.46, Test_acc 39.58
2025-02-15 03:15:38,660 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.32, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 93.67, Test_acc 40.50
2025-02-15 03:17:45,364 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 93.57, Test_acc 40.98
2025-02-15 03:19:49,164 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.31, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 93.72, Test_acc 40.08
2025-02-15 03:21:54,490 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.31, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 93.75, Test_acc 39.92
2025-02-15 03:24:00,053 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 94.04, Test_acc 39.65
2025-02-15 03:26:04,821 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.30, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 94.03, Test_acc 40.72
2025-02-15 03:28:12,242 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.30, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 94.23, Test_acc 40.45
2025-02-15 03:30:18,950 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.29, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 94.32, Test_acc 40.28
2025-02-15 03:32:26,820 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 94.57, Test_acc 40.80
2025-02-15 03:34:30,896 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.28, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 94.46, Test_acc 39.80
2025-02-15 03:36:33,563 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 94.13, Test_acc 40.78
2025-02-15 03:38:38,325 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 94.48, Test_acc 40.50
2025-02-15 03:40:44,239 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.68, Test_acc 40.00
2025-02-15 03:42:49,156 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.47, Test_acc 40.55
2025-02-15 03:44:52,731 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 94.72, Test_acc 40.17
2025-02-15 03:46:56,368 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 94.72, Test_acc 41.80
2025-02-15 03:49:01,408 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 94.84, Test_acc 40.65
2025-02-15 03:51:04,612 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.28, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 94.70, Test_acc 40.90
2025-02-15 03:53:08,587 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 94.99, Test_acc 41.40
2025-02-15 03:55:09,395 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.28, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 94.80, Test_acc 41.05
2025-02-15 03:57:11,076 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.20, Train_acc 94.93, Test_acc 41.38
2025-02-15 03:59:15,621 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 95.00, Test_acc 41.22
2025-02-15 04:01:18,327 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.28, Spatial_loss 1.27, Flat_loss 0.20, Train_acc 94.74, Test_acc 41.58
2025-02-15 04:03:26,170 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.26, Spatial_loss 1.26, Flat_loss 0.20, Train_acc 95.06, Test_acc 41.35
2025-02-15 04:05:27,832 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 95.48, Test_acc 41.45
2025-02-15 04:07:33,912 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.20, Train_acc 95.02, Test_acc 41.68
2025-02-15 04:09:37,051 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.20, Train_acc 95.26, Test_acc 41.68
2025-02-15 04:11:44,259 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.20, Train_acc 95.18, Test_acc 41.60
2025-02-15 04:13:55,201 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.26, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 95.22, Test_acc 41.62
2025-02-15 04:15:59,985 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 95.49, Test_acc 41.42
2025-02-15 04:18:11,237 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.26, Spatial_loss 1.19, Flat_loss 0.20, Train_acc 95.23, Test_acc 41.50
2025-02-15 04:20:18,560 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 95.03, Test_acc 41.58
2025-02-15 04:20:18,561 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 04:20:18,561 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 04:23:12,284 [podnet.py] => The size of finetune dataset: 1600
2025-02-15 04:23:52,351 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.50, Spatial_loss 1.78, Flat_loss 0.19, Train_acc 88.50, Test_acc 47.62
2025-02-15 04:24:29,340 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.32, Spatial_loss 1.50, Flat_loss 0.13, Train_acc 94.88, Test_acc 49.52
2025-02-15 04:25:08,133 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.32, Spatial_loss 1.41, Flat_loss 0.13, Train_acc 93.69, Test_acc 48.52
2025-02-15 04:25:41,695 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.13, Train_acc 94.56, Test_acc 47.95
2025-02-15 04:26:21,206 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.32, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 93.44, Test_acc 47.88
2025-02-15 04:27:01,174 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.12, Train_acc 94.94, Test_acc 48.88
2025-02-15 04:27:40,452 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.32, Spatial_loss 1.42, Flat_loss 0.12, Train_acc 93.25, Test_acc 48.18
2025-02-15 04:28:19,613 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.28, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 95.19, Test_acc 48.70
2025-02-15 04:28:58,573 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.26, Spatial_loss 1.38, Flat_loss 0.12, Train_acc 94.81, Test_acc 48.70
2025-02-15 04:29:30,746 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.12, Train_acc 94.56, Test_acc 48.58
2025-02-15 04:30:07,648 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.31, Spatial_loss 1.33, Flat_loss 0.12, Train_acc 93.25, Test_acc 48.25
2025-02-15 04:30:40,653 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.25, Spatial_loss 1.33, Flat_loss 0.11, Train_acc 95.06, Test_acc 48.32
2025-02-15 04:31:19,020 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.11, Train_acc 95.06, Test_acc 48.48
2025-02-15 04:31:56,644 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 94.94, Test_acc 48.30
2025-02-15 04:32:31,137 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.11, Train_acc 94.94, Test_acc 48.65
2025-02-15 04:33:08,385 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.25, Spatial_loss 1.30, Flat_loss 0.11, Train_acc 95.19, Test_acc 48.35
2025-02-15 04:33:46,510 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.11, Train_acc 94.75, Test_acc 48.30
2025-02-15 04:34:24,221 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.11, Train_acc 94.69, Test_acc 48.25
2025-02-15 04:35:02,154 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.11, Train_acc 95.81, Test_acc 48.35
2025-02-15 04:35:37,559 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.11, Train_acc 95.44, Test_acc 48.18
2025-02-15 04:35:37,561 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 04:39:13,939 [podnet.py] => Exemplar size: 1600
2025-02-15 04:39:13,940 [trainer.py] => CNN: {'total': 48.18, '00-09': 56.0, '10-19': 28.2, '20-29': 30.0, '30-39': 39.4, '40-49': 40.2, '50-59': 56.0, '60-69': 57.4, '70-79': 78.2, 'old': 43.89, 'new': 78.2}
2025-02-15 04:39:13,940 [trainer.py] => NME: {'total': 44.32, '00-09': 61.0, '10-19': 21.4, '20-29': 25.4, '30-39': 34.6, '40-49': 33.6, '50-59': 49.6, '60-69': 51.8, '70-79': 77.2, 'old': 39.63, 'new': 77.2}
2025-02-15 04:39:13,941 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28, 54.43, 50.29, 48.18]
2025-02-15 04:39:13,941 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4, 78.4, 76.91, 74.62]
2025-02-15 04:39:13,941 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6, 49.87, 46.71, 44.32]
2025-02-15 04:39:13,942 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6, 75.07, 72.89, 68.88]

2025-02-15 04:39:13,942 [trainer.py] => Average Accuracy (CNN): 63.88500000000001
2025-02-15 04:39:13,942 [trainer.py] => Average Accuracy (NME): 60.65875
2025-02-15 04:39:13,943 [trainer.py] => All params: 12099113
2025-02-15 04:39:13,944 [trainer.py] => Trainable params: 12099113
2025-02-15 04:39:13,950 [podnet.py] => Learning on 80-90
2025-02-15 04:39:13,958 [podnet.py] => Adaptive factor: 3.0
2025-02-15 04:41:24,327 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 1.69, Spatial_loss 4.21, Flat_loss 1.05, Train_acc 61.80, Test_acc 21.31
2025-02-15 04:43:39,260 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 1.10, Spatial_loss 3.51, Flat_loss 0.56, Train_acc 70.83, Test_acc 17.96
2025-02-15 04:45:51,093 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 1.01, Spatial_loss 3.31, Flat_loss 0.47, Train_acc 73.02, Test_acc 29.20
2025-02-15 04:48:01,852 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 0.96, Spatial_loss 3.18, Flat_loss 0.43, Train_acc 74.35, Test_acc 25.69
2025-02-15 04:50:16,633 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 0.93, Spatial_loss 3.09, Flat_loss 0.41, Train_acc 75.16, Test_acc 27.91
2025-02-15 04:52:32,216 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 0.88, Spatial_loss 3.03, Flat_loss 0.39, Train_acc 76.33, Test_acc 29.00
2025-02-15 04:54:50,512 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 0.87, Spatial_loss 2.97, Flat_loss 0.39, Train_acc 77.02, Test_acc 30.31
2025-02-15 04:57:02,908 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 0.86, Spatial_loss 3.03, Flat_loss 0.39, Train_acc 76.88, Test_acc 30.71
2025-02-15 04:59:14,376 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 0.84, Spatial_loss 2.96, Flat_loss 0.38, Train_acc 77.74, Test_acc 31.69
2025-02-15 05:01:22,425 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 0.81, Spatial_loss 2.89, Flat_loss 0.37, Train_acc 78.80, Test_acc 29.29
2025-02-15 05:03:35,145 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 0.80, Spatial_loss 2.93, Flat_loss 0.37, Train_acc 78.85, Test_acc 29.29
2025-02-15 05:05:46,838 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.78, Spatial_loss 2.91, Flat_loss 0.37, Train_acc 79.59, Test_acc 27.42
2025-02-15 05:07:58,749 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.77, Spatial_loss 2.89, Flat_loss 0.37, Train_acc 79.52, Test_acc 29.02
2025-02-15 05:10:10,796 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.78, Spatial_loss 2.85, Flat_loss 0.36, Train_acc 79.34, Test_acc 31.76
2025-02-15 05:12:24,594 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.77, Spatial_loss 2.92, Flat_loss 0.37, Train_acc 79.55, Test_acc 31.22
2025-02-15 05:14:35,355 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.75, Spatial_loss 2.82, Flat_loss 0.36, Train_acc 80.36, Test_acc 31.38
2025-02-15 05:16:44,373 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.74, Spatial_loss 2.87, Flat_loss 0.36, Train_acc 80.79, Test_acc 32.20
2025-02-15 05:18:57,079 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.73, Spatial_loss 2.88, Flat_loss 0.36, Train_acc 81.06, Test_acc 28.82
2025-02-15 05:21:10,626 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.73, Spatial_loss 2.84, Flat_loss 0.36, Train_acc 80.93, Test_acc 27.16
2025-02-15 05:23:24,745 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.76, Spatial_loss 2.92, Flat_loss 0.37, Train_acc 80.13, Test_acc 33.73
2025-02-15 05:25:38,887 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.74, Spatial_loss 2.94, Flat_loss 0.37, Train_acc 80.72, Test_acc 29.53
2025-02-15 05:27:54,562 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.71, Spatial_loss 2.78, Flat_loss 0.36, Train_acc 81.48, Test_acc 35.02
2025-02-15 05:30:10,393 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.71, Spatial_loss 2.83, Flat_loss 0.36, Train_acc 81.43, Test_acc 31.60
2025-02-15 05:32:21,676 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.71, Spatial_loss 2.84, Flat_loss 0.36, Train_acc 81.62, Test_acc 28.38
2025-02-15 05:34:36,300 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.70, Spatial_loss 2.81, Flat_loss 0.36, Train_acc 82.01, Test_acc 31.40
2025-02-15 05:36:45,291 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.72, Spatial_loss 2.81, Flat_loss 0.36, Train_acc 81.33, Test_acc 31.11
2025-02-15 05:38:59,483 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.67, Spatial_loss 2.71, Flat_loss 0.35, Train_acc 82.59, Test_acc 30.96
2025-02-15 05:41:11,533 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.68, Spatial_loss 2.77, Flat_loss 0.35, Train_acc 82.56, Test_acc 32.87
2025-02-15 05:43:25,359 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.70, Spatial_loss 2.79, Flat_loss 0.36, Train_acc 81.64, Test_acc 28.84
2025-02-15 05:45:39,132 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.70, Spatial_loss 2.85, Flat_loss 0.36, Train_acc 81.91, Test_acc 28.04
2025-02-15 05:47:52,024 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.68, Spatial_loss 2.83, Flat_loss 0.36, Train_acc 82.45, Test_acc 30.49
2025-02-15 05:50:00,685 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.69, Spatial_loss 2.77, Flat_loss 0.36, Train_acc 82.10, Test_acc 31.09
2025-02-15 05:52:07,805 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.70, Spatial_loss 2.81, Flat_loss 0.36, Train_acc 81.90, Test_acc 30.11
2025-02-15 05:54:23,758 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.66, Spatial_loss 2.78, Flat_loss 0.35, Train_acc 82.75, Test_acc 26.07
2025-02-15 05:56:41,161 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.68, Spatial_loss 2.84, Flat_loss 0.36, Train_acc 82.18, Test_acc 29.56
2025-02-15 05:59:07,887 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.68, Spatial_loss 2.74, Flat_loss 0.35, Train_acc 82.59, Test_acc 30.96
2025-02-15 06:01:30,047 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.66, Spatial_loss 2.73, Flat_loss 0.35, Train_acc 82.79, Test_acc 31.11
2025-02-15 06:03:47,734 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.65, Spatial_loss 2.74, Flat_loss 0.35, Train_acc 83.01, Test_acc 29.60
2025-02-15 06:06:02,468 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.66, Spatial_loss 2.76, Flat_loss 0.35, Train_acc 83.06, Test_acc 33.27
2025-02-15 06:08:12,499 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.64, Spatial_loss 2.72, Flat_loss 0.35, Train_acc 83.42, Test_acc 34.02
2025-02-15 06:10:25,100 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.67, Spatial_loss 2.74, Flat_loss 0.35, Train_acc 82.59, Test_acc 31.07
2025-02-15 06:12:44,066 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.67, Spatial_loss 2.76, Flat_loss 0.35, Train_acc 83.02, Test_acc 31.16
2025-02-15 06:15:20,156 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.67, Spatial_loss 2.71, Flat_loss 0.35, Train_acc 82.89, Test_acc 31.22
2025-02-15 06:17:47,293 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.65, Spatial_loss 2.78, Flat_loss 0.36, Train_acc 83.55, Test_acc 30.27
2025-02-15 06:20:02,384 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.64, Spatial_loss 2.71, Flat_loss 0.35, Train_acc 83.88, Test_acc 31.47
2025-02-15 06:22:15,934 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.64, Spatial_loss 2.69, Flat_loss 0.34, Train_acc 83.75, Test_acc 30.80
2025-02-15 06:24:29,503 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.63, Spatial_loss 2.72, Flat_loss 0.35, Train_acc 83.98, Test_acc 28.29
2025-02-15 06:26:44,105 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.65, Spatial_loss 2.69, Flat_loss 0.35, Train_acc 83.54, Test_acc 26.16
2025-02-15 06:28:56,064 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.63, Spatial_loss 2.75, Flat_loss 0.35, Train_acc 83.80, Test_acc 27.38
2025-02-15 06:31:10,563 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.64, Spatial_loss 2.67, Flat_loss 0.35, Train_acc 83.62, Test_acc 34.78
2025-02-15 06:33:22,381 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.63, Spatial_loss 2.70, Flat_loss 0.35, Train_acc 83.93, Test_acc 32.51
2025-02-15 06:35:35,567 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.63, Spatial_loss 2.65, Flat_loss 0.34, Train_acc 83.79, Test_acc 30.04
2025-02-15 06:37:50,144 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.62, Spatial_loss 2.65, Flat_loss 0.34, Train_acc 83.92, Test_acc 34.42
2025-02-15 06:40:01,312 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.63, Spatial_loss 2.65, Flat_loss 0.34, Train_acc 84.07, Test_acc 29.64
2025-02-15 06:42:15,126 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.63, Spatial_loss 2.62, Flat_loss 0.34, Train_acc 84.15, Test_acc 30.16
2025-02-15 06:44:29,783 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.60, Spatial_loss 2.63, Flat_loss 0.34, Train_acc 84.73, Test_acc 33.84
2025-02-15 06:46:43,832 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.61, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 85.13, Test_acc 31.71
2025-02-15 06:48:56,622 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.61, Spatial_loss 2.62, Flat_loss 0.34, Train_acc 85.03, Test_acc 30.00
2025-02-15 06:51:07,954 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.59, Spatial_loss 2.60, Flat_loss 0.34, Train_acc 84.89, Test_acc 31.78
2025-02-15 06:53:24,475 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.60, Spatial_loss 2.56, Flat_loss 0.33, Train_acc 84.98, Test_acc 32.33
2025-02-15 06:55:41,801 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.59, Spatial_loss 2.56, Flat_loss 0.33, Train_acc 85.18, Test_acc 35.80
2025-02-15 06:58:02,743 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.60, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 84.27, Test_acc 36.80
2025-02-15 07:00:19,969 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.59, Spatial_loss 2.56, Flat_loss 0.33, Train_acc 84.91, Test_acc 30.40
2025-02-15 07:02:34,302 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.58, Spatial_loss 2.51, Flat_loss 0.33, Train_acc 85.35, Test_acc 37.02
2025-02-15 07:04:46,643 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.59, Spatial_loss 2.54, Flat_loss 0.33, Train_acc 84.76, Test_acc 35.80
2025-02-15 07:06:59,378 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.59, Spatial_loss 2.58, Flat_loss 0.34, Train_acc 84.72, Test_acc 28.91
2025-02-15 07:09:07,942 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.58, Spatial_loss 2.53, Flat_loss 0.33, Train_acc 85.47, Test_acc 31.96
2025-02-15 07:11:19,989 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.59, Spatial_loss 2.58, Flat_loss 0.33, Train_acc 84.89, Test_acc 32.40
2025-02-15 07:13:32,631 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.56, Spatial_loss 2.48, Flat_loss 0.32, Train_acc 85.80, Test_acc 32.89
2025-02-15 07:15:41,152 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.57, Spatial_loss 2.50, Flat_loss 0.33, Train_acc 85.38, Test_acc 31.60
2025-02-15 07:17:53,351 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.58, Spatial_loss 2.48, Flat_loss 0.32, Train_acc 85.56, Test_acc 31.36
2025-02-15 07:20:08,652 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.54, Spatial_loss 2.45, Flat_loss 0.32, Train_acc 87.01, Test_acc 34.16
2025-02-15 07:22:21,385 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.55, Spatial_loss 2.42, Flat_loss 0.32, Train_acc 86.26, Test_acc 33.22
2025-02-15 07:24:29,449 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.54, Spatial_loss 2.44, Flat_loss 0.32, Train_acc 86.72, Test_acc 32.42
2025-02-15 07:26:40,969 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.55, Spatial_loss 2.42, Flat_loss 0.32, Train_acc 86.44, Test_acc 29.87
2025-02-15 07:28:55,469 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.53, Spatial_loss 2.36, Flat_loss 0.31, Train_acc 86.72, Test_acc 34.84
2025-02-15 07:31:05,150 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.54, Spatial_loss 2.35, Flat_loss 0.31, Train_acc 86.51, Test_acc 31.56
2025-02-15 07:33:16,362 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.53, Spatial_loss 2.40, Flat_loss 0.31, Train_acc 86.86, Test_acc 35.44
2025-02-15 07:35:30,144 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.53, Spatial_loss 2.37, Flat_loss 0.31, Train_acc 86.97, Test_acc 33.84
2025-02-15 07:37:42,714 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.54, Spatial_loss 2.36, Flat_loss 0.31, Train_acc 86.98, Test_acc 34.02
2025-02-15 07:39:56,139 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.53, Spatial_loss 2.35, Flat_loss 0.31, Train_acc 87.00, Test_acc 33.58
2025-02-15 07:42:07,731 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.53, Spatial_loss 2.36, Flat_loss 0.31, Train_acc 87.01, Test_acc 33.51
2025-02-15 07:44:18,698 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.51, Spatial_loss 2.31, Flat_loss 0.31, Train_acc 87.66, Test_acc 33.02
2025-02-15 07:46:32,039 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.52, Spatial_loss 2.33, Flat_loss 0.30, Train_acc 87.47, Test_acc 32.47
2025-02-15 07:48:43,421 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.51, Spatial_loss 2.31, Flat_loss 0.30, Train_acc 87.45, Test_acc 34.62
2025-02-15 07:50:53,940 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.50, Spatial_loss 2.29, Flat_loss 0.30, Train_acc 88.12, Test_acc 35.27
2025-02-15 07:53:05,882 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.51, Spatial_loss 2.29, Flat_loss 0.30, Train_acc 87.54, Test_acc 34.16
2025-02-15 07:55:16,177 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.49, Spatial_loss 2.29, Flat_loss 0.30, Train_acc 87.94, Test_acc 34.11
2025-02-15 07:57:28,298 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.51, Spatial_loss 2.26, Flat_loss 0.30, Train_acc 87.81, Test_acc 29.56
2025-02-15 07:59:42,568 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.48, Spatial_loss 2.24, Flat_loss 0.30, Train_acc 88.17, Test_acc 31.51
2025-02-15 08:01:55,233 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.48, Spatial_loss 2.23, Flat_loss 0.29, Train_acc 88.42, Test_acc 36.31
2025-02-15 08:04:07,895 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.48, Spatial_loss 2.21, Flat_loss 0.29, Train_acc 88.47, Test_acc 34.49
2025-02-15 08:06:19,366 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.47, Spatial_loss 2.16, Flat_loss 0.29, Train_acc 88.91, Test_acc 35.24
2025-02-15 08:08:30,060 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.48, Spatial_loss 2.17, Flat_loss 0.29, Train_acc 88.20, Test_acc 34.11
2025-02-15 08:10:43,059 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.46, Spatial_loss 2.17, Flat_loss 0.29, Train_acc 88.99, Test_acc 35.36
2025-02-15 08:12:54,608 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.46, Spatial_loss 2.13, Flat_loss 0.29, Train_acc 89.12, Test_acc 33.87
2025-02-15 08:15:05,354 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.47, Spatial_loss 2.14, Flat_loss 0.28, Train_acc 88.80, Test_acc 32.69
2025-02-15 08:17:17,122 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.45, Spatial_loss 2.10, Flat_loss 0.28, Train_acc 89.72, Test_acc 35.11
2025-02-15 08:19:26,756 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.44, Spatial_loss 2.07, Flat_loss 0.28, Train_acc 89.49, Test_acc 34.13
2025-02-15 08:21:38,614 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.47, Spatial_loss 2.10, Flat_loss 0.28, Train_acc 88.64, Test_acc 36.47
2025-02-15 08:23:50,303 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.42, Spatial_loss 2.04, Flat_loss 0.27, Train_acc 90.15, Test_acc 34.33
2025-02-15 08:26:04,809 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.44, Spatial_loss 2.05, Flat_loss 0.27, Train_acc 89.96, Test_acc 35.58
2025-02-15 08:28:10,563 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.44, Spatial_loss 2.05, Flat_loss 0.27, Train_acc 89.63, Test_acc 32.20
2025-02-15 08:30:26,273 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.44, Spatial_loss 2.04, Flat_loss 0.28, Train_acc 89.55, Test_acc 33.33
2025-02-15 08:32:40,802 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.41, Spatial_loss 1.99, Flat_loss 0.27, Train_acc 90.80, Test_acc 37.73
2025-02-15 08:34:52,307 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.42, Spatial_loss 1.99, Flat_loss 0.27, Train_acc 90.26, Test_acc 34.47
2025-02-15 08:37:06,094 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.41, Spatial_loss 1.99, Flat_loss 0.27, Train_acc 91.17, Test_acc 34.27
2025-02-15 08:39:17,650 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.42, Spatial_loss 1.94, Flat_loss 0.27, Train_acc 90.19, Test_acc 37.93
2025-02-15 08:41:25,711 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.40, Spatial_loss 1.91, Flat_loss 0.26, Train_acc 91.05, Test_acc 34.71
2025-02-15 08:43:37,559 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.40, Spatial_loss 1.92, Flat_loss 0.26, Train_acc 90.75, Test_acc 36.42
2025-02-15 08:45:50,866 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.40, Spatial_loss 1.94, Flat_loss 0.26, Train_acc 90.58, Test_acc 37.11
2025-02-15 08:48:01,391 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.39, Spatial_loss 1.92, Flat_loss 0.26, Train_acc 91.08, Test_acc 35.20
2025-02-15 08:50:13,871 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.38, Spatial_loss 1.89, Flat_loss 0.26, Train_acc 91.44, Test_acc 36.56
2025-02-15 08:52:25,205 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.39, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 91.16, Test_acc 33.58
2025-02-15 08:54:36,507 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.39, Spatial_loss 1.84, Flat_loss 0.25, Train_acc 91.42, Test_acc 37.36
2025-02-15 08:56:49,120 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.38, Spatial_loss 1.83, Flat_loss 0.25, Train_acc 91.58, Test_acc 34.62
2025-02-15 08:59:03,940 [podnet.py] => Task 8, Epoch 117/160 (LR 0.01679) => LSC_loss 0.37, Spatial_loss 1.78, Flat_loss 0.25, Train_acc 92.02, Test_acc 35.44
2025-02-15 09:01:21,841 [podnet.py] => Task 8, Epoch 118/160 (LR 0.01606) => LSC_loss 0.37, Spatial_loss 1.78, Flat_loss 0.25, Train_acc 91.85, Test_acc 35.04
2025-02-15 09:03:42,199 [podnet.py] => Task 8, Epoch 119/160 (LR 0.01535) => LSC_loss 0.37, Spatial_loss 1.77, Flat_loss 0.25, Train_acc 91.69, Test_acc 35.62
2025-02-15 09:05:53,242 [podnet.py] => Task 8, Epoch 120/160 (LR 0.01464) => LSC_loss 0.36, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 92.22, Test_acc 37.31
2025-02-15 09:08:04,869 [podnet.py] => Task 8, Epoch 121/160 (LR 0.01396) => LSC_loss 0.35, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 92.51, Test_acc 38.07
2025-02-15 09:10:19,102 [podnet.py] => Task 8, Epoch 122/160 (LR 0.01328) => LSC_loss 0.35, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 92.34, Test_acc 37.56
2025-02-15 09:12:32,462 [podnet.py] => Task 8, Epoch 123/160 (LR 0.01262) => LSC_loss 0.35, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 92.44, Test_acc 36.80
2025-02-15 09:14:45,076 [podnet.py] => Task 8, Epoch 124/160 (LR 0.01198) => LSC_loss 0.33, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 93.25, Test_acc 36.73
2025-02-15 09:16:56,173 [podnet.py] => Task 8, Epoch 125/160 (LR 0.01135) => LSC_loss 0.33, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 93.15, Test_acc 35.07
2025-02-15 09:19:03,828 [podnet.py] => Task 8, Epoch 126/160 (LR 0.01073) => LSC_loss 0.34, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 92.95, Test_acc 35.76
2025-02-15 09:21:15,234 [podnet.py] => Task 8, Epoch 127/160 (LR 0.01013) => LSC_loss 0.34, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 92.75, Test_acc 37.07
2025-02-15 09:23:26,001 [podnet.py] => Task 8, Epoch 128/160 (LR 0.00955) => LSC_loss 0.32, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 93.48, Test_acc 36.80
2025-02-15 09:25:38,379 [podnet.py] => Task 8, Epoch 129/160 (LR 0.00898) => LSC_loss 0.31, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 93.75, Test_acc 37.80
2025-02-15 09:27:53,273 [podnet.py] => Task 8, Epoch 130/160 (LR 0.00843) => LSC_loss 0.32, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 93.46, Test_acc 38.00
2025-02-15 09:30:06,641 [podnet.py] => Task 8, Epoch 131/160 (LR 0.00789) => LSC_loss 0.33, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 93.31, Test_acc 36.16
2025-02-15 09:32:19,753 [podnet.py] => Task 8, Epoch 132/160 (LR 0.00737) => LSC_loss 0.31, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 93.75, Test_acc 38.20
2025-02-15 09:34:31,177 [podnet.py] => Task 8, Epoch 133/160 (LR 0.00686) => LSC_loss 0.31, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 93.74, Test_acc 37.00
2025-02-15 09:36:45,144 [podnet.py] => Task 8, Epoch 134/160 (LR 0.00638) => LSC_loss 0.31, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 93.77, Test_acc 37.29
2025-02-15 09:38:54,602 [podnet.py] => Task 8, Epoch 135/160 (LR 0.00590) => LSC_loss 0.31, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 93.80, Test_acc 37.56
2025-02-15 09:41:11,583 [podnet.py] => Task 8, Epoch 136/160 (LR 0.00545) => LSC_loss 0.30, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 94.00, Test_acc 38.38
2025-02-15 09:43:23,987 [podnet.py] => Task 8, Epoch 137/160 (LR 0.00501) => LSC_loss 0.30, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 94.15, Test_acc 38.02
2025-02-15 09:45:38,481 [podnet.py] => Task 8, Epoch 138/160 (LR 0.00459) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 93.98, Test_acc 37.47
2025-02-15 09:47:52,069 [podnet.py] => Task 8, Epoch 139/160 (LR 0.00419) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 94.04, Test_acc 37.80
2025-02-15 09:50:01,917 [podnet.py] => Task 8, Epoch 140/160 (LR 0.00381) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 94.26, Test_acc 39.53
2025-02-15 09:52:17,188 [podnet.py] => Task 8, Epoch 141/160 (LR 0.00344) => LSC_loss 0.29, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 94.56, Test_acc 39.07
2025-02-15 09:54:31,672 [podnet.py] => Task 8, Epoch 142/160 (LR 0.00309) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 94.68, Test_acc 38.36
2025-02-15 09:56:43,864 [podnet.py] => Task 8, Epoch 143/160 (LR 0.00276) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 94.85, Test_acc 38.98
2025-02-15 09:58:52,633 [podnet.py] => Task 8, Epoch 144/160 (LR 0.00245) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.62, Test_acc 38.78
2025-02-15 10:01:06,971 [podnet.py] => Task 8, Epoch 145/160 (LR 0.00215) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.77, Test_acc 38.51
2025-02-15 10:03:19,320 [podnet.py] => Task 8, Epoch 146/160 (LR 0.00188) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.85, Test_acc 38.29
2025-02-15 10:05:32,950 [podnet.py] => Task 8, Epoch 147/160 (LR 0.00162) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 94.92, Test_acc 38.62
2025-02-15 10:07:46,821 [podnet.py] => Task 8, Epoch 148/160 (LR 0.00138) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 94.94, Test_acc 38.62
2025-02-15 10:10:01,819 [podnet.py] => Task 8, Epoch 149/160 (LR 0.00116) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 95.00, Test_acc 38.60
2025-02-15 10:12:14,873 [podnet.py] => Task 8, Epoch 150/160 (LR 0.00096) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 94.99, Test_acc 39.24
2025-02-15 10:14:22,680 [podnet.py] => Task 8, Epoch 151/160 (LR 0.00078) => LSC_loss 0.28, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 94.89, Test_acc 38.60
2025-02-15 10:16:36,231 [podnet.py] => Task 8, Epoch 152/160 (LR 0.00062) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 94.88, Test_acc 39.07
2025-02-15 10:18:48,014 [podnet.py] => Task 8, Epoch 153/160 (LR 0.00047) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 95.21, Test_acc 38.53
2025-02-15 10:21:00,339 [podnet.py] => Task 8, Epoch 154/160 (LR 0.00035) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 95.20, Test_acc 38.67
2025-02-15 10:23:12,075 [podnet.py] => Task 8, Epoch 155/160 (LR 0.00024) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 95.13, Test_acc 38.76
2025-02-15 10:25:21,127 [podnet.py] => Task 8, Epoch 156/160 (LR 0.00015) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 95.15, Test_acc 38.67
2025-02-15 10:27:35,388 [podnet.py] => Task 8, Epoch 157/160 (LR 0.00009) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 95.16, Test_acc 38.64
2025-02-15 10:29:50,218 [podnet.py] => Task 8, Epoch 158/160 (LR 0.00004) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 95.36, Test_acc 38.44
2025-02-15 10:32:04,642 [podnet.py] => Task 8, Epoch 159/160 (LR 0.00001) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 95.04, Test_acc 38.36
2025-02-15 10:34:19,167 [podnet.py] => Task 8, Epoch 160/160 (LR 0.00000) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 95.02, Test_acc 38.96
2025-02-15 10:34:19,168 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 10:34:19,168 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 10:37:23,607 [podnet.py] => The size of finetune dataset: 1800
2025-02-15 10:38:10,264 [podnet.py] => Task 8, Epoch 1/20 (LR 0.00497) => LSC_loss 0.51, Spatial_loss 1.68, Flat_loss 0.20, Train_acc 90.17, Test_acc 44.64
2025-02-15 10:38:56,906 [podnet.py] => Task 8, Epoch 2/20 (LR 0.00488) => LSC_loss 0.44, Spatial_loss 1.75, Flat_loss 0.18, Train_acc 91.72, Test_acc 46.24
2025-02-15 10:39:39,691 [podnet.py] => Task 8, Epoch 3/20 (LR 0.00473) => LSC_loss 0.35, Spatial_loss 1.73, Flat_loss 0.17, Train_acc 92.72, Test_acc 44.04
2025-02-15 10:40:20,053 [podnet.py] => Task 8, Epoch 4/20 (LR 0.00452) => LSC_loss 0.42, Spatial_loss 1.72, Flat_loss 0.18, Train_acc 92.83, Test_acc 45.36
2025-02-15 10:41:03,613 [podnet.py] => Task 8, Epoch 5/20 (LR 0.00427) => LSC_loss 0.40, Spatial_loss 1.70, Flat_loss 0.17, Train_acc 92.44, Test_acc 45.07
2025-02-15 10:41:47,378 [podnet.py] => Task 8, Epoch 6/20 (LR 0.00397) => LSC_loss 0.40, Spatial_loss 1.74, Flat_loss 0.19, Train_acc 92.72, Test_acc 44.80
2025-02-15 10:42:31,173 [podnet.py] => Task 8, Epoch 7/20 (LR 0.00363) => LSC_loss 0.40, Spatial_loss 1.79, Flat_loss 0.19, Train_acc 93.06, Test_acc 45.09
2025-02-15 10:43:14,369 [podnet.py] => Task 8, Epoch 8/20 (LR 0.00327) => LSC_loss 0.34, Spatial_loss 1.71, Flat_loss 0.18, Train_acc 93.56, Test_acc 45.53
2025-02-15 10:43:57,566 [podnet.py] => Task 8, Epoch 9/20 (LR 0.00289) => LSC_loss 0.40, Spatial_loss 1.69, Flat_loss 0.17, Train_acc 91.56, Test_acc 45.24
2025-02-15 10:44:42,006 [podnet.py] => Task 8, Epoch 10/20 (LR 0.00250) => LSC_loss 0.46, Spatial_loss 1.73, Flat_loss 0.18, Train_acc 92.94, Test_acc 43.98
2025-02-15 10:45:22,895 [podnet.py] => Task 8, Epoch 11/20 (LR 0.00211) => LSC_loss 0.34, Spatial_loss 1.61, Flat_loss 0.16, Train_acc 93.39, Test_acc 44.07
2025-02-15 10:46:03,572 [podnet.py] => Task 8, Epoch 12/20 (LR 0.00173) => LSC_loss 0.37, Spatial_loss 1.68, Flat_loss 0.17, Train_acc 94.44, Test_acc 45.18
2025-02-15 10:46:47,641 [podnet.py] => Task 8, Epoch 13/20 (LR 0.00137) => LSC_loss 0.30, Spatial_loss 1.61, Flat_loss 0.16, Train_acc 93.56, Test_acc 46.51
2025-02-15 10:47:29,769 [podnet.py] => Task 8, Epoch 14/20 (LR 0.00103) => LSC_loss 0.31, Spatial_loss 1.57, Flat_loss 0.15, Train_acc 94.33, Test_acc 46.22
2025-02-15 10:48:13,614 [podnet.py] => Task 8, Epoch 15/20 (LR 0.00073) => LSC_loss 0.34, Spatial_loss 1.62, Flat_loss 0.16, Train_acc 93.89, Test_acc 45.40
2025-02-15 10:48:57,251 [podnet.py] => Task 8, Epoch 16/20 (LR 0.00048) => LSC_loss 0.41, Spatial_loss 1.56, Flat_loss 0.15, Train_acc 94.00, Test_acc 45.53
2025-02-15 10:49:41,729 [podnet.py] => Task 8, Epoch 17/20 (LR 0.00027) => LSC_loss 0.33, Spatial_loss 1.59, Flat_loss 0.16, Train_acc 94.33, Test_acc 45.93
2025-02-15 10:50:25,011 [podnet.py] => Task 8, Epoch 18/20 (LR 0.00012) => LSC_loss 0.32, Spatial_loss 1.59, Flat_loss 0.16, Train_acc 94.78, Test_acc 45.73
2025-02-15 10:51:08,698 [podnet.py] => Task 8, Epoch 19/20 (LR 0.00003) => LSC_loss 0.32, Spatial_loss 1.55, Flat_loss 0.15, Train_acc 94.39, Test_acc 45.89
2025-02-15 10:51:53,600 [podnet.py] => Task 8, Epoch 20/20 (LR 0.00000) => LSC_loss 0.28, Spatial_loss 1.51, Flat_loss 0.14, Train_acc 95.00, Test_acc 45.80
2025-02-15 10:51:53,603 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 10:55:48,879 [podnet.py] => Exemplar size: 1800
2025-02-15 10:55:48,880 [trainer.py] => CNN: {'total': 45.8, '00-09': 49.2, '10-19': 29.2, '20-29': 26.8, '30-39': 42.0, '40-49': 36.0, '50-59': 52.8, '60-69': 47.8, '70-79': 53.6, '80-89': 74.8, 'old': 42.18, 'new': 74.8}
2025-02-15 10:55:48,880 [trainer.py] => NME: {'total': 42.82, '00-09': 58.2, '10-19': 22.0, '20-29': 23.0, '30-39': 34.2, '40-49': 31.2, '50-59': 44.4, '60-69': 45.4, '70-79': 53.6, '80-89': 73.4, 'old': 39.0, 'new': 73.4}
2025-02-15 10:55:48,881 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28, 54.43, 50.29, 48.18, 45.8]
2025-02-15 10:55:48,881 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4, 78.4, 76.91, 74.62, 73.16]
2025-02-15 10:55:48,881 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6, 49.87, 46.71, 44.32, 42.82]
2025-02-15 10:55:48,881 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6, 75.07, 72.89, 68.88, 68.16]

2025-02-15 10:55:48,882 [trainer.py] => Average Accuracy (CNN): 61.875555555555565
2025-02-15 10:55:48,882 [trainer.py] => Average Accuracy (NME): 58.67666666666667
2025-02-15 10:55:48,883 [trainer.py] => All params: 12150313
2025-02-15 10:55:48,883 [trainer.py] => Trainable params: 12150313
2025-02-15 10:55:48,889 [podnet.py] => Learning on 90-100
2025-02-15 10:55:48,897 [podnet.py] => Adaptive factor: 3.1622776601683795
2025-02-15 10:58:06,751 [podnet.py] => Task 9, Epoch 1/160 (LR 0.09999) => LSC_loss 1.79, Spatial_loss 4.26, Flat_loss 1.10, Train_acc 58.55, Test_acc 24.86
2025-02-15 11:00:34,413 [podnet.py] => Task 9, Epoch 2/160 (LR 0.09996) => LSC_loss 1.19, Spatial_loss 3.63, Flat_loss 0.61, Train_acc 68.49, Test_acc 26.18
2025-02-15 11:03:00,411 [podnet.py] => Task 9, Epoch 3/160 (LR 0.09991) => LSC_loss 1.11, Spatial_loss 3.42, Flat_loss 0.51, Train_acc 70.56, Test_acc 26.04
2025-02-15 11:05:20,568 [podnet.py] => Task 9, Epoch 4/160 (LR 0.09985) => LSC_loss 1.06, Spatial_loss 3.27, Flat_loss 0.46, Train_acc 71.90, Test_acc 24.88
2025-02-15 11:07:35,548 [podnet.py] => Task 9, Epoch 5/160 (LR 0.09976) => LSC_loss 1.02, Spatial_loss 3.26, Flat_loss 0.45, Train_acc 72.57, Test_acc 27.86
2025-02-15 11:09:51,420 [podnet.py] => Task 9, Epoch 6/160 (LR 0.09965) => LSC_loss 1.00, Spatial_loss 3.20, Flat_loss 0.44, Train_acc 74.06, Test_acc 24.24
2025-02-15 11:12:07,872 [podnet.py] => Task 9, Epoch 7/160 (LR 0.09953) => LSC_loss 0.95, Spatial_loss 3.10, Flat_loss 0.42, Train_acc 74.94, Test_acc 28.14
2025-02-15 11:14:23,256 [podnet.py] => Task 9, Epoch 8/160 (LR 0.09938) => LSC_loss 0.96, Spatial_loss 3.12, Flat_loss 0.43, Train_acc 74.55, Test_acc 30.10
2025-02-15 11:16:39,405 [podnet.py] => Task 9, Epoch 9/160 (LR 0.09922) => LSC_loss 0.94, Spatial_loss 3.09, Flat_loss 0.42, Train_acc 75.24, Test_acc 30.04
2025-02-15 11:18:57,545 [podnet.py] => Task 9, Epoch 10/160 (LR 0.09904) => LSC_loss 0.91, Spatial_loss 2.98, Flat_loss 0.41, Train_acc 75.64, Test_acc 25.48
2025-02-15 11:21:14,211 [podnet.py] => Task 9, Epoch 11/160 (LR 0.09884) => LSC_loss 0.92, Spatial_loss 3.12, Flat_loss 0.42, Train_acc 76.20, Test_acc 29.44
2025-02-15 11:23:32,208 [podnet.py] => Task 9, Epoch 12/160 (LR 0.09862) => LSC_loss 0.90, Spatial_loss 3.11, Flat_loss 0.42, Train_acc 76.70, Test_acc 29.36
2025-02-15 11:25:51,679 [podnet.py] => Task 9, Epoch 13/160 (LR 0.09838) => LSC_loss 0.89, Spatial_loss 3.03, Flat_loss 0.41, Train_acc 76.68, Test_acc 26.60
2025-02-15 11:28:11,668 [podnet.py] => Task 9, Epoch 14/160 (LR 0.09812) => LSC_loss 0.87, Spatial_loss 3.06, Flat_loss 0.41, Train_acc 77.45, Test_acc 28.14
2025-02-15 11:30:29,695 [podnet.py] => Task 9, Epoch 15/160 (LR 0.09785) => LSC_loss 0.85, Spatial_loss 3.02, Flat_loss 0.41, Train_acc 77.78, Test_acc 28.28
2025-02-15 11:32:45,002 [podnet.py] => Task 9, Epoch 16/160 (LR 0.09755) => LSC_loss 0.85, Spatial_loss 3.01, Flat_loss 0.40, Train_acc 78.05, Test_acc 31.70
2025-02-15 11:35:02,028 [podnet.py] => Task 9, Epoch 17/160 (LR 0.09724) => LSC_loss 0.85, Spatial_loss 3.00, Flat_loss 0.41, Train_acc 77.35, Test_acc 24.58
2025-02-15 11:37:19,669 [podnet.py] => Task 9, Epoch 18/160 (LR 0.09691) => LSC_loss 0.83, Spatial_loss 2.99, Flat_loss 0.41, Train_acc 78.77, Test_acc 27.06
2025-02-15 11:39:38,370 [podnet.py] => Task 9, Epoch 19/160 (LR 0.09656) => LSC_loss 0.83, Spatial_loss 2.97, Flat_loss 0.40, Train_acc 78.36, Test_acc 26.64
2025-02-15 11:41:55,987 [podnet.py] => Task 9, Epoch 20/160 (LR 0.09619) => LSC_loss 0.85, Spatial_loss 3.03, Flat_loss 0.41, Train_acc 77.98, Test_acc 28.26
2025-02-15 11:44:15,900 [podnet.py] => Task 9, Epoch 21/160 (LR 0.09581) => LSC_loss 0.82, Spatial_loss 3.00, Flat_loss 0.41, Train_acc 78.61, Test_acc 32.24
2025-02-15 11:46:30,404 [podnet.py] => Task 9, Epoch 22/160 (LR 0.09541) => LSC_loss 0.82, Spatial_loss 3.04, Flat_loss 0.41, Train_acc 78.61, Test_acc 25.82
2025-02-15 11:48:44,624 [podnet.py] => Task 9, Epoch 23/160 (LR 0.09499) => LSC_loss 0.82, Spatial_loss 3.00, Flat_loss 0.40, Train_acc 78.87, Test_acc 29.28
2025-02-15 11:51:00,465 [podnet.py] => Task 9, Epoch 24/160 (LR 0.09455) => LSC_loss 0.81, Spatial_loss 2.97, Flat_loss 0.40, Train_acc 79.01, Test_acc 27.82
2025-02-15 11:53:15,536 [podnet.py] => Task 9, Epoch 25/160 (LR 0.09410) => LSC_loss 0.80, Spatial_loss 2.97, Flat_loss 0.40, Train_acc 79.28, Test_acc 26.00
2025-02-15 11:55:30,825 [podnet.py] => Task 9, Epoch 26/160 (LR 0.09362) => LSC_loss 0.80, Spatial_loss 2.98, Flat_loss 0.41, Train_acc 79.56, Test_acc 28.20
2025-02-15 11:57:46,063 [podnet.py] => Task 9, Epoch 27/160 (LR 0.09314) => LSC_loss 0.81, Spatial_loss 2.96, Flat_loss 0.40, Train_acc 79.26, Test_acc 31.94
2025-02-15 12:00:04,433 [podnet.py] => Task 9, Epoch 28/160 (LR 0.09263) => LSC_loss 0.79, Spatial_loss 2.99, Flat_loss 0.40, Train_acc 79.45, Test_acc 29.88
2025-02-15 12:02:23,304 [podnet.py] => Task 9, Epoch 29/160 (LR 0.09211) => LSC_loss 0.80, Spatial_loss 3.01, Flat_loss 0.40, Train_acc 79.61, Test_acc 28.50
2025-02-15 12:04:38,487 [podnet.py] => Task 9, Epoch 30/160 (LR 0.09157) => LSC_loss 0.79, Spatial_loss 2.95, Flat_loss 0.40, Train_acc 79.74, Test_acc 28.32
2025-02-15 12:06:56,137 [podnet.py] => Task 9, Epoch 31/160 (LR 0.09102) => LSC_loss 0.79, Spatial_loss 2.91, Flat_loss 0.40, Train_acc 79.57, Test_acc 31.64
2025-02-15 12:09:14,134 [podnet.py] => Task 9, Epoch 32/160 (LR 0.09045) => LSC_loss 0.78, Spatial_loss 2.95, Flat_loss 0.40, Train_acc 79.93, Test_acc 29.38
2025-02-15 12:11:31,935 [podnet.py] => Task 9, Epoch 33/160 (LR 0.08987) => LSC_loss 0.78, Spatial_loss 2.94, Flat_loss 0.40, Train_acc 80.47, Test_acc 27.32
2025-02-15 12:13:48,665 [podnet.py] => Task 9, Epoch 34/160 (LR 0.08927) => LSC_loss 0.79, Spatial_loss 2.96, Flat_loss 0.40, Train_acc 79.49, Test_acc 28.98
2025-02-15 12:16:04,226 [podnet.py] => Task 9, Epoch 35/160 (LR 0.08865) => LSC_loss 0.77, Spatial_loss 2.94, Flat_loss 0.40, Train_acc 80.13, Test_acc 30.24
2025-02-15 12:18:21,465 [podnet.py] => Task 9, Epoch 36/160 (LR 0.08802) => LSC_loss 0.77, Spatial_loss 2.93, Flat_loss 0.40, Train_acc 80.46, Test_acc 31.44
2025-02-15 12:20:36,593 [podnet.py] => Task 9, Epoch 37/160 (LR 0.08738) => LSC_loss 0.75, Spatial_loss 2.90, Flat_loss 0.39, Train_acc 80.49, Test_acc 29.52
2025-02-15 12:23:01,705 [podnet.py] => Task 9, Epoch 38/160 (LR 0.08672) => LSC_loss 0.78, Spatial_loss 2.92, Flat_loss 0.40, Train_acc 80.03, Test_acc 27.84
2025-02-15 12:25:34,424 [podnet.py] => Task 9, Epoch 39/160 (LR 0.08604) => LSC_loss 0.76, Spatial_loss 2.90, Flat_loss 0.39, Train_acc 80.63, Test_acc 29.50
2025-02-15 12:28:17,992 [podnet.py] => Task 9, Epoch 40/160 (LR 0.08536) => LSC_loss 0.73, Spatial_loss 2.89, Flat_loss 0.39, Train_acc 81.07, Test_acc 29.44
2025-02-15 12:30:47,513 [podnet.py] => Task 9, Epoch 41/160 (LR 0.08465) => LSC_loss 0.75, Spatial_loss 2.85, Flat_loss 0.39, Train_acc 80.62, Test_acc 25.96
2025-02-15 12:33:07,471 [podnet.py] => Task 9, Epoch 42/160 (LR 0.08394) => LSC_loss 0.75, Spatial_loss 2.85, Flat_loss 0.39, Train_acc 80.72, Test_acc 30.52
2025-02-15 12:35:28,945 [podnet.py] => Task 9, Epoch 43/160 (LR 0.08321) => LSC_loss 0.72, Spatial_loss 2.86, Flat_loss 0.39, Train_acc 81.77, Test_acc 30.90
2025-02-15 12:37:48,207 [podnet.py] => Task 9, Epoch 44/160 (LR 0.08247) => LSC_loss 0.75, Spatial_loss 2.89, Flat_loss 0.40, Train_acc 80.91, Test_acc 26.26
2025-02-15 12:40:06,272 [podnet.py] => Task 9, Epoch 45/160 (LR 0.08172) => LSC_loss 0.72, Spatial_loss 2.84, Flat_loss 0.39, Train_acc 81.70, Test_acc 27.24
2025-02-15 12:42:24,285 [podnet.py] => Task 9, Epoch 46/160 (LR 0.08095) => LSC_loss 0.74, Spatial_loss 2.84, Flat_loss 0.39, Train_acc 80.89, Test_acc 28.58
2025-02-15 12:44:42,319 [podnet.py] => Task 9, Epoch 47/160 (LR 0.08018) => LSC_loss 0.74, Spatial_loss 2.82, Flat_loss 0.39, Train_acc 81.25, Test_acc 29.88
2025-02-15 12:46:58,637 [podnet.py] => Task 9, Epoch 48/160 (LR 0.07939) => LSC_loss 0.72, Spatial_loss 2.84, Flat_loss 0.39, Train_acc 81.97, Test_acc 29.60
2025-02-15 12:49:14,502 [podnet.py] => Task 9, Epoch 49/160 (LR 0.07859) => LSC_loss 0.72, Spatial_loss 2.77, Flat_loss 0.38, Train_acc 81.83, Test_acc 28.98
2025-02-15 12:51:31,851 [podnet.py] => Task 9, Epoch 50/160 (LR 0.07778) => LSC_loss 0.73, Spatial_loss 2.85, Flat_loss 0.39, Train_acc 81.68, Test_acc 30.84
2025-02-15 12:53:47,347 [podnet.py] => Task 9, Epoch 51/160 (LR 0.07696) => LSC_loss 0.71, Spatial_loss 2.83, Flat_loss 0.39, Train_acc 81.68, Test_acc 29.74
2025-02-15 12:56:01,385 [podnet.py] => Task 9, Epoch 52/160 (LR 0.07612) => LSC_loss 0.71, Spatial_loss 2.77, Flat_loss 0.38, Train_acc 81.91, Test_acc 31.08
2025-02-15 12:58:16,628 [podnet.py] => Task 9, Epoch 53/160 (LR 0.07528) => LSC_loss 0.72, Spatial_loss 2.81, Flat_loss 0.38, Train_acc 81.87, Test_acc 31.42
2025-02-15 13:00:33,324 [podnet.py] => Task 9, Epoch 54/160 (LR 0.07443) => LSC_loss 0.71, Spatial_loss 2.83, Flat_loss 0.39, Train_acc 82.07, Test_acc 29.84
2025-02-15 13:02:51,331 [podnet.py] => Task 9, Epoch 55/160 (LR 0.07357) => LSC_loss 0.70, Spatial_loss 2.78, Flat_loss 0.38, Train_acc 82.62, Test_acc 29.18
2025-02-15 13:05:07,921 [podnet.py] => Task 9, Epoch 56/160 (LR 0.07270) => LSC_loss 0.70, Spatial_loss 2.80, Flat_loss 0.38, Train_acc 82.53, Test_acc 32.46
2025-02-15 13:07:24,263 [podnet.py] => Task 9, Epoch 57/160 (LR 0.07182) => LSC_loss 0.70, Spatial_loss 2.76, Flat_loss 0.38, Train_acc 82.05, Test_acc 29.56
2025-02-15 13:09:41,312 [podnet.py] => Task 9, Epoch 58/160 (LR 0.07093) => LSC_loss 0.69, Spatial_loss 2.71, Flat_loss 0.38, Train_acc 82.58, Test_acc 26.60
2025-02-15 13:12:00,063 [podnet.py] => Task 9, Epoch 59/160 (LR 0.07004) => LSC_loss 0.69, Spatial_loss 2.75, Flat_loss 0.38, Train_acc 82.59, Test_acc 25.84
2025-02-15 13:14:18,933 [podnet.py] => Task 9, Epoch 60/160 (LR 0.06913) => LSC_loss 0.68, Spatial_loss 2.70, Flat_loss 0.37, Train_acc 82.99, Test_acc 30.14
2025-02-15 13:16:35,381 [podnet.py] => Task 9, Epoch 61/160 (LR 0.06822) => LSC_loss 0.69, Spatial_loss 2.74, Flat_loss 0.38, Train_acc 82.66, Test_acc 32.40
2025-02-15 13:18:57,283 [podnet.py] => Task 9, Epoch 62/160 (LR 0.06731) => LSC_loss 0.64, Spatial_loss 2.68, Flat_loss 0.37, Train_acc 84.01, Test_acc 29.28
2025-02-15 13:21:21,173 [podnet.py] => Task 9, Epoch 63/160 (LR 0.06638) => LSC_loss 0.69, Spatial_loss 2.70, Flat_loss 0.37, Train_acc 82.50, Test_acc 27.48
2025-02-15 13:23:53,441 [podnet.py] => Task 9, Epoch 64/160 (LR 0.06545) => LSC_loss 0.66, Spatial_loss 2.63, Flat_loss 0.37, Train_acc 83.61, Test_acc 29.92
2025-02-15 13:26:22,530 [podnet.py] => Task 9, Epoch 65/160 (LR 0.06451) => LSC_loss 0.66, Spatial_loss 2.66, Flat_loss 0.37, Train_acc 83.23, Test_acc 32.18
2025-02-15 13:28:48,229 [podnet.py] => Task 9, Epoch 66/160 (LR 0.06357) => LSC_loss 0.66, Spatial_loss 2.64, Flat_loss 0.37, Train_acc 83.58, Test_acc 31.56
2025-02-15 13:31:02,663 [podnet.py] => Task 9, Epoch 67/160 (LR 0.06262) => LSC_loss 0.66, Spatial_loss 2.67, Flat_loss 0.37, Train_acc 83.34, Test_acc 30.26
2025-02-15 13:33:14,273 [podnet.py] => Task 9, Epoch 68/160 (LR 0.06167) => LSC_loss 0.66, Spatial_loss 2.67, Flat_loss 0.37, Train_acc 83.43, Test_acc 31.06
2025-02-15 13:35:30,309 [podnet.py] => Task 9, Epoch 69/160 (LR 0.06072) => LSC_loss 0.66, Spatial_loss 2.63, Flat_loss 0.36, Train_acc 83.23, Test_acc 30.54
2025-02-15 13:37:46,699 [podnet.py] => Task 9, Epoch 70/160 (LR 0.05975) => LSC_loss 0.65, Spatial_loss 2.64, Flat_loss 0.36, Train_acc 83.74, Test_acc 32.54
2025-02-15 13:40:03,734 [podnet.py] => Task 9, Epoch 71/160 (LR 0.05879) => LSC_loss 0.66, Spatial_loss 2.58, Flat_loss 0.36, Train_acc 83.80, Test_acc 33.36
2025-02-15 13:42:21,270 [podnet.py] => Task 9, Epoch 72/160 (LR 0.05782) => LSC_loss 0.64, Spatial_loss 2.58, Flat_loss 0.36, Train_acc 84.26, Test_acc 32.88
2025-02-15 13:44:39,120 [podnet.py] => Task 9, Epoch 73/160 (LR 0.05685) => LSC_loss 0.64, Spatial_loss 2.58, Flat_loss 0.36, Train_acc 84.16, Test_acc 28.38
2025-02-15 13:46:54,928 [podnet.py] => Task 9, Epoch 74/160 (LR 0.05588) => LSC_loss 0.63, Spatial_loss 2.58, Flat_loss 0.36, Train_acc 84.43, Test_acc 31.12
2025-02-15 13:49:11,967 [podnet.py] => Task 9, Epoch 75/160 (LR 0.05490) => LSC_loss 0.63, Spatial_loss 2.58, Flat_loss 0.36, Train_acc 84.58, Test_acc 32.70
2025-02-15 13:51:30,848 [podnet.py] => Task 9, Epoch 76/160 (LR 0.05392) => LSC_loss 0.62, Spatial_loss 2.53, Flat_loss 0.35, Train_acc 84.80, Test_acc 33.02
2025-02-15 13:53:48,067 [podnet.py] => Task 9, Epoch 77/160 (LR 0.05294) => LSC_loss 0.63, Spatial_loss 2.57, Flat_loss 0.36, Train_acc 84.27, Test_acc 30.16
2025-02-15 13:56:13,785 [podnet.py] => Task 9, Epoch 78/160 (LR 0.05196) => LSC_loss 0.64, Spatial_loss 2.52, Flat_loss 0.35, Train_acc 84.03, Test_acc 31.50
2025-02-15 13:58:36,687 [podnet.py] => Task 9, Epoch 79/160 (LR 0.05098) => LSC_loss 0.61, Spatial_loss 2.50, Flat_loss 0.35, Train_acc 84.73, Test_acc 33.22
2025-02-15 14:00:52,641 [podnet.py] => Task 9, Epoch 80/160 (LR 0.05000) => LSC_loss 0.60, Spatial_loss 2.50, Flat_loss 0.35, Train_acc 85.57, Test_acc 31.40
2025-02-15 14:03:09,290 [podnet.py] => Task 9, Epoch 81/160 (LR 0.04902) => LSC_loss 0.61, Spatial_loss 2.43, Flat_loss 0.35, Train_acc 84.57, Test_acc 30.44
2025-02-15 14:05:25,877 [podnet.py] => Task 9, Epoch 82/160 (LR 0.04804) => LSC_loss 0.60, Spatial_loss 2.47, Flat_loss 0.35, Train_acc 85.45, Test_acc 33.38
2025-02-15 14:07:39,874 [podnet.py] => Task 9, Epoch 83/160 (LR 0.04706) => LSC_loss 0.62, Spatial_loss 2.46, Flat_loss 0.35, Train_acc 84.85, Test_acc 31.26
2025-02-15 14:09:55,837 [podnet.py] => Task 9, Epoch 84/160 (LR 0.04608) => LSC_loss 0.60, Spatial_loss 2.46, Flat_loss 0.34, Train_acc 85.50, Test_acc 34.02
2025-02-15 14:12:12,282 [podnet.py] => Task 9, Epoch 85/160 (LR 0.04510) => LSC_loss 0.57, Spatial_loss 2.41, Flat_loss 0.34, Train_acc 86.13, Test_acc 33.88
2025-02-15 14:14:28,609 [podnet.py] => Task 9, Epoch 86/160 (LR 0.04412) => LSC_loss 0.59, Spatial_loss 2.40, Flat_loss 0.34, Train_acc 85.72, Test_acc 29.90
2025-02-15 14:16:42,538 [podnet.py] => Task 9, Epoch 87/160 (LR 0.04315) => LSC_loss 0.58, Spatial_loss 2.39, Flat_loss 0.34, Train_acc 85.85, Test_acc 31.66
2025-02-15 14:18:56,875 [podnet.py] => Task 9, Epoch 88/160 (LR 0.04218) => LSC_loss 0.57, Spatial_loss 2.39, Flat_loss 0.34, Train_acc 86.43, Test_acc 29.10
2025-02-15 14:21:13,712 [podnet.py] => Task 9, Epoch 89/160 (LR 0.04121) => LSC_loss 0.57, Spatial_loss 2.38, Flat_loss 0.34, Train_acc 85.91, Test_acc 30.80
2025-02-15 14:23:32,712 [podnet.py] => Task 9, Epoch 90/160 (LR 0.04025) => LSC_loss 0.57, Spatial_loss 2.36, Flat_loss 0.33, Train_acc 86.28, Test_acc 34.54
2025-02-15 14:26:04,065 [podnet.py] => Task 9, Epoch 91/160 (LR 0.03928) => LSC_loss 0.57, Spatial_loss 2.36, Flat_loss 0.33, Train_acc 86.45, Test_acc 30.46
2025-02-15 14:28:37,647 [podnet.py] => Task 9, Epoch 92/160 (LR 0.03833) => LSC_loss 0.55, Spatial_loss 2.34, Flat_loss 0.33, Train_acc 86.87, Test_acc 32.82
2025-02-15 14:30:53,184 [podnet.py] => Task 9, Epoch 93/160 (LR 0.03738) => LSC_loss 0.54, Spatial_loss 2.30, Flat_loss 0.33, Train_acc 86.89, Test_acc 33.24
2025-02-15 14:33:06,433 [podnet.py] => Task 9, Epoch 94/160 (LR 0.03643) => LSC_loss 0.56, Spatial_loss 2.29, Flat_loss 0.33, Train_acc 86.53, Test_acc 33.16
2025-02-15 14:35:23,429 [podnet.py] => Task 9, Epoch 95/160 (LR 0.03549) => LSC_loss 0.54, Spatial_loss 2.31, Flat_loss 0.33, Train_acc 86.93, Test_acc 30.10
2025-02-15 14:37:38,710 [podnet.py] => Task 9, Epoch 96/160 (LR 0.03455) => LSC_loss 0.53, Spatial_loss 2.22, Flat_loss 0.32, Train_acc 87.36, Test_acc 32.30
2025-02-15 14:39:52,469 [podnet.py] => Task 9, Epoch 97/160 (LR 0.03362) => LSC_loss 0.52, Spatial_loss 2.25, Flat_loss 0.32, Train_acc 88.04, Test_acc 31.84
2025-02-15 14:42:10,494 [podnet.py] => Task 9, Epoch 98/160 (LR 0.03269) => LSC_loss 0.53, Spatial_loss 2.18, Flat_loss 0.31, Train_acc 87.44, Test_acc 33.08
2025-02-15 14:44:27,143 [podnet.py] => Task 9, Epoch 99/160 (LR 0.03178) => LSC_loss 0.53, Spatial_loss 2.21, Flat_loss 0.32, Train_acc 87.39, Test_acc 31.78
2025-02-15 14:46:45,848 [podnet.py] => Task 9, Epoch 100/160 (LR 0.03087) => LSC_loss 0.51, Spatial_loss 2.18, Flat_loss 0.31, Train_acc 87.68, Test_acc 32.20
2025-02-15 14:49:00,574 [podnet.py] => Task 9, Epoch 101/160 (LR 0.02996) => LSC_loss 0.51, Spatial_loss 2.20, Flat_loss 0.31, Train_acc 88.02, Test_acc 31.98
2025-02-15 14:51:14,451 [podnet.py] => Task 9, Epoch 102/160 (LR 0.02907) => LSC_loss 0.51, Spatial_loss 2.20, Flat_loss 0.31, Train_acc 87.77, Test_acc 35.20
2025-02-15 14:53:31,358 [podnet.py] => Task 9, Epoch 103/160 (LR 0.02818) => LSC_loss 0.51, Spatial_loss 2.14, Flat_loss 0.31, Train_acc 87.97, Test_acc 32.12
2025-02-15 14:55:50,019 [podnet.py] => Task 9, Epoch 104/160 (LR 0.02730) => LSC_loss 0.49, Spatial_loss 2.14, Flat_loss 0.31, Train_acc 88.82, Test_acc 32.48
2025-02-15 14:58:06,726 [podnet.py] => Task 9, Epoch 105/160 (LR 0.02643) => LSC_loss 0.50, Spatial_loss 2.09, Flat_loss 0.30, Train_acc 88.39, Test_acc 32.42
2025-02-15 15:00:21,885 [podnet.py] => Task 9, Epoch 106/160 (LR 0.02557) => LSC_loss 0.49, Spatial_loss 2.07, Flat_loss 0.30, Train_acc 88.55, Test_acc 33.72
2025-02-15 15:02:37,489 [podnet.py] => Task 9, Epoch 107/160 (LR 0.02472) => LSC_loss 0.50, Spatial_loss 2.08, Flat_loss 0.30, Train_acc 88.57, Test_acc 32.74
2025-02-15 15:04:51,930 [podnet.py] => Task 9, Epoch 108/160 (LR 0.02388) => LSC_loss 0.48, Spatial_loss 2.08, Flat_loss 0.30, Train_acc 88.95, Test_acc 34.08
2025-02-15 15:07:04,746 [podnet.py] => Task 9, Epoch 109/160 (LR 0.02304) => LSC_loss 0.48, Spatial_loss 2.04, Flat_loss 0.30, Train_acc 89.15, Test_acc 33.54
2025-02-15 15:09:24,207 [podnet.py] => Task 9, Epoch 110/160 (LR 0.02222) => LSC_loss 0.47, Spatial_loss 2.05, Flat_loss 0.30, Train_acc 89.16, Test_acc 31.70
2025-02-15 15:11:55,085 [podnet.py] => Task 9, Epoch 111/160 (LR 0.02141) => LSC_loss 0.45, Spatial_loss 1.97, Flat_loss 0.29, Train_acc 89.70, Test_acc 32.94
2025-02-15 15:14:21,228 [podnet.py] => Task 9, Epoch 112/160 (LR 0.02061) => LSC_loss 0.45, Spatial_loss 1.98, Flat_loss 0.29, Train_acc 89.66, Test_acc 32.66
2025-02-15 15:16:42,921 [podnet.py] => Task 9, Epoch 113/160 (LR 0.01982) => LSC_loss 0.46, Spatial_loss 2.00, Flat_loss 0.29, Train_acc 89.40, Test_acc 31.58
2025-02-15 15:19:00,648 [podnet.py] => Task 9, Epoch 114/160 (LR 0.01905) => LSC_loss 0.44, Spatial_loss 1.92, Flat_loss 0.29, Train_acc 89.93, Test_acc 32.30
2025-02-15 15:21:10,837 [podnet.py] => Task 9, Epoch 115/160 (LR 0.01828) => LSC_loss 0.45, Spatial_loss 1.93, Flat_loss 0.29, Train_acc 89.90, Test_acc 32.28
2025-02-15 15:23:25,895 [podnet.py] => Task 9, Epoch 116/160 (LR 0.01753) => LSC_loss 0.44, Spatial_loss 1.92, Flat_loss 0.28, Train_acc 90.31, Test_acc 35.06
2025-02-15 15:25:43,822 [podnet.py] => Task 9, Epoch 117/160 (LR 0.01679) => LSC_loss 0.43, Spatial_loss 1.91, Flat_loss 0.28, Train_acc 90.53, Test_acc 31.98
2025-02-15 15:27:59,452 [podnet.py] => Task 9, Epoch 118/160 (LR 0.01606) => LSC_loss 0.43, Spatial_loss 1.87, Flat_loss 0.28, Train_acc 90.36, Test_acc 34.80
2025-02-15 15:30:09,167 [podnet.py] => Task 9, Epoch 119/160 (LR 0.01535) => LSC_loss 0.43, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 90.72, Test_acc 35.06
2025-02-15 15:32:25,876 [podnet.py] => Task 9, Epoch 120/160 (LR 0.01464) => LSC_loss 0.41, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 91.01, Test_acc 33.64
2025-02-15 15:34:44,045 [podnet.py] => Task 9, Epoch 121/160 (LR 0.01396) => LSC_loss 0.42, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 90.54, Test_acc 35.56
2025-02-15 15:36:59,205 [podnet.py] => Task 9, Epoch 122/160 (LR 0.01328) => LSC_loss 0.40, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 91.09, Test_acc 35.60
2025-02-15 15:39:14,590 [podnet.py] => Task 9, Epoch 123/160 (LR 0.01262) => LSC_loss 0.40, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 91.45, Test_acc 34.84
2025-02-15 15:41:30,180 [podnet.py] => Task 9, Epoch 124/160 (LR 0.01198) => LSC_loss 0.40, Spatial_loss 1.77, Flat_loss 0.27, Train_acc 91.12, Test_acc 33.02
2025-02-15 15:43:49,622 [podnet.py] => Task 9, Epoch 125/160 (LR 0.01135) => LSC_loss 0.39, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 91.35, Test_acc 34.30
2025-02-15 15:46:05,801 [podnet.py] => Task 9, Epoch 126/160 (LR 0.01073) => LSC_loss 0.40, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 91.57, Test_acc 35.56
2025-02-15 15:48:22,344 [podnet.py] => Task 9, Epoch 127/160 (LR 0.01013) => LSC_loss 0.39, Spatial_loss 1.73, Flat_loss 0.26, Train_acc 91.99, Test_acc 34.10
2025-02-15 15:50:39,949 [podnet.py] => Task 9, Epoch 128/160 (LR 0.00955) => LSC_loss 0.39, Spatial_loss 1.69, Flat_loss 0.26, Train_acc 91.76, Test_acc 34.50
2025-02-15 15:52:49,676 [podnet.py] => Task 9, Epoch 129/160 (LR 0.00898) => LSC_loss 0.39, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 91.87, Test_acc 35.20
2025-02-15 15:55:07,250 [podnet.py] => Task 9, Epoch 130/160 (LR 0.00843) => LSC_loss 0.39, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 91.75, Test_acc 35.30
2025-02-15 15:57:25,801 [podnet.py] => Task 9, Epoch 131/160 (LR 0.00789) => LSC_loss 0.36, Spatial_loss 1.61, Flat_loss 0.26, Train_acc 92.35, Test_acc 33.84
2025-02-15 15:59:42,687 [podnet.py] => Task 9, Epoch 132/160 (LR 0.00737) => LSC_loss 0.37, Spatial_loss 1.63, Flat_loss 0.25, Train_acc 92.44, Test_acc 35.22
2025-02-15 16:01:59,761 [podnet.py] => Task 9, Epoch 133/160 (LR 0.00686) => LSC_loss 0.35, Spatial_loss 1.61, Flat_loss 0.25, Train_acc 92.89, Test_acc 35.04
2025-02-15 16:04:17,761 [podnet.py] => Task 9, Epoch 134/160 (LR 0.00638) => LSC_loss 0.36, Spatial_loss 1.56, Flat_loss 0.25, Train_acc 92.34, Test_acc 34.80
2025-02-15 16:06:36,799 [podnet.py] => Task 9, Epoch 135/160 (LR 0.00590) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.25, Train_acc 92.67, Test_acc 34.48
2025-02-15 16:08:55,116 [podnet.py] => Task 9, Epoch 136/160 (LR 0.00545) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.25, Train_acc 93.14, Test_acc 34.90
2025-02-15 16:11:08,288 [podnet.py] => Task 9, Epoch 137/160 (LR 0.00501) => LSC_loss 0.35, Spatial_loss 1.53, Flat_loss 0.25, Train_acc 92.88, Test_acc 35.80
2025-02-15 16:13:29,939 [podnet.py] => Task 9, Epoch 138/160 (LR 0.00459) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.24, Train_acc 92.95, Test_acc 35.02
2025-02-15 16:15:48,285 [podnet.py] => Task 9, Epoch 139/160 (LR 0.00419) => LSC_loss 0.35, Spatial_loss 1.50, Flat_loss 0.24, Train_acc 92.87, Test_acc 35.46
2025-02-15 16:18:05,652 [podnet.py] => Task 9, Epoch 140/160 (LR 0.00381) => LSC_loss 0.36, Spatial_loss 1.49, Flat_loss 0.24, Train_acc 92.56, Test_acc 34.84
2025-02-15 16:20:22,424 [podnet.py] => Task 9, Epoch 141/160 (LR 0.00344) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.24, Train_acc 93.20, Test_acc 35.38
2025-02-15 16:22:40,304 [podnet.py] => Task 9, Epoch 142/160 (LR 0.00309) => LSC_loss 0.33, Spatial_loss 1.49, Flat_loss 0.24, Train_acc 93.37, Test_acc 34.48
2025-02-15 16:24:50,675 [podnet.py] => Task 9, Epoch 143/160 (LR 0.00276) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 93.09, Test_acc 36.10
2025-02-15 16:27:07,259 [podnet.py] => Task 9, Epoch 144/160 (LR 0.00245) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 93.54, Test_acc 35.84
2025-02-15 16:29:23,869 [podnet.py] => Task 9, Epoch 145/160 (LR 0.00215) => LSC_loss 0.32, Spatial_loss 1.42, Flat_loss 0.24, Train_acc 93.60, Test_acc 36.30
2025-02-15 16:31:41,276 [podnet.py] => Task 9, Epoch 146/160 (LR 0.00188) => LSC_loss 0.32, Spatial_loss 1.40, Flat_loss 0.24, Train_acc 93.45, Test_acc 35.34
2025-02-15 16:33:56,562 [podnet.py] => Task 9, Epoch 147/160 (LR 0.00162) => LSC_loss 0.33, Spatial_loss 1.40, Flat_loss 0.23, Train_acc 93.40, Test_acc 36.32
2025-02-15 16:36:14,468 [podnet.py] => Task 9, Epoch 148/160 (LR 0.00138) => LSC_loss 0.32, Spatial_loss 1.40, Flat_loss 0.23, Train_acc 93.62, Test_acc 36.34
2025-02-15 16:38:27,728 [podnet.py] => Task 9, Epoch 149/160 (LR 0.00116) => LSC_loss 0.32, Spatial_loss 1.38, Flat_loss 0.23, Train_acc 93.54, Test_acc 36.16
2025-02-15 16:40:44,252 [podnet.py] => Task 9, Epoch 150/160 (LR 0.00096) => LSC_loss 0.32, Spatial_loss 1.38, Flat_loss 0.23, Train_acc 93.72, Test_acc 36.48
2025-02-15 16:43:00,915 [podnet.py] => Task 9, Epoch 151/160 (LR 0.00078) => LSC_loss 0.32, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 93.93, Test_acc 36.10
2025-02-15 16:45:16,675 [podnet.py] => Task 9, Epoch 152/160 (LR 0.00062) => LSC_loss 0.32, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 93.75, Test_acc 36.48
2025-02-15 16:47:34,115 [podnet.py] => Task 9, Epoch 153/160 (LR 0.00047) => LSC_loss 0.31, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 93.95, Test_acc 35.70
2025-02-15 16:49:50,100 [podnet.py] => Task 9, Epoch 154/160 (LR 0.00035) => LSC_loss 0.31, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 94.16, Test_acc 36.02
2025-02-15 16:52:06,715 [podnet.py] => Task 9, Epoch 155/160 (LR 0.00024) => LSC_loss 0.32, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 93.86, Test_acc 35.92
2025-02-15 16:54:20,824 [podnet.py] => Task 9, Epoch 156/160 (LR 0.00015) => LSC_loss 0.30, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 94.16, Test_acc 36.08
2025-02-15 16:56:34,130 [podnet.py] => Task 9, Epoch 157/160 (LR 0.00009) => LSC_loss 0.32, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 93.82, Test_acc 36.08
2025-02-15 16:58:49,762 [podnet.py] => Task 9, Epoch 158/160 (LR 0.00004) => LSC_loss 0.32, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 93.93, Test_acc 35.82
2025-02-15 17:01:05,226 [podnet.py] => Task 9, Epoch 159/160 (LR 0.00001) => LSC_loss 0.31, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 93.98, Test_acc 36.20
2025-02-15 17:03:24,431 [podnet.py] => Task 9, Epoch 160/160 (LR 0.00000) => LSC_loss 0.33, Spatial_loss 1.32, Flat_loss 0.23, Train_acc 93.59, Test_acc 36.14
2025-02-15 17:03:24,433 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 17:03:24,433 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 17:06:44,108 [podnet.py] => The size of finetune dataset: 2000
2025-02-15 17:07:33,732 [podnet.py] => Task 9, Epoch 1/20 (LR 0.00497) => LSC_loss 0.51, Spatial_loss 1.64, Flat_loss 0.19, Train_acc 88.95, Test_acc 45.30
2025-02-15 17:08:16,339 [podnet.py] => Task 9, Epoch 2/20 (LR 0.00488) => LSC_loss 0.37, Spatial_loss 1.53, Flat_loss 0.14, Train_acc 92.55, Test_acc 46.04
2025-02-15 17:09:01,860 [podnet.py] => Task 9, Epoch 3/20 (LR 0.00473) => LSC_loss 0.32, Spatial_loss 1.49, Flat_loss 0.13, Train_acc 93.80, Test_acc 44.62
2025-02-15 17:09:48,161 [podnet.py] => Task 9, Epoch 4/20 (LR 0.00452) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.13, Train_acc 94.25, Test_acc 44.22
2025-02-15 17:10:33,645 [podnet.py] => Task 9, Epoch 5/20 (LR 0.00427) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.13, Train_acc 93.45, Test_acc 45.00
2025-02-15 17:11:19,984 [podnet.py] => Task 9, Epoch 6/20 (LR 0.00397) => LSC_loss 0.34, Spatial_loss 1.45, Flat_loss 0.13, Train_acc 93.15, Test_acc 44.12
2025-02-15 17:12:04,022 [podnet.py] => Task 9, Epoch 7/20 (LR 0.00363) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.13, Train_acc 94.55, Test_acc 44.68
2025-02-15 17:12:50,538 [podnet.py] => Task 9, Epoch 8/20 (LR 0.00327) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 94.75, Test_acc 43.96
2025-02-15 17:13:35,597 [podnet.py] => Task 9, Epoch 9/20 (LR 0.00289) => LSC_loss 0.32, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 94.05, Test_acc 44.74
2025-02-15 17:14:21,717 [podnet.py] => Task 9, Epoch 10/20 (LR 0.00250) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.12, Train_acc 93.40, Test_acc 44.48
2025-02-15 17:15:08,310 [podnet.py] => Task 9, Epoch 11/20 (LR 0.00211) => LSC_loss 0.31, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 94.35, Test_acc 44.98
2025-02-15 17:15:55,004 [podnet.py] => Task 9, Epoch 12/20 (LR 0.00173) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.12, Train_acc 94.55, Test_acc 44.42
2025-02-15 17:16:42,935 [podnet.py] => Task 9, Epoch 13/20 (LR 0.00137) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.12, Train_acc 94.35, Test_acc 44.66
2025-02-15 17:17:29,027 [podnet.py] => Task 9, Epoch 14/20 (LR 0.00103) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.12, Train_acc 94.30, Test_acc 44.38
2025-02-15 17:18:12,026 [podnet.py] => Task 9, Epoch 15/20 (LR 0.00073) => LSC_loss 0.30, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 94.30, Test_acc 44.80
2025-02-15 17:18:57,157 [podnet.py] => Task 9, Epoch 16/20 (LR 0.00048) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.12, Train_acc 94.00, Test_acc 44.76
2025-02-15 17:19:43,872 [podnet.py] => Task 9, Epoch 17/20 (LR 0.00027) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.12, Train_acc 94.15, Test_acc 44.80
2025-02-15 17:20:32,191 [podnet.py] => Task 9, Epoch 18/20 (LR 0.00012) => LSC_loss 0.27, Spatial_loss 1.40, Flat_loss 0.12, Train_acc 95.30, Test_acc 44.38
2025-02-15 17:21:18,052 [podnet.py] => Task 9, Epoch 19/20 (LR 0.00003) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.12, Train_acc 94.10, Test_acc 44.56
2025-02-15 17:22:03,302 [podnet.py] => Task 9, Epoch 20/20 (LR 0.00000) => LSC_loss 0.26, Spatial_loss 1.35, Flat_loss 0.11, Train_acc 95.20, Test_acc 44.54
2025-02-15 17:22:03,304 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 17:26:16,481 [podnet.py] => Exemplar size: 2000
2025-02-15 17:26:16,482 [trainer.py] => CNN: {'total': 44.54, '00-09': 49.8, '10-19': 24.6, '20-29': 24.8, '30-39': 36.4, '40-49': 35.2, '50-59': 48.2, '60-69': 44.4, '70-79': 51.0, '80-89': 58.4, '90-99': 72.6, 'old': 41.42, 'new': 72.6}
2025-02-15 17:26:16,482 [trainer.py] => NME: {'total': 41.66, '00-09': 56.8, '10-19': 19.4, '20-29': 20.0, '30-39': 30.2, '40-49': 28.6, '50-59': 41.6, '60-69': 40.2, '70-79': 49.4, '80-89': 57.2, '90-99': 73.2, 'old': 38.16, 'new': 73.2}
2025-02-15 17:26:16,482 [trainer.py] => CNN top1 curve: [89.6, 81.0, 69.2, 61.1, 57.28, 54.43, 50.29, 48.18, 45.8, 44.54]
2025-02-15 17:26:16,482 [trainer.py] => CNN top5 curve: [99.4, 95.7, 91.33, 85.7, 82.4, 78.4, 76.91, 74.62, 73.16, 70.92]
2025-02-15 17:26:16,483 [trainer.py] => NME top1 curve: [90.0, 79.8, 65.47, 56.5, 52.6, 49.87, 46.71, 44.32, 42.82, 41.66]
2025-02-15 17:26:16,483 [trainer.py] => NME top5 curve: [99.4, 94.7, 90.67, 83.1, 78.6, 75.07, 72.89, 68.88, 68.16, 66.02]

2025-02-15 17:26:16,483 [trainer.py] => Average Accuracy (CNN): 60.14200000000001
2025-02-15 17:26:16,483 [trainer.py] => Average Accuracy (NME): 56.975