2025-02-14 22:23:20,229 [trainer.py] => config: ./exps/podnet.json
2025-02-14 22:23:20,230 [trainer.py] => prefix: reproduce
2025-02-14 22:23:20,231 [trainer.py] => dataset: cifar100
2025-02-14 22:23:20,231 [trainer.py] => memory_size: 2000
2025-02-14 22:23:20,232 [trainer.py] => memory_per_class: 20
2025-02-14 22:23:20,232 [trainer.py] => fixed_memory: True
2025-02-14 22:23:20,233 [trainer.py] => shuffle: True
2025-02-14 22:23:20,233 [trainer.py] => init_cls: 5
2025-02-14 22:23:20,233 [trainer.py] => increment: 5
2025-02-14 22:23:20,234 [trainer.py] => model_name: podnet
2025-02-14 22:23:20,234 [trainer.py] => convnet_type: cosine_resnet32
2025-02-14 22:23:20,234 [trainer.py] => device: [device(type='cuda', index=0)]
2025-02-14 22:23:20,235 [trainer.py] => seed: 1993
2025-02-14 22:23:22,268 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-02-14 22:23:25,056 [trainer.py] => All params: 466256
2025-02-14 22:23:25,056 [trainer.py] => Trainable params: 466256
2025-02-14 22:23:25,056 [podnet.py] => Learning on 0-5
2025-02-14 22:23:25,060 [podnet.py] => Adaptive factor: 0
2025-02-14 22:23:28,180 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 1.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 23.76, Test_acc 39.00
2025-02-14 22:23:29,337 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 1.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 40.32, Test_acc 41.20
2025-02-14 22:23:30,444 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 1.40, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 47.48, Test_acc 51.20
2025-02-14 22:23:31,595 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 1.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 55.84, Test_acc 51.20
2025-02-14 22:23:32,746 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 1.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 63.28, Test_acc 46.40
2025-02-14 22:23:33,920 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.16, Test_acc 60.00
2025-02-14 22:23:35,071 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 70.48, Test_acc 74.40
2025-02-14 22:23:36,192 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.44, Test_acc 64.60
2025-02-14 22:23:37,334 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.56, Test_acc 73.60
2025-02-14 22:23:38,538 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.36, Test_acc 75.40
2025-02-14 22:23:39,645 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.76, Test_acc 78.20
2025-02-14 22:23:40,798 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.92, Test_acc 82.00
2025-02-14 22:23:41,912 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 0.50, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.68, Test_acc 82.80
2025-02-14 22:23:43,049 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.40, Test_acc 77.60
2025-02-14 22:23:44,228 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.32, Test_acc 84.60
2025-02-14 22:23:45,346 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.60, Test_acc 82.00
2025-02-14 22:23:46,494 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.76, Test_acc 76.80
2025-02-14 22:23:47,635 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.48, Test_acc 77.60
2025-02-14 22:23:48,794 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.64, Test_acc 81.80
2025-02-14 22:23:49,935 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.72, Test_acc 84.00
2025-02-14 22:23:51,086 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 0.33, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.80, Test_acc 87.00
2025-02-14 22:23:52,216 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.44, Test_acc 80.80
2025-02-14 22:23:53,352 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.60, Test_acc 85.80
2025-02-14 22:23:54,506 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.76, Test_acc 86.00
2025-02-14 22:23:55,677 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.52, Test_acc 90.40
2025-02-14 22:23:56,825 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.04, Test_acc 86.80
2025-02-14 22:23:57,924 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.24, Test_acc 86.20
2025-02-14 22:23:59,106 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.16, Test_acc 84.00
2025-02-14 22:24:00,275 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.36, Test_acc 81.20
2025-02-14 22:24:01,475 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.68, Test_acc 88.60
2025-02-14 22:24:02,672 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.96, Test_acc 89.00
2025-02-14 22:24:03,801 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 0.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.88, Test_acc 89.40
2025-02-14 22:24:04,963 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.52, Test_acc 92.40
2025-02-14 22:24:06,090 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.20, Test_acc 87.20
2025-02-14 22:24:07,227 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.44, Test_acc 80.20
2025-02-14 22:24:08,373 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.84, Test_acc 89.40
2025-02-14 22:24:09,527 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.32, Test_acc 93.00
2025-02-14 22:24:10,679 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.84, Test_acc 90.80
2025-02-14 22:24:11,838 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.12, Test_acc 90.00
2025-02-14 22:24:12,985 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.52, Test_acc 92.20
2025-02-14 22:24:14,156 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.92, Test_acc 84.20
2025-02-14 22:24:15,355 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.28, Test_acc 85.40
2025-02-14 22:24:16,551 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.68, Test_acc 88.00
2025-02-14 22:24:17,753 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.00, Test_acc 93.80
2025-02-14 22:24:18,873 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.76, Test_acc 92.40
2025-02-14 22:24:19,992 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.04, Test_acc 94.60
2025-02-14 22:24:21,173 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.32, Test_acc 92.40
2025-02-14 22:24:22,298 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.68, Test_acc 93.60
2025-02-14 22:24:23,451 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.64, Test_acc 94.40
2025-02-14 22:24:24,618 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.96, Test_acc 95.40
2025-02-14 22:24:25,804 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.04, Test_acc 91.00
2025-02-14 22:24:26,974 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.36, Test_acc 93.80
2025-02-14 22:24:28,157 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.28, Test_acc 92.80
2025-02-14 22:24:29,314 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.32, Test_acc 94.20
2025-02-14 22:24:30,512 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.44, Test_acc 93.20
2025-02-14 22:24:31,671 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.00, Test_acc 95.20
2025-02-14 22:24:32,840 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.76, Test_acc 95.40
2025-02-14 22:24:33,985 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.64, Test_acc 94.60
2025-02-14 22:24:35,181 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.96, Test_acc 90.20
2025-02-14 22:24:36,361 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.44, Test_acc 88.80
2025-02-14 22:24:37,558 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.72, Test_acc 93.00
2025-02-14 22:24:38,728 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.68, Test_acc 90.00
2025-02-14 22:24:39,886 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.12, Test_acc 88.00
2025-02-14 22:24:41,067 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 94.80
2025-02-14 22:24:42,201 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.68, Test_acc 92.60
2025-02-14 22:24:43,373 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.68, Test_acc 96.00
2025-02-14 22:24:44,586 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.76, Test_acc 93.40
2025-02-14 22:24:45,740 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.04, Test_acc 95.00
2025-02-14 22:24:46,884 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 93.80
2025-02-14 22:24:48,045 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 93.80
2025-02-14 22:24:49,180 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.92, Test_acc 96.20
2025-02-14 22:24:50,349 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 95.40
2025-02-14 22:24:51,514 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.28, Test_acc 95.60
2025-02-14 22:24:52,685 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.84, Test_acc 94.60
2025-02-14 22:24:53,860 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.16, Test_acc 94.40
2025-02-14 22:24:55,061 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.04, Test_acc 94.20
2025-02-14 22:24:56,208 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 94.40
2025-02-14 22:24:57,378 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 95.60
2025-02-14 22:24:58,508 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 95.60
2025-02-14 22:24:59,667 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.08, Test_acc 95.40
2025-02-14 22:25:00,846 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 96.80
2025-02-14 22:25:01,954 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 89.60
2025-02-14 22:25:03,116 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 96.00
2025-02-14 22:25:04,211 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.84, Test_acc 96.00
2025-02-14 22:25:05,396 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 95.60
2025-02-14 22:25:06,593 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 96.20
2025-02-14 22:25:07,827 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.24, Test_acc 94.80
2025-02-14 22:25:08,971 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 95.40
2025-02-14 22:25:10,125 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 94.60
2025-02-14 22:25:11,262 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 94.80
2025-02-14 22:25:12,496 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 95.80
2025-02-14 22:25:13,726 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 95.80
2025-02-14 22:25:14,924 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 96.60
2025-02-14 22:25:16,054 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 96.40
2025-02-14 22:25:17,248 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 95.60
2025-02-14 22:25:18,443 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 95.00
2025-02-14 22:25:19,540 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.48, Test_acc 97.20
2025-02-14 22:25:20,675 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 94.60
2025-02-14 22:25:21,794 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 96.40
2025-02-14 22:25:22,946 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 96.80
2025-02-14 22:25:24,080 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 96.60
2025-02-14 22:25:25,225 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 97.20
2025-02-14 22:25:26,373 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 97.00
2025-02-14 22:25:27,578 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 97.40
2025-02-14 22:25:28,690 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 97.20
2025-02-14 22:25:29,884 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 96.60
2025-02-14 22:25:31,061 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 96.80
2025-02-14 22:25:32,223 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.60
2025-02-14 22:25:33,346 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 97.40
2025-02-14 22:25:34,477 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.76, Test_acc 96.60
2025-02-14 22:25:35,605 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 96.60
2025-02-14 22:25:36,756 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:25:37,929 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.20
2025-02-14 22:25:39,103 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.20
2025-02-14 22:25:40,203 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 97.00
2025-02-14 22:25:41,339 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.72, Test_acc 96.80
2025-02-14 22:25:42,435 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.76, Test_acc 97.20
2025-02-14 22:25:43,594 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.84, Test_acc 96.40
2025-02-14 22:25:44,740 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:25:45,916 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:25:47,038 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:25:48,182 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 97.20
2025-02-14 22:25:49,362 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:25:50,511 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:25:51,655 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.84, Test_acc 97.20
2025-02-14 22:25:52,803 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:25:53,978 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:25:55,167 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.80
2025-02-14 22:25:56,359 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 96.80
2025-02-14 22:25:57,519 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.20
2025-02-14 22:25:58,640 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:25:59,802 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.20
2025-02-14 22:26:00,994 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.84, Test_acc 97.20
2025-02-14 22:26:02,167 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:26:03,354 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:26:04,553 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.40
2025-02-14 22:26:05,722 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.60
2025-02-14 22:26:06,854 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:26:08,066 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:26:09,247 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 96.40
2025-02-14 22:26:10,437 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.60
2025-02-14 22:26:11,604 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.60
2025-02-14 22:26:12,747 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.84, Test_acc 96.80
2025-02-14 22:26:13,933 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 96.60
2025-02-14 22:26:15,123 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.80
2025-02-14 22:26:16,304 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 96.80
2025-02-14 22:26:17,469 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.80
2025-02-14 22:26:18,613 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.60
2025-02-14 22:26:19,761 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:26:20,887 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:26:22,007 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:26:23,175 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.80
2025-02-14 22:26:24,328 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:26:25,467 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 97.00
2025-02-14 22:26:26,600 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.80
2025-02-14 22:26:27,768 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 96.60
2025-02-14 22:26:28,932 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:26:30,115 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 97.00
2025-02-14 22:26:31,314 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 96.80
2025-02-14 22:26:32,456 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 96.80
2025-02-14 22:26:32,456 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:26:36,853 [podnet.py] => Exemplar size: 100
2025-02-14 22:26:36,853 [trainer.py] => CNN: {'total': 96.8, '00-09': 96.8, 'old': 0, 'new': 96.8}
2025-02-14 22:26:36,853 [trainer.py] => NME: {'total': 96.8, '00-09': 96.8, 'old': 0, 'new': 96.8}
2025-02-14 22:26:36,853 [trainer.py] => CNN top1 curve: [96.8]
2025-02-14 22:26:36,853 [trainer.py] => CNN top5 curve: [100.0]
2025-02-14 22:26:36,853 [trainer.py] => NME top1 curve: [96.8]
2025-02-14 22:26:36,853 [trainer.py] => NME top5 curve: [100.0]

2025-02-14 22:26:36,853 [trainer.py] => Average Accuracy (CNN): 96.8
2025-02-14 22:26:36,853 [trainer.py] => Average Accuracy (NME): 96.8
2025-02-14 22:26:36,854 [trainer.py] => All params: 469457
2025-02-14 22:26:36,854 [trainer.py] => Trainable params: 469457
2025-02-14 22:26:36,854 [podnet.py] => Learning on 5-10
2025-02-14 22:26:36,875 [podnet.py] => Adaptive factor: 1.4142135623730951
2025-02-14 22:26:38,365 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 2.45, Spatial_loss 2.13, Flat_loss 0.51, Train_acc 33.08, Test_acc 38.70
2025-02-14 22:26:39,743 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 1.36, Spatial_loss 1.70, Flat_loss 0.41, Train_acc 54.42, Test_acc 54.20
2025-02-14 22:26:41,133 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 1.21, Spatial_loss 1.52, Flat_loss 0.34, Train_acc 59.12, Test_acc 60.70
2025-02-14 22:26:42,465 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 1.10, Spatial_loss 1.47, Flat_loss 0.33, Train_acc 63.69, Test_acc 66.30
2025-02-14 22:26:43,875 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 1.00, Spatial_loss 1.50, Flat_loss 0.34, Train_acc 67.08, Test_acc 58.80
2025-02-14 22:26:45,217 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 0.92, Spatial_loss 1.54, Flat_loss 0.35, Train_acc 70.69, Test_acc 65.10
2025-02-14 22:26:46,620 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 0.89, Spatial_loss 1.50, Flat_loss 0.34, Train_acc 71.27, Test_acc 64.50
2025-02-14 22:26:48,014 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 0.83, Spatial_loss 1.45, Flat_loss 0.35, Train_acc 73.46, Test_acc 65.70
2025-02-14 22:26:49,382 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 0.79, Spatial_loss 1.42, Flat_loss 0.34, Train_acc 75.58, Test_acc 66.20
2025-02-14 22:26:50,724 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 0.77, Spatial_loss 1.41, Flat_loss 0.34, Train_acc 76.96, Test_acc 66.00
2025-02-14 22:26:52,014 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 0.75, Spatial_loss 1.40, Flat_loss 0.34, Train_acc 76.42, Test_acc 71.40
2025-02-14 22:26:53,358 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.70, Spatial_loss 1.35, Flat_loss 0.34, Train_acc 79.27, Test_acc 61.30
2025-02-14 22:26:54,746 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.67, Spatial_loss 1.39, Flat_loss 0.34, Train_acc 79.77, Test_acc 63.90
2025-02-14 22:26:56,089 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.70, Spatial_loss 1.40, Flat_loss 0.34, Train_acc 79.04, Test_acc 61.80
2025-02-14 22:26:57,399 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.67, Spatial_loss 1.42, Flat_loss 0.35, Train_acc 79.23, Test_acc 64.30
2025-02-14 22:26:58,685 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.64, Spatial_loss 1.43, Flat_loss 0.35, Train_acc 81.38, Test_acc 64.90
2025-02-14 22:27:00,101 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.64, Spatial_loss 1.37, Flat_loss 0.35, Train_acc 80.58, Test_acc 63.30
2025-02-14 22:27:01,469 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.61, Spatial_loss 1.37, Flat_loss 0.34, Train_acc 82.15, Test_acc 64.60
2025-02-14 22:27:02,816 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.59, Spatial_loss 1.33, Flat_loss 0.34, Train_acc 83.08, Test_acc 68.60
2025-02-14 22:27:04,199 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.58, Spatial_loss 1.33, Flat_loss 0.35, Train_acc 82.96, Test_acc 66.30
2025-02-14 22:27:05,548 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.57, Spatial_loss 1.33, Flat_loss 0.34, Train_acc 82.42, Test_acc 68.40
2025-02-14 22:27:06,875 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.56, Spatial_loss 1.34, Flat_loss 0.34, Train_acc 83.69, Test_acc 65.50
2025-02-14 22:27:08,284 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.56, Spatial_loss 1.31, Flat_loss 0.34, Train_acc 83.77, Test_acc 61.20
2025-02-14 22:27:09,623 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.51, Spatial_loss 1.36, Flat_loss 0.35, Train_acc 84.96, Test_acc 60.30
2025-02-14 22:27:11,036 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.56, Spatial_loss 1.32, Flat_loss 0.34, Train_acc 84.38, Test_acc 69.90
2025-02-14 22:27:12,441 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.53, Spatial_loss 1.42, Flat_loss 0.36, Train_acc 83.81, Test_acc 61.30
2025-02-14 22:27:13,796 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.49, Spatial_loss 1.36, Flat_loss 0.35, Train_acc 85.85, Test_acc 63.80
2025-02-14 22:27:15,142 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.46, Spatial_loss 1.35, Flat_loss 0.35, Train_acc 87.19, Test_acc 71.20
2025-02-14 22:27:16,516 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.45, Spatial_loss 1.29, Flat_loss 0.33, Train_acc 87.42, Test_acc 65.40
2025-02-14 22:27:17,912 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.47, Spatial_loss 1.26, Flat_loss 0.33, Train_acc 86.00, Test_acc 70.10
2025-02-14 22:27:19,283 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.46, Spatial_loss 1.31, Flat_loss 0.34, Train_acc 86.77, Test_acc 67.10
2025-02-14 22:27:20,734 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.43, Spatial_loss 1.32, Flat_loss 0.34, Train_acc 88.08, Test_acc 68.90
2025-02-14 22:27:22,143 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.45, Spatial_loss 1.33, Flat_loss 0.35, Train_acc 87.46, Test_acc 65.90
2025-02-14 22:27:23,542 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.45, Spatial_loss 1.32, Flat_loss 0.34, Train_acc 85.77, Test_acc 69.60
2025-02-14 22:27:24,963 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.45, Spatial_loss 1.31, Flat_loss 0.34, Train_acc 87.04, Test_acc 68.60
2025-02-14 22:27:26,302 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.45, Spatial_loss 1.32, Flat_loss 0.34, Train_acc 86.69, Test_acc 67.60
2025-02-14 22:27:27,745 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.40, Spatial_loss 1.23, Flat_loss 0.33, Train_acc 88.92, Test_acc 72.70
2025-02-14 22:27:29,085 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.40, Spatial_loss 1.27, Flat_loss 0.35, Train_acc 88.19, Test_acc 70.10
2025-02-14 22:27:30,503 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.40, Spatial_loss 1.24, Flat_loss 0.34, Train_acc 88.73, Test_acc 71.00
2025-02-14 22:27:31,871 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.39, Spatial_loss 1.24, Flat_loss 0.34, Train_acc 89.35, Test_acc 69.80
2025-02-14 22:27:33,235 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.39, Spatial_loss 1.30, Flat_loss 0.34, Train_acc 88.46, Test_acc 65.30
2025-02-14 22:27:34,566 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.41, Spatial_loss 1.35, Flat_loss 0.34, Train_acc 88.00, Test_acc 63.60
2025-02-14 22:27:35,923 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.38, Spatial_loss 1.26, Flat_loss 0.33, Train_acc 89.35, Test_acc 66.20
2025-02-14 22:27:37,248 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.35, Spatial_loss 1.29, Flat_loss 0.34, Train_acc 90.54, Test_acc 65.00
2025-02-14 22:27:38,600 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.38, Spatial_loss 1.26, Flat_loss 0.34, Train_acc 88.96, Test_acc 66.10
2025-02-14 22:27:40,012 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.34, Spatial_loss 1.20, Flat_loss 0.33, Train_acc 90.77, Test_acc 70.20
2025-02-14 22:27:41,402 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.33, Train_acc 91.65, Test_acc 69.30
2025-02-14 22:27:42,757 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.35, Spatial_loss 1.22, Flat_loss 0.33, Train_acc 90.50, Test_acc 61.40
2025-02-14 22:27:44,150 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.35, Spatial_loss 1.25, Flat_loss 0.34, Train_acc 90.81, Test_acc 74.00
2025-02-14 22:27:45,530 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.38, Spatial_loss 1.28, Flat_loss 0.34, Train_acc 89.19, Test_acc 62.20
2025-02-14 22:27:46,867 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.38, Spatial_loss 1.31, Flat_loss 0.33, Train_acc 89.54, Test_acc 73.40
2025-02-14 22:27:48,206 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.36, Spatial_loss 1.29, Flat_loss 0.33, Train_acc 89.96, Test_acc 74.80
2025-02-14 22:27:49,557 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.31, Spatial_loss 1.22, Flat_loss 0.33, Train_acc 91.62, Test_acc 70.30
2025-02-14 22:27:50,919 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.33, Spatial_loss 1.18, Flat_loss 0.33, Train_acc 90.88, Test_acc 72.40
2025-02-14 22:27:52,261 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.32, Train_acc 91.65, Test_acc 71.90
2025-02-14 22:27:53,592 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.32, Spatial_loss 1.18, Flat_loss 0.33, Train_acc 90.92, Test_acc 73.30
2025-02-14 22:27:54,926 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.30, Spatial_loss 1.18, Flat_loss 0.33, Train_acc 91.73, Test_acc 73.60
2025-02-14 22:27:56,285 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.30, Spatial_loss 1.19, Flat_loss 0.32, Train_acc 92.04, Test_acc 69.40
2025-02-14 22:27:57,672 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.31, Spatial_loss 1.17, Flat_loss 0.33, Train_acc 91.88, Test_acc 68.40
2025-02-14 22:27:59,045 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.31, Spatial_loss 1.19, Flat_loss 0.33, Train_acc 92.19, Test_acc 70.50
2025-02-14 22:28:00,412 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.29, Spatial_loss 1.21, Flat_loss 0.33, Train_acc 92.12, Test_acc 67.20
2025-02-14 22:28:01,782 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.29, Spatial_loss 1.19, Flat_loss 0.33, Train_acc 92.04, Test_acc 75.70
2025-02-14 22:28:03,127 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.28, Spatial_loss 1.16, Flat_loss 0.32, Train_acc 93.31, Test_acc 71.40
2025-02-14 22:28:04,503 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.27, Spatial_loss 1.17, Flat_loss 0.32, Train_acc 93.04, Test_acc 71.00
2025-02-14 22:28:05,878 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.26, Spatial_loss 1.12, Flat_loss 0.32, Train_acc 93.73, Test_acc 72.70
2025-02-14 22:28:07,201 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.26, Spatial_loss 1.13, Flat_loss 0.32, Train_acc 93.69, Test_acc 67.20
2025-02-14 22:28:08,578 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.28, Spatial_loss 1.13, Flat_loss 0.32, Train_acc 92.77, Test_acc 66.20
2025-02-14 22:28:09,939 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.26, Spatial_loss 1.16, Flat_loss 0.32, Train_acc 93.31, Test_acc 71.10
2025-02-14 22:28:11,337 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.26, Spatial_loss 1.13, Flat_loss 0.32, Train_acc 93.42, Test_acc 67.30
2025-02-14 22:28:12,710 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 1.14, Flat_loss 0.32, Train_acc 93.15, Test_acc 71.40
2025-02-14 22:28:14,098 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.27, Spatial_loss 1.14, Flat_loss 0.32, Train_acc 93.42, Test_acc 64.10
2025-02-14 22:28:15,490 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.26, Spatial_loss 1.16, Flat_loss 0.32, Train_acc 93.08, Test_acc 74.50
2025-02-14 22:28:16,801 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.26, Spatial_loss 1.10, Flat_loss 0.31, Train_acc 93.46, Test_acc 72.00
2025-02-14 22:28:18,149 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.23, Spatial_loss 1.08, Flat_loss 0.32, Train_acc 93.92, Test_acc 71.60
2025-02-14 22:28:19,495 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.31, Train_acc 95.00, Test_acc 72.60
2025-02-14 22:28:20,877 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.31, Train_acc 94.62, Test_acc 73.00
2025-02-14 22:28:22,219 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.23, Spatial_loss 1.08, Flat_loss 0.31, Train_acc 94.04, Test_acc 73.30
2025-02-14 22:28:23,574 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.25, Spatial_loss 1.11, Flat_loss 0.31, Train_acc 93.50, Test_acc 72.60
2025-02-14 22:28:24,970 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.31, Train_acc 94.19, Test_acc 73.60
2025-02-14 22:28:26,341 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.32, Train_acc 95.62, Test_acc 73.60
2025-02-14 22:28:27,712 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.31, Train_acc 94.35, Test_acc 71.70
2025-02-14 22:28:29,097 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 1.09, Flat_loss 0.31, Train_acc 94.23, Test_acc 74.40
2025-02-14 22:28:30,419 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.31, Train_acc 95.12, Test_acc 74.20
2025-02-14 22:28:31,772 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.24, Spatial_loss 1.12, Flat_loss 0.32, Train_acc 93.54, Test_acc 71.70
2025-02-14 22:28:33,096 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.23, Spatial_loss 1.07, Flat_loss 0.31, Train_acc 94.46, Test_acc 66.60
2025-02-14 22:28:34,485 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.31, Train_acc 95.00, Test_acc 77.30
2025-02-14 22:28:35,857 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.22, Spatial_loss 1.04, Flat_loss 0.31, Train_acc 94.85, Test_acc 73.00
2025-02-14 22:28:37,199 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.31, Train_acc 95.62, Test_acc 72.40
2025-02-14 22:28:38,617 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.30, Train_acc 96.19, Test_acc 75.40
2025-02-14 22:28:40,015 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.30, Train_acc 96.23, Test_acc 74.30
2025-02-14 22:28:41,369 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.31, Train_acc 96.12, Test_acc 73.70
2025-02-14 22:28:42,757 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.31, Train_acc 95.62, Test_acc 72.80
2025-02-14 22:28:44,114 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.31, Train_acc 95.54, Test_acc 71.20
2025-02-14 22:28:45,455 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.31, Train_acc 96.46, Test_acc 72.40
2025-02-14 22:28:46,807 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.30, Train_acc 96.46, Test_acc 74.90
2025-02-14 22:28:48,171 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.30, Train_acc 96.12, Test_acc 72.70
2025-02-14 22:28:49,600 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.30, Train_acc 96.50, Test_acc 73.80
2025-02-14 22:28:51,002 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.30, Train_acc 96.58, Test_acc 68.60
2025-02-14 22:28:52,402 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.30, Train_acc 97.46, Test_acc 76.60
2025-02-14 22:28:53,782 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.29, Train_acc 97.27, Test_acc 75.90
2025-02-14 22:28:55,224 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.29, Train_acc 96.65, Test_acc 73.10
2025-02-14 22:28:56,611 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.29, Train_acc 96.08, Test_acc 76.30
2025-02-14 22:28:57,993 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.30, Train_acc 96.38, Test_acc 70.40
2025-02-14 22:28:59,429 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.29, Train_acc 97.27, Test_acc 70.00
2025-02-14 22:29:00,783 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.29, Train_acc 96.65, Test_acc 74.90
2025-02-14 22:29:02,109 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.29, Train_acc 96.96, Test_acc 74.50
2025-02-14 22:29:03,522 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.29, Train_acc 97.42, Test_acc 76.00
2025-02-14 22:29:04,857 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.30, Train_acc 96.77, Test_acc 71.20
2025-02-14 22:29:06,232 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.29, Train_acc 97.77, Test_acc 68.90
2025-02-14 22:29:07,567 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.29, Train_acc 97.62, Test_acc 75.00
2025-02-14 22:29:08,973 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.29, Train_acc 97.88, Test_acc 76.30
2025-02-14 22:29:10,315 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.29, Train_acc 97.69, Test_acc 73.30
2025-02-14 22:29:11,697 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.28, Train_acc 98.31, Test_acc 75.50
2025-02-14 22:29:13,040 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.29, Train_acc 97.81, Test_acc 71.20
2025-02-14 22:29:14,380 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.29, Train_acc 97.73, Test_acc 76.10
2025-02-14 22:29:15,770 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.28, Train_acc 98.19, Test_acc 73.80
2025-02-14 22:29:17,131 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.28, Train_acc 98.31, Test_acc 75.10
2025-02-14 22:29:18,445 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.29, Train_acc 97.77, Test_acc 71.90
2025-02-14 22:29:19,828 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.29, Train_acc 98.35, Test_acc 76.60
2025-02-14 22:29:21,223 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.28, Train_acc 97.73, Test_acc 76.60
2025-02-14 22:29:22,602 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.29, Train_acc 97.92, Test_acc 75.90
2025-02-14 22:29:23,982 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.28, Train_acc 97.96, Test_acc 73.10
2025-02-14 22:29:25,322 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.28, Train_acc 98.15, Test_acc 75.00
2025-02-14 22:29:26,657 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.28, Train_acc 98.50, Test_acc 75.10
2025-02-14 22:29:28,054 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.28, Train_acc 98.31, Test_acc 77.50
2025-02-14 22:29:29,356 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.28, Train_acc 98.19, Test_acc 75.90
2025-02-14 22:29:30,671 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.27, Train_acc 98.58, Test_acc 77.60
2025-02-14 22:29:32,005 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.28, Train_acc 98.23, Test_acc 77.30
2025-02-14 22:29:33,405 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.28, Train_acc 98.62, Test_acc 74.70
2025-02-14 22:29:34,835 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.27, Train_acc 98.69, Test_acc 76.50
2025-02-14 22:29:36,134 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.27, Train_acc 98.69, Test_acc 75.40
2025-02-14 22:29:37,495 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.27, Train_acc 99.08, Test_acc 77.40
2025-02-14 22:29:38,855 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.28, Train_acc 98.73, Test_acc 77.60
2025-02-14 22:29:40,211 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.27, Train_acc 98.77, Test_acc 77.90
2025-02-14 22:29:41,538 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.28, Train_acc 98.85, Test_acc 77.90
2025-02-14 22:29:42,934 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.27, Train_acc 98.88, Test_acc 77.50
2025-02-14 22:29:44,267 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.27, Train_acc 99.00, Test_acc 77.70
2025-02-14 22:29:45,634 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.00, Test_acc 78.60
2025-02-14 22:29:47,047 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.27, Train_acc 99.00, Test_acc 78.00
2025-02-14 22:29:48,424 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.27, Train_acc 99.35, Test_acc 77.50
2025-02-14 22:29:49,819 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.27, Train_acc 99.19, Test_acc 77.00
2025-02-14 22:29:51,176 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.27, Train_acc 98.96, Test_acc 76.70
2025-02-14 22:29:52,515 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.23, Test_acc 77.20
2025-02-14 22:29:53,928 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.27, Train_acc 99.08, Test_acc 77.20
2025-02-14 22:29:55,307 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.27, Train_acc 99.31, Test_acc 78.20
2025-02-14 22:29:56,665 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.27, Train_acc 99.15, Test_acc 78.40
2025-02-14 22:29:58,050 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.27, Train_acc 99.08, Test_acc 76.90
2025-02-14 22:29:59,423 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.12, Test_acc 77.70
2025-02-14 22:30:00,719 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.04, Test_acc 77.70
2025-02-14 22:30:02,054 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.27, Train_acc 99.12, Test_acc 77.70
2025-02-14 22:30:03,419 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 98.85, Test_acc 77.70
2025-02-14 22:30:04,765 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 98.88, Test_acc 77.90
2025-02-14 22:30:06,152 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.35, Test_acc 78.10
2025-02-14 22:30:07,521 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.27, Train_acc 99.12, Test_acc 78.10
2025-02-14 22:30:08,848 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.09, Spatial_loss 0.72, Flat_loss 0.27, Train_acc 99.19, Test_acc 77.70
2025-02-14 22:30:10,206 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.27, Train_acc 99.42, Test_acc 78.20
2025-02-14 22:30:11,578 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.09, Spatial_loss 0.72, Flat_loss 0.27, Train_acc 99.23, Test_acc 77.90
2025-02-14 22:30:12,960 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.27, Train_acc 99.38, Test_acc 78.50
2025-02-14 22:30:14,300 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.10, Spatial_loss 0.75, Flat_loss 0.27, Train_acc 99.08, Test_acc 78.20
2025-02-14 22:30:15,710 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.74, Flat_loss 0.27, Train_acc 99.23, Test_acc 78.30
2025-02-14 22:30:15,710 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:30:15,710 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:30:20,692 [podnet.py] => The size of finetune dataset: 200
2025-02-14 22:30:21,512 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.26, Train_acc 97.00, Test_acc 78.60
2025-02-14 22:30:22,353 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.27, Train_acc 98.50, Test_acc 79.00
2025-02-14 22:30:23,153 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 0.83, Flat_loss 0.25, Train_acc 97.00, Test_acc 79.30
2025-02-14 22:30:23,937 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.24, Train_acc 97.00, Test_acc 79.40
2025-02-14 22:30:24,769 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.23, Train_acc 98.00, Test_acc 80.00
2025-02-14 22:30:25,652 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 0.74, Flat_loss 0.21, Train_acc 99.00, Test_acc 79.60
2025-02-14 22:30:26,471 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.21, Train_acc 99.50, Test_acc 80.00
2025-02-14 22:30:27,265 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.20, Train_acc 99.00, Test_acc 79.80
2025-02-14 22:30:28,082 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 0.74, Flat_loss 0.19, Train_acc 97.50, Test_acc 79.50
2025-02-14 22:30:28,881 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 0.74, Flat_loss 0.20, Train_acc 98.50, Test_acc 79.50
2025-02-14 22:30:29,686 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.20, Train_acc 97.50, Test_acc 79.50
2025-02-14 22:30:30,548 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.69, Flat_loss 0.19, Train_acc 99.50, Test_acc 80.20
2025-02-14 22:30:31,386 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.70, Flat_loss 0.19, Train_acc 99.50, Test_acc 80.80
2025-02-14 22:30:32,153 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 0.71, Flat_loss 0.19, Train_acc 97.50, Test_acc 80.40
2025-02-14 22:30:33,010 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 0.68, Flat_loss 0.19, Train_acc 99.50, Test_acc 80.50
2025-02-14 22:30:33,784 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.73, Flat_loss 0.19, Train_acc 98.50, Test_acc 80.60
2025-02-14 22:30:34,530 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 0.72, Flat_loss 0.19, Train_acc 99.50, Test_acc 80.60
2025-02-14 22:30:35,298 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.71, Flat_loss 0.20, Train_acc 98.00, Test_acc 80.50
2025-02-14 22:30:36,090 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.20, Train_acc 99.00, Test_acc 80.90
2025-02-14 22:30:36,911 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.71, Flat_loss 0.19, Train_acc 99.00, Test_acc 80.50
2025-02-14 22:30:36,912 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:30:42,821 [podnet.py] => Exemplar size: 200
2025-02-14 22:30:42,821 [trainer.py] => CNN: {'total': 80.5, '00-09': 80.5, 'old': 87.4, 'new': 73.6}
2025-02-14 22:30:42,821 [trainer.py] => NME: {'total': 76.7, '00-09': 76.7, 'old': 91.2, 'new': 62.2}
2025-02-14 22:30:42,821 [trainer.py] => CNN top1 curve: [96.8, 80.5]
2025-02-14 22:30:42,821 [trainer.py] => CNN top5 curve: [100.0, 98.6]
2025-02-14 22:30:42,821 [trainer.py] => NME top1 curve: [96.8, 76.7]
2025-02-14 22:30:42,821 [trainer.py] => NME top5 curve: [100.0, 98.3]

2025-02-14 22:30:42,821 [trainer.py] => Average Accuracy (CNN): 88.65
2025-02-14 22:30:42,821 [trainer.py] => Average Accuracy (NME): 86.75
2025-02-14 22:30:42,822 [trainer.py] => All params: 472657
2025-02-14 22:30:42,822 [trainer.py] => Trainable params: 472657
2025-02-14 22:30:42,822 [podnet.py] => Learning on 10-15
2025-02-14 22:30:42,844 [podnet.py] => Adaptive factor: 1.7320508075688772
2025-02-14 22:30:44,376 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 2.77, Spatial_loss 2.15, Flat_loss 0.67, Train_acc 39.30, Test_acc 29.00
2025-02-14 22:30:45,784 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 1.31, Spatial_loss 1.80, Flat_loss 0.34, Train_acc 57.07, Test_acc 45.73
2025-02-14 22:30:47,198 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 1.21, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 61.81, Test_acc 40.60
2025-02-14 22:30:48,579 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 1.14, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 65.07, Test_acc 47.20
2025-02-14 22:30:49,988 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 1.10, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 65.52, Test_acc 41.93
2025-02-14 22:30:51,388 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 1.07, Spatial_loss 1.63, Flat_loss 0.21, Train_acc 67.11, Test_acc 44.73
2025-02-14 22:30:52,770 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 1.01, Spatial_loss 1.65, Flat_loss 0.21, Train_acc 67.96, Test_acc 44.73
2025-02-14 22:30:54,160 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 1.00, Spatial_loss 1.56, Flat_loss 0.20, Train_acc 68.81, Test_acc 49.33
2025-02-14 22:30:55,557 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.94, Spatial_loss 1.62, Flat_loss 0.20, Train_acc 69.11, Test_acc 44.93
2025-02-14 22:30:57,017 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.92, Spatial_loss 1.50, Flat_loss 0.19, Train_acc 70.93, Test_acc 45.33
2025-02-14 22:30:58,441 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.91, Spatial_loss 1.43, Flat_loss 0.18, Train_acc 72.74, Test_acc 47.00
2025-02-14 22:30:59,869 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.89, Spatial_loss 1.44, Flat_loss 0.18, Train_acc 72.52, Test_acc 47.27
2025-02-14 22:31:01,320 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.89, Spatial_loss 1.57, Flat_loss 0.19, Train_acc 72.30, Test_acc 52.47
2025-02-14 22:31:02,726 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.86, Spatial_loss 1.47, Flat_loss 0.18, Train_acc 73.85, Test_acc 45.53
2025-02-14 22:31:04,194 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.84, Spatial_loss 1.52, Flat_loss 0.19, Train_acc 74.26, Test_acc 48.13
2025-02-14 22:31:05,658 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.80, Spatial_loss 1.45, Flat_loss 0.18, Train_acc 75.19, Test_acc 46.93
2025-02-14 22:31:07,098 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.79, Spatial_loss 1.52, Flat_loss 0.19, Train_acc 76.52, Test_acc 45.47
2025-02-14 22:31:08,512 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.87, Spatial_loss 1.56, Flat_loss 0.18, Train_acc 73.48, Test_acc 49.33
2025-02-14 22:31:09,920 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.79, Spatial_loss 1.45, Flat_loss 0.18, Train_acc 76.93, Test_acc 46.20
2025-02-14 22:31:11,315 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.77, Spatial_loss 1.49, Flat_loss 0.19, Train_acc 75.63, Test_acc 51.13
2025-02-14 22:31:12,794 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.74, Spatial_loss 1.36, Flat_loss 0.18, Train_acc 76.78, Test_acc 50.60
2025-02-14 22:31:14,223 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.79, Spatial_loss 1.45, Flat_loss 0.19, Train_acc 75.85, Test_acc 47.53
2025-02-14 22:31:15,607 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.74, Spatial_loss 1.46, Flat_loss 0.18, Train_acc 78.56, Test_acc 50.00
2025-02-14 22:31:16,971 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.72, Spatial_loss 1.39, Flat_loss 0.18, Train_acc 77.11, Test_acc 51.40
2025-02-14 22:31:18,372 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.70, Spatial_loss 1.42, Flat_loss 0.18, Train_acc 79.70, Test_acc 51.80
2025-02-14 22:31:19,834 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.75, Spatial_loss 1.45, Flat_loss 0.18, Train_acc 77.56, Test_acc 54.00
2025-02-14 22:31:21,204 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.70, Spatial_loss 1.40, Flat_loss 0.18, Train_acc 78.85, Test_acc 51.87
2025-02-14 22:31:22,663 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.68, Spatial_loss 1.32, Flat_loss 0.18, Train_acc 78.78, Test_acc 49.67
2025-02-14 22:31:24,128 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.66, Spatial_loss 1.36, Flat_loss 0.18, Train_acc 79.74, Test_acc 50.60
2025-02-14 22:31:25,530 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.70, Spatial_loss 1.42, Flat_loss 0.18, Train_acc 79.30, Test_acc 51.73
2025-02-14 22:31:26,970 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.72, Spatial_loss 1.52, Flat_loss 0.19, Train_acc 77.67, Test_acc 47.67
2025-02-14 22:31:28,373 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.70, Spatial_loss 1.55, Flat_loss 0.19, Train_acc 78.59, Test_acc 51.40
2025-02-14 22:31:29,759 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.64, Spatial_loss 1.44, Flat_loss 0.19, Train_acc 81.89, Test_acc 53.80
2025-02-14 22:31:31,252 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.67, Spatial_loss 1.43, Flat_loss 0.18, Train_acc 80.22, Test_acc 50.27
2025-02-14 22:31:32,669 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.65, Spatial_loss 1.44, Flat_loss 0.19, Train_acc 80.74, Test_acc 45.80
2025-02-14 22:31:34,148 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.64, Spatial_loss 1.52, Flat_loss 0.20, Train_acc 80.70, Test_acc 49.07
2025-02-14 22:31:35,542 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.65, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 81.48, Test_acc 47.33
2025-02-14 22:31:36,955 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.67, Spatial_loss 1.45, Flat_loss 0.19, Train_acc 79.81, Test_acc 51.07
2025-02-14 22:31:38,357 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.60, Spatial_loss 1.37, Flat_loss 0.19, Train_acc 82.89, Test_acc 51.33
2025-02-14 22:31:39,820 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.56, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 83.41, Test_acc 52.07
2025-02-14 22:31:41,259 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.59, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 83.11, Test_acc 46.80
2025-02-14 22:31:42,655 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.61, Spatial_loss 1.39, Flat_loss 0.18, Train_acc 82.67, Test_acc 50.00
2025-02-14 22:31:44,039 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.57, Spatial_loss 1.50, Flat_loss 0.19, Train_acc 83.04, Test_acc 52.67
2025-02-14 22:31:45,475 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.67, Spatial_loss 1.49, Flat_loss 0.19, Train_acc 82.11, Test_acc 53.87
2025-02-14 22:31:46,911 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.62, Spatial_loss 1.48, Flat_loss 0.20, Train_acc 81.67, Test_acc 50.40
2025-02-14 22:31:48,363 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.57, Spatial_loss 1.41, Flat_loss 0.19, Train_acc 84.33, Test_acc 41.20
2025-02-14 22:31:49,731 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.65, Spatial_loss 1.43, Flat_loss 0.20, Train_acc 80.93, Test_acc 53.87
2025-02-14 22:31:51,095 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.60, Spatial_loss 1.45, Flat_loss 0.19, Train_acc 82.22, Test_acc 57.93
2025-02-14 22:31:52,592 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.55, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 84.74, Test_acc 56.80
2025-02-14 22:31:54,003 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.57, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 84.78, Test_acc 55.87
2025-02-14 22:31:55,449 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.61, Spatial_loss 1.51, Flat_loss 0.20, Train_acc 82.85, Test_acc 54.93
2025-02-14 22:31:56,906 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 1.46, Flat_loss 0.19, Train_acc 83.41, Test_acc 53.27
2025-02-14 22:31:58,286 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.54, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 85.52, Test_acc 56.00
2025-02-14 22:31:59,723 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.50, Spatial_loss 1.33, Flat_loss 0.19, Train_acc 85.59, Test_acc 52.53
2025-02-14 22:32:01,109 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.53, Spatial_loss 1.42, Flat_loss 0.19, Train_acc 84.78, Test_acc 51.80
2025-02-14 22:32:02,511 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.53, Spatial_loss 1.40, Flat_loss 0.19, Train_acc 85.59, Test_acc 51.13
2025-02-14 22:32:03,892 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.56, Spatial_loss 1.30, Flat_loss 0.18, Train_acc 84.52, Test_acc 52.60
2025-02-14 22:32:05,233 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.53, Spatial_loss 1.38, Flat_loss 0.19, Train_acc 84.63, Test_acc 54.60
2025-02-14 22:32:06,616 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.47, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 85.78, Test_acc 49.13
2025-02-14 22:32:08,041 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.46, Spatial_loss 1.30, Flat_loss 0.18, Train_acc 88.59, Test_acc 52.80
2025-02-14 22:32:09,489 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.48, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 87.48, Test_acc 54.80
2025-02-14 22:32:10,898 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.47, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 86.93, Test_acc 52.47
2025-02-14 22:32:12,307 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.44, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 88.04, Test_acc 51.07
2025-02-14 22:32:13,689 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.37, Spatial_loss 1.26, Flat_loss 0.18, Train_acc 90.70, Test_acc 51.80
2025-02-14 22:32:15,110 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.43, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 89.15, Test_acc 53.80
2025-02-14 22:32:16,579 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.42, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 89.33, Test_acc 53.00
2025-02-14 22:32:18,007 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.38, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 89.96, Test_acc 53.13
2025-02-14 22:32:19,485 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.36, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 91.00, Test_acc 54.80
2025-02-14 22:32:20,902 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.44, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 89.30, Test_acc 43.07
2025-02-14 22:32:22,342 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.53, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 84.56, Test_acc 52.73
2025-02-14 22:32:23,803 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.40, Spatial_loss 1.29, Flat_loss 0.18, Train_acc 89.59, Test_acc 51.47
2025-02-14 22:32:25,198 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.39, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 89.59, Test_acc 52.73
2025-02-14 22:32:26,626 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.36, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 91.19, Test_acc 54.07
2025-02-14 22:32:28,035 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.37, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 90.04, Test_acc 57.07
2025-02-14 22:32:29,446 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.40, Spatial_loss 1.25, Flat_loss 0.18, Train_acc 90.07, Test_acc 55.80
2025-02-14 22:32:30,887 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.41, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 89.19, Test_acc 55.60
2025-02-14 22:32:32,352 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.37, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 90.37, Test_acc 51.13
2025-02-14 22:32:33,744 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.37, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 91.07, Test_acc 51.07
2025-02-14 22:32:35,177 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.35, Spatial_loss 1.25, Flat_loss 0.18, Train_acc 90.37, Test_acc 54.40
2025-02-14 22:32:36,598 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.30, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 92.33, Test_acc 53.73
2025-02-14 22:32:38,090 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.28, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 93.11, Test_acc 56.00
2025-02-14 22:32:39,440 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.29, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 93.81, Test_acc 54.87
2025-02-14 22:32:40,856 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.38, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 91.11, Test_acc 50.60
2025-02-14 22:32:42,271 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.42, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 88.78, Test_acc 53.80
2025-02-14 22:32:43,734 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.36, Spatial_loss 1.23, Flat_loss 0.18, Train_acc 90.81, Test_acc 53.27
2025-02-14 22:32:45,150 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 89.96, Test_acc 54.87
2025-02-14 22:32:46,518 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.32, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 93.07, Test_acc 54.20
2025-02-14 22:32:47,914 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.15, Flat_loss 0.19, Train_acc 91.81, Test_acc 54.20
2025-02-14 22:32:49,364 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.34, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 90.96, Test_acc 56.00
2025-02-14 22:32:50,826 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.32, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 92.96, Test_acc 55.07
2025-02-14 22:32:52,251 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.32, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 93.00, Test_acc 57.67
2025-02-14 22:32:53,665 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.29, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 93.44, Test_acc 57.60
2025-02-14 22:32:55,065 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.28, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 93.85, Test_acc 55.93
2025-02-14 22:32:56,433 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.26, Spatial_loss 1.10, Flat_loss 0.18, Train_acc 93.89, Test_acc 57.73
2025-02-14 22:32:57,812 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.25, Spatial_loss 1.07, Flat_loss 0.18, Train_acc 94.26, Test_acc 58.53
2025-02-14 22:32:59,255 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.25, Spatial_loss 1.07, Flat_loss 0.18, Train_acc 95.30, Test_acc 55.13
2025-02-14 22:33:00,702 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.36, Spatial_loss 1.19, Flat_loss 0.18, Train_acc 91.81, Test_acc 55.33
2025-02-14 22:33:02,087 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 91.70, Test_acc 56.07
2025-02-14 22:33:03,530 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.25, Spatial_loss 1.08, Flat_loss 0.18, Train_acc 94.37, Test_acc 57.53
2025-02-14 22:33:04,913 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.23, Spatial_loss 1.07, Flat_loss 0.18, Train_acc 95.07, Test_acc 57.00
2025-02-14 22:33:06,356 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 1.05, Flat_loss 0.18, Train_acc 95.37, Test_acc 57.93
2025-02-14 22:33:07,786 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.23, Spatial_loss 1.04, Flat_loss 0.18, Train_acc 95.96, Test_acc 57.87
2025-02-14 22:33:09,247 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.24, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 94.59, Test_acc 58.93
2025-02-14 22:33:10,715 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.18, Train_acc 96.22, Test_acc 59.40
2025-02-14 22:33:12,086 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 0.94, Flat_loss 0.17, Train_acc 97.11, Test_acc 60.80
2025-02-14 22:33:13,520 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.21, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 96.22, Test_acc 57.87
2025-02-14 22:33:14,938 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.18, Train_acc 96.52, Test_acc 57.87
2025-02-14 22:33:16,325 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 95.67, Test_acc 59.80
2025-02-14 22:33:17,744 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.21, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 96.11, Test_acc 60.13
2025-02-14 22:33:19,121 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.18, Train_acc 97.30, Test_acc 57.67
2025-02-14 22:33:20,561 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.18, Train_acc 96.44, Test_acc 57.47
2025-02-14 22:33:21,942 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 96.78, Test_acc 54.27
2025-02-14 22:33:23,323 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 1.03, Flat_loss 0.18, Train_acc 93.89, Test_acc 56.33
2025-02-14 22:33:24,791 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.25, Spatial_loss 1.02, Flat_loss 0.18, Train_acc 94.70, Test_acc 57.60
2025-02-14 22:33:26,181 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.24, Spatial_loss 1.03, Flat_loss 0.18, Train_acc 94.59, Test_acc 57.53
2025-02-14 22:33:27,570 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 95.93, Test_acc 57.40
2025-02-14 22:33:29,077 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 0.99, Flat_loss 0.18, Train_acc 96.04, Test_acc 58.07
2025-02-14 22:33:30,520 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.25, Spatial_loss 1.03, Flat_loss 0.18, Train_acc 95.07, Test_acc 57.73
2025-02-14 22:33:31,918 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.18, Train_acc 96.48, Test_acc 58.67
2025-02-14 22:33:33,307 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 97.07, Test_acc 60.47
2025-02-14 22:33:34,676 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 97.04, Test_acc 57.80
2025-02-14 22:33:36,092 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.18, Train_acc 97.22, Test_acc 59.73
2025-02-14 22:33:37,503 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 97.74, Test_acc 58.80
2025-02-14 22:33:38,865 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.17, Train_acc 98.48, Test_acc 59.80
2025-02-14 22:33:40,224 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.17, Train_acc 97.85, Test_acc 60.87
2025-02-14 22:33:41,638 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 97.26, Test_acc 57.80
2025-02-14 22:33:43,072 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 98.07, Test_acc 60.40
2025-02-14 22:33:44,461 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 0.89, Flat_loss 0.17, Train_acc 97.33, Test_acc 59.87
2025-02-14 22:33:45,910 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 0.90, Flat_loss 0.17, Train_acc 98.07, Test_acc 60.53
2025-02-14 22:33:47,306 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.17, Train_acc 97.59, Test_acc 59.40
2025-02-14 22:33:48,732 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.18, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 98.15, Test_acc 60.07
2025-02-14 22:33:50,110 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 0.89, Flat_loss 0.17, Train_acc 97.81, Test_acc 58.67
2025-02-14 22:33:51,497 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 0.89, Flat_loss 0.17, Train_acc 97.78, Test_acc 60.33
2025-02-14 22:33:52,885 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.15, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 98.48, Test_acc 60.87
2025-02-14 22:33:54,248 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.17, Train_acc 98.22, Test_acc 60.20
2025-02-14 22:33:55,686 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 98.89, Test_acc 60.53
2025-02-14 22:33:57,130 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.15, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 98.48, Test_acc 59.93
2025-02-14 22:33:58,540 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 0.86, Flat_loss 0.16, Train_acc 98.44, Test_acc 59.53
2025-02-14 22:33:59,956 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.14, Spatial_loss 0.82, Flat_loss 0.16, Train_acc 98.30, Test_acc 60.53
2025-02-14 22:34:01,426 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 98.59, Test_acc 60.20
2025-02-14 22:34:02,837 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.15, Spatial_loss 0.83, Flat_loss 0.16, Train_acc 98.52, Test_acc 60.67
2025-02-14 22:34:04,278 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 98.22, Test_acc 60.73
2025-02-14 22:34:05,734 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 98.67, Test_acc 60.33
2025-02-14 22:34:07,143 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 98.96, Test_acc 60.80
2025-02-14 22:34:08,578 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 99.04, Test_acc 61.07
2025-02-14 22:34:10,017 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.14, Spatial_loss 0.80, Flat_loss 0.16, Train_acc 98.70, Test_acc 60.67
2025-02-14 22:34:11,390 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.14, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 98.59, Test_acc 60.47
2025-02-14 22:34:12,787 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.14, Spatial_loss 0.82, Flat_loss 0.16, Train_acc 98.63, Test_acc 60.67
2025-02-14 22:34:14,230 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 98.74, Test_acc 60.27
2025-02-14 22:34:15,641 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.14, Spatial_loss 0.79, Flat_loss 0.16, Train_acc 98.59, Test_acc 60.67
2025-02-14 22:34:17,096 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 98.93, Test_acc 60.60
2025-02-14 22:34:18,487 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.80, Flat_loss 0.16, Train_acc 98.70, Test_acc 60.33
2025-02-14 22:34:19,864 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.16, Train_acc 99.30, Test_acc 60.53
2025-02-14 22:34:21,300 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.82, Flat_loss 0.16, Train_acc 98.63, Test_acc 60.93
2025-02-14 22:34:22,729 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 98.70, Test_acc 60.47
2025-02-14 22:34:24,164 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.16, Train_acc 99.19, Test_acc 60.27
2025-02-14 22:34:25,612 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.13, Spatial_loss 0.80, Flat_loss 0.16, Train_acc 98.74, Test_acc 60.73
2025-02-14 22:34:27,092 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.13, Spatial_loss 0.79, Flat_loss 0.16, Train_acc 99.07, Test_acc 60.47
2025-02-14 22:34:28,515 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 98.78, Test_acc 60.47
2025-02-14 22:34:29,911 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.16, Train_acc 99.11, Test_acc 60.07
2025-02-14 22:34:29,912 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:34:29,912 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:34:36,495 [podnet.py] => The size of finetune dataset: 300
2025-02-14 22:34:37,365 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.40, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 86.67, Test_acc 61.07
2025-02-14 22:34:38,224 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.33, Spatial_loss 1.03, Flat_loss 0.15, Train_acc 92.00, Test_acc 62.13
2025-02-14 22:34:39,092 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.26, Spatial_loss 1.02, Flat_loss 0.16, Train_acc 94.67, Test_acc 61.93
2025-02-14 22:34:39,931 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.24, Spatial_loss 0.92, Flat_loss 0.13, Train_acc 96.00, Test_acc 62.47
2025-02-14 22:34:40,844 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.25, Spatial_loss 0.97, Flat_loss 0.12, Train_acc 95.67, Test_acc 62.53
2025-02-14 22:34:41,723 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.18, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 98.33, Test_acc 62.93
2025-02-14 22:34:42,647 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.16, Spatial_loss 0.89, Flat_loss 0.12, Train_acc 98.33, Test_acc 63.87
2025-02-14 22:34:43,527 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.17, Spatial_loss 0.87, Flat_loss 0.11, Train_acc 97.33, Test_acc 64.60
2025-02-14 22:34:44,402 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.12, Train_acc 98.33, Test_acc 64.73
2025-02-14 22:34:45,243 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.12, Train_acc 97.33, Test_acc 64.27
2025-02-14 22:34:46,023 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.11, Train_acc 99.00, Test_acc 64.20
2025-02-14 22:34:46,887 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.12, Train_acc 99.00, Test_acc 64.27
2025-02-14 22:34:47,774 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.12, Train_acc 97.33, Test_acc 64.47
2025-02-14 22:34:48,603 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.12, Train_acc 98.33, Test_acc 64.40
2025-02-14 22:34:49,425 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.13, Spatial_loss 0.78, Flat_loss 0.12, Train_acc 98.67, Test_acc 64.53
2025-02-14 22:34:50,212 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.11, Train_acc 99.00, Test_acc 64.20
2025-02-14 22:34:51,062 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 0.83, Flat_loss 0.11, Train_acc 99.33, Test_acc 64.13
2025-02-14 22:34:51,969 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.13, Train_acc 98.33, Test_acc 64.00
2025-02-14 22:34:52,849 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.14, Spatial_loss 0.83, Flat_loss 0.11, Train_acc 97.33, Test_acc 64.00
2025-02-14 22:34:53,694 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.11, Train_acc 99.67, Test_acc 64.27
2025-02-14 22:34:53,696 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:35:01,122 [podnet.py] => Exemplar size: 300
2025-02-14 22:35:01,122 [trainer.py] => CNN: {'total': 64.27, '00-09': 62.4, '10-19': 68.0, 'old': 62.4, 'new': 68.0}
2025-02-14 22:35:01,122 [trainer.py] => NME: {'total': 62.53, '00-09': 64.1, '10-19': 59.4, 'old': 64.1, 'new': 59.4}
2025-02-14 22:35:01,122 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27]
2025-02-14 22:35:01,122 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67]
2025-02-14 22:35:01,122 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53]
2025-02-14 22:35:01,122 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27]

2025-02-14 22:35:01,122 [trainer.py] => Average Accuracy (CNN): 80.52333333333333
2025-02-14 22:35:01,123 [trainer.py] => Average Accuracy (NME): 78.67666666666666
2025-02-14 22:35:01,123 [trainer.py] => All params: 475857
2025-02-14 22:35:01,123 [trainer.py] => Trainable params: 475857
2025-02-14 22:35:01,124 [podnet.py] => Learning on 15-20
2025-02-14 22:35:01,146 [podnet.py] => Adaptive factor: 2.0
2025-02-14 22:35:02,628 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 3.15, Spatial_loss 2.28, Flat_loss 0.60, Train_acc 41.11, Test_acc 32.50
2025-02-14 22:35:04,070 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 1.41, Spatial_loss 1.75, Flat_loss 0.25, Train_acc 57.50, Test_acc 34.90
2025-02-14 22:35:05,528 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 1.28, Spatial_loss 1.41, Flat_loss 0.17, Train_acc 60.75, Test_acc 36.65
2025-02-14 22:35:06,965 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 1.18, Spatial_loss 1.30, Flat_loss 0.14, Train_acc 64.68, Test_acc 35.85
2025-02-14 22:35:08,382 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 1.09, Spatial_loss 1.30, Flat_loss 0.13, Train_acc 66.64, Test_acc 40.95
2025-02-14 22:35:09,839 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 1.05, Spatial_loss 1.30, Flat_loss 0.12, Train_acc 68.64, Test_acc 41.05
2025-02-14 22:35:11,348 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 1.04, Spatial_loss 1.31, Flat_loss 0.12, Train_acc 69.29, Test_acc 37.95
2025-02-14 22:35:12,847 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 0.96, Spatial_loss 1.33, Flat_loss 0.13, Train_acc 71.50, Test_acc 41.55
2025-02-14 22:35:14,315 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 0.93, Spatial_loss 1.29, Flat_loss 0.12, Train_acc 72.43, Test_acc 39.50
2025-02-14 22:35:15,726 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 0.91, Spatial_loss 1.32, Flat_loss 0.13, Train_acc 73.79, Test_acc 40.00
2025-02-14 22:35:17,144 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.88, Spatial_loss 1.39, Flat_loss 0.13, Train_acc 74.36, Test_acc 42.05
2025-02-14 22:35:18,562 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.81, Spatial_loss 1.31, Flat_loss 0.14, Train_acc 77.36, Test_acc 41.20
2025-02-14 22:35:20,014 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.82, Spatial_loss 1.37, Flat_loss 0.14, Train_acc 76.79, Test_acc 37.85
2025-02-14 22:35:21,401 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.79, Spatial_loss 1.32, Flat_loss 0.14, Train_acc 78.07, Test_acc 43.95
2025-02-14 22:35:22,811 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.75, Spatial_loss 1.34, Flat_loss 0.14, Train_acc 79.57, Test_acc 35.80
2025-02-14 22:35:24,300 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.75, Spatial_loss 1.33, Flat_loss 0.15, Train_acc 79.39, Test_acc 41.65
2025-02-14 22:35:25,764 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.72, Spatial_loss 1.30, Flat_loss 0.15, Train_acc 79.82, Test_acc 41.80
2025-02-14 22:35:27,267 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.68, Spatial_loss 1.35, Flat_loss 0.15, Train_acc 81.18, Test_acc 37.15
2025-02-14 22:35:28,704 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.69, Spatial_loss 1.33, Flat_loss 0.15, Train_acc 81.21, Test_acc 41.25
2025-02-14 22:35:30,156 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.66, Spatial_loss 1.37, Flat_loss 0.15, Train_acc 81.61, Test_acc 35.45
2025-02-14 22:35:31,613 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.63, Spatial_loss 1.31, Flat_loss 0.15, Train_acc 82.89, Test_acc 41.10
2025-02-14 22:35:33,005 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.65, Spatial_loss 1.42, Flat_loss 0.16, Train_acc 81.89, Test_acc 45.50
2025-02-14 22:35:34,445 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.65, Spatial_loss 1.35, Flat_loss 0.15, Train_acc 82.11, Test_acc 42.10
2025-02-14 22:35:35,864 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.68, Spatial_loss 1.42, Flat_loss 0.16, Train_acc 80.79, Test_acc 43.55
2025-02-14 22:35:37,290 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.61, Spatial_loss 1.34, Flat_loss 0.15, Train_acc 83.43, Test_acc 45.00
2025-02-14 22:35:38,732 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.58, Spatial_loss 1.36, Flat_loss 0.16, Train_acc 84.50, Test_acc 38.15
2025-02-14 22:35:40,205 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.56, Spatial_loss 1.42, Flat_loss 0.16, Train_acc 85.75, Test_acc 46.15
2025-02-14 22:35:41,613 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.54, Spatial_loss 1.36, Flat_loss 0.16, Train_acc 85.86, Test_acc 41.55
2025-02-14 22:35:43,075 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.57, Spatial_loss 1.37, Flat_loss 0.16, Train_acc 84.14, Test_acc 42.35
2025-02-14 22:35:44,571 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.51, Spatial_loss 1.37, Flat_loss 0.17, Train_acc 86.86, Test_acc 47.30
2025-02-14 22:35:46,036 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.58, Spatial_loss 1.37, Flat_loss 0.16, Train_acc 83.57, Test_acc 44.15
2025-02-14 22:35:47,467 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.52, Spatial_loss 1.31, Flat_loss 0.16, Train_acc 87.21, Test_acc 42.30
2025-02-14 22:35:48,948 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.53, Spatial_loss 1.30, Flat_loss 0.16, Train_acc 86.07, Test_acc 43.75
2025-02-14 22:35:50,398 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.51, Spatial_loss 1.36, Flat_loss 0.17, Train_acc 87.25, Test_acc 43.65
2025-02-14 22:35:51,793 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.50, Spatial_loss 1.30, Flat_loss 0.16, Train_acc 86.64, Test_acc 37.50
2025-02-14 22:35:53,255 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.50, Spatial_loss 1.32, Flat_loss 0.16, Train_acc 87.25, Test_acc 44.20
2025-02-14 22:35:54,686 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.48, Spatial_loss 1.31, Flat_loss 0.17, Train_acc 87.57, Test_acc 44.90
2025-02-14 22:35:56,149 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.48, Spatial_loss 1.33, Flat_loss 0.16, Train_acc 87.54, Test_acc 42.30
2025-02-14 22:35:57,598 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.50, Spatial_loss 1.39, Flat_loss 0.17, Train_acc 87.68, Test_acc 35.15
2025-02-14 22:35:59,070 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.43, Spatial_loss 1.33, Flat_loss 0.16, Train_acc 89.14, Test_acc 45.90
2025-02-14 22:36:00,551 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.47, Spatial_loss 1.35, Flat_loss 0.17, Train_acc 87.71, Test_acc 45.90
2025-02-14 22:36:02,005 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.45, Spatial_loss 1.35, Flat_loss 0.16, Train_acc 89.00, Test_acc 43.80
2025-02-14 22:36:03,452 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.45, Spatial_loss 1.32, Flat_loss 0.17, Train_acc 88.36, Test_acc 45.65
2025-02-14 22:36:04,940 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.41, Spatial_loss 1.31, Flat_loss 0.16, Train_acc 90.11, Test_acc 44.80
2025-02-14 22:36:06,353 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.38, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 91.18, Test_acc 40.95
2025-02-14 22:36:07,842 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.38, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 91.04, Test_acc 44.65
2025-02-14 22:36:09,316 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.38, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 91.29, Test_acc 47.40
2025-02-14 22:36:10,774 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.39, Spatial_loss 1.31, Flat_loss 0.17, Train_acc 91.04, Test_acc 45.60
2025-02-14 22:36:12,241 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.39, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 90.89, Test_acc 44.45
2025-02-14 22:36:13,689 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.36, Spatial_loss 1.25, Flat_loss 0.17, Train_acc 91.57, Test_acc 46.10
2025-02-14 22:36:15,121 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.37, Spatial_loss 1.22, Flat_loss 0.16, Train_acc 91.11, Test_acc 50.05
2025-02-14 22:36:16,566 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.37, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 90.96, Test_acc 41.95
2025-02-14 22:36:18,003 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.39, Spatial_loss 1.26, Flat_loss 0.17, Train_acc 91.36, Test_acc 46.75
2025-02-14 22:36:19,459 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.33, Spatial_loss 1.21, Flat_loss 0.16, Train_acc 92.21, Test_acc 40.50
2025-02-14 22:36:20,908 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.35, Spatial_loss 1.26, Flat_loss 0.16, Train_acc 91.61, Test_acc 43.35
2025-02-14 22:36:22,293 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.34, Spatial_loss 1.24, Flat_loss 0.17, Train_acc 92.04, Test_acc 48.75
2025-02-14 22:36:23,747 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.31, Spatial_loss 1.25, Flat_loss 0.17, Train_acc 92.89, Test_acc 46.95
2025-02-14 22:36:25,170 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.33, Spatial_loss 1.22, Flat_loss 0.16, Train_acc 92.39, Test_acc 35.60
2025-02-14 22:36:26,691 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.38, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 90.86, Test_acc 38.95
2025-02-14 22:36:28,159 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.36, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 90.86, Test_acc 45.85
2025-02-14 22:36:29,588 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 92.14, Test_acc 44.20
2025-02-14 22:36:31,041 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.33, Spatial_loss 1.24, Flat_loss 0.17, Train_acc 92.46, Test_acc 41.60
2025-02-14 22:36:32,419 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.33, Spatial_loss 1.26, Flat_loss 0.16, Train_acc 92.96, Test_acc 46.10
2025-02-14 22:36:33,922 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.30, Spatial_loss 1.21, Flat_loss 0.17, Train_acc 93.39, Test_acc 47.90
2025-02-14 22:36:35,345 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.28, Spatial_loss 1.17, Flat_loss 0.16, Train_acc 94.50, Test_acc 46.15
2025-02-14 22:36:36,816 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.30, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 93.64, Test_acc 44.35
2025-02-14 22:36:38,323 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.28, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 94.29, Test_acc 44.00
2025-02-14 22:36:39,782 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.27, Spatial_loss 1.13, Flat_loss 0.16, Train_acc 94.14, Test_acc 46.30
2025-02-14 22:36:41,164 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.26, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 94.54, Test_acc 45.25
2025-02-14 22:36:42,622 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 1.14, Flat_loss 0.17, Train_acc 95.00, Test_acc 45.10
2025-02-14 22:36:44,019 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.26, Spatial_loss 1.14, Flat_loss 0.16, Train_acc 95.00, Test_acc 46.70
2025-02-14 22:36:45,432 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.26, Spatial_loss 1.14, Flat_loss 0.16, Train_acc 94.68, Test_acc 44.70
2025-02-14 22:36:46,910 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.27, Spatial_loss 1.20, Flat_loss 0.16, Train_acc 94.04, Test_acc 47.60
2025-02-14 22:36:48,375 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.24, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 96.00, Test_acc 39.10
2025-02-14 22:36:49,783 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.25, Spatial_loss 1.13, Flat_loss 0.16, Train_acc 94.50, Test_acc 45.15
2025-02-14 22:36:51,226 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.27, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 94.18, Test_acc 47.75
2025-02-14 22:36:52,727 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 96.00, Test_acc 48.55
2025-02-14 22:36:54,178 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.16, Train_acc 95.96, Test_acc 44.10
2025-02-14 22:36:55,617 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 1.08, Flat_loss 0.16, Train_acc 95.96, Test_acc 48.50
2025-02-14 22:36:57,018 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 95.54, Test_acc 44.85
2025-02-14 22:36:58,539 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 96.00, Test_acc 44.90
2025-02-14 22:37:00,019 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 96.39, Test_acc 46.35
2025-02-14 22:37:01,478 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.16, Train_acc 96.61, Test_acc 44.30
2025-02-14 22:37:02,900 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.21, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 96.50, Test_acc 46.10
2025-02-14 22:37:04,413 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.16, Train_acc 96.64, Test_acc 41.85
2025-02-14 22:37:05,891 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.16, Train_acc 96.82, Test_acc 45.25
2025-02-14 22:37:07,305 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 96.43, Test_acc 44.10
2025-02-14 22:37:08,733 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.16, Train_acc 95.75, Test_acc 46.30
2025-02-14 22:37:10,207 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 1.08, Flat_loss 0.16, Train_acc 95.86, Test_acc 44.15
2025-02-14 22:37:11,703 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.16, Train_acc 96.71, Test_acc 49.00
2025-02-14 22:37:13,079 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.15, Train_acc 96.57, Test_acc 45.35
2025-02-14 22:37:14,576 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.15, Train_acc 97.25, Test_acc 46.25
2025-02-14 22:37:16,015 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 97.29, Test_acc 47.65
2025-02-14 22:37:17,491 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.15, Train_acc 97.50, Test_acc 44.05
2025-02-14 22:37:18,975 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.21, Test_acc 45.70
2025-02-14 22:37:20,470 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.15, Train_acc 96.71, Test_acc 50.15
2025-02-14 22:37:21,902 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 97.39, Test_acc 48.60
2025-02-14 22:37:23,396 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.15, Train_acc 97.54, Test_acc 43.95
2025-02-14 22:37:24,798 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.21, Test_acc 47.65
2025-02-14 22:37:26,193 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.15, Train_acc 97.86, Test_acc 48.90
2025-02-14 22:37:27,644 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 97.82, Test_acc 46.05
2025-02-14 22:37:29,092 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.15, Train_acc 98.54, Test_acc 47.05
2025-02-14 22:37:30,535 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.54, Test_acc 50.55
2025-02-14 22:37:31,999 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.15, Train_acc 98.46, Test_acc 47.75
2025-02-14 22:37:33,451 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 97.79, Test_acc 45.30
2025-02-14 22:37:34,891 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.43, Test_acc 42.70
2025-02-14 22:37:36,253 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.25, Test_acc 49.15
2025-02-14 22:37:37,704 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.15, Train_acc 98.39, Test_acc 48.45
2025-02-14 22:37:39,207 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.61, Test_acc 49.35
2025-02-14 22:37:40,650 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 98.89, Test_acc 48.25
2025-02-14 22:37:42,050 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 98.50, Test_acc 48.25
2025-02-14 22:37:43,499 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 98.43, Test_acc 46.45
2025-02-14 22:37:44,977 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.46, Test_acc 46.50
2025-02-14 22:37:46,377 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.64, Test_acc 50.50
2025-02-14 22:37:47,811 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 98.71, Test_acc 48.60
2025-02-14 22:37:49,301 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 98.68, Test_acc 48.10
2025-02-14 22:37:50,731 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.64, Test_acc 45.90
2025-02-14 22:37:52,169 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 98.82, Test_acc 49.25
2025-02-14 22:37:53,628 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 99.00, Test_acc 46.95
2025-02-14 22:37:55,114 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 99.18, Test_acc 48.65
2025-02-14 22:37:56,513 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.14, Train_acc 99.21, Test_acc 50.05
2025-02-14 22:37:57,964 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.14, Test_acc 48.70
2025-02-14 22:37:59,395 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.15, Train_acc 99.21, Test_acc 50.80
2025-02-14 22:38:00,829 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.14, Test_acc 48.95
2025-02-14 22:38:02,237 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.11, Test_acc 51.00
2025-02-14 22:38:03,666 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.29, Test_acc 49.45
2025-02-14 22:38:05,109 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.14, Train_acc 98.82, Test_acc 48.20
2025-02-14 22:38:06,547 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.13, Spatial_loss 0.82, Flat_loss 0.14, Train_acc 99.00, Test_acc 50.70
2025-02-14 22:38:08,029 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 98.86, Test_acc 49.45
2025-02-14 22:38:09,523 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.39, Test_acc 49.65
2025-02-14 22:38:10,933 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.12, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.29, Test_acc 49.80
2025-02-14 22:38:12,345 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 99.36, Test_acc 50.80
2025-02-14 22:38:13,815 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.18, Test_acc 49.85
2025-02-14 22:38:15,239 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.46, Test_acc 49.20
2025-02-14 22:38:16,626 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 99.36, Test_acc 50.55
2025-02-14 22:38:18,114 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.25, Test_acc 49.75
2025-02-14 22:38:19,545 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 99.61, Test_acc 50.35
2025-02-14 22:38:21,016 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.11, Spatial_loss 0.71, Flat_loss 0.14, Train_acc 99.36, Test_acc 50.25
2025-02-14 22:38:22,427 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.11, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 99.39, Test_acc 50.60
2025-02-14 22:38:23,849 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.46, Test_acc 50.05
2025-02-14 22:38:25,281 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.14, Train_acc 99.43, Test_acc 49.45
2025-02-14 22:38:26,743 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.11, Spatial_loss 0.71, Flat_loss 0.14, Train_acc 99.50, Test_acc 50.15
2025-02-14 22:38:28,233 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.11, Spatial_loss 0.71, Flat_loss 0.14, Train_acc 99.43, Test_acc 50.25
2025-02-14 22:38:29,650 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.12, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.11, Test_acc 50.95
2025-02-14 22:38:31,156 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.46, Test_acc 51.00
2025-02-14 22:38:32,630 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 99.57, Test_acc 50.20
2025-02-14 22:38:34,010 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.46, Test_acc 51.10
2025-02-14 22:38:35,513 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.10, Spatial_loss 0.70, Flat_loss 0.14, Train_acc 99.43, Test_acc 50.15
2025-02-14 22:38:36,946 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 99.18, Test_acc 49.90
2025-02-14 22:38:38,359 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.10, Spatial_loss 0.69, Flat_loss 0.14, Train_acc 99.71, Test_acc 50.20
2025-02-14 22:38:39,793 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.10, Spatial_loss 0.70, Flat_loss 0.14, Train_acc 99.61, Test_acc 50.20
2025-02-14 22:38:41,222 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.11, Spatial_loss 0.70, Flat_loss 0.14, Train_acc 99.29, Test_acc 50.40
2025-02-14 22:38:42,646 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.11, Spatial_loss 0.71, Flat_loss 0.14, Train_acc 99.61, Test_acc 50.40
2025-02-14 22:38:44,075 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.10, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.46, Test_acc 50.30
2025-02-14 22:38:45,469 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.10, Spatial_loss 0.70, Flat_loss 0.14, Train_acc 99.50, Test_acc 50.50
2025-02-14 22:38:46,891 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.10, Spatial_loss 0.69, Flat_loss 0.14, Train_acc 99.50, Test_acc 50.70
2025-02-14 22:38:48,334 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.69, Flat_loss 0.14, Train_acc 99.64, Test_acc 50.20
2025-02-14 22:38:49,799 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.14, Train_acc 99.36, Test_acc 50.90
2025-02-14 22:38:51,302 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.11, Spatial_loss 0.70, Flat_loss 0.14, Train_acc 99.54, Test_acc 50.40
2025-02-14 22:38:52,760 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.68, Flat_loss 0.14, Train_acc 99.50, Test_acc 50.35
2025-02-14 22:38:52,761 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:38:52,761 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:39:00,958 [podnet.py] => The size of finetune dataset: 400
2025-02-14 22:39:01,957 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.56, Spatial_loss 1.43, Flat_loss 0.13, Train_acc 85.75, Test_acc 51.15
2025-02-14 22:39:02,849 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.29, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 93.00, Test_acc 52.10
2025-02-14 22:39:03,715 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.39, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 95.00, Test_acc 52.10
2025-02-14 22:39:04,576 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 96.75, Test_acc 53.70
2025-02-14 22:39:05,515 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.10, Train_acc 98.00, Test_acc 55.60
2025-02-14 22:39:06,476 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.09, Train_acc 98.75, Test_acc 55.35
2025-02-14 22:39:07,364 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.11, Train_acc 98.50, Test_acc 53.50
2025-02-14 22:39:08,245 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.18, Spatial_loss 0.98, Flat_loss 0.09, Train_acc 98.75, Test_acc 52.75
2025-02-14 22:39:09,098 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 99.25, Test_acc 52.20
2025-02-14 22:39:10,009 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 100.00, Test_acc 52.35
2025-02-14 22:39:10,928 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.10, Train_acc 98.25, Test_acc 52.85
2025-02-14 22:39:11,848 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.10, Train_acc 99.00, Test_acc 52.55
2025-02-14 22:39:12,749 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 99.00, Test_acc 52.70
2025-02-14 22:39:13,651 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.25, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 98.75, Test_acc 52.85
2025-02-14 22:39:14,581 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 100.00, Test_acc 53.05
2025-02-14 22:39:15,461 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 100.00, Test_acc 53.60
2025-02-14 22:39:16,378 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.01, Flat_loss 0.10, Train_acc 99.75, Test_acc 54.45
2025-02-14 22:39:17,298 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.09, Train_acc 100.00, Test_acc 54.00
2025-02-14 22:39:18,212 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.26, Spatial_loss 1.13, Flat_loss 0.12, Train_acc 98.25, Test_acc 54.15
2025-02-14 22:39:19,163 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 99.00, Test_acc 54.10
2025-02-14 22:39:19,164 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:39:28,500 [podnet.py] => Exemplar size: 400
2025-02-14 22:39:28,500 [trainer.py] => CNN: {'total': 54.1, '00-09': 51.1, '10-19': 57.1, 'old': 48.6, 'new': 70.6}
2025-02-14 22:39:28,500 [trainer.py] => NME: {'total': 52.0, '00-09': 53.6, '10-19': 50.4, 'old': 47.33, 'new': 66.0}
2025-02-14 22:39:28,500 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1]
2025-02-14 22:39:28,500 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0]
2025-02-14 22:39:28,500 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0]
2025-02-14 22:39:28,500 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65]

2025-02-14 22:39:28,500 [trainer.py] => Average Accuracy (CNN): 73.9175
2025-02-14 22:39:28,501 [trainer.py] => Average Accuracy (NME): 72.0075
2025-02-14 22:39:28,501 [trainer.py] => All params: 479057
2025-02-14 22:39:28,501 [trainer.py] => Trainable params: 479057
2025-02-14 22:39:28,502 [podnet.py] => Learning on 20-25
2025-02-14 22:39:28,524 [podnet.py] => Adaptive factor: 2.23606797749979
2025-02-14 22:39:30,019 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 3.44, Spatial_loss 2.54, Flat_loss 0.84, Train_acc 42.45, Test_acc 20.80
2025-02-14 22:39:31,572 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 1.34, Spatial_loss 1.98, Flat_loss 0.35, Train_acc 59.76, Test_acc 30.68
2025-02-14 22:39:33,137 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 1.16, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 67.14, Test_acc 32.04
2025-02-14 22:39:34,665 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 1.07, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 69.83, Test_acc 26.40
2025-02-14 22:39:36,213 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 0.96, Spatial_loss 1.58, Flat_loss 0.20, Train_acc 74.07, Test_acc 33.12
2025-02-14 22:39:37,774 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.89, Spatial_loss 1.62, Flat_loss 0.20, Train_acc 75.21, Test_acc 35.00
2025-02-14 22:39:39,277 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.84, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 78.07, Test_acc 38.64
2025-02-14 22:39:40,803 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.81, Spatial_loss 1.58, Flat_loss 0.21, Train_acc 78.86, Test_acc 35.44
2025-02-14 22:39:42,292 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.76, Spatial_loss 1.61, Flat_loss 0.20, Train_acc 79.90, Test_acc 31.92
2025-02-14 22:39:43,818 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.71, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 81.21, Test_acc 36.92
2025-02-14 22:39:45,356 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.67, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 82.34, Test_acc 32.28
2025-02-14 22:39:46,890 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.66, Spatial_loss 1.62, Flat_loss 0.21, Train_acc 83.10, Test_acc 37.88
2025-02-14 22:39:48,411 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.65, Spatial_loss 1.51, Flat_loss 0.20, Train_acc 83.21, Test_acc 31.48
2025-02-14 22:39:49,953 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.63, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 83.76, Test_acc 36.96
2025-02-14 22:39:51,438 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.59, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 84.72, Test_acc 35.48
2025-02-14 22:39:52,954 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.57, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 85.28, Test_acc 39.36
2025-02-14 22:39:54,515 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.53, Spatial_loss 1.47, Flat_loss 0.20, Train_acc 87.55, Test_acc 37.48
2025-02-14 22:39:55,963 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.54, Spatial_loss 1.51, Flat_loss 0.20, Train_acc 86.31, Test_acc 36.60
2025-02-14 22:39:57,456 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.52, Spatial_loss 1.54, Flat_loss 0.20, Train_acc 86.72, Test_acc 38.92
2025-02-14 22:39:58,938 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.50, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 87.07, Test_acc 35.60
2025-02-14 22:40:00,458 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.50, Spatial_loss 1.52, Flat_loss 0.20, Train_acc 88.34, Test_acc 40.72
2025-02-14 22:40:02,040 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.48, Spatial_loss 1.50, Flat_loss 0.20, Train_acc 88.17, Test_acc 39.80
2025-02-14 22:40:03,513 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.49, Spatial_loss 1.42, Flat_loss 0.19, Train_acc 88.07, Test_acc 32.44
2025-02-14 22:40:05,000 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.47, Spatial_loss 1.50, Flat_loss 0.20, Train_acc 89.24, Test_acc 32.88
2025-02-14 22:40:06,519 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.46, Spatial_loss 1.47, Flat_loss 0.20, Train_acc 88.59, Test_acc 38.24
2025-02-14 22:40:08,063 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.43, Spatial_loss 1.47, Flat_loss 0.20, Train_acc 89.62, Test_acc 41.36
2025-02-14 22:40:09,606 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.43, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 89.62, Test_acc 40.04
2025-02-14 22:40:11,071 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.42, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 90.38, Test_acc 35.20
2025-02-14 22:40:12,631 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.43, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 89.62, Test_acc 40.24
2025-02-14 22:40:14,176 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.40, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 91.07, Test_acc 34.64
2025-02-14 22:40:15,697 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.41, Spatial_loss 1.45, Flat_loss 0.20, Train_acc 90.17, Test_acc 41.24
2025-02-14 22:40:17,199 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.42, Spatial_loss 1.47, Flat_loss 0.20, Train_acc 90.28, Test_acc 33.56
2025-02-14 22:40:18,719 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.38, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 91.86, Test_acc 41.44
2025-02-14 22:40:20,232 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.36, Spatial_loss 1.44, Flat_loss 0.20, Train_acc 92.03, Test_acc 41.12
2025-02-14 22:40:21,738 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.34, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 93.14, Test_acc 34.60
2025-02-14 22:40:23,130 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.38, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 91.83, Test_acc 37.56
2025-02-14 22:40:24,686 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.36, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 91.90, Test_acc 36.00
2025-02-14 22:40:26,221 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.35, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 92.14, Test_acc 34.92
2025-02-14 22:40:27,737 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.35, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 91.93, Test_acc 39.84
2025-02-14 22:40:29,299 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.34, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 92.34, Test_acc 40.36
2025-02-14 22:40:30,834 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.37, Spatial_loss 1.44, Flat_loss 0.20, Train_acc 91.48, Test_acc 39.04
2025-02-14 22:40:32,385 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.35, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 92.07, Test_acc 36.44
2025-02-14 22:40:33,832 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.36, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 92.14, Test_acc 40.08
2025-02-14 22:40:35,351 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 93.83, Test_acc 38.48
2025-02-14 22:40:36,854 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.34, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 92.97, Test_acc 39.28
2025-02-14 22:40:38,418 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.32, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 93.10, Test_acc 40.84
2025-02-14 22:40:39,897 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.30, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 93.97, Test_acc 39.48
2025-02-14 22:40:41,424 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 94.14, Test_acc 44.24
2025-02-14 22:40:42,959 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 94.97, Test_acc 39.84
2025-02-14 22:40:44,523 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 94.62, Test_acc 42.60
2025-02-14 22:40:45,967 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.29, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 94.00, Test_acc 38.32
2025-02-14 22:40:47,486 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.28, Spatial_loss 1.37, Flat_loss 0.19, Train_acc 94.21, Test_acc 38.92
2025-02-14 22:40:49,014 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.28, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 94.28, Test_acc 40.52
2025-02-14 22:40:50,475 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.30, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 93.76, Test_acc 35.36
2025-02-14 22:40:51,980 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 94.59, Test_acc 39.36
2025-02-14 22:40:53,533 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.26, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 95.38, Test_acc 37.92
2025-02-14 22:40:55,034 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 96.31, Test_acc 36.48
2025-02-14 22:40:56,533 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.24, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 95.55, Test_acc 39.92
2025-02-14 22:40:58,087 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.25, Spatial_loss 1.34, Flat_loss 0.19, Train_acc 95.24, Test_acc 41.92
2025-02-14 22:40:59,561 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 96.03, Test_acc 40.76
2025-02-14 22:41:01,076 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 96.00, Test_acc 33.56
2025-02-14 22:41:02,638 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.24, Spatial_loss 1.33, Flat_loss 0.19, Train_acc 95.52, Test_acc 36.32
2025-02-14 22:41:04,110 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.23, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 96.28, Test_acc 40.68
2025-02-14 22:41:05,659 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 96.38, Test_acc 40.52
2025-02-14 22:41:07,148 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.23, Spatial_loss 1.24, Flat_loss 0.18, Train_acc 96.00, Test_acc 36.72
2025-02-14 22:41:08,634 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 96.03, Test_acc 40.08
2025-02-14 22:41:10,109 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 95.72, Test_acc 38.76
2025-02-14 22:41:11,603 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.19, Train_acc 96.41, Test_acc 40.92
2025-02-14 22:41:13,163 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 97.17, Test_acc 37.40
2025-02-14 22:41:14,628 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 95.21, Test_acc 41.80
2025-02-14 22:41:16,099 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.18, Train_acc 96.17, Test_acc 38.24
2025-02-14 22:41:17,642 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 96.07, Test_acc 40.32
2025-02-14 22:41:19,172 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.18, Train_acc 97.48, Test_acc 46.00
2025-02-14 22:41:20,679 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.20, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 97.24, Test_acc 44.80
2025-02-14 22:41:22,201 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.20, Spatial_loss 1.23, Flat_loss 0.18, Train_acc 96.97, Test_acc 40.04
2025-02-14 22:41:23,707 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 97.90, Test_acc 44.52
2025-02-14 22:41:25,246 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 97.76, Test_acc 40.40
2025-02-14 22:41:26,773 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.20, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 96.83, Test_acc 41.96
2025-02-14 22:41:28,231 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 97.34, Test_acc 39.64
2025-02-14 22:41:29,790 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.19, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 97.69, Test_acc 38.68
2025-02-14 22:41:31,315 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.19, Spatial_loss 1.19, Flat_loss 0.18, Train_acc 97.38, Test_acc 42.96
2025-02-14 22:41:32,787 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 97.17, Test_acc 40.32
2025-02-14 22:41:34,281 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 97.00, Test_acc 44.24
2025-02-14 22:41:35,797 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 97.21, Test_acc 41.72
2025-02-14 22:41:37,309 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 98.00, Test_acc 40.64
2025-02-14 22:41:38,789 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 97.72, Test_acc 44.16
2025-02-14 22:41:40,267 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.18, Train_acc 97.90, Test_acc 39.96
2025-02-14 22:41:41,790 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.16, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 98.00, Test_acc 41.80
2025-02-14 22:41:43,301 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 98.07, Test_acc 40.64
2025-02-14 22:41:44,802 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.16, Spatial_loss 1.06, Flat_loss 0.18, Train_acc 98.10, Test_acc 40.12
2025-02-14 22:41:46,254 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.16, Spatial_loss 1.08, Flat_loss 0.18, Train_acc 98.41, Test_acc 44.36
2025-02-14 22:41:47,775 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 1.07, Flat_loss 0.18, Train_acc 98.10, Test_acc 40.00
2025-02-14 22:41:49,289 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 98.45, Test_acc 43.60
2025-02-14 22:41:50,785 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.14, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 98.83, Test_acc 44.32
2025-02-14 22:41:52,325 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 98.55, Test_acc 41.72
2025-02-14 22:41:53,854 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.15, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 98.62, Test_acc 42.16
2025-02-14 22:41:55,282 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.14, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 98.62, Test_acc 41.52
2025-02-14 22:41:56,794 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 98.66, Test_acc 39.92
2025-02-14 22:41:58,307 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 97.90, Test_acc 44.04
2025-02-14 22:41:59,850 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 98.55, Test_acc 46.64
2025-02-14 22:42:01,335 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 98.69, Test_acc 43.88
2025-02-14 22:42:02,827 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 98.79, Test_acc 44.44
2025-02-14 22:42:04,369 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 99.24, Test_acc 45.04
2025-02-14 22:42:05,838 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.17, Train_acc 99.00, Test_acc 40.00
2025-02-14 22:42:07,328 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 99.07, Test_acc 42.80
2025-02-14 22:42:08,890 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 98.69, Test_acc 41.60
2025-02-14 22:42:10,457 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.16, Train_acc 98.93, Test_acc 43.12
2025-02-14 22:42:11,916 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 99.17, Test_acc 43.96
2025-02-14 22:42:13,463 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.28, Test_acc 43.28
2025-02-14 22:42:14,967 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 99.10, Test_acc 44.84
2025-02-14 22:42:16,446 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.17, Train_acc 99.14, Test_acc 41.92
2025-02-14 22:42:17,993 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 99.14, Test_acc 41.04
2025-02-14 22:42:19,564 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 99.03, Test_acc 39.12
2025-02-14 22:42:21,068 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 99.03, Test_acc 40.08
2025-02-14 22:42:22,552 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.41, Test_acc 43.52
2025-02-14 22:42:24,079 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 99.21, Test_acc 43.88
2025-02-14 22:42:25,546 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 99.21, Test_acc 44.68
2025-02-14 22:42:27,072 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 99.38, Test_acc 41.32
2025-02-14 22:42:28,638 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 99.34, Test_acc 44.24
2025-02-14 22:42:30,110 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.41, Test_acc 44.92
2025-02-14 22:42:31,598 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 99.41, Test_acc 44.84
2025-02-14 22:42:33,100 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.62, Test_acc 46.16
2025-02-14 22:42:34,585 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.16, Train_acc 99.45, Test_acc 43.72
2025-02-14 22:42:36,106 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.59, Test_acc 43.96
2025-02-14 22:42:37,663 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.16, Train_acc 99.55, Test_acc 42.48
2025-02-14 22:42:39,195 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.16, Train_acc 99.52, Test_acc 44.72
2025-02-14 22:42:40,711 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.16, Train_acc 99.45, Test_acc 43.76
2025-02-14 22:42:42,230 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 99.72, Test_acc 45.44
2025-02-14 22:42:43,743 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.11, Spatial_loss 0.83, Flat_loss 0.16, Train_acc 99.66, Test_acc 43.20
2025-02-14 22:42:45,264 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.16, Train_acc 99.59, Test_acc 45.52
2025-02-14 22:42:46,787 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.59, Test_acc 44.28
2025-02-14 22:42:48,271 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 99.72, Test_acc 43.08
2025-02-14 22:42:49,810 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.16, Train_acc 99.52, Test_acc 44.44
2025-02-14 22:42:51,336 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.83, Test_acc 44.44
2025-02-14 22:42:52,883 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.59, Test_acc 44.80
2025-02-14 22:42:54,409 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.79, Test_acc 44.28
2025-02-14 22:42:55,903 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.62, Test_acc 44.72
2025-02-14 22:42:57,397 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.72, Test_acc 44.12
2025-02-14 22:42:58,858 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.66, Test_acc 44.60
2025-02-14 22:43:00,354 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.62, Test_acc 43.84
2025-02-14 22:43:01,895 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.66, Test_acc 43.76
2025-02-14 22:43:03,373 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.16, Train_acc 99.62, Test_acc 44.40
2025-02-14 22:43:04,885 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.76, Test_acc 44.28
2025-02-14 22:43:06,391 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.15, Train_acc 99.62, Test_acc 44.20
2025-02-14 22:43:07,967 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.10, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.83, Test_acc 44.76
2025-02-14 22:43:09,467 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.15, Train_acc 99.66, Test_acc 44.36
2025-02-14 22:43:10,989 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.15, Train_acc 99.76, Test_acc 44.88
2025-02-14 22:43:12,506 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.15, Train_acc 99.48, Test_acc 44.20
2025-02-14 22:43:14,008 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.76, Test_acc 44.00
2025-02-14 22:43:15,505 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.16, Train_acc 99.55, Test_acc 44.04
2025-02-14 22:43:17,029 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.11, Spatial_loss 0.75, Flat_loss 0.15, Train_acc 99.62, Test_acc 44.28
2025-02-14 22:43:18,529 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.11, Spatial_loss 0.72, Flat_loss 0.15, Train_acc 99.76, Test_acc 44.36
2025-02-14 22:43:20,033 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.10, Spatial_loss 0.72, Flat_loss 0.15, Train_acc 99.83, Test_acc 44.76
2025-02-14 22:43:21,570 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.10, Spatial_loss 0.71, Flat_loss 0.15, Train_acc 99.90, Test_acc 44.36
2025-02-14 22:43:23,078 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.11, Spatial_loss 0.75, Flat_loss 0.15, Train_acc 99.62, Test_acc 44.56
2025-02-14 22:43:24,509 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.83, Test_acc 44.72
2025-02-14 22:43:26,017 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.83, Test_acc 44.64
2025-02-14 22:43:27,545 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.74, Flat_loss 0.15, Train_acc 99.79, Test_acc 44.60
2025-02-14 22:43:29,037 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.66, Test_acc 44.92
2025-02-14 22:43:30,531 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.73, Flat_loss 0.15, Train_acc 99.66, Test_acc 44.52
2025-02-14 22:43:30,532 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:43:30,533 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:43:40,385 [podnet.py] => The size of finetune dataset: 500
2025-02-14 22:43:41,343 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.37, Spatial_loss 1.15, Flat_loss 0.12, Train_acc 91.00, Test_acc 46.72
2025-02-14 22:43:42,263 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.22, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 97.80, Test_acc 48.92
2025-02-14 22:43:43,222 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.16, Spatial_loss 0.80, Flat_loss 0.08, Train_acc 99.20, Test_acc 50.32
2025-02-14 22:43:44,203 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.08, Train_acc 99.80, Test_acc 51.12
2025-02-14 22:43:45,212 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.08, Train_acc 100.00, Test_acc 51.44
2025-02-14 22:43:46,151 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.08, Train_acc 99.40, Test_acc 50.36
2025-02-14 22:43:47,054 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 0.82, Flat_loss 0.07, Train_acc 100.00, Test_acc 49.40
2025-02-14 22:43:47,999 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.09, Spatial_loss 0.69, Flat_loss 0.07, Train_acc 99.80, Test_acc 48.04
2025-02-14 22:43:48,998 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.07, Train_acc 99.80, Test_acc 47.76
2025-02-14 22:43:49,959 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.08, Spatial_loss 0.80, Flat_loss 0.08, Train_acc 100.00, Test_acc 47.56
2025-02-14 22:43:50,886 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.09, Spatial_loss 0.79, Flat_loss 0.07, Train_acc 99.80, Test_acc 47.48
2025-02-14 22:43:51,782 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 0.78, Flat_loss 0.07, Train_acc 99.80, Test_acc 47.68
2025-02-14 22:43:52,677 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 99.40, Test_acc 47.72
2025-02-14 22:43:53,585 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 99.80, Test_acc 47.60
2025-02-14 22:43:54,558 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 0.71, Flat_loss 0.07, Train_acc 100.00, Test_acc 47.56
2025-02-14 22:43:55,433 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.72, Flat_loss 0.07, Train_acc 99.60, Test_acc 47.44
2025-02-14 22:43:56,433 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 0.69, Flat_loss 0.07, Train_acc 100.00, Test_acc 47.72
2025-02-14 22:43:57,416 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.09, Spatial_loss 0.66, Flat_loss 0.07, Train_acc 100.00, Test_acc 47.40
2025-02-14 22:43:58,372 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.07, Train_acc 99.80, Test_acc 47.44
2025-02-14 22:43:59,360 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.71, Flat_loss 0.07, Train_acc 99.60, Test_acc 47.48
2025-02-14 22:43:59,362 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:44:10,223 [podnet.py] => Exemplar size: 500
2025-02-14 22:44:10,223 [trainer.py] => CNN: {'total': 47.48, '00-09': 48.2, '10-19': 30.4, '20-29': 80.2, 'old': 39.3, 'new': 80.2}
2025-02-14 22:44:10,223 [trainer.py] => NME: {'total': 47.16, '00-09': 51.5, '10-19': 29.7, '20-29': 73.4, 'old': 40.6, 'new': 73.4}
2025-02-14 22:44:10,223 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48]
2025-02-14 22:44:10,223 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44]
2025-02-14 22:44:10,223 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16]
2025-02-14 22:44:10,223 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52]

2025-02-14 22:44:10,224 [trainer.py] => Average Accuracy (CNN): 68.63000000000001
2025-02-14 22:44:10,224 [trainer.py] => Average Accuracy (NME): 67.03799999999998
2025-02-14 22:44:10,224 [trainer.py] => All params: 482257
2025-02-14 22:44:10,224 [trainer.py] => Trainable params: 482257
2025-02-14 22:44:10,225 [podnet.py] => Learning on 25-30
2025-02-14 22:44:10,248 [podnet.py] => Adaptive factor: 2.449489742783178
2025-02-14 22:44:11,835 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 3.29, Spatial_loss 2.72, Flat_loss 0.89, Train_acc 49.17, Test_acc 19.70
2025-02-14 22:44:13,366 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 1.29, Spatial_loss 2.38, Flat_loss 0.38, Train_acc 67.03, Test_acc 25.13
2025-02-14 22:44:14,955 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 1.08, Spatial_loss 1.94, Flat_loss 0.25, Train_acc 72.67, Test_acc 29.00
2025-02-14 22:44:16,598 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 1.00, Spatial_loss 1.82, Flat_loss 0.22, Train_acc 73.80, Test_acc 29.43
2025-02-14 22:44:18,161 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 0.90, Spatial_loss 1.83, Flat_loss 0.21, Train_acc 76.37, Test_acc 30.10
2025-02-14 22:44:19,744 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 0.87, Spatial_loss 1.83, Flat_loss 0.20, Train_acc 76.60, Test_acc 29.40
2025-02-14 22:44:21,308 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 0.77, Spatial_loss 1.76, Flat_loss 0.20, Train_acc 80.33, Test_acc 22.03
2025-02-14 22:44:22,894 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 0.75, Spatial_loss 1.68, Flat_loss 0.19, Train_acc 80.33, Test_acc 32.93
2025-02-14 22:44:24,500 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 0.70, Spatial_loss 1.71, Flat_loss 0.19, Train_acc 81.80, Test_acc 32.83
2025-02-14 22:44:26,087 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 0.72, Spatial_loss 1.76, Flat_loss 0.19, Train_acc 81.67, Test_acc 36.37
2025-02-14 22:44:27,665 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 0.69, Spatial_loss 1.74, Flat_loss 0.20, Train_acc 82.50, Test_acc 32.80
2025-02-14 22:44:29,264 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.67, Spatial_loss 1.66, Flat_loss 0.19, Train_acc 82.40, Test_acc 32.70
2025-02-14 22:44:30,798 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.64, Spatial_loss 1.66, Flat_loss 0.19, Train_acc 83.30, Test_acc 33.93
2025-02-14 22:44:32,383 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.62, Spatial_loss 1.68, Flat_loss 0.19, Train_acc 84.57, Test_acc 23.50
2025-02-14 22:44:33,914 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.63, Spatial_loss 1.69, Flat_loss 0.20, Train_acc 83.80, Test_acc 28.67
2025-02-14 22:44:35,485 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.59, Spatial_loss 1.66, Flat_loss 0.19, Train_acc 85.80, Test_acc 33.77
2025-02-14 22:44:37,083 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.53, Spatial_loss 1.62, Flat_loss 0.19, Train_acc 86.80, Test_acc 34.50
2025-02-14 22:44:38,700 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.55, Spatial_loss 1.64, Flat_loss 0.20, Train_acc 86.13, Test_acc 32.87
2025-02-14 22:44:40,241 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.55, Spatial_loss 1.65, Flat_loss 0.19, Train_acc 86.43, Test_acc 32.00
2025-02-14 22:44:41,829 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.56, Spatial_loss 1.67, Flat_loss 0.19, Train_acc 86.17, Test_acc 33.33
2025-02-14 22:44:43,352 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.54, Spatial_loss 1.56, Flat_loss 0.19, Train_acc 86.50, Test_acc 38.67
2025-02-14 22:44:44,864 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.52, Spatial_loss 1.62, Flat_loss 0.19, Train_acc 86.47, Test_acc 37.13
2025-02-14 22:44:46,402 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.47, Spatial_loss 1.59, Flat_loss 0.19, Train_acc 88.73, Test_acc 33.53
2025-02-14 22:44:47,954 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.47, Spatial_loss 1.55, Flat_loss 0.19, Train_acc 88.10, Test_acc 34.87
2025-02-14 22:44:49,481 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.48, Spatial_loss 1.60, Flat_loss 0.19, Train_acc 88.67, Test_acc 35.87
2025-02-14 22:44:51,019 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.46, Spatial_loss 1.59, Flat_loss 0.19, Train_acc 88.57, Test_acc 33.13
2025-02-14 22:44:52,567 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.44, Spatial_loss 1.62, Flat_loss 0.20, Train_acc 89.07, Test_acc 36.20
2025-02-14 22:44:54,114 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.46, Spatial_loss 1.64, Flat_loss 0.19, Train_acc 89.50, Test_acc 33.10
2025-02-14 22:44:55,664 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.43, Spatial_loss 1.59, Flat_loss 0.19, Train_acc 89.60, Test_acc 31.77
2025-02-14 22:44:57,174 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.44, Spatial_loss 1.61, Flat_loss 0.19, Train_acc 89.80, Test_acc 34.93
2025-02-14 22:44:58,742 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.40, Spatial_loss 1.61, Flat_loss 0.19, Train_acc 90.87, Test_acc 32.73
2025-02-14 22:45:00,307 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.39, Spatial_loss 1.54, Flat_loss 0.19, Train_acc 91.33, Test_acc 31.73
2025-02-14 22:45:01,892 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.42, Spatial_loss 1.52, Flat_loss 0.19, Train_acc 90.43, Test_acc 27.57
2025-02-14 22:45:03,427 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.38, Spatial_loss 1.54, Flat_loss 0.19, Train_acc 91.27, Test_acc 32.33
2025-02-14 22:45:04,945 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.39, Spatial_loss 1.54, Flat_loss 0.18, Train_acc 91.20, Test_acc 32.87
2025-02-14 22:45:06,508 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.38, Spatial_loss 1.54, Flat_loss 0.19, Train_acc 91.37, Test_acc 35.60
2025-02-14 22:45:08,107 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.38, Spatial_loss 1.54, Flat_loss 0.19, Train_acc 92.30, Test_acc 37.27
2025-02-14 22:45:09,669 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 92.87, Test_acc 36.77
2025-02-14 22:45:11,223 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.33, Spatial_loss 1.46, Flat_loss 0.19, Train_acc 93.37, Test_acc 36.00
2025-02-14 22:45:12,756 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.39, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 90.53, Test_acc 31.80
2025-02-14 22:45:14,345 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 92.80, Test_acc 35.67
2025-02-14 22:45:15,879 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.34, Spatial_loss 1.50, Flat_loss 0.19, Train_acc 92.50, Test_acc 37.97
2025-02-14 22:45:17,467 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.19, Train_acc 93.67, Test_acc 34.17
2025-02-14 22:45:18,952 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.33, Spatial_loss 1.53, Flat_loss 0.19, Train_acc 92.93, Test_acc 36.07
2025-02-14 22:45:20,525 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.32, Spatial_loss 1.53, Flat_loss 0.19, Train_acc 93.60, Test_acc 28.37
2025-02-14 22:45:22,091 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.30, Spatial_loss 1.49, Flat_loss 0.19, Train_acc 94.23, Test_acc 37.20
2025-02-14 22:45:23,606 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.19, Train_acc 93.50, Test_acc 36.23
2025-02-14 22:45:25,175 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.31, Spatial_loss 1.56, Flat_loss 0.19, Train_acc 93.33, Test_acc 34.53
2025-02-14 22:45:26,706 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.19, Train_acc 93.37, Test_acc 35.00
2025-02-14 22:45:28,311 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.19, Train_acc 93.20, Test_acc 36.63
2025-02-14 22:45:29,919 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.30, Spatial_loss 1.47, Flat_loss 0.19, Train_acc 93.60, Test_acc 35.13
2025-02-14 22:45:31,454 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.28, Spatial_loss 1.44, Flat_loss 0.18, Train_acc 94.10, Test_acc 30.60
2025-02-14 22:45:33,016 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.19, Train_acc 93.73, Test_acc 35.53
2025-02-14 22:45:34,575 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.30, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 93.83, Test_acc 32.60
2025-02-14 22:45:36,060 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.30, Spatial_loss 1.44, Flat_loss 0.18, Train_acc 94.43, Test_acc 35.77
2025-02-14 22:45:37,645 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.18, Train_acc 95.23, Test_acc 35.07
2025-02-14 22:45:39,227 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.29, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 93.87, Test_acc 35.50
2025-02-14 22:45:40,775 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.19, Train_acc 93.60, Test_acc 35.77
2025-02-14 22:45:42,357 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.26, Spatial_loss 1.41, Flat_loss 0.18, Train_acc 95.37, Test_acc 36.17
2025-02-14 22:45:43,928 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.18, Train_acc 94.93, Test_acc 36.97
2025-02-14 22:45:45,509 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.24, Spatial_loss 1.33, Flat_loss 0.18, Train_acc 95.23, Test_acc 36.87
2025-02-14 22:45:47,067 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.25, Spatial_loss 1.41, Flat_loss 0.18, Train_acc 95.50, Test_acc 38.10
2025-02-14 22:45:48,651 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.24, Spatial_loss 1.34, Flat_loss 0.17, Train_acc 95.83, Test_acc 35.73
2025-02-14 22:45:50,200 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.24, Spatial_loss 1.37, Flat_loss 0.18, Train_acc 95.67, Test_acc 35.20
2025-02-14 22:45:51,782 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.23, Spatial_loss 1.38, Flat_loss 0.18, Train_acc 96.00, Test_acc 35.90
2025-02-14 22:45:53,333 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.23, Spatial_loss 1.34, Flat_loss 0.18, Train_acc 95.73, Test_acc 37.83
2025-02-14 22:45:54,875 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.24, Spatial_loss 1.32, Flat_loss 0.18, Train_acc 95.67, Test_acc 37.27
2025-02-14 22:45:56,430 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.20, Spatial_loss 1.34, Flat_loss 0.18, Train_acc 97.43, Test_acc 37.67
2025-02-14 22:45:58,035 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.20, Spatial_loss 1.33, Flat_loss 0.17, Train_acc 97.10, Test_acc 36.97
2025-02-14 22:45:59,618 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.23, Spatial_loss 1.36, Flat_loss 0.19, Train_acc 95.87, Test_acc 31.77
2025-02-14 22:46:01,232 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.24, Spatial_loss 1.33, Flat_loss 0.18, Train_acc 95.60, Test_acc 33.90
2025-02-14 22:46:02,794 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.20, Spatial_loss 1.26, Flat_loss 0.17, Train_acc 97.10, Test_acc 39.00
2025-02-14 22:46:04,370 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.20, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 97.13, Test_acc 37.47
2025-02-14 22:46:05,947 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 96.67, Test_acc 37.13
2025-02-14 22:46:07,489 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.20, Spatial_loss 1.28, Flat_loss 0.17, Train_acc 96.83, Test_acc 37.10
2025-02-14 22:46:09,090 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.20, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 96.93, Test_acc 39.37
2025-02-14 22:46:10,666 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.18, Spatial_loss 1.19, Flat_loss 0.17, Train_acc 97.50, Test_acc 37.90
2025-02-14 22:46:12,264 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.21, Spatial_loss 1.24, Flat_loss 0.17, Train_acc 96.70, Test_acc 34.90
2025-02-14 22:46:13,764 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.20, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 97.57, Test_acc 35.40
2025-02-14 22:46:15,371 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.18, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 98.03, Test_acc 37.27
2025-02-14 22:46:16,975 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 98.50, Test_acc 37.60
2025-02-14 22:46:18,552 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 98.03, Test_acc 38.40
2025-02-14 22:46:20,123 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.18, Spatial_loss 1.20, Flat_loss 0.16, Train_acc 97.37, Test_acc 36.60
2025-02-14 22:46:21,641 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 1.23, Flat_loss 0.17, Train_acc 98.23, Test_acc 36.33
2025-02-14 22:46:23,137 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.17, Spatial_loss 1.16, Flat_loss 0.16, Train_acc 97.90, Test_acc 35.00
2025-02-14 22:46:24,683 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.17, Train_acc 98.03, Test_acc 35.80
2025-02-14 22:46:26,323 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.16, Spatial_loss 1.21, Flat_loss 0.17, Train_acc 98.13, Test_acc 36.03
2025-02-14 22:46:27,912 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 97.67, Test_acc 35.13
2025-02-14 22:46:29,382 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.16, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 98.03, Test_acc 37.43
2025-02-14 22:46:30,982 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.17, Train_acc 97.60, Test_acc 39.00
2025-02-14 22:46:32,585 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.17, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 97.87, Test_acc 38.30
2025-02-14 22:46:34,106 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 98.20, Test_acc 38.70
2025-02-14 22:46:35,673 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.17, Spatial_loss 1.19, Flat_loss 0.17, Train_acc 98.13, Test_acc 38.17
2025-02-14 22:46:37,199 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.16, Spatial_loss 1.10, Flat_loss 0.16, Train_acc 98.23, Test_acc 36.47
2025-02-14 22:46:38,772 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.15, Spatial_loss 1.09, Flat_loss 0.16, Train_acc 98.63, Test_acc 40.20
2025-02-14 22:46:40,341 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.15, Spatial_loss 1.08, Flat_loss 0.16, Train_acc 98.80, Test_acc 39.03
2025-02-14 22:46:41,897 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.14, Spatial_loss 1.06, Flat_loss 0.15, Train_acc 99.17, Test_acc 36.93
2025-02-14 22:46:43,455 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.13, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 99.07, Test_acc 37.73
2025-02-14 22:46:44,967 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.14, Spatial_loss 1.08, Flat_loss 0.16, Train_acc 99.03, Test_acc 37.77
2025-02-14 22:46:46,483 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.16, Train_acc 98.87, Test_acc 36.83
2025-02-14 22:46:48,032 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.15, Spatial_loss 1.09, Flat_loss 0.16, Train_acc 98.43, Test_acc 39.20
2025-02-14 22:46:49,554 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.16, Train_acc 98.40, Test_acc 40.03
2025-02-14 22:46:51,092 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.16, Train_acc 98.33, Test_acc 36.77
2025-02-14 22:46:52,649 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.14, Spatial_loss 1.03, Flat_loss 0.16, Train_acc 98.80, Test_acc 35.50
2025-02-14 22:46:54,198 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.13, Spatial_loss 1.04, Flat_loss 0.16, Train_acc 99.23, Test_acc 39.33
2025-02-14 22:46:55,752 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.13, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 99.20, Test_acc 37.60
2025-02-14 22:46:57,332 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.13, Spatial_loss 1.10, Flat_loss 0.16, Train_acc 99.17, Test_acc 39.57
2025-02-14 22:46:58,964 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.16, Train_acc 98.97, Test_acc 38.40
2025-02-14 22:47:00,539 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.16, Train_acc 99.43, Test_acc 40.20
2025-02-14 22:47:02,111 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.16, Train_acc 99.00, Test_acc 38.07
2025-02-14 22:47:03,653 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.15, Train_acc 99.27, Test_acc 37.83
2025-02-14 22:47:05,250 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.15, Train_acc 99.27, Test_acc 38.97
2025-02-14 22:47:06,828 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.15, Train_acc 99.23, Test_acc 38.83
2025-02-14 22:47:08,417 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.13, Spatial_loss 1.00, Flat_loss 0.15, Train_acc 99.20, Test_acc 39.67
2025-02-14 22:47:10,024 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.13, Spatial_loss 1.00, Flat_loss 0.15, Train_acc 99.27, Test_acc 39.20
2025-02-14 22:47:11,557 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.15, Train_acc 99.20, Test_acc 39.27
2025-02-14 22:47:13,088 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.12, Spatial_loss 0.98, Flat_loss 0.15, Train_acc 99.47, Test_acc 38.90
2025-02-14 22:47:14,636 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.15, Train_acc 99.17, Test_acc 37.73
2025-02-14 22:47:16,140 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.12, Spatial_loss 0.99, Flat_loss 0.15, Train_acc 99.30, Test_acc 38.97
2025-02-14 22:47:17,746 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.97, Flat_loss 0.15, Train_acc 99.23, Test_acc 38.93
2025-02-14 22:47:19,301 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 99.47, Test_acc 36.97
2025-02-14 22:47:20,823 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.12, Spatial_loss 0.95, Flat_loss 0.15, Train_acc 99.53, Test_acc 38.47
2025-02-14 22:47:22,381 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.14, Train_acc 99.17, Test_acc 38.60
2025-02-14 22:47:23,962 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.15, Train_acc 99.53, Test_acc 38.97
2025-02-14 22:47:25,510 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 99.40, Test_acc 37.93
2025-02-14 22:47:27,037 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.14, Train_acc 99.27, Test_acc 38.83
2025-02-14 22:47:28,636 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 99.50, Test_acc 39.60
2025-02-14 22:47:30,257 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.14, Train_acc 99.53, Test_acc 38.63
2025-02-14 22:47:31,780 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.14, Train_acc 99.40, Test_acc 39.53
2025-02-14 22:47:33,329 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 99.60, Test_acc 39.67
2025-02-14 22:47:34,921 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 99.47, Test_acc 38.40
2025-02-14 22:47:36,520 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.14, Train_acc 99.37, Test_acc 38.53
2025-02-14 22:47:38,054 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.14, Train_acc 99.53, Test_acc 38.93
2025-02-14 22:47:39,571 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.14, Train_acc 99.70, Test_acc 39.03
2025-02-14 22:47:41,138 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.14, Train_acc 99.73, Test_acc 39.33
2025-02-14 22:47:42,736 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 99.73, Test_acc 38.43
2025-02-14 22:47:44,283 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.14, Train_acc 99.73, Test_acc 39.63
2025-02-14 22:47:45,822 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.14, Train_acc 99.67, Test_acc 39.53
2025-02-14 22:47:47,387 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 99.70, Test_acc 39.10
2025-02-14 22:47:48,941 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.77, Test_acc 39.73
2025-02-14 22:47:50,489 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.43, Test_acc 38.90
2025-02-14 22:47:52,109 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.63, Test_acc 38.90
2025-02-14 22:47:53,709 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 99.53, Test_acc 38.97
2025-02-14 22:47:55,272 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.70, Test_acc 39.17
2025-02-14 22:47:56,871 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 99.50, Test_acc 39.00
2025-02-14 22:47:58,367 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.77, Test_acc 39.10
2025-02-14 22:47:59,856 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.60, Test_acc 39.23
2025-02-14 22:48:01,478 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 99.70, Test_acc 39.37
2025-02-14 22:48:03,036 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.14, Train_acc 99.63, Test_acc 39.50
2025-02-14 22:48:04,600 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.70, Test_acc 39.00
2025-02-14 22:48:06,118 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.47, Test_acc 39.10
2025-02-14 22:48:07,639 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.83, Test_acc 39.23
2025-02-14 22:48:09,258 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.67, Test_acc 39.20
2025-02-14 22:48:10,837 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.67, Test_acc 39.10
2025-02-14 22:48:12,395 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.57, Test_acc 38.93
2025-02-14 22:48:14,005 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 99.73, Test_acc 39.17
2025-02-14 22:48:15,550 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.73, Test_acc 39.23
2025-02-14 22:48:17,116 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 99.80, Test_acc 38.93
2025-02-14 22:48:18,693 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.83, Test_acc 39.20
2025-02-14 22:48:20,296 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.73, Test_acc 38.90
2025-02-14 22:48:20,297 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:48:20,297 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:48:31,664 [podnet.py] => The size of finetune dataset: 600
2025-02-14 22:48:32,702 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.38, Spatial_loss 1.06, Flat_loss 0.11, Train_acc 89.67, Test_acc 42.10
2025-02-14 22:48:33,693 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.21, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 97.00, Test_acc 43.70
2025-02-14 22:48:34,675 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 99.50, Test_acc 43.93
2025-02-14 22:48:35,674 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.08, Train_acc 99.33, Test_acc 44.53
2025-02-14 22:48:36,666 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.10, Spatial_loss 0.88, Flat_loss 0.07, Train_acc 100.00, Test_acc 43.60
2025-02-14 22:48:37,656 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.07, Train_acc 100.00, Test_acc 43.17
2025-02-14 22:48:38,683 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 0.80, Flat_loss 0.07, Train_acc 100.00, Test_acc 42.67
2025-02-14 22:48:39,673 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 0.81, Flat_loss 0.07, Train_acc 100.00, Test_acc 42.43
2025-02-14 22:48:40,664 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 0.82, Flat_loss 0.07, Train_acc 100.00, Test_acc 42.30
2025-02-14 22:48:41,672 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.09, Spatial_loss 0.92, Flat_loss 0.07, Train_acc 100.00, Test_acc 42.27
2025-02-14 22:48:42,683 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.07, Train_acc 99.67, Test_acc 41.97
2025-02-14 22:48:43,689 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.07, Train_acc 100.00, Test_acc 41.60
2025-02-14 22:48:44,746 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 99.67, Test_acc 41.87
2025-02-14 22:48:45,742 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 0.75, Flat_loss 0.07, Train_acc 99.67, Test_acc 42.03
2025-02-14 22:48:46,749 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 0.70, Flat_loss 0.06, Train_acc 100.00, Test_acc 42.10
2025-02-14 22:48:47,779 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.91, Flat_loss 0.07, Train_acc 99.67, Test_acc 42.13
2025-02-14 22:48:48,784 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.07, Train_acc 99.83, Test_acc 42.33
2025-02-14 22:48:49,771 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 0.84, Flat_loss 0.07, Train_acc 99.50, Test_acc 42.17
2025-02-14 22:48:50,734 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 100.00, Test_acc 42.20
2025-02-14 22:48:51,764 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.84, Flat_loss 0.07, Train_acc 99.67, Test_acc 42.30
2025-02-14 22:48:51,765 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:49:04,106 [podnet.py] => Exemplar size: 600
2025-02-14 22:49:04,106 [trainer.py] => CNN: {'total': 42.3, '00-09': 43.0, '10-19': 18.0, '20-29': 65.9, 'old': 33.76, 'new': 85.0}
2025-02-14 22:49:04,106 [trainer.py] => NME: {'total': 42.4, '00-09': 48.8, '10-19': 18.6, '20-29': 59.8, 'old': 35.36, 'new': 77.6}
2025-02-14 22:49:04,106 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3]
2025-02-14 22:49:04,106 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5]
2025-02-14 22:49:04,106 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4]
2025-02-14 22:49:04,106 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7]

2025-02-14 22:49:04,106 [trainer.py] => Average Accuracy (CNN): 64.24166666666667
2025-02-14 22:49:04,106 [trainer.py] => Average Accuracy (NME): 62.93166666666665
2025-02-14 22:49:04,107 [trainer.py] => All params: 485457
2025-02-14 22:49:04,107 [trainer.py] => Trainable params: 485457
2025-02-14 22:49:04,108 [podnet.py] => Learning on 30-35
2025-02-14 22:49:04,131 [podnet.py] => Adaptive factor: 2.6457513110645907
2025-02-14 22:49:05,795 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 3.54, Spatial_loss 2.71, Flat_loss 0.99, Train_acc 39.94, Test_acc 16.71
2025-02-14 22:49:07,397 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 1.54, Spatial_loss 2.26, Flat_loss 0.42, Train_acc 53.90, Test_acc 23.14
2025-02-14 22:49:09,043 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 1.33, Spatial_loss 2.01, Flat_loss 0.28, Train_acc 59.42, Test_acc 29.29
2025-02-14 22:49:10,701 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 1.24, Spatial_loss 1.94, Flat_loss 0.25, Train_acc 62.13, Test_acc 29.80
2025-02-14 22:49:12,350 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 1.18, Spatial_loss 1.89, Flat_loss 0.24, Train_acc 63.26, Test_acc 23.00
2025-02-14 22:49:14,038 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 1.11, Spatial_loss 1.91, Flat_loss 0.23, Train_acc 64.68, Test_acc 26.94
2025-02-14 22:49:15,661 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 1.04, Spatial_loss 1.87, Flat_loss 0.22, Train_acc 67.90, Test_acc 23.89
2025-02-14 22:49:17,250 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 1.04, Spatial_loss 1.88, Flat_loss 0.22, Train_acc 68.29, Test_acc 27.40
2025-02-14 22:49:18,867 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 1.01, Spatial_loss 1.85, Flat_loss 0.22, Train_acc 69.68, Test_acc 24.23
2025-02-14 22:49:20,522 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.94, Spatial_loss 1.88, Flat_loss 0.22, Train_acc 71.48, Test_acc 21.97
2025-02-14 22:49:22,123 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.96, Spatial_loss 1.92, Flat_loss 0.22, Train_acc 71.39, Test_acc 32.83
2025-02-14 22:49:23,722 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.91, Spatial_loss 1.80, Flat_loss 0.21, Train_acc 72.48, Test_acc 28.11
2025-02-14 22:49:25,384 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.87, Spatial_loss 1.71, Flat_loss 0.20, Train_acc 75.13, Test_acc 26.23
2025-02-14 22:49:27,043 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.83, Spatial_loss 1.84, Flat_loss 0.21, Train_acc 74.97, Test_acc 28.06
2025-02-14 22:49:28,649 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.86, Spatial_loss 1.81, Flat_loss 0.22, Train_acc 74.81, Test_acc 30.37
2025-02-14 22:49:30,302 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.88, Spatial_loss 1.74, Flat_loss 0.22, Train_acc 75.03, Test_acc 25.57
2025-02-14 22:49:31,926 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.84, Spatial_loss 1.82, Flat_loss 0.22, Train_acc 75.90, Test_acc 32.37
2025-02-14 22:49:33,540 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.80, Spatial_loss 1.79, Flat_loss 0.22, Train_acc 76.29, Test_acc 29.37
2025-02-14 22:49:35,218 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.76, Spatial_loss 1.76, Flat_loss 0.22, Train_acc 78.00, Test_acc 33.26
2025-02-14 22:49:36,818 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.78, Spatial_loss 1.95, Flat_loss 0.23, Train_acc 77.71, Test_acc 25.37
2025-02-14 22:49:38,421 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.72, Spatial_loss 1.71, Flat_loss 0.21, Train_acc 79.61, Test_acc 33.91
2025-02-14 22:49:40,089 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.77, Spatial_loss 1.73, Flat_loss 0.22, Train_acc 77.84, Test_acc 27.03
2025-02-14 22:49:41,787 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.73, Spatial_loss 1.71, Flat_loss 0.22, Train_acc 79.71, Test_acc 33.11
2025-02-14 22:49:43,417 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.73, Spatial_loss 1.72, Flat_loss 0.22, Train_acc 79.45, Test_acc 33.31
2025-02-14 22:49:45,082 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.75, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 79.55, Test_acc 29.74
2025-02-14 22:49:46,639 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.70, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 79.39, Test_acc 32.31
2025-02-14 22:49:48,273 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.65, Spatial_loss 1.73, Flat_loss 0.22, Train_acc 82.13, Test_acc 28.80
2025-02-14 22:49:49,917 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.63, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 82.74, Test_acc 33.94
2025-02-14 22:49:51,562 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.64, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 82.03, Test_acc 35.83
2025-02-14 22:49:53,132 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.64, Spatial_loss 1.71, Flat_loss 0.23, Train_acc 82.39, Test_acc 30.97
2025-02-14 22:49:54,742 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.69, Spatial_loss 1.75, Flat_loss 0.23, Train_acc 81.32, Test_acc 28.51
2025-02-14 22:49:56,331 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.63, Spatial_loss 1.76, Flat_loss 0.22, Train_acc 83.29, Test_acc 26.71
2025-02-14 22:49:57,937 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.60, Spatial_loss 1.72, Flat_loss 0.23, Train_acc 83.61, Test_acc 32.83
2025-02-14 22:49:59,525 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.57, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 84.94, Test_acc 29.11
2025-02-14 22:50:01,173 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.57, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 85.06, Test_acc 34.83
2025-02-14 22:50:02,778 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.56, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 85.52, Test_acc 32.11
2025-02-14 22:50:04,384 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.61, Spatial_loss 1.67, Flat_loss 0.23, Train_acc 83.90, Test_acc 30.46
2025-02-14 22:50:05,969 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.62, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 83.10, Test_acc 31.54
2025-02-14 22:50:07,589 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.59, Spatial_loss 1.76, Flat_loss 0.24, Train_acc 83.94, Test_acc 28.49
2025-02-14 22:50:09,245 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.52, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 87.71, Test_acc 29.63
2025-02-14 22:50:10,862 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.54, Spatial_loss 1.73, Flat_loss 0.23, Train_acc 86.23, Test_acc 30.26
2025-02-14 22:50:12,446 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.52, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 86.52, Test_acc 35.26
2025-02-14 22:50:14,009 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.51, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 86.52, Test_acc 30.71
2025-02-14 22:50:15,660 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.50, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 87.35, Test_acc 34.14
2025-02-14 22:50:17,313 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.58, Spatial_loss 1.70, Flat_loss 0.23, Train_acc 84.52, Test_acc 24.51
2025-02-14 22:50:18,927 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.57, Spatial_loss 1.69, Flat_loss 0.23, Train_acc 85.29, Test_acc 32.43
2025-02-14 22:50:20,533 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.56, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 85.81, Test_acc 31.26
2025-02-14 22:50:22,177 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.51, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 86.55, Test_acc 29.83
2025-02-14 22:50:23,876 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.44, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 89.39, Test_acc 36.60
2025-02-14 22:50:25,485 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.45, Spatial_loss 1.54, Flat_loss 0.23, Train_acc 89.35, Test_acc 30.06
2025-02-14 22:50:27,098 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.45, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 88.94, Test_acc 32.40
2025-02-14 22:50:28,710 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.42, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 89.65, Test_acc 34.51
2025-02-14 22:50:30,360 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 90.35, Test_acc 35.31
2025-02-14 22:50:32,031 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.46, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 88.32, Test_acc 32.49
2025-02-14 22:50:33,601 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.45, Spatial_loss 1.54, Flat_loss 0.23, Train_acc 89.61, Test_acc 30.37
2025-02-14 22:50:35,188 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.46, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 88.87, Test_acc 32.49
2025-02-14 22:50:36,750 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.42, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 90.58, Test_acc 31.03
2025-02-14 22:50:38,364 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.43, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 90.03, Test_acc 32.40
2025-02-14 22:50:40,027 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.42, Spatial_loss 1.58, Flat_loss 0.24, Train_acc 90.00, Test_acc 32.83
2025-02-14 22:50:41,698 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.40, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 90.84, Test_acc 23.51
2025-02-14 22:50:43,340 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.39, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 90.61, Test_acc 34.63
2025-02-14 22:50:44,974 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 92.00, Test_acc 28.26
2025-02-14 22:50:46,512 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.35, Spatial_loss 1.45, Flat_loss 0.22, Train_acc 92.65, Test_acc 30.00
2025-02-14 22:50:48,176 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.38, Spatial_loss 1.46, Flat_loss 0.23, Train_acc 90.90, Test_acc 32.40
2025-02-14 22:50:49,784 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.36, Spatial_loss 1.49, Flat_loss 0.23, Train_acc 92.06, Test_acc 30.31
2025-02-14 22:50:51,379 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.37, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 91.94, Test_acc 34.97
2025-02-14 22:50:53,007 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.34, Spatial_loss 1.45, Flat_loss 0.22, Train_acc 93.10, Test_acc 30.91
2025-02-14 22:50:54,609 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.31, Spatial_loss 1.43, Flat_loss 0.22, Train_acc 93.84, Test_acc 29.63
2025-02-14 22:50:56,154 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 92.65, Test_acc 36.86
2025-02-14 22:50:57,790 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.36, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 92.16, Test_acc 32.89
2025-02-14 22:50:59,344 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.36, Spatial_loss 1.45, Flat_loss 0.23, Train_acc 92.16, Test_acc 33.06
2025-02-14 22:51:00,930 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.34, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 92.55, Test_acc 31.69
2025-02-14 22:51:02,481 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.34, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 92.61, Test_acc 34.63
2025-02-14 22:51:04,061 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.32, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 93.26, Test_acc 31.29
2025-02-14 22:51:05,648 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.31, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 94.13, Test_acc 32.11
2025-02-14 22:51:07,266 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.30, Spatial_loss 1.38, Flat_loss 0.22, Train_acc 94.03, Test_acc 32.66
2025-02-14 22:51:08,943 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.33, Spatial_loss 1.42, Flat_loss 0.22, Train_acc 93.16, Test_acc 33.60
2025-02-14 22:51:10,575 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 94.32, Test_acc 30.91
2025-02-14 22:51:12,257 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.22, Train_acc 93.97, Test_acc 37.31
2025-02-14 22:51:13,889 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.22, Train_acc 94.90, Test_acc 33.63
2025-02-14 22:51:15,506 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.29, Spatial_loss 1.41, Flat_loss 0.22, Train_acc 94.42, Test_acc 35.60
2025-02-14 22:51:17,101 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.30, Spatial_loss 1.43, Flat_loss 0.22, Train_acc 94.68, Test_acc 36.54
2025-02-14 22:51:18,823 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.30, Spatial_loss 1.44, Flat_loss 0.22, Train_acc 94.39, Test_acc 34.11
2025-02-14 22:51:20,416 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.30, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 94.77, Test_acc 33.97
2025-02-14 22:51:22,058 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.22, Train_acc 94.42, Test_acc 32.09
2025-02-14 22:51:23,664 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 95.35, Test_acc 34.09
2025-02-14 22:51:25,317 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.28, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 94.52, Test_acc 34.91
2025-02-14 22:51:26,892 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.29, Spatial_loss 1.33, Flat_loss 0.21, Train_acc 94.26, Test_acc 33.29
2025-02-14 22:51:28,549 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.21, Train_acc 95.26, Test_acc 35.49
2025-02-14 22:51:30,187 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.22, Train_acc 94.77, Test_acc 32.83
2025-02-14 22:51:31,878 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 96.45, Test_acc 36.51
2025-02-14 22:51:33,492 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.25, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 96.19, Test_acc 33.23
2025-02-14 22:51:35,140 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.21, Train_acc 95.32, Test_acc 35.57
2025-02-14 22:51:36,716 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.21, Train_acc 96.26, Test_acc 33.23
2025-02-14 22:51:38,320 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.20, Train_acc 96.87, Test_acc 34.14
2025-02-14 22:51:39,943 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.24, Spatial_loss 1.29, Flat_loss 0.21, Train_acc 95.87, Test_acc 31.00
2025-02-14 22:51:41,583 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.21, Train_acc 96.23, Test_acc 35.20
2025-02-14 22:51:43,172 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.20, Train_acc 96.19, Test_acc 32.29
2025-02-14 22:51:44,860 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 1.24, Flat_loss 0.21, Train_acc 96.52, Test_acc 29.80
2025-02-14 22:51:46,543 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.21, Train_acc 95.94, Test_acc 34.14
2025-02-14 22:51:48,204 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.21, Train_acc 96.13, Test_acc 34.26
2025-02-14 22:51:49,816 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 96.90, Test_acc 33.06
2025-02-14 22:51:51,427 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.20, Train_acc 97.39, Test_acc 35.40
2025-02-14 22:51:53,038 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.20, Train_acc 97.29, Test_acc 33.63
2025-02-14 22:51:54,681 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.20, Spatial_loss 1.24, Flat_loss 0.21, Train_acc 97.45, Test_acc 34.83
2025-02-14 22:51:56,294 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.20, Train_acc 97.81, Test_acc 35.60
2025-02-14 22:51:57,942 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 98.19, Test_acc 34.34
2025-02-14 22:51:59,601 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 97.81, Test_acc 37.06
2025-02-14 22:52:01,183 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 97.26, Test_acc 34.63
2025-02-14 22:52:02,835 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 97.71, Test_acc 36.17
2025-02-14 22:52:04,495 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 97.90, Test_acc 36.26
2025-02-14 22:52:06,117 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 97.97, Test_acc 34.60
2025-02-14 22:52:07,794 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 97.71, Test_acc 35.14
2025-02-14 22:52:09,385 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 98.16, Test_acc 32.31
2025-02-14 22:52:11,002 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 98.13, Test_acc 35.06
2025-02-14 22:52:12,612 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 98.26, Test_acc 34.97
2025-02-14 22:52:14,228 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 98.06, Test_acc 35.74
2025-02-14 22:52:15,812 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.55, Test_acc 35.54
2025-02-14 22:52:17,433 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 1.04, Flat_loss 0.19, Train_acc 98.45, Test_acc 36.51
2025-02-14 22:52:19,051 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.19, Train_acc 98.35, Test_acc 36.00
2025-02-14 22:52:20,710 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.06, Test_acc 35.31
2025-02-14 22:52:22,350 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.39, Test_acc 34.29
2025-02-14 22:52:23,977 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.81, Test_acc 35.54
2025-02-14 22:52:25,565 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.77, Test_acc 34.40
2025-02-14 22:52:27,210 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 99.19, Test_acc 36.23
2025-02-14 22:52:28,837 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 99.10, Test_acc 35.40
2025-02-14 22:52:30,474 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.15, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.97, Test_acc 37.66
2025-02-14 22:52:32,061 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.84, Test_acc 34.49
2025-02-14 22:52:33,730 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 99.03, Test_acc 35.91
2025-02-14 22:52:35,341 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 99.10, Test_acc 35.63
2025-02-14 22:52:36,954 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.15, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.68, Test_acc 35.17
2025-02-14 22:52:38,518 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.16, Test_acc 35.49
2025-02-14 22:52:40,129 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 99.06, Test_acc 35.57
2025-02-14 22:52:41,736 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.14, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 99.06, Test_acc 36.63
2025-02-14 22:52:43,326 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 99.23, Test_acc 35.74
2025-02-14 22:52:44,925 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 99.29, Test_acc 35.23
2025-02-14 22:52:46,486 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 99.32, Test_acc 37.31
2025-02-14 22:52:48,093 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 99.32, Test_acc 37.29
2025-02-14 22:52:49,726 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.03, Test_acc 34.89
2025-02-14 22:52:51,318 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 99.32, Test_acc 37.00
2025-02-14 22:52:52,937 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.10, Test_acc 36.80
2025-02-14 22:52:54,534 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.10, Test_acc 36.29
2025-02-14 22:52:56,196 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 98.87, Test_acc 36.20
2025-02-14 22:52:57,815 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 99.06, Test_acc 35.54
2025-02-14 22:52:59,392 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.06, Test_acc 36.09
2025-02-14 22:53:01,064 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.55, Test_acc 36.57
2025-02-14 22:53:02,670 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.16, Test_acc 37.03
2025-02-14 22:53:04,226 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 99.10, Test_acc 35.86
2025-02-14 22:53:05,824 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.26, Test_acc 36.26
2025-02-14 22:53:07,464 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.45, Test_acc 36.00
2025-02-14 22:53:09,094 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.18, Train_acc 99.19, Test_acc 36.49
2025-02-14 22:53:10,678 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.61, Test_acc 36.51
2025-02-14 22:53:12,313 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.14, Spatial_loss 0.82, Flat_loss 0.18, Train_acc 99.19, Test_acc 36.51
2025-02-14 22:53:13,946 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.42, Test_acc 36.49
2025-02-14 22:53:15,563 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.18, Train_acc 99.29, Test_acc 36.66
2025-02-14 22:53:17,207 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.23, Test_acc 36.49
2025-02-14 22:53:18,797 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.14, Spatial_loss 0.84, Flat_loss 0.18, Train_acc 99.39, Test_acc 36.26
2025-02-14 22:53:20,424 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.18, Train_acc 99.16, Test_acc 36.14
2025-02-14 22:53:22,061 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.18, Train_acc 99.26, Test_acc 36.26
2025-02-14 22:53:23,715 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.18, Train_acc 99.45, Test_acc 36.77
2025-02-14 22:53:23,716 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:53:23,716 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:53:36,867 [podnet.py] => The size of finetune dataset: 700
2025-02-14 22:53:37,928 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.50, Spatial_loss 1.36, Flat_loss 0.15, Train_acc 87.57, Test_acc 40.14
2025-02-14 22:53:39,030 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.25, Spatial_loss 1.09, Flat_loss 0.12, Train_acc 95.71, Test_acc 40.17
2025-02-14 22:53:40,121 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 98.86, Test_acc 41.06
2025-02-14 22:53:41,170 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.16, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.86, Test_acc 41.69
2025-02-14 22:53:42,277 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.09, Train_acc 99.71, Test_acc 40.80
2025-02-14 22:53:43,329 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 99.43, Test_acc 39.66
2025-02-14 22:53:44,367 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.09, Train_acc 99.86, Test_acc 39.29
2025-02-14 22:53:45,415 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 99.29, Test_acc 39.71
2025-02-14 22:53:46,511 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 99.57, Test_acc 39.51
2025-02-14 22:53:47,560 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 99.71, Test_acc 39.29
2025-02-14 22:53:48,526 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.43, Test_acc 39.51
2025-02-14 22:53:49,501 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 99.43, Test_acc 39.77
2025-02-14 22:53:50,491 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 99.86, Test_acc 39.66
2025-02-14 22:53:51,578 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 0.95, Flat_loss 0.08, Train_acc 99.57, Test_acc 39.40
2025-02-14 22:53:52,602 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 99.43, Test_acc 39.34
2025-02-14 22:53:53,633 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 99.57, Test_acc 39.51
2025-02-14 22:53:54,675 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.08, Train_acc 100.00, Test_acc 39.46
2025-02-14 22:53:55,700 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 99.86, Test_acc 39.66
2025-02-14 22:53:56,788 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 100.00, Test_acc 39.63
2025-02-14 22:53:57,814 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.87, Flat_loss 0.08, Train_acc 100.00, Test_acc 39.49
2025-02-14 22:53:57,816 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:54:12,002 [podnet.py] => Exemplar size: 700
2025-02-14 22:54:12,002 [trainer.py] => CNN: {'total': 39.49, '00-09': 43.2, '10-19': 15.9, '20-29': 43.1, '30-39': 72.0, 'old': 34.07, 'new': 72.0}
2025-02-14 22:54:12,002 [trainer.py] => NME: {'total': 38.97, '00-09': 47.6, '10-19': 15.4, '20-29': 40.4, '30-39': 66.0, 'old': 34.47, 'new': 66.0}
2025-02-14 22:54:12,002 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49]
2025-02-14 22:54:12,002 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54]
2025-02-14 22:54:12,002 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97]
2025-02-14 22:54:12,002 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0]

2025-02-14 22:54:12,002 [trainer.py] => Average Accuracy (CNN): 60.70571428571429
2025-02-14 22:54:12,002 [trainer.py] => Average Accuracy (NME): 59.50857142857142
2025-02-14 22:54:12,003 [trainer.py] => All params: 488657
2025-02-14 22:54:12,003 [trainer.py] => Trainable params: 488657
2025-02-14 22:54:12,004 [podnet.py] => Learning on 35-40
2025-02-14 22:54:12,028 [podnet.py] => Adaptive factor: 2.8284271247461903
2025-02-14 22:54:13,682 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 3.25, Spatial_loss 2.76, Flat_loss 0.86, Train_acc 49.88, Test_acc 17.62
2025-02-14 22:54:15,308 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 1.37, Spatial_loss 2.26, Flat_loss 0.37, Train_acc 63.91, Test_acc 27.72
2025-02-14 22:54:17,068 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 1.12, Spatial_loss 1.97, Flat_loss 0.29, Train_acc 69.47, Test_acc 27.45
2025-02-14 22:54:18,788 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 1.02, Spatial_loss 2.00, Flat_loss 0.26, Train_acc 72.44, Test_acc 24.30
2025-02-14 22:54:20,442 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 0.99, Spatial_loss 2.03, Flat_loss 0.27, Train_acc 73.31, Test_acc 27.70
2025-02-14 22:54:22,086 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 0.91, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 76.59, Test_acc 27.55
2025-02-14 22:54:23,758 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 0.92, Spatial_loss 1.93, Flat_loss 0.26, Train_acc 75.41, Test_acc 30.48
2025-02-14 22:54:25,419 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 0.83, Spatial_loss 1.90, Flat_loss 0.25, Train_acc 78.59, Test_acc 23.90
2025-02-14 22:54:27,148 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 0.83, Spatial_loss 1.97, Flat_loss 0.25, Train_acc 78.25, Test_acc 30.95
2025-02-14 22:54:28,810 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 0.75, Spatial_loss 1.87, Flat_loss 0.24, Train_acc 81.28, Test_acc 20.08
2025-02-14 22:54:30,509 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 0.77, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 79.91, Test_acc 25.55
2025-02-14 22:54:32,243 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 0.71, Spatial_loss 1.81, Flat_loss 0.24, Train_acc 81.97, Test_acc 27.30
2025-02-14 22:54:33,900 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 0.71, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 82.28, Test_acc 24.05
2025-02-14 22:54:35,557 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.64, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 84.06, Test_acc 27.08
2025-02-14 22:54:37,264 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.64, Spatial_loss 1.78, Flat_loss 0.25, Train_acc 84.00, Test_acc 27.50
2025-02-14 22:54:38,943 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.62, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 84.91, Test_acc 22.45
2025-02-14 22:54:40,558 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.64, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 84.69, Test_acc 26.70
2025-02-14 22:54:42,207 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.62, Spatial_loss 1.85, Flat_loss 0.25, Train_acc 84.09, Test_acc 29.08
2025-02-14 22:54:43,889 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.63, Spatial_loss 1.83, Flat_loss 0.25, Train_acc 84.34, Test_acc 28.38
2025-02-14 22:54:45,516 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.60, Spatial_loss 1.82, Flat_loss 0.25, Train_acc 85.16, Test_acc 27.82
2025-02-14 22:54:47,218 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.55, Spatial_loss 1.76, Flat_loss 0.24, Train_acc 86.56, Test_acc 27.62
2025-02-14 22:54:48,896 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.59, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 85.34, Test_acc 29.02
2025-02-14 22:54:50,584 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.56, Spatial_loss 1.75, Flat_loss 0.25, Train_acc 86.03, Test_acc 22.22
2025-02-14 22:54:52,291 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.55, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 86.47, Test_acc 28.68
2025-02-14 22:54:53,929 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.56, Spatial_loss 1.76, Flat_loss 0.25, Train_acc 86.50, Test_acc 30.18
2025-02-14 22:54:55,588 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.51, Spatial_loss 1.64, Flat_loss 0.24, Train_acc 87.97, Test_acc 30.20
2025-02-14 22:54:57,248 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.48, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 89.03, Test_acc 26.12
2025-02-14 22:54:58,869 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.51, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 88.00, Test_acc 25.95
2025-02-14 22:55:00,596 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.53, Spatial_loss 1.82, Flat_loss 0.25, Train_acc 86.84, Test_acc 28.40
2025-02-14 22:55:02,274 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.53, Spatial_loss 1.78, Flat_loss 0.25, Train_acc 87.19, Test_acc 27.68
2025-02-14 22:55:03,920 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.47, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 89.44, Test_acc 30.25
2025-02-14 22:55:05,528 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.44, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 89.78, Test_acc 25.18
2025-02-14 22:55:07,164 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.46, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 89.34, Test_acc 26.30
2025-02-14 22:55:08,903 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.44, Spatial_loss 1.64, Flat_loss 0.24, Train_acc 89.66, Test_acc 30.15
2025-02-14 22:55:10,581 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.47, Spatial_loss 1.71, Flat_loss 0.25, Train_acc 88.62, Test_acc 26.52
2025-02-14 22:55:12,208 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.44, Spatial_loss 1.73, Flat_loss 0.25, Train_acc 90.22, Test_acc 32.38
2025-02-14 22:55:13,892 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.45, Spatial_loss 1.72, Flat_loss 0.25, Train_acc 89.22, Test_acc 29.90
2025-02-14 22:55:15,594 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.45, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 89.28, Test_acc 28.62
2025-02-14 22:55:17,309 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.42, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 90.53, Test_acc 27.70
2025-02-14 22:55:18,954 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.43, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 90.19, Test_acc 27.58
2025-02-14 22:55:20,702 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.43, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 90.38, Test_acc 29.70
2025-02-14 22:55:22,372 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.41, Spatial_loss 1.59, Flat_loss 0.24, Train_acc 90.84, Test_acc 29.30
2025-02-14 22:55:24,024 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.39, Spatial_loss 1.56, Flat_loss 0.24, Train_acc 91.84, Test_acc 31.95
2025-02-14 22:55:25,668 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.38, Spatial_loss 1.59, Flat_loss 0.24, Train_acc 91.59, Test_acc 30.70
2025-02-14 22:55:27,355 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.39, Spatial_loss 1.62, Flat_loss 0.25, Train_acc 90.97, Test_acc 29.90
2025-02-14 22:55:29,027 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.41, Spatial_loss 1.68, Flat_loss 0.25, Train_acc 90.34, Test_acc 28.62
2025-02-14 22:55:30,681 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.41, Spatial_loss 1.73, Flat_loss 0.26, Train_acc 90.38, Test_acc 25.20
2025-02-14 22:55:32,292 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.38, Spatial_loss 1.58, Flat_loss 0.24, Train_acc 91.69, Test_acc 30.08
2025-02-14 22:55:33,942 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.35, Spatial_loss 1.62, Flat_loss 0.25, Train_acc 92.25, Test_acc 28.75
2025-02-14 22:55:35,569 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.32, Spatial_loss 1.51, Flat_loss 0.23, Train_acc 93.84, Test_acc 29.75
2025-02-14 22:55:37,216 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.35, Spatial_loss 1.52, Flat_loss 0.24, Train_acc 93.06, Test_acc 27.48
2025-02-14 22:55:38,913 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.36, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 92.44, Test_acc 31.10
2025-02-14 22:55:40,526 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.35, Spatial_loss 1.55, Flat_loss 0.24, Train_acc 92.81, Test_acc 23.88
2025-02-14 22:55:42,136 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.35, Spatial_loss 1.53, Flat_loss 0.24, Train_acc 92.38, Test_acc 29.75
2025-02-14 22:55:43,824 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.34, Spatial_loss 1.56, Flat_loss 0.24, Train_acc 92.94, Test_acc 27.25
2025-02-14 22:55:45,491 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.32, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 93.91, Test_acc 29.58
2025-02-14 22:55:47,105 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.31, Spatial_loss 1.52, Flat_loss 0.24, Train_acc 93.72, Test_acc 27.55
2025-02-14 22:55:48,675 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.33, Spatial_loss 1.56, Flat_loss 0.24, Train_acc 93.62, Test_acc 29.88
2025-02-14 22:55:50,366 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.31, Spatial_loss 1.55, Flat_loss 0.24, Train_acc 93.97, Test_acc 22.45
2025-02-14 22:55:51,970 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.33, Spatial_loss 1.62, Flat_loss 0.24, Train_acc 93.50, Test_acc 29.62
2025-02-14 22:55:53,604 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.29, Spatial_loss 1.46, Flat_loss 0.23, Train_acc 94.16, Test_acc 30.52
2025-02-14 22:55:55,172 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.29, Spatial_loss 1.48, Flat_loss 0.24, Train_acc 94.53, Test_acc 28.18
2025-02-14 22:55:56,799 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.32, Spatial_loss 1.54, Flat_loss 0.24, Train_acc 93.72, Test_acc 30.88
2025-02-14 22:55:58,425 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.30, Spatial_loss 1.49, Flat_loss 0.23, Train_acc 94.50, Test_acc 25.55
2025-02-14 22:56:00,090 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.31, Spatial_loss 1.53, Flat_loss 0.24, Train_acc 93.66, Test_acc 28.10
2025-02-14 22:56:01,701 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.29, Spatial_loss 1.41, Flat_loss 0.23, Train_acc 94.84, Test_acc 31.08
2025-02-14 22:56:03,331 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.27, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 95.28, Test_acc 32.20
2025-02-14 22:56:04,993 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.31, Spatial_loss 1.51, Flat_loss 0.23, Train_acc 93.94, Test_acc 31.58
2025-02-14 22:56:06,659 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.30, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 94.31, Test_acc 28.45
2025-02-14 22:56:08,302 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 96.19, Test_acc 26.52
2025-02-14 22:56:09,916 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.24, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 96.25, Test_acc 28.48
2025-02-14 22:56:11,557 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 95.66, Test_acc 29.80
2025-02-14 22:56:13,211 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.27, Spatial_loss 1.38, Flat_loss 0.23, Train_acc 95.50, Test_acc 30.90
2025-02-14 22:56:14,853 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 94.72, Test_acc 31.80
2025-02-14 22:56:16,463 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.24, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 96.16, Test_acc 28.70
2025-02-14 22:56:18,113 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.26, Spatial_loss 1.43, Flat_loss 0.23, Train_acc 95.38, Test_acc 30.18
2025-02-14 22:56:19,697 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 1.39, Flat_loss 0.23, Train_acc 96.09, Test_acc 30.90
2025-02-14 22:56:21,340 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 1.35, Flat_loss 0.22, Train_acc 96.53, Test_acc 32.42
2025-02-14 22:56:23,002 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.24, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 96.31, Test_acc 29.80
2025-02-14 22:56:24,682 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.23, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 96.50, Test_acc 30.70
2025-02-14 22:56:26,273 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 96.38, Test_acc 32.33
2025-02-14 22:56:27,927 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.22, Spatial_loss 1.32, Flat_loss 0.22, Train_acc 96.84, Test_acc 29.60
2025-02-14 22:56:29,638 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.22, Spatial_loss 1.30, Flat_loss 0.22, Train_acc 96.91, Test_acc 30.90
2025-02-14 22:56:31,286 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.20, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 97.88, Test_acc 30.55
2025-02-14 22:56:32,978 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.21, Spatial_loss 1.30, Flat_loss 0.22, Train_acc 97.12, Test_acc 31.68
2025-02-14 22:56:34,638 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.19, Spatial_loss 1.23, Flat_loss 0.21, Train_acc 97.78, Test_acc 30.55
2025-02-14 22:56:36,346 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.21, Train_acc 97.56, Test_acc 29.12
2025-02-14 22:56:37,985 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 1.31, Flat_loss 0.22, Train_acc 97.00, Test_acc 30.00
2025-02-14 22:56:39,612 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.21, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 97.25, Test_acc 32.60
2025-02-14 22:56:41,265 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 97.72, Test_acc 30.25
2025-02-14 22:56:42,948 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.21, Train_acc 97.34, Test_acc 29.12
2025-02-14 22:56:44,527 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.19, Spatial_loss 1.26, Flat_loss 0.22, Train_acc 97.97, Test_acc 29.72
2025-02-14 22:56:46,143 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 98.06, Test_acc 27.60
2025-02-14 22:56:47,795 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 1.18, Flat_loss 0.21, Train_acc 97.56, Test_acc 29.02
2025-02-14 22:56:49,404 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.18, Spatial_loss 1.23, Flat_loss 0.21, Train_acc 97.94, Test_acc 30.62
2025-02-14 22:56:50,988 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.18, Spatial_loss 1.22, Flat_loss 0.21, Train_acc 97.84, Test_acc 27.90
2025-02-14 22:56:52,593 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.19, Spatial_loss 1.28, Flat_loss 0.21, Train_acc 97.88, Test_acc 32.05
2025-02-14 22:56:54,245 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 97.88, Test_acc 29.28
2025-02-14 22:56:55,939 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 98.41, Test_acc 30.25
2025-02-14 22:56:57,591 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 98.03, Test_acc 28.52
2025-02-14 22:56:59,280 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.17, Spatial_loss 1.19, Flat_loss 0.20, Train_acc 98.19, Test_acc 31.30
2025-02-14 22:57:00,951 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.20, Train_acc 98.38, Test_acc 28.45
2025-02-14 22:57:02,583 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 98.19, Test_acc 31.65
2025-02-14 22:57:04,226 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.17, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 98.41, Test_acc 29.20
2025-02-14 22:57:05,856 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.17, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 98.62, Test_acc 30.42
2025-02-14 22:57:07,610 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 1.26, Flat_loss 0.21, Train_acc 98.25, Test_acc 30.45
2025-02-14 22:57:09,248 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.20, Train_acc 98.72, Test_acc 33.00
2025-02-14 22:57:10,912 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 98.56, Test_acc 30.25
2025-02-14 22:57:12,543 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.16, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 98.69, Test_acc 31.30
2025-02-14 22:57:14,201 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 98.69, Test_acc 31.75
2025-02-14 22:57:15,868 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 99.00, Test_acc 31.85
2025-02-14 22:57:17,532 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.20, Train_acc 98.25, Test_acc 31.40
2025-02-14 22:57:19,180 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 98.97, Test_acc 30.82
2025-02-14 22:57:20,827 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.15, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 98.78, Test_acc 32.02
2025-02-14 22:57:22,525 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.20, Train_acc 98.91, Test_acc 31.32
2025-02-14 22:57:24,128 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.20, Train_acc 99.09, Test_acc 29.90
2025-02-14 22:57:25,778 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.15, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.81, Test_acc 32.22
2025-02-14 22:57:27,422 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.15, Spatial_loss 1.05, Flat_loss 0.20, Train_acc 98.81, Test_acc 29.65
2025-02-14 22:57:29,057 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 99.12, Test_acc 30.72
2025-02-14 22:57:30,709 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 99.19, Test_acc 32.02
2025-02-14 22:57:32,467 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 99.09, Test_acc 31.08
2025-02-14 22:57:34,099 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 1.04, Flat_loss 0.19, Train_acc 99.09, Test_acc 32.60
2025-02-14 22:57:35,781 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 99.25, Test_acc 32.12
2025-02-14 22:57:37,480 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 99.34, Test_acc 31.72
2025-02-14 22:57:39,102 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.94, Test_acc 30.70
2025-02-14 22:57:40,732 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 99.22, Test_acc 31.95
2025-02-14 22:57:42,361 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 99.34, Test_acc 31.30
2025-02-14 22:57:44,002 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.13, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 99.41, Test_acc 31.70
2025-02-14 22:57:45,622 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.14, Spatial_loss 1.07, Flat_loss 0.19, Train_acc 99.44, Test_acc 32.35
2025-02-14 22:57:47,287 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.14, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 99.28, Test_acc 32.48
2025-02-14 22:57:48,981 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 99.38, Test_acc 31.75
2025-02-14 22:57:50,611 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.22, Test_acc 32.45
2025-02-14 22:57:52,254 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.94, Test_acc 30.52
2025-02-14 22:57:53,949 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 99.38, Test_acc 31.92
2025-02-14 22:57:55,566 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 99.31, Test_acc 31.92
2025-02-14 22:57:57,208 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.53, Test_acc 32.25
2025-02-14 22:57:58,789 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 99.22, Test_acc 31.20
2025-02-14 22:58:00,404 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 99.59, Test_acc 31.22
2025-02-14 22:58:02,052 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 99.38, Test_acc 31.30
2025-02-14 22:58:03,714 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.34, Test_acc 31.58
2025-02-14 22:58:05,381 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.44, Test_acc 32.30
2025-02-14 22:58:07,042 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.22, Test_acc 31.65
2025-02-14 22:58:08,750 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.18, Train_acc 99.34, Test_acc 31.88
2025-02-14 22:58:10,454 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.50, Test_acc 31.52
2025-02-14 22:58:12,084 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.41, Test_acc 32.25
2025-02-14 22:58:13,762 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.62, Test_acc 31.72
2025-02-14 22:58:15,447 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.18, Train_acc 99.31, Test_acc 31.82
2025-02-14 22:58:17,114 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.34, Test_acc 32.35
2025-02-14 22:58:18,759 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.25, Test_acc 31.58
2025-02-14 22:58:20,308 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.66, Test_acc 32.40
2025-02-14 22:58:21,906 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.18, Train_acc 99.62, Test_acc 32.02
2025-02-14 22:58:23,560 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.38, Test_acc 32.08
2025-02-14 22:58:25,158 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.14, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.47, Test_acc 32.20
2025-02-14 22:58:26,821 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.44, Test_acc 32.12
2025-02-14 22:58:28,437 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.18, Train_acc 99.59, Test_acc 32.30
2025-02-14 22:58:30,032 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.53, Test_acc 32.22
2025-02-14 22:58:31,666 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.18, Train_acc 99.53, Test_acc 32.22
2025-02-14 22:58:33,309 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.38, Test_acc 32.08
2025-02-14 22:58:34,916 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.47, Test_acc 32.33
2025-02-14 22:58:36,532 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.56, Test_acc 32.22
2025-02-14 22:58:36,533 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 22:58:36,533 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:58:51,297 [podnet.py] => The size of finetune dataset: 800
2025-02-14 22:58:52,438 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.46, Spatial_loss 1.02, Flat_loss 0.15, Train_acc 86.12, Test_acc 34.78
2025-02-14 22:58:53,504 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.22, Spatial_loss 1.01, Flat_loss 0.11, Train_acc 98.12, Test_acc 37.12
2025-02-14 22:58:54,681 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 99.62, Test_acc 37.90
2025-02-14 22:58:55,763 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.09, Train_acc 99.88, Test_acc 37.50
2025-02-14 22:58:56,887 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 99.25, Test_acc 35.95
2025-02-14 22:58:57,967 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 99.50, Test_acc 34.17
2025-02-14 22:58:59,081 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 99.38, Test_acc 34.55
2025-02-14 22:59:00,178 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.75, Test_acc 35.50
2025-02-14 22:59:01,221 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.25, Test_acc 35.60
2025-02-14 22:59:02,322 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.98, Flat_loss 0.09, Train_acc 99.50, Test_acc 35.40
2025-02-14 22:59:03,471 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 99.88, Test_acc 34.90
2025-02-14 22:59:04,606 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 99.25, Test_acc 35.25
2025-02-14 22:59:05,767 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 99.75, Test_acc 34.98
2025-02-14 22:59:06,821 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 0.93, Flat_loss 0.09, Train_acc 99.62, Test_acc 35.05
2025-02-14 22:59:07,919 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 99.50, Test_acc 35.45
2025-02-14 22:59:09,046 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.62, Test_acc 35.45
2025-02-14 22:59:10,206 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 99.75, Test_acc 35.48
2025-02-14 22:59:11,301 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.86, Flat_loss 0.08, Train_acc 99.62, Test_acc 35.42
2025-02-14 22:59:12,428 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.90, Flat_loss 0.09, Train_acc 99.50, Test_acc 35.42
2025-02-14 22:59:13,476 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 99.50, Test_acc 35.33
2025-02-14 22:59:13,478 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 22:59:29,501 [podnet.py] => Exemplar size: 800
2025-02-14 22:59:29,501 [trainer.py] => CNN: {'total': 35.33, '00-09': 38.8, '10-19': 12.3, '20-29': 28.8, '30-39': 61.4, 'old': 29.34, 'new': 77.2}
2025-02-14 22:59:29,501 [trainer.py] => NME: {'total': 35.15, '00-09': 45.5, '10-19': 11.7, '20-29': 29.2, '30-39': 54.2, 'old': 30.74, 'new': 66.0}
2025-02-14 22:59:29,502 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33]
2025-02-14 22:59:29,502 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15]
2025-02-14 22:59:29,502 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15]
2025-02-14 22:59:29,502 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6]

2025-02-14 22:59:29,502 [trainer.py] => Average Accuracy (CNN): 57.533750000000005
2025-02-14 22:59:29,502 [trainer.py] => Average Accuracy (NME): 56.46374999999999
2025-02-14 22:59:29,502 [trainer.py] => All params: 491857
2025-02-14 22:59:29,502 [trainer.py] => Trainable params: 491857
2025-02-14 22:59:29,503 [podnet.py] => Learning on 40-45
2025-02-14 22:59:29,528 [podnet.py] => Adaptive factor: 3.0
2025-02-14 22:59:31,263 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 3.12, Spatial_loss 3.08, Flat_loss 1.02, Train_acc 50.00, Test_acc 24.67
2025-02-14 22:59:33,037 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 1.32, Spatial_loss 2.51, Flat_loss 0.44, Train_acc 66.85, Test_acc 20.64
2025-02-14 22:59:34,646 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 1.05, Spatial_loss 2.26, Flat_loss 0.35, Train_acc 72.30, Test_acc 26.02
2025-02-14 22:59:36,370 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 0.98, Spatial_loss 2.25, Flat_loss 0.31, Train_acc 75.06, Test_acc 22.07
2025-02-14 22:59:38,106 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 0.91, Spatial_loss 2.10, Flat_loss 0.30, Train_acc 76.55, Test_acc 29.87
2025-02-14 22:59:39,811 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 0.87, Spatial_loss 2.13, Flat_loss 0.29, Train_acc 77.48, Test_acc 25.16
2025-02-14 22:59:41,457 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 0.80, Spatial_loss 2.08, Flat_loss 0.27, Train_acc 79.09, Test_acc 27.13
2025-02-14 22:59:43,142 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 0.72, Spatial_loss 1.91, Flat_loss 0.26, Train_acc 81.21, Test_acc 23.60
2025-02-14 22:59:44,812 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 0.74, Spatial_loss 2.03, Flat_loss 0.27, Train_acc 81.21, Test_acc 29.11
2025-02-14 22:59:46,573 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 0.71, Spatial_loss 2.01, Flat_loss 0.27, Train_acc 81.97, Test_acc 29.07
2025-02-14 22:59:48,326 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 0.71, Spatial_loss 1.94, Flat_loss 0.26, Train_acc 82.12, Test_acc 30.38
2025-02-14 22:59:50,041 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.67, Spatial_loss 1.93, Flat_loss 0.27, Train_acc 82.45, Test_acc 26.24
2025-02-14 22:59:51,719 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.63, Spatial_loss 1.89, Flat_loss 0.26, Train_acc 84.30, Test_acc 27.87
2025-02-14 22:59:53,460 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.65, Spatial_loss 1.92, Flat_loss 0.26, Train_acc 83.39, Test_acc 28.91
2025-02-14 22:59:55,136 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.59, Spatial_loss 1.89, Flat_loss 0.26, Train_acc 85.67, Test_acc 29.29
2025-02-14 22:59:56,837 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.62, Spatial_loss 1.93, Flat_loss 0.26, Train_acc 84.06, Test_acc 27.16
2025-02-14 22:59:58,535 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.57, Spatial_loss 1.95, Flat_loss 0.25, Train_acc 85.64, Test_acc 25.04
2025-02-14 23:00:00,263 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.55, Spatial_loss 1.93, Flat_loss 0.25, Train_acc 86.18, Test_acc 24.56
2025-02-14 23:00:02,021 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.57, Spatial_loss 1.91, Flat_loss 0.26, Train_acc 86.73, Test_acc 31.33
2025-02-14 23:00:03,692 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.54, Spatial_loss 1.90, Flat_loss 0.26, Train_acc 86.61, Test_acc 28.56
2025-02-14 23:00:05,424 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.55, Spatial_loss 1.92, Flat_loss 0.25, Train_acc 86.27, Test_acc 24.09
2025-02-14 23:00:07,104 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.56, Spatial_loss 1.90, Flat_loss 0.26, Train_acc 85.91, Test_acc 24.93
2025-02-14 23:00:08,788 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.50, Spatial_loss 1.88, Flat_loss 0.26, Train_acc 88.27, Test_acc 28.56
2025-02-14 23:00:10,502 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.50, Spatial_loss 1.86, Flat_loss 0.25, Train_acc 88.58, Test_acc 29.67
2025-02-14 23:00:12,158 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.53, Spatial_loss 1.86, Flat_loss 0.26, Train_acc 87.24, Test_acc 25.76
2025-02-14 23:00:13,864 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.52, Spatial_loss 1.94, Flat_loss 0.25, Train_acc 87.79, Test_acc 30.91
2025-02-14 23:00:15,573 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.48, Spatial_loss 1.85, Flat_loss 0.26, Train_acc 88.03, Test_acc 28.09
2025-02-14 23:00:17,295 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.49, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 88.24, Test_acc 20.64
2025-02-14 23:00:19,014 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.49, Spatial_loss 1.92, Flat_loss 0.26, Train_acc 88.91, Test_acc 29.02
2025-02-14 23:00:20,745 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.45, Spatial_loss 1.85, Flat_loss 0.25, Train_acc 90.09, Test_acc 27.84
2025-02-14 23:00:22,446 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.43, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 89.97, Test_acc 25.13
2025-02-14 23:00:24,130 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.45, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 89.42, Test_acc 23.16
2025-02-14 23:00:25,865 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.45, Spatial_loss 1.90, Flat_loss 0.26, Train_acc 88.79, Test_acc 31.38
2025-02-14 23:00:27,590 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.44, Spatial_loss 1.85, Flat_loss 0.25, Train_acc 89.15, Test_acc 29.87
2025-02-14 23:00:29,221 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.45, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 90.39, Test_acc 28.84
2025-02-14 23:00:30,937 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.45, Spatial_loss 1.80, Flat_loss 0.26, Train_acc 89.39, Test_acc 26.11
2025-02-14 23:00:32,691 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.43, Spatial_loss 1.75, Flat_loss 0.25, Train_acc 89.67, Test_acc 26.56
2025-02-14 23:00:34,375 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.40, Spatial_loss 1.68, Flat_loss 0.25, Train_acc 90.70, Test_acc 29.31
2025-02-14 23:00:36,097 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.39, Spatial_loss 1.79, Flat_loss 0.24, Train_acc 91.33, Test_acc 24.69
2025-02-14 23:00:37,823 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.37, Spatial_loss 1.76, Flat_loss 0.25, Train_acc 91.91, Test_acc 25.73
2025-02-14 23:00:39,561 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.35, Spatial_loss 1.83, Flat_loss 0.24, Train_acc 92.76, Test_acc 31.87
2025-02-14 23:00:41,306 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.38, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 91.88, Test_acc 25.64
2025-02-14 23:00:43,098 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.37, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 91.94, Test_acc 28.11
2025-02-14 23:00:44,822 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.38, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 91.27, Test_acc 25.38
2025-02-14 23:00:46,549 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.40, Spatial_loss 1.74, Flat_loss 0.25, Train_acc 90.97, Test_acc 27.09
2025-02-14 23:00:48,262 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.35, Spatial_loss 1.74, Flat_loss 0.24, Train_acc 92.39, Test_acc 29.91
2025-02-14 23:00:49,991 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.32, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 93.52, Test_acc 29.07
2025-02-14 23:00:51,706 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.34, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 92.64, Test_acc 31.49
2025-02-14 23:00:53,405 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.34, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 92.70, Test_acc 27.78
2025-02-14 23:00:55,092 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.31, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 93.58, Test_acc 29.49
2025-02-14 23:00:56,784 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.31, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 93.79, Test_acc 28.78
2025-02-14 23:00:58,476 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.32, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 93.18, Test_acc 25.38
2025-02-14 23:01:00,198 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.34, Spatial_loss 1.68, Flat_loss 0.23, Train_acc 92.36, Test_acc 29.56
2025-02-14 23:01:01,888 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.32, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 93.27, Test_acc 27.40
2025-02-14 23:01:03,538 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.31, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 93.97, Test_acc 28.91
2025-02-14 23:01:05,258 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.27, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 95.18, Test_acc 32.22
2025-02-14 23:01:06,942 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.30, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 94.76, Test_acc 28.31
2025-02-14 23:01:08,652 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.29, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 94.09, Test_acc 29.89
2025-02-14 23:01:10,381 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.30, Spatial_loss 1.61, Flat_loss 0.24, Train_acc 93.79, Test_acc 31.51
2025-02-14 23:01:12,115 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.30, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 94.36, Test_acc 30.04
2025-02-14 23:01:13,784 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.29, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 94.42, Test_acc 30.76
2025-02-14 23:01:15,450 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.30, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 93.97, Test_acc 29.62
2025-02-14 23:01:17,191 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.25, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 95.42, Test_acc 28.64
2025-02-14 23:01:18,918 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.28, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 94.70, Test_acc 31.40
2025-02-14 23:01:20,608 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.30, Spatial_loss 1.71, Flat_loss 0.23, Train_acc 93.97, Test_acc 29.13
2025-02-14 23:01:22,411 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.27, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 95.30, Test_acc 28.62
2025-02-14 23:01:24,134 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.26, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 95.58, Test_acc 31.76
2025-02-14 23:01:25,863 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.25, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 95.42, Test_acc 27.82
2025-02-14 23:01:27,515 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.26, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 95.12, Test_acc 29.09
2025-02-14 23:01:29,183 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.24, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 95.76, Test_acc 26.84
2025-02-14 23:01:30,909 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.24, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 95.97, Test_acc 32.00
2025-02-14 23:01:32,611 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.23, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 96.27, Test_acc 28.44
2025-02-14 23:01:34,271 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.24, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 95.76, Test_acc 27.58
2025-02-14 23:01:36,008 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.26, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 95.33, Test_acc 32.09
2025-02-14 23:01:37,723 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.24, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 95.85, Test_acc 32.20
2025-02-14 23:01:39,496 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.22, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 96.39, Test_acc 29.31
2025-02-14 23:01:41,223 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.21, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 96.85, Test_acc 29.13
2025-02-14 23:01:42,914 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.22, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 96.52, Test_acc 28.09
2025-02-14 23:01:44,567 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 96.15, Test_acc 30.80
2025-02-14 23:01:46,379 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.22, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 96.39, Test_acc 30.04
2025-02-14 23:01:48,098 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 95.85, Test_acc 31.76
2025-02-14 23:01:49,779 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.21, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 96.79, Test_acc 29.18
2025-02-14 23:01:51,461 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.22, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 96.79, Test_acc 26.67
2025-02-14 23:01:53,209 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.22, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 96.45, Test_acc 31.69
2025-02-14 23:01:54,908 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.21, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 96.55, Test_acc 27.53
2025-02-14 23:01:56,614 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 97.06, Test_acc 31.22
2025-02-14 23:01:58,331 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.20, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 97.30, Test_acc 30.38
2025-02-14 23:02:00,081 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.17, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 98.03, Test_acc 31.82
2025-02-14 23:02:01,823 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.18, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 97.76, Test_acc 34.04
2025-02-14 23:02:03,526 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.18, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 97.58, Test_acc 32.84
2025-02-14 23:02:05,226 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.19, Spatial_loss 1.29, Flat_loss 0.20, Train_acc 97.58, Test_acc 31.89
2025-02-14 23:02:06,945 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.19, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 97.55, Test_acc 32.40
2025-02-14 23:02:08,673 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.17, Spatial_loss 1.27, Flat_loss 0.20, Train_acc 97.97, Test_acc 30.24
2025-02-14 23:02:10,410 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 97.52, Test_acc 30.84
2025-02-14 23:02:12,093 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.19, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 97.03, Test_acc 30.40
2025-02-14 23:02:13,768 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.18, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 98.00, Test_acc 29.18
2025-02-14 23:02:15,500 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 98.00, Test_acc 30.64
2025-02-14 23:02:17,219 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 98.09, Test_acc 34.16
2025-02-14 23:02:18,848 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.18, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 97.76, Test_acc 29.58
2025-02-14 23:02:20,604 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.17, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 98.00, Test_acc 31.62
2025-02-14 23:02:22,302 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 98.45, Test_acc 32.93
2025-02-14 23:02:24,068 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.16, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 98.36, Test_acc 31.29
2025-02-14 23:02:25,807 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 98.42, Test_acc 30.64
2025-02-14 23:02:27,547 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 98.67, Test_acc 32.16
2025-02-14 23:02:29,305 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 98.12, Test_acc 32.13
2025-02-14 23:02:30,990 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.16, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 98.42, Test_acc 32.02
2025-02-14 23:02:32,720 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 98.36, Test_acc 31.33
2025-02-14 23:02:34,402 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 98.15, Test_acc 30.69
2025-02-14 23:02:36,097 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 98.67, Test_acc 32.69
2025-02-14 23:02:37,757 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 98.58, Test_acc 30.87
2025-02-14 23:02:39,473 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.14, Spatial_loss 1.21, Flat_loss 0.18, Train_acc 99.03, Test_acc 31.64
2025-02-14 23:02:41,230 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.14, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 98.94, Test_acc 31.51
2025-02-14 23:02:43,030 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.15, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 98.85, Test_acc 32.84
2025-02-14 23:02:44,786 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.14, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 98.91, Test_acc 31.71
2025-02-14 23:02:46,461 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.14, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 98.85, Test_acc 32.38
2025-02-14 23:02:48,182 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 98.94, Test_acc 34.49
2025-02-14 23:02:49,872 [podnet.py] => Task 8, Epoch 117/160 (LR 0.01679) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 98.85, Test_acc 32.64
2025-02-14 23:02:51,536 [podnet.py] => Task 8, Epoch 118/160 (LR 0.01606) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 98.91, Test_acc 33.07
2025-02-14 23:02:53,238 [podnet.py] => Task 8, Epoch 119/160 (LR 0.01535) => LSC_loss 0.14, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 98.94, Test_acc 33.07
2025-02-14 23:02:54,936 [podnet.py] => Task 8, Epoch 120/160 (LR 0.01464) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 98.76, Test_acc 34.09
2025-02-14 23:02:56,579 [podnet.py] => Task 8, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 98.91, Test_acc 34.13
2025-02-14 23:02:58,239 [podnet.py] => Task 8, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 98.64, Test_acc 32.69
2025-02-14 23:02:59,898 [podnet.py] => Task 8, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 99.09, Test_acc 33.29
2025-02-14 23:03:01,641 [podnet.py] => Task 8, Epoch 124/160 (LR 0.01198) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 99.09, Test_acc 32.47
2025-02-14 23:03:03,363 [podnet.py] => Task 8, Epoch 125/160 (LR 0.01135) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 99.00, Test_acc 33.29
2025-02-14 23:03:05,100 [podnet.py] => Task 8, Epoch 126/160 (LR 0.01073) => LSC_loss 0.13, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 99.15, Test_acc 33.38
2025-02-14 23:03:06,812 [podnet.py] => Task 8, Epoch 127/160 (LR 0.01013) => LSC_loss 0.13, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 99.30, Test_acc 31.93
2025-02-14 23:03:08,561 [podnet.py] => Task 8, Epoch 128/160 (LR 0.00955) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 99.39, Test_acc 32.71
2025-02-14 23:03:10,327 [podnet.py] => Task 8, Epoch 129/160 (LR 0.00898) => LSC_loss 0.14, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 98.85, Test_acc 33.00
2025-02-14 23:03:12,053 [podnet.py] => Task 8, Epoch 130/160 (LR 0.00843) => LSC_loss 0.12, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 99.21, Test_acc 33.49
2025-02-14 23:03:13,800 [podnet.py] => Task 8, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 99.09, Test_acc 32.76
2025-02-14 23:03:15,464 [podnet.py] => Task 8, Epoch 132/160 (LR 0.00737) => LSC_loss 0.13, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 99.27, Test_acc 32.87
2025-02-14 23:03:17,241 [podnet.py] => Task 8, Epoch 133/160 (LR 0.00686) => LSC_loss 0.13, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 99.09, Test_acc 33.22
2025-02-14 23:03:18,943 [podnet.py] => Task 8, Epoch 134/160 (LR 0.00638) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 99.39, Test_acc 33.29
2025-02-14 23:03:20,658 [podnet.py] => Task 8, Epoch 135/160 (LR 0.00590) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 99.21, Test_acc 32.56
2025-02-14 23:03:22,375 [podnet.py] => Task 8, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 99.27, Test_acc 32.51
2025-02-14 23:03:24,089 [podnet.py] => Task 8, Epoch 137/160 (LR 0.00501) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 99.27, Test_acc 32.96
2025-02-14 23:03:25,761 [podnet.py] => Task 8, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 99.45, Test_acc 32.76
2025-02-14 23:03:27,532 [podnet.py] => Task 8, Epoch 139/160 (LR 0.00419) => LSC_loss 0.12, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 99.42, Test_acc 32.56
2025-02-14 23:03:29,239 [podnet.py] => Task 8, Epoch 140/160 (LR 0.00381) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 99.45, Test_acc 34.07
2025-02-14 23:03:31,014 [podnet.py] => Task 8, Epoch 141/160 (LR 0.00344) => LSC_loss 0.12, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 99.36, Test_acc 32.73
2025-02-14 23:03:32,698 [podnet.py] => Task 8, Epoch 142/160 (LR 0.00309) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 99.30, Test_acc 33.87
2025-02-14 23:03:34,391 [podnet.py] => Task 8, Epoch 143/160 (LR 0.00276) => LSC_loss 0.12, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 99.55, Test_acc 33.38
2025-02-14 23:03:36,147 [podnet.py] => Task 8, Epoch 144/160 (LR 0.00245) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 99.36, Test_acc 32.82
2025-02-14 23:03:37,861 [podnet.py] => Task 8, Epoch 145/160 (LR 0.00215) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 99.39, Test_acc 32.89
2025-02-14 23:03:39,586 [podnet.py] => Task 8, Epoch 146/160 (LR 0.00188) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 99.42, Test_acc 33.58
2025-02-14 23:03:41,319 [podnet.py] => Task 8, Epoch 147/160 (LR 0.00162) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.30, Test_acc 33.11
2025-02-14 23:03:43,028 [podnet.py] => Task 8, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 99.27, Test_acc 32.89
2025-02-14 23:03:44,733 [podnet.py] => Task 8, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.52, Test_acc 33.89
2025-02-14 23:03:46,415 [podnet.py] => Task 8, Epoch 150/160 (LR 0.00096) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 99.55, Test_acc 33.33
2025-02-14 23:03:48,145 [podnet.py] => Task 8, Epoch 151/160 (LR 0.00078) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.36, Test_acc 33.44
2025-02-14 23:03:49,903 [podnet.py] => Task 8, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 99.39, Test_acc 33.22
2025-02-14 23:03:51,634 [podnet.py] => Task 8, Epoch 153/160 (LR 0.00047) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 99.33, Test_acc 33.69
2025-02-14 23:03:53,366 [podnet.py] => Task 8, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 99.09, Test_acc 33.40
2025-02-14 23:03:55,091 [podnet.py] => Task 8, Epoch 155/160 (LR 0.00024) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 99.58, Test_acc 33.40
2025-02-14 23:03:56,823 [podnet.py] => Task 8, Epoch 156/160 (LR 0.00015) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 99.42, Test_acc 33.44
2025-02-14 23:03:58,560 [podnet.py] => Task 8, Epoch 157/160 (LR 0.00009) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 99.61, Test_acc 33.33
2025-02-14 23:04:00,328 [podnet.py] => Task 8, Epoch 158/160 (LR 0.00004) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.39, Test_acc 33.33
2025-02-14 23:04:02,029 [podnet.py] => Task 8, Epoch 159/160 (LR 0.00001) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 99.48, Test_acc 33.60
2025-02-14 23:04:03,677 [podnet.py] => Task 8, Epoch 160/160 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.16, Train_acc 99.48, Test_acc 33.78
2025-02-14 23:04:03,678 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:04:03,679 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:04:20,513 [podnet.py] => The size of finetune dataset: 900
2025-02-14 23:04:21,742 [podnet.py] => Task 8, Epoch 1/20 (LR 0.00497) => LSC_loss 0.43, Spatial_loss 1.56, Flat_loss 0.17, Train_acc 91.44, Test_acc 36.44
2025-02-14 23:04:22,932 [podnet.py] => Task 8, Epoch 2/20 (LR 0.00488) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.13, Train_acc 99.00, Test_acc 37.98
2025-02-14 23:04:24,096 [podnet.py] => Task 8, Epoch 3/20 (LR 0.00473) => LSC_loss 0.20, Spatial_loss 1.39, Flat_loss 0.15, Train_acc 98.33, Test_acc 38.53
2025-02-14 23:04:25,303 [podnet.py] => Task 8, Epoch 4/20 (LR 0.00452) => LSC_loss 0.48, Spatial_loss 1.30, Flat_loss 0.15, Train_acc 97.56, Test_acc 36.04
2025-02-14 23:04:26,499 [podnet.py] => Task 8, Epoch 5/20 (LR 0.00427) => LSC_loss 0.28, Spatial_loss 1.62, Flat_loss 0.17, Train_acc 97.11, Test_acc 32.49
2025-02-14 23:04:27,724 [podnet.py] => Task 8, Epoch 6/20 (LR 0.00397) => LSC_loss 0.29, Spatial_loss 1.43, Flat_loss 0.17, Train_acc 96.67, Test_acc 36.20
2025-02-14 23:04:28,886 [podnet.py] => Task 8, Epoch 7/20 (LR 0.00363) => LSC_loss 0.24, Spatial_loss 1.30, Flat_loss 0.15, Train_acc 98.22, Test_acc 35.53
2025-02-14 23:04:30,070 [podnet.py] => Task 8, Epoch 8/20 (LR 0.00327) => LSC_loss 0.36, Spatial_loss 1.50, Flat_loss 0.17, Train_acc 97.00, Test_acc 36.71
2025-02-14 23:04:31,300 [podnet.py] => Task 8, Epoch 9/20 (LR 0.00289) => LSC_loss 0.30, Spatial_loss 1.28, Flat_loss 0.15, Train_acc 97.44, Test_acc 36.73
2025-02-14 23:04:32,483 [podnet.py] => Task 8, Epoch 10/20 (LR 0.00250) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.14, Train_acc 98.67, Test_acc 36.20
2025-02-14 23:04:33,622 [podnet.py] => Task 8, Epoch 11/20 (LR 0.00211) => LSC_loss 0.32, Spatial_loss 1.83, Flat_loss 0.18, Train_acc 98.56, Test_acc 33.93
2025-02-14 23:04:34,808 [podnet.py] => Task 8, Epoch 12/20 (LR 0.00173) => LSC_loss 0.27, Spatial_loss 1.19, Flat_loss 0.14, Train_acc 98.44, Test_acc 34.78
2025-02-14 23:04:35,980 [podnet.py] => Task 8, Epoch 13/20 (LR 0.00137) => LSC_loss 0.37, Spatial_loss 1.45, Flat_loss 0.18, Train_acc 98.00, Test_acc 35.98
2025-02-14 23:04:37,158 [podnet.py] => Task 8, Epoch 14/20 (LR 0.00103) => LSC_loss 0.39, Spatial_loss 1.34, Flat_loss 0.17, Train_acc 98.11, Test_acc 35.98
2025-02-14 23:04:38,311 [podnet.py] => Task 8, Epoch 15/20 (LR 0.00073) => LSC_loss 0.48, Spatial_loss 1.29, Flat_loss 0.15, Train_acc 98.78, Test_acc 36.73
2025-02-14 23:04:39,426 [podnet.py] => Task 8, Epoch 16/20 (LR 0.00048) => LSC_loss 0.33, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 98.44, Test_acc 37.27
2025-02-14 23:04:40,555 [podnet.py] => Task 8, Epoch 17/20 (LR 0.00027) => LSC_loss 0.17, Spatial_loss 1.30, Flat_loss 0.14, Train_acc 99.56, Test_acc 36.82
2025-02-14 23:04:41,735 [podnet.py] => Task 8, Epoch 18/20 (LR 0.00012) => LSC_loss 0.39, Spatial_loss 1.47, Flat_loss 0.17, Train_acc 98.67, Test_acc 35.89
2025-02-14 23:04:42,886 [podnet.py] => Task 8, Epoch 19/20 (LR 0.00003) => LSC_loss 0.18, Spatial_loss 1.45, Flat_loss 0.14, Train_acc 98.56, Test_acc 36.20
2025-02-14 23:04:44,052 [podnet.py] => Task 8, Epoch 20/20 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.32, Flat_loss 0.13, Train_acc 97.78, Test_acc 36.56
2025-02-14 23:04:44,053 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:05:02,309 [podnet.py] => Exemplar size: 900
2025-02-14 23:05:02,309 [trainer.py] => CNN: {'total': 36.56, '00-09': 41.8, '10-19': 14.3, '20-29': 30.4, '30-39': 40.8, '40-49': 74.4, 'old': 31.82, 'new': 74.4}
2025-02-14 23:05:02,309 [trainer.py] => NME: {'total': 35.84, '00-09': 45.8, '10-19': 13.8, '20-29': 28.7, '30-39': 39.9, '40-49': 66.2, 'old': 32.05, 'new': 66.2}
2025-02-14 23:05:02,309 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56]
2025-02-14 23:05:02,309 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11]
2025-02-14 23:05:02,309 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84]
2025-02-14 23:05:02,309 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24]

2025-02-14 23:05:02,310 [trainer.py] => Average Accuracy (CNN): 55.20333333333334
2025-02-14 23:05:02,310 [trainer.py] => Average Accuracy (NME): 54.17222222222222
2025-02-14 23:05:02,310 [trainer.py] => All params: 495057
2025-02-14 23:05:02,310 [trainer.py] => Trainable params: 495057
2025-02-14 23:05:02,311 [podnet.py] => Learning on 45-50
2025-02-14 23:05:02,336 [podnet.py] => Adaptive factor: 3.1622776601683795
2025-02-14 23:05:04,144 [podnet.py] => Task 9, Epoch 1/160 (LR 0.09999) => LSC_loss 3.12, Spatial_loss 3.04, Flat_loss 1.00, Train_acc 51.82, Test_acc 15.28
2025-02-14 23:05:05,869 [podnet.py] => Task 9, Epoch 2/160 (LR 0.09996) => LSC_loss 1.32, Spatial_loss 2.60, Flat_loss 0.53, Train_acc 67.79, Test_acc 25.30
2025-02-14 23:05:07,624 [podnet.py] => Task 9, Epoch 3/160 (LR 0.09991) => LSC_loss 1.05, Spatial_loss 2.25, Flat_loss 0.41, Train_acc 72.79, Test_acc 23.68
2025-02-14 23:05:09,422 [podnet.py] => Task 9, Epoch 4/160 (LR 0.09985) => LSC_loss 0.91, Spatial_loss 2.15, Flat_loss 0.37, Train_acc 76.82, Test_acc 26.42
2025-02-14 23:05:11,204 [podnet.py] => Task 9, Epoch 5/160 (LR 0.09976) => LSC_loss 0.87, Spatial_loss 2.15, Flat_loss 0.35, Train_acc 76.97, Test_acc 20.30
2025-02-14 23:05:12,944 [podnet.py] => Task 9, Epoch 6/160 (LR 0.09965) => LSC_loss 0.84, Spatial_loss 2.18, Flat_loss 0.35, Train_acc 78.53, Test_acc 21.26
2025-02-14 23:05:14,654 [podnet.py] => Task 9, Epoch 7/160 (LR 0.09953) => LSC_loss 0.77, Spatial_loss 2.20, Flat_loss 0.33, Train_acc 79.94, Test_acc 27.98
2025-02-14 23:05:16,348 [podnet.py] => Task 9, Epoch 8/160 (LR 0.09938) => LSC_loss 0.69, Spatial_loss 2.05, Flat_loss 0.32, Train_acc 82.29, Test_acc 26.98
2025-02-14 23:05:18,140 [podnet.py] => Task 9, Epoch 9/160 (LR 0.09922) => LSC_loss 0.68, Spatial_loss 2.02, Flat_loss 0.31, Train_acc 82.94, Test_acc 27.28
2025-02-14 23:05:19,901 [podnet.py] => Task 9, Epoch 10/160 (LR 0.09904) => LSC_loss 0.67, Spatial_loss 2.00, Flat_loss 0.31, Train_acc 83.53, Test_acc 27.88
2025-02-14 23:05:21,669 [podnet.py] => Task 9, Epoch 11/160 (LR 0.09884) => LSC_loss 0.63, Spatial_loss 1.99, Flat_loss 0.30, Train_acc 85.00, Test_acc 27.34
2025-02-14 23:05:23,489 [podnet.py] => Task 9, Epoch 12/160 (LR 0.09862) => LSC_loss 0.61, Spatial_loss 2.02, Flat_loss 0.30, Train_acc 84.88, Test_acc 29.80
2025-02-14 23:05:25,246 [podnet.py] => Task 9, Epoch 13/160 (LR 0.09838) => LSC_loss 0.58, Spatial_loss 1.97, Flat_loss 0.30, Train_acc 86.09, Test_acc 27.20
2025-02-14 23:05:26,962 [podnet.py] => Task 9, Epoch 14/160 (LR 0.09812) => LSC_loss 0.58, Spatial_loss 1.93, Flat_loss 0.30, Train_acc 86.26, Test_acc 27.68
2025-02-14 23:05:28,749 [podnet.py] => Task 9, Epoch 15/160 (LR 0.09785) => LSC_loss 0.53, Spatial_loss 1.95, Flat_loss 0.29, Train_acc 87.06, Test_acc 24.36
2025-02-14 23:05:30,520 [podnet.py] => Task 9, Epoch 16/160 (LR 0.09755) => LSC_loss 0.54, Spatial_loss 1.97, Flat_loss 0.30, Train_acc 86.65, Test_acc 28.34
2025-02-14 23:05:32,301 [podnet.py] => Task 9, Epoch 17/160 (LR 0.09724) => LSC_loss 0.54, Spatial_loss 1.95, Flat_loss 0.29, Train_acc 87.26, Test_acc 30.46
2025-02-14 23:05:34,038 [podnet.py] => Task 9, Epoch 18/160 (LR 0.09691) => LSC_loss 0.56, Spatial_loss 2.00, Flat_loss 0.30, Train_acc 86.47, Test_acc 20.84
2025-02-14 23:05:35,813 [podnet.py] => Task 9, Epoch 19/160 (LR 0.09656) => LSC_loss 0.55, Spatial_loss 1.91, Flat_loss 0.30, Train_acc 85.85, Test_acc 26.38
2025-02-14 23:05:37,619 [podnet.py] => Task 9, Epoch 20/160 (LR 0.09619) => LSC_loss 0.53, Spatial_loss 1.98, Flat_loss 0.31, Train_acc 87.44, Test_acc 24.68
2025-02-14 23:05:39,382 [podnet.py] => Task 9, Epoch 21/160 (LR 0.09581) => LSC_loss 0.50, Spatial_loss 1.98, Flat_loss 0.30, Train_acc 88.15, Test_acc 24.14
2025-02-14 23:05:41,169 [podnet.py] => Task 9, Epoch 22/160 (LR 0.09541) => LSC_loss 0.49, Spatial_loss 1.94, Flat_loss 0.29, Train_acc 88.35, Test_acc 28.80
2025-02-14 23:05:42,946 [podnet.py] => Task 9, Epoch 23/160 (LR 0.09499) => LSC_loss 0.49, Spatial_loss 1.93, Flat_loss 0.29, Train_acc 88.21, Test_acc 24.92
2025-02-14 23:05:44,745 [podnet.py] => Task 9, Epoch 24/160 (LR 0.09455) => LSC_loss 0.47, Spatial_loss 1.89, Flat_loss 0.29, Train_acc 88.38, Test_acc 27.32
2025-02-14 23:05:46,507 [podnet.py] => Task 9, Epoch 25/160 (LR 0.09410) => LSC_loss 0.46, Spatial_loss 1.91, Flat_loss 0.29, Train_acc 88.97, Test_acc 31.30
2025-02-14 23:05:48,293 [podnet.py] => Task 9, Epoch 26/160 (LR 0.09362) => LSC_loss 0.43, Spatial_loss 1.91, Flat_loss 0.28, Train_acc 90.56, Test_acc 23.80
2025-02-14 23:05:50,065 [podnet.py] => Task 9, Epoch 27/160 (LR 0.09314) => LSC_loss 0.42, Spatial_loss 1.85, Flat_loss 0.28, Train_acc 90.38, Test_acc 30.60
2025-02-14 23:05:51,839 [podnet.py] => Task 9, Epoch 28/160 (LR 0.09263) => LSC_loss 0.46, Spatial_loss 1.90, Flat_loss 0.29, Train_acc 89.29, Test_acc 27.48
2025-02-14 23:05:53,639 [podnet.py] => Task 9, Epoch 29/160 (LR 0.09211) => LSC_loss 0.45, Spatial_loss 1.88, Flat_loss 0.29, Train_acc 89.35, Test_acc 30.36
2025-02-14 23:05:55,424 [podnet.py] => Task 9, Epoch 30/160 (LR 0.09157) => LSC_loss 0.43, Spatial_loss 1.78, Flat_loss 0.29, Train_acc 90.29, Test_acc 26.58
2025-02-14 23:05:57,158 [podnet.py] => Task 9, Epoch 31/160 (LR 0.09102) => LSC_loss 0.40, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 91.26, Test_acc 29.58
2025-02-14 23:05:58,936 [podnet.py] => Task 9, Epoch 32/160 (LR 0.09045) => LSC_loss 0.37, Spatial_loss 1.76, Flat_loss 0.27, Train_acc 92.03, Test_acc 28.24
2025-02-14 23:06:00,674 [podnet.py] => Task 9, Epoch 33/160 (LR 0.08987) => LSC_loss 0.37, Spatial_loss 1.80, Flat_loss 0.27, Train_acc 91.53, Test_acc 30.66
2025-02-14 23:06:02,463 [podnet.py] => Task 9, Epoch 34/160 (LR 0.08927) => LSC_loss 0.38, Spatial_loss 1.87, Flat_loss 0.28, Train_acc 91.59, Test_acc 31.90
2025-02-14 23:06:04,220 [podnet.py] => Task 9, Epoch 35/160 (LR 0.08865) => LSC_loss 0.37, Spatial_loss 1.77, Flat_loss 0.28, Train_acc 91.62, Test_acc 26.82
2025-02-14 23:06:06,013 [podnet.py] => Task 9, Epoch 36/160 (LR 0.08802) => LSC_loss 0.35, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 91.82, Test_acc 29.94
2025-02-14 23:06:07,829 [podnet.py] => Task 9, Epoch 37/160 (LR 0.08738) => LSC_loss 0.36, Spatial_loss 1.82, Flat_loss 0.28, Train_acc 92.50, Test_acc 28.28
2025-02-14 23:06:09,590 [podnet.py] => Task 9, Epoch 38/160 (LR 0.08672) => LSC_loss 0.34, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 92.88, Test_acc 29.38
2025-02-14 23:06:11,283 [podnet.py] => Task 9, Epoch 39/160 (LR 0.08604) => LSC_loss 0.36, Spatial_loss 1.76, Flat_loss 0.28, Train_acc 92.29, Test_acc 24.96
2025-02-14 23:06:13,091 [podnet.py] => Task 9, Epoch 40/160 (LR 0.08536) => LSC_loss 0.34, Spatial_loss 1.83, Flat_loss 0.27, Train_acc 93.00, Test_acc 26.46
2025-02-14 23:06:14,825 [podnet.py] => Task 9, Epoch 41/160 (LR 0.08465) => LSC_loss 0.35, Spatial_loss 1.86, Flat_loss 0.28, Train_acc 92.59, Test_acc 26.46
2025-02-14 23:06:16,593 [podnet.py] => Task 9, Epoch 42/160 (LR 0.08394) => LSC_loss 0.36, Spatial_loss 1.77, Flat_loss 0.28, Train_acc 92.18, Test_acc 28.16
2025-02-14 23:06:18,333 [podnet.py] => Task 9, Epoch 43/160 (LR 0.08321) => LSC_loss 0.37, Spatial_loss 1.86, Flat_loss 0.28, Train_acc 92.03, Test_acc 29.02
2025-02-14 23:06:20,158 [podnet.py] => Task 9, Epoch 44/160 (LR 0.08247) => LSC_loss 0.34, Spatial_loss 1.71, Flat_loss 0.27, Train_acc 92.56, Test_acc 30.98
2025-02-14 23:06:21,869 [podnet.py] => Task 9, Epoch 45/160 (LR 0.08172) => LSC_loss 0.31, Spatial_loss 1.64, Flat_loss 0.27, Train_acc 93.56, Test_acc 29.46
2025-02-14 23:06:23,670 [podnet.py] => Task 9, Epoch 46/160 (LR 0.08095) => LSC_loss 0.32, Spatial_loss 1.76, Flat_loss 0.27, Train_acc 93.21, Test_acc 30.96
2025-02-14 23:06:25,385 [podnet.py] => Task 9, Epoch 47/160 (LR 0.08018) => LSC_loss 0.33, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 92.68, Test_acc 30.00
2025-02-14 23:06:27,114 [podnet.py] => Task 9, Epoch 48/160 (LR 0.07939) => LSC_loss 0.33, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 92.97, Test_acc 27.12
2025-02-14 23:06:28,852 [podnet.py] => Task 9, Epoch 49/160 (LR 0.07859) => LSC_loss 0.31, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 93.53, Test_acc 27.20
2025-02-14 23:06:30,601 [podnet.py] => Task 9, Epoch 50/160 (LR 0.07778) => LSC_loss 0.30, Spatial_loss 1.69, Flat_loss 0.27, Train_acc 93.82, Test_acc 30.00
2025-02-14 23:06:32,434 [podnet.py] => Task 9, Epoch 51/160 (LR 0.07696) => LSC_loss 0.30, Spatial_loss 1.69, Flat_loss 0.26, Train_acc 94.09, Test_acc 27.70
2025-02-14 23:06:34,221 [podnet.py] => Task 9, Epoch 52/160 (LR 0.07612) => LSC_loss 0.33, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 93.09, Test_acc 29.40
2025-02-14 23:06:35,975 [podnet.py] => Task 9, Epoch 53/160 (LR 0.07528) => LSC_loss 0.31, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 93.79, Test_acc 27.70
2025-02-14 23:06:37,801 [podnet.py] => Task 9, Epoch 54/160 (LR 0.07443) => LSC_loss 0.30, Spatial_loss 1.80, Flat_loss 0.26, Train_acc 94.18, Test_acc 26.56
2025-02-14 23:06:39,563 [podnet.py] => Task 9, Epoch 55/160 (LR 0.07357) => LSC_loss 0.27, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 94.85, Test_acc 29.70
2025-02-14 23:06:41,405 [podnet.py] => Task 9, Epoch 56/160 (LR 0.07270) => LSC_loss 0.28, Spatial_loss 1.65, Flat_loss 0.25, Train_acc 94.47, Test_acc 27.24
2025-02-14 23:06:43,185 [podnet.py] => Task 9, Epoch 57/160 (LR 0.07182) => LSC_loss 0.27, Spatial_loss 1.64, Flat_loss 0.26, Train_acc 94.88, Test_acc 27.92
2025-02-14 23:06:44,901 [podnet.py] => Task 9, Epoch 58/160 (LR 0.07093) => LSC_loss 0.27, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 94.53, Test_acc 29.68
2025-02-14 23:06:46,665 [podnet.py] => Task 9, Epoch 59/160 (LR 0.07004) => LSC_loss 0.32, Spatial_loss 1.68, Flat_loss 0.26, Train_acc 93.41, Test_acc 32.32
2025-02-14 23:06:48,471 [podnet.py] => Task 9, Epoch 60/160 (LR 0.06913) => LSC_loss 0.29, Spatial_loss 1.67, Flat_loss 0.26, Train_acc 94.06, Test_acc 26.16
2025-02-14 23:06:50,204 [podnet.py] => Task 9, Epoch 61/160 (LR 0.06822) => LSC_loss 0.26, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 94.74, Test_acc 34.40
2025-02-14 23:06:51,959 [podnet.py] => Task 9, Epoch 62/160 (LR 0.06731) => LSC_loss 0.26, Spatial_loss 1.55, Flat_loss 0.25, Train_acc 95.35, Test_acc 30.76
2025-02-14 23:06:53,709 [podnet.py] => Task 9, Epoch 63/160 (LR 0.06638) => LSC_loss 0.26, Spatial_loss 1.65, Flat_loss 0.25, Train_acc 95.15, Test_acc 31.64
2025-02-14 23:06:55,479 [podnet.py] => Task 9, Epoch 64/160 (LR 0.06545) => LSC_loss 0.25, Spatial_loss 1.65, Flat_loss 0.25, Train_acc 95.18, Test_acc 30.04
2025-02-14 23:06:57,201 [podnet.py] => Task 9, Epoch 65/160 (LR 0.06451) => LSC_loss 0.25, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 95.85, Test_acc 28.92
2025-02-14 23:06:58,931 [podnet.py] => Task 9, Epoch 66/160 (LR 0.06357) => LSC_loss 0.24, Spatial_loss 1.59, Flat_loss 0.25, Train_acc 96.03, Test_acc 28.80
2025-02-14 23:07:00,730 [podnet.py] => Task 9, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 1.61, Flat_loss 0.25, Train_acc 95.94, Test_acc 30.84
2025-02-14 23:07:02,515 [podnet.py] => Task 9, Epoch 68/160 (LR 0.06167) => LSC_loss 0.24, Spatial_loss 1.55, Flat_loss 0.24, Train_acc 96.18, Test_acc 27.84
2025-02-14 23:07:04,349 [podnet.py] => Task 9, Epoch 69/160 (LR 0.06072) => LSC_loss 0.22, Spatial_loss 1.54, Flat_loss 0.24, Train_acc 96.65, Test_acc 31.66
2025-02-14 23:07:06,113 [podnet.py] => Task 9, Epoch 70/160 (LR 0.05975) => LSC_loss 0.22, Spatial_loss 1.47, Flat_loss 0.23, Train_acc 96.74, Test_acc 32.08
2025-02-14 23:07:07,888 [podnet.py] => Task 9, Epoch 71/160 (LR 0.05879) => LSC_loss 0.22, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 96.47, Test_acc 30.90
2025-02-14 23:07:09,724 [podnet.py] => Task 9, Epoch 72/160 (LR 0.05782) => LSC_loss 0.24, Spatial_loss 1.56, Flat_loss 0.24, Train_acc 95.65, Test_acc 29.56
2025-02-14 23:07:11,473 [podnet.py] => Task 9, Epoch 73/160 (LR 0.05685) => LSC_loss 0.22, Spatial_loss 1.53, Flat_loss 0.24, Train_acc 96.74, Test_acc 32.68
2025-02-14 23:07:13,271 [podnet.py] => Task 9, Epoch 74/160 (LR 0.05588) => LSC_loss 0.25, Spatial_loss 1.51, Flat_loss 0.24, Train_acc 95.79, Test_acc 29.30
2025-02-14 23:07:15,038 [podnet.py] => Task 9, Epoch 75/160 (LR 0.05490) => LSC_loss 0.22, Spatial_loss 1.49, Flat_loss 0.24, Train_acc 96.56, Test_acc 31.04
2025-02-14 23:07:16,774 [podnet.py] => Task 9, Epoch 76/160 (LR 0.05392) => LSC_loss 0.23, Spatial_loss 1.43, Flat_loss 0.24, Train_acc 95.71, Test_acc 31.16
2025-02-14 23:07:18,517 [podnet.py] => Task 9, Epoch 77/160 (LR 0.05294) => LSC_loss 0.22, Spatial_loss 1.48, Flat_loss 0.24, Train_acc 96.50, Test_acc 28.70
2025-02-14 23:07:20,302 [podnet.py] => Task 9, Epoch 78/160 (LR 0.05196) => LSC_loss 0.21, Spatial_loss 1.50, Flat_loss 0.24, Train_acc 96.85, Test_acc 29.08
2025-02-14 23:07:22,063 [podnet.py] => Task 9, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 1.49, Flat_loss 0.23, Train_acc 97.03, Test_acc 32.20
2025-02-14 23:07:23,873 [podnet.py] => Task 9, Epoch 80/160 (LR 0.05000) => LSC_loss 0.20, Spatial_loss 1.41, Flat_loss 0.23, Train_acc 96.97, Test_acc 29.56
2025-02-14 23:07:25,621 [podnet.py] => Task 9, Epoch 81/160 (LR 0.04902) => LSC_loss 0.19, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 97.47, Test_acc 31.16
2025-02-14 23:07:27,372 [podnet.py] => Task 9, Epoch 82/160 (LR 0.04804) => LSC_loss 0.21, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 96.62, Test_acc 27.26
2025-02-14 23:07:29,091 [podnet.py] => Task 9, Epoch 83/160 (LR 0.04706) => LSC_loss 0.19, Spatial_loss 1.45, Flat_loss 0.23, Train_acc 97.24, Test_acc 30.72
2025-02-14 23:07:30,897 [podnet.py] => Task 9, Epoch 84/160 (LR 0.04608) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.23, Train_acc 96.82, Test_acc 30.82
2025-02-14 23:07:32,691 [podnet.py] => Task 9, Epoch 85/160 (LR 0.04510) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.24, Train_acc 96.62, Test_acc 32.00
2025-02-14 23:07:34,476 [podnet.py] => Task 9, Epoch 86/160 (LR 0.04412) => LSC_loss 0.19, Spatial_loss 1.35, Flat_loss 0.22, Train_acc 97.47, Test_acc 28.86
2025-02-14 23:07:36,215 [podnet.py] => Task 9, Epoch 87/160 (LR 0.04315) => LSC_loss 0.19, Spatial_loss 1.41, Flat_loss 0.23, Train_acc 97.09, Test_acc 28.86
2025-02-14 23:07:38,004 [podnet.py] => Task 9, Epoch 88/160 (LR 0.04218) => LSC_loss 0.18, Spatial_loss 1.37, Flat_loss 0.22, Train_acc 97.65, Test_acc 30.90
2025-02-14 23:07:39,764 [podnet.py] => Task 9, Epoch 89/160 (LR 0.04121) => LSC_loss 0.18, Spatial_loss 1.42, Flat_loss 0.22, Train_acc 97.85, Test_acc 30.24
2025-02-14 23:07:41,535 [podnet.py] => Task 9, Epoch 90/160 (LR 0.04025) => LSC_loss 0.18, Spatial_loss 1.35, Flat_loss 0.22, Train_acc 97.88, Test_acc 29.40
2025-02-14 23:07:43,280 [podnet.py] => Task 9, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 1.37, Flat_loss 0.22, Train_acc 97.47, Test_acc 29.76
2025-02-14 23:07:45,020 [podnet.py] => Task 9, Epoch 92/160 (LR 0.03833) => LSC_loss 0.18, Spatial_loss 1.43, Flat_loss 0.22, Train_acc 97.79, Test_acc 30.66
2025-02-14 23:07:46,777 [podnet.py] => Task 9, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 97.26, Test_acc 29.62
2025-02-14 23:07:48,555 [podnet.py] => Task 9, Epoch 94/160 (LR 0.03643) => LSC_loss 0.17, Spatial_loss 1.31, Flat_loss 0.22, Train_acc 98.03, Test_acc 31.50
2025-02-14 23:07:50,318 [podnet.py] => Task 9, Epoch 95/160 (LR 0.03549) => LSC_loss 0.17, Spatial_loss 1.28, Flat_loss 0.21, Train_acc 97.97, Test_acc 29.28
2025-02-14 23:07:52,072 [podnet.py] => Task 9, Epoch 96/160 (LR 0.03455) => LSC_loss 0.16, Spatial_loss 1.32, Flat_loss 0.21, Train_acc 98.24, Test_acc 30.92
2025-02-14 23:07:53,781 [podnet.py] => Task 9, Epoch 97/160 (LR 0.03362) => LSC_loss 0.18, Spatial_loss 1.32, Flat_loss 0.22, Train_acc 97.68, Test_acc 30.70
2025-02-14 23:07:55,558 [podnet.py] => Task 9, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 97.74, Test_acc 30.10
2025-02-14 23:07:57,386 [podnet.py] => Task 9, Epoch 99/160 (LR 0.03178) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.22, Train_acc 97.74, Test_acc 31.30
2025-02-14 23:07:59,123 [podnet.py] => Task 9, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 1.26, Flat_loss 0.21, Train_acc 98.26, Test_acc 30.48
2025-02-14 23:08:00,893 [podnet.py] => Task 9, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 1.23, Flat_loss 0.21, Train_acc 98.29, Test_acc 30.26
2025-02-14 23:08:02,631 [podnet.py] => Task 9, Epoch 102/160 (LR 0.02907) => LSC_loss 0.16, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 98.65, Test_acc 31.48
2025-02-14 23:08:04,397 [podnet.py] => Task 9, Epoch 103/160 (LR 0.02818) => LSC_loss 0.17, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 97.82, Test_acc 27.64
2025-02-14 23:08:06,197 [podnet.py] => Task 9, Epoch 104/160 (LR 0.02730) => LSC_loss 0.16, Spatial_loss 1.26, Flat_loss 0.21, Train_acc 98.76, Test_acc 28.50
2025-02-14 23:08:07,949 [podnet.py] => Task 9, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 1.29, Flat_loss 0.21, Train_acc 98.32, Test_acc 30.78
2025-02-14 23:08:09,756 [podnet.py] => Task 9, Epoch 106/160 (LR 0.02557) => LSC_loss 0.16, Spatial_loss 1.19, Flat_loss 0.20, Train_acc 97.97, Test_acc 29.30
2025-02-14 23:08:11,563 [podnet.py] => Task 9, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 98.26, Test_acc 30.94
2025-02-14 23:08:13,432 [podnet.py] => Task 9, Epoch 108/160 (LR 0.02388) => LSC_loss 0.15, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 98.82, Test_acc 30.78
2025-02-14 23:08:15,188 [podnet.py] => Task 9, Epoch 109/160 (LR 0.02304) => LSC_loss 0.16, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 98.15, Test_acc 31.16
2025-02-14 23:08:16,957 [podnet.py] => Task 9, Epoch 110/160 (LR 0.02222) => LSC_loss 0.15, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 98.76, Test_acc 28.68
2025-02-14 23:08:18,728 [podnet.py] => Task 9, Epoch 111/160 (LR 0.02141) => LSC_loss 0.15, Spatial_loss 1.20, Flat_loss 0.20, Train_acc 98.68, Test_acc 32.00
2025-02-14 23:08:20,466 [podnet.py] => Task 9, Epoch 112/160 (LR 0.02061) => LSC_loss 0.14, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 98.91, Test_acc 30.32
2025-02-14 23:08:22,239 [podnet.py] => Task 9, Epoch 113/160 (LR 0.01982) => LSC_loss 0.15, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 98.32, Test_acc 33.56
2025-02-14 23:08:24,017 [podnet.py] => Task 9, Epoch 114/160 (LR 0.01905) => LSC_loss 0.15, Spatial_loss 1.17, Flat_loss 0.20, Train_acc 98.82, Test_acc 31.56
2025-02-14 23:08:25,788 [podnet.py] => Task 9, Epoch 115/160 (LR 0.01828) => LSC_loss 0.15, Spatial_loss 1.13, Flat_loss 0.20, Train_acc 98.50, Test_acc 30.76
2025-02-14 23:08:27,567 [podnet.py] => Task 9, Epoch 116/160 (LR 0.01753) => LSC_loss 0.15, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 98.44, Test_acc 32.12
2025-02-14 23:08:29,311 [podnet.py] => Task 9, Epoch 117/160 (LR 0.01679) => LSC_loss 0.15, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 98.76, Test_acc 29.90
2025-02-14 23:08:31,097 [podnet.py] => Task 9, Epoch 118/160 (LR 0.01606) => LSC_loss 0.14, Spatial_loss 1.20, Flat_loss 0.20, Train_acc 98.79, Test_acc 31.40
2025-02-14 23:08:32,886 [podnet.py] => Task 9, Epoch 119/160 (LR 0.01535) => LSC_loss 0.14, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 99.00, Test_acc 31.06
2025-02-14 23:08:34,659 [podnet.py] => Task 9, Epoch 120/160 (LR 0.01464) => LSC_loss 0.15, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 98.44, Test_acc 32.18
2025-02-14 23:08:36,470 [podnet.py] => Task 9, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.19, Train_acc 98.85, Test_acc 30.84
2025-02-14 23:08:38,226 [podnet.py] => Task 9, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.19, Train_acc 99.18, Test_acc 31.78
2025-02-14 23:08:39,964 [podnet.py] => Task 9, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 1.08, Flat_loss 0.19, Train_acc 98.85, Test_acc 31.32
2025-02-14 23:08:41,732 [podnet.py] => Task 9, Epoch 124/160 (LR 0.01198) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.19, Train_acc 98.91, Test_acc 31.12
2025-02-14 23:08:43,486 [podnet.py] => Task 9, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 98.88, Test_acc 31.84
2025-02-14 23:08:45,260 [podnet.py] => Task 9, Epoch 126/160 (LR 0.01073) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.19, Train_acc 99.06, Test_acc 30.76
2025-02-14 23:08:47,025 [podnet.py] => Task 9, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.19, Train_acc 98.94, Test_acc 31.60
2025-02-14 23:08:48,811 [podnet.py] => Task 9, Epoch 128/160 (LR 0.00955) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 99.06, Test_acc 31.66
2025-02-14 23:08:50,556 [podnet.py] => Task 9, Epoch 129/160 (LR 0.00898) => LSC_loss 0.13, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 99.15, Test_acc 31.26
2025-02-14 23:08:52,324 [podnet.py] => Task 9, Epoch 130/160 (LR 0.00843) => LSC_loss 0.14, Spatial_loss 1.04, Flat_loss 0.18, Train_acc 98.94, Test_acc 32.08
2025-02-14 23:08:54,069 [podnet.py] => Task 9, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 1.00, Flat_loss 0.18, Train_acc 98.91, Test_acc 32.04
2025-02-14 23:08:55,863 [podnet.py] => Task 9, Epoch 132/160 (LR 0.00737) => LSC_loss 0.13, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 99.12, Test_acc 32.18
2025-02-14 23:08:57,665 [podnet.py] => Task 9, Epoch 133/160 (LR 0.00686) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.19, Train_acc 99.21, Test_acc 31.32
2025-02-14 23:08:59,423 [podnet.py] => Task 9, Epoch 134/160 (LR 0.00638) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.18, Train_acc 99.15, Test_acc 31.68
2025-02-14 23:09:01,194 [podnet.py] => Task 9, Epoch 135/160 (LR 0.00590) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 99.18, Test_acc 32.14
2025-02-14 23:09:02,917 [podnet.py] => Task 9, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.18, Train_acc 99.26, Test_acc 31.56
2025-02-14 23:09:04,709 [podnet.py] => Task 9, Epoch 137/160 (LR 0.00501) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.18, Train_acc 99.12, Test_acc 31.46
2025-02-14 23:09:06,430 [podnet.py] => Task 9, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 99.18, Test_acc 31.96
2025-02-14 23:09:08,158 [podnet.py] => Task 9, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.18, Train_acc 99.32, Test_acc 32.38
2025-02-14 23:09:09,903 [podnet.py] => Task 9, Epoch 140/160 (LR 0.00381) => LSC_loss 0.13, Spatial_loss 1.00, Flat_loss 0.18, Train_acc 99.29, Test_acc 31.28
2025-02-14 23:09:11,670 [podnet.py] => Task 9, Epoch 141/160 (LR 0.00344) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.21, Test_acc 32.08
2025-02-14 23:09:13,433 [podnet.py] => Task 9, Epoch 142/160 (LR 0.00309) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.18, Train_acc 99.21, Test_acc 32.14
2025-02-14 23:09:15,169 [podnet.py] => Task 9, Epoch 143/160 (LR 0.00276) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.24, Test_acc 31.86
2025-02-14 23:09:16,929 [podnet.py] => Task 9, Epoch 144/160 (LR 0.00245) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.18, Train_acc 99.12, Test_acc 32.14
2025-02-14 23:09:18,677 [podnet.py] => Task 9, Epoch 145/160 (LR 0.00215) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.18, Train_acc 99.29, Test_acc 31.84
2025-02-14 23:09:20,436 [podnet.py] => Task 9, Epoch 146/160 (LR 0.00188) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.18, Train_acc 99.12, Test_acc 31.28
2025-02-14 23:09:22,190 [podnet.py] => Task 9, Epoch 147/160 (LR 0.00162) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.18, Test_acc 31.84
2025-02-14 23:09:24,001 [podnet.py] => Task 9, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.09, Test_acc 31.52
2025-02-14 23:09:25,738 [podnet.py] => Task 9, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.00, Test_acc 31.70
2025-02-14 23:09:27,497 [podnet.py] => Task 9, Epoch 150/160 (LR 0.00096) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.06, Test_acc 31.68
2025-02-14 23:09:29,248 [podnet.py] => Task 9, Epoch 151/160 (LR 0.00078) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.29, Test_acc 31.66
2025-02-14 23:09:31,030 [podnet.py] => Task 9, Epoch 152/160 (LR 0.00062) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.44, Test_acc 31.84
2025-02-14 23:09:32,777 [podnet.py] => Task 9, Epoch 153/160 (LR 0.00047) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.00, Test_acc 31.72
2025-02-14 23:09:34,602 [podnet.py] => Task 9, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 99.59, Test_acc 32.06
2025-02-14 23:09:36,362 [podnet.py] => Task 9, Epoch 155/160 (LR 0.00024) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.38, Test_acc 31.92
2025-02-14 23:09:38,101 [podnet.py] => Task 9, Epoch 156/160 (LR 0.00015) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.35, Test_acc 31.94
2025-02-14 23:09:39,904 [podnet.py] => Task 9, Epoch 157/160 (LR 0.00009) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.38, Test_acc 31.98
2025-02-14 23:09:41,701 [podnet.py] => Task 9, Epoch 158/160 (LR 0.00004) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.18, Train_acc 99.50, Test_acc 31.82
2025-02-14 23:09:43,464 [podnet.py] => Task 9, Epoch 159/160 (LR 0.00001) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.03, Test_acc 31.82
2025-02-14 23:09:45,213 [podnet.py] => Task 9, Epoch 160/160 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.18, Train_acc 99.32, Test_acc 32.12
2025-02-14 23:09:45,215 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:09:45,215 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:10:03,480 [podnet.py] => The size of finetune dataset: 1000
2025-02-14 23:10:04,615 [podnet.py] => Task 9, Epoch 1/20 (LR 0.00497) => LSC_loss 0.29, Spatial_loss 1.06, Flat_loss 0.15, Train_acc 94.90, Test_acc 32.78
2025-02-14 23:10:05,847 [podnet.py] => Task 9, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.11, Train_acc 99.20, Test_acc 35.52
2025-02-14 23:10:07,038 [podnet.py] => Task 9, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 99.30, Test_acc 35.06
2025-02-14 23:10:08,266 [podnet.py] => Task 9, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 0.92, Flat_loss 0.09, Train_acc 99.60, Test_acc 34.76
2025-02-14 23:10:09,507 [podnet.py] => Task 9, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 99.30, Test_acc 34.08
2025-02-14 23:10:10,748 [podnet.py] => Task 9, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 99.50, Test_acc 33.70
2025-02-14 23:10:12,013 [podnet.py] => Task 9, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 99.60, Test_acc 34.20
2025-02-14 23:10:13,240 [podnet.py] => Task 9, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.30, Test_acc 33.98
2025-02-14 23:10:14,465 [podnet.py] => Task 9, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.50, Test_acc 33.88
2025-02-14 23:10:15,672 [podnet.py] => Task 9, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 99.70, Test_acc 34.04
2025-02-14 23:10:16,948 [podnet.py] => Task 9, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 99.50, Test_acc 34.16
2025-02-14 23:10:18,174 [podnet.py] => Task 9, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 99.50, Test_acc 33.98
2025-02-14 23:10:19,405 [podnet.py] => Task 9, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.87, Flat_loss 0.08, Train_acc 99.30, Test_acc 33.84
2025-02-14 23:10:20,603 [podnet.py] => Task 9, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 99.50, Test_acc 33.86
2025-02-14 23:10:21,828 [podnet.py] => Task 9, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 99.60, Test_acc 33.96
2025-02-14 23:10:23,038 [podnet.py] => Task 9, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 99.60, Test_acc 34.10
2025-02-14 23:10:24,281 [podnet.py] => Task 9, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 99.50, Test_acc 34.14
2025-02-14 23:10:25,489 [podnet.py] => Task 9, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.87, Flat_loss 0.08, Train_acc 99.80, Test_acc 33.98
2025-02-14 23:10:26,687 [podnet.py] => Task 9, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 0.86, Flat_loss 0.08, Train_acc 99.50, Test_acc 33.98
2025-02-14 23:10:27,872 [podnet.py] => Task 9, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 99.70, Test_acc 33.98
2025-02-14 23:10:27,875 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:10:47,908 [podnet.py] => Exemplar size: 1000
2025-02-14 23:10:47,909 [trainer.py] => CNN: {'total': 33.98, '00-09': 38.2, '10-19': 10.7, '20-29': 24.8, '30-39': 26.7, '40-49': 69.5, 'old': 28.91, 'new': 79.6}
2025-02-14 23:10:47,909 [trainer.py] => NME: {'total': 34.3, '00-09': 44.9, '10-19': 11.4, '20-29': 24.5, '30-39': 26.8, '40-49': 63.9, 'old': 29.91, 'new': 73.8}
2025-02-14 23:10:47,909 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98]
2025-02-14 23:10:47,909 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54]
2025-02-14 23:10:47,909 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3]
2025-02-14 23:10:47,909 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52]

2025-02-14 23:10:47,909 [trainer.py] => Average Accuracy (CNN): 53.081
2025-02-14 23:10:47,909 [trainer.py] => Average Accuracy (NME): 52.18499999999999
2025-02-14 23:10:47,909 [trainer.py] => All params: 498257
2025-02-14 23:10:47,910 [trainer.py] => Trainable params: 498257
2025-02-14 23:10:47,910 [podnet.py] => Learning on 50-55
2025-02-14 23:10:47,937 [podnet.py] => Adaptive factor: 3.3166247903554
2025-02-14 23:10:49,744 [podnet.py] => Task 10, Epoch 1/160 (LR 0.09999) => LSC_loss 2.73, Spatial_loss 3.27, Flat_loss 1.08, Train_acc 54.60, Test_acc 15.95
2025-02-14 23:10:51,526 [podnet.py] => Task 10, Epoch 2/160 (LR 0.09996) => LSC_loss 1.27, Spatial_loss 2.71, Flat_loss 0.51, Train_acc 67.34, Test_acc 21.05
2025-02-14 23:10:53,294 [podnet.py] => Task 10, Epoch 3/160 (LR 0.09991) => LSC_loss 1.05, Spatial_loss 2.63, Flat_loss 0.42, Train_acc 72.14, Test_acc 19.53
2025-02-14 23:10:55,098 [podnet.py] => Task 10, Epoch 4/160 (LR 0.09985) => LSC_loss 0.94, Spatial_loss 2.58, Flat_loss 0.37, Train_acc 75.83, Test_acc 18.85
2025-02-14 23:10:56,900 [podnet.py] => Task 10, Epoch 5/160 (LR 0.09976) => LSC_loss 0.90, Spatial_loss 2.40, Flat_loss 0.34, Train_acc 77.74, Test_acc 24.45
2025-02-14 23:10:58,748 [podnet.py] => Task 10, Epoch 6/160 (LR 0.09965) => LSC_loss 0.84, Spatial_loss 2.29, Flat_loss 0.31, Train_acc 79.14, Test_acc 23.58
2025-02-14 23:11:00,556 [podnet.py] => Task 10, Epoch 7/160 (LR 0.09953) => LSC_loss 0.82, Spatial_loss 2.35, Flat_loss 0.32, Train_acc 78.46, Test_acc 22.31
2025-02-14 23:11:02,459 [podnet.py] => Task 10, Epoch 8/160 (LR 0.09938) => LSC_loss 0.81, Spatial_loss 2.30, Flat_loss 0.32, Train_acc 79.23, Test_acc 22.96
2025-02-14 23:11:04,231 [podnet.py] => Task 10, Epoch 9/160 (LR 0.09922) => LSC_loss 0.76, Spatial_loss 2.33, Flat_loss 0.31, Train_acc 80.94, Test_acc 24.09
2025-02-14 23:11:06,113 [podnet.py] => Task 10, Epoch 10/160 (LR 0.09904) => LSC_loss 0.72, Spatial_loss 2.22, Flat_loss 0.29, Train_acc 81.71, Test_acc 24.49
2025-02-14 23:11:07,937 [podnet.py] => Task 10, Epoch 11/160 (LR 0.09884) => LSC_loss 0.73, Spatial_loss 2.22, Flat_loss 0.29, Train_acc 82.00, Test_acc 20.78
2025-02-14 23:11:09,769 [podnet.py] => Task 10, Epoch 12/160 (LR 0.09862) => LSC_loss 0.69, Spatial_loss 2.26, Flat_loss 0.28, Train_acc 83.06, Test_acc 25.84
2025-02-14 23:11:11,592 [podnet.py] => Task 10, Epoch 13/160 (LR 0.09838) => LSC_loss 0.68, Spatial_loss 2.25, Flat_loss 0.29, Train_acc 83.60, Test_acc 24.07
2025-02-14 23:11:13,449 [podnet.py] => Task 10, Epoch 14/160 (LR 0.09812) => LSC_loss 0.66, Spatial_loss 2.23, Flat_loss 0.28, Train_acc 83.57, Test_acc 23.40
2025-02-14 23:11:15,214 [podnet.py] => Task 10, Epoch 15/160 (LR 0.09785) => LSC_loss 0.67, Spatial_loss 2.23, Flat_loss 0.28, Train_acc 83.40, Test_acc 24.22
2025-02-14 23:11:17,031 [podnet.py] => Task 10, Epoch 16/160 (LR 0.09755) => LSC_loss 0.61, Spatial_loss 2.11, Flat_loss 0.27, Train_acc 85.03, Test_acc 26.47
2025-02-14 23:11:18,828 [podnet.py] => Task 10, Epoch 17/160 (LR 0.09724) => LSC_loss 0.58, Spatial_loss 2.04, Flat_loss 0.27, Train_acc 85.91, Test_acc 19.87
2025-02-14 23:11:20,607 [podnet.py] => Task 10, Epoch 18/160 (LR 0.09691) => LSC_loss 0.61, Spatial_loss 2.11, Flat_loss 0.27, Train_acc 85.63, Test_acc 25.31
2025-02-14 23:11:22,437 [podnet.py] => Task 10, Epoch 19/160 (LR 0.09656) => LSC_loss 0.63, Spatial_loss 2.28, Flat_loss 0.27, Train_acc 83.80, Test_acc 23.58
2025-02-14 23:11:24,249 [podnet.py] => Task 10, Epoch 20/160 (LR 0.09619) => LSC_loss 0.57, Spatial_loss 2.14, Flat_loss 0.27, Train_acc 86.14, Test_acc 25.16
2025-02-14 23:11:26,068 [podnet.py] => Task 10, Epoch 21/160 (LR 0.09581) => LSC_loss 0.52, Spatial_loss 1.98, Flat_loss 0.26, Train_acc 86.89, Test_acc 24.67
2025-02-14 23:11:27,840 [podnet.py] => Task 10, Epoch 22/160 (LR 0.09541) => LSC_loss 0.54, Spatial_loss 2.02, Flat_loss 0.26, Train_acc 86.69, Test_acc 28.18
2025-02-14 23:11:29,667 [podnet.py] => Task 10, Epoch 23/160 (LR 0.09499) => LSC_loss 0.55, Spatial_loss 2.06, Flat_loss 0.26, Train_acc 86.57, Test_acc 27.65
2025-02-14 23:11:31,483 [podnet.py] => Task 10, Epoch 24/160 (LR 0.09455) => LSC_loss 0.61, Spatial_loss 2.13, Flat_loss 0.28, Train_acc 84.54, Test_acc 27.13
2025-02-14 23:11:33,291 [podnet.py] => Task 10, Epoch 25/160 (LR 0.09410) => LSC_loss 0.54, Spatial_loss 2.11, Flat_loss 0.27, Train_acc 87.20, Test_acc 19.27
2025-02-14 23:11:35,044 [podnet.py] => Task 10, Epoch 26/160 (LR 0.09362) => LSC_loss 0.53, Spatial_loss 2.11, Flat_loss 0.26, Train_acc 87.57, Test_acc 23.44
2025-02-14 23:11:36,842 [podnet.py] => Task 10, Epoch 27/160 (LR 0.09314) => LSC_loss 0.51, Spatial_loss 2.03, Flat_loss 0.26, Train_acc 87.40, Test_acc 27.58
2025-02-14 23:11:38,712 [podnet.py] => Task 10, Epoch 28/160 (LR 0.09263) => LSC_loss 0.59, Spatial_loss 2.21, Flat_loss 0.28, Train_acc 86.00, Test_acc 22.67
2025-02-14 23:11:40,459 [podnet.py] => Task 10, Epoch 29/160 (LR 0.09211) => LSC_loss 0.53, Spatial_loss 2.06, Flat_loss 0.27, Train_acc 87.49, Test_acc 26.89
2025-02-14 23:11:42,277 [podnet.py] => Task 10, Epoch 30/160 (LR 0.09157) => LSC_loss 0.49, Spatial_loss 1.99, Flat_loss 0.25, Train_acc 88.31, Test_acc 26.16
2025-02-14 23:11:44,103 [podnet.py] => Task 10, Epoch 31/160 (LR 0.09102) => LSC_loss 0.52, Spatial_loss 2.15, Flat_loss 0.27, Train_acc 87.40, Test_acc 28.29
2025-02-14 23:11:45,909 [podnet.py] => Task 10, Epoch 32/160 (LR 0.09045) => LSC_loss 0.52, Spatial_loss 2.11, Flat_loss 0.27, Train_acc 87.83, Test_acc 23.55
2025-02-14 23:11:47,754 [podnet.py] => Task 10, Epoch 33/160 (LR 0.08987) => LSC_loss 0.49, Spatial_loss 2.08, Flat_loss 0.27, Train_acc 87.80, Test_acc 27.87
2025-02-14 23:11:49,553 [podnet.py] => Task 10, Epoch 34/160 (LR 0.08927) => LSC_loss 0.48, Spatial_loss 2.03, Flat_loss 0.26, Train_acc 88.80, Test_acc 28.85
2025-02-14 23:11:51,414 [podnet.py] => Task 10, Epoch 35/160 (LR 0.08865) => LSC_loss 0.48, Spatial_loss 2.06, Flat_loss 0.26, Train_acc 89.17, Test_acc 24.25
2025-02-14 23:11:53,214 [podnet.py] => Task 10, Epoch 36/160 (LR 0.08802) => LSC_loss 0.46, Spatial_loss 2.01, Flat_loss 0.25, Train_acc 89.34, Test_acc 25.04
2025-02-14 23:11:55,036 [podnet.py] => Task 10, Epoch 37/160 (LR 0.08738) => LSC_loss 0.49, Spatial_loss 2.05, Flat_loss 0.27, Train_acc 87.74, Test_acc 27.24
2025-02-14 23:11:56,805 [podnet.py] => Task 10, Epoch 38/160 (LR 0.08672) => LSC_loss 0.45, Spatial_loss 1.94, Flat_loss 0.25, Train_acc 89.31, Test_acc 26.35
2025-02-14 23:11:58,608 [podnet.py] => Task 10, Epoch 39/160 (LR 0.08604) => LSC_loss 0.42, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 90.29, Test_acc 25.56
2025-02-14 23:12:00,450 [podnet.py] => Task 10, Epoch 40/160 (LR 0.08536) => LSC_loss 0.41, Spatial_loss 1.92, Flat_loss 0.25, Train_acc 89.94, Test_acc 24.20
2025-02-14 23:12:02,221 [podnet.py] => Task 10, Epoch 41/160 (LR 0.08465) => LSC_loss 0.41, Spatial_loss 1.98, Flat_loss 0.25, Train_acc 90.51, Test_acc 30.27
2025-02-14 23:12:04,078 [podnet.py] => Task 10, Epoch 42/160 (LR 0.08394) => LSC_loss 0.40, Spatial_loss 1.91, Flat_loss 0.24, Train_acc 90.91, Test_acc 25.51
2025-02-14 23:12:05,864 [podnet.py] => Task 10, Epoch 43/160 (LR 0.08321) => LSC_loss 0.41, Spatial_loss 1.93, Flat_loss 0.25, Train_acc 90.06, Test_acc 23.67
2025-02-14 23:12:07,695 [podnet.py] => Task 10, Epoch 44/160 (LR 0.08247) => LSC_loss 0.42, Spatial_loss 2.02, Flat_loss 0.24, Train_acc 90.00, Test_acc 27.33
2025-02-14 23:12:09,502 [podnet.py] => Task 10, Epoch 45/160 (LR 0.08172) => LSC_loss 0.43, Spatial_loss 1.95, Flat_loss 0.25, Train_acc 89.80, Test_acc 29.33
2025-02-14 23:12:11,282 [podnet.py] => Task 10, Epoch 46/160 (LR 0.08095) => LSC_loss 0.42, Spatial_loss 1.99, Flat_loss 0.25, Train_acc 90.74, Test_acc 25.49
2025-02-14 23:12:13,078 [podnet.py] => Task 10, Epoch 47/160 (LR 0.08018) => LSC_loss 0.43, Spatial_loss 1.99, Flat_loss 0.25, Train_acc 90.37, Test_acc 28.05
2025-02-14 23:12:14,876 [podnet.py] => Task 10, Epoch 48/160 (LR 0.07939) => LSC_loss 0.38, Spatial_loss 1.95, Flat_loss 0.24, Train_acc 91.91, Test_acc 25.56
2025-02-14 23:12:16,661 [podnet.py] => Task 10, Epoch 49/160 (LR 0.07859) => LSC_loss 0.38, Spatial_loss 1.89, Flat_loss 0.24, Train_acc 91.37, Test_acc 25.78
2025-02-14 23:12:18,503 [podnet.py] => Task 10, Epoch 50/160 (LR 0.07778) => LSC_loss 0.38, Spatial_loss 1.98, Flat_loss 0.24, Train_acc 91.14, Test_acc 27.84
2025-02-14 23:12:20,368 [podnet.py] => Task 10, Epoch 51/160 (LR 0.07696) => LSC_loss 0.36, Spatial_loss 1.86, Flat_loss 0.24, Train_acc 91.40, Test_acc 24.40
2025-02-14 23:12:22,200 [podnet.py] => Task 10, Epoch 52/160 (LR 0.07612) => LSC_loss 0.36, Spatial_loss 1.87, Flat_loss 0.24, Train_acc 92.03, Test_acc 26.84
2025-02-14 23:12:24,012 [podnet.py] => Task 10, Epoch 53/160 (LR 0.07528) => LSC_loss 0.36, Spatial_loss 1.86, Flat_loss 0.24, Train_acc 91.77, Test_acc 26.16
2025-02-14 23:12:25,857 [podnet.py] => Task 10, Epoch 54/160 (LR 0.07443) => LSC_loss 0.35, Spatial_loss 1.88, Flat_loss 0.24, Train_acc 91.97, Test_acc 27.22
2025-02-14 23:12:27,690 [podnet.py] => Task 10, Epoch 55/160 (LR 0.07357) => LSC_loss 0.36, Spatial_loss 1.76, Flat_loss 0.23, Train_acc 91.91, Test_acc 29.25
2025-02-14 23:12:29,535 [podnet.py] => Task 10, Epoch 56/160 (LR 0.07270) => LSC_loss 0.34, Spatial_loss 1.78, Flat_loss 0.23, Train_acc 93.00, Test_acc 26.75
2025-02-14 23:12:31,337 [podnet.py] => Task 10, Epoch 57/160 (LR 0.07182) => LSC_loss 0.36, Spatial_loss 1.90, Flat_loss 0.24, Train_acc 91.80, Test_acc 24.05
2025-02-14 23:12:33,183 [podnet.py] => Task 10, Epoch 58/160 (LR 0.07093) => LSC_loss 0.37, Spatial_loss 1.89, Flat_loss 0.25, Train_acc 91.51, Test_acc 24.71
2025-02-14 23:12:34,986 [podnet.py] => Task 10, Epoch 59/160 (LR 0.07004) => LSC_loss 0.38, Spatial_loss 1.85, Flat_loss 0.24, Train_acc 91.51, Test_acc 27.60
2025-02-14 23:12:36,808 [podnet.py] => Task 10, Epoch 60/160 (LR 0.06913) => LSC_loss 0.37, Spatial_loss 1.89, Flat_loss 0.24, Train_acc 91.94, Test_acc 26.51
2025-02-14 23:12:38,607 [podnet.py] => Task 10, Epoch 61/160 (LR 0.06822) => LSC_loss 0.34, Spatial_loss 1.82, Flat_loss 0.23, Train_acc 92.86, Test_acc 28.02
2025-02-14 23:12:40,486 [podnet.py] => Task 10, Epoch 62/160 (LR 0.06731) => LSC_loss 0.33, Spatial_loss 1.85, Flat_loss 0.24, Train_acc 92.83, Test_acc 27.95
2025-02-14 23:12:42,250 [podnet.py] => Task 10, Epoch 63/160 (LR 0.06638) => LSC_loss 0.34, Spatial_loss 1.76, Flat_loss 0.24, Train_acc 92.97, Test_acc 26.76
2025-02-14 23:12:44,022 [podnet.py] => Task 10, Epoch 64/160 (LR 0.06545) => LSC_loss 0.31, Spatial_loss 1.78, Flat_loss 0.23, Train_acc 93.34, Test_acc 26.96
2025-02-14 23:12:45,757 [podnet.py] => Task 10, Epoch 65/160 (LR 0.06451) => LSC_loss 0.32, Spatial_loss 1.80, Flat_loss 0.23, Train_acc 93.06, Test_acc 29.60
2025-02-14 23:12:47,604 [podnet.py] => Task 10, Epoch 66/160 (LR 0.06357) => LSC_loss 0.31, Spatial_loss 1.76, Flat_loss 0.23, Train_acc 93.20, Test_acc 31.64
2025-02-14 23:12:49,420 [podnet.py] => Task 10, Epoch 67/160 (LR 0.06262) => LSC_loss 0.32, Spatial_loss 1.80, Flat_loss 0.23, Train_acc 93.29, Test_acc 27.22
2025-02-14 23:12:51,220 [podnet.py] => Task 10, Epoch 68/160 (LR 0.06167) => LSC_loss 0.30, Spatial_loss 1.75, Flat_loss 0.22, Train_acc 94.06, Test_acc 29.87
2025-02-14 23:12:53,024 [podnet.py] => Task 10, Epoch 69/160 (LR 0.06072) => LSC_loss 0.29, Spatial_loss 1.68, Flat_loss 0.22, Train_acc 94.31, Test_acc 30.67
2025-02-14 23:12:54,834 [podnet.py] => Task 10, Epoch 70/160 (LR 0.05975) => LSC_loss 0.29, Spatial_loss 1.72, Flat_loss 0.22, Train_acc 94.20, Test_acc 27.44
2025-02-14 23:12:56,619 [podnet.py] => Task 10, Epoch 71/160 (LR 0.05879) => LSC_loss 0.30, Spatial_loss 1.76, Flat_loss 0.23, Train_acc 94.14, Test_acc 23.40
2025-02-14 23:12:58,404 [podnet.py] => Task 10, Epoch 72/160 (LR 0.05782) => LSC_loss 0.29, Spatial_loss 1.75, Flat_loss 0.22, Train_acc 93.97, Test_acc 23.84
2025-02-14 23:13:00,174 [podnet.py] => Task 10, Epoch 73/160 (LR 0.05685) => LSC_loss 0.26, Spatial_loss 1.68, Flat_loss 0.21, Train_acc 95.06, Test_acc 27.22
2025-02-14 23:13:02,015 [podnet.py] => Task 10, Epoch 74/160 (LR 0.05588) => LSC_loss 0.26, Spatial_loss 1.66, Flat_loss 0.21, Train_acc 95.11, Test_acc 24.78
2025-02-14 23:13:03,830 [podnet.py] => Task 10, Epoch 75/160 (LR 0.05490) => LSC_loss 0.27, Spatial_loss 1.66, Flat_loss 0.21, Train_acc 95.23, Test_acc 24.87
2025-02-14 23:13:05,650 [podnet.py] => Task 10, Epoch 76/160 (LR 0.05392) => LSC_loss 0.28, Spatial_loss 1.66, Flat_loss 0.21, Train_acc 94.97, Test_acc 28.02
2025-02-14 23:13:07,527 [podnet.py] => Task 10, Epoch 77/160 (LR 0.05294) => LSC_loss 0.28, Spatial_loss 1.65, Flat_loss 0.21, Train_acc 94.46, Test_acc 27.93
2025-02-14 23:13:09,306 [podnet.py] => Task 10, Epoch 78/160 (LR 0.05196) => LSC_loss 0.29, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 94.00, Test_acc 25.02
2025-02-14 23:13:11,094 [podnet.py] => Task 10, Epoch 79/160 (LR 0.05098) => LSC_loss 0.26, Spatial_loss 1.60, Flat_loss 0.21, Train_acc 94.97, Test_acc 25.58
2025-02-14 23:13:12,956 [podnet.py] => Task 10, Epoch 80/160 (LR 0.05000) => LSC_loss 0.25, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 95.43, Test_acc 27.65
2025-02-14 23:13:14,752 [podnet.py] => Task 10, Epoch 81/160 (LR 0.04902) => LSC_loss 0.26, Spatial_loss 1.71, Flat_loss 0.21, Train_acc 94.74, Test_acc 26.91
2025-02-14 23:13:16,506 [podnet.py] => Task 10, Epoch 82/160 (LR 0.04804) => LSC_loss 0.25, Spatial_loss 1.59, Flat_loss 0.20, Train_acc 95.34, Test_acc 29.40
2025-02-14 23:13:18,334 [podnet.py] => Task 10, Epoch 83/160 (LR 0.04706) => LSC_loss 0.24, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 95.60, Test_acc 25.25
2025-02-14 23:13:20,109 [podnet.py] => Task 10, Epoch 84/160 (LR 0.04608) => LSC_loss 0.26, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 94.89, Test_acc 28.13
2025-02-14 23:13:21,938 [podnet.py] => Task 10, Epoch 85/160 (LR 0.04510) => LSC_loss 0.26, Spatial_loss 1.59, Flat_loss 0.20, Train_acc 95.11, Test_acc 26.58
2025-02-14 23:13:23,711 [podnet.py] => Task 10, Epoch 86/160 (LR 0.04412) => LSC_loss 0.25, Spatial_loss 1.60, Flat_loss 0.20, Train_acc 95.66, Test_acc 28.65
2025-02-14 23:13:25,507 [podnet.py] => Task 10, Epoch 87/160 (LR 0.04315) => LSC_loss 0.25, Spatial_loss 1.68, Flat_loss 0.21, Train_acc 95.40, Test_acc 25.18
2025-02-14 23:13:27,346 [podnet.py] => Task 10, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 1.51, Flat_loss 0.19, Train_acc 96.57, Test_acc 28.31
2025-02-14 23:13:29,112 [podnet.py] => Task 10, Epoch 89/160 (LR 0.04121) => LSC_loss 0.24, Spatial_loss 1.56, Flat_loss 0.20, Train_acc 95.89, Test_acc 27.24
2025-02-14 23:13:30,931 [podnet.py] => Task 10, Epoch 90/160 (LR 0.04025) => LSC_loss 0.25, Spatial_loss 1.63, Flat_loss 0.21, Train_acc 94.83, Test_acc 28.18
2025-02-14 23:13:32,743 [podnet.py] => Task 10, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 1.74, Flat_loss 0.21, Train_acc 96.14, Test_acc 28.45
2025-02-14 23:13:34,540 [podnet.py] => Task 10, Epoch 92/160 (LR 0.03833) => LSC_loss 0.23, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 95.86, Test_acc 26.62
2025-02-14 23:13:36,387 [podnet.py] => Task 10, Epoch 93/160 (LR 0.03738) => LSC_loss 0.23, Spatial_loss 1.59, Flat_loss 0.20, Train_acc 96.26, Test_acc 25.84
2025-02-14 23:13:38,239 [podnet.py] => Task 10, Epoch 94/160 (LR 0.03643) => LSC_loss 0.24, Spatial_loss 1.52, Flat_loss 0.20, Train_acc 95.80, Test_acc 26.56
2025-02-14 23:13:40,058 [podnet.py] => Task 10, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 1.56, Flat_loss 0.20, Train_acc 96.40, Test_acc 29.49
2025-02-14 23:13:41,901 [podnet.py] => Task 10, Epoch 96/160 (LR 0.03455) => LSC_loss 0.21, Spatial_loss 1.39, Flat_loss 0.19, Train_acc 96.91, Test_acc 30.69
2025-02-14 23:13:43,675 [podnet.py] => Task 10, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.19, Train_acc 96.46, Test_acc 31.22
2025-02-14 23:13:45,470 [podnet.py] => Task 10, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 1.43, Flat_loss 0.18, Train_acc 96.60, Test_acc 29.95
2025-02-14 23:13:47,318 [podnet.py] => Task 10, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 1.48, Flat_loss 0.19, Train_acc 96.97, Test_acc 27.69
2025-02-14 23:13:49,107 [podnet.py] => Task 10, Epoch 100/160 (LR 0.03087) => LSC_loss 0.21, Spatial_loss 1.57, Flat_loss 0.19, Train_acc 96.66, Test_acc 26.09
2025-02-14 23:13:50,906 [podnet.py] => Task 10, Epoch 101/160 (LR 0.02996) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.18, Train_acc 96.69, Test_acc 27.65
2025-02-14 23:13:52,637 [podnet.py] => Task 10, Epoch 102/160 (LR 0.02907) => LSC_loss 0.20, Spatial_loss 1.44, Flat_loss 0.19, Train_acc 97.31, Test_acc 28.58
2025-02-14 23:13:54,477 [podnet.py] => Task 10, Epoch 103/160 (LR 0.02818) => LSC_loss 0.19, Spatial_loss 1.37, Flat_loss 0.18, Train_acc 97.09, Test_acc 29.42
2025-02-14 23:13:56,181 [podnet.py] => Task 10, Epoch 104/160 (LR 0.02730) => LSC_loss 0.18, Spatial_loss 1.32, Flat_loss 0.17, Train_acc 97.40, Test_acc 26.24
2025-02-14 23:13:58,014 [podnet.py] => Task 10, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 1.33, Flat_loss 0.17, Train_acc 97.14, Test_acc 29.80
2025-02-14 23:13:59,739 [podnet.py] => Task 10, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 1.27, Flat_loss 0.18, Train_acc 97.49, Test_acc 27.49
2025-02-14 23:14:01,526 [podnet.py] => Task 10, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 1.42, Flat_loss 0.18, Train_acc 97.51, Test_acc 29.55
2025-02-14 23:14:03,356 [podnet.py] => Task 10, Epoch 108/160 (LR 0.02388) => LSC_loss 0.19, Spatial_loss 1.43, Flat_loss 0.18, Train_acc 97.20, Test_acc 25.15
2025-02-14 23:14:05,148 [podnet.py] => Task 10, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 1.38, Flat_loss 0.18, Train_acc 97.51, Test_acc 28.98
2025-02-14 23:14:06,981 [podnet.py] => Task 10, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 1.34, Flat_loss 0.17, Train_acc 97.91, Test_acc 29.69
2025-02-14 23:14:08,695 [podnet.py] => Task 10, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 1.31, Flat_loss 0.17, Train_acc 97.69, Test_acc 29.18
2025-02-14 23:14:10,534 [podnet.py] => Task 10, Epoch 112/160 (LR 0.02061) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 97.43, Test_acc 28.05
2025-02-14 23:14:12,391 [podnet.py] => Task 10, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 1.29, Flat_loss 0.17, Train_acc 97.57, Test_acc 28.75
2025-02-14 23:14:14,181 [podnet.py] => Task 10, Epoch 114/160 (LR 0.01905) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 97.91, Test_acc 27.89
2025-02-14 23:14:16,025 [podnet.py] => Task 10, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 1.22, Flat_loss 0.16, Train_acc 98.29, Test_acc 29.24
2025-02-14 23:14:17,821 [podnet.py] => Task 10, Epoch 116/160 (LR 0.01753) => LSC_loss 0.18, Spatial_loss 1.20, Flat_loss 0.17, Train_acc 97.40, Test_acc 28.87
2025-02-14 23:14:19,657 [podnet.py] => Task 10, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 1.23, Flat_loss 0.17, Train_acc 97.11, Test_acc 26.58
2025-02-14 23:14:21,522 [podnet.py] => Task 10, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 97.71, Test_acc 27.42
2025-02-14 23:14:23,345 [podnet.py] => Task 10, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 1.22, Flat_loss 0.17, Train_acc 98.06, Test_acc 29.95
2025-02-14 23:14:25,176 [podnet.py] => Task 10, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 1.23, Flat_loss 0.16, Train_acc 98.26, Test_acc 30.16
2025-02-14 23:14:26,980 [podnet.py] => Task 10, Epoch 121/160 (LR 0.01396) => LSC_loss 0.16, Spatial_loss 1.25, Flat_loss 0.17, Train_acc 98.20, Test_acc 29.09
2025-02-14 23:14:28,814 [podnet.py] => Task 10, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 1.19, Flat_loss 0.16, Train_acc 98.29, Test_acc 29.15
2025-02-14 23:14:30,625 [podnet.py] => Task 10, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 98.03, Test_acc 26.95
2025-02-14 23:14:32,434 [podnet.py] => Task 10, Epoch 124/160 (LR 0.01198) => LSC_loss 0.16, Spatial_loss 1.21, Flat_loss 0.16, Train_acc 98.40, Test_acc 29.05
2025-02-14 23:14:34,280 [podnet.py] => Task 10, Epoch 125/160 (LR 0.01135) => LSC_loss 0.16, Spatial_loss 1.21, Flat_loss 0.16, Train_acc 98.00, Test_acc 28.75
2025-02-14 23:14:36,149 [podnet.py] => Task 10, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 98.14, Test_acc 27.60
2025-02-14 23:14:37,943 [podnet.py] => Task 10, Epoch 127/160 (LR 0.01013) => LSC_loss 0.16, Spatial_loss 1.17, Flat_loss 0.16, Train_acc 98.37, Test_acc 30.20
2025-02-14 23:14:39,807 [podnet.py] => Task 10, Epoch 128/160 (LR 0.00955) => LSC_loss 0.16, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 98.26, Test_acc 28.27
2025-02-14 23:14:41,660 [podnet.py] => Task 10, Epoch 129/160 (LR 0.00898) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 98.29, Test_acc 29.78
2025-02-14 23:14:43,437 [podnet.py] => Task 10, Epoch 130/160 (LR 0.00843) => LSC_loss 0.15, Spatial_loss 1.14, Flat_loss 0.15, Train_acc 98.09, Test_acc 29.35
2025-02-14 23:14:45,169 [podnet.py] => Task 10, Epoch 131/160 (LR 0.00789) => LSC_loss 0.15, Spatial_loss 1.12, Flat_loss 0.16, Train_acc 98.63, Test_acc 28.84
2025-02-14 23:14:46,977 [podnet.py] => Task 10, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 1.17, Flat_loss 0.16, Train_acc 98.34, Test_acc 29.15
2025-02-14 23:14:48,824 [podnet.py] => Task 10, Epoch 133/160 (LR 0.00686) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 98.49, Test_acc 29.24
2025-02-14 23:14:50,587 [podnet.py] => Task 10, Epoch 134/160 (LR 0.00638) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.16, Train_acc 98.34, Test_acc 27.93
2025-02-14 23:14:52,356 [podnet.py] => Task 10, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.11, Flat_loss 0.15, Train_acc 98.29, Test_acc 29.04
2025-02-14 23:14:54,124 [podnet.py] => Task 10, Epoch 136/160 (LR 0.00545) => LSC_loss 0.15, Spatial_loss 1.07, Flat_loss 0.15, Train_acc 98.57, Test_acc 30.13
2025-02-14 23:14:55,921 [podnet.py] => Task 10, Epoch 137/160 (LR 0.00501) => LSC_loss 0.16, Spatial_loss 1.13, Flat_loss 0.16, Train_acc 98.26, Test_acc 29.33
2025-02-14 23:14:57,759 [podnet.py] => Task 10, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 1.09, Flat_loss 0.15, Train_acc 98.60, Test_acc 29.20
2025-02-14 23:14:59,587 [podnet.py] => Task 10, Epoch 139/160 (LR 0.00419) => LSC_loss 0.15, Spatial_loss 1.10, Flat_loss 0.16, Train_acc 98.54, Test_acc 29.53
2025-02-14 23:15:01,391 [podnet.py] => Task 10, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.06, Flat_loss 0.15, Train_acc 98.49, Test_acc 30.05
2025-02-14 23:15:03,169 [podnet.py] => Task 10, Epoch 141/160 (LR 0.00344) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.15, Train_acc 98.66, Test_acc 29.73
2025-02-14 23:15:04,991 [podnet.py] => Task 10, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 98.43, Test_acc 29.55
2025-02-14 23:15:06,779 [podnet.py] => Task 10, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 98.69, Test_acc 29.71
2025-02-14 23:15:08,597 [podnet.py] => Task 10, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.15, Train_acc 98.63, Test_acc 29.55
2025-02-14 23:15:10,350 [podnet.py] => Task 10, Epoch 145/160 (LR 0.00215) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.15, Train_acc 98.91, Test_acc 29.35
2025-02-14 23:15:12,126 [podnet.py] => Task 10, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 1.07, Flat_loss 0.15, Train_acc 98.46, Test_acc 29.31
2025-02-14 23:15:13,943 [podnet.py] => Task 10, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.16, Train_acc 98.57, Test_acc 29.22
2025-02-14 23:15:15,746 [podnet.py] => Task 10, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 1.05, Flat_loss 0.15, Train_acc 98.43, Test_acc 29.75
2025-02-14 23:15:17,568 [podnet.py] => Task 10, Epoch 149/160 (LR 0.00116) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.15, Train_acc 98.80, Test_acc 29.35
2025-02-14 23:15:19,383 [podnet.py] => Task 10, Epoch 150/160 (LR 0.00096) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.15, Train_acc 98.77, Test_acc 29.62
2025-02-14 23:15:21,192 [podnet.py] => Task 10, Epoch 151/160 (LR 0.00078) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 98.60, Test_acc 29.42
2025-02-14 23:15:22,969 [podnet.py] => Task 10, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 98.54, Test_acc 29.80
2025-02-14 23:15:24,810 [podnet.py] => Task 10, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.15, Train_acc 98.49, Test_acc 29.05
2025-02-14 23:15:26,615 [podnet.py] => Task 10, Epoch 154/160 (LR 0.00035) => LSC_loss 0.14, Spatial_loss 1.01, Flat_loss 0.15, Train_acc 98.83, Test_acc 29.36
2025-02-14 23:15:28,415 [podnet.py] => Task 10, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.15, Train_acc 98.77, Test_acc 29.36
2025-02-14 23:15:30,184 [podnet.py] => Task 10, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 98.69, Test_acc 29.36
2025-02-14 23:15:32,030 [podnet.py] => Task 10, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 0.99, Flat_loss 0.15, Train_acc 98.83, Test_acc 29.73
2025-02-14 23:15:33,872 [podnet.py] => Task 10, Epoch 158/160 (LR 0.00004) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.15, Train_acc 98.49, Test_acc 29.44
2025-02-14 23:15:35,674 [podnet.py] => Task 10, Epoch 159/160 (LR 0.00001) => LSC_loss 0.14, Spatial_loss 1.01, Flat_loss 0.15, Train_acc 98.60, Test_acc 29.24
2025-02-14 23:15:37,501 [podnet.py] => Task 10, Epoch 160/160 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.15, Train_acc 98.54, Test_acc 29.31
2025-02-14 23:15:37,502 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:15:37,502 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:15:57,403 [podnet.py] => The size of finetune dataset: 1100
2025-02-14 23:15:58,740 [podnet.py] => Task 10, Epoch 1/20 (LR 0.00497) => LSC_loss 0.44, Spatial_loss 1.79, Flat_loss 0.17, Train_acc 88.64, Test_acc 32.07
2025-02-14 23:15:59,984 [podnet.py] => Task 10, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 1.28, Flat_loss 0.11, Train_acc 98.91, Test_acc 34.15
2025-02-14 23:16:01,260 [podnet.py] => Task 10, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 1.20, Flat_loss 0.10, Train_acc 99.36, Test_acc 33.69
2025-02-14 23:16:02,483 [podnet.py] => Task 10, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 1.07, Flat_loss 0.08, Train_acc 99.36, Test_acc 32.71
2025-02-14 23:16:03,739 [podnet.py] => Task 10, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 1.10, Flat_loss 0.08, Train_acc 98.91, Test_acc 32.29
2025-02-14 23:16:04,947 [podnet.py] => Task 10, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.04, Flat_loss 0.08, Train_acc 99.45, Test_acc 31.76
2025-02-14 23:16:06,248 [podnet.py] => Task 10, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 99.55, Test_acc 31.62
2025-02-14 23:16:07,483 [podnet.py] => Task 10, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.05, Flat_loss 0.08, Train_acc 99.27, Test_acc 31.78
2025-02-14 23:16:08,761 [podnet.py] => Task 10, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 1.02, Flat_loss 0.07, Train_acc 99.64, Test_acc 32.07
2025-02-14 23:16:09,984 [podnet.py] => Task 10, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 99.64, Test_acc 32.07
2025-02-14 23:16:11,273 [podnet.py] => Task 10, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 0.93, Flat_loss 0.07, Train_acc 99.45, Test_acc 31.96
2025-02-14 23:16:12,447 [podnet.py] => Task 10, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 99.36, Test_acc 31.80
2025-02-14 23:16:13,672 [podnet.py] => Task 10, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.07, Train_acc 99.45, Test_acc 31.80
2025-02-14 23:16:14,973 [podnet.py] => Task 10, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.07, Train_acc 99.45, Test_acc 32.20
2025-02-14 23:16:16,248 [podnet.py] => Task 10, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 99.55, Test_acc 31.96
2025-02-14 23:16:17,543 [podnet.py] => Task 10, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.91, Flat_loss 0.07, Train_acc 99.64, Test_acc 31.95
2025-02-14 23:16:18,833 [podnet.py] => Task 10, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 99.55, Test_acc 31.82
2025-02-14 23:16:20,074 [podnet.py] => Task 10, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 0.93, Flat_loss 0.07, Train_acc 99.27, Test_acc 31.93
2025-02-14 23:16:21,352 [podnet.py] => Task 10, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.07, Train_acc 99.36, Test_acc 31.93
2025-02-14 23:16:22,588 [podnet.py] => Task 10, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 99.64, Test_acc 32.11
2025-02-14 23:16:22,590 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:16:44,062 [podnet.py] => Exemplar size: 1100
2025-02-14 23:16:44,062 [trainer.py] => CNN: {'total': 32.11, '00-09': 32.8, '10-19': 10.4, '20-29': 21.1, '30-39': 21.1, '40-49': 51.1, '50-59': 80.2, 'old': 27.3, 'new': 80.2}
2025-02-14 23:16:44,062 [trainer.py] => NME: {'total': 32.27, '00-09': 40.2, '10-19': 10.1, '20-29': 20.5, '30-39': 22.7, '40-49': 47.9, '50-59': 72.2, 'old': 28.28, 'new': 72.2}
2025-02-14 23:16:44,062 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11]
2025-02-14 23:16:44,062 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73]
2025-02-14 23:16:44,063 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27]
2025-02-14 23:16:44,063 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31]

2025-02-14 23:16:44,063 [trainer.py] => Average Accuracy (CNN): 51.17454545454546
2025-02-14 23:16:44,063 [trainer.py] => Average Accuracy (NME): 50.37454545454545
2025-02-14 23:16:44,063 [trainer.py] => All params: 501457
2025-02-14 23:16:44,063 [trainer.py] => Trainable params: 501457
2025-02-14 23:16:44,064 [podnet.py] => Learning on 55-60
2025-02-14 23:16:44,090 [podnet.py] => Adaptive factor: 3.4641016151377544
2025-02-14 23:16:45,882 [podnet.py] => Task 11, Epoch 1/160 (LR 0.09999) => LSC_loss 3.47, Spatial_loss 3.03, Flat_loss 1.30, Train_acc 30.11, Test_acc 20.10
2025-02-14 23:16:47,780 [podnet.py] => Task 11, Epoch 2/160 (LR 0.09996) => LSC_loss 1.90, Spatial_loss 2.59, Flat_loss 0.64, Train_acc 41.11, Test_acc 19.27
2025-02-14 23:16:49,642 [podnet.py] => Task 11, Epoch 3/160 (LR 0.09991) => LSC_loss 1.65, Spatial_loss 2.36, Flat_loss 0.48, Train_acc 49.94, Test_acc 24.05
2025-02-14 23:16:51,514 [podnet.py] => Task 11, Epoch 4/160 (LR 0.09985) => LSC_loss 1.55, Spatial_loss 2.29, Flat_loss 0.43, Train_acc 50.64, Test_acc 23.73
2025-02-14 23:16:53,415 [podnet.py] => Task 11, Epoch 5/160 (LR 0.09976) => LSC_loss 1.49, Spatial_loss 2.22, Flat_loss 0.42, Train_acc 54.39, Test_acc 25.88
2025-02-14 23:16:55,261 [podnet.py] => Task 11, Epoch 6/160 (LR 0.09965) => LSC_loss 1.47, Spatial_loss 2.23, Flat_loss 0.40, Train_acc 54.28, Test_acc 24.63
2025-02-14 23:16:57,113 [podnet.py] => Task 11, Epoch 7/160 (LR 0.09953) => LSC_loss 1.42, Spatial_loss 2.28, Flat_loss 0.38, Train_acc 56.97, Test_acc 22.77
2025-02-14 23:16:58,995 [podnet.py] => Task 11, Epoch 8/160 (LR 0.09938) => LSC_loss 1.43, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 56.56, Test_acc 20.87
2025-02-14 23:17:00,844 [podnet.py] => Task 11, Epoch 9/160 (LR 0.09922) => LSC_loss 1.36, Spatial_loss 2.31, Flat_loss 0.39, Train_acc 59.69, Test_acc 24.62
2025-02-14 23:17:02,736 [podnet.py] => Task 11, Epoch 10/160 (LR 0.09904) => LSC_loss 1.37, Spatial_loss 2.36, Flat_loss 0.40, Train_acc 60.22, Test_acc 19.33
2025-02-14 23:17:04,535 [podnet.py] => Task 11, Epoch 11/160 (LR 0.09884) => LSC_loss 1.36, Spatial_loss 2.35, Flat_loss 0.40, Train_acc 58.83, Test_acc 22.52
2025-02-14 23:17:06,368 [podnet.py] => Task 11, Epoch 12/160 (LR 0.09862) => LSC_loss 1.27, Spatial_loss 2.12, Flat_loss 0.37, Train_acc 62.11, Test_acc 25.68
2025-02-14 23:17:08,264 [podnet.py] => Task 11, Epoch 13/160 (LR 0.09838) => LSC_loss 1.26, Spatial_loss 2.14, Flat_loss 0.39, Train_acc 63.00, Test_acc 24.05
2025-02-14 23:17:10,101 [podnet.py] => Task 11, Epoch 14/160 (LR 0.09812) => LSC_loss 1.26, Spatial_loss 2.23, Flat_loss 0.40, Train_acc 63.89, Test_acc 22.87
2025-02-14 23:17:11,968 [podnet.py] => Task 11, Epoch 15/160 (LR 0.09785) => LSC_loss 1.17, Spatial_loss 2.14, Flat_loss 0.37, Train_acc 66.03, Test_acc 24.72
2025-02-14 23:17:13,796 [podnet.py] => Task 11, Epoch 16/160 (LR 0.09755) => LSC_loss 1.15, Spatial_loss 2.11, Flat_loss 0.36, Train_acc 66.47, Test_acc 29.23
2025-02-14 23:17:15,767 [podnet.py] => Task 11, Epoch 17/160 (LR 0.09724) => LSC_loss 1.10, Spatial_loss 2.05, Flat_loss 0.37, Train_acc 67.86, Test_acc 25.47
2025-02-14 23:17:17,622 [podnet.py] => Task 11, Epoch 18/160 (LR 0.09691) => LSC_loss 1.06, Spatial_loss 2.03, Flat_loss 0.37, Train_acc 68.78, Test_acc 25.37
2025-02-14 23:17:19,442 [podnet.py] => Task 11, Epoch 19/160 (LR 0.09656) => LSC_loss 1.19, Spatial_loss 2.11, Flat_loss 0.40, Train_acc 66.08, Test_acc 24.60
2025-02-14 23:17:21,269 [podnet.py] => Task 11, Epoch 20/160 (LR 0.09619) => LSC_loss 1.14, Spatial_loss 2.19, Flat_loss 0.40, Train_acc 67.31, Test_acc 24.95
2025-02-14 23:17:23,128 [podnet.py] => Task 11, Epoch 21/160 (LR 0.09581) => LSC_loss 1.13, Spatial_loss 2.22, Flat_loss 0.40, Train_acc 67.39, Test_acc 28.60
2025-02-14 23:17:25,001 [podnet.py] => Task 11, Epoch 22/160 (LR 0.09541) => LSC_loss 1.04, Spatial_loss 2.14, Flat_loss 0.37, Train_acc 70.58, Test_acc 29.40
2025-02-14 23:17:26,853 [podnet.py] => Task 11, Epoch 23/160 (LR 0.09499) => LSC_loss 0.97, Spatial_loss 1.95, Flat_loss 0.36, Train_acc 72.58, Test_acc 23.18
2025-02-14 23:17:28,766 [podnet.py] => Task 11, Epoch 24/160 (LR 0.09455) => LSC_loss 1.05, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 69.69, Test_acc 25.85
2025-02-14 23:17:30,615 [podnet.py] => Task 11, Epoch 25/160 (LR 0.09410) => LSC_loss 0.99, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 71.72, Test_acc 22.07
2025-02-14 23:17:32,515 [podnet.py] => Task 11, Epoch 26/160 (LR 0.09362) => LSC_loss 0.97, Spatial_loss 2.06, Flat_loss 0.37, Train_acc 73.42, Test_acc 24.70
2025-02-14 23:17:34,331 [podnet.py] => Task 11, Epoch 27/160 (LR 0.09314) => LSC_loss 1.12, Spatial_loss 2.20, Flat_loss 0.41, Train_acc 68.33, Test_acc 26.78
2025-02-14 23:17:36,188 [podnet.py] => Task 11, Epoch 28/160 (LR 0.09263) => LSC_loss 1.02, Spatial_loss 2.15, Flat_loss 0.39, Train_acc 71.67, Test_acc 25.85
2025-02-14 23:17:38,118 [podnet.py] => Task 11, Epoch 29/160 (LR 0.09211) => LSC_loss 0.88, Spatial_loss 2.05, Flat_loss 0.38, Train_acc 75.78, Test_acc 27.47
2025-02-14 23:17:39,974 [podnet.py] => Task 11, Epoch 30/160 (LR 0.09157) => LSC_loss 0.92, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 73.89, Test_acc 21.47
2025-02-14 23:17:41,837 [podnet.py] => Task 11, Epoch 31/160 (LR 0.09102) => LSC_loss 0.86, Spatial_loss 1.96, Flat_loss 0.37, Train_acc 76.53, Test_acc 27.17
2025-02-14 23:17:43,684 [podnet.py] => Task 11, Epoch 32/160 (LR 0.09045) => LSC_loss 0.89, Spatial_loss 2.15, Flat_loss 0.38, Train_acc 75.81, Test_acc 26.75
2025-02-14 23:17:45,605 [podnet.py] => Task 11, Epoch 33/160 (LR 0.08987) => LSC_loss 0.89, Spatial_loss 2.03, Flat_loss 0.39, Train_acc 75.47, Test_acc 22.97
2025-02-14 23:17:47,476 [podnet.py] => Task 11, Epoch 34/160 (LR 0.08927) => LSC_loss 0.92, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 74.42, Test_acc 27.35
2025-02-14 23:17:49,377 [podnet.py] => Task 11, Epoch 35/160 (LR 0.08865) => LSC_loss 0.88, Spatial_loss 2.12, Flat_loss 0.39, Train_acc 75.31, Test_acc 29.03
2025-02-14 23:17:51,192 [podnet.py] => Task 11, Epoch 36/160 (LR 0.08802) => LSC_loss 0.90, Spatial_loss 2.05, Flat_loss 0.40, Train_acc 75.03, Test_acc 27.40
2025-02-14 23:17:53,022 [podnet.py] => Task 11, Epoch 37/160 (LR 0.08738) => LSC_loss 0.90, Spatial_loss 2.29, Flat_loss 0.41, Train_acc 75.08, Test_acc 28.50
2025-02-14 23:17:54,942 [podnet.py] => Task 11, Epoch 38/160 (LR 0.08672) => LSC_loss 0.81, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 77.69, Test_acc 27.45
2025-02-14 23:17:56,773 [podnet.py] => Task 11, Epoch 39/160 (LR 0.08604) => LSC_loss 0.81, Spatial_loss 2.02, Flat_loss 0.38, Train_acc 77.67, Test_acc 23.90
2025-02-14 23:17:58,649 [podnet.py] => Task 11, Epoch 40/160 (LR 0.08536) => LSC_loss 0.73, Spatial_loss 2.01, Flat_loss 0.38, Train_acc 80.58, Test_acc 24.87
2025-02-14 23:18:00,533 [podnet.py] => Task 11, Epoch 41/160 (LR 0.08465) => LSC_loss 0.87, Spatial_loss 2.19, Flat_loss 0.41, Train_acc 76.17, Test_acc 27.33
2025-02-14 23:18:02,427 [podnet.py] => Task 11, Epoch 42/160 (LR 0.08394) => LSC_loss 0.84, Spatial_loss 2.14, Flat_loss 0.42, Train_acc 76.67, Test_acc 22.95
2025-02-14 23:18:04,319 [podnet.py] => Task 11, Epoch 43/160 (LR 0.08321) => LSC_loss 0.74, Spatial_loss 1.96, Flat_loss 0.39, Train_acc 80.53, Test_acc 27.93
2025-02-14 23:18:06,134 [podnet.py] => Task 11, Epoch 44/160 (LR 0.08247) => LSC_loss 0.84, Spatial_loss 2.12, Flat_loss 0.40, Train_acc 77.69, Test_acc 25.65
2025-02-14 23:18:07,990 [podnet.py] => Task 11, Epoch 45/160 (LR 0.08172) => LSC_loss 0.77, Spatial_loss 2.03, Flat_loss 0.39, Train_acc 79.53, Test_acc 22.72
2025-02-14 23:18:09,844 [podnet.py] => Task 11, Epoch 46/160 (LR 0.08095) => LSC_loss 0.70, Spatial_loss 1.93, Flat_loss 0.38, Train_acc 82.39, Test_acc 28.55
2025-02-14 23:18:11,678 [podnet.py] => Task 11, Epoch 47/160 (LR 0.08018) => LSC_loss 0.73, Spatial_loss 1.95, Flat_loss 0.38, Train_acc 80.61, Test_acc 22.50
2025-02-14 23:18:13,586 [podnet.py] => Task 11, Epoch 48/160 (LR 0.07939) => LSC_loss 0.79, Spatial_loss 1.96, Flat_loss 0.39, Train_acc 78.67, Test_acc 29.30
2025-02-14 23:18:15,438 [podnet.py] => Task 11, Epoch 49/160 (LR 0.07859) => LSC_loss 0.63, Spatial_loss 1.93, Flat_loss 0.37, Train_acc 83.89, Test_acc 26.73
2025-02-14 23:18:17,297 [podnet.py] => Task 11, Epoch 50/160 (LR 0.07778) => LSC_loss 0.60, Spatial_loss 1.89, Flat_loss 0.37, Train_acc 84.58, Test_acc 26.97
2025-02-14 23:18:19,175 [podnet.py] => Task 11, Epoch 51/160 (LR 0.07696) => LSC_loss 0.61, Spatial_loss 1.90, Flat_loss 0.37, Train_acc 83.53, Test_acc 28.47
2025-02-14 23:18:21,007 [podnet.py] => Task 11, Epoch 52/160 (LR 0.07612) => LSC_loss 0.61, Spatial_loss 1.85, Flat_loss 0.37, Train_acc 85.44, Test_acc 26.92
2025-02-14 23:18:22,835 [podnet.py] => Task 11, Epoch 53/160 (LR 0.07528) => LSC_loss 0.70, Spatial_loss 1.91, Flat_loss 0.39, Train_acc 81.72, Test_acc 25.83
2025-02-14 23:18:24,694 [podnet.py] => Task 11, Epoch 54/160 (LR 0.07443) => LSC_loss 0.65, Spatial_loss 1.91, Flat_loss 0.38, Train_acc 83.81, Test_acc 24.90
2025-02-14 23:18:26,550 [podnet.py] => Task 11, Epoch 55/160 (LR 0.07357) => LSC_loss 0.71, Spatial_loss 2.00, Flat_loss 0.39, Train_acc 82.00, Test_acc 30.50
2025-02-14 23:18:28,411 [podnet.py] => Task 11, Epoch 56/160 (LR 0.07270) => LSC_loss 0.68, Spatial_loss 1.96, Flat_loss 0.39, Train_acc 82.39, Test_acc 27.65
2025-02-14 23:18:30,256 [podnet.py] => Task 11, Epoch 57/160 (LR 0.07182) => LSC_loss 0.66, Spatial_loss 1.96, Flat_loss 0.38, Train_acc 83.25, Test_acc 29.43
2025-02-14 23:18:32,154 [podnet.py] => Task 11, Epoch 58/160 (LR 0.07093) => LSC_loss 0.64, Spatial_loss 1.91, Flat_loss 0.38, Train_acc 83.39, Test_acc 26.27
2025-02-14 23:18:34,029 [podnet.py] => Task 11, Epoch 59/160 (LR 0.07004) => LSC_loss 0.59, Spatial_loss 1.91, Flat_loss 0.37, Train_acc 84.67, Test_acc 25.58
2025-02-14 23:18:35,891 [podnet.py] => Task 11, Epoch 60/160 (LR 0.06913) => LSC_loss 0.55, Spatial_loss 1.75, Flat_loss 0.37, Train_acc 87.81, Test_acc 26.87
2025-02-14 23:18:37,704 [podnet.py] => Task 11, Epoch 61/160 (LR 0.06822) => LSC_loss 0.57, Spatial_loss 1.81, Flat_loss 0.38, Train_acc 85.42, Test_acc 26.82
2025-02-14 23:18:39,520 [podnet.py] => Task 11, Epoch 62/160 (LR 0.06731) => LSC_loss 0.65, Spatial_loss 1.83, Flat_loss 0.37, Train_acc 82.75, Test_acc 28.22
2025-02-14 23:18:41,349 [podnet.py] => Task 11, Epoch 63/160 (LR 0.06638) => LSC_loss 0.53, Spatial_loss 1.82, Flat_loss 0.37, Train_acc 87.67, Test_acc 31.18
2025-02-14 23:18:43,224 [podnet.py] => Task 11, Epoch 64/160 (LR 0.06545) => LSC_loss 0.61, Spatial_loss 1.82, Flat_loss 0.38, Train_acc 84.58, Test_acc 26.93
2025-02-14 23:18:45,074 [podnet.py] => Task 11, Epoch 65/160 (LR 0.06451) => LSC_loss 0.59, Spatial_loss 1.80, Flat_loss 0.37, Train_acc 85.14, Test_acc 22.75
2025-02-14 23:18:47,000 [podnet.py] => Task 11, Epoch 66/160 (LR 0.06357) => LSC_loss 0.56, Spatial_loss 1.82, Flat_loss 0.37, Train_acc 85.75, Test_acc 25.53
2025-02-14 23:18:48,918 [podnet.py] => Task 11, Epoch 67/160 (LR 0.06262) => LSC_loss 0.56, Spatial_loss 1.81, Flat_loss 0.37, Train_acc 86.61, Test_acc 28.53
2025-02-14 23:18:50,742 [podnet.py] => Task 11, Epoch 68/160 (LR 0.06167) => LSC_loss 0.53, Spatial_loss 1.77, Flat_loss 0.37, Train_acc 87.36, Test_acc 25.68
2025-02-14 23:18:52,627 [podnet.py] => Task 11, Epoch 69/160 (LR 0.06072) => LSC_loss 0.48, Spatial_loss 1.75, Flat_loss 0.37, Train_acc 88.94, Test_acc 27.80
2025-02-14 23:18:54,579 [podnet.py] => Task 11, Epoch 70/160 (LR 0.05975) => LSC_loss 0.53, Spatial_loss 1.79, Flat_loss 0.36, Train_acc 87.42, Test_acc 30.58
2025-02-14 23:18:56,478 [podnet.py] => Task 11, Epoch 71/160 (LR 0.05879) => LSC_loss 0.50, Spatial_loss 1.83, Flat_loss 0.39, Train_acc 88.03, Test_acc 23.08
2025-02-14 23:18:58,371 [podnet.py] => Task 11, Epoch 72/160 (LR 0.05782) => LSC_loss 0.50, Spatial_loss 1.77, Flat_loss 0.37, Train_acc 87.97, Test_acc 26.10
2025-02-14 23:19:00,244 [podnet.py] => Task 11, Epoch 73/160 (LR 0.05685) => LSC_loss 0.50, Spatial_loss 1.71, Flat_loss 0.37, Train_acc 88.28, Test_acc 28.68
2025-02-14 23:19:02,114 [podnet.py] => Task 11, Epoch 74/160 (LR 0.05588) => LSC_loss 0.47, Spatial_loss 1.72, Flat_loss 0.36, Train_acc 89.89, Test_acc 30.27
2025-02-14 23:19:03,983 [podnet.py] => Task 11, Epoch 75/160 (LR 0.05490) => LSC_loss 0.48, Spatial_loss 1.71, Flat_loss 0.37, Train_acc 88.75, Test_acc 24.33
2025-02-14 23:19:05,834 [podnet.py] => Task 11, Epoch 76/160 (LR 0.05392) => LSC_loss 0.50, Spatial_loss 1.78, Flat_loss 0.38, Train_acc 89.08, Test_acc 30.62
2025-02-14 23:19:07,689 [podnet.py] => Task 11, Epoch 77/160 (LR 0.05294) => LSC_loss 0.51, Spatial_loss 1.75, Flat_loss 0.37, Train_acc 87.83, Test_acc 27.20
2025-02-14 23:19:09,513 [podnet.py] => Task 11, Epoch 78/160 (LR 0.05196) => LSC_loss 0.45, Spatial_loss 1.70, Flat_loss 0.35, Train_acc 90.36, Test_acc 25.63
2025-02-14 23:19:11,366 [podnet.py] => Task 11, Epoch 79/160 (LR 0.05098) => LSC_loss 0.50, Spatial_loss 1.71, Flat_loss 0.37, Train_acc 88.69, Test_acc 29.42
2025-02-14 23:19:13,265 [podnet.py] => Task 11, Epoch 80/160 (LR 0.05000) => LSC_loss 0.47, Spatial_loss 1.75, Flat_loss 0.35, Train_acc 88.89, Test_acc 29.33
2025-02-14 23:19:15,156 [podnet.py] => Task 11, Epoch 81/160 (LR 0.04902) => LSC_loss 0.45, Spatial_loss 1.74, Flat_loss 0.37, Train_acc 90.83, Test_acc 29.33
2025-02-14 23:19:16,981 [podnet.py] => Task 11, Epoch 82/160 (LR 0.04804) => LSC_loss 0.46, Spatial_loss 1.79, Flat_loss 0.36, Train_acc 89.56, Test_acc 30.77
2025-02-14 23:19:18,823 [podnet.py] => Task 11, Epoch 83/160 (LR 0.04706) => LSC_loss 0.45, Spatial_loss 1.70, Flat_loss 0.36, Train_acc 90.06, Test_acc 29.80
2025-02-14 23:19:20,737 [podnet.py] => Task 11, Epoch 84/160 (LR 0.04608) => LSC_loss 0.42, Spatial_loss 1.73, Flat_loss 0.35, Train_acc 90.83, Test_acc 27.15
2025-02-14 23:19:22,597 [podnet.py] => Task 11, Epoch 85/160 (LR 0.04510) => LSC_loss 0.40, Spatial_loss 1.59, Flat_loss 0.35, Train_acc 91.22, Test_acc 29.38
2025-02-14 23:19:24,444 [podnet.py] => Task 11, Epoch 86/160 (LR 0.04412) => LSC_loss 0.36, Spatial_loss 1.58, Flat_loss 0.35, Train_acc 92.83, Test_acc 29.75
2025-02-14 23:19:26,320 [podnet.py] => Task 11, Epoch 87/160 (LR 0.04315) => LSC_loss 0.38, Spatial_loss 1.60, Flat_loss 0.35, Train_acc 92.14, Test_acc 31.97
2025-02-14 23:19:28,225 [podnet.py] => Task 11, Epoch 88/160 (LR 0.04218) => LSC_loss 0.35, Spatial_loss 1.57, Flat_loss 0.34, Train_acc 92.89, Test_acc 28.63
2025-02-14 23:19:30,077 [podnet.py] => Task 11, Epoch 89/160 (LR 0.04121) => LSC_loss 0.39, Spatial_loss 1.58, Flat_loss 0.35, Train_acc 91.86, Test_acc 27.02
2025-02-14 23:19:31,991 [podnet.py] => Task 11, Epoch 90/160 (LR 0.04025) => LSC_loss 0.39, Spatial_loss 1.55, Flat_loss 0.34, Train_acc 92.33, Test_acc 29.40
2025-02-14 23:19:33,861 [podnet.py] => Task 11, Epoch 91/160 (LR 0.03928) => LSC_loss 0.35, Spatial_loss 1.57, Flat_loss 0.35, Train_acc 92.39, Test_acc 29.72
2025-02-14 23:19:35,780 [podnet.py] => Task 11, Epoch 92/160 (LR 0.03833) => LSC_loss 0.32, Spatial_loss 1.54, Flat_loss 0.34, Train_acc 94.42, Test_acc 28.90
2025-02-14 23:19:37,621 [podnet.py] => Task 11, Epoch 93/160 (LR 0.03738) => LSC_loss 0.32, Spatial_loss 1.54, Flat_loss 0.34, Train_acc 93.86, Test_acc 29.05
2025-02-14 23:19:39,405 [podnet.py] => Task 11, Epoch 94/160 (LR 0.03643) => LSC_loss 0.36, Spatial_loss 1.51, Flat_loss 0.34, Train_acc 94.03, Test_acc 27.63
2025-02-14 23:19:41,283 [podnet.py] => Task 11, Epoch 95/160 (LR 0.03549) => LSC_loss 0.41, Spatial_loss 1.55, Flat_loss 0.36, Train_acc 91.03, Test_acc 31.95
2025-02-14 23:19:43,135 [podnet.py] => Task 11, Epoch 96/160 (LR 0.03455) => LSC_loss 0.32, Spatial_loss 1.49, Flat_loss 0.34, Train_acc 94.22, Test_acc 29.17
2025-02-14 23:19:44,927 [podnet.py] => Task 11, Epoch 97/160 (LR 0.03362) => LSC_loss 0.33, Spatial_loss 1.52, Flat_loss 0.34, Train_acc 94.25, Test_acc 27.90
2025-02-14 23:19:46,765 [podnet.py] => Task 11, Epoch 98/160 (LR 0.03269) => LSC_loss 0.32, Spatial_loss 1.53, Flat_loss 0.33, Train_acc 94.53, Test_acc 27.85
2025-02-14 23:19:48,648 [podnet.py] => Task 11, Epoch 99/160 (LR 0.03178) => LSC_loss 0.34, Spatial_loss 1.50, Flat_loss 0.33, Train_acc 94.00, Test_acc 29.38
2025-02-14 23:19:50,477 [podnet.py] => Task 11, Epoch 100/160 (LR 0.03087) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.34, Train_acc 92.56, Test_acc 27.43
2025-02-14 23:19:52,378 [podnet.py] => Task 11, Epoch 101/160 (LR 0.02996) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.35, Train_acc 93.56, Test_acc 29.78
2025-02-14 23:19:54,253 [podnet.py] => Task 11, Epoch 102/160 (LR 0.02907) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.33, Train_acc 94.94, Test_acc 30.68
2025-02-14 23:19:56,127 [podnet.py] => Task 11, Epoch 103/160 (LR 0.02818) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.33, Train_acc 94.50, Test_acc 29.48
2025-02-14 23:19:57,997 [podnet.py] => Task 11, Epoch 104/160 (LR 0.02730) => LSC_loss 0.32, Spatial_loss 1.47, Flat_loss 0.34, Train_acc 93.64, Test_acc 29.72
2025-02-14 23:19:59,841 [podnet.py] => Task 11, Epoch 105/160 (LR 0.02643) => LSC_loss 0.28, Spatial_loss 1.44, Flat_loss 0.33, Train_acc 95.83, Test_acc 29.50
2025-02-14 23:20:01,687 [podnet.py] => Task 11, Epoch 106/160 (LR 0.02557) => LSC_loss 0.26, Spatial_loss 1.38, Flat_loss 0.33, Train_acc 95.97, Test_acc 31.73
2025-02-14 23:20:03,509 [podnet.py] => Task 11, Epoch 107/160 (LR 0.02472) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.32, Train_acc 95.97, Test_acc 28.75
2025-02-14 23:20:05,365 [podnet.py] => Task 11, Epoch 108/160 (LR 0.02388) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.33, Train_acc 95.61, Test_acc 30.75
2025-02-14 23:20:07,233 [podnet.py] => Task 11, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.32, Train_acc 95.39, Test_acc 30.30
2025-02-14 23:20:09,124 [podnet.py] => Task 11, Epoch 110/160 (LR 0.02222) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.32, Train_acc 96.25, Test_acc 29.55
2025-02-14 23:20:10,952 [podnet.py] => Task 11, Epoch 111/160 (LR 0.02141) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.32, Train_acc 96.17, Test_acc 28.72
2025-02-14 23:20:12,857 [podnet.py] => Task 11, Epoch 112/160 (LR 0.02061) => LSC_loss 0.25, Spatial_loss 1.29, Flat_loss 0.31, Train_acc 96.83, Test_acc 29.50
2025-02-14 23:20:14,708 [podnet.py] => Task 11, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.35, Flat_loss 0.33, Train_acc 95.86, Test_acc 31.02
2025-02-14 23:20:16,546 [podnet.py] => Task 11, Epoch 114/160 (LR 0.01905) => LSC_loss 0.25, Spatial_loss 1.35, Flat_loss 0.32, Train_acc 96.19, Test_acc 28.58
2025-02-14 23:20:18,409 [podnet.py] => Task 11, Epoch 115/160 (LR 0.01828) => LSC_loss 0.24, Spatial_loss 1.34, Flat_loss 0.31, Train_acc 97.14, Test_acc 30.83
2025-02-14 23:20:20,291 [podnet.py] => Task 11, Epoch 116/160 (LR 0.01753) => LSC_loss 0.24, Spatial_loss 1.30, Flat_loss 0.32, Train_acc 96.67, Test_acc 30.38
2025-02-14 23:20:22,128 [podnet.py] => Task 11, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.31, Train_acc 96.56, Test_acc 30.57
2025-02-14 23:20:23,993 [podnet.py] => Task 11, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.31, Train_acc 97.33, Test_acc 31.68
2025-02-14 23:20:25,907 [podnet.py] => Task 11, Epoch 119/160 (LR 0.01535) => LSC_loss 0.23, Spatial_loss 1.29, Flat_loss 0.31, Train_acc 97.22, Test_acc 29.85
2025-02-14 23:20:27,804 [podnet.py] => Task 11, Epoch 120/160 (LR 0.01464) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.31, Train_acc 97.03, Test_acc 28.57
2025-02-14 23:20:29,546 [podnet.py] => Task 11, Epoch 121/160 (LR 0.01396) => LSC_loss 0.27, Spatial_loss 1.29, Flat_loss 0.32, Train_acc 96.28, Test_acc 30.75
2025-02-14 23:20:31,370 [podnet.py] => Task 11, Epoch 122/160 (LR 0.01328) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.32, Train_acc 97.06, Test_acc 30.75
2025-02-14 23:20:33,286 [podnet.py] => Task 11, Epoch 123/160 (LR 0.01262) => LSC_loss 0.24, Spatial_loss 1.28, Flat_loss 0.31, Train_acc 97.44, Test_acc 30.80
2025-02-14 23:20:35,113 [podnet.py] => Task 11, Epoch 124/160 (LR 0.01198) => LSC_loss 0.23, Spatial_loss 1.26, Flat_loss 0.31, Train_acc 96.75, Test_acc 29.55
2025-02-14 23:20:37,037 [podnet.py] => Task 11, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.30, Train_acc 97.58, Test_acc 29.28
2025-02-14 23:20:38,810 [podnet.py] => Task 11, Epoch 126/160 (LR 0.01073) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.30, Train_acc 97.97, Test_acc 29.73
2025-02-14 23:20:40,645 [podnet.py] => Task 11, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.30, Train_acc 97.75, Test_acc 30.70
2025-02-14 23:20:42,507 [podnet.py] => Task 11, Epoch 128/160 (LR 0.00955) => LSC_loss 0.21, Spatial_loss 1.19, Flat_loss 0.30, Train_acc 97.69, Test_acc 30.80
2025-02-14 23:20:44,394 [podnet.py] => Task 11, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.30, Train_acc 97.61, Test_acc 31.60
2025-02-14 23:20:46,214 [podnet.py] => Task 11, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.30, Train_acc 97.67, Test_acc 30.48
2025-02-14 23:20:48,102 [podnet.py] => Task 11, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.29, Train_acc 98.00, Test_acc 30.65
2025-02-14 23:20:49,938 [podnet.py] => Task 11, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.30, Train_acc 97.94, Test_acc 30.45
2025-02-14 23:20:51,818 [podnet.py] => Task 11, Epoch 133/160 (LR 0.00686) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.29, Train_acc 98.22, Test_acc 30.85
2025-02-14 23:20:53,634 [podnet.py] => Task 11, Epoch 134/160 (LR 0.00638) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.29, Train_acc 98.17, Test_acc 31.22
2025-02-14 23:20:55,478 [podnet.py] => Task 11, Epoch 135/160 (LR 0.00590) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.29, Train_acc 98.39, Test_acc 31.37
2025-02-14 23:20:57,344 [podnet.py] => Task 11, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.10, Flat_loss 0.29, Train_acc 98.36, Test_acc 29.98
2025-02-14 23:20:59,220 [podnet.py] => Task 11, Epoch 137/160 (LR 0.00501) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.29, Train_acc 98.36, Test_acc 31.45
2025-02-14 23:21:01,124 [podnet.py] => Task 11, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.29, Train_acc 98.39, Test_acc 31.28
2025-02-14 23:21:03,015 [podnet.py] => Task 11, Epoch 139/160 (LR 0.00419) => LSC_loss 0.19, Spatial_loss 1.12, Flat_loss 0.29, Train_acc 98.64, Test_acc 31.17
2025-02-14 23:21:04,824 [podnet.py] => Task 11, Epoch 140/160 (LR 0.00381) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.29, Train_acc 98.36, Test_acc 31.47
2025-02-14 23:21:06,686 [podnet.py] => Task 11, Epoch 141/160 (LR 0.00344) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.29, Train_acc 98.61, Test_acc 31.38
2025-02-14 23:21:08,589 [podnet.py] => Task 11, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.29, Train_acc 98.61, Test_acc 31.72
2025-02-14 23:21:10,441 [podnet.py] => Task 11, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.29, Train_acc 98.31, Test_acc 31.02
2025-02-14 23:21:12,242 [podnet.py] => Task 11, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.29, Train_acc 98.50, Test_acc 31.10
2025-02-14 23:21:14,145 [podnet.py] => Task 11, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.29, Train_acc 98.31, Test_acc 31.02
2025-02-14 23:21:16,030 [podnet.py] => Task 11, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.29, Train_acc 98.56, Test_acc 30.73
2025-02-14 23:21:17,875 [podnet.py] => Task 11, Epoch 147/160 (LR 0.00162) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.28, Train_acc 98.53, Test_acc 31.17
2025-02-14 23:21:19,746 [podnet.py] => Task 11, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.28, Train_acc 98.53, Test_acc 31.22
2025-02-14 23:21:21,600 [podnet.py] => Task 11, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.28, Train_acc 98.33, Test_acc 30.88
2025-02-14 23:21:23,549 [podnet.py] => Task 11, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.28, Train_acc 98.83, Test_acc 30.97
2025-02-14 23:21:25,434 [podnet.py] => Task 11, Epoch 151/160 (LR 0.00078) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.28, Train_acc 98.28, Test_acc 31.08
2025-02-14 23:21:27,306 [podnet.py] => Task 11, Epoch 152/160 (LR 0.00062) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.28, Train_acc 98.56, Test_acc 31.13
2025-02-14 23:21:29,137 [podnet.py] => Task 11, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.29, Train_acc 98.50, Test_acc 31.25
2025-02-14 23:21:30,961 [podnet.py] => Task 11, Epoch 154/160 (LR 0.00035) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.28, Train_acc 98.92, Test_acc 31.02
2025-02-14 23:21:32,860 [podnet.py] => Task 11, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.28, Train_acc 98.08, Test_acc 30.82
2025-02-14 23:21:34,695 [podnet.py] => Task 11, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.28, Train_acc 98.58, Test_acc 31.33
2025-02-14 23:21:36,550 [podnet.py] => Task 11, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.28, Train_acc 98.53, Test_acc 31.08
2025-02-14 23:21:38,478 [podnet.py] => Task 11, Epoch 158/160 (LR 0.00004) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.29, Train_acc 98.64, Test_acc 31.42
2025-02-14 23:21:40,368 [podnet.py] => Task 11, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.28, Train_acc 98.44, Test_acc 31.00
2025-02-14 23:21:42,250 [podnet.py] => Task 11, Epoch 160/160 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.28, Train_acc 98.44, Test_acc 31.38
2025-02-14 23:21:42,250 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:21:42,251 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:22:04,441 [podnet.py] => The size of finetune dataset: 1200
2025-02-14 23:22:05,758 [podnet.py] => Task 11, Epoch 1/20 (LR 0.00497) => LSC_loss 0.41, Spatial_loss 1.64, Flat_loss 0.24, Train_acc 89.83, Test_acc 31.35
2025-02-14 23:22:07,034 [podnet.py] => Task 11, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 1.37, Flat_loss 0.16, Train_acc 99.00, Test_acc 33.33
2025-02-14 23:22:08,378 [podnet.py] => Task 11, Epoch 3/20 (LR 0.00473) => LSC_loss 0.14, Spatial_loss 1.28, Flat_loss 0.14, Train_acc 99.17, Test_acc 33.28
2025-02-14 23:22:09,693 [podnet.py] => Task 11, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 1.17, Flat_loss 0.13, Train_acc 99.33, Test_acc 32.95
2025-02-14 23:22:11,013 [podnet.py] => Task 11, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 1.26, Flat_loss 0.13, Train_acc 99.33, Test_acc 32.23
2025-02-14 23:22:12,321 [podnet.py] => Task 11, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.18, Flat_loss 0.12, Train_acc 99.42, Test_acc 31.73
2025-02-14 23:22:13,594 [podnet.py] => Task 11, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 1.22, Flat_loss 0.12, Train_acc 99.33, Test_acc 31.97
2025-02-14 23:22:14,862 [podnet.py] => Task 11, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.14, Flat_loss 0.12, Train_acc 99.25, Test_acc 32.10
2025-02-14 23:22:16,167 [podnet.py] => Task 11, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 1.12, Flat_loss 0.12, Train_acc 98.92, Test_acc 32.57
2025-02-14 23:22:17,432 [podnet.py] => Task 11, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 1.17, Flat_loss 0.12, Train_acc 99.25, Test_acc 32.00
2025-02-14 23:22:18,744 [podnet.py] => Task 11, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 1.08, Flat_loss 0.11, Train_acc 99.50, Test_acc 32.58
2025-02-14 23:22:20,060 [podnet.py] => Task 11, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 1.11, Flat_loss 0.12, Train_acc 99.25, Test_acc 32.68
2025-02-14 23:22:21,342 [podnet.py] => Task 11, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.13, Flat_loss 0.12, Train_acc 99.67, Test_acc 32.33
2025-02-14 23:22:22,700 [podnet.py] => Task 11, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 1.16, Flat_loss 0.12, Train_acc 99.50, Test_acc 32.22
2025-02-14 23:22:24,046 [podnet.py] => Task 11, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 1.17, Flat_loss 0.12, Train_acc 99.50, Test_acc 32.32
2025-02-14 23:22:25,376 [podnet.py] => Task 11, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 1.08, Flat_loss 0.12, Train_acc 99.33, Test_acc 32.43
2025-02-14 23:22:26,704 [podnet.py] => Task 11, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.09, Flat_loss 0.12, Train_acc 99.67, Test_acc 32.28
2025-02-14 23:22:28,048 [podnet.py] => Task 11, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 1.09, Flat_loss 0.12, Train_acc 99.67, Test_acc 32.42
2025-02-14 23:22:29,363 [podnet.py] => Task 11, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 1.10, Flat_loss 0.11, Train_acc 99.42, Test_acc 32.37
2025-02-14 23:22:30,654 [podnet.py] => Task 11, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 1.06, Flat_loss 0.12, Train_acc 99.25, Test_acc 32.42
2025-02-14 23:22:30,656 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:22:53,850 [podnet.py] => Exemplar size: 1200
2025-02-14 23:22:53,851 [trainer.py] => CNN: {'total': 32.42, '00-09': 36.9, '10-19': 10.5, '20-29': 21.4, '30-39': 21.3, '40-49': 48.0, '50-59': 56.4, 'old': 30.55, 'new': 53.0}
2025-02-14 23:22:53,851 [trainer.py] => NME: {'total': 32.35, '00-09': 43.1, '10-19': 10.5, '20-29': 21.1, '30-39': 22.5, '40-49': 43.4, '50-59': 53.5, 'old': 30.35, 'new': 54.4}
2025-02-14 23:22:53,851 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42]
2025-02-14 23:22:53,851 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92]
2025-02-14 23:22:53,851 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35]
2025-02-14 23:22:53,851 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03]

2025-02-14 23:22:53,851 [trainer.py] => Average Accuracy (CNN): 49.61166666666667
2025-02-14 23:22:53,851 [trainer.py] => Average Accuracy (NME): 48.872499999999995
2025-02-14 23:22:53,851 [trainer.py] => All params: 504657
2025-02-14 23:22:53,852 [trainer.py] => Trainable params: 504657
2025-02-14 23:22:53,852 [podnet.py] => Learning on 60-65
2025-02-14 23:22:53,879 [podnet.py] => Adaptive factor: 3.605551275463989
2025-02-14 23:22:55,814 [podnet.py] => Task 12, Epoch 1/160 (LR 0.09999) => LSC_loss 3.27, Spatial_loss 3.11, Flat_loss 1.24, Train_acc 43.78, Test_acc 16.25
2025-02-14 23:22:57,673 [podnet.py] => Task 12, Epoch 2/160 (LR 0.09996) => LSC_loss 1.49, Spatial_loss 2.65, Flat_loss 0.65, Train_acc 60.97, Test_acc 21.60
2025-02-14 23:22:59,598 [podnet.py] => Task 12, Epoch 3/160 (LR 0.09991) => LSC_loss 1.22, Spatial_loss 2.48, Flat_loss 0.51, Train_acc 67.62, Test_acc 25.17
2025-02-14 23:23:01,536 [podnet.py] => Task 12, Epoch 4/160 (LR 0.09985) => LSC_loss 1.10, Spatial_loss 2.28, Flat_loss 0.45, Train_acc 70.89, Test_acc 21.62
2025-02-14 23:23:03,424 [podnet.py] => Task 12, Epoch 5/160 (LR 0.09976) => LSC_loss 1.07, Spatial_loss 2.37, Flat_loss 0.43, Train_acc 71.54, Test_acc 21.00
2025-02-14 23:23:05,292 [podnet.py] => Task 12, Epoch 6/160 (LR 0.09965) => LSC_loss 0.99, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 74.65, Test_acc 25.06
2025-02-14 23:23:07,194 [podnet.py] => Task 12, Epoch 7/160 (LR 0.09953) => LSC_loss 0.94, Spatial_loss 2.22, Flat_loss 0.41, Train_acc 76.03, Test_acc 24.31
2025-02-14 23:23:09,064 [podnet.py] => Task 12, Epoch 8/160 (LR 0.09938) => LSC_loss 0.91, Spatial_loss 2.17, Flat_loss 0.39, Train_acc 76.49, Test_acc 23.60
2025-02-14 23:23:10,945 [podnet.py] => Task 12, Epoch 9/160 (LR 0.09922) => LSC_loss 0.92, Spatial_loss 2.29, Flat_loss 0.40, Train_acc 76.54, Test_acc 27.51
2025-02-14 23:23:12,813 [podnet.py] => Task 12, Epoch 10/160 (LR 0.09904) => LSC_loss 0.87, Spatial_loss 2.21, Flat_loss 0.39, Train_acc 77.59, Test_acc 24.94
2025-02-14 23:23:14,716 [podnet.py] => Task 12, Epoch 11/160 (LR 0.09884) => LSC_loss 0.83, Spatial_loss 2.21, Flat_loss 0.38, Train_acc 79.22, Test_acc 23.26
2025-02-14 23:23:16,595 [podnet.py] => Task 12, Epoch 12/160 (LR 0.09862) => LSC_loss 0.82, Spatial_loss 2.25, Flat_loss 0.38, Train_acc 79.16, Test_acc 22.66
2025-02-14 23:23:18,489 [podnet.py] => Task 12, Epoch 13/160 (LR 0.09838) => LSC_loss 0.84, Spatial_loss 2.24, Flat_loss 0.39, Train_acc 78.62, Test_acc 23.31
2025-02-14 23:23:20,392 [podnet.py] => Task 12, Epoch 14/160 (LR 0.09812) => LSC_loss 0.73, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 82.30, Test_acc 27.17
2025-02-14 23:23:22,280 [podnet.py] => Task 12, Epoch 15/160 (LR 0.09785) => LSC_loss 0.72, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 82.35, Test_acc 27.28
2025-02-14 23:23:24,217 [podnet.py] => Task 12, Epoch 16/160 (LR 0.09755) => LSC_loss 0.73, Spatial_loss 2.12, Flat_loss 0.38, Train_acc 81.92, Test_acc 26.26
2025-02-14 23:23:26,095 [podnet.py] => Task 12, Epoch 17/160 (LR 0.09724) => LSC_loss 0.70, Spatial_loss 2.02, Flat_loss 0.37, Train_acc 83.05, Test_acc 26.09
2025-02-14 23:23:27,981 [podnet.py] => Task 12, Epoch 18/160 (LR 0.09691) => LSC_loss 0.71, Spatial_loss 2.12, Flat_loss 0.38, Train_acc 83.03, Test_acc 22.57
2025-02-14 23:23:29,835 [podnet.py] => Task 12, Epoch 19/160 (LR 0.09656) => LSC_loss 0.68, Spatial_loss 1.96, Flat_loss 0.37, Train_acc 83.35, Test_acc 29.15
2025-02-14 23:23:31,704 [podnet.py] => Task 12, Epoch 20/160 (LR 0.09619) => LSC_loss 0.65, Spatial_loss 2.01, Flat_loss 0.36, Train_acc 84.16, Test_acc 24.40
2025-02-14 23:23:33,617 [podnet.py] => Task 12, Epoch 21/160 (LR 0.09581) => LSC_loss 0.64, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 84.41, Test_acc 27.31
2025-02-14 23:23:35,528 [podnet.py] => Task 12, Epoch 22/160 (LR 0.09541) => LSC_loss 0.60, Spatial_loss 2.07, Flat_loss 0.37, Train_acc 85.35, Test_acc 24.17
2025-02-14 23:23:37,444 [podnet.py] => Task 12, Epoch 23/160 (LR 0.09499) => LSC_loss 0.63, Spatial_loss 1.98, Flat_loss 0.37, Train_acc 84.84, Test_acc 25.69
2025-02-14 23:23:39,286 [podnet.py] => Task 12, Epoch 24/160 (LR 0.09455) => LSC_loss 0.61, Spatial_loss 1.99, Flat_loss 0.37, Train_acc 85.27, Test_acc 23.35
2025-02-14 23:23:41,222 [podnet.py] => Task 12, Epoch 25/160 (LR 0.09410) => LSC_loss 0.63, Spatial_loss 2.08, Flat_loss 0.37, Train_acc 84.92, Test_acc 28.48
2025-02-14 23:23:43,166 [podnet.py] => Task 12, Epoch 26/160 (LR 0.09362) => LSC_loss 0.62, Spatial_loss 2.10, Flat_loss 0.38, Train_acc 84.57, Test_acc 24.40
2025-02-14 23:23:45,011 [podnet.py] => Task 12, Epoch 27/160 (LR 0.09314) => LSC_loss 0.58, Spatial_loss 2.05, Flat_loss 0.37, Train_acc 86.59, Test_acc 26.52
2025-02-14 23:23:46,937 [podnet.py] => Task 12, Epoch 28/160 (LR 0.09263) => LSC_loss 0.59, Spatial_loss 2.03, Flat_loss 0.37, Train_acc 85.62, Test_acc 23.22
2025-02-14 23:23:48,838 [podnet.py] => Task 12, Epoch 29/160 (LR 0.09211) => LSC_loss 0.57, Spatial_loss 2.01, Flat_loss 0.36, Train_acc 86.00, Test_acc 24.31
2025-02-14 23:23:50,780 [podnet.py] => Task 12, Epoch 30/160 (LR 0.09157) => LSC_loss 0.58, Spatial_loss 2.00, Flat_loss 0.37, Train_acc 86.65, Test_acc 25.71
2025-02-14 23:23:52,683 [podnet.py] => Task 12, Epoch 31/160 (LR 0.09102) => LSC_loss 0.59, Spatial_loss 2.04, Flat_loss 0.37, Train_acc 86.22, Test_acc 25.37
2025-02-14 23:23:54,576 [podnet.py] => Task 12, Epoch 32/160 (LR 0.09045) => LSC_loss 0.54, Spatial_loss 1.93, Flat_loss 0.36, Train_acc 87.86, Test_acc 25.51
2025-02-14 23:23:56,479 [podnet.py] => Task 12, Epoch 33/160 (LR 0.08987) => LSC_loss 0.52, Spatial_loss 1.98, Flat_loss 0.36, Train_acc 87.86, Test_acc 28.85
2025-02-14 23:23:58,383 [podnet.py] => Task 12, Epoch 34/160 (LR 0.08927) => LSC_loss 0.56, Spatial_loss 1.99, Flat_loss 0.38, Train_acc 86.57, Test_acc 25.65
2025-02-14 23:24:00,260 [podnet.py] => Task 12, Epoch 35/160 (LR 0.08865) => LSC_loss 0.49, Spatial_loss 1.99, Flat_loss 0.36, Train_acc 88.97, Test_acc 29.66
2025-02-14 23:24:02,149 [podnet.py] => Task 12, Epoch 36/160 (LR 0.08802) => LSC_loss 0.51, Spatial_loss 1.92, Flat_loss 0.36, Train_acc 88.30, Test_acc 26.46
2025-02-14 23:24:04,116 [podnet.py] => Task 12, Epoch 37/160 (LR 0.08738) => LSC_loss 0.52, Spatial_loss 1.98, Flat_loss 0.36, Train_acc 88.41, Test_acc 22.95
2025-02-14 23:24:06,074 [podnet.py] => Task 12, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 1.86, Flat_loss 0.36, Train_acc 88.11, Test_acc 28.31
2025-02-14 23:24:08,026 [podnet.py] => Task 12, Epoch 39/160 (LR 0.08604) => LSC_loss 0.49, Spatial_loss 1.95, Flat_loss 0.36, Train_acc 88.32, Test_acc 24.72
2025-02-14 23:24:09,895 [podnet.py] => Task 12, Epoch 40/160 (LR 0.08536) => LSC_loss 0.47, Spatial_loss 1.91, Flat_loss 0.35, Train_acc 89.86, Test_acc 26.22
2025-02-14 23:24:11,789 [podnet.py] => Task 12, Epoch 41/160 (LR 0.08465) => LSC_loss 0.48, Spatial_loss 1.91, Flat_loss 0.36, Train_acc 88.65, Test_acc 26.46
2025-02-14 23:24:13,674 [podnet.py] => Task 12, Epoch 42/160 (LR 0.08394) => LSC_loss 0.51, Spatial_loss 1.97, Flat_loss 0.36, Train_acc 87.76, Test_acc 23.17
2025-02-14 23:24:15,594 [podnet.py] => Task 12, Epoch 43/160 (LR 0.08321) => LSC_loss 0.49, Spatial_loss 2.04, Flat_loss 0.37, Train_acc 88.78, Test_acc 25.89
2025-02-14 23:24:17,452 [podnet.py] => Task 12, Epoch 44/160 (LR 0.08247) => LSC_loss 0.48, Spatial_loss 2.00, Flat_loss 0.37, Train_acc 89.35, Test_acc 22.11
2025-02-14 23:24:19,350 [podnet.py] => Task 12, Epoch 45/160 (LR 0.08172) => LSC_loss 0.49, Spatial_loss 1.95, Flat_loss 0.36, Train_acc 88.78, Test_acc 20.75
2025-02-14 23:24:21,244 [podnet.py] => Task 12, Epoch 46/160 (LR 0.08095) => LSC_loss 0.46, Spatial_loss 1.92, Flat_loss 0.36, Train_acc 90.11, Test_acc 26.51
2025-02-14 23:24:23,170 [podnet.py] => Task 12, Epoch 47/160 (LR 0.08018) => LSC_loss 0.46, Spatial_loss 1.82, Flat_loss 0.35, Train_acc 89.16, Test_acc 26.97
2025-02-14 23:24:25,048 [podnet.py] => Task 12, Epoch 48/160 (LR 0.07939) => LSC_loss 0.45, Spatial_loss 1.86, Flat_loss 0.35, Train_acc 89.84, Test_acc 23.58
2025-02-14 23:24:26,900 [podnet.py] => Task 12, Epoch 49/160 (LR 0.07859) => LSC_loss 0.42, Spatial_loss 1.82, Flat_loss 0.35, Train_acc 91.03, Test_acc 27.29
2025-02-14 23:24:28,761 [podnet.py] => Task 12, Epoch 50/160 (LR 0.07778) => LSC_loss 0.40, Spatial_loss 1.81, Flat_loss 0.35, Train_acc 91.41, Test_acc 29.48
2025-02-14 23:24:30,689 [podnet.py] => Task 12, Epoch 51/160 (LR 0.07696) => LSC_loss 0.41, Spatial_loss 1.85, Flat_loss 0.34, Train_acc 91.08, Test_acc 25.34
2025-02-14 23:24:32,545 [podnet.py] => Task 12, Epoch 52/160 (LR 0.07612) => LSC_loss 0.41, Spatial_loss 1.81, Flat_loss 0.35, Train_acc 91.14, Test_acc 22.00
2025-02-14 23:24:34,431 [podnet.py] => Task 12, Epoch 53/160 (LR 0.07528) => LSC_loss 0.41, Spatial_loss 1.80, Flat_loss 0.35, Train_acc 91.14, Test_acc 26.26
2025-02-14 23:24:36,331 [podnet.py] => Task 12, Epoch 54/160 (LR 0.07443) => LSC_loss 0.41, Spatial_loss 1.83, Flat_loss 0.34, Train_acc 91.14, Test_acc 27.86
2025-02-14 23:24:38,248 [podnet.py] => Task 12, Epoch 55/160 (LR 0.07357) => LSC_loss 0.40, Spatial_loss 1.91, Flat_loss 0.35, Train_acc 91.70, Test_acc 26.78
2025-02-14 23:24:40,132 [podnet.py] => Task 12, Epoch 56/160 (LR 0.07270) => LSC_loss 0.42, Spatial_loss 1.83, Flat_loss 0.35, Train_acc 90.65, Test_acc 24.46
2025-02-14 23:24:42,055 [podnet.py] => Task 12, Epoch 57/160 (LR 0.07182) => LSC_loss 0.42, Spatial_loss 1.81, Flat_loss 0.36, Train_acc 90.89, Test_acc 25.78
2025-02-14 23:24:43,953 [podnet.py] => Task 12, Epoch 58/160 (LR 0.07093) => LSC_loss 0.39, Spatial_loss 1.76, Flat_loss 0.34, Train_acc 91.57, Test_acc 23.80
2025-02-14 23:24:45,889 [podnet.py] => Task 12, Epoch 59/160 (LR 0.07004) => LSC_loss 0.39, Spatial_loss 1.91, Flat_loss 0.35, Train_acc 92.08, Test_acc 25.77
2025-02-14 23:24:47,779 [podnet.py] => Task 12, Epoch 60/160 (LR 0.06913) => LSC_loss 0.39, Spatial_loss 1.80, Flat_loss 0.34, Train_acc 91.89, Test_acc 27.66
2025-02-14 23:24:49,737 [podnet.py] => Task 12, Epoch 61/160 (LR 0.06822) => LSC_loss 0.34, Spatial_loss 1.74, Flat_loss 0.32, Train_acc 93.51, Test_acc 23.71
2025-02-14 23:24:51,637 [podnet.py] => Task 12, Epoch 62/160 (LR 0.06731) => LSC_loss 0.34, Spatial_loss 1.69, Flat_loss 0.33, Train_acc 93.51, Test_acc 25.58
2025-02-14 23:24:53,576 [podnet.py] => Task 12, Epoch 63/160 (LR 0.06638) => LSC_loss 0.37, Spatial_loss 1.79, Flat_loss 0.34, Train_acc 92.19, Test_acc 26.05
2025-02-14 23:24:55,426 [podnet.py] => Task 12, Epoch 64/160 (LR 0.06545) => LSC_loss 0.38, Spatial_loss 1.80, Flat_loss 0.34, Train_acc 91.73, Test_acc 29.38
2025-02-14 23:24:57,330 [podnet.py] => Task 12, Epoch 65/160 (LR 0.06451) => LSC_loss 0.34, Spatial_loss 1.74, Flat_loss 0.33, Train_acc 93.41, Test_acc 28.11
2025-02-14 23:24:59,303 [podnet.py] => Task 12, Epoch 66/160 (LR 0.06357) => LSC_loss 0.32, Spatial_loss 1.71, Flat_loss 0.32, Train_acc 94.05, Test_acc 27.65
2025-02-14 23:25:01,125 [podnet.py] => Task 12, Epoch 67/160 (LR 0.06262) => LSC_loss 0.33, Spatial_loss 1.63, Flat_loss 0.32, Train_acc 93.57, Test_acc 23.62
2025-02-14 23:25:03,092 [podnet.py] => Task 12, Epoch 68/160 (LR 0.06167) => LSC_loss 0.31, Spatial_loss 1.67, Flat_loss 0.32, Train_acc 94.32, Test_acc 30.60
2025-02-14 23:25:04,954 [podnet.py] => Task 12, Epoch 69/160 (LR 0.06072) => LSC_loss 0.31, Spatial_loss 1.70, Flat_loss 0.32, Train_acc 94.14, Test_acc 25.98
2025-02-14 23:25:06,853 [podnet.py] => Task 12, Epoch 70/160 (LR 0.05975) => LSC_loss 0.31, Spatial_loss 1.61, Flat_loss 0.32, Train_acc 94.70, Test_acc 28.46
2025-02-14 23:25:08,729 [podnet.py] => Task 12, Epoch 71/160 (LR 0.05879) => LSC_loss 0.31, Spatial_loss 1.59, Flat_loss 0.31, Train_acc 94.68, Test_acc 25.03
2025-02-14 23:25:10,649 [podnet.py] => Task 12, Epoch 72/160 (LR 0.05782) => LSC_loss 0.30, Spatial_loss 1.67, Flat_loss 0.32, Train_acc 94.38, Test_acc 26.58
2025-02-14 23:25:12,506 [podnet.py] => Task 12, Epoch 73/160 (LR 0.05685) => LSC_loss 0.31, Spatial_loss 1.58, Flat_loss 0.31, Train_acc 94.73, Test_acc 26.77
2025-02-14 23:25:14,441 [podnet.py] => Task 12, Epoch 74/160 (LR 0.05588) => LSC_loss 0.31, Spatial_loss 1.65, Flat_loss 0.32, Train_acc 94.03, Test_acc 26.22
2025-02-14 23:25:16,342 [podnet.py] => Task 12, Epoch 75/160 (LR 0.05490) => LSC_loss 0.30, Spatial_loss 1.62, Flat_loss 0.31, Train_acc 94.76, Test_acc 29.58
2025-02-14 23:25:18,203 [podnet.py] => Task 12, Epoch 76/160 (LR 0.05392) => LSC_loss 0.29, Spatial_loss 1.69, Flat_loss 0.31, Train_acc 95.14, Test_acc 28.17
2025-02-14 23:25:20,050 [podnet.py] => Task 12, Epoch 77/160 (LR 0.05294) => LSC_loss 0.29, Spatial_loss 1.61, Flat_loss 0.32, Train_acc 95.03, Test_acc 28.63
2025-02-14 23:25:21,974 [podnet.py] => Task 12, Epoch 78/160 (LR 0.05196) => LSC_loss 0.28, Spatial_loss 1.55, Flat_loss 0.30, Train_acc 95.43, Test_acc 28.52
2025-02-14 23:25:23,885 [podnet.py] => Task 12, Epoch 79/160 (LR 0.05098) => LSC_loss 0.26, Spatial_loss 1.51, Flat_loss 0.30, Train_acc 95.97, Test_acc 28.11
2025-02-14 23:25:25,744 [podnet.py] => Task 12, Epoch 80/160 (LR 0.05000) => LSC_loss 0.27, Spatial_loss 1.61, Flat_loss 0.31, Train_acc 95.57, Test_acc 26.66
2025-02-14 23:25:27,706 [podnet.py] => Task 12, Epoch 81/160 (LR 0.04902) => LSC_loss 0.28, Spatial_loss 1.54, Flat_loss 0.30, Train_acc 95.00, Test_acc 28.88
2025-02-14 23:25:29,595 [podnet.py] => Task 12, Epoch 82/160 (LR 0.04804) => LSC_loss 0.28, Spatial_loss 1.56, Flat_loss 0.30, Train_acc 95.05, Test_acc 26.37
2025-02-14 23:25:31,491 [podnet.py] => Task 12, Epoch 83/160 (LR 0.04706) => LSC_loss 0.27, Spatial_loss 1.55, Flat_loss 0.30, Train_acc 95.81, Test_acc 28.32
2025-02-14 23:25:33,407 [podnet.py] => Task 12, Epoch 84/160 (LR 0.04608) => LSC_loss 0.25, Spatial_loss 1.59, Flat_loss 0.30, Train_acc 95.92, Test_acc 25.52
2025-02-14 23:25:35,300 [podnet.py] => Task 12, Epoch 85/160 (LR 0.04510) => LSC_loss 0.26, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 95.92, Test_acc 25.85
2025-02-14 23:25:37,161 [podnet.py] => Task 12, Epoch 86/160 (LR 0.04412) => LSC_loss 0.24, Spatial_loss 1.49, Flat_loss 0.30, Train_acc 96.05, Test_acc 27.20
2025-02-14 23:25:38,997 [podnet.py] => Task 12, Epoch 87/160 (LR 0.04315) => LSC_loss 0.26, Spatial_loss 1.44, Flat_loss 0.30, Train_acc 95.57, Test_acc 25.78
2025-02-14 23:25:40,901 [podnet.py] => Task 12, Epoch 88/160 (LR 0.04218) => LSC_loss 0.24, Spatial_loss 1.51, Flat_loss 0.30, Train_acc 96.16, Test_acc 28.98
2025-02-14 23:25:42,831 [podnet.py] => Task 12, Epoch 89/160 (LR 0.04121) => LSC_loss 0.25, Spatial_loss 1.43, Flat_loss 0.30, Train_acc 96.14, Test_acc 28.28
2025-02-14 23:25:44,716 [podnet.py] => Task 12, Epoch 90/160 (LR 0.04025) => LSC_loss 0.25, Spatial_loss 1.45, Flat_loss 0.30, Train_acc 96.46, Test_acc 28.45
2025-02-14 23:25:46,565 [podnet.py] => Task 12, Epoch 91/160 (LR 0.03928) => LSC_loss 0.24, Spatial_loss 1.48, Flat_loss 0.30, Train_acc 96.03, Test_acc 27.54
2025-02-14 23:25:48,437 [podnet.py] => Task 12, Epoch 92/160 (LR 0.03833) => LSC_loss 0.25, Spatial_loss 1.44, Flat_loss 0.29, Train_acc 95.95, Test_acc 24.34
2025-02-14 23:25:50,322 [podnet.py] => Task 12, Epoch 93/160 (LR 0.03738) => LSC_loss 0.24, Spatial_loss 1.45, Flat_loss 0.29, Train_acc 96.51, Test_acc 29.72
2025-02-14 23:25:52,225 [podnet.py] => Task 12, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 1.39, Flat_loss 0.28, Train_acc 96.73, Test_acc 25.63
2025-02-14 23:25:54,104 [podnet.py] => Task 12, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 1.41, Flat_loss 0.28, Train_acc 97.08, Test_acc 23.69
2025-02-14 23:25:56,020 [podnet.py] => Task 12, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 1.38, Flat_loss 0.28, Train_acc 97.57, Test_acc 28.42
2025-02-14 23:25:57,959 [podnet.py] => Task 12, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 1.39, Flat_loss 0.28, Train_acc 97.00, Test_acc 27.37
2025-02-14 23:25:59,858 [podnet.py] => Task 12, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 1.40, Flat_loss 0.28, Train_acc 97.16, Test_acc 27.52
2025-02-14 23:26:01,793 [podnet.py] => Task 12, Epoch 99/160 (LR 0.03178) => LSC_loss 0.22, Spatial_loss 1.42, Flat_loss 0.28, Train_acc 97.11, Test_acc 26.51
2025-02-14 23:26:03,726 [podnet.py] => Task 12, Epoch 100/160 (LR 0.03087) => LSC_loss 0.21, Spatial_loss 1.36, Flat_loss 0.28, Train_acc 97.51, Test_acc 30.89
2025-02-14 23:26:05,659 [podnet.py] => Task 12, Epoch 101/160 (LR 0.02996) => LSC_loss 0.20, Spatial_loss 1.37, Flat_loss 0.28, Train_acc 98.03, Test_acc 26.77
2025-02-14 23:26:07,549 [podnet.py] => Task 12, Epoch 102/160 (LR 0.02907) => LSC_loss 0.21, Spatial_loss 1.37, Flat_loss 0.27, Train_acc 97.24, Test_acc 27.80
2025-02-14 23:26:09,505 [podnet.py] => Task 12, Epoch 103/160 (LR 0.02818) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.27, Train_acc 97.95, Test_acc 28.31
2025-02-14 23:26:11,330 [podnet.py] => Task 12, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 1.34, Flat_loss 0.27, Train_acc 97.84, Test_acc 28.85
2025-02-14 23:26:13,236 [podnet.py] => Task 12, Epoch 105/160 (LR 0.02643) => LSC_loss 0.21, Spatial_loss 1.29, Flat_loss 0.27, Train_acc 97.30, Test_acc 29.05
2025-02-14 23:26:15,116 [podnet.py] => Task 12, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 1.29, Flat_loss 0.27, Train_acc 97.97, Test_acc 26.34
2025-02-14 23:26:17,045 [podnet.py] => Task 12, Epoch 107/160 (LR 0.02472) => LSC_loss 0.20, Spatial_loss 1.40, Flat_loss 0.27, Train_acc 97.92, Test_acc 31.02
2025-02-14 23:26:18,977 [podnet.py] => Task 12, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 1.30, Flat_loss 0.27, Train_acc 97.92, Test_acc 26.71
2025-02-14 23:26:20,865 [podnet.py] => Task 12, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 1.31, Flat_loss 0.27, Train_acc 98.14, Test_acc 27.08
2025-02-14 23:26:22,817 [podnet.py] => Task 12, Epoch 110/160 (LR 0.02222) => LSC_loss 0.19, Spatial_loss 1.21, Flat_loss 0.26, Train_acc 97.97, Test_acc 28.14
2025-02-14 23:26:24,730 [podnet.py] => Task 12, Epoch 111/160 (LR 0.02141) => LSC_loss 0.19, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 98.14, Test_acc 28.32
2025-02-14 23:26:26,659 [podnet.py] => Task 12, Epoch 112/160 (LR 0.02061) => LSC_loss 0.18, Spatial_loss 1.24, Flat_loss 0.26, Train_acc 98.32, Test_acc 29.12
2025-02-14 23:26:28,514 [podnet.py] => Task 12, Epoch 113/160 (LR 0.01982) => LSC_loss 0.19, Spatial_loss 1.20, Flat_loss 0.26, Train_acc 98.03, Test_acc 27.77
2025-02-14 23:26:30,407 [podnet.py] => Task 12, Epoch 114/160 (LR 0.01905) => LSC_loss 0.19, Spatial_loss 1.29, Flat_loss 0.26, Train_acc 97.97, Test_acc 29.58
2025-02-14 23:26:32,282 [podnet.py] => Task 12, Epoch 115/160 (LR 0.01828) => LSC_loss 0.19, Spatial_loss 1.26, Flat_loss 0.26, Train_acc 98.32, Test_acc 24.15
2025-02-14 23:26:34,180 [podnet.py] => Task 12, Epoch 116/160 (LR 0.01753) => LSC_loss 0.18, Spatial_loss 1.28, Flat_loss 0.26, Train_acc 98.35, Test_acc 29.20
2025-02-14 23:26:36,026 [podnet.py] => Task 12, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 1.24, Flat_loss 0.26, Train_acc 98.24, Test_acc 28.62
2025-02-14 23:26:37,912 [podnet.py] => Task 12, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 98.62, Test_acc 29.00
2025-02-14 23:26:39,787 [podnet.py] => Task 12, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 98.59, Test_acc 28.97
2025-02-14 23:26:41,635 [podnet.py] => Task 12, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 98.30, Test_acc 29.60
2025-02-14 23:26:43,472 [podnet.py] => Task 12, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.25, Train_acc 98.51, Test_acc 28.78
2025-02-14 23:26:45,375 [podnet.py] => Task 12, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.24, Train_acc 98.46, Test_acc 29.23
2025-02-14 23:26:47,299 [podnet.py] => Task 12, Epoch 123/160 (LR 0.01262) => LSC_loss 0.17, Spatial_loss 1.11, Flat_loss 0.25, Train_acc 98.65, Test_acc 30.32
2025-02-14 23:26:49,157 [podnet.py] => Task 12, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 98.65, Test_acc 29.66
2025-02-14 23:26:51,065 [podnet.py] => Task 12, Epoch 125/160 (LR 0.01135) => LSC_loss 0.16, Spatial_loss 1.16, Flat_loss 0.25, Train_acc 98.76, Test_acc 28.09
2025-02-14 23:26:52,953 [podnet.py] => Task 12, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 1.17, Flat_loss 0.25, Train_acc 98.51, Test_acc 28.68
2025-02-14 23:26:54,890 [podnet.py] => Task 12, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.24, Train_acc 98.54, Test_acc 29.18
2025-02-14 23:26:56,741 [podnet.py] => Task 12, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 1.07, Flat_loss 0.24, Train_acc 98.73, Test_acc 28.95
2025-02-14 23:26:58,590 [podnet.py] => Task 12, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 1.11, Flat_loss 0.24, Train_acc 98.62, Test_acc 28.08
2025-02-14 23:27:00,484 [podnet.py] => Task 12, Epoch 130/160 (LR 0.00843) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.24, Train_acc 98.97, Test_acc 30.09
2025-02-14 23:27:02,337 [podnet.py] => Task 12, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 1.09, Flat_loss 0.24, Train_acc 98.86, Test_acc 28.62
2025-02-14 23:27:04,212 [podnet.py] => Task 12, Epoch 132/160 (LR 0.00737) => LSC_loss 0.17, Spatial_loss 1.11, Flat_loss 0.24, Train_acc 98.89, Test_acc 29.98
2025-02-14 23:27:06,157 [podnet.py] => Task 12, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 1.06, Flat_loss 0.24, Train_acc 98.97, Test_acc 28.71
2025-02-14 23:27:08,089 [podnet.py] => Task 12, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.24, Train_acc 98.81, Test_acc 28.65
2025-02-14 23:27:09,971 [podnet.py] => Task 12, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.24, Train_acc 98.78, Test_acc 29.77
2025-02-14 23:27:11,876 [podnet.py] => Task 12, Epoch 136/160 (LR 0.00545) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.24, Train_acc 99.16, Test_acc 28.55
2025-02-14 23:27:13,739 [podnet.py] => Task 12, Epoch 137/160 (LR 0.00501) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.24, Train_acc 99.22, Test_acc 30.02
2025-02-14 23:27:15,639 [podnet.py] => Task 12, Epoch 138/160 (LR 0.00459) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.24, Train_acc 98.97, Test_acc 29.08
2025-02-14 23:27:17,539 [podnet.py] => Task 12, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 1.04, Flat_loss 0.24, Train_acc 98.97, Test_acc 29.35
2025-02-14 23:27:19,437 [podnet.py] => Task 12, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.24, Train_acc 98.97, Test_acc 28.92
2025-02-14 23:27:21,374 [podnet.py] => Task 12, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.24, Train_acc 99.11, Test_acc 29.12
2025-02-14 23:27:23,270 [podnet.py] => Task 12, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.23, Train_acc 98.73, Test_acc 29.14
2025-02-14 23:27:25,166 [podnet.py] => Task 12, Epoch 143/160 (LR 0.00276) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 99.03, Test_acc 29.34
2025-02-14 23:27:27,070 [podnet.py] => Task 12, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.24, Train_acc 99.08, Test_acc 28.92
2025-02-14 23:27:28,982 [podnet.py] => Task 12, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.23, Train_acc 99.19, Test_acc 29.31
2025-02-14 23:27:30,885 [podnet.py] => Task 12, Epoch 146/160 (LR 0.00188) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.23, Train_acc 98.97, Test_acc 29.78
2025-02-14 23:27:32,801 [podnet.py] => Task 12, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.24, Train_acc 99.30, Test_acc 29.20
2025-02-14 23:27:34,656 [podnet.py] => Task 12, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.23, Train_acc 99.08, Test_acc 29.22
2025-02-14 23:27:36,562 [podnet.py] => Task 12, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.23, Train_acc 99.05, Test_acc 29.69
2025-02-14 23:27:38,439 [podnet.py] => Task 12, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.23, Train_acc 99.03, Test_acc 29.51
2025-02-14 23:27:40,358 [podnet.py] => Task 12, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.23, Train_acc 99.16, Test_acc 29.14
2025-02-14 23:27:42,260 [podnet.py] => Task 12, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.23, Train_acc 98.95, Test_acc 29.72
2025-02-14 23:27:44,130 [podnet.py] => Task 12, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.23, Train_acc 99.27, Test_acc 29.38
2025-02-14 23:27:46,076 [podnet.py] => Task 12, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.23, Train_acc 99.27, Test_acc 29.38
2025-02-14 23:27:47,968 [podnet.py] => Task 12, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.23, Train_acc 99.05, Test_acc 29.57
2025-02-14 23:27:49,850 [podnet.py] => Task 12, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.23, Train_acc 99.24, Test_acc 29.54
2025-02-14 23:27:51,734 [podnet.py] => Task 12, Epoch 157/160 (LR 0.00009) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.23, Train_acc 99.16, Test_acc 29.51
2025-02-14 23:27:53,640 [podnet.py] => Task 12, Epoch 158/160 (LR 0.00004) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.23, Train_acc 99.19, Test_acc 29.66
2025-02-14 23:27:55,586 [podnet.py] => Task 12, Epoch 159/160 (LR 0.00001) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.23, Train_acc 99.08, Test_acc 29.43
2025-02-14 23:27:57,537 [podnet.py] => Task 12, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.23, Train_acc 99.11, Test_acc 29.74
2025-02-14 23:27:57,537 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:27:57,537 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:28:21,149 [podnet.py] => The size of finetune dataset: 1300
2025-02-14 23:28:22,485 [podnet.py] => Task 12, Epoch 1/20 (LR 0.00497) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 92.77, Test_acc 32.49
2025-02-14 23:28:23,880 [podnet.py] => Task 12, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 1.30, Flat_loss 0.14, Train_acc 99.38, Test_acc 33.31
2025-02-14 23:28:25,294 [podnet.py] => Task 12, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 1.30, Flat_loss 0.13, Train_acc 99.23, Test_acc 31.25
2025-02-14 23:28:26,720 [podnet.py] => Task 12, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 1.29, Flat_loss 0.12, Train_acc 99.31, Test_acc 31.05
2025-02-14 23:28:28,032 [podnet.py] => Task 12, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 99.31, Test_acc 31.20
2025-02-14 23:28:29,322 [podnet.py] => Task 12, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 99.31, Test_acc 31.34
2025-02-14 23:28:30,695 [podnet.py] => Task 12, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 1.22, Flat_loss 0.11, Train_acc 99.62, Test_acc 31.23
2025-02-14 23:28:32,102 [podnet.py] => Task 12, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 99.46, Test_acc 31.20
2025-02-14 23:28:33,456 [podnet.py] => Task 12, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.11, Train_acc 99.38, Test_acc 31.92
2025-02-14 23:28:34,794 [podnet.py] => Task 12, Epoch 10/20 (LR 0.00250) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.11, Train_acc 99.38, Test_acc 31.40
2025-02-14 23:28:36,153 [podnet.py] => Task 12, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 1.08, Flat_loss 0.11, Train_acc 99.46, Test_acc 31.51
2025-02-14 23:28:37,528 [podnet.py] => Task 12, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 99.23, Test_acc 31.69
2025-02-14 23:28:38,953 [podnet.py] => Task 12, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.54, Test_acc 31.17
2025-02-14 23:28:40,269 [podnet.py] => Task 12, Epoch 14/20 (LR 0.00103) => LSC_loss 0.13, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 99.38, Test_acc 31.62
2025-02-14 23:28:41,642 [podnet.py] => Task 12, Epoch 15/20 (LR 0.00073) => LSC_loss 0.14, Spatial_loss 1.10, Flat_loss 0.11, Train_acc 99.62, Test_acc 31.62
2025-02-14 23:28:42,970 [podnet.py] => Task 12, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 99.69, Test_acc 31.92
2025-02-14 23:28:44,328 [podnet.py] => Task 12, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.77, Test_acc 31.89
2025-02-14 23:28:45,667 [podnet.py] => Task 12, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.62, Test_acc 31.95
2025-02-14 23:28:46,994 [podnet.py] => Task 12, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 99.85, Test_acc 31.62
2025-02-14 23:28:48,407 [podnet.py] => Task 12, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 99.69, Test_acc 31.49
2025-02-14 23:28:48,410 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:29:13,977 [podnet.py] => Exemplar size: 1300
2025-02-14 23:29:13,978 [trainer.py] => CNN: {'total': 31.49, '00-09': 36.5, '10-19': 10.0, '20-29': 21.1, '30-39': 21.1, '40-49': 42.4, '50-59': 39.1, '60-69': 69.0, 'old': 28.37, 'new': 69.0}
2025-02-14 23:29:13,978 [trainer.py] => NME: {'total': 31.65, '00-09': 42.8, '10-19': 10.0, '20-29': 19.0, '30-39': 21.7, '40-49': 40.5, '50-59': 39.6, '60-69': 64.2, 'old': 28.93, 'new': 64.2}
2025-02-14 23:29:13,978 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49]
2025-02-14 23:29:13,978 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06]
2025-02-14 23:29:13,978 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65]
2025-02-14 23:29:13,978 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88]

2025-02-14 23:29:13,978 [trainer.py] => Average Accuracy (CNN): 48.21769230769231
2025-02-14 23:29:13,978 [trainer.py] => Average Accuracy (NME): 47.5476923076923
2025-02-14 23:29:13,978 [trainer.py] => All params: 507857
2025-02-14 23:29:13,979 [trainer.py] => Trainable params: 507857
2025-02-14 23:29:13,979 [podnet.py] => Learning on 65-70
2025-02-14 23:29:14,009 [podnet.py] => Adaptive factor: 3.7416573867739413
2025-02-14 23:29:15,923 [podnet.py] => Task 13, Epoch 1/160 (LR 0.09999) => LSC_loss 3.05, Spatial_loss 3.30, Flat_loss 1.36, Train_acc 48.24, Test_acc 18.09
2025-02-14 23:29:17,893 [podnet.py] => Task 13, Epoch 2/160 (LR 0.09996) => LSC_loss 1.51, Spatial_loss 2.78, Flat_loss 0.71, Train_acc 62.42, Test_acc 23.01
2025-02-14 23:29:19,866 [podnet.py] => Task 13, Epoch 3/160 (LR 0.09991) => LSC_loss 1.24, Spatial_loss 2.58, Flat_loss 0.56, Train_acc 67.97, Test_acc 21.51
2025-02-14 23:29:21,722 [podnet.py] => Task 13, Epoch 4/160 (LR 0.09985) => LSC_loss 1.14, Spatial_loss 2.54, Flat_loss 0.50, Train_acc 70.68, Test_acc 19.31
2025-02-14 23:29:23,672 [podnet.py] => Task 13, Epoch 5/160 (LR 0.09976) => LSC_loss 1.10, Spatial_loss 2.55, Flat_loss 0.48, Train_acc 71.55, Test_acc 23.43
2025-02-14 23:29:25,565 [podnet.py] => Task 13, Epoch 6/160 (LR 0.09965) => LSC_loss 1.01, Spatial_loss 2.47, Flat_loss 0.45, Train_acc 74.53, Test_acc 22.90
2025-02-14 23:29:27,538 [podnet.py] => Task 13, Epoch 7/160 (LR 0.09953) => LSC_loss 0.96, Spatial_loss 2.42, Flat_loss 0.44, Train_acc 75.74, Test_acc 19.01
2025-02-14 23:29:29,513 [podnet.py] => Task 13, Epoch 8/160 (LR 0.09938) => LSC_loss 0.99, Spatial_loss 2.48, Flat_loss 0.45, Train_acc 74.47, Test_acc 20.87
2025-02-14 23:29:31,534 [podnet.py] => Task 13, Epoch 9/160 (LR 0.09922) => LSC_loss 0.94, Spatial_loss 2.42, Flat_loss 0.44, Train_acc 76.05, Test_acc 23.73
2025-02-14 23:29:33,510 [podnet.py] => Task 13, Epoch 10/160 (LR 0.09904) => LSC_loss 0.84, Spatial_loss 2.26, Flat_loss 0.40, Train_acc 79.21, Test_acc 22.73
2025-02-14 23:29:35,415 [podnet.py] => Task 13, Epoch 11/160 (LR 0.09884) => LSC_loss 0.85, Spatial_loss 2.42, Flat_loss 0.41, Train_acc 79.08, Test_acc 23.81
2025-02-14 23:29:37,410 [podnet.py] => Task 13, Epoch 12/160 (LR 0.09862) => LSC_loss 0.81, Spatial_loss 2.41, Flat_loss 0.41, Train_acc 79.50, Test_acc 24.99
2025-02-14 23:29:39,394 [podnet.py] => Task 13, Epoch 13/160 (LR 0.09838) => LSC_loss 0.80, Spatial_loss 2.33, Flat_loss 0.41, Train_acc 79.89, Test_acc 21.69
2025-02-14 23:29:41,346 [podnet.py] => Task 13, Epoch 14/160 (LR 0.09812) => LSC_loss 0.78, Spatial_loss 2.34, Flat_loss 0.41, Train_acc 80.76, Test_acc 21.71
2025-02-14 23:29:43,309 [podnet.py] => Task 13, Epoch 15/160 (LR 0.09785) => LSC_loss 0.76, Spatial_loss 2.37, Flat_loss 0.40, Train_acc 80.97, Test_acc 20.93
2025-02-14 23:29:45,341 [podnet.py] => Task 13, Epoch 16/160 (LR 0.09755) => LSC_loss 0.74, Spatial_loss 2.29, Flat_loss 0.40, Train_acc 81.92, Test_acc 22.53
2025-02-14 23:29:47,297 [podnet.py] => Task 13, Epoch 17/160 (LR 0.09724) => LSC_loss 0.72, Spatial_loss 2.27, Flat_loss 0.40, Train_acc 81.97, Test_acc 22.94
2025-02-14 23:29:49,267 [podnet.py] => Task 13, Epoch 18/160 (LR 0.09691) => LSC_loss 0.72, Spatial_loss 2.23, Flat_loss 0.39, Train_acc 82.50, Test_acc 24.19
2025-02-14 23:29:51,220 [podnet.py] => Task 13, Epoch 19/160 (LR 0.09656) => LSC_loss 0.70, Spatial_loss 2.31, Flat_loss 0.40, Train_acc 82.45, Test_acc 23.91
2025-02-14 23:29:53,159 [podnet.py] => Task 13, Epoch 20/160 (LR 0.09619) => LSC_loss 0.72, Spatial_loss 2.26, Flat_loss 0.40, Train_acc 82.05, Test_acc 21.69
2025-02-14 23:29:55,110 [podnet.py] => Task 13, Epoch 21/160 (LR 0.09581) => LSC_loss 0.72, Spatial_loss 2.35, Flat_loss 0.39, Train_acc 82.05, Test_acc 26.19
2025-02-14 23:29:57,036 [podnet.py] => Task 13, Epoch 22/160 (LR 0.09541) => LSC_loss 0.66, Spatial_loss 2.19, Flat_loss 0.38, Train_acc 84.03, Test_acc 23.69
2025-02-14 23:29:59,012 [podnet.py] => Task 13, Epoch 23/160 (LR 0.09499) => LSC_loss 0.63, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 85.18, Test_acc 21.63
2025-02-14 23:30:00,979 [podnet.py] => Task 13, Epoch 24/160 (LR 0.09455) => LSC_loss 0.67, Spatial_loss 2.20, Flat_loss 0.38, Train_acc 83.55, Test_acc 24.49
2025-02-14 23:30:02,943 [podnet.py] => Task 13, Epoch 25/160 (LR 0.09410) => LSC_loss 0.64, Spatial_loss 2.17, Flat_loss 0.38, Train_acc 84.53, Test_acc 25.54
2025-02-14 23:30:04,929 [podnet.py] => Task 13, Epoch 26/160 (LR 0.09362) => LSC_loss 0.64, Spatial_loss 2.12, Flat_loss 0.38, Train_acc 84.21, Test_acc 26.33
2025-02-14 23:30:06,897 [podnet.py] => Task 13, Epoch 27/160 (LR 0.09314) => LSC_loss 0.57, Spatial_loss 2.10, Flat_loss 0.36, Train_acc 87.26, Test_acc 24.51
2025-02-14 23:30:08,821 [podnet.py] => Task 13, Epoch 28/160 (LR 0.09263) => LSC_loss 0.64, Spatial_loss 2.27, Flat_loss 0.39, Train_acc 84.18, Test_acc 21.81
2025-02-14 23:30:10,778 [podnet.py] => Task 13, Epoch 29/160 (LR 0.09211) => LSC_loss 0.58, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 86.05, Test_acc 26.47
2025-02-14 23:30:12,756 [podnet.py] => Task 13, Epoch 30/160 (LR 0.09157) => LSC_loss 0.58, Spatial_loss 2.13, Flat_loss 0.37, Train_acc 86.47, Test_acc 24.96
2025-02-14 23:30:14,681 [podnet.py] => Task 13, Epoch 31/160 (LR 0.09102) => LSC_loss 0.61, Spatial_loss 2.18, Flat_loss 0.39, Train_acc 85.47, Test_acc 27.70
2025-02-14 23:30:16,672 [podnet.py] => Task 13, Epoch 32/160 (LR 0.09045) => LSC_loss 0.56, Spatial_loss 2.13, Flat_loss 0.37, Train_acc 86.63, Test_acc 25.27
2025-02-14 23:30:18,613 [podnet.py] => Task 13, Epoch 33/160 (LR 0.08987) => LSC_loss 0.55, Spatial_loss 2.16, Flat_loss 0.37, Train_acc 87.00, Test_acc 24.30
2025-02-14 23:30:20,556 [podnet.py] => Task 13, Epoch 34/160 (LR 0.08927) => LSC_loss 0.52, Spatial_loss 2.07, Flat_loss 0.35, Train_acc 87.68, Test_acc 25.36
2025-02-14 23:30:22,491 [podnet.py] => Task 13, Epoch 35/160 (LR 0.08865) => LSC_loss 0.54, Spatial_loss 2.09, Flat_loss 0.37, Train_acc 87.29, Test_acc 21.47
2025-02-14 23:30:24,436 [podnet.py] => Task 13, Epoch 36/160 (LR 0.08802) => LSC_loss 0.56, Spatial_loss 2.10, Flat_loss 0.37, Train_acc 86.00, Test_acc 25.84
2025-02-14 23:30:26,378 [podnet.py] => Task 13, Epoch 37/160 (LR 0.08738) => LSC_loss 0.48, Spatial_loss 2.13, Flat_loss 0.36, Train_acc 89.26, Test_acc 23.13
2025-02-14 23:30:28,373 [podnet.py] => Task 13, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 2.10, Flat_loss 0.35, Train_acc 88.50, Test_acc 25.69
2025-02-14 23:30:30,301 [podnet.py] => Task 13, Epoch 39/160 (LR 0.08604) => LSC_loss 0.52, Spatial_loss 2.08, Flat_loss 0.37, Train_acc 88.00, Test_acc 26.37
2025-02-14 23:30:32,254 [podnet.py] => Task 13, Epoch 40/160 (LR 0.08536) => LSC_loss 0.52, Spatial_loss 2.02, Flat_loss 0.37, Train_acc 87.66, Test_acc 23.51
2025-02-14 23:30:34,213 [podnet.py] => Task 13, Epoch 41/160 (LR 0.08465) => LSC_loss 0.51, Spatial_loss 2.06, Flat_loss 0.36, Train_acc 88.32, Test_acc 24.00
2025-02-14 23:30:36,180 [podnet.py] => Task 13, Epoch 42/160 (LR 0.08394) => LSC_loss 0.53, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 86.82, Test_acc 21.93
2025-02-14 23:30:38,107 [podnet.py] => Task 13, Epoch 43/160 (LR 0.08321) => LSC_loss 0.51, Spatial_loss 2.09, Flat_loss 0.36, Train_acc 88.34, Test_acc 27.04
2025-02-14 23:30:40,045 [podnet.py] => Task 13, Epoch 44/160 (LR 0.08247) => LSC_loss 0.45, Spatial_loss 2.06, Flat_loss 0.35, Train_acc 90.11, Test_acc 23.37
2025-02-14 23:30:41,977 [podnet.py] => Task 13, Epoch 45/160 (LR 0.08172) => LSC_loss 0.46, Spatial_loss 1.98, Flat_loss 0.35, Train_acc 88.82, Test_acc 24.07
2025-02-14 23:30:43,938 [podnet.py] => Task 13, Epoch 46/160 (LR 0.08095) => LSC_loss 0.45, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 90.18, Test_acc 25.39
2025-02-14 23:30:45,866 [podnet.py] => Task 13, Epoch 47/160 (LR 0.08018) => LSC_loss 0.40, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 91.66, Test_acc 30.49
2025-02-14 23:30:47,813 [podnet.py] => Task 13, Epoch 48/160 (LR 0.07939) => LSC_loss 0.46, Spatial_loss 1.99, Flat_loss 0.34, Train_acc 89.74, Test_acc 25.77
2025-02-14 23:30:49,796 [podnet.py] => Task 13, Epoch 49/160 (LR 0.07859) => LSC_loss 0.47, Spatial_loss 2.04, Flat_loss 0.36, Train_acc 89.21, Test_acc 24.94
2025-02-14 23:30:51,806 [podnet.py] => Task 13, Epoch 50/160 (LR 0.07778) => LSC_loss 0.44, Spatial_loss 1.95, Flat_loss 0.34, Train_acc 90.53, Test_acc 25.63
2025-02-14 23:30:53,703 [podnet.py] => Task 13, Epoch 51/160 (LR 0.07696) => LSC_loss 0.43, Spatial_loss 1.99, Flat_loss 0.34, Train_acc 90.42, Test_acc 21.47
2025-02-14 23:30:55,607 [podnet.py] => Task 13, Epoch 52/160 (LR 0.07612) => LSC_loss 0.44, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 90.03, Test_acc 21.76
2025-02-14 23:30:57,543 [podnet.py] => Task 13, Epoch 53/160 (LR 0.07528) => LSC_loss 0.43, Spatial_loss 1.97, Flat_loss 0.35, Train_acc 90.21, Test_acc 26.31
2025-02-14 23:30:59,513 [podnet.py] => Task 13, Epoch 54/160 (LR 0.07443) => LSC_loss 0.40, Spatial_loss 1.94, Flat_loss 0.34, Train_acc 91.34, Test_acc 25.84
2025-02-14 23:31:01,504 [podnet.py] => Task 13, Epoch 55/160 (LR 0.07357) => LSC_loss 0.42, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 90.61, Test_acc 26.04
2025-02-14 23:31:03,446 [podnet.py] => Task 13, Epoch 56/160 (LR 0.07270) => LSC_loss 0.43, Spatial_loss 1.98, Flat_loss 0.35, Train_acc 90.34, Test_acc 23.07
2025-02-14 23:31:05,440 [podnet.py] => Task 13, Epoch 57/160 (LR 0.07182) => LSC_loss 0.42, Spatial_loss 2.00, Flat_loss 0.35, Train_acc 90.24, Test_acc 21.07
2025-02-14 23:31:07,399 [podnet.py] => Task 13, Epoch 58/160 (LR 0.07093) => LSC_loss 0.44, Spatial_loss 1.92, Flat_loss 0.35, Train_acc 89.82, Test_acc 28.44
2025-02-14 23:31:09,344 [podnet.py] => Task 13, Epoch 59/160 (LR 0.07004) => LSC_loss 0.40, Spatial_loss 1.89, Flat_loss 0.34, Train_acc 91.47, Test_acc 26.17
2025-02-14 23:31:11,241 [podnet.py] => Task 13, Epoch 60/160 (LR 0.06913) => LSC_loss 0.39, Spatial_loss 1.86, Flat_loss 0.33, Train_acc 92.00, Test_acc 24.49
2025-02-14 23:31:13,179 [podnet.py] => Task 13, Epoch 61/160 (LR 0.06822) => LSC_loss 0.38, Spatial_loss 1.83, Flat_loss 0.33, Train_acc 91.79, Test_acc 29.00
2025-02-14 23:31:15,110 [podnet.py] => Task 13, Epoch 62/160 (LR 0.06731) => LSC_loss 0.36, Spatial_loss 1.92, Flat_loss 0.33, Train_acc 92.74, Test_acc 28.34
2025-02-14 23:31:17,035 [podnet.py] => Task 13, Epoch 63/160 (LR 0.06638) => LSC_loss 0.37, Spatial_loss 1.90, Flat_loss 0.32, Train_acc 92.26, Test_acc 26.76
2025-02-14 23:31:18,954 [podnet.py] => Task 13, Epoch 64/160 (LR 0.06545) => LSC_loss 0.37, Spatial_loss 1.83, Flat_loss 0.32, Train_acc 91.79, Test_acc 18.44
2025-02-14 23:31:20,922 [podnet.py] => Task 13, Epoch 65/160 (LR 0.06451) => LSC_loss 0.34, Spatial_loss 1.88, Flat_loss 0.33, Train_acc 92.97, Test_acc 29.19
2025-02-14 23:31:22,894 [podnet.py] => Task 13, Epoch 66/160 (LR 0.06357) => LSC_loss 0.36, Spatial_loss 1.82, Flat_loss 0.32, Train_acc 92.79, Test_acc 27.27
2025-02-14 23:31:24,825 [podnet.py] => Task 13, Epoch 67/160 (LR 0.06262) => LSC_loss 0.36, Spatial_loss 1.81, Flat_loss 0.32, Train_acc 92.58, Test_acc 26.20
2025-02-14 23:31:26,737 [podnet.py] => Task 13, Epoch 68/160 (LR 0.06167) => LSC_loss 0.34, Spatial_loss 1.83, Flat_loss 0.32, Train_acc 93.39, Test_acc 24.66
2025-02-14 23:31:28,659 [podnet.py] => Task 13, Epoch 69/160 (LR 0.06072) => LSC_loss 0.35, Spatial_loss 1.86, Flat_loss 0.32, Train_acc 93.16, Test_acc 25.51
2025-02-14 23:31:30,590 [podnet.py] => Task 13, Epoch 70/160 (LR 0.05975) => LSC_loss 0.31, Spatial_loss 1.74, Flat_loss 0.31, Train_acc 94.16, Test_acc 28.20
2025-02-14 23:31:32,500 [podnet.py] => Task 13, Epoch 71/160 (LR 0.05879) => LSC_loss 0.33, Spatial_loss 1.83, Flat_loss 0.32, Train_acc 93.87, Test_acc 22.87
2025-02-14 23:31:34,480 [podnet.py] => Task 13, Epoch 72/160 (LR 0.05782) => LSC_loss 0.32, Spatial_loss 1.77, Flat_loss 0.31, Train_acc 93.68, Test_acc 25.97
2025-02-14 23:31:36,409 [podnet.py] => Task 13, Epoch 73/160 (LR 0.05685) => LSC_loss 0.32, Spatial_loss 1.71, Flat_loss 0.31, Train_acc 93.63, Test_acc 29.36
2025-02-14 23:31:38,356 [podnet.py] => Task 13, Epoch 74/160 (LR 0.05588) => LSC_loss 0.33, Spatial_loss 1.76, Flat_loss 0.32, Train_acc 93.53, Test_acc 26.67
2025-02-14 23:31:40,254 [podnet.py] => Task 13, Epoch 75/160 (LR 0.05490) => LSC_loss 0.32, Spatial_loss 1.74, Flat_loss 0.30, Train_acc 93.95, Test_acc 29.07
2025-02-14 23:31:42,163 [podnet.py] => Task 13, Epoch 76/160 (LR 0.05392) => LSC_loss 0.29, Spatial_loss 1.66, Flat_loss 0.30, Train_acc 94.71, Test_acc 26.14
2025-02-14 23:31:44,117 [podnet.py] => Task 13, Epoch 77/160 (LR 0.05294) => LSC_loss 0.30, Spatial_loss 1.75, Flat_loss 0.31, Train_acc 94.53, Test_acc 24.50
2025-02-14 23:31:46,107 [podnet.py] => Task 13, Epoch 78/160 (LR 0.05196) => LSC_loss 0.31, Spatial_loss 1.77, Flat_loss 0.31, Train_acc 94.37, Test_acc 21.40
2025-02-14 23:31:48,011 [podnet.py] => Task 13, Epoch 79/160 (LR 0.05098) => LSC_loss 0.29, Spatial_loss 1.70, Flat_loss 0.30, Train_acc 94.58, Test_acc 25.29
2025-02-14 23:31:49,976 [podnet.py] => Task 13, Epoch 80/160 (LR 0.05000) => LSC_loss 0.29, Spatial_loss 1.64, Flat_loss 0.30, Train_acc 94.71, Test_acc 25.14
2025-02-14 23:31:51,904 [podnet.py] => Task 13, Epoch 81/160 (LR 0.04902) => LSC_loss 0.31, Spatial_loss 1.69, Flat_loss 0.30, Train_acc 94.18, Test_acc 28.14
2025-02-14 23:31:53,744 [podnet.py] => Task 13, Epoch 82/160 (LR 0.04804) => LSC_loss 0.32, Spatial_loss 1.71, Flat_loss 0.31, Train_acc 94.03, Test_acc 24.71
2025-02-14 23:31:55,668 [podnet.py] => Task 13, Epoch 83/160 (LR 0.04706) => LSC_loss 0.29, Spatial_loss 1.69, Flat_loss 0.30, Train_acc 95.05, Test_acc 26.84
2025-02-14 23:31:57,583 [podnet.py] => Task 13, Epoch 84/160 (LR 0.04608) => LSC_loss 0.27, Spatial_loss 1.66, Flat_loss 0.29, Train_acc 95.82, Test_acc 25.37
2025-02-14 23:31:59,456 [podnet.py] => Task 13, Epoch 85/160 (LR 0.04510) => LSC_loss 0.26, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 95.68, Test_acc 28.93
2025-02-14 23:32:01,451 [podnet.py] => Task 13, Epoch 86/160 (LR 0.04412) => LSC_loss 0.27, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 95.61, Test_acc 29.21
2025-02-14 23:32:03,363 [podnet.py] => Task 13, Epoch 87/160 (LR 0.04315) => LSC_loss 0.24, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 96.58, Test_acc 25.43
2025-02-14 23:32:05,296 [podnet.py] => Task 13, Epoch 88/160 (LR 0.04218) => LSC_loss 0.25, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 95.97, Test_acc 25.21
2025-02-14 23:32:07,188 [podnet.py] => Task 13, Epoch 89/160 (LR 0.04121) => LSC_loss 0.25, Spatial_loss 1.59, Flat_loss 0.28, Train_acc 95.92, Test_acc 28.56
2025-02-14 23:32:09,118 [podnet.py] => Task 13, Epoch 90/160 (LR 0.04025) => LSC_loss 0.25, Spatial_loss 1.58, Flat_loss 0.27, Train_acc 96.21, Test_acc 27.49
2025-02-14 23:32:11,121 [podnet.py] => Task 13, Epoch 91/160 (LR 0.03928) => LSC_loss 0.24, Spatial_loss 1.58, Flat_loss 0.28, Train_acc 96.13, Test_acc 24.27
2025-02-14 23:32:13,041 [podnet.py] => Task 13, Epoch 92/160 (LR 0.03833) => LSC_loss 0.26, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 95.97, Test_acc 28.73
2025-02-14 23:32:14,996 [podnet.py] => Task 13, Epoch 93/160 (LR 0.03738) => LSC_loss 0.24, Spatial_loss 1.51, Flat_loss 0.27, Train_acc 96.26, Test_acc 29.11
2025-02-14 23:32:16,956 [podnet.py] => Task 13, Epoch 94/160 (LR 0.03643) => LSC_loss 0.24, Spatial_loss 1.57, Flat_loss 0.27, Train_acc 96.29, Test_acc 29.49
2025-02-14 23:32:18,956 [podnet.py] => Task 13, Epoch 95/160 (LR 0.03549) => LSC_loss 0.24, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 96.50, Test_acc 28.57
2025-02-14 23:32:20,949 [podnet.py] => Task 13, Epoch 96/160 (LR 0.03455) => LSC_loss 0.23, Spatial_loss 1.49, Flat_loss 0.27, Train_acc 96.50, Test_acc 28.56
2025-02-14 23:32:22,899 [podnet.py] => Task 13, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 1.43, Flat_loss 0.26, Train_acc 96.87, Test_acc 29.33
2025-02-14 23:32:24,847 [podnet.py] => Task 13, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 1.51, Flat_loss 0.27, Train_acc 96.66, Test_acc 28.47
2025-02-14 23:32:26,757 [podnet.py] => Task 13, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 1.46, Flat_loss 0.26, Train_acc 96.55, Test_acc 25.13
2025-02-14 23:32:28,717 [podnet.py] => Task 13, Epoch 100/160 (LR 0.03087) => LSC_loss 0.21, Spatial_loss 1.51, Flat_loss 0.26, Train_acc 97.45, Test_acc 27.26
2025-02-14 23:32:30,713 [podnet.py] => Task 13, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 1.46, Flat_loss 0.26, Train_acc 96.79, Test_acc 25.00
2025-02-14 23:32:32,638 [podnet.py] => Task 13, Epoch 102/160 (LR 0.02907) => LSC_loss 0.21, Spatial_loss 1.47, Flat_loss 0.26, Train_acc 97.16, Test_acc 26.00
2025-02-14 23:32:34,599 [podnet.py] => Task 13, Epoch 103/160 (LR 0.02818) => LSC_loss 0.21, Spatial_loss 1.48, Flat_loss 0.26, Train_acc 97.05, Test_acc 28.36
2025-02-14 23:32:36,554 [podnet.py] => Task 13, Epoch 104/160 (LR 0.02730) => LSC_loss 0.22, Spatial_loss 1.49, Flat_loss 0.26, Train_acc 97.11, Test_acc 26.51
2025-02-14 23:32:38,479 [podnet.py] => Task 13, Epoch 105/160 (LR 0.02643) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.26, Train_acc 97.45, Test_acc 27.87
2025-02-14 23:32:40,480 [podnet.py] => Task 13, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 1.40, Flat_loss 0.25, Train_acc 97.71, Test_acc 28.73
2025-02-14 23:32:42,419 [podnet.py] => Task 13, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 1.41, Flat_loss 0.25, Train_acc 97.92, Test_acc 26.01
2025-02-14 23:32:44,391 [podnet.py] => Task 13, Epoch 108/160 (LR 0.02388) => LSC_loss 0.21, Spatial_loss 1.45, Flat_loss 0.26, Train_acc 97.26, Test_acc 29.49
2025-02-14 23:32:46,266 [podnet.py] => Task 13, Epoch 109/160 (LR 0.02304) => LSC_loss 0.20, Spatial_loss 1.35, Flat_loss 0.25, Train_acc 97.79, Test_acc 27.41
2025-02-14 23:32:48,272 [podnet.py] => Task 13, Epoch 110/160 (LR 0.02222) => LSC_loss 0.19, Spatial_loss 1.40, Flat_loss 0.25, Train_acc 98.08, Test_acc 26.94
2025-02-14 23:32:50,222 [podnet.py] => Task 13, Epoch 111/160 (LR 0.02141) => LSC_loss 0.19, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 98.00, Test_acc 27.61
2025-02-14 23:32:52,187 [podnet.py] => Task 13, Epoch 112/160 (LR 0.02061) => LSC_loss 0.19, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 97.92, Test_acc 27.64
2025-02-14 23:32:54,110 [podnet.py] => Task 13, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 1.34, Flat_loss 0.25, Train_acc 97.26, Test_acc 26.80
2025-02-14 23:32:56,028 [podnet.py] => Task 13, Epoch 114/160 (LR 0.01905) => LSC_loss 0.19, Spatial_loss 1.37, Flat_loss 0.24, Train_acc 97.79, Test_acc 26.27
2025-02-14 23:32:57,972 [podnet.py] => Task 13, Epoch 115/160 (LR 0.01828) => LSC_loss 0.19, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 97.76, Test_acc 27.90
2025-02-14 23:32:59,949 [podnet.py] => Task 13, Epoch 116/160 (LR 0.01753) => LSC_loss 0.19, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 98.00, Test_acc 27.30
2025-02-14 23:33:01,891 [podnet.py] => Task 13, Epoch 117/160 (LR 0.01679) => LSC_loss 0.19, Spatial_loss 1.31, Flat_loss 0.24, Train_acc 98.03, Test_acc 29.24
2025-02-14 23:33:03,874 [podnet.py] => Task 13, Epoch 118/160 (LR 0.01606) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.23, Train_acc 98.37, Test_acc 29.09
2025-02-14 23:33:05,879 [podnet.py] => Task 13, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 98.37, Test_acc 26.77
2025-02-14 23:33:07,940 [podnet.py] => Task 13, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 98.16, Test_acc 29.41
2025-02-14 23:33:09,832 [podnet.py] => Task 13, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 1.24, Flat_loss 0.23, Train_acc 98.53, Test_acc 27.29
2025-02-14 23:33:11,814 [podnet.py] => Task 13, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 1.25, Flat_loss 0.23, Train_acc 98.34, Test_acc 28.31
2025-02-14 23:33:13,707 [podnet.py] => Task 13, Epoch 123/160 (LR 0.01262) => LSC_loss 0.19, Spatial_loss 1.21, Flat_loss 0.23, Train_acc 97.89, Test_acc 29.86
2025-02-14 23:33:15,614 [podnet.py] => Task 13, Epoch 124/160 (LR 0.01198) => LSC_loss 0.18, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 98.21, Test_acc 29.16
2025-02-14 23:33:17,553 [podnet.py] => Task 13, Epoch 125/160 (LR 0.01135) => LSC_loss 0.17, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 98.74, Test_acc 28.64
2025-02-14 23:33:19,505 [podnet.py] => Task 13, Epoch 126/160 (LR 0.01073) => LSC_loss 0.18, Spatial_loss 1.24, Flat_loss 0.23, Train_acc 98.16, Test_acc 28.47
2025-02-14 23:33:21,444 [podnet.py] => Task 13, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.19, Flat_loss 0.23, Train_acc 98.58, Test_acc 29.33
2025-02-14 23:33:23,388 [podnet.py] => Task 13, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 98.55, Test_acc 28.09
2025-02-14 23:33:25,348 [podnet.py] => Task 13, Epoch 129/160 (LR 0.00898) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.22, Train_acc 98.92, Test_acc 27.96
2025-02-14 23:33:27,322 [podnet.py] => Task 13, Epoch 130/160 (LR 0.00843) => LSC_loss 0.17, Spatial_loss 1.16, Flat_loss 0.22, Train_acc 98.53, Test_acc 28.64
2025-02-14 23:33:29,292 [podnet.py] => Task 13, Epoch 131/160 (LR 0.00789) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.22, Train_acc 98.32, Test_acc 28.23
2025-02-14 23:33:31,222 [podnet.py] => Task 13, Epoch 132/160 (LR 0.00737) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.23, Train_acc 98.61, Test_acc 28.96
2025-02-14 23:33:33,181 [podnet.py] => Task 13, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 1.13, Flat_loss 0.22, Train_acc 98.82, Test_acc 27.80
2025-02-14 23:33:35,046 [podnet.py] => Task 13, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.13, Flat_loss 0.22, Train_acc 98.76, Test_acc 28.41
2025-02-14 23:33:37,036 [podnet.py] => Task 13, Epoch 135/160 (LR 0.00590) => LSC_loss 0.17, Spatial_loss 1.18, Flat_loss 0.22, Train_acc 98.47, Test_acc 30.03
2025-02-14 23:33:38,934 [podnet.py] => Task 13, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 1.13, Flat_loss 0.22, Train_acc 98.37, Test_acc 28.27
2025-02-14 23:33:40,889 [podnet.py] => Task 13, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.22, Train_acc 98.74, Test_acc 28.73
2025-02-14 23:33:42,816 [podnet.py] => Task 13, Epoch 138/160 (LR 0.00459) => LSC_loss 0.17, Spatial_loss 1.15, Flat_loss 0.22, Train_acc 98.63, Test_acc 28.83
2025-02-14 23:33:44,746 [podnet.py] => Task 13, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 1.08, Flat_loss 0.21, Train_acc 98.50, Test_acc 28.71
2025-02-14 23:33:46,752 [podnet.py] => Task 13, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 98.71, Test_acc 28.76
2025-02-14 23:33:48,729 [podnet.py] => Task 13, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.22, Train_acc 98.82, Test_acc 28.91
2025-02-14 23:33:50,799 [podnet.py] => Task 13, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 98.63, Test_acc 29.07
2025-02-14 23:33:52,791 [podnet.py] => Task 13, Epoch 143/160 (LR 0.00276) => LSC_loss 0.16, Spatial_loss 1.09, Flat_loss 0.21, Train_acc 98.66, Test_acc 28.96
2025-02-14 23:33:54,739 [podnet.py] => Task 13, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.21, Train_acc 98.68, Test_acc 28.67
2025-02-14 23:33:56,679 [podnet.py] => Task 13, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 98.82, Test_acc 28.66
2025-02-14 23:33:58,660 [podnet.py] => Task 13, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 98.68, Test_acc 29.11
2025-02-14 23:34:00,577 [podnet.py] => Task 13, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 1.07, Flat_loss 0.21, Train_acc 98.97, Test_acc 28.99
2025-02-14 23:34:02,550 [podnet.py] => Task 13, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 1.06, Flat_loss 0.21, Train_acc 99.11, Test_acc 29.07
2025-02-14 23:34:04,417 [podnet.py] => Task 13, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.21, Train_acc 98.87, Test_acc 28.89
2025-02-14 23:34:06,364 [podnet.py] => Task 13, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.21, Train_acc 98.97, Test_acc 29.21
2025-02-14 23:34:08,305 [podnet.py] => Task 13, Epoch 151/160 (LR 0.00078) => LSC_loss 0.15, Spatial_loss 1.03, Flat_loss 0.21, Train_acc 99.18, Test_acc 29.13
2025-02-14 23:34:10,271 [podnet.py] => Task 13, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.98, Flat_loss 0.21, Train_acc 99.13, Test_acc 28.94
2025-02-14 23:34:12,208 [podnet.py] => Task 13, Epoch 153/160 (LR 0.00047) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.21, Train_acc 98.92, Test_acc 28.60
2025-02-14 23:34:14,122 [podnet.py] => Task 13, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.21, Train_acc 98.97, Test_acc 28.89
2025-02-14 23:34:16,097 [podnet.py] => Task 13, Epoch 155/160 (LR 0.00024) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.21, Train_acc 99.11, Test_acc 28.96
2025-02-14 23:34:18,039 [podnet.py] => Task 13, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.21, Train_acc 98.92, Test_acc 29.14
2025-02-14 23:34:19,922 [podnet.py] => Task 13, Epoch 157/160 (LR 0.00009) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.21, Train_acc 98.79, Test_acc 28.71
2025-02-14 23:34:21,884 [podnet.py] => Task 13, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.21, Train_acc 99.24, Test_acc 29.19
2025-02-14 23:34:23,824 [podnet.py] => Task 13, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.21, Train_acc 99.00, Test_acc 29.10
2025-02-14 23:34:25,822 [podnet.py] => Task 13, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.21, Train_acc 99.05, Test_acc 28.94
2025-02-14 23:34:25,822 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:34:25,823 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:34:51,309 [podnet.py] => The size of finetune dataset: 1400
2025-02-14 23:34:52,686 [podnet.py] => Task 13, Epoch 1/20 (LR 0.00497) => LSC_loss 0.31, Spatial_loss 1.17, Flat_loss 0.17, Train_acc 93.50, Test_acc 30.06
2025-02-14 23:34:54,030 [podnet.py] => Task 13, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.07, Test_acc 31.76
2025-02-14 23:34:55,455 [podnet.py] => Task 13, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 99.43, Test_acc 32.13
2025-02-14 23:34:56,824 [podnet.py] => Task 13, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 1.13, Flat_loss 0.10, Train_acc 99.50, Test_acc 31.34
2025-02-14 23:34:58,177 [podnet.py] => Task 13, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 1.02, Flat_loss 0.09, Train_acc 99.29, Test_acc 30.51
2025-02-14 23:34:59,620 [podnet.py] => Task 13, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 99.43, Test_acc 30.53
2025-02-14 23:35:01,034 [podnet.py] => Task 13, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 99.36, Test_acc 30.57
2025-02-14 23:35:02,433 [podnet.py] => Task 13, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 98.86, Test_acc 30.97
2025-02-14 23:35:03,846 [podnet.py] => Task 13, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 99.29, Test_acc 30.99
2025-02-14 23:35:05,241 [podnet.py] => Task 13, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 99.64, Test_acc 30.87
2025-02-14 23:35:06,687 [podnet.py] => Task 13, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 0.97, Flat_loss 0.09, Train_acc 99.36, Test_acc 31.13
2025-02-14 23:35:08,053 [podnet.py] => Task 13, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 1.02, Flat_loss 0.09, Train_acc 99.43, Test_acc 30.94
2025-02-14 23:35:09,482 [podnet.py] => Task 13, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 1.07, Flat_loss 0.09, Train_acc 99.64, Test_acc 31.11
2025-02-14 23:35:10,857 [podnet.py] => Task 13, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 1.00, Flat_loss 0.09, Train_acc 99.43, Test_acc 31.10
2025-02-14 23:35:12,296 [podnet.py] => Task 13, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 99.71, Test_acc 31.10
2025-02-14 23:35:13,700 [podnet.py] => Task 13, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 1.00, Flat_loss 0.09, Train_acc 99.43, Test_acc 30.99
2025-02-14 23:35:15,112 [podnet.py] => Task 13, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 99.50, Test_acc 31.11
2025-02-14 23:35:16,480 [podnet.py] => Task 13, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 0.98, Flat_loss 0.09, Train_acc 99.43, Test_acc 30.96
2025-02-14 23:35:17,869 [podnet.py] => Task 13, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 99.50, Test_acc 31.09
2025-02-14 23:35:19,324 [podnet.py] => Task 13, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 99.57, Test_acc 31.04
2025-02-14 23:35:19,325 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:35:46,118 [podnet.py] => Exemplar size: 1400
2025-02-14 23:35:46,119 [trainer.py] => CNN: {'total': 31.04, '00-09': 36.9, '10-19': 9.2, '20-29': 19.2, '30-39': 17.5, '40-49': 39.4, '50-59': 31.5, '60-69': 63.6, 'old': 27.42, 'new': 78.2}
2025-02-14 23:35:46,119 [trainer.py] => NME: {'total': 30.91, '00-09': 42.5, '10-19': 9.8, '20-29': 19.9, '30-39': 17.5, '40-49': 37.9, '50-59': 29.9, '60-69': 58.9, 'old': 27.6, 'new': 74.0}
2025-02-14 23:35:46,119 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04]
2025-02-14 23:35:46,119 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97]
2025-02-14 23:35:46,119 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91]
2025-02-14 23:35:46,119 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4]

2025-02-14 23:35:46,119 [trainer.py] => Average Accuracy (CNN): 46.99071428571428
2025-02-14 23:35:46,119 [trainer.py] => Average Accuracy (NME): 46.359285714285704
2025-02-14 23:35:46,119 [trainer.py] => All params: 511057
2025-02-14 23:35:46,120 [trainer.py] => Trainable params: 511057
2025-02-14 23:35:46,120 [podnet.py] => Learning on 70-75
2025-02-14 23:35:46,149 [podnet.py] => Adaptive factor: 3.872983346207417
2025-02-14 23:35:48,227 [podnet.py] => Task 14, Epoch 1/160 (LR 0.09999) => LSC_loss 3.01, Spatial_loss 3.33, Flat_loss 1.36, Train_acc 46.49, Test_acc 20.47
2025-02-14 23:35:50,224 [podnet.py] => Task 14, Epoch 2/160 (LR 0.09996) => LSC_loss 1.59, Spatial_loss 2.86, Flat_loss 0.74, Train_acc 60.26, Test_acc 19.21
2025-02-14 23:35:52,246 [podnet.py] => Task 14, Epoch 3/160 (LR 0.09991) => LSC_loss 1.39, Spatial_loss 2.70, Flat_loss 0.59, Train_acc 64.23, Test_acc 21.13
2025-02-14 23:35:54,204 [podnet.py] => Task 14, Epoch 4/160 (LR 0.09985) => LSC_loss 1.30, Spatial_loss 2.62, Flat_loss 0.53, Train_acc 65.82, Test_acc 24.52
2025-02-14 23:35:56,218 [podnet.py] => Task 14, Epoch 5/160 (LR 0.09976) => LSC_loss 1.15, Spatial_loss 2.49, Flat_loss 0.48, Train_acc 70.21, Test_acc 20.32
2025-02-14 23:35:58,257 [podnet.py] => Task 14, Epoch 6/160 (LR 0.09965) => LSC_loss 1.13, Spatial_loss 2.54, Flat_loss 0.48, Train_acc 70.62, Test_acc 21.60
2025-02-14 23:36:00,246 [podnet.py] => Task 14, Epoch 7/160 (LR 0.09953) => LSC_loss 1.10, Spatial_loss 2.46, Flat_loss 0.45, Train_acc 71.72, Test_acc 15.81
2025-02-14 23:36:02,237 [podnet.py] => Task 14, Epoch 8/160 (LR 0.09938) => LSC_loss 1.05, Spatial_loss 2.48, Flat_loss 0.45, Train_acc 72.97, Test_acc 20.77
2025-02-14 23:36:04,220 [podnet.py] => Task 14, Epoch 9/160 (LR 0.09922) => LSC_loss 1.05, Spatial_loss 2.46, Flat_loss 0.45, Train_acc 73.26, Test_acc 23.88
2025-02-14 23:36:06,195 [podnet.py] => Task 14, Epoch 10/160 (LR 0.09904) => LSC_loss 1.04, Spatial_loss 2.52, Flat_loss 0.45, Train_acc 73.13, Test_acc 17.08
2025-02-14 23:36:08,156 [podnet.py] => Task 14, Epoch 11/160 (LR 0.09884) => LSC_loss 1.01, Spatial_loss 2.52, Flat_loss 0.45, Train_acc 73.64, Test_acc 21.07
2025-02-14 23:36:10,137 [podnet.py] => Task 14, Epoch 12/160 (LR 0.09862) => LSC_loss 0.96, Spatial_loss 2.44, Flat_loss 0.43, Train_acc 75.08, Test_acc 20.75
2025-02-14 23:36:12,074 [podnet.py] => Task 14, Epoch 13/160 (LR 0.09838) => LSC_loss 0.96, Spatial_loss 2.40, Flat_loss 0.43, Train_acc 75.08, Test_acc 20.43
2025-02-14 23:36:14,079 [podnet.py] => Task 14, Epoch 14/160 (LR 0.09812) => LSC_loss 0.91, Spatial_loss 2.41, Flat_loss 0.42, Train_acc 76.46, Test_acc 22.57
2025-02-14 23:36:16,022 [podnet.py] => Task 14, Epoch 15/160 (LR 0.09785) => LSC_loss 0.94, Spatial_loss 2.50, Flat_loss 0.43, Train_acc 75.28, Test_acc 18.32
2025-02-14 23:36:18,030 [podnet.py] => Task 14, Epoch 16/160 (LR 0.09755) => LSC_loss 0.89, Spatial_loss 2.35, Flat_loss 0.42, Train_acc 76.82, Test_acc 22.35
2025-02-14 23:36:20,005 [podnet.py] => Task 14, Epoch 17/160 (LR 0.09724) => LSC_loss 0.84, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 79.51, Test_acc 22.48
2025-02-14 23:36:21,993 [podnet.py] => Task 14, Epoch 18/160 (LR 0.09691) => LSC_loss 0.84, Spatial_loss 2.31, Flat_loss 0.40, Train_acc 78.64, Test_acc 23.63
2025-02-14 23:36:24,001 [podnet.py] => Task 14, Epoch 19/160 (LR 0.09656) => LSC_loss 0.86, Spatial_loss 2.43, Flat_loss 0.42, Train_acc 78.00, Test_acc 20.52
2025-02-14 23:36:26,036 [podnet.py] => Task 14, Epoch 20/160 (LR 0.09619) => LSC_loss 0.82, Spatial_loss 2.37, Flat_loss 0.41, Train_acc 79.00, Test_acc 25.76
2025-02-14 23:36:28,030 [podnet.py] => Task 14, Epoch 21/160 (LR 0.09581) => LSC_loss 0.74, Spatial_loss 2.24, Flat_loss 0.38, Train_acc 81.03, Test_acc 20.05
2025-02-14 23:36:30,066 [podnet.py] => Task 14, Epoch 22/160 (LR 0.09541) => LSC_loss 0.76, Spatial_loss 2.25, Flat_loss 0.39, Train_acc 80.79, Test_acc 21.35
2025-02-14 23:36:32,027 [podnet.py] => Task 14, Epoch 23/160 (LR 0.09499) => LSC_loss 0.81, Spatial_loss 2.31, Flat_loss 0.41, Train_acc 79.38, Test_acc 20.76
2025-02-14 23:36:34,002 [podnet.py] => Task 14, Epoch 24/160 (LR 0.09455) => LSC_loss 0.77, Spatial_loss 2.30, Flat_loss 0.41, Train_acc 81.13, Test_acc 24.36
2025-02-14 23:36:35,974 [podnet.py] => Task 14, Epoch 25/160 (LR 0.09410) => LSC_loss 0.74, Spatial_loss 2.18, Flat_loss 0.39, Train_acc 81.44, Test_acc 25.41
2025-02-14 23:36:37,958 [podnet.py] => Task 14, Epoch 26/160 (LR 0.09362) => LSC_loss 0.76, Spatial_loss 2.27, Flat_loss 0.39, Train_acc 80.95, Test_acc 24.11
2025-02-14 23:36:39,967 [podnet.py] => Task 14, Epoch 27/160 (LR 0.09314) => LSC_loss 0.75, Spatial_loss 2.28, Flat_loss 0.39, Train_acc 81.00, Test_acc 22.96
2025-02-14 23:36:41,969 [podnet.py] => Task 14, Epoch 28/160 (LR 0.09263) => LSC_loss 0.73, Spatial_loss 2.31, Flat_loss 0.40, Train_acc 81.79, Test_acc 24.87
2025-02-14 23:36:43,990 [podnet.py] => Task 14, Epoch 29/160 (LR 0.09211) => LSC_loss 0.72, Spatial_loss 2.30, Flat_loss 0.40, Train_acc 81.54, Test_acc 24.03
2025-02-14 23:36:45,950 [podnet.py] => Task 14, Epoch 30/160 (LR 0.09157) => LSC_loss 0.70, Spatial_loss 2.25, Flat_loss 0.39, Train_acc 82.10, Test_acc 25.63
2025-02-14 23:36:47,905 [podnet.py] => Task 14, Epoch 31/160 (LR 0.09102) => LSC_loss 0.70, Spatial_loss 2.27, Flat_loss 0.38, Train_acc 82.26, Test_acc 21.75
2025-02-14 23:36:49,898 [podnet.py] => Task 14, Epoch 32/160 (LR 0.09045) => LSC_loss 0.70, Spatial_loss 2.17, Flat_loss 0.39, Train_acc 81.97, Test_acc 21.27
2025-02-14 23:36:51,934 [podnet.py] => Task 14, Epoch 33/160 (LR 0.08987) => LSC_loss 0.67, Spatial_loss 2.19, Flat_loss 0.39, Train_acc 83.85, Test_acc 19.85
2025-02-14 23:36:53,887 [podnet.py] => Task 14, Epoch 34/160 (LR 0.08927) => LSC_loss 0.62, Spatial_loss 2.16, Flat_loss 0.37, Train_acc 84.10, Test_acc 24.28
2025-02-14 23:36:55,981 [podnet.py] => Task 14, Epoch 35/160 (LR 0.08865) => LSC_loss 0.69, Spatial_loss 2.33, Flat_loss 0.39, Train_acc 82.90, Test_acc 22.49
2025-02-14 23:36:57,965 [podnet.py] => Task 14, Epoch 36/160 (LR 0.08802) => LSC_loss 0.67, Spatial_loss 2.18, Flat_loss 0.40, Train_acc 83.33, Test_acc 27.47
2025-02-14 23:37:00,018 [podnet.py] => Task 14, Epoch 37/160 (LR 0.08738) => LSC_loss 0.65, Spatial_loss 2.16, Flat_loss 0.38, Train_acc 84.26, Test_acc 23.91
2025-02-14 23:37:02,021 [podnet.py] => Task 14, Epoch 38/160 (LR 0.08672) => LSC_loss 0.60, Spatial_loss 2.14, Flat_loss 0.37, Train_acc 85.33, Test_acc 22.69
2025-02-14 23:37:03,970 [podnet.py] => Task 14, Epoch 39/160 (LR 0.08604) => LSC_loss 0.62, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 84.64, Test_acc 18.61
2025-02-14 23:37:05,938 [podnet.py] => Task 14, Epoch 40/160 (LR 0.08536) => LSC_loss 0.60, Spatial_loss 2.11, Flat_loss 0.37, Train_acc 85.41, Test_acc 23.85
2025-02-14 23:37:07,938 [podnet.py] => Task 14, Epoch 41/160 (LR 0.08465) => LSC_loss 0.58, Spatial_loss 2.15, Flat_loss 0.37, Train_acc 85.51, Test_acc 24.45
2025-02-14 23:37:09,934 [podnet.py] => Task 14, Epoch 42/160 (LR 0.08394) => LSC_loss 0.62, Spatial_loss 2.12, Flat_loss 0.38, Train_acc 84.85, Test_acc 23.29
2025-02-14 23:37:11,979 [podnet.py] => Task 14, Epoch 43/160 (LR 0.08321) => LSC_loss 0.63, Spatial_loss 2.19, Flat_loss 0.39, Train_acc 84.64, Test_acc 23.61
2025-02-14 23:37:13,938 [podnet.py] => Task 14, Epoch 44/160 (LR 0.08247) => LSC_loss 0.55, Spatial_loss 2.11, Flat_loss 0.37, Train_acc 86.56, Test_acc 25.33
2025-02-14 23:37:15,953 [podnet.py] => Task 14, Epoch 45/160 (LR 0.08172) => LSC_loss 0.57, Spatial_loss 2.14, Flat_loss 0.37, Train_acc 86.31, Test_acc 21.49
2025-02-14 23:37:17,979 [podnet.py] => Task 14, Epoch 46/160 (LR 0.08095) => LSC_loss 0.58, Spatial_loss 2.20, Flat_loss 0.37, Train_acc 86.03, Test_acc 24.59
2025-02-14 23:37:19,941 [podnet.py] => Task 14, Epoch 47/160 (LR 0.08018) => LSC_loss 0.58, Spatial_loss 2.09, Flat_loss 0.38, Train_acc 86.46, Test_acc 26.16
2025-02-14 23:37:21,935 [podnet.py] => Task 14, Epoch 48/160 (LR 0.07939) => LSC_loss 0.53, Spatial_loss 2.13, Flat_loss 0.37, Train_acc 87.62, Test_acc 25.35
2025-02-14 23:37:23,943 [podnet.py] => Task 14, Epoch 49/160 (LR 0.07859) => LSC_loss 0.53, Spatial_loss 2.06, Flat_loss 0.37, Train_acc 87.33, Test_acc 20.77
2025-02-14 23:37:25,958 [podnet.py] => Task 14, Epoch 50/160 (LR 0.07778) => LSC_loss 0.53, Spatial_loss 2.04, Flat_loss 0.37, Train_acc 87.56, Test_acc 26.57
2025-02-14 23:37:27,947 [podnet.py] => Task 14, Epoch 51/160 (LR 0.07696) => LSC_loss 0.53, Spatial_loss 2.01, Flat_loss 0.36, Train_acc 87.82, Test_acc 25.95
2025-02-14 23:37:29,957 [podnet.py] => Task 14, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 2.05, Flat_loss 0.37, Train_acc 86.21, Test_acc 26.57
2025-02-14 23:37:31,997 [podnet.py] => Task 14, Epoch 53/160 (LR 0.07528) => LSC_loss 0.53, Spatial_loss 2.02, Flat_loss 0.37, Train_acc 87.46, Test_acc 19.80
2025-02-14 23:37:34,013 [podnet.py] => Task 14, Epoch 54/160 (LR 0.07443) => LSC_loss 0.53, Spatial_loss 2.06, Flat_loss 0.36, Train_acc 87.67, Test_acc 23.53
2025-02-14 23:37:36,049 [podnet.py] => Task 14, Epoch 55/160 (LR 0.07357) => LSC_loss 0.49, Spatial_loss 2.09, Flat_loss 0.36, Train_acc 88.56, Test_acc 24.89
2025-02-14 23:37:38,079 [podnet.py] => Task 14, Epoch 56/160 (LR 0.07270) => LSC_loss 0.46, Spatial_loss 2.03, Flat_loss 0.35, Train_acc 89.36, Test_acc 27.00
2025-02-14 23:37:40,048 [podnet.py] => Task 14, Epoch 57/160 (LR 0.07182) => LSC_loss 0.47, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 88.90, Test_acc 22.03
2025-02-14 23:37:42,064 [podnet.py] => Task 14, Epoch 58/160 (LR 0.07093) => LSC_loss 0.45, Spatial_loss 2.00, Flat_loss 0.35, Train_acc 90.38, Test_acc 23.25
2025-02-14 23:37:44,051 [podnet.py] => Task 14, Epoch 59/160 (LR 0.07004) => LSC_loss 0.44, Spatial_loss 1.97, Flat_loss 0.34, Train_acc 89.82, Test_acc 26.80
2025-02-14 23:37:46,075 [podnet.py] => Task 14, Epoch 60/160 (LR 0.06913) => LSC_loss 0.50, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 88.00, Test_acc 23.99
2025-02-14 23:37:48,086 [podnet.py] => Task 14, Epoch 61/160 (LR 0.06822) => LSC_loss 0.48, Spatial_loss 1.98, Flat_loss 0.36, Train_acc 88.74, Test_acc 23.44
2025-02-14 23:37:50,027 [podnet.py] => Task 14, Epoch 62/160 (LR 0.06731) => LSC_loss 0.48, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 89.08, Test_acc 24.85
2025-02-14 23:37:52,048 [podnet.py] => Task 14, Epoch 63/160 (LR 0.06638) => LSC_loss 0.46, Spatial_loss 1.96, Flat_loss 0.35, Train_acc 89.72, Test_acc 24.47
2025-02-14 23:37:54,076 [podnet.py] => Task 14, Epoch 64/160 (LR 0.06545) => LSC_loss 0.46, Spatial_loss 1.93, Flat_loss 0.35, Train_acc 89.38, Test_acc 24.81
2025-02-14 23:37:56,088 [podnet.py] => Task 14, Epoch 65/160 (LR 0.06451) => LSC_loss 0.49, Spatial_loss 1.94, Flat_loss 0.36, Train_acc 88.51, Test_acc 21.51
2025-02-14 23:37:58,072 [podnet.py] => Task 14, Epoch 66/160 (LR 0.06357) => LSC_loss 0.44, Spatial_loss 1.87, Flat_loss 0.34, Train_acc 90.64, Test_acc 24.75
2025-02-14 23:38:00,092 [podnet.py] => Task 14, Epoch 67/160 (LR 0.06262) => LSC_loss 0.44, Spatial_loss 1.88, Flat_loss 0.35, Train_acc 89.90, Test_acc 25.16
2025-02-14 23:38:02,073 [podnet.py] => Task 14, Epoch 68/160 (LR 0.06167) => LSC_loss 0.43, Spatial_loss 1.92, Flat_loss 0.35, Train_acc 90.44, Test_acc 26.85
2025-02-14 23:38:04,138 [podnet.py] => Task 14, Epoch 69/160 (LR 0.06072) => LSC_loss 0.40, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 91.26, Test_acc 24.37
2025-02-14 23:38:06,164 [podnet.py] => Task 14, Epoch 70/160 (LR 0.05975) => LSC_loss 0.41, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 91.13, Test_acc 25.33
2025-02-14 23:38:08,119 [podnet.py] => Task 14, Epoch 71/160 (LR 0.05879) => LSC_loss 0.41, Spatial_loss 1.96, Flat_loss 0.34, Train_acc 90.85, Test_acc 20.99
2025-02-14 23:38:10,102 [podnet.py] => Task 14, Epoch 72/160 (LR 0.05782) => LSC_loss 0.41, Spatial_loss 1.82, Flat_loss 0.33, Train_acc 90.79, Test_acc 26.35
2025-02-14 23:38:12,055 [podnet.py] => Task 14, Epoch 73/160 (LR 0.05685) => LSC_loss 0.40, Spatial_loss 1.82, Flat_loss 0.33, Train_acc 91.90, Test_acc 23.32
2025-02-14 23:38:14,067 [podnet.py] => Task 14, Epoch 74/160 (LR 0.05588) => LSC_loss 0.39, Spatial_loss 1.81, Flat_loss 0.32, Train_acc 91.95, Test_acc 26.13
2025-02-14 23:38:16,078 [podnet.py] => Task 14, Epoch 75/160 (LR 0.05490) => LSC_loss 0.35, Spatial_loss 1.84, Flat_loss 0.32, Train_acc 93.03, Test_acc 26.09
2025-02-14 23:38:18,026 [podnet.py] => Task 14, Epoch 76/160 (LR 0.05392) => LSC_loss 0.37, Spatial_loss 1.80, Flat_loss 0.32, Train_acc 92.49, Test_acc 24.60
2025-02-14 23:38:20,009 [podnet.py] => Task 14, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.76, Flat_loss 0.32, Train_acc 92.97, Test_acc 26.99
2025-02-14 23:38:22,030 [podnet.py] => Task 14, Epoch 78/160 (LR 0.05196) => LSC_loss 0.37, Spatial_loss 1.85, Flat_loss 0.32, Train_acc 92.33, Test_acc 26.16
2025-02-14 23:38:23,950 [podnet.py] => Task 14, Epoch 79/160 (LR 0.05098) => LSC_loss 0.36, Spatial_loss 1.86, Flat_loss 0.32, Train_acc 92.28, Test_acc 29.40
2025-02-14 23:38:25,935 [podnet.py] => Task 14, Epoch 80/160 (LR 0.05000) => LSC_loss 0.36, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 92.72, Test_acc 24.57
2025-02-14 23:38:27,925 [podnet.py] => Task 14, Epoch 81/160 (LR 0.04902) => LSC_loss 0.35, Spatial_loss 1.68, Flat_loss 0.31, Train_acc 92.79, Test_acc 28.67
2025-02-14 23:38:29,925 [podnet.py] => Task 14, Epoch 82/160 (LR 0.04804) => LSC_loss 0.34, Spatial_loss 1.69, Flat_loss 0.31, Train_acc 93.03, Test_acc 26.77
2025-02-14 23:38:31,906 [podnet.py] => Task 14, Epoch 83/160 (LR 0.04706) => LSC_loss 0.36, Spatial_loss 1.82, Flat_loss 0.33, Train_acc 92.23, Test_acc 27.40
2025-02-14 23:38:33,887 [podnet.py] => Task 14, Epoch 84/160 (LR 0.04608) => LSC_loss 0.33, Spatial_loss 1.75, Flat_loss 0.31, Train_acc 93.49, Test_acc 24.39
2025-02-14 23:38:35,911 [podnet.py] => Task 14, Epoch 85/160 (LR 0.04510) => LSC_loss 0.34, Spatial_loss 1.65, Flat_loss 0.31, Train_acc 93.49, Test_acc 25.00
2025-02-14 23:38:37,871 [podnet.py] => Task 14, Epoch 86/160 (LR 0.04412) => LSC_loss 0.31, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 94.15, Test_acc 26.04
2025-02-14 23:38:39,896 [podnet.py] => Task 14, Epoch 87/160 (LR 0.04315) => LSC_loss 0.32, Spatial_loss 1.68, Flat_loss 0.30, Train_acc 93.64, Test_acc 26.59
2025-02-14 23:38:41,929 [podnet.py] => Task 14, Epoch 88/160 (LR 0.04218) => LSC_loss 0.31, Spatial_loss 1.66, Flat_loss 0.30, Train_acc 94.44, Test_acc 20.57
2025-02-14 23:38:43,917 [podnet.py] => Task 14, Epoch 89/160 (LR 0.04121) => LSC_loss 0.30, Spatial_loss 1.69, Flat_loss 0.29, Train_acc 94.38, Test_acc 26.17
2025-02-14 23:38:45,929 [podnet.py] => Task 14, Epoch 90/160 (LR 0.04025) => LSC_loss 0.30, Spatial_loss 1.68, Flat_loss 0.30, Train_acc 94.41, Test_acc 26.13
2025-02-14 23:38:47,912 [podnet.py] => Task 14, Epoch 91/160 (LR 0.03928) => LSC_loss 0.32, Spatial_loss 1.72, Flat_loss 0.30, Train_acc 93.59, Test_acc 24.65
2025-02-14 23:38:49,924 [podnet.py] => Task 14, Epoch 92/160 (LR 0.03833) => LSC_loss 0.30, Spatial_loss 1.62, Flat_loss 0.29, Train_acc 94.56, Test_acc 26.13
2025-02-14 23:38:51,892 [podnet.py] => Task 14, Epoch 93/160 (LR 0.03738) => LSC_loss 0.29, Spatial_loss 1.59, Flat_loss 0.29, Train_acc 94.69, Test_acc 26.97
2025-02-14 23:38:53,931 [podnet.py] => Task 14, Epoch 94/160 (LR 0.03643) => LSC_loss 0.29, Spatial_loss 1.61, Flat_loss 0.29, Train_acc 94.33, Test_acc 25.73
2025-02-14 23:38:55,880 [podnet.py] => Task 14, Epoch 95/160 (LR 0.03549) => LSC_loss 0.29, Spatial_loss 1.63, Flat_loss 0.29, Train_acc 94.82, Test_acc 25.81
2025-02-14 23:38:57,889 [podnet.py] => Task 14, Epoch 96/160 (LR 0.03455) => LSC_loss 0.28, Spatial_loss 1.55, Flat_loss 0.29, Train_acc 95.44, Test_acc 28.03
2025-02-14 23:38:59,890 [podnet.py] => Task 14, Epoch 97/160 (LR 0.03362) => LSC_loss 0.27, Spatial_loss 1.55, Flat_loss 0.28, Train_acc 95.10, Test_acc 26.95
2025-02-14 23:39:01,920 [podnet.py] => Task 14, Epoch 98/160 (LR 0.03269) => LSC_loss 0.27, Spatial_loss 1.51, Flat_loss 0.28, Train_acc 95.46, Test_acc 25.95
2025-02-14 23:39:03,890 [podnet.py] => Task 14, Epoch 99/160 (LR 0.03178) => LSC_loss 0.27, Spatial_loss 1.48, Flat_loss 0.28, Train_acc 95.18, Test_acc 25.19
2025-02-14 23:39:05,884 [podnet.py] => Task 14, Epoch 100/160 (LR 0.03087) => LSC_loss 0.27, Spatial_loss 1.60, Flat_loss 0.28, Train_acc 95.72, Test_acc 27.56
2025-02-14 23:39:07,938 [podnet.py] => Task 14, Epoch 101/160 (LR 0.02996) => LSC_loss 0.26, Spatial_loss 1.55, Flat_loss 0.29, Train_acc 95.23, Test_acc 25.51
2025-02-14 23:39:09,938 [podnet.py] => Task 14, Epoch 102/160 (LR 0.02907) => LSC_loss 0.27, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 95.33, Test_acc 26.63
2025-02-14 23:39:11,943 [podnet.py] => Task 14, Epoch 103/160 (LR 0.02818) => LSC_loss 0.26, Spatial_loss 1.61, Flat_loss 0.28, Train_acc 95.59, Test_acc 27.00
2025-02-14 23:39:13,950 [podnet.py] => Task 14, Epoch 104/160 (LR 0.02730) => LSC_loss 0.25, Spatial_loss 1.51, Flat_loss 0.27, Train_acc 96.21, Test_acc 24.52
2025-02-14 23:39:15,953 [podnet.py] => Task 14, Epoch 105/160 (LR 0.02643) => LSC_loss 0.25, Spatial_loss 1.51, Flat_loss 0.28, Train_acc 96.05, Test_acc 26.76
2025-02-14 23:39:18,033 [podnet.py] => Task 14, Epoch 106/160 (LR 0.02557) => LSC_loss 0.24, Spatial_loss 1.46, Flat_loss 0.27, Train_acc 96.51, Test_acc 27.87
2025-02-14 23:39:20,013 [podnet.py] => Task 14, Epoch 107/160 (LR 0.02472) => LSC_loss 0.23, Spatial_loss 1.40, Flat_loss 0.26, Train_acc 96.72, Test_acc 28.72
2025-02-14 23:39:22,006 [podnet.py] => Task 14, Epoch 108/160 (LR 0.02388) => LSC_loss 0.23, Spatial_loss 1.43, Flat_loss 0.26, Train_acc 96.90, Test_acc 26.57
2025-02-14 23:39:24,043 [podnet.py] => Task 14, Epoch 109/160 (LR 0.02304) => LSC_loss 0.22, Spatial_loss 1.40, Flat_loss 0.26, Train_acc 97.23, Test_acc 27.75
2025-02-14 23:39:26,037 [podnet.py] => Task 14, Epoch 110/160 (LR 0.02222) => LSC_loss 0.23, Spatial_loss 1.37, Flat_loss 0.25, Train_acc 96.82, Test_acc 28.07
2025-02-14 23:39:28,026 [podnet.py] => Task 14, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 1.43, Flat_loss 0.26, Train_acc 96.62, Test_acc 27.21
2025-02-14 23:39:30,048 [podnet.py] => Task 14, Epoch 112/160 (LR 0.02061) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 97.26, Test_acc 28.53
2025-02-14 23:39:32,080 [podnet.py] => Task 14, Epoch 113/160 (LR 0.01982) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 97.00, Test_acc 26.88
2025-02-14 23:39:34,076 [podnet.py] => Task 14, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 1.46, Flat_loss 0.26, Train_acc 97.38, Test_acc 27.25
2025-02-14 23:39:36,043 [podnet.py] => Task 14, Epoch 115/160 (LR 0.01828) => LSC_loss 0.23, Spatial_loss 1.41, Flat_loss 0.25, Train_acc 96.92, Test_acc 27.59
2025-02-14 23:39:38,069 [podnet.py] => Task 14, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 1.37, Flat_loss 0.26, Train_acc 97.03, Test_acc 28.93
2025-02-14 23:39:40,038 [podnet.py] => Task 14, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 97.21, Test_acc 27.96
2025-02-14 23:39:42,050 [podnet.py] => Task 14, Epoch 118/160 (LR 0.01606) => LSC_loss 0.21, Spatial_loss 1.41, Flat_loss 0.25, Train_acc 97.72, Test_acc 28.01
2025-02-14 23:39:43,961 [podnet.py] => Task 14, Epoch 119/160 (LR 0.01535) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 97.18, Test_acc 28.48
2025-02-14 23:39:45,977 [podnet.py] => Task 14, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 1.36, Flat_loss 0.25, Train_acc 97.28, Test_acc 26.68
2025-02-14 23:39:47,927 [podnet.py] => Task 14, Epoch 121/160 (LR 0.01396) => LSC_loss 0.20, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 97.46, Test_acc 29.36
2025-02-14 23:39:49,936 [podnet.py] => Task 14, Epoch 122/160 (LR 0.01328) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.24, Train_acc 97.77, Test_acc 27.53
2025-02-14 23:39:51,941 [podnet.py] => Task 14, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 98.00, Test_acc 27.68
2025-02-14 23:39:53,930 [podnet.py] => Task 14, Epoch 124/160 (LR 0.01198) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.24, Train_acc 97.64, Test_acc 28.15
2025-02-14 23:39:55,938 [podnet.py] => Task 14, Epoch 125/160 (LR 0.01135) => LSC_loss 0.21, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 97.33, Test_acc 26.63
2025-02-14 23:39:57,880 [podnet.py] => Task 14, Epoch 126/160 (LR 0.01073) => LSC_loss 0.21, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 97.26, Test_acc 27.48
2025-02-14 23:39:59,867 [podnet.py] => Task 14, Epoch 127/160 (LR 0.01013) => LSC_loss 0.20, Spatial_loss 1.23, Flat_loss 0.24, Train_acc 97.69, Test_acc 28.20
2025-02-14 23:40:01,918 [podnet.py] => Task 14, Epoch 128/160 (LR 0.00955) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.24, Train_acc 98.23, Test_acc 28.41
2025-02-14 23:40:03,905 [podnet.py] => Task 14, Epoch 129/160 (LR 0.00898) => LSC_loss 0.20, Spatial_loss 1.25, Flat_loss 0.24, Train_acc 97.46, Test_acc 27.60
2025-02-14 23:40:05,926 [podnet.py] => Task 14, Epoch 130/160 (LR 0.00843) => LSC_loss 0.19, Spatial_loss 1.21, Flat_loss 0.23, Train_acc 98.05, Test_acc 29.01
2025-02-14 23:40:07,877 [podnet.py] => Task 14, Epoch 131/160 (LR 0.00789) => LSC_loss 0.19, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 98.05, Test_acc 28.88
2025-02-14 23:40:09,886 [podnet.py] => Task 14, Epoch 132/160 (LR 0.00737) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 98.00, Test_acc 28.36
2025-02-14 23:40:11,901 [podnet.py] => Task 14, Epoch 133/160 (LR 0.00686) => LSC_loss 0.19, Spatial_loss 1.22, Flat_loss 0.23, Train_acc 97.77, Test_acc 28.09
2025-02-14 23:40:13,924 [podnet.py] => Task 14, Epoch 134/160 (LR 0.00638) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 97.54, Test_acc 28.36
2025-02-14 23:40:15,921 [podnet.py] => Task 14, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 1.14, Flat_loss 0.23, Train_acc 98.21, Test_acc 28.51
2025-02-14 23:40:17,933 [podnet.py] => Task 14, Epoch 136/160 (LR 0.00545) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 98.15, Test_acc 28.16
2025-02-14 23:40:19,919 [podnet.py] => Task 14, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 98.03, Test_acc 27.93
2025-02-14 23:40:21,956 [podnet.py] => Task 14, Epoch 138/160 (LR 0.00459) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.23, Train_acc 98.05, Test_acc 27.07
2025-02-14 23:40:23,964 [podnet.py] => Task 14, Epoch 139/160 (LR 0.00419) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 98.36, Test_acc 27.99
2025-02-14 23:40:25,972 [podnet.py] => Task 14, Epoch 140/160 (LR 0.00381) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.23, Train_acc 97.92, Test_acc 28.13
2025-02-14 23:40:27,953 [podnet.py] => Task 14, Epoch 141/160 (LR 0.00344) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 98.54, Test_acc 28.61
2025-02-14 23:40:29,967 [podnet.py] => Task 14, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.22, Train_acc 98.18, Test_acc 28.76
2025-02-14 23:40:31,982 [podnet.py] => Task 14, Epoch 143/160 (LR 0.00276) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.23, Train_acc 98.44, Test_acc 28.81
2025-02-14 23:40:34,029 [podnet.py] => Task 14, Epoch 144/160 (LR 0.00245) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.22, Train_acc 98.31, Test_acc 28.23
2025-02-14 23:40:35,990 [podnet.py] => Task 14, Epoch 145/160 (LR 0.00215) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 98.46, Test_acc 28.11
2025-02-14 23:40:38,010 [podnet.py] => Task 14, Epoch 146/160 (LR 0.00188) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 98.54, Test_acc 28.52
2025-02-14 23:40:40,003 [podnet.py] => Task 14, Epoch 147/160 (LR 0.00162) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.23, Train_acc 97.97, Test_acc 28.67
2025-02-14 23:40:42,019 [podnet.py] => Task 14, Epoch 148/160 (LR 0.00138) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.22, Train_acc 98.31, Test_acc 28.67
2025-02-14 23:40:44,101 [podnet.py] => Task 14, Epoch 149/160 (LR 0.00116) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 98.18, Test_acc 28.59
2025-02-14 23:40:46,087 [podnet.py] => Task 14, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 98.56, Test_acc 28.57
2025-02-14 23:40:48,090 [podnet.py] => Task 14, Epoch 151/160 (LR 0.00078) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 98.28, Test_acc 28.36
2025-02-14 23:40:50,113 [podnet.py] => Task 14, Epoch 152/160 (LR 0.00062) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.51, Test_acc 28.81
2025-02-14 23:40:52,092 [podnet.py] => Task 14, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.26, Test_acc 28.63
2025-02-14 23:40:54,174 [podnet.py] => Task 14, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 98.49, Test_acc 28.91
2025-02-14 23:40:56,172 [podnet.py] => Task 14, Epoch 155/160 (LR 0.00024) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.64, Test_acc 28.48
2025-02-14 23:40:58,199 [podnet.py] => Task 14, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 98.33, Test_acc 28.64
2025-02-14 23:41:00,228 [podnet.py] => Task 14, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.28, Test_acc 28.63
2025-02-14 23:41:02,246 [podnet.py] => Task 14, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 98.41, Test_acc 28.80
2025-02-14 23:41:04,280 [podnet.py] => Task 14, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 98.54, Test_acc 28.32
2025-02-14 23:41:06,269 [podnet.py] => Task 14, Epoch 160/160 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.22, Train_acc 98.28, Test_acc 28.81
2025-02-14 23:41:06,271 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:41:06,271 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:41:33,523 [podnet.py] => The size of finetune dataset: 1500
2025-02-14 23:41:34,996 [podnet.py] => Task 14, Epoch 1/20 (LR 0.00497) => LSC_loss 0.35, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 92.80, Test_acc 30.04
2025-02-14 23:41:36,433 [podnet.py] => Task 14, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 1.28, Flat_loss 0.13, Train_acc 98.53, Test_acc 31.72
2025-02-14 23:41:37,884 [podnet.py] => Task 14, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 1.21, Flat_loss 0.12, Train_acc 98.67, Test_acc 30.53
2025-02-14 23:41:39,270 [podnet.py] => Task 14, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 1.06, Flat_loss 0.11, Train_acc 99.33, Test_acc 29.71
2025-02-14 23:41:40,735 [podnet.py] => Task 14, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 99.13, Test_acc 29.59
2025-02-14 23:41:42,201 [podnet.py] => Task 14, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.40, Test_acc 30.03
2025-02-14 23:41:43,626 [podnet.py] => Task 14, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 98.87, Test_acc 29.96
2025-02-14 23:41:45,050 [podnet.py] => Task 14, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 99.40, Test_acc 30.07
2025-02-14 23:41:46,457 [podnet.py] => Task 14, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 99.33, Test_acc 30.33
2025-02-14 23:41:47,976 [podnet.py] => Task 14, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.33, Test_acc 30.07
2025-02-14 23:41:49,399 [podnet.py] => Task 14, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 99.27, Test_acc 30.09
2025-02-14 23:41:50,817 [podnet.py] => Task 14, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 99.27, Test_acc 30.40
2025-02-14 23:41:52,227 [podnet.py] => Task 14, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 1.07, Flat_loss 0.10, Train_acc 99.40, Test_acc 30.25
2025-02-14 23:41:53,725 [podnet.py] => Task 14, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.33, Test_acc 30.39
2025-02-14 23:41:55,144 [podnet.py] => Task 14, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 99.47, Test_acc 30.51
2025-02-14 23:41:56,585 [podnet.py] => Task 14, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 99.73, Test_acc 30.55
2025-02-14 23:41:57,997 [podnet.py] => Task 14, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 99.53, Test_acc 30.43
2025-02-14 23:41:59,488 [podnet.py] => Task 14, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 1.02, Flat_loss 0.10, Train_acc 99.20, Test_acc 30.29
2025-02-14 23:42:00,927 [podnet.py] => Task 14, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 99.27, Test_acc 30.36
2025-02-14 23:42:02,401 [podnet.py] => Task 14, Epoch 20/20 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 1.07, Flat_loss 0.10, Train_acc 99.27, Test_acc 30.24
2025-02-14 23:42:02,402 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:42:30,898 [podnet.py] => Exemplar size: 1500
2025-02-14 23:42:30,898 [trainer.py] => CNN: {'total': 30.24, '00-09': 35.9, '10-19': 9.9, '20-29': 20.1, '30-39': 17.3, '40-49': 36.2, '50-59': 27.5, '60-69': 46.4, '70-79': 67.0, 'old': 27.61, 'new': 67.0}
2025-02-14 23:42:30,898 [trainer.py] => NME: {'total': 30.08, '00-09': 42.0, '10-19': 10.7, '20-29': 19.4, '30-39': 16.5, '40-49': 35.4, '50-59': 26.9, '60-69': 43.3, '70-79': 62.8, 'old': 27.74, 'new': 62.8}
2025-02-14 23:42:30,898 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24]
2025-02-14 23:42:30,898 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85]
2025-02-14 23:42:30,898 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08]
2025-02-14 23:42:30,898 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49]

2025-02-14 23:42:30,898 [trainer.py] => Average Accuracy (CNN): 45.874
2025-02-14 23:42:30,899 [trainer.py] => Average Accuracy (NME): 45.273999999999994
2025-02-14 23:42:30,899 [trainer.py] => All params: 514257
2025-02-14 23:42:30,899 [trainer.py] => Trainable params: 514257
2025-02-14 23:42:30,900 [podnet.py] => Learning on 75-80
2025-02-14 23:42:30,930 [podnet.py] => Adaptive factor: 4.0
2025-02-14 23:42:32,976 [podnet.py] => Task 15, Epoch 1/160 (LR 0.09999) => LSC_loss 2.94, Spatial_loss 3.50, Flat_loss 1.44, Train_acc 46.15, Test_acc 15.69
2025-02-14 23:42:35,041 [podnet.py] => Task 15, Epoch 2/160 (LR 0.09996) => LSC_loss 1.54, Spatial_loss 3.00, Flat_loss 0.81, Train_acc 61.10, Test_acc 17.01
2025-02-14 23:42:37,091 [podnet.py] => Task 15, Epoch 3/160 (LR 0.09991) => LSC_loss 1.33, Spatial_loss 2.93, Flat_loss 0.66, Train_acc 65.05, Test_acc 18.38
2025-02-14 23:42:39,161 [podnet.py] => Task 15, Epoch 4/160 (LR 0.09985) => LSC_loss 1.20, Spatial_loss 2.76, Flat_loss 0.60, Train_acc 68.65, Test_acc 18.01
2025-02-14 23:42:41,195 [podnet.py] => Task 15, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 2.84, Flat_loss 0.59, Train_acc 67.58, Test_acc 16.30
2025-02-14 23:42:43,273 [podnet.py] => Task 15, Epoch 6/160 (LR 0.09965) => LSC_loss 1.17, Spatial_loss 2.76, Flat_loss 0.55, Train_acc 70.05, Test_acc 20.10
2025-02-14 23:42:45,299 [podnet.py] => Task 15, Epoch 7/160 (LR 0.09953) => LSC_loss 1.08, Spatial_loss 2.72, Flat_loss 0.53, Train_acc 72.45, Test_acc 21.22
2025-02-14 23:42:47,414 [podnet.py] => Task 15, Epoch 8/160 (LR 0.09938) => LSC_loss 1.08, Spatial_loss 2.71, Flat_loss 0.52, Train_acc 70.88, Test_acc 21.11
2025-02-14 23:42:49,477 [podnet.py] => Task 15, Epoch 9/160 (LR 0.09922) => LSC_loss 1.00, Spatial_loss 2.76, Flat_loss 0.51, Train_acc 75.05, Test_acc 18.55
2025-02-14 23:42:51,524 [podnet.py] => Task 15, Epoch 10/160 (LR 0.09904) => LSC_loss 0.97, Spatial_loss 2.63, Flat_loss 0.49, Train_acc 74.90, Test_acc 21.04
2025-02-14 23:42:53,585 [podnet.py] => Task 15, Epoch 11/160 (LR 0.09884) => LSC_loss 0.97, Spatial_loss 2.61, Flat_loss 0.50, Train_acc 75.22, Test_acc 18.02
2025-02-14 23:42:55,627 [podnet.py] => Task 15, Epoch 12/160 (LR 0.09862) => LSC_loss 0.95, Spatial_loss 2.55, Flat_loss 0.51, Train_acc 74.70, Test_acc 19.59
2025-02-14 23:42:57,740 [podnet.py] => Task 15, Epoch 13/160 (LR 0.09838) => LSC_loss 0.92, Spatial_loss 2.53, Flat_loss 0.48, Train_acc 76.18, Test_acc 22.25
2025-02-14 23:42:59,739 [podnet.py] => Task 15, Epoch 14/160 (LR 0.09812) => LSC_loss 0.87, Spatial_loss 2.50, Flat_loss 0.47, Train_acc 77.88, Test_acc 20.38
2025-02-14 23:43:01,830 [podnet.py] => Task 15, Epoch 15/160 (LR 0.09785) => LSC_loss 0.84, Spatial_loss 2.52, Flat_loss 0.47, Train_acc 78.03, Test_acc 19.99
2025-02-14 23:43:03,820 [podnet.py] => Task 15, Epoch 16/160 (LR 0.09755) => LSC_loss 0.82, Spatial_loss 2.49, Flat_loss 0.46, Train_acc 78.92, Test_acc 18.19
2025-02-14 23:43:05,881 [podnet.py] => Task 15, Epoch 17/160 (LR 0.09724) => LSC_loss 0.84, Spatial_loss 2.51, Flat_loss 0.46, Train_acc 78.65, Test_acc 16.04
2025-02-14 23:43:07,913 [podnet.py] => Task 15, Epoch 18/160 (LR 0.09691) => LSC_loss 0.88, Spatial_loss 2.66, Flat_loss 0.49, Train_acc 77.38, Test_acc 18.55
2025-02-14 23:43:09,935 [podnet.py] => Task 15, Epoch 19/160 (LR 0.09656) => LSC_loss 0.83, Spatial_loss 2.54, Flat_loss 0.46, Train_acc 78.72, Test_acc 20.85
2025-02-14 23:43:12,004 [podnet.py] => Task 15, Epoch 20/160 (LR 0.09619) => LSC_loss 0.79, Spatial_loss 2.54, Flat_loss 0.46, Train_acc 79.72, Test_acc 23.05
2025-02-14 23:43:14,097 [podnet.py] => Task 15, Epoch 21/160 (LR 0.09581) => LSC_loss 0.72, Spatial_loss 2.40, Flat_loss 0.44, Train_acc 82.20, Test_acc 19.65
2025-02-14 23:43:16,119 [podnet.py] => Task 15, Epoch 22/160 (LR 0.09541) => LSC_loss 0.75, Spatial_loss 2.42, Flat_loss 0.44, Train_acc 81.53, Test_acc 19.02
2025-02-14 23:43:18,164 [podnet.py] => Task 15, Epoch 23/160 (LR 0.09499) => LSC_loss 0.76, Spatial_loss 2.51, Flat_loss 0.46, Train_acc 80.55, Test_acc 20.04
2025-02-14 23:43:20,192 [podnet.py] => Task 15, Epoch 24/160 (LR 0.09455) => LSC_loss 0.76, Spatial_loss 2.44, Flat_loss 0.46, Train_acc 80.10, Test_acc 20.71
2025-02-14 23:43:22,216 [podnet.py] => Task 15, Epoch 25/160 (LR 0.09410) => LSC_loss 0.75, Spatial_loss 2.50, Flat_loss 0.45, Train_acc 81.22, Test_acc 22.41
2025-02-14 23:43:24,256 [podnet.py] => Task 15, Epoch 26/160 (LR 0.09362) => LSC_loss 0.73, Spatial_loss 2.46, Flat_loss 0.44, Train_acc 81.80, Test_acc 21.68
2025-02-14 23:43:26,249 [podnet.py] => Task 15, Epoch 27/160 (LR 0.09314) => LSC_loss 0.74, Spatial_loss 2.35, Flat_loss 0.44, Train_acc 81.40, Test_acc 20.20
2025-02-14 23:43:28,275 [podnet.py] => Task 15, Epoch 28/160 (LR 0.09263) => LSC_loss 0.67, Spatial_loss 2.39, Flat_loss 0.44, Train_acc 83.65, Test_acc 20.96
2025-02-14 23:43:30,266 [podnet.py] => Task 15, Epoch 29/160 (LR 0.09211) => LSC_loss 0.68, Spatial_loss 2.35, Flat_loss 0.44, Train_acc 83.52, Test_acc 14.05
2025-02-14 23:43:32,333 [podnet.py] => Task 15, Epoch 30/160 (LR 0.09157) => LSC_loss 0.67, Spatial_loss 2.39, Flat_loss 0.44, Train_acc 83.88, Test_acc 21.52
2025-02-14 23:43:34,406 [podnet.py] => Task 15, Epoch 31/160 (LR 0.09102) => LSC_loss 0.74, Spatial_loss 2.39, Flat_loss 0.46, Train_acc 81.40, Test_acc 18.82
2025-02-14 23:43:36,438 [podnet.py] => Task 15, Epoch 32/160 (LR 0.09045) => LSC_loss 0.70, Spatial_loss 2.43, Flat_loss 0.45, Train_acc 82.28, Test_acc 23.89
2025-02-14 23:43:38,505 [podnet.py] => Task 15, Epoch 33/160 (LR 0.08987) => LSC_loss 0.70, Spatial_loss 2.38, Flat_loss 0.44, Train_acc 82.72, Test_acc 18.14
2025-02-14 23:43:40,571 [podnet.py] => Task 15, Epoch 34/160 (LR 0.08927) => LSC_loss 0.73, Spatial_loss 2.52, Flat_loss 0.46, Train_acc 81.53, Test_acc 21.61
2025-02-14 23:43:42,592 [podnet.py] => Task 15, Epoch 35/160 (LR 0.08865) => LSC_loss 0.67, Spatial_loss 2.41, Flat_loss 0.44, Train_acc 83.15, Test_acc 23.34
2025-02-14 23:43:44,602 [podnet.py] => Task 15, Epoch 36/160 (LR 0.08802) => LSC_loss 0.61, Spatial_loss 2.25, Flat_loss 0.42, Train_acc 85.68, Test_acc 19.14
2025-02-14 23:43:46,639 [podnet.py] => Task 15, Epoch 37/160 (LR 0.08738) => LSC_loss 0.65, Spatial_loss 2.28, Flat_loss 0.42, Train_acc 83.20, Test_acc 23.85
2025-02-14 23:43:48,643 [podnet.py] => Task 15, Epoch 38/160 (LR 0.08672) => LSC_loss 0.60, Spatial_loss 2.27, Flat_loss 0.42, Train_acc 85.35, Test_acc 21.81
2025-02-14 23:43:50,667 [podnet.py] => Task 15, Epoch 39/160 (LR 0.08604) => LSC_loss 0.56, Spatial_loss 2.29, Flat_loss 0.42, Train_acc 86.68, Test_acc 23.81
2025-02-14 23:43:52,760 [podnet.py] => Task 15, Epoch 40/160 (LR 0.08536) => LSC_loss 0.61, Spatial_loss 2.28, Flat_loss 0.42, Train_acc 85.20, Test_acc 25.51
2025-02-14 23:43:54,819 [podnet.py] => Task 15, Epoch 41/160 (LR 0.08465) => LSC_loss 0.66, Spatial_loss 2.36, Flat_loss 0.43, Train_acc 83.62, Test_acc 21.88
2025-02-14 23:43:56,790 [podnet.py] => Task 15, Epoch 42/160 (LR 0.08394) => LSC_loss 0.56, Spatial_loss 2.23, Flat_loss 0.41, Train_acc 86.58, Test_acc 21.46
2025-02-14 23:43:58,820 [podnet.py] => Task 15, Epoch 43/160 (LR 0.08321) => LSC_loss 0.58, Spatial_loss 2.33, Flat_loss 0.42, Train_acc 85.62, Test_acc 21.22
2025-02-14 23:44:00,818 [podnet.py] => Task 15, Epoch 44/160 (LR 0.08247) => LSC_loss 0.59, Spatial_loss 2.29, Flat_loss 0.42, Train_acc 85.70, Test_acc 21.65
2025-02-14 23:44:02,805 [podnet.py] => Task 15, Epoch 45/160 (LR 0.08172) => LSC_loss 0.59, Spatial_loss 2.34, Flat_loss 0.42, Train_acc 85.88, Test_acc 21.88
2025-02-14 23:44:04,764 [podnet.py] => Task 15, Epoch 46/160 (LR 0.08095) => LSC_loss 0.58, Spatial_loss 2.21, Flat_loss 0.42, Train_acc 85.88, Test_acc 24.00
2025-02-14 23:44:06,789 [podnet.py] => Task 15, Epoch 47/160 (LR 0.08018) => LSC_loss 0.59, Spatial_loss 2.35, Flat_loss 0.43, Train_acc 85.40, Test_acc 21.61
2025-02-14 23:44:08,853 [podnet.py] => Task 15, Epoch 48/160 (LR 0.07939) => LSC_loss 0.53, Spatial_loss 2.19, Flat_loss 0.40, Train_acc 86.92, Test_acc 21.60
2025-02-14 23:44:10,879 [podnet.py] => Task 15, Epoch 49/160 (LR 0.07859) => LSC_loss 0.58, Spatial_loss 2.28, Flat_loss 0.41, Train_acc 85.82, Test_acc 22.74
2025-02-14 23:44:12,945 [podnet.py] => Task 15, Epoch 50/160 (LR 0.07778) => LSC_loss 0.54, Spatial_loss 2.09, Flat_loss 0.39, Train_acc 88.00, Test_acc 19.65
2025-02-14 23:44:14,989 [podnet.py] => Task 15, Epoch 51/160 (LR 0.07696) => LSC_loss 0.58, Spatial_loss 2.16, Flat_loss 0.41, Train_acc 86.28, Test_acc 23.26
2025-02-14 23:44:17,011 [podnet.py] => Task 15, Epoch 52/160 (LR 0.07612) => LSC_loss 0.56, Spatial_loss 2.18, Flat_loss 0.42, Train_acc 86.15, Test_acc 19.15
2025-02-14 23:44:19,063 [podnet.py] => Task 15, Epoch 53/160 (LR 0.07528) => LSC_loss 0.57, Spatial_loss 2.23, Flat_loss 0.42, Train_acc 85.90, Test_acc 26.25
2025-02-14 23:44:21,153 [podnet.py] => Task 15, Epoch 54/160 (LR 0.07443) => LSC_loss 0.54, Spatial_loss 2.23, Flat_loss 0.41, Train_acc 87.22, Test_acc 21.32
2025-02-14 23:44:23,218 [podnet.py] => Task 15, Epoch 55/160 (LR 0.07357) => LSC_loss 0.51, Spatial_loss 2.15, Flat_loss 0.40, Train_acc 88.08, Test_acc 23.72
2025-02-14 23:44:25,236 [podnet.py] => Task 15, Epoch 56/160 (LR 0.07270) => LSC_loss 0.52, Spatial_loss 2.26, Flat_loss 0.41, Train_acc 87.00, Test_acc 21.95
2025-02-14 23:44:27,247 [podnet.py] => Task 15, Epoch 57/160 (LR 0.07182) => LSC_loss 0.52, Spatial_loss 2.19, Flat_loss 0.41, Train_acc 86.70, Test_acc 26.34
2025-02-14 23:44:29,262 [podnet.py] => Task 15, Epoch 58/160 (LR 0.07093) => LSC_loss 0.51, Spatial_loss 2.18, Flat_loss 0.40, Train_acc 88.40, Test_acc 27.06
2025-02-14 23:44:31,339 [podnet.py] => Task 15, Epoch 59/160 (LR 0.07004) => LSC_loss 0.51, Spatial_loss 2.11, Flat_loss 0.40, Train_acc 87.70, Test_acc 25.12
2025-02-14 23:44:33,409 [podnet.py] => Task 15, Epoch 60/160 (LR 0.06913) => LSC_loss 0.48, Spatial_loss 2.08, Flat_loss 0.39, Train_acc 88.50, Test_acc 24.08
2025-02-14 23:44:35,430 [podnet.py] => Task 15, Epoch 61/160 (LR 0.06822) => LSC_loss 0.46, Spatial_loss 2.12, Flat_loss 0.39, Train_acc 89.30, Test_acc 23.72
2025-02-14 23:44:37,421 [podnet.py] => Task 15, Epoch 62/160 (LR 0.06731) => LSC_loss 0.43, Spatial_loss 2.01, Flat_loss 0.37, Train_acc 90.35, Test_acc 26.25
2025-02-14 23:44:39,509 [podnet.py] => Task 15, Epoch 63/160 (LR 0.06638) => LSC_loss 0.45, Spatial_loss 1.97, Flat_loss 0.37, Train_acc 89.30, Test_acc 24.50
2025-02-14 23:44:41,641 [podnet.py] => Task 15, Epoch 64/160 (LR 0.06545) => LSC_loss 0.44, Spatial_loss 2.03, Flat_loss 0.38, Train_acc 90.05, Test_acc 25.70
2025-02-14 23:44:43,713 [podnet.py] => Task 15, Epoch 65/160 (LR 0.06451) => LSC_loss 0.46, Spatial_loss 2.09, Flat_loss 0.38, Train_acc 89.32, Test_acc 18.68
2025-02-14 23:44:45,736 [podnet.py] => Task 15, Epoch 66/160 (LR 0.06357) => LSC_loss 0.48, Spatial_loss 2.09, Flat_loss 0.40, Train_acc 88.18, Test_acc 21.45
2025-02-14 23:44:47,728 [podnet.py] => Task 15, Epoch 67/160 (LR 0.06262) => LSC_loss 0.48, Spatial_loss 2.00, Flat_loss 0.39, Train_acc 88.70, Test_acc 22.75
2025-02-14 23:44:49,749 [podnet.py] => Task 15, Epoch 68/160 (LR 0.06167) => LSC_loss 0.44, Spatial_loss 2.05, Flat_loss 0.38, Train_acc 89.50, Test_acc 18.82
2025-02-14 23:44:51,791 [podnet.py] => Task 15, Epoch 69/160 (LR 0.06072) => LSC_loss 0.44, Spatial_loss 2.13, Flat_loss 0.38, Train_acc 89.45, Test_acc 24.45
2025-02-14 23:44:53,786 [podnet.py] => Task 15, Epoch 70/160 (LR 0.05975) => LSC_loss 0.44, Spatial_loss 1.99, Flat_loss 0.37, Train_acc 90.38, Test_acc 24.65
2025-02-14 23:44:55,877 [podnet.py] => Task 15, Epoch 71/160 (LR 0.05879) => LSC_loss 0.46, Spatial_loss 2.04, Flat_loss 0.38, Train_acc 89.30, Test_acc 21.51
2025-02-14 23:44:57,967 [podnet.py] => Task 15, Epoch 72/160 (LR 0.05782) => LSC_loss 0.43, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 90.08, Test_acc 20.23
2025-02-14 23:44:59,998 [podnet.py] => Task 15, Epoch 73/160 (LR 0.05685) => LSC_loss 0.42, Spatial_loss 1.91, Flat_loss 0.36, Train_acc 90.50, Test_acc 21.92
2025-02-14 23:45:02,075 [podnet.py] => Task 15, Epoch 74/160 (LR 0.05588) => LSC_loss 0.40, Spatial_loss 1.95, Flat_loss 0.36, Train_acc 91.20, Test_acc 21.24
2025-02-14 23:45:04,154 [podnet.py] => Task 15, Epoch 75/160 (LR 0.05490) => LSC_loss 0.42, Spatial_loss 1.99, Flat_loss 0.38, Train_acc 90.80, Test_acc 25.70
2025-02-14 23:45:06,212 [podnet.py] => Task 15, Epoch 76/160 (LR 0.05392) => LSC_loss 0.41, Spatial_loss 2.03, Flat_loss 0.36, Train_acc 91.12, Test_acc 26.39
2025-02-14 23:45:08,242 [podnet.py] => Task 15, Epoch 77/160 (LR 0.05294) => LSC_loss 0.41, Spatial_loss 1.99, Flat_loss 0.36, Train_acc 91.15, Test_acc 24.05
2025-02-14 23:45:10,264 [podnet.py] => Task 15, Epoch 78/160 (LR 0.05196) => LSC_loss 0.35, Spatial_loss 1.85, Flat_loss 0.34, Train_acc 93.05, Test_acc 24.28
2025-02-14 23:45:12,326 [podnet.py] => Task 15, Epoch 79/160 (LR 0.05098) => LSC_loss 0.34, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 93.92, Test_acc 22.32
2025-02-14 23:45:14,375 [podnet.py] => Task 15, Epoch 80/160 (LR 0.05000) => LSC_loss 0.36, Spatial_loss 1.83, Flat_loss 0.34, Train_acc 92.42, Test_acc 21.26
2025-02-14 23:45:16,428 [podnet.py] => Task 15, Epoch 81/160 (LR 0.04902) => LSC_loss 0.37, Spatial_loss 1.93, Flat_loss 0.35, Train_acc 92.38, Test_acc 24.09
2025-02-14 23:45:18,389 [podnet.py] => Task 15, Epoch 82/160 (LR 0.04804) => LSC_loss 0.38, Spatial_loss 1.88, Flat_loss 0.35, Train_acc 92.20, Test_acc 20.98
2025-02-14 23:45:20,484 [podnet.py] => Task 15, Epoch 83/160 (LR 0.04706) => LSC_loss 0.34, Spatial_loss 1.93, Flat_loss 0.35, Train_acc 92.90, Test_acc 21.35
2025-02-14 23:45:22,528 [podnet.py] => Task 15, Epoch 84/160 (LR 0.04608) => LSC_loss 0.35, Spatial_loss 1.82, Flat_loss 0.34, Train_acc 92.82, Test_acc 23.64
2025-02-14 23:45:24,560 [podnet.py] => Task 15, Epoch 85/160 (LR 0.04510) => LSC_loss 0.34, Spatial_loss 1.84, Flat_loss 0.34, Train_acc 92.78, Test_acc 28.12
2025-02-14 23:45:26,624 [podnet.py] => Task 15, Epoch 86/160 (LR 0.04412) => LSC_loss 0.30, Spatial_loss 1.78, Flat_loss 0.33, Train_acc 94.70, Test_acc 23.71
2025-02-14 23:45:28,645 [podnet.py] => Task 15, Epoch 87/160 (LR 0.04315) => LSC_loss 0.33, Spatial_loss 1.77, Flat_loss 0.33, Train_acc 93.92, Test_acc 24.52
2025-02-14 23:45:30,744 [podnet.py] => Task 15, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.83, Flat_loss 0.33, Train_acc 93.45, Test_acc 23.34
2025-02-14 23:45:32,803 [podnet.py] => Task 15, Epoch 89/160 (LR 0.04121) => LSC_loss 0.31, Spatial_loss 1.70, Flat_loss 0.32, Train_acc 94.65, Test_acc 24.50
2025-02-14 23:45:34,925 [podnet.py] => Task 15, Epoch 90/160 (LR 0.04025) => LSC_loss 0.32, Spatial_loss 1.78, Flat_loss 0.32, Train_acc 93.95, Test_acc 22.36
2025-02-14 23:45:37,041 [podnet.py] => Task 15, Epoch 91/160 (LR 0.03928) => LSC_loss 0.32, Spatial_loss 1.78, Flat_loss 0.33, Train_acc 93.92, Test_acc 23.69
2025-02-14 23:45:39,077 [podnet.py] => Task 15, Epoch 92/160 (LR 0.03833) => LSC_loss 0.31, Spatial_loss 1.74, Flat_loss 0.32, Train_acc 94.00, Test_acc 24.26
2025-02-14 23:45:41,121 [podnet.py] => Task 15, Epoch 93/160 (LR 0.03738) => LSC_loss 0.30, Spatial_loss 1.66, Flat_loss 0.32, Train_acc 94.50, Test_acc 28.00
2025-02-14 23:45:43,180 [podnet.py] => Task 15, Epoch 94/160 (LR 0.03643) => LSC_loss 0.31, Spatial_loss 1.74, Flat_loss 0.31, Train_acc 94.28, Test_acc 19.89
2025-02-14 23:45:45,218 [podnet.py] => Task 15, Epoch 95/160 (LR 0.03549) => LSC_loss 0.29, Spatial_loss 1.76, Flat_loss 0.32, Train_acc 94.18, Test_acc 27.10
2025-02-14 23:45:47,279 [podnet.py] => Task 15, Epoch 96/160 (LR 0.03455) => LSC_loss 0.30, Spatial_loss 1.83, Flat_loss 0.32, Train_acc 94.82, Test_acc 24.01
2025-02-14 23:45:49,384 [podnet.py] => Task 15, Epoch 97/160 (LR 0.03362) => LSC_loss 0.30, Spatial_loss 1.74, Flat_loss 0.32, Train_acc 94.12, Test_acc 22.35
2025-02-14 23:45:51,414 [podnet.py] => Task 15, Epoch 98/160 (LR 0.03269) => LSC_loss 0.32, Spatial_loss 1.81, Flat_loss 0.33, Train_acc 93.98, Test_acc 27.26
2025-02-14 23:45:53,483 [podnet.py] => Task 15, Epoch 99/160 (LR 0.03178) => LSC_loss 0.31, Spatial_loss 1.79, Flat_loss 0.32, Train_acc 94.20, Test_acc 25.00
2025-02-14 23:45:55,596 [podnet.py] => Task 15, Epoch 100/160 (LR 0.03087) => LSC_loss 0.28, Spatial_loss 1.66, Flat_loss 0.31, Train_acc 94.85, Test_acc 24.09
2025-02-14 23:45:57,639 [podnet.py] => Task 15, Epoch 101/160 (LR 0.02996) => LSC_loss 0.27, Spatial_loss 1.67, Flat_loss 0.31, Train_acc 95.25, Test_acc 27.36
2025-02-14 23:45:59,782 [podnet.py] => Task 15, Epoch 102/160 (LR 0.02907) => LSC_loss 0.28, Spatial_loss 1.66, Flat_loss 0.30, Train_acc 95.12, Test_acc 23.34
2025-02-14 23:46:01,804 [podnet.py] => Task 15, Epoch 103/160 (LR 0.02818) => LSC_loss 0.28, Spatial_loss 1.68, Flat_loss 0.31, Train_acc 94.60, Test_acc 24.29
2025-02-14 23:46:03,796 [podnet.py] => Task 15, Epoch 104/160 (LR 0.02730) => LSC_loss 0.26, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 95.65, Test_acc 26.09
2025-02-14 23:46:05,874 [podnet.py] => Task 15, Epoch 105/160 (LR 0.02643) => LSC_loss 0.25, Spatial_loss 1.63, Flat_loss 0.30, Train_acc 95.65, Test_acc 23.10
2025-02-14 23:46:07,974 [podnet.py] => Task 15, Epoch 106/160 (LR 0.02557) => LSC_loss 0.25, Spatial_loss 1.60, Flat_loss 0.29, Train_acc 95.90, Test_acc 24.46
2025-02-14 23:46:10,052 [podnet.py] => Task 15, Epoch 107/160 (LR 0.02472) => LSC_loss 0.26, Spatial_loss 1.59, Flat_loss 0.29, Train_acc 96.00, Test_acc 24.91
2025-02-14 23:46:12,059 [podnet.py] => Task 15, Epoch 108/160 (LR 0.02388) => LSC_loss 0.27, Spatial_loss 1.60, Flat_loss 0.31, Train_acc 95.35, Test_acc 26.45
2025-02-14 23:46:14,141 [podnet.py] => Task 15, Epoch 109/160 (LR 0.02304) => LSC_loss 0.26, Spatial_loss 1.53, Flat_loss 0.29, Train_acc 95.95, Test_acc 22.36
2025-02-14 23:46:16,204 [podnet.py] => Task 15, Epoch 110/160 (LR 0.02222) => LSC_loss 0.25, Spatial_loss 1.55, Flat_loss 0.29, Train_acc 96.00, Test_acc 25.38
2025-02-14 23:46:18,266 [podnet.py] => Task 15, Epoch 111/160 (LR 0.02141) => LSC_loss 0.24, Spatial_loss 1.49, Flat_loss 0.28, Train_acc 96.28, Test_acc 23.89
2025-02-14 23:46:20,274 [podnet.py] => Task 15, Epoch 112/160 (LR 0.02061) => LSC_loss 0.23, Spatial_loss 1.49, Flat_loss 0.29, Train_acc 96.98, Test_acc 24.92
2025-02-14 23:46:22,371 [podnet.py] => Task 15, Epoch 113/160 (LR 0.01982) => LSC_loss 0.24, Spatial_loss 1.55, Flat_loss 0.28, Train_acc 96.60, Test_acc 24.91
2025-02-14 23:46:24,416 [podnet.py] => Task 15, Epoch 114/160 (LR 0.01905) => LSC_loss 0.24, Spatial_loss 1.57, Flat_loss 0.28, Train_acc 96.60, Test_acc 25.92
2025-02-14 23:46:26,406 [podnet.py] => Task 15, Epoch 115/160 (LR 0.01828) => LSC_loss 0.24, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 96.25, Test_acc 25.75
2025-02-14 23:46:28,427 [podnet.py] => Task 15, Epoch 116/160 (LR 0.01753) => LSC_loss 0.23, Spatial_loss 1.40, Flat_loss 0.28, Train_acc 96.80, Test_acc 25.74
2025-02-14 23:46:30,447 [podnet.py] => Task 15, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 1.43, Flat_loss 0.27, Train_acc 97.02, Test_acc 26.00
2025-02-14 23:46:32,546 [podnet.py] => Task 15, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 1.39, Flat_loss 0.27, Train_acc 97.00, Test_acc 24.38
2025-02-14 23:46:34,570 [podnet.py] => Task 15, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 1.43, Flat_loss 0.27, Train_acc 97.30, Test_acc 24.42
2025-02-14 23:46:36,680 [podnet.py] => Task 15, Epoch 120/160 (LR 0.01464) => LSC_loss 0.22, Spatial_loss 1.37, Flat_loss 0.27, Train_acc 96.92, Test_acc 24.42
2025-02-14 23:46:38,702 [podnet.py] => Task 15, Epoch 121/160 (LR 0.01396) => LSC_loss 0.22, Spatial_loss 1.38, Flat_loss 0.27, Train_acc 97.08, Test_acc 25.10
2025-02-14 23:46:40,787 [podnet.py] => Task 15, Epoch 122/160 (LR 0.01328) => LSC_loss 0.22, Spatial_loss 1.38, Flat_loss 0.27, Train_acc 97.12, Test_acc 25.95
2025-02-14 23:46:42,853 [podnet.py] => Task 15, Epoch 123/160 (LR 0.01262) => LSC_loss 0.21, Spatial_loss 1.33, Flat_loss 0.26, Train_acc 97.25, Test_acc 26.29
2025-02-14 23:46:44,874 [podnet.py] => Task 15, Epoch 124/160 (LR 0.01198) => LSC_loss 0.21, Spatial_loss 1.37, Flat_loss 0.26, Train_acc 97.08, Test_acc 25.55
2025-02-14 23:46:46,940 [podnet.py] => Task 15, Epoch 125/160 (LR 0.01135) => LSC_loss 0.21, Spatial_loss 1.38, Flat_loss 0.26, Train_acc 97.28, Test_acc 26.92
2025-02-14 23:46:49,053 [podnet.py] => Task 15, Epoch 126/160 (LR 0.01073) => LSC_loss 0.21, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 97.58, Test_acc 26.55
2025-02-14 23:46:51,060 [podnet.py] => Task 15, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 1.34, Flat_loss 0.26, Train_acc 97.30, Test_acc 25.52
2025-02-14 23:46:53,143 [podnet.py] => Task 15, Epoch 128/160 (LR 0.00955) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.26, Train_acc 97.75, Test_acc 27.20
2025-02-14 23:46:55,158 [podnet.py] => Task 15, Epoch 129/160 (LR 0.00898) => LSC_loss 0.21, Spatial_loss 1.33, Flat_loss 0.26, Train_acc 97.95, Test_acc 26.42
2025-02-14 23:46:57,180 [podnet.py] => Task 15, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.26, Train_acc 97.20, Test_acc 25.79
2025-02-14 23:46:59,253 [podnet.py] => Task 15, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 97.02, Test_acc 25.22
2025-02-14 23:47:01,348 [podnet.py] => Task 15, Epoch 132/160 (LR 0.00737) => LSC_loss 0.20, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 97.98, Test_acc 25.04
2025-02-14 23:47:03,368 [podnet.py] => Task 15, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.29, Flat_loss 0.25, Train_acc 97.62, Test_acc 25.26
2025-02-14 23:47:05,438 [podnet.py] => Task 15, Epoch 134/160 (LR 0.00638) => LSC_loss 0.20, Spatial_loss 1.23, Flat_loss 0.25, Train_acc 97.58, Test_acc 26.96
2025-02-14 23:47:07,483 [podnet.py] => Task 15, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.29, Flat_loss 0.25, Train_acc 97.58, Test_acc 25.72
2025-02-14 23:47:09,543 [podnet.py] => Task 15, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.24, Flat_loss 0.25, Train_acc 97.58, Test_acc 25.96
2025-02-14 23:47:11,646 [podnet.py] => Task 15, Epoch 137/160 (LR 0.00501) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.26, Train_acc 97.75, Test_acc 25.95
2025-02-14 23:47:13,740 [podnet.py] => Task 15, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 97.45, Test_acc 26.30
2025-02-14 23:47:15,752 [podnet.py] => Task 15, Epoch 139/160 (LR 0.00419) => LSC_loss 0.20, Spatial_loss 1.23, Flat_loss 0.25, Train_acc 97.88, Test_acc 25.79
2025-02-14 23:47:17,809 [podnet.py] => Task 15, Epoch 140/160 (LR 0.00381) => LSC_loss 0.19, Spatial_loss 1.28, Flat_loss 0.25, Train_acc 98.08, Test_acc 26.29
2025-02-14 23:47:19,873 [podnet.py] => Task 15, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.23, Flat_loss 0.24, Train_acc 97.42, Test_acc 25.11
2025-02-14 23:47:21,975 [podnet.py] => Task 15, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.22, Flat_loss 0.25, Train_acc 97.95, Test_acc 26.08
2025-02-14 23:47:24,060 [podnet.py] => Task 15, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 97.92, Test_acc 26.41
2025-02-14 23:47:26,086 [podnet.py] => Task 15, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 97.88, Test_acc 26.56
2025-02-14 23:47:28,134 [podnet.py] => Task 15, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.22, Flat_loss 0.24, Train_acc 98.22, Test_acc 26.24
2025-02-14 23:47:30,209 [podnet.py] => Task 15, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.20, Flat_loss 0.24, Train_acc 98.22, Test_acc 26.35
2025-02-14 23:47:32,255 [podnet.py] => Task 15, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 98.28, Test_acc 26.61
2025-02-14 23:47:34,230 [podnet.py] => Task 15, Epoch 148/160 (LR 0.00138) => LSC_loss 0.18, Spatial_loss 1.15, Flat_loss 0.24, Train_acc 98.38, Test_acc 26.20
2025-02-14 23:47:36,324 [podnet.py] => Task 15, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.24, Train_acc 97.85, Test_acc 26.24
2025-02-14 23:47:38,449 [podnet.py] => Task 15, Epoch 150/160 (LR 0.00096) => LSC_loss 0.18, Spatial_loss 1.17, Flat_loss 0.24, Train_acc 98.35, Test_acc 26.60
2025-02-14 23:47:40,511 [podnet.py] => Task 15, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.24, Train_acc 97.92, Test_acc 26.36
2025-02-14 23:47:42,524 [podnet.py] => Task 15, Epoch 152/160 (LR 0.00062) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.24, Train_acc 98.20, Test_acc 26.22
2025-02-14 23:47:44,585 [podnet.py] => Task 15, Epoch 153/160 (LR 0.00047) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.24, Train_acc 97.98, Test_acc 26.24
2025-02-14 23:47:46,634 [podnet.py] => Task 15, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.24, Train_acc 98.20, Test_acc 26.54
2025-02-14 23:47:48,693 [podnet.py] => Task 15, Epoch 155/160 (LR 0.00024) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 97.82, Test_acc 26.31
2025-02-14 23:47:50,656 [podnet.py] => Task 15, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.24, Train_acc 98.10, Test_acc 26.20
2025-02-14 23:47:52,753 [podnet.py] => Task 15, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.12, Flat_loss 0.24, Train_acc 98.18, Test_acc 26.32
2025-02-14 23:47:54,777 [podnet.py] => Task 15, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.24, Train_acc 98.20, Test_acc 26.50
2025-02-14 23:47:56,907 [podnet.py] => Task 15, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 98.08, Test_acc 25.99
2025-02-14 23:47:58,989 [podnet.py] => Task 15, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 98.00, Test_acc 26.30
2025-02-14 23:47:58,990 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:47:58,990 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:48:27,132 [podnet.py] => The size of finetune dataset: 1600
2025-02-14 23:48:28,633 [podnet.py] => Task 15, Epoch 1/20 (LR 0.00497) => LSC_loss 0.31, Spatial_loss 1.61, Flat_loss 0.20, Train_acc 93.44, Test_acc 26.19
2025-02-14 23:48:30,150 [podnet.py] => Task 15, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 1.34, Flat_loss 0.14, Train_acc 98.69, Test_acc 30.29
2025-02-14 23:48:31,625 [podnet.py] => Task 15, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 1.27, Flat_loss 0.12, Train_acc 98.50, Test_acc 28.66
2025-02-14 23:48:33,121 [podnet.py] => Task 15, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.38, Test_acc 28.22
2025-02-14 23:48:34,601 [podnet.py] => Task 15, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 99.19, Test_acc 28.18
2025-02-14 23:48:36,060 [podnet.py] => Task 15, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 1.14, Flat_loss 0.11, Train_acc 99.19, Test_acc 28.50
2025-02-14 23:48:37,572 [podnet.py] => Task 15, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.31, Test_acc 28.96
2025-02-14 23:48:39,092 [podnet.py] => Task 15, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 1.14, Flat_loss 0.10, Train_acc 99.12, Test_acc 28.39
2025-02-14 23:48:40,607 [podnet.py] => Task 15, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 1.14, Flat_loss 0.11, Train_acc 98.94, Test_acc 28.69
2025-02-14 23:48:42,095 [podnet.py] => Task 15, Epoch 10/20 (LR 0.00250) => LSC_loss 0.13, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 98.94, Test_acc 28.25
2025-02-14 23:48:43,643 [podnet.py] => Task 15, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 1.14, Flat_loss 0.10, Train_acc 99.25, Test_acc 28.61
2025-02-14 23:48:45,105 [podnet.py] => Task 15, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.11, Flat_loss 0.10, Train_acc 99.50, Test_acc 28.76
2025-02-14 23:48:46,638 [podnet.py] => Task 15, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 99.31, Test_acc 28.65
2025-02-14 23:48:48,151 [podnet.py] => Task 15, Epoch 14/20 (LR 0.00103) => LSC_loss 0.13, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 99.25, Test_acc 28.59
2025-02-14 23:48:49,654 [podnet.py] => Task 15, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.44, Test_acc 28.91
2025-02-14 23:48:51,164 [podnet.py] => Task 15, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 98.81, Test_acc 28.64
2025-02-14 23:48:52,621 [podnet.py] => Task 15, Epoch 17/20 (LR 0.00027) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 99.19, Test_acc 28.76
2025-02-14 23:48:54,045 [podnet.py] => Task 15, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 1.07, Flat_loss 0.10, Train_acc 99.44, Test_acc 28.68
2025-02-14 23:48:55,536 [podnet.py] => Task 15, Epoch 19/20 (LR 0.00003) => LSC_loss 0.13, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 99.44, Test_acc 28.72
2025-02-14 23:48:57,076 [podnet.py] => Task 15, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 1.07, Flat_loss 0.10, Train_acc 99.38, Test_acc 28.70
2025-02-14 23:48:57,079 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:49:27,008 [podnet.py] => Exemplar size: 1600
2025-02-14 23:49:27,008 [trainer.py] => CNN: {'total': 28.7, '00-09': 33.8, '10-19': 11.1, '20-29': 20.0, '30-39': 15.3, '40-49': 30.3, '50-59': 18.7, '60-69': 41.1, '70-79': 59.3, 'old': 26.28, 'new': 65.0}
2025-02-14 23:49:27,008 [trainer.py] => NME: {'total': 28.69, '00-09': 41.6, '10-19': 10.9, '20-29': 18.4, '30-39': 16.0, '40-49': 31.8, '50-59': 20.0, '60-69': 36.9, '70-79': 53.9, 'old': 26.68, 'new': 58.8}
2025-02-14 23:49:27,008 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24, 28.7]
2025-02-14 23:49:27,009 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85, 55.0]
2025-02-14 23:49:27,009 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08, 28.69]
2025-02-14 23:49:27,009 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49, 55.08]

2025-02-14 23:49:27,009 [trainer.py] => Average Accuracy (CNN): 44.800625000000004
2025-02-14 23:49:27,009 [trainer.py] => Average Accuracy (NME): 44.2375
2025-02-14 23:49:27,009 [trainer.py] => All params: 517457
2025-02-14 23:49:27,009 [trainer.py] => Trainable params: 517457
2025-02-14 23:49:27,010 [podnet.py] => Learning on 80-85
2025-02-14 23:49:27,041 [podnet.py] => Adaptive factor: 4.123105625617661
2025-02-14 23:49:29,143 [podnet.py] => Task 16, Epoch 1/160 (LR 0.09999) => LSC_loss 2.84, Spatial_loss 3.52, Flat_loss 1.42, Train_acc 48.66, Test_acc 14.39
2025-02-14 23:49:31,259 [podnet.py] => Task 16, Epoch 2/160 (LR 0.09996) => LSC_loss 1.76, Spatial_loss 3.82, Flat_loss 0.92, Train_acc 57.73, Test_acc 13.14
2025-02-14 23:49:33,433 [podnet.py] => Task 16, Epoch 3/160 (LR 0.09991) => LSC_loss 1.67, Spatial_loss 3.32, Flat_loss 0.76, Train_acc 61.73, Test_acc 13.61
2025-02-14 23:49:35,482 [podnet.py] => Task 16, Epoch 4/160 (LR 0.09985) => LSC_loss 2.00, Spatial_loss 4.05, Flat_loss 0.97, Train_acc 53.68, Test_acc 15.31
2025-02-14 23:49:37,669 [podnet.py] => Task 16, Epoch 5/160 (LR 0.09976) => LSC_loss 1.63, Spatial_loss 3.25, Flat_loss 0.79, Train_acc 59.83, Test_acc 19.06
2025-02-14 23:49:39,770 [podnet.py] => Task 16, Epoch 6/160 (LR 0.09965) => LSC_loss 1.35, Spatial_loss 2.86, Flat_loss 0.64, Train_acc 66.29, Test_acc 14.49
2025-02-14 23:49:41,869 [podnet.py] => Task 16, Epoch 7/160 (LR 0.09953) => LSC_loss 1.61, Spatial_loss 3.20, Flat_loss 0.74, Train_acc 60.39, Test_acc 19.88
2025-02-14 23:49:43,939 [podnet.py] => Task 16, Epoch 8/160 (LR 0.09938) => LSC_loss 1.54, Spatial_loss 3.11, Flat_loss 0.71, Train_acc 61.32, Test_acc 17.27
2025-02-14 23:49:46,068 [podnet.py] => Task 16, Epoch 9/160 (LR 0.09922) => LSC_loss 1.52, Spatial_loss 3.05, Flat_loss 0.71, Train_acc 63.56, Test_acc 16.06
2025-02-14 23:49:48,228 [podnet.py] => Task 16, Epoch 10/160 (LR 0.09904) => LSC_loss 1.59, Spatial_loss 3.29, Flat_loss 0.74, Train_acc 62.78, Test_acc 16.89
2025-02-14 23:49:50,286 [podnet.py] => Task 16, Epoch 11/160 (LR 0.09884) => LSC_loss 1.50, Spatial_loss 3.15, Flat_loss 0.71, Train_acc 63.88, Test_acc 19.18
2025-02-14 23:49:52,388 [podnet.py] => Task 16, Epoch 12/160 (LR 0.09862) => LSC_loss 1.57, Spatial_loss 3.35, Flat_loss 0.74, Train_acc 61.90, Test_acc 19.29
2025-02-14 23:49:54,501 [podnet.py] => Task 16, Epoch 13/160 (LR 0.09838) => LSC_loss 1.44, Spatial_loss 3.10, Flat_loss 0.68, Train_acc 64.76, Test_acc 19.79
2025-02-14 23:49:56,597 [podnet.py] => Task 16, Epoch 14/160 (LR 0.09812) => LSC_loss 1.39, Spatial_loss 3.24, Flat_loss 0.67, Train_acc 65.54, Test_acc 19.48
2025-02-14 23:49:58,725 [podnet.py] => Task 16, Epoch 15/160 (LR 0.09785) => LSC_loss 1.35, Spatial_loss 2.97, Flat_loss 0.65, Train_acc 66.85, Test_acc 17.80
2025-02-14 23:50:00,831 [podnet.py] => Task 16, Epoch 16/160 (LR 0.09755) => LSC_loss 1.47, Spatial_loss 3.28, Flat_loss 0.74, Train_acc 63.12, Test_acc 19.20
2025-02-14 23:50:02,978 [podnet.py] => Task 16, Epoch 17/160 (LR 0.09724) => LSC_loss 1.26, Spatial_loss 2.90, Flat_loss 0.62, Train_acc 70.10, Test_acc 16.45
2025-02-14 23:50:05,065 [podnet.py] => Task 16, Epoch 18/160 (LR 0.09691) => LSC_loss 1.59, Spatial_loss 3.56, Flat_loss 0.80, Train_acc 61.93, Test_acc 15.51
2025-02-14 23:50:07,243 [podnet.py] => Task 16, Epoch 19/160 (LR 0.09656) => LSC_loss 1.32, Spatial_loss 2.89, Flat_loss 0.66, Train_acc 67.98, Test_acc 18.61
2025-02-14 23:50:09,326 [podnet.py] => Task 16, Epoch 20/160 (LR 0.09619) => LSC_loss 1.28, Spatial_loss 2.85, Flat_loss 0.65, Train_acc 68.83, Test_acc 21.14
2025-02-14 23:50:11,489 [podnet.py] => Task 16, Epoch 21/160 (LR 0.09581) => LSC_loss 1.29, Spatial_loss 2.85, Flat_loss 0.65, Train_acc 67.83, Test_acc 23.20
2025-02-14 23:50:13,593 [podnet.py] => Task 16, Epoch 22/160 (LR 0.09541) => LSC_loss 1.20, Spatial_loss 2.85, Flat_loss 0.60, Train_acc 71.20, Test_acc 19.39
2025-02-14 23:50:15,670 [podnet.py] => Task 16, Epoch 23/160 (LR 0.09499) => LSC_loss 1.25, Spatial_loss 3.07, Flat_loss 0.63, Train_acc 69.32, Test_acc 18.75
2025-02-14 23:50:17,785 [podnet.py] => Task 16, Epoch 24/160 (LR 0.09455) => LSC_loss 1.17, Spatial_loss 2.80, Flat_loss 0.59, Train_acc 71.29, Test_acc 16.29
2025-02-14 23:50:19,903 [podnet.py] => Task 16, Epoch 25/160 (LR 0.09410) => LSC_loss 1.26, Spatial_loss 2.99, Flat_loss 0.61, Train_acc 70.07, Test_acc 20.68
2025-02-14 23:50:22,041 [podnet.py] => Task 16, Epoch 26/160 (LR 0.09362) => LSC_loss 1.35, Spatial_loss 2.95, Flat_loss 0.69, Train_acc 66.10, Test_acc 21.11
2025-02-14 23:50:24,152 [podnet.py] => Task 16, Epoch 27/160 (LR 0.09314) => LSC_loss 1.16, Spatial_loss 2.90, Flat_loss 0.60, Train_acc 70.71, Test_acc 20.62
2025-02-14 23:50:26,291 [podnet.py] => Task 16, Epoch 28/160 (LR 0.09263) => LSC_loss 0.97, Spatial_loss 2.54, Flat_loss 0.53, Train_acc 75.56, Test_acc 22.29
2025-02-14 23:50:28,393 [podnet.py] => Task 16, Epoch 29/160 (LR 0.09211) => LSC_loss 0.92, Spatial_loss 2.43, Flat_loss 0.48, Train_acc 78.39, Test_acc 16.71
2025-02-14 23:50:30,505 [podnet.py] => Task 16, Epoch 30/160 (LR 0.09157) => LSC_loss 1.14, Spatial_loss 2.94, Flat_loss 0.62, Train_acc 71.54, Test_acc 22.68
2025-02-14 23:50:32,654 [podnet.py] => Task 16, Epoch 31/160 (LR 0.09102) => LSC_loss 1.10, Spatial_loss 2.74, Flat_loss 0.58, Train_acc 74.37, Test_acc 19.67
2025-02-14 23:50:34,760 [podnet.py] => Task 16, Epoch 32/160 (LR 0.09045) => LSC_loss 1.37, Spatial_loss 3.10, Flat_loss 0.71, Train_acc 66.66, Test_acc 16.85
2025-02-14 23:50:36,869 [podnet.py] => Task 16, Epoch 33/160 (LR 0.08987) => LSC_loss 1.36, Spatial_loss 2.99, Flat_loss 0.68, Train_acc 67.63, Test_acc 20.28
2025-02-14 23:50:38,966 [podnet.py] => Task 16, Epoch 34/160 (LR 0.08927) => LSC_loss 1.36, Spatial_loss 2.86, Flat_loss 0.67, Train_acc 67.29, Test_acc 21.64
2025-02-14 23:50:41,035 [podnet.py] => Task 16, Epoch 35/160 (LR 0.08865) => LSC_loss 1.32, Spatial_loss 3.08, Flat_loss 0.65, Train_acc 67.46, Test_acc 18.73
2025-02-14 23:50:43,168 [podnet.py] => Task 16, Epoch 36/160 (LR 0.08802) => LSC_loss 1.12, Spatial_loss 2.77, Flat_loss 0.59, Train_acc 72.80, Test_acc 20.51
2025-02-14 23:50:45,348 [podnet.py] => Task 16, Epoch 37/160 (LR 0.08738) => LSC_loss 1.07, Spatial_loss 2.69, Flat_loss 0.56, Train_acc 73.56, Test_acc 19.89
2025-02-14 23:50:47,429 [podnet.py] => Task 16, Epoch 38/160 (LR 0.08672) => LSC_loss 1.04, Spatial_loss 2.81, Flat_loss 0.57, Train_acc 76.80, Test_acc 20.21
2025-02-14 23:50:49,501 [podnet.py] => Task 16, Epoch 39/160 (LR 0.08604) => LSC_loss 1.30, Spatial_loss 3.30, Flat_loss 0.66, Train_acc 66.46, Test_acc 21.73
2025-02-14 23:50:51,580 [podnet.py] => Task 16, Epoch 40/160 (LR 0.08536) => LSC_loss 1.01, Spatial_loss 2.67, Flat_loss 0.55, Train_acc 75.76, Test_acc 18.54
2025-02-14 23:50:53,711 [podnet.py] => Task 16, Epoch 41/160 (LR 0.08465) => LSC_loss 1.25, Spatial_loss 3.09, Flat_loss 0.65, Train_acc 70.85, Test_acc 17.14
2025-02-14 23:50:55,764 [podnet.py] => Task 16, Epoch 42/160 (LR 0.08394) => LSC_loss 1.06, Spatial_loss 2.67, Flat_loss 0.57, Train_acc 72.80, Test_acc 23.75
2025-02-14 23:50:57,891 [podnet.py] => Task 16, Epoch 43/160 (LR 0.08321) => LSC_loss 0.83, Spatial_loss 2.54, Flat_loss 0.50, Train_acc 79.78, Test_acc 19.61
2025-02-14 23:51:00,010 [podnet.py] => Task 16, Epoch 44/160 (LR 0.08247) => LSC_loss 0.88, Spatial_loss 2.53, Flat_loss 0.52, Train_acc 77.93, Test_acc 18.73
2025-02-14 23:51:02,140 [podnet.py] => Task 16, Epoch 45/160 (LR 0.08172) => LSC_loss 0.86, Spatial_loss 2.58, Flat_loss 0.52, Train_acc 78.80, Test_acc 20.39
2025-02-14 23:51:04,273 [podnet.py] => Task 16, Epoch 46/160 (LR 0.08095) => LSC_loss 0.93, Spatial_loss 2.72, Flat_loss 0.55, Train_acc 76.07, Test_acc 23.65
2025-02-14 23:51:06,431 [podnet.py] => Task 16, Epoch 47/160 (LR 0.08018) => LSC_loss 0.78, Spatial_loss 2.48, Flat_loss 0.48, Train_acc 81.00, Test_acc 22.04
2025-02-14 23:51:08,565 [podnet.py] => Task 16, Epoch 48/160 (LR 0.07939) => LSC_loss 1.05, Spatial_loss 2.68, Flat_loss 0.58, Train_acc 75.34, Test_acc 19.33
2025-02-14 23:51:10,652 [podnet.py] => Task 16, Epoch 49/160 (LR 0.07859) => LSC_loss 1.19, Spatial_loss 2.87, Flat_loss 0.67, Train_acc 69.24, Test_acc 19.06
2025-02-14 23:51:12,769 [podnet.py] => Task 16, Epoch 50/160 (LR 0.07778) => LSC_loss 0.82, Spatial_loss 2.52, Flat_loss 0.52, Train_acc 79.12, Test_acc 20.18
2025-02-14 23:51:14,873 [podnet.py] => Task 16, Epoch 51/160 (LR 0.07696) => LSC_loss 0.87, Spatial_loss 2.64, Flat_loss 0.51, Train_acc 80.59, Test_acc 19.28
2025-02-14 23:51:16,963 [podnet.py] => Task 16, Epoch 52/160 (LR 0.07612) => LSC_loss 1.18, Spatial_loss 3.10, Flat_loss 0.65, Train_acc 70.17, Test_acc 21.81
2025-02-14 23:51:19,001 [podnet.py] => Task 16, Epoch 53/160 (LR 0.07528) => LSC_loss 1.10, Spatial_loss 2.87, Flat_loss 0.63, Train_acc 73.05, Test_acc 21.79
2025-02-14 23:51:21,139 [podnet.py] => Task 16, Epoch 54/160 (LR 0.07443) => LSC_loss 1.18, Spatial_loss 2.81, Flat_loss 0.62, Train_acc 71.02, Test_acc 19.84
2025-02-14 23:51:23,243 [podnet.py] => Task 16, Epoch 55/160 (LR 0.07357) => LSC_loss 0.91, Spatial_loss 2.62, Flat_loss 0.54, Train_acc 78.00, Test_acc 21.58
2025-02-14 23:51:25,303 [podnet.py] => Task 16, Epoch 56/160 (LR 0.07270) => LSC_loss 0.94, Spatial_loss 2.66, Flat_loss 0.57, Train_acc 76.93, Test_acc 22.36
2025-02-14 23:51:27,481 [podnet.py] => Task 16, Epoch 57/160 (LR 0.07182) => LSC_loss 1.02, Spatial_loss 2.69, Flat_loss 0.60, Train_acc 73.61, Test_acc 22.22
2025-02-14 23:51:29,593 [podnet.py] => Task 16, Epoch 58/160 (LR 0.07093) => LSC_loss 0.79, Spatial_loss 2.52, Flat_loss 0.50, Train_acc 80.49, Test_acc 23.45
2025-02-14 23:51:31,659 [podnet.py] => Task 16, Epoch 59/160 (LR 0.07004) => LSC_loss 0.86, Spatial_loss 2.65, Flat_loss 0.53, Train_acc 78.22, Test_acc 21.18
2025-02-14 23:51:33,785 [podnet.py] => Task 16, Epoch 60/160 (LR 0.06913) => LSC_loss 0.76, Spatial_loss 2.53, Flat_loss 0.49, Train_acc 81.54, Test_acc 24.16
2025-02-14 23:51:35,893 [podnet.py] => Task 16, Epoch 61/160 (LR 0.06822) => LSC_loss 0.74, Spatial_loss 2.41, Flat_loss 0.48, Train_acc 82.59, Test_acc 21.01
2025-02-14 23:51:37,935 [podnet.py] => Task 16, Epoch 62/160 (LR 0.06731) => LSC_loss 0.97, Spatial_loss 2.84, Flat_loss 0.57, Train_acc 76.61, Test_acc 19.85
2025-02-14 23:51:40,090 [podnet.py] => Task 16, Epoch 63/160 (LR 0.06638) => LSC_loss 0.83, Spatial_loss 2.51, Flat_loss 0.51, Train_acc 79.37, Test_acc 21.21
2025-02-14 23:51:42,244 [podnet.py] => Task 16, Epoch 64/160 (LR 0.06545) => LSC_loss 0.75, Spatial_loss 2.29, Flat_loss 0.47, Train_acc 81.80, Test_acc 22.26
2025-02-14 23:51:44,328 [podnet.py] => Task 16, Epoch 65/160 (LR 0.06451) => LSC_loss 0.75, Spatial_loss 2.39, Flat_loss 0.50, Train_acc 81.20, Test_acc 21.94
2025-02-14 23:51:46,423 [podnet.py] => Task 16, Epoch 66/160 (LR 0.06357) => LSC_loss 0.64, Spatial_loss 2.29, Flat_loss 0.44, Train_acc 84.90, Test_acc 19.49
2025-02-14 23:51:48,534 [podnet.py] => Task 16, Epoch 67/160 (LR 0.06262) => LSC_loss 0.76, Spatial_loss 2.31, Flat_loss 0.46, Train_acc 84.49, Test_acc 18.99
2025-02-14 23:51:50,640 [podnet.py] => Task 16, Epoch 68/160 (LR 0.06167) => LSC_loss 0.95, Spatial_loss 2.77, Flat_loss 0.54, Train_acc 75.49, Test_acc 22.87
2025-02-14 23:51:52,767 [podnet.py] => Task 16, Epoch 69/160 (LR 0.06072) => LSC_loss 0.72, Spatial_loss 2.39, Flat_loss 0.48, Train_acc 82.27, Test_acc 20.24
2025-02-14 23:51:54,864 [podnet.py] => Task 16, Epoch 70/160 (LR 0.05975) => LSC_loss 0.79, Spatial_loss 2.49, Flat_loss 0.51, Train_acc 81.12, Test_acc 25.49
2025-02-14 23:51:56,924 [podnet.py] => Task 16, Epoch 71/160 (LR 0.05879) => LSC_loss 0.85, Spatial_loss 2.48, Flat_loss 0.54, Train_acc 78.85, Test_acc 23.95
2025-02-14 23:51:59,049 [podnet.py] => Task 16, Epoch 72/160 (LR 0.05782) => LSC_loss 0.69, Spatial_loss 2.32, Flat_loss 0.47, Train_acc 83.17, Test_acc 20.60
2025-02-14 23:52:01,095 [podnet.py] => Task 16, Epoch 73/160 (LR 0.05685) => LSC_loss 0.83, Spatial_loss 2.39, Flat_loss 0.50, Train_acc 80.22, Test_acc 21.36
2025-02-14 23:52:03,217 [podnet.py] => Task 16, Epoch 74/160 (LR 0.05588) => LSC_loss 0.86, Spatial_loss 2.50, Flat_loss 0.51, Train_acc 78.71, Test_acc 16.73
2025-02-14 23:52:05,364 [podnet.py] => Task 16, Epoch 75/160 (LR 0.05490) => LSC_loss 0.93, Spatial_loss 2.74, Flat_loss 0.58, Train_acc 77.51, Test_acc 22.45
2025-02-14 23:52:07,495 [podnet.py] => Task 16, Epoch 76/160 (LR 0.05392) => LSC_loss 0.77, Spatial_loss 2.46, Flat_loss 0.49, Train_acc 81.80, Test_acc 19.91
2025-02-14 23:52:09,641 [podnet.py] => Task 16, Epoch 77/160 (LR 0.05294) => LSC_loss 0.81, Spatial_loss 2.45, Flat_loss 0.52, Train_acc 80.73, Test_acc 19.08
2025-02-14 23:52:11,750 [podnet.py] => Task 16, Epoch 78/160 (LR 0.05196) => LSC_loss 0.94, Spatial_loss 2.60, Flat_loss 0.57, Train_acc 78.20, Test_acc 24.00
2025-02-14 23:52:13,828 [podnet.py] => Task 16, Epoch 79/160 (LR 0.05098) => LSC_loss 0.85, Spatial_loss 2.60, Flat_loss 0.53, Train_acc 81.49, Test_acc 21.41
2025-02-14 23:52:15,927 [podnet.py] => Task 16, Epoch 80/160 (LR 0.05000) => LSC_loss 0.79, Spatial_loss 2.43, Flat_loss 0.52, Train_acc 81.90, Test_acc 23.84
2025-02-14 23:52:18,061 [podnet.py] => Task 16, Epoch 81/160 (LR 0.04902) => LSC_loss 0.84, Spatial_loss 2.48, Flat_loss 0.52, Train_acc 79.78, Test_acc 22.84
2025-02-14 23:52:20,134 [podnet.py] => Task 16, Epoch 82/160 (LR 0.04804) => LSC_loss 0.69, Spatial_loss 2.26, Flat_loss 0.49, Train_acc 83.29, Test_acc 21.88
2025-02-14 23:52:22,239 [podnet.py] => Task 16, Epoch 83/160 (LR 0.04706) => LSC_loss 0.65, Spatial_loss 2.27, Flat_loss 0.45, Train_acc 85.59, Test_acc 23.79
2025-02-14 23:52:24,340 [podnet.py] => Task 16, Epoch 84/160 (LR 0.04608) => LSC_loss 0.76, Spatial_loss 2.30, Flat_loss 0.46, Train_acc 83.29, Test_acc 23.56
2025-02-14 23:52:26,470 [podnet.py] => Task 16, Epoch 85/160 (LR 0.04510) => LSC_loss 0.68, Spatial_loss 2.31, Flat_loss 0.46, Train_acc 84.07, Test_acc 22.73
2025-02-14 23:52:28,612 [podnet.py] => Task 16, Epoch 86/160 (LR 0.04412) => LSC_loss 0.76, Spatial_loss 2.46, Flat_loss 0.48, Train_acc 82.54, Test_acc 22.20
2025-02-14 23:52:30,739 [podnet.py] => Task 16, Epoch 87/160 (LR 0.04315) => LSC_loss 0.70, Spatial_loss 2.32, Flat_loss 0.47, Train_acc 83.27, Test_acc 24.01
2025-02-14 23:52:32,873 [podnet.py] => Task 16, Epoch 88/160 (LR 0.04218) => LSC_loss 0.63, Spatial_loss 2.23, Flat_loss 0.44, Train_acc 85.41, Test_acc 20.82
2025-02-14 23:52:35,012 [podnet.py] => Task 16, Epoch 89/160 (LR 0.04121) => LSC_loss 0.62, Spatial_loss 2.14, Flat_loss 0.45, Train_acc 84.78, Test_acc 20.25
2025-02-14 23:52:37,064 [podnet.py] => Task 16, Epoch 90/160 (LR 0.04025) => LSC_loss 0.64, Spatial_loss 2.18, Flat_loss 0.43, Train_acc 86.02, Test_acc 24.15
2025-02-14 23:52:39,185 [podnet.py] => Task 16, Epoch 91/160 (LR 0.03928) => LSC_loss 0.72, Spatial_loss 2.37, Flat_loss 0.48, Train_acc 83.20, Test_acc 24.91
2025-02-14 23:52:41,304 [podnet.py] => Task 16, Epoch 92/160 (LR 0.03833) => LSC_loss 0.62, Spatial_loss 2.15, Flat_loss 0.44, Train_acc 86.85, Test_acc 25.18
2025-02-14 23:52:43,385 [podnet.py] => Task 16, Epoch 93/160 (LR 0.03738) => LSC_loss 0.70, Spatial_loss 2.27, Flat_loss 0.50, Train_acc 83.37, Test_acc 21.69
2025-02-14 23:52:45,531 [podnet.py] => Task 16, Epoch 94/160 (LR 0.03643) => LSC_loss 0.72, Spatial_loss 2.28, Flat_loss 0.47, Train_acc 84.15, Test_acc 23.21
2025-02-14 23:52:47,601 [podnet.py] => Task 16, Epoch 95/160 (LR 0.03549) => LSC_loss 0.77, Spatial_loss 2.32, Flat_loss 0.52, Train_acc 81.15, Test_acc 25.54
2025-02-14 23:52:49,704 [podnet.py] => Task 16, Epoch 96/160 (LR 0.03455) => LSC_loss 0.63, Spatial_loss 2.24, Flat_loss 0.44, Train_acc 86.12, Test_acc 23.12
2025-02-14 23:52:51,744 [podnet.py] => Task 16, Epoch 97/160 (LR 0.03362) => LSC_loss 0.54, Spatial_loss 2.06, Flat_loss 0.44, Train_acc 87.95, Test_acc 23.67
2025-02-14 23:52:53,860 [podnet.py] => Task 16, Epoch 98/160 (LR 0.03269) => LSC_loss 0.45, Spatial_loss 2.02, Flat_loss 0.40, Train_acc 90.17, Test_acc 22.18
2025-02-14 23:52:55,900 [podnet.py] => Task 16, Epoch 99/160 (LR 0.03178) => LSC_loss 0.50, Spatial_loss 1.95, Flat_loss 0.37, Train_acc 91.27, Test_acc 25.72
2025-02-14 23:52:58,011 [podnet.py] => Task 16, Epoch 100/160 (LR 0.03087) => LSC_loss 0.50, Spatial_loss 2.10, Flat_loss 0.41, Train_acc 88.73, Test_acc 24.64
2025-02-14 23:53:00,045 [podnet.py] => Task 16, Epoch 101/160 (LR 0.02996) => LSC_loss 0.41, Spatial_loss 1.89, Flat_loss 0.37, Train_acc 92.32, Test_acc 23.80
2025-02-14 23:53:02,163 [podnet.py] => Task 16, Epoch 102/160 (LR 0.02907) => LSC_loss 0.56, Spatial_loss 2.02, Flat_loss 0.42, Train_acc 87.39, Test_acc 22.92
2025-02-14 23:53:04,234 [podnet.py] => Task 16, Epoch 103/160 (LR 0.02818) => LSC_loss 0.69, Spatial_loss 2.14, Flat_loss 0.47, Train_acc 85.83, Test_acc 23.93
2025-02-14 23:53:06,383 [podnet.py] => Task 16, Epoch 104/160 (LR 0.02730) => LSC_loss 0.63, Spatial_loss 2.23, Flat_loss 0.46, Train_acc 86.02, Test_acc 24.05
2025-02-14 23:53:08,426 [podnet.py] => Task 16, Epoch 105/160 (LR 0.02643) => LSC_loss 0.64, Spatial_loss 2.18, Flat_loss 0.48, Train_acc 84.56, Test_acc 23.27
2025-02-14 23:53:10,516 [podnet.py] => Task 16, Epoch 106/160 (LR 0.02557) => LSC_loss 0.41, Spatial_loss 1.86, Flat_loss 0.38, Train_acc 91.00, Test_acc 25.08
2025-02-14 23:53:12,666 [podnet.py] => Task 16, Epoch 107/160 (LR 0.02472) => LSC_loss 0.41, Spatial_loss 1.81, Flat_loss 0.36, Train_acc 92.07, Test_acc 26.71
2025-02-14 23:53:14,824 [podnet.py] => Task 16, Epoch 108/160 (LR 0.02388) => LSC_loss 0.49, Spatial_loss 1.88, Flat_loss 0.40, Train_acc 89.39, Test_acc 24.89
2025-02-14 23:53:16,898 [podnet.py] => Task 16, Epoch 109/160 (LR 0.02304) => LSC_loss 0.48, Spatial_loss 1.79, Flat_loss 0.37, Train_acc 91.73, Test_acc 26.59
2025-02-14 23:53:19,100 [podnet.py] => Task 16, Epoch 110/160 (LR 0.02222) => LSC_loss 0.47, Spatial_loss 1.86, Flat_loss 0.39, Train_acc 89.63, Test_acc 25.04
2025-02-14 23:53:21,282 [podnet.py] => Task 16, Epoch 111/160 (LR 0.02141) => LSC_loss 0.43, Spatial_loss 1.86, Flat_loss 0.37, Train_acc 91.10, Test_acc 25.91
2025-02-14 23:53:23,433 [podnet.py] => Task 16, Epoch 112/160 (LR 0.02061) => LSC_loss 0.37, Spatial_loss 1.90, Flat_loss 0.35, Train_acc 92.80, Test_acc 25.85
2025-02-14 23:53:25,586 [podnet.py] => Task 16, Epoch 113/160 (LR 0.01982) => LSC_loss 0.37, Spatial_loss 1.72, Flat_loss 0.34, Train_acc 93.49, Test_acc 24.87
2025-02-14 23:53:27,701 [podnet.py] => Task 16, Epoch 114/160 (LR 0.01905) => LSC_loss 0.44, Spatial_loss 1.79, Flat_loss 0.38, Train_acc 92.02, Test_acc 25.52
2025-02-14 23:53:29,762 [podnet.py] => Task 16, Epoch 115/160 (LR 0.01828) => LSC_loss 0.53, Spatial_loss 1.92, Flat_loss 0.41, Train_acc 88.34, Test_acc 24.95
2025-02-14 23:53:31,862 [podnet.py] => Task 16, Epoch 116/160 (LR 0.01753) => LSC_loss 0.47, Spatial_loss 1.84, Flat_loss 0.38, Train_acc 90.59, Test_acc 23.05
2025-02-14 23:53:34,057 [podnet.py] => Task 16, Epoch 117/160 (LR 0.01679) => LSC_loss 0.42, Spatial_loss 1.77, Flat_loss 0.36, Train_acc 92.39, Test_acc 23.02
2025-02-14 23:53:36,098 [podnet.py] => Task 16, Epoch 118/160 (LR 0.01606) => LSC_loss 0.41, Spatial_loss 1.66, Flat_loss 0.35, Train_acc 92.76, Test_acc 26.06
2025-02-14 23:53:38,258 [podnet.py] => Task 16, Epoch 119/160 (LR 0.01535) => LSC_loss 0.41, Spatial_loss 1.74, Flat_loss 0.35, Train_acc 91.73, Test_acc 26.40
2025-02-14 23:53:40,347 [podnet.py] => Task 16, Epoch 120/160 (LR 0.01464) => LSC_loss 0.40, Spatial_loss 1.70, Flat_loss 0.34, Train_acc 92.93, Test_acc 25.86
2025-02-14 23:53:42,441 [podnet.py] => Task 16, Epoch 121/160 (LR 0.01396) => LSC_loss 0.41, Spatial_loss 1.73, Flat_loss 0.35, Train_acc 92.22, Test_acc 26.69
2025-02-14 23:53:44,534 [podnet.py] => Task 16, Epoch 122/160 (LR 0.01328) => LSC_loss 0.36, Spatial_loss 1.65, Flat_loss 0.35, Train_acc 92.93, Test_acc 24.56
2025-02-14 23:53:46,663 [podnet.py] => Task 16, Epoch 123/160 (LR 0.01262) => LSC_loss 0.38, Spatial_loss 1.66, Flat_loss 0.35, Train_acc 92.73, Test_acc 26.76
2025-02-14 23:53:48,785 [podnet.py] => Task 16, Epoch 124/160 (LR 0.01198) => LSC_loss 0.35, Spatial_loss 1.61, Flat_loss 0.33, Train_acc 94.37, Test_acc 26.44
2025-02-14 23:53:50,854 [podnet.py] => Task 16, Epoch 125/160 (LR 0.01135) => LSC_loss 0.35, Spatial_loss 1.60, Flat_loss 0.32, Train_acc 94.39, Test_acc 26.06
2025-02-14 23:53:52,960 [podnet.py] => Task 16, Epoch 126/160 (LR 0.01073) => LSC_loss 0.36, Spatial_loss 1.54, Flat_loss 0.33, Train_acc 94.39, Test_acc 26.87
2025-02-14 23:53:55,095 [podnet.py] => Task 16, Epoch 127/160 (LR 0.01013) => LSC_loss 0.35, Spatial_loss 1.55, Flat_loss 0.33, Train_acc 94.12, Test_acc 26.85
2025-02-14 23:53:57,220 [podnet.py] => Task 16, Epoch 128/160 (LR 0.00955) => LSC_loss 0.36, Spatial_loss 1.77, Flat_loss 0.34, Train_acc 93.46, Test_acc 25.52
2025-02-14 23:53:59,350 [podnet.py] => Task 16, Epoch 129/160 (LR 0.00898) => LSC_loss 0.34, Spatial_loss 1.56, Flat_loss 0.32, Train_acc 95.00, Test_acc 26.12
2025-02-14 23:54:01,418 [podnet.py] => Task 16, Epoch 130/160 (LR 0.00843) => LSC_loss 0.36, Spatial_loss 1.53, Flat_loss 0.32, Train_acc 94.59, Test_acc 25.96
2025-02-14 23:54:03,513 [podnet.py] => Task 16, Epoch 131/160 (LR 0.00789) => LSC_loss 0.36, Spatial_loss 1.51, Flat_loss 0.32, Train_acc 94.66, Test_acc 27.06
2025-02-14 23:54:05,613 [podnet.py] => Task 16, Epoch 132/160 (LR 0.00737) => LSC_loss 0.37, Spatial_loss 1.61, Flat_loss 0.34, Train_acc 93.85, Test_acc 26.89
2025-02-14 23:54:07,742 [podnet.py] => Task 16, Epoch 133/160 (LR 0.00686) => LSC_loss 0.35, Spatial_loss 1.59, Flat_loss 0.33, Train_acc 93.88, Test_acc 25.60
2025-02-14 23:54:09,857 [podnet.py] => Task 16, Epoch 134/160 (LR 0.00638) => LSC_loss 0.41, Spatial_loss 1.62, Flat_loss 0.33, Train_acc 94.15, Test_acc 25.88
2025-02-14 23:54:11,912 [podnet.py] => Task 16, Epoch 135/160 (LR 0.00590) => LSC_loss 0.38, Spatial_loss 1.61, Flat_loss 0.33, Train_acc 93.10, Test_acc 25.41
2025-02-14 23:54:14,085 [podnet.py] => Task 16, Epoch 136/160 (LR 0.00545) => LSC_loss 0.30, Spatial_loss 1.55, Flat_loss 0.31, Train_acc 94.85, Test_acc 26.80
2025-02-14 23:54:16,224 [podnet.py] => Task 16, Epoch 137/160 (LR 0.00501) => LSC_loss 0.31, Spatial_loss 1.54, Flat_loss 0.31, Train_acc 95.02, Test_acc 24.96
2025-02-14 23:54:18,359 [podnet.py] => Task 16, Epoch 138/160 (LR 0.00459) => LSC_loss 0.33, Spatial_loss 1.51, Flat_loss 0.30, Train_acc 95.27, Test_acc 27.20
2025-02-14 23:54:20,381 [podnet.py] => Task 16, Epoch 139/160 (LR 0.00419) => LSC_loss 0.29, Spatial_loss 1.46, Flat_loss 0.31, Train_acc 94.80, Test_acc 25.66
2025-02-14 23:54:22,490 [podnet.py] => Task 16, Epoch 140/160 (LR 0.00381) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.30, Train_acc 96.29, Test_acc 25.06
2025-02-14 23:54:24,611 [podnet.py] => Task 16, Epoch 141/160 (LR 0.00344) => LSC_loss 0.31, Spatial_loss 1.39, Flat_loss 0.28, Train_acc 95.85, Test_acc 26.59
2025-02-14 23:54:26,741 [podnet.py] => Task 16, Epoch 142/160 (LR 0.00309) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.30, Train_acc 95.46, Test_acc 26.42
2025-02-14 23:54:28,866 [podnet.py] => Task 16, Epoch 143/160 (LR 0.00276) => LSC_loss 0.38, Spatial_loss 1.41, Flat_loss 0.31, Train_acc 96.07, Test_acc 26.24
2025-02-14 23:54:31,024 [podnet.py] => Task 16, Epoch 144/160 (LR 0.00245) => LSC_loss 0.39, Spatial_loss 1.41, Flat_loss 0.31, Train_acc 95.24, Test_acc 26.06
2025-02-14 23:54:33,113 [podnet.py] => Task 16, Epoch 145/160 (LR 0.00215) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 96.02, Test_acc 27.05
2025-02-14 23:54:35,213 [podnet.py] => Task 16, Epoch 146/160 (LR 0.00188) => LSC_loss 0.33, Spatial_loss 1.42, Flat_loss 0.31, Train_acc 95.98, Test_acc 25.94
2025-02-14 23:54:37,290 [podnet.py] => Task 16, Epoch 147/160 (LR 0.00162) => LSC_loss 0.30, Spatial_loss 1.45, Flat_loss 0.29, Train_acc 95.80, Test_acc 27.15
2025-02-14 23:54:39,407 [podnet.py] => Task 16, Epoch 148/160 (LR 0.00138) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.30, Train_acc 95.90, Test_acc 26.55
2025-02-14 23:54:41,548 [podnet.py] => Task 16, Epoch 149/160 (LR 0.00116) => LSC_loss 0.31, Spatial_loss 1.36, Flat_loss 0.29, Train_acc 96.20, Test_acc 26.45
2025-02-14 23:54:43,650 [podnet.py] => Task 16, Epoch 150/160 (LR 0.00096) => LSC_loss 0.27, Spatial_loss 1.39, Flat_loss 0.28, Train_acc 96.00, Test_acc 27.40
2025-02-14 23:54:45,768 [podnet.py] => Task 16, Epoch 151/160 (LR 0.00078) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.29, Train_acc 96.24, Test_acc 27.26
2025-02-14 23:54:47,846 [podnet.py] => Task 16, Epoch 152/160 (LR 0.00062) => LSC_loss 0.34, Spatial_loss 1.35, Flat_loss 0.30, Train_acc 96.17, Test_acc 26.48
2025-02-14 23:54:49,972 [podnet.py] => Task 16, Epoch 153/160 (LR 0.00047) => LSC_loss 0.31, Spatial_loss 1.37, Flat_loss 0.28, Train_acc 96.32, Test_acc 26.79
2025-02-14 23:54:52,006 [podnet.py] => Task 16, Epoch 154/160 (LR 0.00035) => LSC_loss 0.35, Spatial_loss 1.37, Flat_loss 0.28, Train_acc 96.15, Test_acc 26.94
2025-02-14 23:54:54,184 [podnet.py] => Task 16, Epoch 155/160 (LR 0.00024) => LSC_loss 0.31, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 96.29, Test_acc 26.64
2025-02-14 23:54:56,236 [podnet.py] => Task 16, Epoch 156/160 (LR 0.00015) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.29, Train_acc 96.22, Test_acc 26.73
2025-02-14 23:54:58,389 [podnet.py] => Task 16, Epoch 157/160 (LR 0.00009) => LSC_loss 0.30, Spatial_loss 1.33, Flat_loss 0.28, Train_acc 95.98, Test_acc 26.65
2025-02-14 23:55:00,466 [podnet.py] => Task 16, Epoch 158/160 (LR 0.00004) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.29, Train_acc 96.80, Test_acc 26.41
2025-02-14 23:55:02,544 [podnet.py] => Task 16, Epoch 159/160 (LR 0.00001) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.28, Train_acc 96.24, Test_acc 26.96
2025-02-14 23:55:04,669 [podnet.py] => Task 16, Epoch 160/160 (LR 0.00000) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.29, Train_acc 96.15, Test_acc 26.14
2025-02-14 23:55:04,669 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-14 23:55:04,670 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:55:35,023 [podnet.py] => The size of finetune dataset: 1700
2025-02-14 23:55:36,593 [podnet.py] => Task 16, Epoch 1/20 (LR 0.00497) => LSC_loss 0.46, Spatial_loss 1.82, Flat_loss 0.26, Train_acc 89.35, Test_acc 27.51
2025-02-14 23:55:38,183 [podnet.py] => Task 16, Epoch 2/20 (LR 0.00488) => LSC_loss 0.26, Spatial_loss 1.47, Flat_loss 0.19, Train_acc 96.82, Test_acc 29.74
2025-02-14 23:55:39,763 [podnet.py] => Task 16, Epoch 3/20 (LR 0.00473) => LSC_loss 0.25, Spatial_loss 1.34, Flat_loss 0.18, Train_acc 97.06, Test_acc 28.88
2025-02-14 23:55:41,293 [podnet.py] => Task 16, Epoch 4/20 (LR 0.00452) => LSC_loss 0.24, Spatial_loss 1.33, Flat_loss 0.17, Train_acc 97.18, Test_acc 28.27
2025-02-14 23:55:42,837 [podnet.py] => Task 16, Epoch 5/20 (LR 0.00427) => LSC_loss 0.24, Spatial_loss 1.32, Flat_loss 0.17, Train_acc 97.29, Test_acc 28.48
2025-02-14 23:55:44,372 [podnet.py] => Task 16, Epoch 6/20 (LR 0.00397) => LSC_loss 0.24, Spatial_loss 1.36, Flat_loss 0.17, Train_acc 97.29, Test_acc 28.36
2025-02-14 23:55:45,934 [podnet.py] => Task 16, Epoch 7/20 (LR 0.00363) => LSC_loss 0.24, Spatial_loss 1.38, Flat_loss 0.17, Train_acc 97.35, Test_acc 28.52
2025-02-14 23:55:47,518 [podnet.py] => Task 16, Epoch 8/20 (LR 0.00327) => LSC_loss 0.22, Spatial_loss 1.40, Flat_loss 0.17, Train_acc 97.41, Test_acc 28.39
2025-02-14 23:55:49,085 [podnet.py] => Task 16, Epoch 9/20 (LR 0.00289) => LSC_loss 0.23, Spatial_loss 1.30, Flat_loss 0.16, Train_acc 97.41, Test_acc 28.58
2025-02-14 23:55:50,708 [podnet.py] => Task 16, Epoch 10/20 (LR 0.00250) => LSC_loss 0.23, Spatial_loss 1.36, Flat_loss 0.17, Train_acc 97.76, Test_acc 28.44
2025-02-14 23:55:52,281 [podnet.py] => Task 16, Epoch 11/20 (LR 0.00211) => LSC_loss 0.24, Spatial_loss 1.36, Flat_loss 0.16, Train_acc 96.59, Test_acc 28.56
2025-02-14 23:55:53,837 [podnet.py] => Task 16, Epoch 12/20 (LR 0.00173) => LSC_loss 0.22, Spatial_loss 1.36, Flat_loss 0.16, Train_acc 97.41, Test_acc 28.56
2025-02-14 23:55:55,389 [podnet.py] => Task 16, Epoch 13/20 (LR 0.00137) => LSC_loss 0.22, Spatial_loss 1.42, Flat_loss 0.16, Train_acc 98.06, Test_acc 28.87
2025-02-14 23:55:56,972 [podnet.py] => Task 16, Epoch 14/20 (LR 0.00103) => LSC_loss 0.23, Spatial_loss 1.28, Flat_loss 0.16, Train_acc 97.24, Test_acc 28.80
2025-02-14 23:55:58,602 [podnet.py] => Task 16, Epoch 15/20 (LR 0.00073) => LSC_loss 0.24, Spatial_loss 1.35, Flat_loss 0.16, Train_acc 97.47, Test_acc 28.82
2025-02-14 23:56:00,153 [podnet.py] => Task 16, Epoch 16/20 (LR 0.00048) => LSC_loss 0.21, Spatial_loss 1.38, Flat_loss 0.16, Train_acc 97.65, Test_acc 28.85
2025-02-14 23:56:01,724 [podnet.py] => Task 16, Epoch 17/20 (LR 0.00027) => LSC_loss 0.22, Spatial_loss 1.31, Flat_loss 0.16, Train_acc 98.12, Test_acc 28.84
2025-02-14 23:56:03,353 [podnet.py] => Task 16, Epoch 18/20 (LR 0.00012) => LSC_loss 0.23, Spatial_loss 1.26, Flat_loss 0.16, Train_acc 97.71, Test_acc 28.89
2025-02-14 23:56:04,889 [podnet.py] => Task 16, Epoch 19/20 (LR 0.00003) => LSC_loss 0.22, Spatial_loss 1.32, Flat_loss 0.16, Train_acc 97.82, Test_acc 28.89
2025-02-14 23:56:06,406 [podnet.py] => Task 16, Epoch 20/20 (LR 0.00000) => LSC_loss 0.23, Spatial_loss 1.29, Flat_loss 0.16, Train_acc 97.18, Test_acc 28.87
2025-02-14 23:56:06,408 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-14 23:56:38,689 [podnet.py] => Exemplar size: 1700
2025-02-14 23:56:38,689 [trainer.py] => CNN: {'total': 28.87, '00-09': 35.1, '10-19': 11.2, '20-29': 17.9, '30-39': 16.3, '40-49': 32.4, '50-59': 21.1, '60-69': 34.7, '70-79': 41.2, '80-89': 71.0, 'old': 26.24, 'new': 71.0}
2025-02-14 23:56:38,689 [trainer.py] => NME: {'total': 29.13, '00-09': 42.3, '10-19': 12.2, '20-29': 18.2, '30-39': 16.0, '40-49': 33.9, '50-59': 19.6, '60-69': 34.6, '70-79': 39.8, '80-89': 62.0, 'old': 27.08, 'new': 62.0}
2025-02-14 23:56:38,690 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24, 28.7, 28.87]
2025-02-14 23:56:38,690 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85, 55.0, 56.02]
2025-02-14 23:56:38,690 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08, 28.69, 29.13]
2025-02-14 23:56:38,690 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49, 55.08, 55.31]

2025-02-14 23:56:38,690 [trainer.py] => Average Accuracy (CNN): 43.86352941176471
2025-02-14 23:56:38,690 [trainer.py] => Average Accuracy (NME): 43.34882352941176
2025-02-14 23:56:38,690 [trainer.py] => All params: 520657
2025-02-14 23:56:38,690 [trainer.py] => Trainable params: 520657
2025-02-14 23:56:38,691 [podnet.py] => Learning on 85-90
2025-02-14 23:56:38,723 [podnet.py] => Adaptive factor: 4.242640687119285
2025-02-14 23:56:40,918 [podnet.py] => Task 17, Epoch 1/160 (LR 0.09999) => LSC_loss 2.70, Spatial_loss 2.79, Flat_loss 1.07, Train_acc 47.31, Test_acc 17.78
2025-02-14 23:56:43,130 [podnet.py] => Task 17, Epoch 2/160 (LR 0.09996) => LSC_loss 1.39, Spatial_loss 2.52, Flat_loss 0.60, Train_acc 61.12, Test_acc 21.31
2025-02-14 23:56:45,292 [podnet.py] => Task 17, Epoch 3/160 (LR 0.09991) => LSC_loss 1.27, Spatial_loss 2.47, Flat_loss 0.51, Train_acc 65.02, Test_acc 18.94
2025-02-14 23:56:47,427 [podnet.py] => Task 17, Epoch 4/160 (LR 0.09985) => LSC_loss 1.23, Spatial_loss 2.41, Flat_loss 0.49, Train_acc 66.40, Test_acc 22.46
2025-02-14 23:56:49,642 [podnet.py] => Task 17, Epoch 5/160 (LR 0.09976) => LSC_loss 1.18, Spatial_loss 2.31, Flat_loss 0.48, Train_acc 67.31, Test_acc 21.08
2025-02-14 23:56:51,791 [podnet.py] => Task 17, Epoch 6/160 (LR 0.09965) => LSC_loss 1.13, Spatial_loss 2.38, Flat_loss 0.47, Train_acc 69.14, Test_acc 22.80
2025-02-14 23:56:53,956 [podnet.py] => Task 17, Epoch 7/160 (LR 0.09953) => LSC_loss 1.15, Spatial_loss 2.42, Flat_loss 0.47, Train_acc 69.24, Test_acc 23.17
2025-02-14 23:56:56,168 [podnet.py] => Task 17, Epoch 8/160 (LR 0.09938) => LSC_loss 1.13, Spatial_loss 2.31, Flat_loss 0.45, Train_acc 69.64, Test_acc 20.69
2025-02-14 23:56:58,328 [podnet.py] => Task 17, Epoch 9/160 (LR 0.09922) => LSC_loss 1.06, Spatial_loss 2.35, Flat_loss 0.45, Train_acc 71.29, Test_acc 21.13
2025-02-14 23:57:00,454 [podnet.py] => Task 17, Epoch 10/160 (LR 0.09904) => LSC_loss 1.02, Spatial_loss 2.45, Flat_loss 0.45, Train_acc 71.93, Test_acc 19.72
2025-02-14 23:57:02,581 [podnet.py] => Task 17, Epoch 11/160 (LR 0.09884) => LSC_loss 1.01, Spatial_loss 2.32, Flat_loss 0.45, Train_acc 73.57, Test_acc 21.72
2025-02-14 23:57:04,752 [podnet.py] => Task 17, Epoch 12/160 (LR 0.09862) => LSC_loss 1.01, Spatial_loss 2.34, Flat_loss 0.45, Train_acc 72.86, Test_acc 19.97
2025-02-14 23:57:06,882 [podnet.py] => Task 17, Epoch 13/160 (LR 0.09838) => LSC_loss 0.98, Spatial_loss 2.31, Flat_loss 0.45, Train_acc 73.48, Test_acc 21.56
2025-02-14 23:57:09,064 [podnet.py] => Task 17, Epoch 14/160 (LR 0.09812) => LSC_loss 1.00, Spatial_loss 2.28, Flat_loss 0.46, Train_acc 73.81, Test_acc 23.54
2025-02-14 23:57:11,194 [podnet.py] => Task 17, Epoch 15/160 (LR 0.09785) => LSC_loss 0.99, Spatial_loss 2.34, Flat_loss 0.46, Train_acc 73.31, Test_acc 23.48
2025-02-14 23:57:13,261 [podnet.py] => Task 17, Epoch 16/160 (LR 0.09755) => LSC_loss 0.96, Spatial_loss 2.31, Flat_loss 0.45, Train_acc 74.40, Test_acc 19.11
2025-02-14 23:57:15,357 [podnet.py] => Task 17, Epoch 17/160 (LR 0.09724) => LSC_loss 0.95, Spatial_loss 2.30, Flat_loss 0.47, Train_acc 74.29, Test_acc 20.93
2025-02-14 23:57:17,508 [podnet.py] => Task 17, Epoch 18/160 (LR 0.09691) => LSC_loss 0.90, Spatial_loss 2.18, Flat_loss 0.46, Train_acc 76.48, Test_acc 20.77
2025-02-14 23:57:19,657 [podnet.py] => Task 17, Epoch 19/160 (LR 0.09656) => LSC_loss 0.89, Spatial_loss 2.20, Flat_loss 0.45, Train_acc 76.74, Test_acc 19.02
2025-02-14 23:57:21,822 [podnet.py] => Task 17, Epoch 20/160 (LR 0.09619) => LSC_loss 0.90, Spatial_loss 2.32, Flat_loss 0.46, Train_acc 76.62, Test_acc 19.10
2025-02-14 23:57:23,965 [podnet.py] => Task 17, Epoch 21/160 (LR 0.09581) => LSC_loss 0.91, Spatial_loss 2.34, Flat_loss 0.47, Train_acc 76.69, Test_acc 18.88
2025-02-14 23:57:26,108 [podnet.py] => Task 17, Epoch 22/160 (LR 0.09541) => LSC_loss 0.85, Spatial_loss 2.22, Flat_loss 0.45, Train_acc 76.86, Test_acc 21.71
2025-02-14 23:57:28,210 [podnet.py] => Task 17, Epoch 23/160 (LR 0.09499) => LSC_loss 0.85, Spatial_loss 2.26, Flat_loss 0.45, Train_acc 77.76, Test_acc 20.51
2025-02-14 23:57:30,407 [podnet.py] => Task 17, Epoch 24/160 (LR 0.09455) => LSC_loss 0.86, Spatial_loss 2.27, Flat_loss 0.45, Train_acc 77.33, Test_acc 22.10
2025-02-14 23:57:32,603 [podnet.py] => Task 17, Epoch 25/160 (LR 0.09410) => LSC_loss 0.86, Spatial_loss 2.31, Flat_loss 0.46, Train_acc 77.43, Test_acc 21.54
2025-02-14 23:57:34,745 [podnet.py] => Task 17, Epoch 26/160 (LR 0.09362) => LSC_loss 0.84, Spatial_loss 2.35, Flat_loss 0.46, Train_acc 77.33, Test_acc 21.28
2025-02-14 23:57:36,863 [podnet.py] => Task 17, Epoch 27/160 (LR 0.09314) => LSC_loss 0.87, Spatial_loss 2.28, Flat_loss 0.46, Train_acc 76.12, Test_acc 23.09
2025-02-14 23:57:39,070 [podnet.py] => Task 17, Epoch 28/160 (LR 0.09263) => LSC_loss 0.80, Spatial_loss 2.19, Flat_loss 0.46, Train_acc 79.45, Test_acc 21.86
2025-02-14 23:57:41,181 [podnet.py] => Task 17, Epoch 29/160 (LR 0.09211) => LSC_loss 0.80, Spatial_loss 2.13, Flat_loss 0.44, Train_acc 79.79, Test_acc 19.98
2025-02-14 23:57:43,318 [podnet.py] => Task 17, Epoch 30/160 (LR 0.09157) => LSC_loss 0.81, Spatial_loss 2.15, Flat_loss 0.45, Train_acc 78.83, Test_acc 21.59
2025-02-14 23:57:45,400 [podnet.py] => Task 17, Epoch 31/160 (LR 0.09102) => LSC_loss 0.78, Spatial_loss 2.20, Flat_loss 0.45, Train_acc 79.71, Test_acc 22.98
2025-02-14 23:57:47,555 [podnet.py] => Task 17, Epoch 32/160 (LR 0.09045) => LSC_loss 0.79, Spatial_loss 2.30, Flat_loss 0.46, Train_acc 79.88, Test_acc 20.59
2025-02-14 23:57:49,663 [podnet.py] => Task 17, Epoch 33/160 (LR 0.08987) => LSC_loss 0.77, Spatial_loss 2.15, Flat_loss 0.46, Train_acc 80.05, Test_acc 23.37
2025-02-14 23:57:51,779 [podnet.py] => Task 17, Epoch 34/160 (LR 0.08927) => LSC_loss 0.74, Spatial_loss 2.18, Flat_loss 0.45, Train_acc 81.21, Test_acc 16.91
2025-02-14 23:57:53,918 [podnet.py] => Task 17, Epoch 35/160 (LR 0.08865) => LSC_loss 0.84, Spatial_loss 2.26, Flat_loss 0.49, Train_acc 77.38, Test_acc 20.98
2025-02-14 23:57:56,062 [podnet.py] => Task 17, Epoch 36/160 (LR 0.08802) => LSC_loss 0.77, Spatial_loss 2.27, Flat_loss 0.47, Train_acc 79.81, Test_acc 22.59
2025-02-14 23:57:58,149 [podnet.py] => Task 17, Epoch 37/160 (LR 0.08738) => LSC_loss 0.76, Spatial_loss 2.23, Flat_loss 0.46, Train_acc 80.48, Test_acc 20.49
2025-02-14 23:58:00,273 [podnet.py] => Task 17, Epoch 38/160 (LR 0.08672) => LSC_loss 0.76, Spatial_loss 2.28, Flat_loss 0.46, Train_acc 81.12, Test_acc 21.88
2025-02-14 23:58:02,405 [podnet.py] => Task 17, Epoch 39/160 (LR 0.08604) => LSC_loss 0.73, Spatial_loss 2.25, Flat_loss 0.46, Train_acc 81.90, Test_acc 26.08
2025-02-14 23:58:04,561 [podnet.py] => Task 17, Epoch 40/160 (LR 0.08536) => LSC_loss 0.73, Spatial_loss 2.31, Flat_loss 0.46, Train_acc 81.10, Test_acc 22.86
2025-02-14 23:58:06,732 [podnet.py] => Task 17, Epoch 41/160 (LR 0.08465) => LSC_loss 0.72, Spatial_loss 2.17, Flat_loss 0.46, Train_acc 80.83, Test_acc 21.09
2025-02-14 23:58:08,840 [podnet.py] => Task 17, Epoch 42/160 (LR 0.08394) => LSC_loss 0.69, Spatial_loss 2.19, Flat_loss 0.44, Train_acc 81.86, Test_acc 22.22
2025-02-14 23:58:10,970 [podnet.py] => Task 17, Epoch 43/160 (LR 0.08321) => LSC_loss 0.73, Spatial_loss 2.26, Flat_loss 0.46, Train_acc 82.02, Test_acc 24.40
2025-02-14 23:58:13,070 [podnet.py] => Task 17, Epoch 44/160 (LR 0.08247) => LSC_loss 0.70, Spatial_loss 2.19, Flat_loss 0.45, Train_acc 82.62, Test_acc 23.39
2025-02-14 23:58:15,211 [podnet.py] => Task 17, Epoch 45/160 (LR 0.08172) => LSC_loss 0.71, Spatial_loss 2.19, Flat_loss 0.46, Train_acc 81.93, Test_acc 20.98
2025-02-14 23:58:17,365 [podnet.py] => Task 17, Epoch 46/160 (LR 0.08095) => LSC_loss 0.71, Spatial_loss 2.18, Flat_loss 0.46, Train_acc 81.12, Test_acc 22.41
2025-02-14 23:58:19,553 [podnet.py] => Task 17, Epoch 47/160 (LR 0.08018) => LSC_loss 0.70, Spatial_loss 2.16, Flat_loss 0.45, Train_acc 82.07, Test_acc 21.56
2025-02-14 23:58:21,699 [podnet.py] => Task 17, Epoch 48/160 (LR 0.07939) => LSC_loss 0.66, Spatial_loss 2.14, Flat_loss 0.45, Train_acc 83.00, Test_acc 22.78
2025-02-14 23:58:23,820 [podnet.py] => Task 17, Epoch 49/160 (LR 0.07859) => LSC_loss 0.66, Spatial_loss 2.12, Flat_loss 0.45, Train_acc 83.14, Test_acc 20.23
2025-02-14 23:58:25,969 [podnet.py] => Task 17, Epoch 50/160 (LR 0.07778) => LSC_loss 0.67, Spatial_loss 2.10, Flat_loss 0.45, Train_acc 83.57, Test_acc 22.90
2025-02-14 23:58:28,118 [podnet.py] => Task 17, Epoch 51/160 (LR 0.07696) => LSC_loss 0.66, Spatial_loss 2.05, Flat_loss 0.44, Train_acc 83.33, Test_acc 20.86
2025-02-14 23:58:30,221 [podnet.py] => Task 17, Epoch 52/160 (LR 0.07612) => LSC_loss 0.66, Spatial_loss 2.16, Flat_loss 0.45, Train_acc 83.50, Test_acc 24.46
2025-02-14 23:58:32,343 [podnet.py] => Task 17, Epoch 53/160 (LR 0.07528) => LSC_loss 0.60, Spatial_loss 2.01, Flat_loss 0.44, Train_acc 85.24, Test_acc 21.56
2025-02-14 23:58:34,496 [podnet.py] => Task 17, Epoch 54/160 (LR 0.07443) => LSC_loss 0.62, Spatial_loss 2.08, Flat_loss 0.43, Train_acc 85.12, Test_acc 23.24
2025-02-14 23:58:36,639 [podnet.py] => Task 17, Epoch 55/160 (LR 0.07357) => LSC_loss 0.62, Spatial_loss 2.12, Flat_loss 0.45, Train_acc 83.52, Test_acc 21.49
2025-02-14 23:58:38,753 [podnet.py] => Task 17, Epoch 56/160 (LR 0.07270) => LSC_loss 0.63, Spatial_loss 2.10, Flat_loss 0.44, Train_acc 84.52, Test_acc 22.12
2025-02-14 23:58:40,849 [podnet.py] => Task 17, Epoch 57/160 (LR 0.07182) => LSC_loss 0.61, Spatial_loss 2.10, Flat_loss 0.44, Train_acc 85.36, Test_acc 22.68
2025-02-14 23:58:42,991 [podnet.py] => Task 17, Epoch 58/160 (LR 0.07093) => LSC_loss 0.59, Spatial_loss 2.06, Flat_loss 0.43, Train_acc 85.45, Test_acc 22.08
2025-02-14 23:58:45,114 [podnet.py] => Task 17, Epoch 59/160 (LR 0.07004) => LSC_loss 0.63, Spatial_loss 2.11, Flat_loss 0.45, Train_acc 84.50, Test_acc 21.73
2025-02-14 23:58:47,201 [podnet.py] => Task 17, Epoch 60/160 (LR 0.06913) => LSC_loss 0.57, Spatial_loss 2.06, Flat_loss 0.43, Train_acc 86.19, Test_acc 21.01
2025-02-14 23:58:49,321 [podnet.py] => Task 17, Epoch 61/160 (LR 0.06822) => LSC_loss 0.60, Spatial_loss 2.08, Flat_loss 0.45, Train_acc 85.67, Test_acc 21.62
2025-02-14 23:58:51,433 [podnet.py] => Task 17, Epoch 62/160 (LR 0.06731) => LSC_loss 0.58, Spatial_loss 1.99, Flat_loss 0.43, Train_acc 86.10, Test_acc 23.49
2025-02-14 23:58:53,548 [podnet.py] => Task 17, Epoch 63/160 (LR 0.06638) => LSC_loss 0.55, Spatial_loss 2.05, Flat_loss 0.43, Train_acc 86.74, Test_acc 24.13
2025-02-14 23:58:55,642 [podnet.py] => Task 17, Epoch 64/160 (LR 0.06545) => LSC_loss 0.54, Spatial_loss 1.99, Flat_loss 0.43, Train_acc 87.17, Test_acc 20.71
2025-02-14 23:58:57,775 [podnet.py] => Task 17, Epoch 65/160 (LR 0.06451) => LSC_loss 0.55, Spatial_loss 1.93, Flat_loss 0.43, Train_acc 86.36, Test_acc 21.00
2025-02-14 23:58:59,849 [podnet.py] => Task 17, Epoch 66/160 (LR 0.06357) => LSC_loss 0.56, Spatial_loss 1.97, Flat_loss 0.42, Train_acc 86.33, Test_acc 24.37
2025-02-14 23:59:01,963 [podnet.py] => Task 17, Epoch 67/160 (LR 0.06262) => LSC_loss 0.55, Spatial_loss 2.01, Flat_loss 0.42, Train_acc 86.71, Test_acc 20.40
2025-02-14 23:59:04,123 [podnet.py] => Task 17, Epoch 68/160 (LR 0.06167) => LSC_loss 0.57, Spatial_loss 2.01, Flat_loss 0.44, Train_acc 86.17, Test_acc 21.84
2025-02-14 23:59:06,243 [podnet.py] => Task 17, Epoch 69/160 (LR 0.06072) => LSC_loss 0.51, Spatial_loss 1.99, Flat_loss 0.42, Train_acc 88.14, Test_acc 23.40
2025-02-14 23:59:08,383 [podnet.py] => Task 17, Epoch 70/160 (LR 0.05975) => LSC_loss 0.50, Spatial_loss 1.94, Flat_loss 0.42, Train_acc 88.43, Test_acc 23.66
2025-02-14 23:59:10,506 [podnet.py] => Task 17, Epoch 71/160 (LR 0.05879) => LSC_loss 0.51, Spatial_loss 1.99, Flat_loss 0.43, Train_acc 88.21, Test_acc 23.43
2025-02-14 23:59:12,716 [podnet.py] => Task 17, Epoch 72/160 (LR 0.05782) => LSC_loss 0.52, Spatial_loss 1.91, Flat_loss 0.42, Train_acc 87.71, Test_acc 20.86
2025-02-14 23:59:14,735 [podnet.py] => Task 17, Epoch 73/160 (LR 0.05685) => LSC_loss 0.51, Spatial_loss 1.94, Flat_loss 0.41, Train_acc 88.55, Test_acc 24.47
2025-02-14 23:59:16,848 [podnet.py] => Task 17, Epoch 74/160 (LR 0.05588) => LSC_loss 0.52, Spatial_loss 1.97, Flat_loss 0.43, Train_acc 87.40, Test_acc 23.24
2025-02-14 23:59:18,981 [podnet.py] => Task 17, Epoch 75/160 (LR 0.05490) => LSC_loss 0.50, Spatial_loss 1.90, Flat_loss 0.41, Train_acc 87.83, Test_acc 26.19
2025-02-14 23:59:21,117 [podnet.py] => Task 17, Epoch 76/160 (LR 0.05392) => LSC_loss 0.52, Spatial_loss 1.98, Flat_loss 0.43, Train_acc 87.52, Test_acc 24.27
2025-02-14 23:59:23,246 [podnet.py] => Task 17, Epoch 77/160 (LR 0.05294) => LSC_loss 0.50, Spatial_loss 1.90, Flat_loss 0.41, Train_acc 88.21, Test_acc 23.83
2025-02-14 23:59:25,378 [podnet.py] => Task 17, Epoch 78/160 (LR 0.05196) => LSC_loss 0.49, Spatial_loss 1.92, Flat_loss 0.41, Train_acc 88.83, Test_acc 22.99
2025-02-14 23:59:27,519 [podnet.py] => Task 17, Epoch 79/160 (LR 0.05098) => LSC_loss 0.44, Spatial_loss 1.83, Flat_loss 0.40, Train_acc 90.50, Test_acc 21.63
2025-02-14 23:59:29,605 [podnet.py] => Task 17, Epoch 80/160 (LR 0.05000) => LSC_loss 0.46, Spatial_loss 1.83, Flat_loss 0.40, Train_acc 89.62, Test_acc 25.26
2025-02-14 23:59:31,757 [podnet.py] => Task 17, Epoch 81/160 (LR 0.04902) => LSC_loss 0.45, Spatial_loss 1.78, Flat_loss 0.39, Train_acc 90.10, Test_acc 24.92
2025-02-14 23:59:33,911 [podnet.py] => Task 17, Epoch 82/160 (LR 0.04804) => LSC_loss 0.45, Spatial_loss 1.78, Flat_loss 0.40, Train_acc 90.14, Test_acc 24.01
2025-02-14 23:59:36,049 [podnet.py] => Task 17, Epoch 83/160 (LR 0.04706) => LSC_loss 0.43, Spatial_loss 1.79, Flat_loss 0.39, Train_acc 91.17, Test_acc 24.41
2025-02-14 23:59:38,190 [podnet.py] => Task 17, Epoch 84/160 (LR 0.04608) => LSC_loss 0.42, Spatial_loss 1.74, Flat_loss 0.38, Train_acc 90.90, Test_acc 23.48
2025-02-14 23:59:40,349 [podnet.py] => Task 17, Epoch 85/160 (LR 0.04510) => LSC_loss 0.41, Spatial_loss 1.75, Flat_loss 0.38, Train_acc 90.98, Test_acc 24.53
2025-02-14 23:59:42,431 [podnet.py] => Task 17, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 1.74, Flat_loss 0.38, Train_acc 91.17, Test_acc 21.67
2025-02-14 23:59:44,564 [podnet.py] => Task 17, Epoch 87/160 (LR 0.04315) => LSC_loss 0.39, Spatial_loss 1.76, Flat_loss 0.38, Train_acc 92.48, Test_acc 23.77
2025-02-14 23:59:46,749 [podnet.py] => Task 17, Epoch 88/160 (LR 0.04218) => LSC_loss 0.41, Spatial_loss 1.76, Flat_loss 0.38, Train_acc 91.29, Test_acc 19.73
2025-02-14 23:59:48,886 [podnet.py] => Task 17, Epoch 89/160 (LR 0.04121) => LSC_loss 0.40, Spatial_loss 1.76, Flat_loss 0.38, Train_acc 91.62, Test_acc 23.47
2025-02-14 23:59:50,998 [podnet.py] => Task 17, Epoch 90/160 (LR 0.04025) => LSC_loss 0.39, Spatial_loss 1.68, Flat_loss 0.38, Train_acc 91.64, Test_acc 22.37
2025-02-14 23:59:53,136 [podnet.py] => Task 17, Epoch 91/160 (LR 0.03928) => LSC_loss 0.40, Spatial_loss 1.70, Flat_loss 0.37, Train_acc 91.76, Test_acc 25.77
2025-02-14 23:59:55,299 [podnet.py] => Task 17, Epoch 92/160 (LR 0.03833) => LSC_loss 0.39, Spatial_loss 1.63, Flat_loss 0.37, Train_acc 91.14, Test_acc 22.43
2025-02-14 23:59:57,486 [podnet.py] => Task 17, Epoch 93/160 (LR 0.03738) => LSC_loss 0.37, Spatial_loss 1.60, Flat_loss 0.37, Train_acc 93.07, Test_acc 24.63
2025-02-14 23:59:59,664 [podnet.py] => Task 17, Epoch 94/160 (LR 0.03643) => LSC_loss 0.37, Spatial_loss 1.75, Flat_loss 0.38, Train_acc 92.38, Test_acc 23.70
2025-02-15 00:00:01,812 [podnet.py] => Task 17, Epoch 95/160 (LR 0.03549) => LSC_loss 0.37, Spatial_loss 1.82, Flat_loss 0.39, Train_acc 92.21, Test_acc 24.10
2025-02-15 00:00:03,929 [podnet.py] => Task 17, Epoch 96/160 (LR 0.03455) => LSC_loss 0.35, Spatial_loss 1.67, Flat_loss 0.37, Train_acc 93.21, Test_acc 20.82
2025-02-15 00:00:06,101 [podnet.py] => Task 17, Epoch 97/160 (LR 0.03362) => LSC_loss 0.36, Spatial_loss 1.70, Flat_loss 0.37, Train_acc 93.19, Test_acc 23.28
2025-02-15 00:00:08,279 [podnet.py] => Task 17, Epoch 98/160 (LR 0.03269) => LSC_loss 0.35, Spatial_loss 1.63, Flat_loss 0.36, Train_acc 93.40, Test_acc 24.66
2025-02-15 00:00:10,419 [podnet.py] => Task 17, Epoch 99/160 (LR 0.03178) => LSC_loss 0.35, Spatial_loss 1.59, Flat_loss 0.36, Train_acc 92.67, Test_acc 25.44
2025-02-15 00:00:12,526 [podnet.py] => Task 17, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.62, Flat_loss 0.36, Train_acc 93.79, Test_acc 24.17
2025-02-15 00:00:14,725 [podnet.py] => Task 17, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.57, Flat_loss 0.36, Train_acc 94.38, Test_acc 23.53
2025-02-15 00:00:16,856 [podnet.py] => Task 17, Epoch 102/160 (LR 0.02907) => LSC_loss 0.33, Spatial_loss 1.50, Flat_loss 0.35, Train_acc 94.02, Test_acc 23.78
2025-02-15 00:00:18,986 [podnet.py] => Task 17, Epoch 103/160 (LR 0.02818) => LSC_loss 0.33, Spatial_loss 1.62, Flat_loss 0.36, Train_acc 93.81, Test_acc 23.22
2025-02-15 00:00:21,139 [podnet.py] => Task 17, Epoch 104/160 (LR 0.02730) => LSC_loss 0.31, Spatial_loss 1.53, Flat_loss 0.34, Train_acc 94.69, Test_acc 22.77
2025-02-15 00:00:23,259 [podnet.py] => Task 17, Epoch 105/160 (LR 0.02643) => LSC_loss 0.32, Spatial_loss 1.59, Flat_loss 0.35, Train_acc 94.19, Test_acc 25.03
2025-02-15 00:00:25,383 [podnet.py] => Task 17, Epoch 106/160 (LR 0.02557) => LSC_loss 0.31, Spatial_loss 1.52, Flat_loss 0.34, Train_acc 94.57, Test_acc 24.18
2025-02-15 00:00:27,495 [podnet.py] => Task 17, Epoch 107/160 (LR 0.02472) => LSC_loss 0.33, Spatial_loss 1.54, Flat_loss 0.34, Train_acc 94.00, Test_acc 24.87
2025-02-15 00:00:29,656 [podnet.py] => Task 17, Epoch 108/160 (LR 0.02388) => LSC_loss 0.30, Spatial_loss 1.51, Flat_loss 0.34, Train_acc 94.81, Test_acc 26.14
2025-02-15 00:00:31,821 [podnet.py] => Task 17, Epoch 109/160 (LR 0.02304) => LSC_loss 0.29, Spatial_loss 1.48, Flat_loss 0.33, Train_acc 94.98, Test_acc 23.86
2025-02-15 00:00:33,931 [podnet.py] => Task 17, Epoch 110/160 (LR 0.02222) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.34, Train_acc 94.48, Test_acc 25.73
2025-02-15 00:00:36,088 [podnet.py] => Task 17, Epoch 111/160 (LR 0.02141) => LSC_loss 0.30, Spatial_loss 1.49, Flat_loss 0.33, Train_acc 94.64, Test_acc 26.89
2025-02-15 00:00:38,211 [podnet.py] => Task 17, Epoch 112/160 (LR 0.02061) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.32, Train_acc 95.40, Test_acc 25.83
2025-02-15 00:00:40,329 [podnet.py] => Task 17, Epoch 113/160 (LR 0.01982) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.32, Train_acc 95.38, Test_acc 26.29
2025-02-15 00:00:42,525 [podnet.py] => Task 17, Epoch 114/160 (LR 0.01905) => LSC_loss 0.30, Spatial_loss 1.47, Flat_loss 0.33, Train_acc 94.88, Test_acc 24.23
2025-02-15 00:00:44,674 [podnet.py] => Task 17, Epoch 115/160 (LR 0.01828) => LSC_loss 0.28, Spatial_loss 1.45, Flat_loss 0.33, Train_acc 95.52, Test_acc 23.36
2025-02-15 00:00:46,817 [podnet.py] => Task 17, Epoch 116/160 (LR 0.01753) => LSC_loss 0.27, Spatial_loss 1.40, Flat_loss 0.33, Train_acc 95.62, Test_acc 25.68
2025-02-15 00:00:48,925 [podnet.py] => Task 17, Epoch 117/160 (LR 0.01679) => LSC_loss 0.27, Spatial_loss 1.40, Flat_loss 0.32, Train_acc 96.21, Test_acc 24.74
2025-02-15 00:00:51,076 [podnet.py] => Task 17, Epoch 118/160 (LR 0.01606) => LSC_loss 0.27, Spatial_loss 1.41, Flat_loss 0.32, Train_acc 95.90, Test_acc 24.11
2025-02-15 00:00:53,225 [podnet.py] => Task 17, Epoch 119/160 (LR 0.01535) => LSC_loss 0.27, Spatial_loss 1.43, Flat_loss 0.32, Train_acc 95.31, Test_acc 25.21
2025-02-15 00:00:55,290 [podnet.py] => Task 17, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.31, Train_acc 96.74, Test_acc 26.04
2025-02-15 00:00:57,366 [podnet.py] => Task 17, Epoch 121/160 (LR 0.01396) => LSC_loss 0.27, Spatial_loss 1.41, Flat_loss 0.32, Train_acc 95.74, Test_acc 25.52
2025-02-15 00:00:59,504 [podnet.py] => Task 17, Epoch 122/160 (LR 0.01328) => LSC_loss 0.26, Spatial_loss 1.40, Flat_loss 0.32, Train_acc 96.07, Test_acc 25.73
2025-02-15 00:01:01,583 [podnet.py] => Task 17, Epoch 123/160 (LR 0.01262) => LSC_loss 0.26, Spatial_loss 1.32, Flat_loss 0.31, Train_acc 96.29, Test_acc 26.11
2025-02-15 00:01:03,730 [podnet.py] => Task 17, Epoch 124/160 (LR 0.01198) => LSC_loss 0.26, Spatial_loss 1.32, Flat_loss 0.31, Train_acc 96.33, Test_acc 26.94
2025-02-15 00:01:05,851 [podnet.py] => Task 17, Epoch 125/160 (LR 0.01135) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.31, Train_acc 96.40, Test_acc 26.48
2025-02-15 00:01:08,001 [podnet.py] => Task 17, Epoch 126/160 (LR 0.01073) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.30, Train_acc 96.62, Test_acc 24.91
2025-02-15 00:01:10,064 [podnet.py] => Task 17, Epoch 127/160 (LR 0.01013) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.30, Train_acc 96.67, Test_acc 26.43
2025-02-15 00:01:12,271 [podnet.py] => Task 17, Epoch 128/160 (LR 0.00955) => LSC_loss 0.25, Spatial_loss 1.33, Flat_loss 0.30, Train_acc 96.48, Test_acc 25.74
2025-02-15 00:01:14,384 [podnet.py] => Task 17, Epoch 129/160 (LR 0.00898) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.30, Train_acc 96.45, Test_acc 25.49
2025-02-15 00:01:16,516 [podnet.py] => Task 17, Epoch 130/160 (LR 0.00843) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.30, Train_acc 96.69, Test_acc 25.00
2025-02-15 00:01:18,592 [podnet.py] => Task 17, Epoch 131/160 (LR 0.00789) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.30, Train_acc 97.00, Test_acc 26.81
2025-02-15 00:01:20,750 [podnet.py] => Task 17, Epoch 132/160 (LR 0.00737) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.30, Train_acc 96.40, Test_acc 26.83
2025-02-15 00:01:22,879 [podnet.py] => Task 17, Epoch 133/160 (LR 0.00686) => LSC_loss 0.24, Spatial_loss 1.30, Flat_loss 0.30, Train_acc 97.10, Test_acc 26.24
2025-02-15 00:01:25,017 [podnet.py] => Task 17, Epoch 134/160 (LR 0.00638) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.29, Train_acc 96.55, Test_acc 25.90
2025-02-15 00:01:27,184 [podnet.py] => Task 17, Epoch 135/160 (LR 0.00590) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.29, Train_acc 96.79, Test_acc 25.21
2025-02-15 00:01:29,334 [podnet.py] => Task 17, Epoch 136/160 (LR 0.00545) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.29, Train_acc 96.86, Test_acc 26.23
2025-02-15 00:01:31,499 [podnet.py] => Task 17, Epoch 137/160 (LR 0.00501) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.29, Train_acc 96.81, Test_acc 25.79
2025-02-15 00:01:33,572 [podnet.py] => Task 17, Epoch 138/160 (LR 0.00459) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.29, Train_acc 96.69, Test_acc 25.60
2025-02-15 00:01:35,699 [podnet.py] => Task 17, Epoch 139/160 (LR 0.00419) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.29, Train_acc 96.62, Test_acc 25.76
2025-02-15 00:01:37,801 [podnet.py] => Task 17, Epoch 140/160 (LR 0.00381) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.29, Train_acc 97.31, Test_acc 25.69
2025-02-15 00:01:39,914 [podnet.py] => Task 17, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.29, Train_acc 97.64, Test_acc 26.61
2025-02-15 00:01:42,061 [podnet.py] => Task 17, Epoch 142/160 (LR 0.00309) => LSC_loss 0.24, Spatial_loss 1.15, Flat_loss 0.28, Train_acc 97.24, Test_acc 25.30
2025-02-15 00:01:44,241 [podnet.py] => Task 17, Epoch 143/160 (LR 0.00276) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.29, Train_acc 97.00, Test_acc 25.81
2025-02-15 00:01:46,397 [podnet.py] => Task 17, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.29, Train_acc 97.21, Test_acc 26.73
2025-02-15 00:01:48,564 [podnet.py] => Task 17, Epoch 145/160 (LR 0.00215) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.29, Train_acc 96.83, Test_acc 25.81
2025-02-15 00:01:50,689 [podnet.py] => Task 17, Epoch 146/160 (LR 0.00188) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.29, Train_acc 96.98, Test_acc 26.26
2025-02-15 00:01:52,843 [podnet.py] => Task 17, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.28, Train_acc 97.57, Test_acc 26.04
2025-02-15 00:01:54,950 [podnet.py] => Task 17, Epoch 148/160 (LR 0.00138) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.28, Train_acc 97.24, Test_acc 26.49
2025-02-15 00:01:57,095 [podnet.py] => Task 17, Epoch 149/160 (LR 0.00116) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.28, Train_acc 97.43, Test_acc 26.81
2025-02-15 00:01:59,253 [podnet.py] => Task 17, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 1.12, Flat_loss 0.29, Train_acc 97.50, Test_acc 26.43
2025-02-15 00:02:01,398 [podnet.py] => Task 17, Epoch 151/160 (LR 0.00078) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.28, Train_acc 97.14, Test_acc 26.54
2025-02-15 00:02:03,554 [podnet.py] => Task 17, Epoch 152/160 (LR 0.00062) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.28, Train_acc 97.21, Test_acc 26.51
2025-02-15 00:02:05,700 [podnet.py] => Task 17, Epoch 153/160 (LR 0.00047) => LSC_loss 0.23, Spatial_loss 1.12, Flat_loss 0.29, Train_acc 97.12, Test_acc 26.16
2025-02-15 00:02:07,871 [podnet.py] => Task 17, Epoch 154/160 (LR 0.00035) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.29, Train_acc 97.83, Test_acc 26.32
2025-02-15 00:02:10,026 [podnet.py] => Task 17, Epoch 155/160 (LR 0.00024) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.28, Train_acc 96.83, Test_acc 26.36
2025-02-15 00:02:12,131 [podnet.py] => Task 17, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.09, Flat_loss 0.28, Train_acc 97.62, Test_acc 26.39
2025-02-15 00:02:14,290 [podnet.py] => Task 17, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.05, Flat_loss 0.28, Train_acc 97.79, Test_acc 26.48
2025-02-15 00:02:16,392 [podnet.py] => Task 17, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.28, Train_acc 97.62, Test_acc 26.34
2025-02-15 00:02:18,586 [podnet.py] => Task 17, Epoch 159/160 (LR 0.00001) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.28, Train_acc 97.14, Test_acc 26.34
2025-02-15 00:02:20,681 [podnet.py] => Task 17, Epoch 160/160 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.28, Train_acc 97.62, Test_acc 26.24
2025-02-15 00:02:20,682 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 00:02:20,682 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:02:52,780 [podnet.py] => The size of finetune dataset: 1800
2025-02-15 00:02:54,398 [podnet.py] => Task 17, Epoch 1/20 (LR 0.00497) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 94.83, Test_acc 27.21
2025-02-15 00:02:56,006 [podnet.py] => Task 17, Epoch 2/20 (LR 0.00488) => LSC_loss 0.24, Spatial_loss 1.42, Flat_loss 0.17, Train_acc 97.94, Test_acc 28.58
2025-02-15 00:02:57,636 [podnet.py] => Task 17, Epoch 3/20 (LR 0.00473) => LSC_loss 0.20, Spatial_loss 1.40, Flat_loss 0.16, Train_acc 97.83, Test_acc 27.06
2025-02-15 00:02:59,265 [podnet.py] => Task 17, Epoch 4/20 (LR 0.00452) => LSC_loss 0.22, Spatial_loss 1.37, Flat_loss 0.16, Train_acc 98.00, Test_acc 26.97
2025-02-15 00:03:00,816 [podnet.py] => Task 17, Epoch 5/20 (LR 0.00427) => LSC_loss 0.24, Spatial_loss 1.48, Flat_loss 0.19, Train_acc 97.78, Test_acc 27.81
2025-02-15 00:03:02,436 [podnet.py] => Task 17, Epoch 6/20 (LR 0.00397) => LSC_loss 0.19, Spatial_loss 1.46, Flat_loss 0.17, Train_acc 97.50, Test_acc 28.20
2025-02-15 00:03:04,110 [podnet.py] => Task 17, Epoch 7/20 (LR 0.00363) => LSC_loss 0.18, Spatial_loss 1.58, Flat_loss 0.16, Train_acc 97.89, Test_acc 27.28
2025-02-15 00:03:05,712 [podnet.py] => Task 17, Epoch 8/20 (LR 0.00327) => LSC_loss 0.19, Spatial_loss 1.37, Flat_loss 0.15, Train_acc 98.61, Test_acc 27.11
2025-02-15 00:03:07,349 [podnet.py] => Task 17, Epoch 9/20 (LR 0.00289) => LSC_loss 0.20, Spatial_loss 1.35, Flat_loss 0.15, Train_acc 98.17, Test_acc 28.26
2025-02-15 00:03:08,978 [podnet.py] => Task 17, Epoch 10/20 (LR 0.00250) => LSC_loss 0.17, Spatial_loss 1.26, Flat_loss 0.14, Train_acc 98.44, Test_acc 28.11
2025-02-15 00:03:10,604 [podnet.py] => Task 17, Epoch 11/20 (LR 0.00211) => LSC_loss 0.21, Spatial_loss 1.25, Flat_loss 0.15, Train_acc 98.72, Test_acc 28.48
2025-02-15 00:03:12,234 [podnet.py] => Task 17, Epoch 12/20 (LR 0.00173) => LSC_loss 0.21, Spatial_loss 1.32, Flat_loss 0.14, Train_acc 98.17, Test_acc 27.46
2025-02-15 00:03:13,864 [podnet.py] => Task 17, Epoch 13/20 (LR 0.00137) => LSC_loss 0.17, Spatial_loss 1.24, Flat_loss 0.14, Train_acc 98.44, Test_acc 27.24
2025-02-15 00:03:15,440 [podnet.py] => Task 17, Epoch 14/20 (LR 0.00103) => LSC_loss 0.20, Spatial_loss 1.31, Flat_loss 0.15, Train_acc 98.39, Test_acc 27.94
2025-02-15 00:03:16,963 [podnet.py] => Task 17, Epoch 15/20 (LR 0.00073) => LSC_loss 0.18, Spatial_loss 1.30, Flat_loss 0.14, Train_acc 98.28, Test_acc 28.03
2025-02-15 00:03:18,477 [podnet.py] => Task 17, Epoch 16/20 (LR 0.00048) => LSC_loss 0.18, Spatial_loss 1.37, Flat_loss 0.15, Train_acc 98.89, Test_acc 28.26
2025-02-15 00:03:20,136 [podnet.py] => Task 17, Epoch 17/20 (LR 0.00027) => LSC_loss 0.18, Spatial_loss 1.35, Flat_loss 0.14, Train_acc 98.83, Test_acc 27.89
2025-02-15 00:03:21,735 [podnet.py] => Task 17, Epoch 18/20 (LR 0.00012) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.13, Train_acc 98.94, Test_acc 28.08
2025-02-15 00:03:23,316 [podnet.py] => Task 17, Epoch 19/20 (LR 0.00003) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.14, Train_acc 98.72, Test_acc 28.11
2025-02-15 00:03:24,887 [podnet.py] => Task 17, Epoch 20/20 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.28, Flat_loss 0.14, Train_acc 98.83, Test_acc 28.16
2025-02-15 00:03:24,889 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:03:58,590 [podnet.py] => Exemplar size: 1800
2025-02-15 00:03:58,590 [trainer.py] => CNN: {'total': 28.16, '00-09': 34.3, '10-19': 11.2, '20-29': 19.6, '30-39': 18.0, '40-49': 31.2, '50-59': 19.2, '60-69': 30.9, '70-79': 32.5, '80-89': 56.5, 'old': 26.68, 'new': 53.2}
2025-02-15 00:03:58,590 [trainer.py] => NME: {'total': 27.86, '00-09': 41.6, '10-19': 12.2, '20-29': 19.0, '30-39': 17.0, '40-49': 31.0, '50-59': 15.6, '60-69': 29.9, '70-79': 33.4, '80-89': 51.0, 'old': 26.67, 'new': 48.0}
2025-02-15 00:03:58,590 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24, 28.7, 28.87, 28.16]
2025-02-15 00:03:58,590 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85, 55.0, 56.02, 54.61]
2025-02-15 00:03:58,590 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08, 28.69, 29.13, 27.86]
2025-02-15 00:03:58,590 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49, 55.08, 55.31, 54.06]

2025-02-15 00:03:58,591 [trainer.py] => Average Accuracy (CNN): 42.99111111111111
2025-02-15 00:03:58,591 [trainer.py] => Average Accuracy (NME): 42.48833333333333
2025-02-15 00:03:58,591 [trainer.py] => All params: 523857
2025-02-15 00:03:58,591 [trainer.py] => Trainable params: 523857
2025-02-15 00:03:58,592 [podnet.py] => Learning on 90-95
2025-02-15 00:03:58,624 [podnet.py] => Adaptive factor: 4.358898943540674
2025-02-15 00:04:00,836 [podnet.py] => Task 18, Epoch 1/160 (LR 0.09999) => LSC_loss 2.92, Spatial_loss 3.73, Flat_loss 1.42, Train_acc 43.70, Test_acc 15.14
2025-02-15 00:04:03,045 [podnet.py] => Task 18, Epoch 2/160 (LR 0.09996) => LSC_loss 1.63, Spatial_loss 3.16, Flat_loss 0.81, Train_acc 56.60, Test_acc 18.58
2025-02-15 00:04:05,230 [podnet.py] => Task 18, Epoch 3/160 (LR 0.09991) => LSC_loss 1.42, Spatial_loss 3.05, Flat_loss 0.66, Train_acc 61.44, Test_acc 12.95
2025-02-15 00:04:07,392 [podnet.py] => Task 18, Epoch 4/160 (LR 0.09985) => LSC_loss 1.37, Spatial_loss 3.07, Flat_loss 0.62, Train_acc 63.98, Test_acc 16.84
2025-02-15 00:04:09,515 [podnet.py] => Task 18, Epoch 5/160 (LR 0.09976) => LSC_loss 1.32, Spatial_loss 2.92, Flat_loss 0.61, Train_acc 64.47, Test_acc 16.02
2025-02-15 00:04:11,666 [podnet.py] => Task 18, Epoch 6/160 (LR 0.09965) => LSC_loss 1.22, Spatial_loss 2.86, Flat_loss 0.57, Train_acc 67.51, Test_acc 19.58
2025-02-15 00:04:13,848 [podnet.py] => Task 18, Epoch 7/160 (LR 0.09953) => LSC_loss 1.19, Spatial_loss 2.94, Flat_loss 0.57, Train_acc 68.28, Test_acc 17.80
2025-02-15 00:04:16,007 [podnet.py] => Task 18, Epoch 8/160 (LR 0.09938) => LSC_loss 1.15, Spatial_loss 2.80, Flat_loss 0.54, Train_acc 69.77, Test_acc 17.33
2025-02-15 00:04:18,255 [podnet.py] => Task 18, Epoch 9/160 (LR 0.09922) => LSC_loss 1.12, Spatial_loss 2.74, Flat_loss 0.54, Train_acc 70.35, Test_acc 16.86
2025-02-15 00:04:20,419 [podnet.py] => Task 18, Epoch 10/160 (LR 0.09904) => LSC_loss 1.09, Spatial_loss 2.66, Flat_loss 0.52, Train_acc 70.56, Test_acc 18.19
2025-02-15 00:04:22,615 [podnet.py] => Task 18, Epoch 11/160 (LR 0.09884) => LSC_loss 1.07, Spatial_loss 2.74, Flat_loss 0.53, Train_acc 71.77, Test_acc 21.67
2025-02-15 00:04:24,780 [podnet.py] => Task 18, Epoch 12/160 (LR 0.09862) => LSC_loss 1.02, Spatial_loss 2.67, Flat_loss 0.52, Train_acc 73.19, Test_acc 20.08
2025-02-15 00:04:26,994 [podnet.py] => Task 18, Epoch 13/160 (LR 0.09838) => LSC_loss 1.05, Spatial_loss 2.72, Flat_loss 0.53, Train_acc 72.44, Test_acc 17.67
2025-02-15 00:04:29,183 [podnet.py] => Task 18, Epoch 14/160 (LR 0.09812) => LSC_loss 0.92, Spatial_loss 2.63, Flat_loss 0.50, Train_acc 76.56, Test_acc 16.07
2025-02-15 00:04:31,401 [podnet.py] => Task 18, Epoch 15/160 (LR 0.09785) => LSC_loss 0.92, Spatial_loss 2.65, Flat_loss 0.49, Train_acc 76.28, Test_acc 19.45
2025-02-15 00:04:33,660 [podnet.py] => Task 18, Epoch 16/160 (LR 0.09755) => LSC_loss 0.92, Spatial_loss 2.72, Flat_loss 0.50, Train_acc 75.12, Test_acc 19.48
2025-02-15 00:04:35,881 [podnet.py] => Task 18, Epoch 17/160 (LR 0.09724) => LSC_loss 0.93, Spatial_loss 2.65, Flat_loss 0.51, Train_acc 75.91, Test_acc 17.85
2025-02-15 00:04:38,075 [podnet.py] => Task 18, Epoch 18/160 (LR 0.09691) => LSC_loss 0.91, Spatial_loss 2.58, Flat_loss 0.49, Train_acc 76.12, Test_acc 17.92
2025-02-15 00:04:40,296 [podnet.py] => Task 18, Epoch 19/160 (LR 0.09656) => LSC_loss 0.90, Spatial_loss 2.75, Flat_loss 0.49, Train_acc 77.21, Test_acc 16.34
2025-02-15 00:04:42,472 [podnet.py] => Task 18, Epoch 20/160 (LR 0.09619) => LSC_loss 0.88, Spatial_loss 2.70, Flat_loss 0.50, Train_acc 77.40, Test_acc 22.36
2025-02-15 00:04:44,584 [podnet.py] => Task 18, Epoch 21/160 (LR 0.09581) => LSC_loss 0.89, Spatial_loss 2.66, Flat_loss 0.49, Train_acc 76.60, Test_acc 21.84
2025-02-15 00:04:46,796 [podnet.py] => Task 18, Epoch 22/160 (LR 0.09541) => LSC_loss 0.88, Spatial_loss 2.64, Flat_loss 0.50, Train_acc 76.58, Test_acc 17.17
2025-02-15 00:04:48,995 [podnet.py] => Task 18, Epoch 23/160 (LR 0.09499) => LSC_loss 0.88, Spatial_loss 2.59, Flat_loss 0.49, Train_acc 77.51, Test_acc 19.92
2025-02-15 00:04:51,181 [podnet.py] => Task 18, Epoch 24/160 (LR 0.09455) => LSC_loss 0.80, Spatial_loss 2.53, Flat_loss 0.47, Train_acc 79.63, Test_acc 18.68
2025-02-15 00:04:53,304 [podnet.py] => Task 18, Epoch 25/160 (LR 0.09410) => LSC_loss 0.81, Spatial_loss 2.65, Flat_loss 0.49, Train_acc 79.02, Test_acc 19.11
2025-02-15 00:04:55,526 [podnet.py] => Task 18, Epoch 26/160 (LR 0.09362) => LSC_loss 0.84, Spatial_loss 2.54, Flat_loss 0.49, Train_acc 77.42, Test_acc 18.97
2025-02-15 00:04:57,694 [podnet.py] => Task 18, Epoch 27/160 (LR 0.09314) => LSC_loss 0.79, Spatial_loss 2.50, Flat_loss 0.49, Train_acc 79.74, Test_acc 18.34
2025-02-15 00:04:59,890 [podnet.py] => Task 18, Epoch 28/160 (LR 0.09263) => LSC_loss 0.79, Spatial_loss 2.56, Flat_loss 0.48, Train_acc 79.65, Test_acc 22.61
2025-02-15 00:05:02,035 [podnet.py] => Task 18, Epoch 29/160 (LR 0.09211) => LSC_loss 0.78, Spatial_loss 2.52, Flat_loss 0.48, Train_acc 79.58, Test_acc 22.28
2025-02-15 00:05:04,215 [podnet.py] => Task 18, Epoch 30/160 (LR 0.09157) => LSC_loss 0.76, Spatial_loss 2.49, Flat_loss 0.47, Train_acc 81.26, Test_acc 17.55
2025-02-15 00:05:06,426 [podnet.py] => Task 18, Epoch 31/160 (LR 0.09102) => LSC_loss 0.83, Spatial_loss 2.66, Flat_loss 0.50, Train_acc 78.07, Test_acc 22.17
2025-02-15 00:05:08,646 [podnet.py] => Task 18, Epoch 32/160 (LR 0.09045) => LSC_loss 0.79, Spatial_loss 2.52, Flat_loss 0.49, Train_acc 79.26, Test_acc 23.58
2025-02-15 00:05:10,797 [podnet.py] => Task 18, Epoch 33/160 (LR 0.08987) => LSC_loss 0.75, Spatial_loss 2.55, Flat_loss 0.49, Train_acc 81.40, Test_acc 17.71
2025-02-15 00:05:13,029 [podnet.py] => Task 18, Epoch 34/160 (LR 0.08927) => LSC_loss 0.73, Spatial_loss 2.49, Flat_loss 0.47, Train_acc 81.40, Test_acc 17.28
2025-02-15 00:05:15,235 [podnet.py] => Task 18, Epoch 35/160 (LR 0.08865) => LSC_loss 0.73, Spatial_loss 2.47, Flat_loss 0.48, Train_acc 80.91, Test_acc 18.85
2025-02-15 00:05:17,402 [podnet.py] => Task 18, Epoch 36/160 (LR 0.08802) => LSC_loss 0.77, Spatial_loss 2.55, Flat_loss 0.49, Train_acc 80.26, Test_acc 14.22
2025-02-15 00:05:19,618 [podnet.py] => Task 18, Epoch 37/160 (LR 0.08738) => LSC_loss 0.75, Spatial_loss 2.56, Flat_loss 0.49, Train_acc 80.65, Test_acc 20.58
2025-02-15 00:05:21,864 [podnet.py] => Task 18, Epoch 38/160 (LR 0.08672) => LSC_loss 0.66, Spatial_loss 2.37, Flat_loss 0.46, Train_acc 83.77, Test_acc 18.05
2025-02-15 00:05:24,054 [podnet.py] => Task 18, Epoch 39/160 (LR 0.08604) => LSC_loss 0.66, Spatial_loss 2.36, Flat_loss 0.44, Train_acc 83.47, Test_acc 18.96
2025-02-15 00:05:26,246 [podnet.py] => Task 18, Epoch 40/160 (LR 0.08536) => LSC_loss 0.68, Spatial_loss 2.39, Flat_loss 0.46, Train_acc 83.91, Test_acc 19.87
2025-02-15 00:05:28,382 [podnet.py] => Task 18, Epoch 41/160 (LR 0.08465) => LSC_loss 0.69, Spatial_loss 2.46, Flat_loss 0.46, Train_acc 82.33, Test_acc 21.49
2025-02-15 00:05:30,661 [podnet.py] => Task 18, Epoch 42/160 (LR 0.08394) => LSC_loss 0.73, Spatial_loss 2.55, Flat_loss 0.48, Train_acc 81.70, Test_acc 17.12
2025-02-15 00:05:32,935 [podnet.py] => Task 18, Epoch 43/160 (LR 0.08321) => LSC_loss 0.72, Spatial_loss 2.52, Flat_loss 0.47, Train_acc 82.44, Test_acc 16.71
2025-02-15 00:05:35,124 [podnet.py] => Task 18, Epoch 44/160 (LR 0.08247) => LSC_loss 0.70, Spatial_loss 2.53, Flat_loss 0.48, Train_acc 81.56, Test_acc 19.65
2025-02-15 00:05:37,351 [podnet.py] => Task 18, Epoch 45/160 (LR 0.08172) => LSC_loss 0.70, Spatial_loss 2.51, Flat_loss 0.47, Train_acc 82.12, Test_acc 21.65
2025-02-15 00:05:39,510 [podnet.py] => Task 18, Epoch 46/160 (LR 0.08095) => LSC_loss 0.63, Spatial_loss 2.35, Flat_loss 0.44, Train_acc 84.72, Test_acc 19.79
2025-02-15 00:05:41,707 [podnet.py] => Task 18, Epoch 47/160 (LR 0.08018) => LSC_loss 0.65, Spatial_loss 2.48, Flat_loss 0.47, Train_acc 83.40, Test_acc 20.06
2025-02-15 00:05:43,918 [podnet.py] => Task 18, Epoch 48/160 (LR 0.07939) => LSC_loss 0.63, Spatial_loss 2.31, Flat_loss 0.44, Train_acc 84.72, Test_acc 18.73
2025-02-15 00:05:46,119 [podnet.py] => Task 18, Epoch 49/160 (LR 0.07859) => LSC_loss 0.62, Spatial_loss 2.27, Flat_loss 0.44, Train_acc 84.28, Test_acc 23.49
2025-02-15 00:05:48,329 [podnet.py] => Task 18, Epoch 50/160 (LR 0.07778) => LSC_loss 0.62, Spatial_loss 2.34, Flat_loss 0.44, Train_acc 85.05, Test_acc 22.03
2025-02-15 00:05:50,597 [podnet.py] => Task 18, Epoch 51/160 (LR 0.07696) => LSC_loss 0.58, Spatial_loss 2.35, Flat_loss 0.44, Train_acc 85.56, Test_acc 17.26
2025-02-15 00:05:52,785 [podnet.py] => Task 18, Epoch 52/160 (LR 0.07612) => LSC_loss 0.62, Spatial_loss 2.38, Flat_loss 0.46, Train_acc 84.28, Test_acc 21.18
2025-02-15 00:05:54,964 [podnet.py] => Task 18, Epoch 53/160 (LR 0.07528) => LSC_loss 0.64, Spatial_loss 2.30, Flat_loss 0.45, Train_acc 83.98, Test_acc 21.47
2025-02-15 00:05:57,201 [podnet.py] => Task 18, Epoch 54/160 (LR 0.07443) => LSC_loss 0.61, Spatial_loss 2.32, Flat_loss 0.45, Train_acc 84.37, Test_acc 16.66
2025-02-15 00:05:59,391 [podnet.py] => Task 18, Epoch 55/160 (LR 0.07357) => LSC_loss 0.58, Spatial_loss 2.41, Flat_loss 0.44, Train_acc 85.47, Test_acc 23.63
2025-02-15 00:06:01,567 [podnet.py] => Task 18, Epoch 56/160 (LR 0.07270) => LSC_loss 0.57, Spatial_loss 2.26, Flat_loss 0.43, Train_acc 86.33, Test_acc 23.72
2025-02-15 00:06:03,726 [podnet.py] => Task 18, Epoch 57/160 (LR 0.07182) => LSC_loss 0.52, Spatial_loss 2.23, Flat_loss 0.42, Train_acc 87.47, Test_acc 16.97
2025-02-15 00:06:05,960 [podnet.py] => Task 18, Epoch 58/160 (LR 0.07093) => LSC_loss 0.55, Spatial_loss 2.31, Flat_loss 0.43, Train_acc 86.47, Test_acc 22.62
2025-02-15 00:06:08,135 [podnet.py] => Task 18, Epoch 59/160 (LR 0.07004) => LSC_loss 0.54, Spatial_loss 2.32, Flat_loss 0.44, Train_acc 87.14, Test_acc 22.52
2025-02-15 00:06:10,354 [podnet.py] => Task 18, Epoch 60/160 (LR 0.06913) => LSC_loss 0.57, Spatial_loss 2.28, Flat_loss 0.44, Train_acc 85.67, Test_acc 22.12
2025-02-15 00:06:12,505 [podnet.py] => Task 18, Epoch 61/160 (LR 0.06822) => LSC_loss 0.56, Spatial_loss 2.36, Flat_loss 0.44, Train_acc 86.28, Test_acc 22.13
2025-02-15 00:06:14,664 [podnet.py] => Task 18, Epoch 62/160 (LR 0.06731) => LSC_loss 0.51, Spatial_loss 2.13, Flat_loss 0.42, Train_acc 87.79, Test_acc 20.39
2025-02-15 00:06:16,851 [podnet.py] => Task 18, Epoch 63/160 (LR 0.06638) => LSC_loss 0.51, Spatial_loss 2.19, Flat_loss 0.42, Train_acc 88.09, Test_acc 22.27
2025-02-15 00:06:19,115 [podnet.py] => Task 18, Epoch 64/160 (LR 0.06545) => LSC_loss 0.54, Spatial_loss 2.33, Flat_loss 0.43, Train_acc 87.09, Test_acc 20.17
2025-02-15 00:06:21,372 [podnet.py] => Task 18, Epoch 65/160 (LR 0.06451) => LSC_loss 0.52, Spatial_loss 2.24, Flat_loss 0.43, Train_acc 87.79, Test_acc 21.74
2025-02-15 00:06:23,606 [podnet.py] => Task 18, Epoch 66/160 (LR 0.06357) => LSC_loss 0.49, Spatial_loss 2.15, Flat_loss 0.41, Train_acc 88.67, Test_acc 21.03
2025-02-15 00:06:25,763 [podnet.py] => Task 18, Epoch 67/160 (LR 0.06262) => LSC_loss 0.52, Spatial_loss 2.24, Flat_loss 0.43, Train_acc 87.77, Test_acc 21.09
2025-02-15 00:06:27,942 [podnet.py] => Task 18, Epoch 68/160 (LR 0.06167) => LSC_loss 0.47, Spatial_loss 2.21, Flat_loss 0.42, Train_acc 88.98, Test_acc 17.74
2025-02-15 00:06:30,097 [podnet.py] => Task 18, Epoch 69/160 (LR 0.06072) => LSC_loss 0.47, Spatial_loss 2.09, Flat_loss 0.41, Train_acc 89.37, Test_acc 22.41
2025-02-15 00:06:32,336 [podnet.py] => Task 18, Epoch 70/160 (LR 0.05975) => LSC_loss 0.45, Spatial_loss 2.18, Flat_loss 0.41, Train_acc 89.65, Test_acc 20.88
2025-02-15 00:06:34,565 [podnet.py] => Task 18, Epoch 71/160 (LR 0.05879) => LSC_loss 0.45, Spatial_loss 2.14, Flat_loss 0.40, Train_acc 89.79, Test_acc 21.78
2025-02-15 00:06:36,818 [podnet.py] => Task 18, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 2.06, Flat_loss 0.41, Train_acc 88.56, Test_acc 21.11
2025-02-15 00:06:39,020 [podnet.py] => Task 18, Epoch 73/160 (LR 0.05685) => LSC_loss 0.46, Spatial_loss 2.09, Flat_loss 0.40, Train_acc 89.40, Test_acc 21.00
2025-02-15 00:06:41,163 [podnet.py] => Task 18, Epoch 74/160 (LR 0.05588) => LSC_loss 0.48, Spatial_loss 2.15, Flat_loss 0.40, Train_acc 89.14, Test_acc 20.73
2025-02-15 00:06:43,311 [podnet.py] => Task 18, Epoch 75/160 (LR 0.05490) => LSC_loss 0.47, Spatial_loss 2.10, Flat_loss 0.41, Train_acc 89.30, Test_acc 20.87
2025-02-15 00:06:45,498 [podnet.py] => Task 18, Epoch 76/160 (LR 0.05392) => LSC_loss 0.46, Spatial_loss 2.12, Flat_loss 0.41, Train_acc 89.56, Test_acc 24.88
2025-02-15 00:06:47,659 [podnet.py] => Task 18, Epoch 77/160 (LR 0.05294) => LSC_loss 0.45, Spatial_loss 2.09, Flat_loss 0.40, Train_acc 89.74, Test_acc 19.09
2025-02-15 00:06:49,875 [podnet.py] => Task 18, Epoch 78/160 (LR 0.05196) => LSC_loss 0.42, Spatial_loss 1.98, Flat_loss 0.38, Train_acc 91.16, Test_acc 22.69
2025-02-15 00:06:52,048 [podnet.py] => Task 18, Epoch 79/160 (LR 0.05098) => LSC_loss 0.43, Spatial_loss 2.10, Flat_loss 0.39, Train_acc 90.70, Test_acc 19.81
2025-02-15 00:06:54,243 [podnet.py] => Task 18, Epoch 80/160 (LR 0.05000) => LSC_loss 0.43, Spatial_loss 2.09, Flat_loss 0.40, Train_acc 90.40, Test_acc 25.19
2025-02-15 00:06:56,483 [podnet.py] => Task 18, Epoch 81/160 (LR 0.04902) => LSC_loss 0.42, Spatial_loss 1.92, Flat_loss 0.39, Train_acc 90.65, Test_acc 20.16
2025-02-15 00:06:58,655 [podnet.py] => Task 18, Epoch 82/160 (LR 0.04804) => LSC_loss 0.41, Spatial_loss 2.01, Flat_loss 0.38, Train_acc 91.00, Test_acc 20.58
2025-02-15 00:07:00,879 [podnet.py] => Task 18, Epoch 83/160 (LR 0.04706) => LSC_loss 0.39, Spatial_loss 2.02, Flat_loss 0.38, Train_acc 92.09, Test_acc 22.16
2025-02-15 00:07:03,093 [podnet.py] => Task 18, Epoch 84/160 (LR 0.04608) => LSC_loss 0.40, Spatial_loss 2.01, Flat_loss 0.37, Train_acc 91.51, Test_acc 21.88
2025-02-15 00:07:05,281 [podnet.py] => Task 18, Epoch 85/160 (LR 0.04510) => LSC_loss 0.38, Spatial_loss 1.98, Flat_loss 0.37, Train_acc 92.05, Test_acc 23.66
2025-02-15 00:07:07,496 [podnet.py] => Task 18, Epoch 86/160 (LR 0.04412) => LSC_loss 0.36, Spatial_loss 1.82, Flat_loss 0.36, Train_acc 92.33, Test_acc 23.12
2025-02-15 00:07:09,648 [podnet.py] => Task 18, Epoch 87/160 (LR 0.04315) => LSC_loss 0.37, Spatial_loss 1.90, Flat_loss 0.37, Train_acc 92.72, Test_acc 23.75
2025-02-15 00:07:11,887 [podnet.py] => Task 18, Epoch 88/160 (LR 0.04218) => LSC_loss 0.38, Spatial_loss 1.90, Flat_loss 0.36, Train_acc 92.14, Test_acc 26.17
2025-02-15 00:07:14,109 [podnet.py] => Task 18, Epoch 89/160 (LR 0.04121) => LSC_loss 0.37, Spatial_loss 1.85, Flat_loss 0.36, Train_acc 92.33, Test_acc 23.88
2025-02-15 00:07:16,354 [podnet.py] => Task 18, Epoch 90/160 (LR 0.04025) => LSC_loss 0.39, Spatial_loss 1.92, Flat_loss 0.36, Train_acc 92.00, Test_acc 21.99
2025-02-15 00:07:18,504 [podnet.py] => Task 18, Epoch 91/160 (LR 0.03928) => LSC_loss 0.37, Spatial_loss 1.92, Flat_loss 0.35, Train_acc 92.12, Test_acc 22.66
2025-02-15 00:07:20,651 [podnet.py] => Task 18, Epoch 92/160 (LR 0.03833) => LSC_loss 0.33, Spatial_loss 1.88, Flat_loss 0.35, Train_acc 93.58, Test_acc 22.09
2025-02-15 00:07:22,884 [podnet.py] => Task 18, Epoch 93/160 (LR 0.03738) => LSC_loss 0.34, Spatial_loss 1.91, Flat_loss 0.35, Train_acc 93.53, Test_acc 22.44
2025-02-15 00:07:25,095 [podnet.py] => Task 18, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.88, Flat_loss 0.35, Train_acc 93.95, Test_acc 22.47
2025-02-15 00:07:27,261 [podnet.py] => Task 18, Epoch 95/160 (LR 0.03549) => LSC_loss 0.32, Spatial_loss 1.79, Flat_loss 0.34, Train_acc 93.65, Test_acc 21.93
2025-02-15 00:07:29,423 [podnet.py] => Task 18, Epoch 96/160 (LR 0.03455) => LSC_loss 0.33, Spatial_loss 1.83, Flat_loss 0.34, Train_acc 93.72, Test_acc 23.00
2025-02-15 00:07:31,596 [podnet.py] => Task 18, Epoch 97/160 (LR 0.03362) => LSC_loss 0.32, Spatial_loss 1.82, Flat_loss 0.35, Train_acc 93.65, Test_acc 23.66
2025-02-15 00:07:33,768 [podnet.py] => Task 18, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.72, Flat_loss 0.33, Train_acc 93.49, Test_acc 24.15
2025-02-15 00:07:35,936 [podnet.py] => Task 18, Epoch 99/160 (LR 0.03178) => LSC_loss 0.33, Spatial_loss 1.85, Flat_loss 0.34, Train_acc 93.14, Test_acc 22.44
2025-02-15 00:07:38,099 [podnet.py] => Task 18, Epoch 100/160 (LR 0.03087) => LSC_loss 0.32, Spatial_loss 1.74, Flat_loss 0.34, Train_acc 94.14, Test_acc 24.12
2025-02-15 00:07:40,343 [podnet.py] => Task 18, Epoch 101/160 (LR 0.02996) => LSC_loss 0.33, Spatial_loss 1.82, Flat_loss 0.34, Train_acc 93.51, Test_acc 23.85
2025-02-15 00:07:42,507 [podnet.py] => Task 18, Epoch 102/160 (LR 0.02907) => LSC_loss 0.32, Spatial_loss 1.85, Flat_loss 0.34, Train_acc 94.23, Test_acc 23.47
2025-02-15 00:07:44,668 [podnet.py] => Task 18, Epoch 103/160 (LR 0.02818) => LSC_loss 0.29, Spatial_loss 1.71, Flat_loss 0.33, Train_acc 95.02, Test_acc 23.17
2025-02-15 00:07:46,870 [podnet.py] => Task 18, Epoch 104/160 (LR 0.02730) => LSC_loss 0.30, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 94.74, Test_acc 25.11
2025-02-15 00:07:49,056 [podnet.py] => Task 18, Epoch 105/160 (LR 0.02643) => LSC_loss 0.30, Spatial_loss 1.78, Flat_loss 0.33, Train_acc 94.81, Test_acc 20.61
2025-02-15 00:07:51,226 [podnet.py] => Task 18, Epoch 106/160 (LR 0.02557) => LSC_loss 0.27, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 95.51, Test_acc 25.08
2025-02-15 00:07:53,400 [podnet.py] => Task 18, Epoch 107/160 (LR 0.02472) => LSC_loss 0.28, Spatial_loss 1.74, Flat_loss 0.32, Train_acc 95.07, Test_acc 24.22
2025-02-15 00:07:55,624 [podnet.py] => Task 18, Epoch 108/160 (LR 0.02388) => LSC_loss 0.29, Spatial_loss 1.71, Flat_loss 0.31, Train_acc 95.14, Test_acc 22.61
2025-02-15 00:07:57,780 [podnet.py] => Task 18, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.66, Flat_loss 0.32, Train_acc 95.09, Test_acc 25.02
2025-02-15 00:07:59,930 [podnet.py] => Task 18, Epoch 110/160 (LR 0.02222) => LSC_loss 0.27, Spatial_loss 1.54, Flat_loss 0.31, Train_acc 95.21, Test_acc 23.26
2025-02-15 00:08:02,080 [podnet.py] => Task 18, Epoch 111/160 (LR 0.02141) => LSC_loss 0.26, Spatial_loss 1.60, Flat_loss 0.30, Train_acc 96.14, Test_acc 22.22
2025-02-15 00:08:04,239 [podnet.py] => Task 18, Epoch 112/160 (LR 0.02061) => LSC_loss 0.26, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 95.84, Test_acc 23.94
2025-02-15 00:08:06,363 [podnet.py] => Task 18, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.60, Flat_loss 0.30, Train_acc 96.30, Test_acc 23.37
2025-02-15 00:08:08,565 [podnet.py] => Task 18, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 1.60, Flat_loss 0.30, Train_acc 95.70, Test_acc 22.60
2025-02-15 00:08:10,693 [podnet.py] => Task 18, Epoch 115/160 (LR 0.01828) => LSC_loss 0.27, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 95.67, Test_acc 22.51
2025-02-15 00:08:12,939 [podnet.py] => Task 18, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.67, Flat_loss 0.30, Train_acc 96.40, Test_acc 23.47
2025-02-15 00:08:15,130 [podnet.py] => Task 18, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 1.55, Flat_loss 0.29, Train_acc 96.14, Test_acc 24.09
2025-02-15 00:08:17,357 [podnet.py] => Task 18, Epoch 118/160 (LR 0.01606) => LSC_loss 0.25, Spatial_loss 1.56, Flat_loss 0.29, Train_acc 96.44, Test_acc 22.22
2025-02-15 00:08:19,515 [podnet.py] => Task 18, Epoch 119/160 (LR 0.01535) => LSC_loss 0.24, Spatial_loss 1.59, Flat_loss 0.30, Train_acc 96.60, Test_acc 23.71
2025-02-15 00:08:21,756 [podnet.py] => Task 18, Epoch 120/160 (LR 0.01464) => LSC_loss 0.24, Spatial_loss 1.54, Flat_loss 0.29, Train_acc 96.70, Test_acc 25.08
2025-02-15 00:08:23,999 [podnet.py] => Task 18, Epoch 121/160 (LR 0.01396) => LSC_loss 0.25, Spatial_loss 1.54, Flat_loss 0.29, Train_acc 96.09, Test_acc 23.15
2025-02-15 00:08:26,203 [podnet.py] => Task 18, Epoch 122/160 (LR 0.01328) => LSC_loss 0.24, Spatial_loss 1.48, Flat_loss 0.28, Train_acc 96.72, Test_acc 24.68
2025-02-15 00:08:28,417 [podnet.py] => Task 18, Epoch 123/160 (LR 0.01262) => LSC_loss 0.24, Spatial_loss 1.52, Flat_loss 0.29, Train_acc 96.47, Test_acc 23.85
2025-02-15 00:08:30,653 [podnet.py] => Task 18, Epoch 124/160 (LR 0.01198) => LSC_loss 0.23, Spatial_loss 1.50, Flat_loss 0.28, Train_acc 97.02, Test_acc 24.58
2025-02-15 00:08:32,790 [podnet.py] => Task 18, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 1.48, Flat_loss 0.28, Train_acc 97.02, Test_acc 24.92
2025-02-15 00:08:34,978 [podnet.py] => Task 18, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 1.44, Flat_loss 0.28, Train_acc 97.16, Test_acc 25.14
2025-02-15 00:08:37,112 [podnet.py] => Task 18, Epoch 127/160 (LR 0.01013) => LSC_loss 0.24, Spatial_loss 1.44, Flat_loss 0.27, Train_acc 96.86, Test_acc 23.77
2025-02-15 00:08:39,350 [podnet.py] => Task 18, Epoch 128/160 (LR 0.00955) => LSC_loss 0.23, Spatial_loss 1.45, Flat_loss 0.28, Train_acc 96.98, Test_acc 24.32
2025-02-15 00:08:41,489 [podnet.py] => Task 18, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 1.39, Flat_loss 0.27, Train_acc 97.60, Test_acc 25.39
2025-02-15 00:08:43,721 [podnet.py] => Task 18, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.51, Flat_loss 0.28, Train_acc 97.02, Test_acc 25.23
2025-02-15 00:08:45,852 [podnet.py] => Task 18, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 1.43, Flat_loss 0.27, Train_acc 96.70, Test_acc 25.46
2025-02-15 00:08:48,055 [podnet.py] => Task 18, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.26, Train_acc 97.21, Test_acc 25.46
2025-02-15 00:08:50,246 [podnet.py] => Task 18, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 1.44, Flat_loss 0.27, Train_acc 96.88, Test_acc 24.93
2025-02-15 00:08:52,381 [podnet.py] => Task 18, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.49, Flat_loss 0.27, Train_acc 97.23, Test_acc 24.29
2025-02-15 00:08:54,581 [podnet.py] => Task 18, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.39, Flat_loss 0.27, Train_acc 97.60, Test_acc 24.77
2025-02-15 00:08:56,755 [podnet.py] => Task 18, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.39, Flat_loss 0.27, Train_acc 97.14, Test_acc 25.08
2025-02-15 00:08:58,909 [podnet.py] => Task 18, Epoch 137/160 (LR 0.00501) => LSC_loss 0.22, Spatial_loss 1.36, Flat_loss 0.26, Train_acc 97.79, Test_acc 25.61
2025-02-15 00:09:01,135 [podnet.py] => Task 18, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.33, Flat_loss 0.26, Train_acc 97.51, Test_acc 25.38
2025-02-15 00:09:03,302 [podnet.py] => Task 18, Epoch 139/160 (LR 0.00419) => LSC_loss 0.22, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 97.35, Test_acc 25.91
2025-02-15 00:09:05,532 [podnet.py] => Task 18, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.37, Flat_loss 0.26, Train_acc 97.35, Test_acc 25.17
2025-02-15 00:09:07,680 [podnet.py] => Task 18, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.25, Flat_loss 0.26, Train_acc 97.42, Test_acc 25.71
2025-02-15 00:09:09,855 [podnet.py] => Task 18, Epoch 142/160 (LR 0.00309) => LSC_loss 0.20, Spatial_loss 1.26, Flat_loss 0.26, Train_acc 97.77, Test_acc 24.86
2025-02-15 00:09:12,057 [podnet.py] => Task 18, Epoch 143/160 (LR 0.00276) => LSC_loss 0.21, Spatial_loss 1.35, Flat_loss 0.26, Train_acc 97.58, Test_acc 25.07
2025-02-15 00:09:14,253 [podnet.py] => Task 18, Epoch 144/160 (LR 0.00245) => LSC_loss 0.22, Spatial_loss 1.36, Flat_loss 0.26, Train_acc 97.28, Test_acc 25.28
2025-02-15 00:09:16,422 [podnet.py] => Task 18, Epoch 145/160 (LR 0.00215) => LSC_loss 0.21, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 97.58, Test_acc 25.36
2025-02-15 00:09:18,574 [podnet.py] => Task 18, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 97.86, Test_acc 25.53
2025-02-15 00:09:20,766 [podnet.py] => Task 18, Epoch 147/160 (LR 0.00162) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.26, Train_acc 97.58, Test_acc 25.29
2025-02-15 00:09:23,036 [podnet.py] => Task 18, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.26, Train_acc 97.84, Test_acc 25.66
2025-02-15 00:09:25,234 [podnet.py] => Task 18, Epoch 149/160 (LR 0.00116) => LSC_loss 0.21, Spatial_loss 1.28, Flat_loss 0.26, Train_acc 97.77, Test_acc 25.26
2025-02-15 00:09:27,473 [podnet.py] => Task 18, Epoch 150/160 (LR 0.00096) => LSC_loss 0.21, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 97.77, Test_acc 25.61
2025-02-15 00:09:29,661 [podnet.py] => Task 18, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.34, Flat_loss 0.26, Train_acc 97.58, Test_acc 25.06
2025-02-15 00:09:31,866 [podnet.py] => Task 18, Epoch 152/160 (LR 0.00062) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.25, Train_acc 97.58, Test_acc 25.33
2025-02-15 00:09:34,080 [podnet.py] => Task 18, Epoch 153/160 (LR 0.00047) => LSC_loss 0.21, Spatial_loss 1.29, Flat_loss 0.25, Train_acc 97.70, Test_acc 25.49
2025-02-15 00:09:36,208 [podnet.py] => Task 18, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.25, Train_acc 98.19, Test_acc 25.88
2025-02-15 00:09:38,367 [podnet.py] => Task 18, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.22, Flat_loss 0.26, Train_acc 97.72, Test_acc 25.29
2025-02-15 00:09:40,474 [podnet.py] => Task 18, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 98.21, Test_acc 25.40
2025-02-15 00:09:42,660 [podnet.py] => Task 18, Epoch 157/160 (LR 0.00009) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 97.81, Test_acc 25.79
2025-02-15 00:09:44,892 [podnet.py] => Task 18, Epoch 158/160 (LR 0.00004) => LSC_loss 0.21, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 97.79, Test_acc 25.26
2025-02-15 00:09:47,100 [podnet.py] => Task 18, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 98.12, Test_acc 25.33
2025-02-15 00:09:49,246 [podnet.py] => Task 18, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.21, Flat_loss 0.25, Train_acc 98.21, Test_acc 25.43
2025-02-15 00:09:49,247 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 00:09:49,247 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:10:23,088 [podnet.py] => The size of finetune dataset: 1900
2025-02-15 00:10:24,822 [podnet.py] => Task 18, Epoch 1/20 (LR 0.00497) => LSC_loss 0.27, Spatial_loss 1.58, Flat_loss 0.20, Train_acc 95.79, Test_acc 27.21
2025-02-15 00:10:26,445 [podnet.py] => Task 18, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 1.38, Flat_loss 0.14, Train_acc 98.26, Test_acc 27.89
2025-02-15 00:10:28,079 [podnet.py] => Task 18, Epoch 3/20 (LR 0.00473) => LSC_loss 0.14, Spatial_loss 1.19, Flat_loss 0.12, Train_acc 99.11, Test_acc 26.39
2025-02-15 00:10:29,727 [podnet.py] => Task 18, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 1.26, Flat_loss 0.12, Train_acc 98.89, Test_acc 26.28
2025-02-15 00:10:31,380 [podnet.py] => Task 18, Epoch 5/20 (LR 0.00427) => LSC_loss 0.15, Spatial_loss 1.26, Flat_loss 0.12, Train_acc 98.95, Test_acc 26.62
2025-02-15 00:10:32,993 [podnet.py] => Task 18, Epoch 6/20 (LR 0.00397) => LSC_loss 0.14, Spatial_loss 1.24, Flat_loss 0.12, Train_acc 98.95, Test_acc 26.64
2025-02-15 00:10:34,667 [podnet.py] => Task 18, Epoch 7/20 (LR 0.00363) => LSC_loss 0.14, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 99.16, Test_acc 26.79
2025-02-15 00:10:36,292 [podnet.py] => Task 18, Epoch 8/20 (LR 0.00327) => LSC_loss 0.15, Spatial_loss 1.20, Flat_loss 0.12, Train_acc 99.16, Test_acc 26.42
2025-02-15 00:10:37,891 [podnet.py] => Task 18, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 1.24, Flat_loss 0.12, Train_acc 99.37, Test_acc 26.69
2025-02-15 00:10:39,519 [podnet.py] => Task 18, Epoch 10/20 (LR 0.00250) => LSC_loss 0.14, Spatial_loss 1.26, Flat_loss 0.12, Train_acc 99.32, Test_acc 26.75
2025-02-15 00:10:41,128 [podnet.py] => Task 18, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 1.20, Flat_loss 0.11, Train_acc 99.11, Test_acc 26.83
2025-02-15 00:10:42,798 [podnet.py] => Task 18, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.21, Test_acc 26.99
2025-02-15 00:10:44,456 [podnet.py] => Task 18, Epoch 13/20 (LR 0.00137) => LSC_loss 0.14, Spatial_loss 1.10, Flat_loss 0.11, Train_acc 99.00, Test_acc 27.05
2025-02-15 00:10:46,067 [podnet.py] => Task 18, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 99.16, Test_acc 26.95
2025-02-15 00:10:47,633 [podnet.py] => Task 18, Epoch 15/20 (LR 0.00073) => LSC_loss 0.14, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 99.11, Test_acc 26.88
2025-02-15 00:10:49,217 [podnet.py] => Task 18, Epoch 16/20 (LR 0.00048) => LSC_loss 0.13, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 99.32, Test_acc 26.75
2025-02-15 00:10:50,887 [podnet.py] => Task 18, Epoch 17/20 (LR 0.00027) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 99.16, Test_acc 26.88
2025-02-15 00:10:52,597 [podnet.py] => Task 18, Epoch 18/20 (LR 0.00012) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.11, Train_acc 99.00, Test_acc 26.94
2025-02-15 00:10:54,233 [podnet.py] => Task 18, Epoch 19/20 (LR 0.00003) => LSC_loss 0.14, Spatial_loss 1.14, Flat_loss 0.11, Train_acc 98.95, Test_acc 26.93
2025-02-15 00:10:55,876 [podnet.py] => Task 18, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 1.11, Flat_loss 0.11, Train_acc 98.79, Test_acc 26.99
2025-02-15 00:10:55,879 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:11:31,521 [podnet.py] => Exemplar size: 1900
2025-02-15 00:11:31,522 [trainer.py] => CNN: {'total': 26.99, '00-09': 32.3, '10-19': 11.1, '20-29': 19.4, '30-39': 16.4, '40-49': 31.5, '50-59': 16.7, '60-69': 29.1, '70-79': 28.3, '80-89': 41.8, '90-99': 59.6, 'old': 25.18, 'new': 59.6}
2025-02-15 00:11:31,522 [trainer.py] => NME: {'total': 27.19, '00-09': 40.4, '10-19': 12.1, '20-29': 20.9, '30-39': 17.2, '40-49': 31.5, '50-59': 15.5, '60-69': 27.9, '70-79': 28.8, '80-89': 38.5, '90-99': 51.0, 'old': 25.87, 'new': 51.0}
2025-02-15 00:11:31,522 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24, 28.7, 28.87, 28.16, 26.99]
2025-02-15 00:11:31,522 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85, 55.0, 56.02, 54.61, 53.34]
2025-02-15 00:11:31,522 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08, 28.69, 29.13, 27.86, 27.19]
2025-02-15 00:11:31,522 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49, 55.08, 55.31, 54.06, 53.25]

2025-02-15 00:11:31,522 [trainer.py] => Average Accuracy (CNN): 42.148947368421055
2025-02-15 00:11:31,522 [trainer.py] => Average Accuracy (NME): 41.683157894736844
2025-02-15 00:11:31,522 [trainer.py] => All params: 527057
2025-02-15 00:11:31,523 [trainer.py] => Trainable params: 527057
2025-02-15 00:11:31,524 [podnet.py] => Learning on 95-100
2025-02-15 00:11:31,557 [podnet.py] => Adaptive factor: 4.47213595499958
2025-02-15 00:11:33,823 [podnet.py] => Task 19, Epoch 1/160 (LR 0.09999) => LSC_loss 2.76, Spatial_loss 3.51, Flat_loss 1.31, Train_acc 46.02, Test_acc 15.07
2025-02-15 00:11:36,088 [podnet.py] => Task 19, Epoch 2/160 (LR 0.09996) => LSC_loss 1.63, Spatial_loss 3.24, Flat_loss 0.81, Train_acc 58.02, Test_acc 14.77
2025-02-15 00:11:38,314 [podnet.py] => Task 19, Epoch 3/160 (LR 0.09991) => LSC_loss 1.48, Spatial_loss 3.20, Flat_loss 0.72, Train_acc 61.64, Test_acc 18.06
2025-02-15 00:11:40,547 [podnet.py] => Task 19, Epoch 4/160 (LR 0.09985) => LSC_loss 1.39, Spatial_loss 3.14, Flat_loss 0.66, Train_acc 63.16, Test_acc 17.56
2025-02-15 00:11:42,755 [podnet.py] => Task 19, Epoch 5/160 (LR 0.09976) => LSC_loss 1.27, Spatial_loss 2.89, Flat_loss 0.59, Train_acc 67.25, Test_acc 17.94
2025-02-15 00:11:44,969 [podnet.py] => Task 19, Epoch 6/160 (LR 0.09965) => LSC_loss 1.23, Spatial_loss 2.91, Flat_loss 0.58, Train_acc 68.00, Test_acc 17.69
2025-02-15 00:11:47,276 [podnet.py] => Task 19, Epoch 7/160 (LR 0.09953) => LSC_loss 1.17, Spatial_loss 3.02, Flat_loss 0.56, Train_acc 69.70, Test_acc 18.63
2025-02-15 00:11:49,518 [podnet.py] => Task 19, Epoch 8/160 (LR 0.09938) => LSC_loss 1.16, Spatial_loss 2.94, Flat_loss 0.56, Train_acc 69.75, Test_acc 18.28
2025-02-15 00:11:51,781 [podnet.py] => Task 19, Epoch 9/160 (LR 0.09922) => LSC_loss 1.13, Spatial_loss 2.72, Flat_loss 0.54, Train_acc 70.84, Test_acc 16.11
2025-02-15 00:11:53,970 [podnet.py] => Task 19, Epoch 10/160 (LR 0.09904) => LSC_loss 1.12, Spatial_loss 2.80, Flat_loss 0.54, Train_acc 70.48, Test_acc 15.94
2025-02-15 00:11:56,219 [podnet.py] => Task 19, Epoch 11/160 (LR 0.09884) => LSC_loss 1.08, Spatial_loss 2.78, Flat_loss 0.53, Train_acc 71.89, Test_acc 17.05
2025-02-15 00:11:58,461 [podnet.py] => Task 19, Epoch 12/160 (LR 0.09862) => LSC_loss 1.07, Spatial_loss 2.79, Flat_loss 0.52, Train_acc 72.75, Test_acc 17.37
2025-02-15 00:12:00,735 [podnet.py] => Task 19, Epoch 13/160 (LR 0.09838) => LSC_loss 0.99, Spatial_loss 2.76, Flat_loss 0.52, Train_acc 74.73, Test_acc 17.33
2025-02-15 00:12:02,971 [podnet.py] => Task 19, Epoch 14/160 (LR 0.09812) => LSC_loss 1.03, Spatial_loss 2.75, Flat_loss 0.52, Train_acc 74.32, Test_acc 18.68
2025-02-15 00:12:05,197 [podnet.py] => Task 19, Epoch 15/160 (LR 0.09785) => LSC_loss 1.03, Spatial_loss 2.88, Flat_loss 0.52, Train_acc 73.70, Test_acc 15.44
2025-02-15 00:12:07,474 [podnet.py] => Task 19, Epoch 16/160 (LR 0.09755) => LSC_loss 1.02, Spatial_loss 2.83, Flat_loss 0.53, Train_acc 73.89, Test_acc 17.27
2025-02-15 00:12:09,659 [podnet.py] => Task 19, Epoch 17/160 (LR 0.09724) => LSC_loss 1.01, Spatial_loss 2.78, Flat_loss 0.52, Train_acc 74.05, Test_acc 18.73
2025-02-15 00:12:11,921 [podnet.py] => Task 19, Epoch 18/160 (LR 0.09691) => LSC_loss 0.96, Spatial_loss 2.76, Flat_loss 0.51, Train_acc 75.50, Test_acc 15.98
2025-02-15 00:12:14,240 [podnet.py] => Task 19, Epoch 19/160 (LR 0.09656) => LSC_loss 0.95, Spatial_loss 2.78, Flat_loss 0.51, Train_acc 76.09, Test_acc 16.81
2025-02-15 00:12:16,449 [podnet.py] => Task 19, Epoch 20/160 (LR 0.09619) => LSC_loss 0.95, Spatial_loss 2.88, Flat_loss 0.51, Train_acc 75.93, Test_acc 20.07
2025-02-15 00:12:18,682 [podnet.py] => Task 19, Epoch 21/160 (LR 0.09581) => LSC_loss 0.95, Spatial_loss 2.74, Flat_loss 0.50, Train_acc 76.66, Test_acc 14.88
2025-02-15 00:12:20,957 [podnet.py] => Task 19, Epoch 22/160 (LR 0.09541) => LSC_loss 0.86, Spatial_loss 2.64, Flat_loss 0.48, Train_acc 78.18, Test_acc 19.15
2025-02-15 00:12:23,229 [podnet.py] => Task 19, Epoch 23/160 (LR 0.09499) => LSC_loss 0.91, Spatial_loss 2.66, Flat_loss 0.49, Train_acc 77.34, Test_acc 18.44
2025-02-15 00:12:25,492 [podnet.py] => Task 19, Epoch 24/160 (LR 0.09455) => LSC_loss 0.89, Spatial_loss 2.60, Flat_loss 0.49, Train_acc 76.59, Test_acc 22.04
2025-02-15 00:12:27,666 [podnet.py] => Task 19, Epoch 25/160 (LR 0.09410) => LSC_loss 0.88, Spatial_loss 2.67, Flat_loss 0.49, Train_acc 78.52, Test_acc 19.85
2025-02-15 00:12:29,868 [podnet.py] => Task 19, Epoch 26/160 (LR 0.09362) => LSC_loss 0.83, Spatial_loss 2.68, Flat_loss 0.48, Train_acc 78.82, Test_acc 18.38
2025-02-15 00:12:32,106 [podnet.py] => Task 19, Epoch 27/160 (LR 0.09314) => LSC_loss 0.85, Spatial_loss 2.65, Flat_loss 0.50, Train_acc 78.48, Test_acc 17.69
2025-02-15 00:12:34,332 [podnet.py] => Task 19, Epoch 28/160 (LR 0.09263) => LSC_loss 0.88, Spatial_loss 2.57, Flat_loss 0.48, Train_acc 77.41, Test_acc 19.98
2025-02-15 00:12:36,529 [podnet.py] => Task 19, Epoch 29/160 (LR 0.09211) => LSC_loss 0.81, Spatial_loss 2.62, Flat_loss 0.48, Train_acc 79.23, Test_acc 18.51
2025-02-15 00:12:38,791 [podnet.py] => Task 19, Epoch 30/160 (LR 0.09157) => LSC_loss 0.85, Spatial_loss 2.67, Flat_loss 0.49, Train_acc 78.84, Test_acc 18.06
2025-02-15 00:12:41,023 [podnet.py] => Task 19, Epoch 31/160 (LR 0.09102) => LSC_loss 0.83, Spatial_loss 2.63, Flat_loss 0.48, Train_acc 79.23, Test_acc 14.12
2025-02-15 00:12:43,243 [podnet.py] => Task 19, Epoch 32/160 (LR 0.09045) => LSC_loss 0.79, Spatial_loss 2.62, Flat_loss 0.47, Train_acc 80.11, Test_acc 16.74
2025-02-15 00:12:45,485 [podnet.py] => Task 19, Epoch 33/160 (LR 0.08987) => LSC_loss 0.80, Spatial_loss 2.62, Flat_loss 0.47, Train_acc 79.89, Test_acc 16.50
2025-02-15 00:12:47,762 [podnet.py] => Task 19, Epoch 34/160 (LR 0.08927) => LSC_loss 0.77, Spatial_loss 2.51, Flat_loss 0.47, Train_acc 81.00, Test_acc 21.39
2025-02-15 00:12:49,980 [podnet.py] => Task 19, Epoch 35/160 (LR 0.08865) => LSC_loss 0.75, Spatial_loss 2.55, Flat_loss 0.47, Train_acc 81.61, Test_acc 20.07
2025-02-15 00:12:52,199 [podnet.py] => Task 19, Epoch 36/160 (LR 0.08802) => LSC_loss 0.74, Spatial_loss 2.57, Flat_loss 0.46, Train_acc 80.86, Test_acc 20.88
2025-02-15 00:12:54,418 [podnet.py] => Task 19, Epoch 37/160 (LR 0.08738) => LSC_loss 0.74, Spatial_loss 2.46, Flat_loss 0.46, Train_acc 81.16, Test_acc 20.14
2025-02-15 00:12:56,670 [podnet.py] => Task 19, Epoch 38/160 (LR 0.08672) => LSC_loss 0.74, Spatial_loss 2.44, Flat_loss 0.45, Train_acc 81.86, Test_acc 20.09
2025-02-15 00:12:58,900 [podnet.py] => Task 19, Epoch 39/160 (LR 0.08604) => LSC_loss 0.77, Spatial_loss 2.66, Flat_loss 0.49, Train_acc 80.32, Test_acc 20.44
2025-02-15 00:13:01,149 [podnet.py] => Task 19, Epoch 40/160 (LR 0.08536) => LSC_loss 0.70, Spatial_loss 2.47, Flat_loss 0.45, Train_acc 82.52, Test_acc 23.08
2025-02-15 00:13:03,421 [podnet.py] => Task 19, Epoch 41/160 (LR 0.08465) => LSC_loss 0.70, Spatial_loss 2.42, Flat_loss 0.45, Train_acc 82.25, Test_acc 19.66
2025-02-15 00:13:05,683 [podnet.py] => Task 19, Epoch 42/160 (LR 0.08394) => LSC_loss 0.72, Spatial_loss 2.51, Flat_loss 0.45, Train_acc 82.84, Test_acc 20.51
2025-02-15 00:13:07,898 [podnet.py] => Task 19, Epoch 43/160 (LR 0.08321) => LSC_loss 0.73, Spatial_loss 2.56, Flat_loss 0.47, Train_acc 81.75, Test_acc 19.41
2025-02-15 00:13:10,141 [podnet.py] => Task 19, Epoch 44/160 (LR 0.08247) => LSC_loss 0.73, Spatial_loss 2.56, Flat_loss 0.47, Train_acc 81.66, Test_acc 20.53
2025-02-15 00:13:12,386 [podnet.py] => Task 19, Epoch 45/160 (LR 0.08172) => LSC_loss 0.71, Spatial_loss 2.46, Flat_loss 0.46, Train_acc 82.57, Test_acc 17.76
2025-02-15 00:13:14,582 [podnet.py] => Task 19, Epoch 46/160 (LR 0.08095) => LSC_loss 0.70, Spatial_loss 2.51, Flat_loss 0.46, Train_acc 83.18, Test_acc 20.63
2025-02-15 00:13:16,787 [podnet.py] => Task 19, Epoch 47/160 (LR 0.08018) => LSC_loss 0.69, Spatial_loss 2.37, Flat_loss 0.45, Train_acc 83.34, Test_acc 20.94
2025-02-15 00:13:18,958 [podnet.py] => Task 19, Epoch 48/160 (LR 0.07939) => LSC_loss 0.66, Spatial_loss 2.44, Flat_loss 0.44, Train_acc 84.23, Test_acc 21.70
2025-02-15 00:13:21,136 [podnet.py] => Task 19, Epoch 49/160 (LR 0.07859) => LSC_loss 0.65, Spatial_loss 2.45, Flat_loss 0.44, Train_acc 84.57, Test_acc 21.77
2025-02-15 00:13:23,420 [podnet.py] => Task 19, Epoch 50/160 (LR 0.07778) => LSC_loss 0.66, Spatial_loss 2.42, Flat_loss 0.44, Train_acc 83.84, Test_acc 21.30
2025-02-15 00:13:25,658 [podnet.py] => Task 19, Epoch 51/160 (LR 0.07696) => LSC_loss 0.66, Spatial_loss 2.43, Flat_loss 0.45, Train_acc 83.11, Test_acc 18.15
2025-02-15 00:13:27,936 [podnet.py] => Task 19, Epoch 52/160 (LR 0.07612) => LSC_loss 0.66, Spatial_loss 2.47, Flat_loss 0.45, Train_acc 84.27, Test_acc 20.25
2025-02-15 00:13:30,133 [podnet.py] => Task 19, Epoch 53/160 (LR 0.07528) => LSC_loss 0.68, Spatial_loss 2.57, Flat_loss 0.46, Train_acc 83.20, Test_acc 20.33
2025-02-15 00:13:32,404 [podnet.py] => Task 19, Epoch 54/160 (LR 0.07443) => LSC_loss 0.67, Spatial_loss 2.40, Flat_loss 0.45, Train_acc 83.52, Test_acc 21.94
2025-02-15 00:13:34,680 [podnet.py] => Task 19, Epoch 55/160 (LR 0.07357) => LSC_loss 0.61, Spatial_loss 2.38, Flat_loss 0.43, Train_acc 84.89, Test_acc 16.91
2025-02-15 00:13:36,927 [podnet.py] => Task 19, Epoch 56/160 (LR 0.07270) => LSC_loss 0.61, Spatial_loss 2.43, Flat_loss 0.43, Train_acc 85.64, Test_acc 19.20
2025-02-15 00:13:39,138 [podnet.py] => Task 19, Epoch 57/160 (LR 0.07182) => LSC_loss 0.61, Spatial_loss 2.36, Flat_loss 0.43, Train_acc 85.07, Test_acc 18.97
2025-02-15 00:13:41,364 [podnet.py] => Task 19, Epoch 58/160 (LR 0.07093) => LSC_loss 0.59, Spatial_loss 2.33, Flat_loss 0.42, Train_acc 85.80, Test_acc 20.72
2025-02-15 00:13:43,561 [podnet.py] => Task 19, Epoch 59/160 (LR 0.07004) => LSC_loss 0.63, Spatial_loss 2.42, Flat_loss 0.43, Train_acc 84.86, Test_acc 16.23
2025-02-15 00:13:45,808 [podnet.py] => Task 19, Epoch 60/160 (LR 0.06913) => LSC_loss 0.60, Spatial_loss 2.24, Flat_loss 0.43, Train_acc 84.80, Test_acc 20.24
2025-02-15 00:13:47,981 [podnet.py] => Task 19, Epoch 61/160 (LR 0.06822) => LSC_loss 0.57, Spatial_loss 2.31, Flat_loss 0.42, Train_acc 86.30, Test_acc 17.80
2025-02-15 00:13:50,235 [podnet.py] => Task 19, Epoch 62/160 (LR 0.06731) => LSC_loss 0.55, Spatial_loss 2.44, Flat_loss 0.42, Train_acc 87.23, Test_acc 17.28
2025-02-15 00:13:52,489 [podnet.py] => Task 19, Epoch 63/160 (LR 0.06638) => LSC_loss 0.56, Spatial_loss 2.24, Flat_loss 0.41, Train_acc 86.23, Test_acc 18.71
2025-02-15 00:13:54,710 [podnet.py] => Task 19, Epoch 64/160 (LR 0.06545) => LSC_loss 0.53, Spatial_loss 2.16, Flat_loss 0.40, Train_acc 88.07, Test_acc 19.21
2025-02-15 00:13:56,968 [podnet.py] => Task 19, Epoch 65/160 (LR 0.06451) => LSC_loss 0.54, Spatial_loss 2.28, Flat_loss 0.40, Train_acc 87.80, Test_acc 21.93
2025-02-15 00:13:59,210 [podnet.py] => Task 19, Epoch 66/160 (LR 0.06357) => LSC_loss 0.54, Spatial_loss 2.39, Flat_loss 0.41, Train_acc 87.27, Test_acc 20.38
2025-02-15 00:14:01,425 [podnet.py] => Task 19, Epoch 67/160 (LR 0.06262) => LSC_loss 0.58, Spatial_loss 2.29, Flat_loss 0.42, Train_acc 86.36, Test_acc 21.59
2025-02-15 00:14:03,697 [podnet.py] => Task 19, Epoch 68/160 (LR 0.06167) => LSC_loss 0.57, Spatial_loss 2.22, Flat_loss 0.42, Train_acc 86.32, Test_acc 20.07
2025-02-15 00:14:05,968 [podnet.py] => Task 19, Epoch 69/160 (LR 0.06072) => LSC_loss 0.54, Spatial_loss 2.21, Flat_loss 0.41, Train_acc 87.91, Test_acc 22.96
2025-02-15 00:14:08,221 [podnet.py] => Task 19, Epoch 70/160 (LR 0.05975) => LSC_loss 0.52, Spatial_loss 2.27, Flat_loss 0.40, Train_acc 87.75, Test_acc 21.92
2025-02-15 00:14:10,499 [podnet.py] => Task 19, Epoch 71/160 (LR 0.05879) => LSC_loss 0.56, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 86.91, Test_acc 20.87
2025-02-15 00:14:12,787 [podnet.py] => Task 19, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 2.19, Flat_loss 0.39, Train_acc 88.77, Test_acc 20.25
2025-02-15 00:14:15,050 [podnet.py] => Task 19, Epoch 73/160 (LR 0.05685) => LSC_loss 0.47, Spatial_loss 2.07, Flat_loss 0.37, Train_acc 89.91, Test_acc 18.96
2025-02-15 00:14:17,271 [podnet.py] => Task 19, Epoch 74/160 (LR 0.05588) => LSC_loss 0.46, Spatial_loss 2.15, Flat_loss 0.38, Train_acc 89.39, Test_acc 18.02
2025-02-15 00:14:19,478 [podnet.py] => Task 19, Epoch 75/160 (LR 0.05490) => LSC_loss 0.50, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 88.48, Test_acc 18.36
2025-02-15 00:14:21,723 [podnet.py] => Task 19, Epoch 76/160 (LR 0.05392) => LSC_loss 0.47, Spatial_loss 2.16, Flat_loss 0.38, Train_acc 88.91, Test_acc 22.71
2025-02-15 00:14:23,892 [podnet.py] => Task 19, Epoch 77/160 (LR 0.05294) => LSC_loss 0.47, Spatial_loss 2.06, Flat_loss 0.37, Train_acc 89.36, Test_acc 19.92
2025-02-15 00:14:26,128 [podnet.py] => Task 19, Epoch 78/160 (LR 0.05196) => LSC_loss 0.46, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 89.30, Test_acc 18.91
2025-02-15 00:14:28,378 [podnet.py] => Task 19, Epoch 79/160 (LR 0.05098) => LSC_loss 0.46, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 90.11, Test_acc 22.43
2025-02-15 00:14:30,629 [podnet.py] => Task 19, Epoch 80/160 (LR 0.05000) => LSC_loss 0.46, Spatial_loss 2.09, Flat_loss 0.36, Train_acc 89.50, Test_acc 19.61
2025-02-15 00:14:32,940 [podnet.py] => Task 19, Epoch 81/160 (LR 0.04902) => LSC_loss 0.45, Spatial_loss 2.10, Flat_loss 0.37, Train_acc 90.25, Test_acc 22.59
2025-02-15 00:14:35,145 [podnet.py] => Task 19, Epoch 82/160 (LR 0.04804) => LSC_loss 0.43, Spatial_loss 1.99, Flat_loss 0.36, Train_acc 90.32, Test_acc 22.41
2025-02-15 00:14:37,329 [podnet.py] => Task 19, Epoch 83/160 (LR 0.04706) => LSC_loss 0.43, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 91.00, Test_acc 20.50
2025-02-15 00:14:39,508 [podnet.py] => Task 19, Epoch 84/160 (LR 0.04608) => LSC_loss 0.41, Spatial_loss 2.14, Flat_loss 0.36, Train_acc 91.43, Test_acc 20.18
2025-02-15 00:14:41,715 [podnet.py] => Task 19, Epoch 85/160 (LR 0.04510) => LSC_loss 0.39, Spatial_loss 2.03, Flat_loss 0.34, Train_acc 92.30, Test_acc 22.08
2025-02-15 00:14:43,969 [podnet.py] => Task 19, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 2.02, Flat_loss 0.36, Train_acc 90.55, Test_acc 24.21
2025-02-15 00:14:46,233 [podnet.py] => Task 19, Epoch 87/160 (LR 0.04315) => LSC_loss 0.41, Spatial_loss 2.05, Flat_loss 0.36, Train_acc 91.20, Test_acc 21.33
2025-02-15 00:14:48,523 [podnet.py] => Task 19, Epoch 88/160 (LR 0.04218) => LSC_loss 0.38, Spatial_loss 2.12, Flat_loss 0.35, Train_acc 92.75, Test_acc 20.23
2025-02-15 00:14:50,801 [podnet.py] => Task 19, Epoch 89/160 (LR 0.04121) => LSC_loss 0.39, Spatial_loss 1.97, Flat_loss 0.34, Train_acc 91.82, Test_acc 20.36
2025-02-15 00:14:53,006 [podnet.py] => Task 19, Epoch 90/160 (LR 0.04025) => LSC_loss 0.38, Spatial_loss 1.94, Flat_loss 0.34, Train_acc 91.75, Test_acc 24.02
2025-02-15 00:14:55,238 [podnet.py] => Task 19, Epoch 91/160 (LR 0.03928) => LSC_loss 0.40, Spatial_loss 1.95, Flat_loss 0.35, Train_acc 91.68, Test_acc 20.38
2025-02-15 00:14:57,488 [podnet.py] => Task 19, Epoch 92/160 (LR 0.03833) => LSC_loss 0.38, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 91.86, Test_acc 24.01
2025-02-15 00:14:59,741 [podnet.py] => Task 19, Epoch 93/160 (LR 0.03738) => LSC_loss 0.37, Spatial_loss 1.93, Flat_loss 0.33, Train_acc 92.61, Test_acc 25.48
2025-02-15 00:15:01,981 [podnet.py] => Task 19, Epoch 94/160 (LR 0.03643) => LSC_loss 0.36, Spatial_loss 2.00, Flat_loss 0.34, Train_acc 92.55, Test_acc 21.85
2025-02-15 00:15:04,200 [podnet.py] => Task 19, Epoch 95/160 (LR 0.03549) => LSC_loss 0.39, Spatial_loss 1.95, Flat_loss 0.35, Train_acc 91.75, Test_acc 17.67
2025-02-15 00:15:06,482 [podnet.py] => Task 19, Epoch 96/160 (LR 0.03455) => LSC_loss 0.36, Spatial_loss 1.92, Flat_loss 0.33, Train_acc 92.59, Test_acc 17.94
2025-02-15 00:15:08,722 [podnet.py] => Task 19, Epoch 97/160 (LR 0.03362) => LSC_loss 0.37, Spatial_loss 2.05, Flat_loss 0.34, Train_acc 92.34, Test_acc 20.88
2025-02-15 00:15:10,956 [podnet.py] => Task 19, Epoch 98/160 (LR 0.03269) => LSC_loss 0.34, Spatial_loss 1.86, Flat_loss 0.32, Train_acc 93.45, Test_acc 23.07
2025-02-15 00:15:13,201 [podnet.py] => Task 19, Epoch 99/160 (LR 0.03178) => LSC_loss 0.34, Spatial_loss 1.89, Flat_loss 0.33, Train_acc 93.30, Test_acc 23.29
2025-02-15 00:15:15,430 [podnet.py] => Task 19, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.94, Flat_loss 0.32, Train_acc 93.89, Test_acc 22.75
2025-02-15 00:15:17,669 [podnet.py] => Task 19, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.70, Flat_loss 0.31, Train_acc 93.91, Test_acc 21.31
2025-02-15 00:15:19,869 [podnet.py] => Task 19, Epoch 102/160 (LR 0.02907) => LSC_loss 0.33, Spatial_loss 1.74, Flat_loss 0.31, Train_acc 93.70, Test_acc 21.82
2025-02-15 00:15:22,140 [podnet.py] => Task 19, Epoch 103/160 (LR 0.02818) => LSC_loss 0.32, Spatial_loss 1.79, Flat_loss 0.30, Train_acc 93.80, Test_acc 22.70
2025-02-15 00:15:24,403 [podnet.py] => Task 19, Epoch 104/160 (LR 0.02730) => LSC_loss 0.31, Spatial_loss 1.75, Flat_loss 0.31, Train_acc 94.30, Test_acc 22.23
2025-02-15 00:15:26,667 [podnet.py] => Task 19, Epoch 105/160 (LR 0.02643) => LSC_loss 0.31, Spatial_loss 1.81, Flat_loss 0.31, Train_acc 94.34, Test_acc 18.77
2025-02-15 00:15:28,844 [podnet.py] => Task 19, Epoch 106/160 (LR 0.02557) => LSC_loss 0.31, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 94.05, Test_acc 20.33
2025-02-15 00:15:31,070 [podnet.py] => Task 19, Epoch 107/160 (LR 0.02472) => LSC_loss 0.32, Spatial_loss 1.79, Flat_loss 0.31, Train_acc 94.30, Test_acc 20.47
2025-02-15 00:15:33,261 [podnet.py] => Task 19, Epoch 108/160 (LR 0.02388) => LSC_loss 0.30, Spatial_loss 1.71, Flat_loss 0.30, Train_acc 94.66, Test_acc 22.95
2025-02-15 00:15:35,457 [podnet.py] => Task 19, Epoch 109/160 (LR 0.02304) => LSC_loss 0.29, Spatial_loss 1.61, Flat_loss 0.29, Train_acc 94.86, Test_acc 23.65
2025-02-15 00:15:37,741 [podnet.py] => Task 19, Epoch 110/160 (LR 0.02222) => LSC_loss 0.29, Spatial_loss 1.76, Flat_loss 0.29, Train_acc 94.50, Test_acc 22.18
2025-02-15 00:15:39,952 [podnet.py] => Task 19, Epoch 111/160 (LR 0.02141) => LSC_loss 0.28, Spatial_loss 1.62, Flat_loss 0.29, Train_acc 94.95, Test_acc 21.52
2025-02-15 00:15:42,143 [podnet.py] => Task 19, Epoch 112/160 (LR 0.02061) => LSC_loss 0.28, Spatial_loss 1.64, Flat_loss 0.29, Train_acc 95.09, Test_acc 23.26
2025-02-15 00:15:44,436 [podnet.py] => Task 19, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 1.63, Flat_loss 0.28, Train_acc 95.43, Test_acc 22.29
2025-02-15 00:15:46,680 [podnet.py] => Task 19, Epoch 114/160 (LR 0.01905) => LSC_loss 0.27, Spatial_loss 1.71, Flat_loss 0.29, Train_acc 95.50, Test_acc 24.61
2025-02-15 00:15:48,943 [podnet.py] => Task 19, Epoch 115/160 (LR 0.01828) => LSC_loss 0.28, Spatial_loss 1.76, Flat_loss 0.29, Train_acc 95.18, Test_acc 21.90
2025-02-15 00:15:51,226 [podnet.py] => Task 19, Epoch 116/160 (LR 0.01753) => LSC_loss 0.28, Spatial_loss 1.64, Flat_loss 0.28, Train_acc 95.25, Test_acc 23.71
2025-02-15 00:15:53,536 [podnet.py] => Task 19, Epoch 117/160 (LR 0.01679) => LSC_loss 0.28, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 95.30, Test_acc 24.07
2025-02-15 00:15:55,759 [podnet.py] => Task 19, Epoch 118/160 (LR 0.01606) => LSC_loss 0.26, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 95.91, Test_acc 23.09
2025-02-15 00:15:57,969 [podnet.py] => Task 19, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 1.58, Flat_loss 0.28, Train_acc 95.39, Test_acc 20.70
2025-02-15 00:16:00,193 [podnet.py] => Task 19, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 1.66, Flat_loss 0.28, Train_acc 95.80, Test_acc 22.76
2025-02-15 00:16:02,405 [podnet.py] => Task 19, Epoch 121/160 (LR 0.01396) => LSC_loss 0.27, Spatial_loss 1.61, Flat_loss 0.27, Train_acc 95.45, Test_acc 23.16
2025-02-15 00:16:04,637 [podnet.py] => Task 19, Epoch 122/160 (LR 0.01328) => LSC_loss 0.26, Spatial_loss 1.54, Flat_loss 0.27, Train_acc 96.25, Test_acc 23.36
2025-02-15 00:16:06,931 [podnet.py] => Task 19, Epoch 123/160 (LR 0.01262) => LSC_loss 0.25, Spatial_loss 1.59, Flat_loss 0.27, Train_acc 96.07, Test_acc 23.25
2025-02-15 00:16:09,209 [podnet.py] => Task 19, Epoch 124/160 (LR 0.01198) => LSC_loss 0.26, Spatial_loss 1.54, Flat_loss 0.26, Train_acc 96.23, Test_acc 23.89
2025-02-15 00:16:11,448 [podnet.py] => Task 19, Epoch 125/160 (LR 0.01135) => LSC_loss 0.25, Spatial_loss 1.47, Flat_loss 0.26, Train_acc 96.02, Test_acc 22.04
2025-02-15 00:16:13,707 [podnet.py] => Task 19, Epoch 126/160 (LR 0.01073) => LSC_loss 0.24, Spatial_loss 1.52, Flat_loss 0.26, Train_acc 96.59, Test_acc 24.98
2025-02-15 00:16:15,906 [podnet.py] => Task 19, Epoch 127/160 (LR 0.01013) => LSC_loss 0.24, Spatial_loss 1.40, Flat_loss 0.26, Train_acc 96.59, Test_acc 24.85
2025-02-15 00:16:18,138 [podnet.py] => Task 19, Epoch 128/160 (LR 0.00955) => LSC_loss 0.24, Spatial_loss 1.51, Flat_loss 0.25, Train_acc 96.18, Test_acc 24.49
2025-02-15 00:16:20,365 [podnet.py] => Task 19, Epoch 129/160 (LR 0.00898) => LSC_loss 0.25, Spatial_loss 1.43, Flat_loss 0.25, Train_acc 96.07, Test_acc 23.02
2025-02-15 00:16:22,646 [podnet.py] => Task 19, Epoch 130/160 (LR 0.00843) => LSC_loss 0.25, Spatial_loss 1.46, Flat_loss 0.26, Train_acc 96.32, Test_acc 24.15
2025-02-15 00:16:24,833 [podnet.py] => Task 19, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 1.44, Flat_loss 0.26, Train_acc 96.75, Test_acc 23.33
2025-02-15 00:16:27,128 [podnet.py] => Task 19, Epoch 132/160 (LR 0.00737) => LSC_loss 0.23, Spatial_loss 1.45, Flat_loss 0.25, Train_acc 96.95, Test_acc 23.43
2025-02-15 00:16:29,350 [podnet.py] => Task 19, Epoch 133/160 (LR 0.00686) => LSC_loss 0.24, Spatial_loss 1.41, Flat_loss 0.25, Train_acc 96.32, Test_acc 24.32
2025-02-15 00:16:31,618 [podnet.py] => Task 19, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.38, Flat_loss 0.25, Train_acc 97.11, Test_acc 23.32
2025-02-15 00:16:33,857 [podnet.py] => Task 19, Epoch 135/160 (LR 0.00590) => LSC_loss 0.23, Spatial_loss 1.39, Flat_loss 0.25, Train_acc 96.30, Test_acc 23.31
2025-02-15 00:16:36,160 [podnet.py] => Task 19, Epoch 136/160 (LR 0.00545) => LSC_loss 0.23, Spatial_loss 1.38, Flat_loss 0.25, Train_acc 97.23, Test_acc 25.37
2025-02-15 00:16:38,379 [podnet.py] => Task 19, Epoch 137/160 (LR 0.00501) => LSC_loss 0.23, Spatial_loss 1.36, Flat_loss 0.24, Train_acc 96.80, Test_acc 23.63
2025-02-15 00:16:40,615 [podnet.py] => Task 19, Epoch 138/160 (LR 0.00459) => LSC_loss 0.23, Spatial_loss 1.37, Flat_loss 0.25, Train_acc 96.50, Test_acc 23.98
2025-02-15 00:16:42,784 [podnet.py] => Task 19, Epoch 139/160 (LR 0.00419) => LSC_loss 0.23, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 96.75, Test_acc 23.26
2025-02-15 00:16:45,022 [podnet.py] => Task 19, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 97.14, Test_acc 24.38
2025-02-15 00:16:47,318 [podnet.py] => Task 19, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 97.39, Test_acc 23.62
2025-02-15 00:16:49,588 [podnet.py] => Task 19, Epoch 142/160 (LR 0.00309) => LSC_loss 0.22, Spatial_loss 1.25, Flat_loss 0.24, Train_acc 97.18, Test_acc 24.27
2025-02-15 00:16:51,789 [podnet.py] => Task 19, Epoch 143/160 (LR 0.00276) => LSC_loss 0.21, Spatial_loss 1.32, Flat_loss 0.24, Train_acc 97.30, Test_acc 24.57
2025-02-15 00:16:54,050 [podnet.py] => Task 19, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 97.02, Test_acc 24.24
2025-02-15 00:16:56,275 [podnet.py] => Task 19, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 97.25, Test_acc 24.07
2025-02-15 00:16:58,521 [podnet.py] => Task 19, Epoch 146/160 (LR 0.00188) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 97.43, Test_acc 23.98
2025-02-15 00:17:00,691 [podnet.py] => Task 19, Epoch 147/160 (LR 0.00162) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 96.50, Test_acc 24.64
2025-02-15 00:17:02,961 [podnet.py] => Task 19, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 97.20, Test_acc 24.39
2025-02-15 00:17:05,203 [podnet.py] => Task 19, Epoch 149/160 (LR 0.00116) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 97.34, Test_acc 24.24
2025-02-15 00:17:07,417 [podnet.py] => Task 19, Epoch 150/160 (LR 0.00096) => LSC_loss 0.21, Spatial_loss 1.19, Flat_loss 0.24, Train_acc 97.18, Test_acc 24.52
2025-02-15 00:17:09,636 [podnet.py] => Task 19, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 97.43, Test_acc 24.33
2025-02-15 00:17:11,833 [podnet.py] => Task 19, Epoch 152/160 (LR 0.00062) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 97.30, Test_acc 24.54
2025-02-15 00:17:14,084 [podnet.py] => Task 19, Epoch 153/160 (LR 0.00047) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 97.41, Test_acc 24.37
2025-02-15 00:17:16,339 [podnet.py] => Task 19, Epoch 154/160 (LR 0.00035) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.24, Train_acc 97.05, Test_acc 24.32
2025-02-15 00:17:18,549 [podnet.py] => Task 19, Epoch 155/160 (LR 0.00024) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 97.36, Test_acc 24.32
2025-02-15 00:17:20,782 [podnet.py] => Task 19, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 97.00, Test_acc 24.23
2025-02-15 00:17:23,040 [podnet.py] => Task 19, Epoch 157/160 (LR 0.00009) => LSC_loss 0.21, Spatial_loss 1.27, Flat_loss 0.23, Train_acc 97.23, Test_acc 24.58
2025-02-15 00:17:25,242 [podnet.py] => Task 19, Epoch 158/160 (LR 0.00004) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 97.57, Test_acc 24.29
2025-02-15 00:17:27,490 [podnet.py] => Task 19, Epoch 159/160 (LR 0.00001) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 97.34, Test_acc 24.27
2025-02-15 00:17:29,773 [podnet.py] => Task 19, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.24, Flat_loss 0.23, Train_acc 97.48, Test_acc 24.27
2025-02-15 00:17:29,774 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-15 00:17:29,774 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:18:05,674 [podnet.py] => The size of finetune dataset: 2000
2025-02-15 00:18:07,343 [podnet.py] => Task 19, Epoch 1/20 (LR 0.00497) => LSC_loss 0.25, Spatial_loss 1.42, Flat_loss 0.18, Train_acc 96.00, Test_acc 26.47
2025-02-15 00:18:09,013 [podnet.py] => Task 19, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 1.30, Flat_loss 0.13, Train_acc 98.75, Test_acc 27.04
2025-02-15 00:18:10,708 [podnet.py] => Task 19, Epoch 3/20 (LR 0.00473) => LSC_loss 0.16, Spatial_loss 1.23, Flat_loss 0.12, Train_acc 98.75, Test_acc 25.03
2025-02-15 00:18:12,361 [podnet.py] => Task 19, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 1.24, Flat_loss 0.11, Train_acc 98.60, Test_acc 25.09
2025-02-15 00:18:13,995 [podnet.py] => Task 19, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 1.28, Flat_loss 0.11, Train_acc 99.00, Test_acc 25.73
2025-02-15 00:18:15,705 [podnet.py] => Task 19, Epoch 6/20 (LR 0.00397) => LSC_loss 0.15, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 99.15, Test_acc 25.31
2025-02-15 00:18:17,463 [podnet.py] => Task 19, Epoch 7/20 (LR 0.00363) => LSC_loss 0.14, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 99.10, Test_acc 25.83
2025-02-15 00:18:19,200 [podnet.py] => Task 19, Epoch 8/20 (LR 0.00327) => LSC_loss 0.15, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 98.75, Test_acc 25.89
2025-02-15 00:18:20,893 [podnet.py] => Task 19, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 98.90, Test_acc 25.95
2025-02-15 00:18:22,544 [podnet.py] => Task 19, Epoch 10/20 (LR 0.00250) => LSC_loss 0.15, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 99.00, Test_acc 26.10
2025-02-15 00:18:24,280 [podnet.py] => Task 19, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 99.15, Test_acc 25.52
2025-02-15 00:18:25,934 [podnet.py] => Task 19, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 1.18, Flat_loss 0.11, Train_acc 98.90, Test_acc 25.61
2025-02-15 00:18:27,647 [podnet.py] => Task 19, Epoch 13/20 (LR 0.00137) => LSC_loss 0.14, Spatial_loss 1.21, Flat_loss 0.10, Train_acc 99.05, Test_acc 25.85
2025-02-15 00:18:29,257 [podnet.py] => Task 19, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 99.30, Test_acc 25.76
2025-02-15 00:18:30,928 [podnet.py] => Task 19, Epoch 15/20 (LR 0.00073) => LSC_loss 0.14, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 99.35, Test_acc 26.01
2025-02-15 00:18:32,544 [podnet.py] => Task 19, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 99.45, Test_acc 25.82
2025-02-15 00:18:34,216 [podnet.py] => Task 19, Epoch 17/20 (LR 0.00027) => LSC_loss 0.13, Spatial_loss 1.08, Flat_loss 0.11, Train_acc 99.45, Test_acc 25.90
2025-02-15 00:18:35,935 [podnet.py] => Task 19, Epoch 18/20 (LR 0.00012) => LSC_loss 0.14, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 99.05, Test_acc 25.89
2025-02-15 00:18:37,610 [podnet.py] => Task 19, Epoch 19/20 (LR 0.00003) => LSC_loss 0.15, Spatial_loss 1.17, Flat_loss 0.10, Train_acc 99.15, Test_acc 25.85
2025-02-15 00:18:39,264 [podnet.py] => Task 19, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.11, Train_acc 99.45, Test_acc 25.85
2025-02-15 00:18:39,266 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-15 00:19:16,519 [podnet.py] => Exemplar size: 2000
2025-02-15 00:19:16,520 [trainer.py] => CNN: {'total': 25.85, '00-09': 30.9, '10-19': 10.3, '20-29': 18.2, '30-39': 15.8, '40-49': 27.3, '50-59': 13.4, '60-69': 26.2, '70-79': 28.1, '80-89': 36.0, '90-99': 52.3, 'old': 23.96, 'new': 61.8}
2025-02-15 00:19:16,520 [trainer.py] => NME: {'total': 27.14, '00-09': 41.1, '10-19': 11.9, '20-29': 20.8, '30-39': 16.7, '40-49': 29.8, '50-59': 13.6, '60-69': 27.3, '70-79': 29.7, '80-89': 34.1, '90-99': 46.4, 'old': 25.78, 'new': 53.0}
2025-02-15 00:19:16,520 [trainer.py] => CNN top1 curve: [96.8, 80.5, 64.27, 54.1, 47.48, 42.3, 39.49, 35.33, 36.56, 33.98, 32.11, 32.42, 31.49, 31.04, 30.24, 28.7, 28.87, 28.16, 26.99, 25.85]
2025-02-15 00:19:16,520 [trainer.py] => CNN top5 curve: [100.0, 98.6, 93.67, 87.0, 80.44, 74.5, 69.54, 65.15, 64.11, 62.54, 61.73, 58.92, 58.06, 56.97, 55.85, 55.0, 56.02, 54.61, 53.34, 51.94]
2025-02-15 00:19:16,520 [trainer.py] => NME top1 curve: [96.8, 76.7, 62.53, 52.0, 47.16, 42.4, 38.97, 35.15, 35.84, 34.3, 32.27, 32.35, 31.65, 30.91, 30.08, 28.69, 29.13, 27.86, 27.19, 27.14]
2025-02-15 00:19:16,520 [trainer.py] => NME top5 curve: [100.0, 98.3, 92.27, 84.65, 78.52, 73.7, 69.0, 64.6, 63.24, 62.52, 61.31, 58.03, 56.88, 56.4, 55.49, 55.08, 55.31, 54.06, 53.25, 52.06]

2025-02-15 00:19:16,520 [trainer.py] => Average Accuracy (CNN): 41.334
2025-02-15 00:19:16,520 [trainer.py] => Average Accuracy (NME): 40.956