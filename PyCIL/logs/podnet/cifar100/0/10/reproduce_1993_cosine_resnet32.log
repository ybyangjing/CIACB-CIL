2025-02-17 12:12:46,758 [trainer.py] => config: ./exps/podnet.json
2025-02-17 12:12:46,760 [trainer.py] => prefix: reproduce
2025-02-17 12:12:46,761 [trainer.py] => dataset: cifar100
2025-02-17 12:12:46,761 [trainer.py] => memory_size: 2000
2025-02-17 12:12:46,762 [trainer.py] => memory_per_class: 20
2025-02-17 12:12:46,762 [trainer.py] => fixed_memory: True
2025-02-17 12:12:46,762 [trainer.py] => shuffle: True
2025-02-17 12:12:46,763 [trainer.py] => init_cls: 10
2025-02-17 12:12:46,763 [trainer.py] => increment: 10
2025-02-17 12:12:46,763 [trainer.py] => model_name: podnet
2025-02-17 12:12:46,764 [trainer.py] => convnet_type: cosine_resnet32
2025-02-17 12:12:46,764 [trainer.py] => device: [device(type='cuda', index=0)]
2025-02-17 12:12:46,764 [trainer.py] => seed: 1993
2025-02-17 12:12:48,727 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-02-17 12:12:54,043 [trainer.py] => All params: 466256
2025-02-17 12:12:54,044 [trainer.py] => Trainable params: 466256
2025-02-17 12:12:54,044 [podnet.py] => Learning on 0-10
2025-02-17 12:12:54,052 [podnet.py] => Adaptive factor: 0
2025-02-17 12:13:15,075 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 2.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 14.62, Test_acc 15.00
2025-02-17 12:13:16,749 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 2.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 24.86, Test_acc 16.70
2025-02-17 12:13:18,394 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 1.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 33.34, Test_acc 12.60
2025-02-17 12:13:20,032 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 1.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 40.26, Test_acc 33.60
2025-02-17 12:13:21,711 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 1.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 44.76, Test_acc 41.20
2025-02-17 12:13:23,366 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 1.54, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 46.82, Test_acc 39.50
2025-02-17 12:13:24,982 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 1.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 52.08, Test_acc 53.20
2025-02-17 12:13:26,673 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 1.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 55.36, Test_acc 38.70
2025-02-17 12:13:28,329 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 1.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 57.46, Test_acc 58.30
2025-02-17 12:13:29,963 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 1.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 59.24, Test_acc 39.30
2025-02-17 12:13:31,605 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 1.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 61.30, Test_acc 59.00
2025-02-17 12:13:33,269 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 1.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 62.94, Test_acc 52.20
2025-02-17 12:13:34,967 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 1.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 65.22, Test_acc 62.50
2025-02-17 12:13:36,637 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 1.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.08, Test_acc 54.90
2025-02-17 12:13:38,274 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 0.98, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.10, Test_acc 60.90
2025-02-17 12:13:39,925 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 0.99, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.12, Test_acc 63.80
2025-02-17 12:13:41,508 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 0.96, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.58, Test_acc 67.30
2025-02-17 12:13:43,141 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 0.86, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.20, Test_acc 67.20
2025-02-17 12:13:44,837 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.40, Test_acc 69.80
2025-02-17 12:13:46,501 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.50, Test_acc 73.10
2025-02-17 12:13:48,131 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 0.74, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.52, Test_acc 70.80
2025-02-17 12:13:49,801 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.84, Test_acc 69.40
2025-02-17 12:13:51,512 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.90, Test_acc 68.70
2025-02-17 12:13:53,199 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 0.71, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.20, Test_acc 70.10
2025-02-17 12:13:54,851 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 0.72, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.20, Test_acc 61.80
2025-02-17 12:13:56,508 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 0.72, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.50, Test_acc 74.00
2025-02-17 12:13:58,086 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.32, Test_acc 71.40
2025-02-17 12:13:59,699 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.40, Test_acc 73.00
2025-02-17 12:14:01,378 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.48, Test_acc 73.50
2025-02-17 12:14:02,967 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.22, Test_acc 75.00
2025-02-17 12:14:04,585 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.98, Test_acc 72.10
2025-02-17 12:14:06,273 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.82, Test_acc 71.80
2025-02-17 12:14:07,965 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 0.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.54, Test_acc 67.70
2025-02-17 12:14:09,646 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.20, Test_acc 71.70
2025-02-17 12:14:11,283 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.48, Test_acc 75.60
2025-02-17 12:14:12,952 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.54, Test_acc 80.40
2025-02-17 12:14:14,641 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.64, Test_acc 74.60
2025-02-17 12:14:16,299 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.84, Test_acc 77.10
2025-02-17 12:14:17,917 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.34, Test_acc 77.50
2025-02-17 12:14:19,611 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.32, Test_acc 74.80
2025-02-17 12:14:21,270 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.00, Test_acc 74.90
2025-02-17 12:14:22,923 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 0.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.28, Test_acc 78.60
2025-02-17 12:14:24,544 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.10, Test_acc 81.90
2025-02-17 12:14:26,205 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.28, Test_acc 80.50
2025-02-17 12:14:27,885 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.56, Test_acc 81.70
2025-02-17 12:14:29,601 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.90, Test_acc 74.80
2025-02-17 12:14:31,252 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.76, Test_acc 78.50
2025-02-17 12:14:32,923 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.08, Test_acc 76.90
2025-02-17 12:14:34,501 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.76, Test_acc 74.10
2025-02-17 12:14:36,148 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.32, Test_acc 80.20
2025-02-17 12:14:37,802 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.06, Test_acc 81.60
2025-02-17 12:14:39,429 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.38, Test_acc 75.90
2025-02-17 12:14:41,057 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.02, Test_acc 83.30
2025-02-17 12:14:42,663 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.54, Test_acc 82.40
2025-02-17 12:14:44,350 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.16, Test_acc 84.40
2025-02-17 12:14:45,987 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.78, Test_acc 83.10
2025-02-17 12:14:47,614 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.44, Test_acc 71.10
2025-02-17 12:14:49,249 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.20, Test_acc 81.50
2025-02-17 12:14:50,919 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.68, Test_acc 85.70
2025-02-17 12:14:52,541 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.72, Test_acc 82.80
2025-02-17 12:14:54,153 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.42, Test_acc 82.80
2025-02-17 12:14:55,774 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.60, Test_acc 83.70
2025-02-17 12:14:57,446 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.62, Test_acc 79.80
2025-02-17 12:14:59,068 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.24, Test_acc 84.90
2025-02-17 12:15:00,712 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.40, Test_acc 84.50
2025-02-17 12:15:02,333 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.58, Test_acc 84.00
2025-02-17 12:15:04,008 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.54, Test_acc 84.00
2025-02-17 12:15:05,629 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.32, Test_acc 85.40
2025-02-17 12:15:07,324 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.46, Test_acc 86.90
2025-02-17 12:15:08,883 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.86, Test_acc 80.80
2025-02-17 12:15:10,562 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.38, Test_acc 86.30
2025-02-17 12:15:12,191 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.26, Test_acc 85.70
2025-02-17 12:15:13,873 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.66, Test_acc 81.10
2025-02-17 12:15:15,497 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.76, Test_acc 84.50
2025-02-17 12:15:17,190 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.16, Test_acc 84.90
2025-02-17 12:15:18,851 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.06, Test_acc 86.00
2025-02-17 12:15:20,504 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.74, Test_acc 87.00
2025-02-17 12:15:22,162 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 85.00
2025-02-17 12:15:23,867 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.90, Test_acc 87.30
2025-02-17 12:15:25,502 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.28, Test_acc 84.80
2025-02-17 12:15:27,120 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.34, Test_acc 86.20
2025-02-17 12:15:28,770 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.56, Test_acc 84.30
2025-02-17 12:15:30,399 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.10, Test_acc 86.50
2025-02-17 12:15:32,054 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 86.00
2025-02-17 12:15:33,708 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.70, Test_acc 80.30
2025-02-17 12:15:35,373 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.00, Test_acc 88.20
2025-02-17 12:15:37,031 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.66, Test_acc 85.40
2025-02-17 12:15:38,714 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.62, Test_acc 86.70
2025-02-17 12:15:40,373 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.92, Test_acc 86.20
2025-02-17 12:15:42,027 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.32, Test_acc 89.70
2025-02-17 12:15:43,747 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.60, Test_acc 77.20
2025-02-17 12:15:45,405 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.36, Test_acc 87.10
2025-02-17 12:15:47,028 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.70, Test_acc 85.90
2025-02-17 12:15:48,691 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.66, Test_acc 86.40
2025-02-17 12:15:50,343 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.36, Test_acc 86.70
2025-02-17 12:15:51,999 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.22, Test_acc 84.10
2025-02-17 12:15:53,676 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.08, Test_acc 87.30
2025-02-17 12:15:55,360 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.40, Test_acc 88.00
2025-02-17 12:15:57,063 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.70, Test_acc 87.50
2025-02-17 12:15:58,714 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.32, Test_acc 87.20
2025-02-17 12:16:00,394 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.90, Test_acc 87.20
2025-02-17 12:16:02,041 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.22, Test_acc 89.30
2025-02-17 12:16:03,705 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.20, Test_acc 88.60
2025-02-17 12:16:05,327 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.16, Test_acc 87.40
2025-02-17 12:16:06,910 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.94, Test_acc 89.00
2025-02-17 12:16:08,535 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.68, Test_acc 87.90
2025-02-17 12:16:10,148 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.10, Test_acc 85.30
2025-02-17 12:16:11,848 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.32, Test_acc 85.10
2025-02-17 12:16:13,490 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.26, Test_acc 86.30
2025-02-17 12:16:15,118 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.66, Test_acc 87.10
2025-02-17 12:16:16,796 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.22, Test_acc 88.90
2025-02-17 12:16:18,412 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.88, Test_acc 85.80
2025-02-17 12:16:20,066 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.10, Test_acc 88.80
2025-02-17 12:16:21,763 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.66, Test_acc 90.10
2025-02-17 12:16:23,466 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.58, Test_acc 89.00
2025-02-17 12:16:25,145 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.18, Test_acc 89.10
2025-02-17 12:16:26,859 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.34, Test_acc 89.00
2025-02-17 12:16:28,505 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.38, Test_acc 89.20
2025-02-17 12:16:30,146 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.46, Test_acc 89.60
2025-02-17 12:16:31,805 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.68, Test_acc 89.00
2025-02-17 12:16:33,468 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 89.90
2025-02-17 12:16:35,094 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.14, Test_acc 90.00
2025-02-17 12:16:36,721 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 89.80
2025-02-17 12:16:38,282 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.14, Test_acc 90.60
2025-02-17 12:16:39,846 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.78, Test_acc 89.60
2025-02-17 12:16:41,522 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.62, Test_acc 90.50
2025-02-17 12:16:43,148 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 90.30
2025-02-17 12:16:44,805 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 89.50
2025-02-17 12:16:46,431 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 90.50
2025-02-17 12:16:48,037 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 90.80
2025-02-17 12:16:49,612 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 89.50
2025-02-17 12:16:51,232 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 90.80
2025-02-17 12:16:52,834 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.60
2025-02-17 12:16:54,448 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.32, Test_acc 89.40
2025-02-17 12:16:56,052 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 91.00
2025-02-17 12:16:57,647 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.96, Test_acc 90.30
2025-02-17 12:16:59,225 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 90.30
2025-02-17 12:17:00,836 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 90.10
2025-02-17 12:17:02,457 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.80
2025-02-17 12:17:04,088 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 91.00
2025-02-17 12:17:05,706 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.58, Test_acc 90.20
2025-02-17 12:17:07,346 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 90.60
2025-02-17 12:17:08,990 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 90.80
2025-02-17 12:17:10,629 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.50, Test_acc 90.60
2025-02-17 12:17:12,206 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 90.80
2025-02-17 12:17:13,777 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 90.60
2025-02-17 12:17:15,425 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 90.50
2025-02-17 12:17:17,039 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.66, Test_acc 90.40
2025-02-17 12:17:18,650 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.20
2025-02-17 12:17:20,254 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.82, Test_acc 90.40
2025-02-17 12:17:21,869 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 90.40
2025-02-17 12:17:23,506 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 90.80
2025-02-17 12:17:25,133 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 90.90
2025-02-17 12:17:26,769 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.50
2025-02-17 12:17:28,369 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.80
2025-02-17 12:17:29,976 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 90.40
2025-02-17 12:17:31,572 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 90.50
2025-02-17 12:17:33,209 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.66, Test_acc 90.20
2025-02-17 12:17:34,828 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 90.40
2025-02-17 12:17:36,438 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.30
2025-02-17 12:17:36,439 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:17:44,426 [podnet.py] => Exemplar size: 200
2025-02-17 12:17:44,426 [trainer.py] => CNN: {'total': 90.3, '00-09': 90.3, 'old': 0, 'new': 90.3}
2025-02-17 12:17:44,426 [trainer.py] => NME: {'total': 89.9, '00-09': 89.9, 'old': 0, 'new': 89.9}
2025-02-17 12:17:44,426 [trainer.py] => CNN top1 curve: [90.3]
2025-02-17 12:17:44,426 [trainer.py] => CNN top5 curve: [99.3]
2025-02-17 12:17:44,426 [trainer.py] => NME top1 curve: [89.9]
2025-02-17 12:17:44,426 [trainer.py] => NME top5 curve: [99.3]

2025-02-17 12:17:44,426 [trainer.py] => Average Accuracy (CNN): 90.3
2025-02-17 12:17:44,426 [trainer.py] => Average Accuracy (NME): 89.9
2025-02-17 12:17:44,427 [trainer.py] => All params: 472657
2025-02-17 12:17:44,427 [trainer.py] => Trainable params: 472657
2025-02-17 12:17:44,428 [podnet.py] => Learning on 10-20
2025-02-17 12:17:44,471 [podnet.py] => Adaptive factor: 1.4142135623730951
2025-02-17 12:17:46,681 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 2.48, Spatial_loss 1.75, Flat_loss 0.48, Train_acc 32.85, Test_acc 50.00
2025-02-17 12:17:48,646 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 1.67, Spatial_loss 1.41, Flat_loss 0.28, Train_acc 48.25, Test_acc 52.25
2025-02-17 12:17:50,676 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 1.53, Spatial_loss 1.37, Flat_loss 0.25, Train_acc 52.92, Test_acc 53.90
2025-02-17 12:17:52,703 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 1.44, Spatial_loss 1.38, Flat_loss 0.25, Train_acc 56.12, Test_acc 43.25
2025-02-17 12:17:54,684 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 1.34, Spatial_loss 1.39, Flat_loss 0.25, Train_acc 59.71, Test_acc 52.10
2025-02-17 12:17:56,725 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 1.28, Spatial_loss 1.37, Flat_loss 0.25, Train_acc 61.44, Test_acc 57.55
2025-02-17 12:17:58,716 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 1.19, Spatial_loss 1.40, Flat_loss 0.26, Train_acc 65.13, Test_acc 53.25
2025-02-17 12:18:00,755 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 1.13, Spatial_loss 1.42, Flat_loss 0.26, Train_acc 66.00, Test_acc 54.55
2025-02-17 12:18:02,844 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 1.09, Spatial_loss 1.43, Flat_loss 0.27, Train_acc 68.06, Test_acc 56.60
2025-02-17 12:18:04,883 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 1.03, Spatial_loss 1.43, Flat_loss 0.27, Train_acc 69.77, Test_acc 58.10
2025-02-17 12:18:06,912 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 1.01, Spatial_loss 1.45, Flat_loss 0.27, Train_acc 70.10, Test_acc 58.35
2025-02-17 12:18:08,914 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 1.45, Flat_loss 0.28, Train_acc 71.48, Test_acc 53.55
2025-02-17 12:18:10,919 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.94, Spatial_loss 1.44, Flat_loss 0.28, Train_acc 72.23, Test_acc 50.35
2025-02-17 12:18:12,981 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.91, Spatial_loss 1.47, Flat_loss 0.29, Train_acc 72.96, Test_acc 50.40
2025-02-17 12:18:15,013 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.89, Spatial_loss 1.47, Flat_loss 0.28, Train_acc 73.48, Test_acc 54.70
2025-02-17 12:18:17,070 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.85, Spatial_loss 1.44, Flat_loss 0.29, Train_acc 75.04, Test_acc 55.50
2025-02-17 12:18:19,066 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.85, Spatial_loss 1.45, Flat_loss 0.29, Train_acc 74.88, Test_acc 50.30
2025-02-17 12:18:21,111 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.82, Spatial_loss 1.45, Flat_loss 0.29, Train_acc 75.40, Test_acc 59.85
2025-02-17 12:18:23,155 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.80, Spatial_loss 1.46, Flat_loss 0.29, Train_acc 76.62, Test_acc 57.95
2025-02-17 12:18:25,195 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.75, Spatial_loss 1.44, Flat_loss 0.29, Train_acc 77.69, Test_acc 60.25
2025-02-17 12:18:27,184 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.73, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 78.73, Test_acc 62.75
2025-02-17 12:18:29,227 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.74, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 78.50, Test_acc 50.95
2025-02-17 12:18:31,259 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.69, Spatial_loss 1.41, Flat_loss 0.29, Train_acc 80.12, Test_acc 57.75
2025-02-17 12:18:33,228 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.70, Spatial_loss 1.44, Flat_loss 0.30, Train_acc 79.40, Test_acc 59.65
2025-02-17 12:18:35,266 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.70, Spatial_loss 1.46, Flat_loss 0.30, Train_acc 79.67, Test_acc 56.30
2025-02-17 12:18:37,278 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.66, Spatial_loss 1.44, Flat_loss 0.30, Train_acc 81.12, Test_acc 61.60
2025-02-17 12:18:39,318 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.65, Spatial_loss 1.43, Flat_loss 0.30, Train_acc 81.23, Test_acc 58.10
2025-02-17 12:18:41,292 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.61, Spatial_loss 1.42, Flat_loss 0.30, Train_acc 82.85, Test_acc 58.90
2025-02-17 12:18:43,302 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.61, Spatial_loss 1.44, Flat_loss 0.30, Train_acc 81.88, Test_acc 58.10
2025-02-17 12:18:45,365 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.57, Spatial_loss 1.46, Flat_loss 0.30, Train_acc 83.81, Test_acc 58.10
2025-02-17 12:18:47,417 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.61, Spatial_loss 1.45, Flat_loss 0.30, Train_acc 82.29, Test_acc 58.70
2025-02-17 12:18:49,414 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.60, Spatial_loss 1.43, Flat_loss 0.30, Train_acc 82.31, Test_acc 54.75
2025-02-17 12:18:51,405 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.54, Spatial_loss 1.41, Flat_loss 0.30, Train_acc 84.88, Test_acc 60.95
2025-02-17 12:18:53,497 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.54, Spatial_loss 1.40, Flat_loss 0.29, Train_acc 85.08, Test_acc 57.75
2025-02-17 12:18:55,484 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.58, Spatial_loss 1.42, Flat_loss 0.30, Train_acc 83.10, Test_acc 60.40
2025-02-17 12:18:57,538 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.52, Spatial_loss 1.40, Flat_loss 0.30, Train_acc 85.23, Test_acc 61.20
2025-02-17 12:18:59,541 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.53, Spatial_loss 1.41, Flat_loss 0.30, Train_acc 84.96, Test_acc 56.15
2025-02-17 12:19:01,590 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 1.40, Flat_loss 0.30, Train_acc 85.35, Test_acc 61.95
2025-02-17 12:19:03,593 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.49, Spatial_loss 1.39, Flat_loss 0.30, Train_acc 85.94, Test_acc 58.75
2025-02-17 12:19:05,596 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.52, Spatial_loss 1.43, Flat_loss 0.30, Train_acc 84.71, Test_acc 63.30
2025-02-17 12:19:07,632 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.47, Spatial_loss 1.39, Flat_loss 0.30, Train_acc 87.19, Test_acc 62.50
2025-02-17 12:19:09,607 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.47, Spatial_loss 1.39, Flat_loss 0.30, Train_acc 86.35, Test_acc 58.50
2025-02-17 12:19:11,617 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.48, Spatial_loss 1.40, Flat_loss 0.30, Train_acc 86.71, Test_acc 60.90
2025-02-17 12:19:13,673 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.46, Spatial_loss 1.41, Flat_loss 0.30, Train_acc 86.65, Test_acc 59.25
2025-02-17 12:19:15,710 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.44, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 87.98, Test_acc 57.20
2025-02-17 12:19:17,763 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.44, Spatial_loss 1.38, Flat_loss 0.29, Train_acc 87.69, Test_acc 56.05
2025-02-17 12:19:19,780 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.43, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 88.06, Test_acc 63.00
2025-02-17 12:19:21,776 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.41, Spatial_loss 1.35, Flat_loss 0.29, Train_acc 89.29, Test_acc 62.20
2025-02-17 12:19:23,809 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.38, Spatial_loss 1.34, Flat_loss 0.30, Train_acc 89.69, Test_acc 57.15
2025-02-17 12:19:25,777 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.41, Spatial_loss 1.36, Flat_loss 0.30, Train_acc 88.56, Test_acc 61.15
2025-02-17 12:19:27,839 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.42, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 88.50, Test_acc 63.10
2025-02-17 12:19:29,819 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.40, Spatial_loss 1.34, Flat_loss 0.29, Train_acc 89.27, Test_acc 59.05
2025-02-17 12:19:31,893 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.40, Spatial_loss 1.37, Flat_loss 0.29, Train_acc 89.02, Test_acc 58.10
2025-02-17 12:19:33,897 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.38, Spatial_loss 1.33, Flat_loss 0.29, Train_acc 90.13, Test_acc 60.65
2025-02-17 12:19:35,919 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.37, Spatial_loss 1.34, Flat_loss 0.29, Train_acc 89.88, Test_acc 63.35
2025-02-17 12:19:37,982 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.36, Spatial_loss 1.34, Flat_loss 0.29, Train_acc 90.48, Test_acc 56.60
2025-02-17 12:19:40,016 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.35, Spatial_loss 1.33, Flat_loss 0.29, Train_acc 91.33, Test_acc 58.70
2025-02-17 12:19:42,060 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.35, Spatial_loss 1.31, Flat_loss 0.29, Train_acc 90.44, Test_acc 61.75
2025-02-17 12:19:44,057 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.34, Spatial_loss 1.32, Flat_loss 0.29, Train_acc 91.25, Test_acc 61.25
2025-02-17 12:19:46,079 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.35, Spatial_loss 1.30, Flat_loss 0.29, Train_acc 90.67, Test_acc 58.50
2025-02-17 12:19:48,106 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.37, Spatial_loss 1.32, Flat_loss 0.29, Train_acc 89.85, Test_acc 61.45
2025-02-17 12:19:50,119 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.32, Spatial_loss 1.30, Flat_loss 0.29, Train_acc 91.56, Test_acc 61.65
2025-02-17 12:19:52,156 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.31, Spatial_loss 1.29, Flat_loss 0.29, Train_acc 91.90, Test_acc 62.60
2025-02-17 12:19:54,199 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.32, Spatial_loss 1.28, Flat_loss 0.29, Train_acc 91.29, Test_acc 60.80
2025-02-17 12:19:56,274 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.33, Spatial_loss 1.28, Flat_loss 0.29, Train_acc 91.52, Test_acc 61.20
2025-02-17 12:19:58,360 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.31, Spatial_loss 1.25, Flat_loss 0.29, Train_acc 91.81, Test_acc 56.70
2025-02-17 12:20:00,351 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.32, Spatial_loss 1.29, Flat_loss 0.29, Train_acc 91.58, Test_acc 59.75
2025-02-17 12:20:02,430 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.31, Spatial_loss 1.29, Flat_loss 0.29, Train_acc 91.81, Test_acc 61.55
2025-02-17 12:20:04,472 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.29, Spatial_loss 1.27, Flat_loss 0.29, Train_acc 92.54, Test_acc 58.95
2025-02-17 12:20:06,473 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.28, Spatial_loss 1.24, Flat_loss 0.29, Train_acc 93.08, Test_acc 58.25
2025-02-17 12:20:08,508 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.29, Spatial_loss 1.25, Flat_loss 0.29, Train_acc 92.90, Test_acc 59.85
2025-02-17 12:20:10,522 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.29, Train_acc 93.27, Test_acc 63.75
2025-02-17 12:20:12,579 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.28, Spatial_loss 1.24, Flat_loss 0.29, Train_acc 92.85, Test_acc 61.50
2025-02-17 12:20:14,534 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.28, Spatial_loss 1.23, Flat_loss 0.28, Train_acc 93.33, Test_acc 63.15
2025-02-17 12:20:16,543 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.27, Spatial_loss 1.22, Flat_loss 0.28, Train_acc 93.60, Test_acc 63.75
2025-02-17 12:20:18,522 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.27, Spatial_loss 1.21, Flat_loss 0.28, Train_acc 93.29, Test_acc 58.70
2025-02-17 12:20:20,540 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.28, Train_acc 94.25, Test_acc 62.40
2025-02-17 12:20:22,563 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.27, Spatial_loss 1.21, Flat_loss 0.28, Train_acc 93.12, Test_acc 62.70
2025-02-17 12:20:24,588 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.28, Train_acc 93.71, Test_acc 62.30
2025-02-17 12:20:26,590 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.28, Train_acc 93.65, Test_acc 63.65
2025-02-17 12:20:28,566 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.28, Train_acc 94.65, Test_acc 65.35
2025-02-17 12:20:30,606 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.28, Train_acc 94.56, Test_acc 59.90
2025-02-17 12:20:32,619 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.28, Train_acc 93.83, Test_acc 62.70
2025-02-17 12:20:34,631 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.28, Train_acc 94.48, Test_acc 65.35
2025-02-17 12:20:36,660 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.27, Train_acc 94.79, Test_acc 63.95
2025-02-17 12:20:38,717 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.27, Train_acc 95.79, Test_acc 63.00
2025-02-17 12:20:40,717 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.28, Train_acc 94.63, Test_acc 60.40
2025-02-17 12:20:42,745 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.20, Spatial_loss 1.16, Flat_loss 0.28, Train_acc 95.19, Test_acc 67.00
2025-02-17 12:20:44,816 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.27, Train_acc 95.73, Test_acc 63.60
2025-02-17 12:20:46,859 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.27, Train_acc 95.83, Test_acc 65.30
2025-02-17 12:20:48,887 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.27, Train_acc 95.38, Test_acc 62.60
2025-02-17 12:20:50,982 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.27, Train_acc 95.69, Test_acc 65.50
2025-02-17 12:20:53,033 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.27, Train_acc 96.44, Test_acc 63.50
2025-02-17 12:20:55,065 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.27, Train_acc 95.94, Test_acc 65.65
2025-02-17 12:20:57,101 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.27, Train_acc 96.04, Test_acc 64.60
2025-02-17 12:20:59,145 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.27, Train_acc 96.15, Test_acc 65.45
2025-02-17 12:21:01,142 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.27, Train_acc 95.50, Test_acc 61.40
2025-02-17 12:21:03,163 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.27, Train_acc 96.50, Test_acc 63.85
2025-02-17 12:21:05,267 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.26, Train_acc 96.75, Test_acc 65.60
2025-02-17 12:21:07,303 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.26, Train_acc 96.40, Test_acc 62.80
2025-02-17 12:21:09,334 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.26, Train_acc 95.96, Test_acc 65.40
2025-02-17 12:21:11,371 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.26, Train_acc 96.44, Test_acc 63.60
2025-02-17 12:21:13,449 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.26, Train_acc 97.02, Test_acc 66.45
2025-02-17 12:21:15,508 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.26, Train_acc 97.04, Test_acc 65.55
2025-02-17 12:21:17,583 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.26, Train_acc 97.12, Test_acc 65.10
2025-02-17 12:21:19,650 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.26, Train_acc 96.98, Test_acc 66.50
2025-02-17 12:21:21,636 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.26, Train_acc 97.33, Test_acc 65.20
2025-02-17 12:21:23,717 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.26, Train_acc 97.38, Test_acc 68.20
2025-02-17 12:21:25,721 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.26, Train_acc 97.46, Test_acc 66.60
2025-02-17 12:21:27,711 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.25, Train_acc 97.75, Test_acc 66.20
2025-02-17 12:21:29,797 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.25, Train_acc 97.67, Test_acc 67.15
2025-02-17 12:21:31,788 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.25, Train_acc 97.42, Test_acc 66.80
2025-02-17 12:21:33,794 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.25, Train_acc 97.60, Test_acc 68.60
2025-02-17 12:21:35,899 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.25, Train_acc 97.44, Test_acc 68.05
2025-02-17 12:21:37,957 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.25, Train_acc 97.38, Test_acc 66.85
2025-02-17 12:21:40,035 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.25, Train_acc 98.31, Test_acc 68.40
2025-02-17 12:21:42,076 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.25, Train_acc 97.98, Test_acc 65.80
2025-02-17 12:21:44,138 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.25, Train_acc 97.88, Test_acc 65.35
2025-02-17 12:21:46,199 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.24, Train_acc 98.15, Test_acc 66.70
2025-02-17 12:21:48,249 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.24, Train_acc 98.37, Test_acc 67.45
2025-02-17 12:21:50,321 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.24, Train_acc 98.25, Test_acc 66.85
2025-02-17 12:21:52,444 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.24, Train_acc 98.25, Test_acc 68.20
2025-02-17 12:21:54,544 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.24, Train_acc 98.21, Test_acc 68.60
2025-02-17 12:21:56,645 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.24, Train_acc 98.83, Test_acc 67.70
2025-02-17 12:21:58,760 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.24, Train_acc 98.73, Test_acc 68.50
2025-02-17 12:22:00,894 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.24, Train_acc 98.40, Test_acc 66.20
2025-02-17 12:22:02,936 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.11, Spatial_loss 0.90, Flat_loss 0.24, Train_acc 98.44, Test_acc 68.15
2025-02-17 12:22:04,953 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.24, Train_acc 98.71, Test_acc 68.95
2025-02-17 12:22:07,086 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.24, Train_acc 98.46, Test_acc 68.30
2025-02-17 12:22:09,183 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.24, Train_acc 98.48, Test_acc 69.15
2025-02-17 12:22:11,298 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.24, Train_acc 98.56, Test_acc 69.70
2025-02-17 12:22:13,465 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.24, Train_acc 98.71, Test_acc 68.60
2025-02-17 12:22:15,538 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.10, Spatial_loss 0.86, Flat_loss 0.23, Train_acc 98.83, Test_acc 69.00
2025-02-17 12:22:17,614 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.23, Train_acc 98.85, Test_acc 68.75
2025-02-17 12:22:19,718 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.23, Train_acc 98.98, Test_acc 68.50
2025-02-17 12:22:21,777 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.23, Train_acc 98.50, Test_acc 68.55
2025-02-17 12:22:23,854 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.24, Train_acc 98.79, Test_acc 68.20
2025-02-17 12:22:25,863 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.23, Train_acc 98.92, Test_acc 69.20
2025-02-17 12:22:27,947 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.23, Train_acc 98.87, Test_acc 68.80
2025-02-17 12:22:30,013 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.23, Train_acc 99.00, Test_acc 69.35
2025-02-17 12:22:32,043 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.23, Train_acc 98.90, Test_acc 68.20
2025-02-17 12:22:34,173 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.23, Train_acc 99.15, Test_acc 69.25
2025-02-17 12:22:36,331 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 98.83, Test_acc 68.90
2025-02-17 12:22:38,333 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 99.12, Test_acc 69.05
2025-02-17 12:22:40,388 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 98.85, Test_acc 69.60
2025-02-17 12:22:42,506 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 99.02, Test_acc 69.50
2025-02-17 12:22:44,632 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 98.90, Test_acc 69.35
2025-02-17 12:22:46,749 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.13, Test_acc 68.85
2025-02-17 12:22:48,910 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.23, Train_acc 98.87, Test_acc 69.20
2025-02-17 12:22:51,023 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 98.94, Test_acc 69.15
2025-02-17 12:22:53,148 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.35, Test_acc 69.45
2025-02-17 12:22:55,227 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.23, Train_acc 99.00, Test_acc 69.40
2025-02-17 12:22:57,306 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.35, Test_acc 69.40
2025-02-17 12:22:59,370 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.08, Test_acc 69.50
2025-02-17 12:23:01,466 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.23, Train_acc 99.21, Test_acc 69.30
2025-02-17 12:23:03,559 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.08, Test_acc 69.40
2025-02-17 12:23:05,659 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.04, Test_acc 69.30
2025-02-17 12:23:07,713 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.35, Test_acc 69.15
2025-02-17 12:23:09,811 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.25, Test_acc 69.30
2025-02-17 12:23:11,906 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.23, Train_acc 99.12, Test_acc 68.95
2025-02-17 12:23:11,907 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:23:11,907 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:23:22,341 [podnet.py] => The size of finetune dataset: 400
2025-02-17 12:23:23,418 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.24, Spatial_loss 0.99, Flat_loss 0.23, Train_acc 95.75, Test_acc 69.40
2025-02-17 12:23:24,367 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.22, Train_acc 98.75, Test_acc 70.10
2025-02-17 12:23:25,237 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.18, Spatial_loss 0.98, Flat_loss 0.21, Train_acc 97.75, Test_acc 69.95
2025-02-17 12:23:26,178 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.25, Test_acc 69.85
2025-02-17 12:23:27,093 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.20, Train_acc 97.75, Test_acc 69.95
2025-02-17 12:23:27,996 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 97.50, Test_acc 69.25
2025-02-17 12:23:28,873 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 99.00, Test_acc 69.40
2025-02-17 12:23:29,733 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 99.00, Test_acc 69.55
2025-02-17 12:23:30,682 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 99.50, Test_acc 69.90
2025-02-17 12:23:31,648 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.17, Train_acc 98.25, Test_acc 70.25
2025-02-17 12:23:32,512 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.50, Test_acc 70.00
2025-02-17 12:23:33,448 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 0.99, Flat_loss 0.20, Train_acc 98.75, Test_acc 70.00
2025-02-17 12:23:34,374 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 98.75, Test_acc 69.55
2025-02-17 12:23:35,268 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.18, Train_acc 98.75, Test_acc 69.55
2025-02-17 12:23:36,169 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.07, Spatial_loss 0.92, Flat_loss 0.18, Train_acc 99.25, Test_acc 70.00
2025-02-17 12:23:37,160 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.96, Flat_loss 0.20, Train_acc 99.50, Test_acc 69.70
2025-02-17 12:23:38,060 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 99.50, Test_acc 69.85
2025-02-17 12:23:39,026 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.15, Spatial_loss 0.87, Flat_loss 0.18, Train_acc 99.00, Test_acc 70.20
2025-02-17 12:23:39,927 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 0.92, Flat_loss 0.17, Train_acc 99.50, Test_acc 70.15
2025-02-17 12:23:40,817 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.89, Flat_loss 0.18, Train_acc 99.75, Test_acc 70.25
2025-02-17 12:23:40,820 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:23:52,176 [podnet.py] => Exemplar size: 400
2025-02-17 12:23:52,176 [trainer.py] => CNN: {'total': 70.25, '00-09': 75.9, '10-19': 64.6, 'old': 75.9, 'new': 64.6}
2025-02-17 12:23:52,176 [trainer.py] => NME: {'total': 69.8, '00-09': 80.3, '10-19': 59.3, 'old': 80.3, 'new': 59.3}
2025-02-17 12:23:52,176 [trainer.py] => CNN top1 curve: [90.3, 70.25]
2025-02-17 12:23:52,176 [trainer.py] => CNN top5 curve: [99.3, 93.4]
2025-02-17 12:23:52,177 [trainer.py] => NME top1 curve: [89.9, 69.8]
2025-02-17 12:23:52,177 [trainer.py] => NME top5 curve: [99.3, 93.0]

2025-02-17 12:23:52,177 [trainer.py] => Average Accuracy (CNN): 80.275
2025-02-17 12:23:52,177 [trainer.py] => Average Accuracy (NME): 79.85
2025-02-17 12:23:52,177 [trainer.py] => All params: 479057
2025-02-17 12:23:52,177 [trainer.py] => Trainable params: 479057
2025-02-17 12:23:52,178 [podnet.py] => Learning on 20-30
2025-02-17 12:23:52,220 [podnet.py] => Adaptive factor: 1.7320508075688772
2025-02-17 12:23:54,510 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 2.46, Spatial_loss 2.38, Flat_loss 0.71, Train_acc 49.09, Test_acc 29.23
2025-02-17 12:23:56,632 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 1.23, Spatial_loss 2.08, Flat_loss 0.40, Train_acc 66.26, Test_acc 31.63
2025-02-17 12:23:58,740 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 1.02, Spatial_loss 1.78, Flat_loss 0.29, Train_acc 71.17, Test_acc 39.57
2025-02-17 12:24:00,844 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 0.92, Spatial_loss 1.70, Flat_loss 0.25, Train_acc 74.19, Test_acc 40.77
2025-02-17 12:24:03,019 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 0.86, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 76.50, Test_acc 40.93
2025-02-17 12:24:05,250 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 0.81, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 77.63, Test_acc 44.67
2025-02-17 12:24:07,417 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 0.75, Spatial_loss 1.60, Flat_loss 0.21, Train_acc 79.13, Test_acc 37.90
2025-02-17 12:24:09,560 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 0.76, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 79.56, Test_acc 38.80
2025-02-17 12:24:11,729 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.76, Spatial_loss 1.61, Flat_loss 0.21, Train_acc 79.65, Test_acc 35.93
2025-02-17 12:24:13,885 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.70, Spatial_loss 1.62, Flat_loss 0.21, Train_acc 81.26, Test_acc 44.37
2025-02-17 12:24:16,084 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.66, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 82.76, Test_acc 42.60
2025-02-17 12:24:18,189 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.66, Spatial_loss 1.58, Flat_loss 0.21, Train_acc 82.22, Test_acc 33.57
2025-02-17 12:24:20,382 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.60, Spatial_loss 1.57, Flat_loss 0.21, Train_acc 84.09, Test_acc 50.63
2025-02-17 12:24:22,544 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.60, Spatial_loss 1.52, Flat_loss 0.20, Train_acc 83.80, Test_acc 41.40
2025-02-17 12:24:24,698 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.60, Spatial_loss 1.56, Flat_loss 0.21, Train_acc 83.69, Test_acc 46.57
2025-02-17 12:24:26,846 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.53, Spatial_loss 1.51, Flat_loss 0.20, Train_acc 86.24, Test_acc 45.60
2025-02-17 12:24:29,032 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.54, Spatial_loss 1.54, Flat_loss 0.21, Train_acc 85.70, Test_acc 47.90
2025-02-17 12:24:31,144 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.52, Spatial_loss 1.49, Flat_loss 0.20, Train_acc 86.59, Test_acc 46.10
2025-02-17 12:24:33,289 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.54, Spatial_loss 1.57, Flat_loss 0.21, Train_acc 85.30, Test_acc 46.63
2025-02-17 12:24:35,424 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.49, Spatial_loss 1.44, Flat_loss 0.20, Train_acc 87.41, Test_acc 41.90
2025-02-17 12:24:37,613 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.52, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 86.31, Test_acc 47.37
2025-02-17 12:24:39,760 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.50, Spatial_loss 1.54, Flat_loss 0.21, Train_acc 87.00, Test_acc 46.13
2025-02-17 12:24:41,885 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.50, Spatial_loss 1.50, Flat_loss 0.21, Train_acc 86.33, Test_acc 48.57
2025-02-17 12:24:43,987 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.46, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 87.85, Test_acc 43.87
2025-02-17 12:24:46,130 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.46, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 88.07, Test_acc 44.03
2025-02-17 12:24:48,216 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.45, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 88.04, Test_acc 43.27
2025-02-17 12:24:50,369 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.43, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 88.50, Test_acc 49.40
2025-02-17 12:24:52,544 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.45, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 88.43, Test_acc 42.40
2025-02-17 12:24:54,701 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.43, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 89.39, Test_acc 46.33
2025-02-17 12:24:56,814 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.42, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 89.19, Test_acc 45.70
2025-02-17 12:24:58,949 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.40, Spatial_loss 1.46, Flat_loss 0.20, Train_acc 89.93, Test_acc 48.73
2025-02-17 12:25:01,027 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.41, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 88.96, Test_acc 50.27
2025-02-17 12:25:03,098 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.41, Spatial_loss 1.46, Flat_loss 0.20, Train_acc 89.37, Test_acc 41.90
2025-02-17 12:25:05,216 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.41, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 89.48, Test_acc 42.47
2025-02-17 12:25:07,395 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.39, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 90.06, Test_acc 50.33
2025-02-17 12:25:09,548 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.35, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 91.56, Test_acc 50.40
2025-02-17 12:25:11,757 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.33, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 91.54, Test_acc 47.70
2025-02-17 12:25:13,877 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.36, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 90.96, Test_acc 45.07
2025-02-17 12:25:16,048 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.36, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 90.76, Test_acc 44.97
2025-02-17 12:25:18,127 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.38, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 90.46, Test_acc 49.90
2025-02-17 12:25:20,277 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.41, Spatial_loss 1.52, Flat_loss 0.21, Train_acc 89.07, Test_acc 50.30
2025-02-17 12:25:22,336 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.35, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 91.67, Test_acc 46.10
2025-02-17 12:25:24,457 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 90.52, Test_acc 46.93
2025-02-17 12:25:26,675 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.31, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 92.43, Test_acc 48.53
2025-02-17 12:25:28,845 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.32, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 92.09, Test_acc 44.57
2025-02-17 12:25:31,060 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.34, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 91.24, Test_acc 45.23
2025-02-17 12:25:33,216 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.33, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 91.39, Test_acc 41.53
2025-02-17 12:25:35,345 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.33, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 91.67, Test_acc 47.77
2025-02-17 12:25:37,458 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 92.85, Test_acc 43.43
2025-02-17 12:25:39,574 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.30, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 92.83, Test_acc 51.67
2025-02-17 12:25:41,725 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.29, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 93.43, Test_acc 52.57
2025-02-17 12:25:43,815 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 92.89, Test_acc 48.07
2025-02-17 12:25:45,969 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 94.13, Test_acc 51.23
2025-02-17 12:25:48,093 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 93.48, Test_acc 49.97
2025-02-17 12:25:50,238 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.28, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 93.13, Test_acc 49.73
2025-02-17 12:25:52,469 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.33, Spatial_loss 1.39, Flat_loss 0.20, Train_acc 91.65, Test_acc 45.87
2025-02-17 12:25:54,593 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.29, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 92.98, Test_acc 51.63
2025-02-17 12:25:56,763 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 94.13, Test_acc 50.03
2025-02-17 12:25:58,887 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 94.59, Test_acc 47.50
2025-02-17 12:26:01,045 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 93.48, Test_acc 47.53
2025-02-17 12:26:03,179 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 93.65, Test_acc 49.93
2025-02-17 12:26:05,276 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 93.54, Test_acc 47.27
2025-02-17 12:26:07,447 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.28, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 94.19, Test_acc 43.77
2025-02-17 12:26:09,563 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 92.94, Test_acc 50.70
2025-02-17 12:26:11,781 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.27, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 94.20, Test_acc 47.60
2025-02-17 12:26:13,926 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.28, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 92.96, Test_acc 49.67
2025-02-17 12:26:16,025 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 94.74, Test_acc 53.07
2025-02-17 12:26:18,254 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 94.46, Test_acc 46.30
2025-02-17 12:26:20,404 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.23, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 95.33, Test_acc 48.80
2025-02-17 12:26:22,489 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 94.76, Test_acc 50.53
2025-02-17 12:26:24,649 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 94.80, Test_acc 48.63
2025-02-17 12:26:26,800 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 94.43, Test_acc 49.87
2025-02-17 12:26:28,919 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 94.20, Test_acc 49.20
2025-02-17 12:26:31,114 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 93.24, Test_acc 50.80
2025-02-17 12:26:33,270 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 95.19, Test_acc 52.87
2025-02-17 12:26:35,438 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.22, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 95.54, Test_acc 50.93
2025-02-17 12:26:37,551 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 94.94, Test_acc 51.67
2025-02-17 12:26:39,678 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 95.09, Test_acc 52.13
2025-02-17 12:26:41,800 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 1.19, Flat_loss 0.19, Train_acc 95.83, Test_acc 49.50
2025-02-17 12:26:43,930 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 96.30, Test_acc 53.53
2025-02-17 12:26:46,044 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 96.31, Test_acc 49.67
2025-02-17 12:26:48,157 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 95.61, Test_acc 51.40
2025-02-17 12:26:50,296 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 95.69, Test_acc 49.33
2025-02-17 12:26:52,394 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 95.07, Test_acc 52.57
2025-02-17 12:26:54,562 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 95.93, Test_acc 51.63
2025-02-17 12:26:56,693 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 95.74, Test_acc 51.67
2025-02-17 12:26:58,842 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 96.15, Test_acc 53.20
2025-02-17 12:27:01,013 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 96.69, Test_acc 49.50
2025-02-17 12:27:03,147 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 95.85, Test_acc 51.70
2025-02-17 12:27:05,318 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 96.37, Test_acc 54.13
2025-02-17 12:27:07,489 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 96.19, Test_acc 50.20
2025-02-17 12:27:09,633 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 96.35, Test_acc 51.67
2025-02-17 12:27:11,736 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 95.59, Test_acc 53.20
2025-02-17 12:27:13,841 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.18, Train_acc 96.44, Test_acc 53.03
2025-02-17 12:27:16,032 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 97.17, Test_acc 50.83
2025-02-17 12:27:18,221 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 97.65, Test_acc 53.20
2025-02-17 12:27:20,326 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 97.72, Test_acc 53.87
2025-02-17 12:27:22,395 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 97.72, Test_acc 54.87
2025-02-17 12:27:24,512 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.16, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 97.57, Test_acc 51.73
2025-02-17 12:27:26,630 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 97.37, Test_acc 50.83
2025-02-17 12:27:28,746 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 97.67, Test_acc 53.20
2025-02-17 12:27:30,870 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 96.89, Test_acc 54.40
2025-02-17 12:27:33,019 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 97.76, Test_acc 53.60
2025-02-17 12:27:35,159 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 97.72, Test_acc 54.50
2025-02-17 12:27:37,299 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 97.93, Test_acc 54.40
2025-02-17 12:27:39,438 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 97.87, Test_acc 54.47
2025-02-17 12:27:41,547 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.14, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 98.02, Test_acc 55.00
2025-02-17 12:27:43,774 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 97.89, Test_acc 54.13
2025-02-17 12:27:45,931 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 97.70, Test_acc 53.47
2025-02-17 12:27:48,066 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 97.98, Test_acc 52.70
2025-02-17 12:27:50,218 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 98.07, Test_acc 55.43
2025-02-17 12:27:52,324 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.07, Test_acc 53.77
2025-02-17 12:27:54,454 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.39, Test_acc 52.13
2025-02-17 12:27:56,616 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 98.96, Test_acc 55.67
2025-02-17 12:27:58,737 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 98.19, Test_acc 55.73
2025-02-17 12:28:00,844 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.54, Test_acc 53.53
2025-02-17 12:28:03,004 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.50, Test_acc 54.40
2025-02-17 12:28:05,167 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.57, Test_acc 54.00
2025-02-17 12:28:07,320 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 98.81, Test_acc 55.63
2025-02-17 12:28:09,408 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.48, Test_acc 54.33
2025-02-17 12:28:11,570 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.16, Train_acc 98.81, Test_acc 56.20
2025-02-17 12:28:13,669 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.74, Test_acc 55.23
2025-02-17 12:28:15,863 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.76, Test_acc 54.80
2025-02-17 12:28:18,061 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 98.78, Test_acc 53.93
2025-02-17 12:28:20,270 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.39, Test_acc 54.17
2025-02-17 12:28:22,497 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.91, Test_acc 55.43
2025-02-17 12:28:24,649 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.72, Test_acc 55.00
2025-02-17 12:28:26,813 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.85, Test_acc 55.73
2025-02-17 12:28:28,953 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.87, Test_acc 54.30
2025-02-17 12:28:31,108 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 98.98, Test_acc 55.97
2025-02-17 12:28:33,244 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.94, Test_acc 55.77
2025-02-17 12:28:35,482 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 99.22, Test_acc 55.57
2025-02-17 12:28:37,659 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.11, Test_acc 55.67
2025-02-17 12:28:39,860 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 98.81, Test_acc 55.60
2025-02-17 12:28:42,007 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 99.28, Test_acc 56.27
2025-02-17 12:28:44,182 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.15, Train_acc 99.33, Test_acc 56.00
2025-02-17 12:28:46,407 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.15, Train_acc 99.24, Test_acc 56.23
2025-02-17 12:28:48,568 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 99.26, Test_acc 56.23
2025-02-17 12:28:50,794 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.15, Train_acc 99.28, Test_acc 55.43
2025-02-17 12:28:52,990 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.10, Spatial_loss 0.83, Flat_loss 0.15, Train_acc 99.33, Test_acc 56.50
2025-02-17 12:28:55,229 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.15, Train_acc 99.30, Test_acc 56.33
2025-02-17 12:28:57,422 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.15, Train_acc 99.37, Test_acc 56.13
2025-02-17 12:28:59,566 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.15, Train_acc 99.33, Test_acc 55.97
2025-02-17 12:29:01,757 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.15, Train_acc 99.35, Test_acc 55.87
2025-02-17 12:29:03,958 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.15, Train_acc 99.46, Test_acc 56.27
2025-02-17 12:29:06,190 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.15, Train_acc 99.13, Test_acc 56.63
2025-02-17 12:29:08,334 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.15, Train_acc 99.43, Test_acc 56.37
2025-02-17 12:29:10,493 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.15, Train_acc 99.11, Test_acc 56.37
2025-02-17 12:29:12,769 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.15, Train_acc 99.43, Test_acc 56.10
2025-02-17 12:29:15,012 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.30, Test_acc 56.43
2025-02-17 12:29:17,245 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.30, Test_acc 56.27
2025-02-17 12:29:19,440 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.46, Test_acc 56.37
2025-02-17 12:29:21,649 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.20, Test_acc 56.37
2025-02-17 12:29:23,872 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.46, Test_acc 56.43
2025-02-17 12:29:26,041 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.15, Train_acc 99.33, Test_acc 56.27
2025-02-17 12:29:28,272 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.39, Test_acc 55.93
2025-02-17 12:29:30,509 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.43, Test_acc 56.33
2025-02-17 12:29:32,692 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 99.30, Test_acc 56.13
2025-02-17 12:29:34,907 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.15, Train_acc 99.37, Test_acc 56.33
2025-02-17 12:29:37,118 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 99.22, Test_acc 55.87
2025-02-17 12:29:37,119 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:29:37,119 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:29:51,384 [podnet.py] => The size of finetune dataset: 600
2025-02-17 12:29:52,471 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.21, Spatial_loss 0.86, Flat_loss 0.12, Train_acc 97.33, Test_acc 56.40
2025-02-17 12:29:53,558 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 0.83, Flat_loss 0.11, Train_acc 98.67, Test_acc 57.20
2025-02-17 12:29:54,638 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 0.79, Flat_loss 0.10, Train_acc 99.33, Test_acc 58.10
2025-02-17 12:29:55,722 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.10, Train_acc 99.50, Test_acc 59.00
2025-02-17 12:29:56,792 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.00, Test_acc 59.43
2025-02-17 12:29:57,808 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.33, Test_acc 59.13
2025-02-17 12:29:58,846 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 99.50, Test_acc 58.77
2025-02-17 12:29:59,906 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.09, Train_acc 99.33, Test_acc 58.83
2025-02-17 12:30:00,923 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.50, Test_acc 59.03
2025-02-17 12:30:02,027 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.50, Test_acc 59.03
2025-02-17 12:30:03,111 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.08, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.67, Test_acc 59.13
2025-02-17 12:30:04,223 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.08, Spatial_loss 0.74, Flat_loss 0.09, Train_acc 99.67, Test_acc 59.37
2025-02-17 12:30:05,242 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 99.83, Test_acc 59.30
2025-02-17 12:30:06,303 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.50, Test_acc 59.27
2025-02-17 12:30:07,337 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 0.73, Flat_loss 0.09, Train_acc 99.83, Test_acc 59.20
2025-02-17 12:30:08,331 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.09, Train_acc 99.50, Test_acc 59.10
2025-02-17 12:30:09,399 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.09, Train_acc 99.33, Test_acc 59.20
2025-02-17 12:30:10,429 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 0.72, Flat_loss 0.09, Train_acc 100.00, Test_acc 59.07
2025-02-17 12:30:11,550 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 99.67, Test_acc 59.27
2025-02-17 12:30:12,592 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.70, Flat_loss 0.09, Train_acc 99.67, Test_acc 59.23
2025-02-17 12:30:12,594 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:30:27,960 [podnet.py] => Exemplar size: 600
2025-02-17 12:30:27,960 [trainer.py] => CNN: {'total': 59.23, '00-09': 68.5, '10-19': 33.3, '20-29': 75.9, 'old': 50.9, 'new': 75.9}
2025-02-17 12:30:27,960 [trainer.py] => NME: {'total': 59.13, '00-09': 76.5, '10-19': 32.2, '20-29': 68.7, 'old': 54.35, 'new': 68.7}
2025-02-17 12:30:27,960 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23]
2025-02-17 12:30:27,960 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03]
2025-02-17 12:30:27,960 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13]
2025-02-17 12:30:27,960 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07]

2025-02-17 12:30:27,960 [trainer.py] => Average Accuracy (CNN): 73.26
2025-02-17 12:30:27,960 [trainer.py] => Average Accuracy (NME): 72.94333333333333
2025-02-17 12:30:27,961 [trainer.py] => All params: 485457
2025-02-17 12:30:27,961 [trainer.py] => Trainable params: 485457
2025-02-17 12:30:27,962 [podnet.py] => Learning on 30-40
2025-02-17 12:30:28,007 [podnet.py] => Adaptive factor: 2.0
2025-02-17 12:30:30,626 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 2.74, Spatial_loss 2.62, Flat_loss 0.82, Train_acc 42.96, Test_acc 21.92
2025-02-17 12:30:32,914 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 1.39, Spatial_loss 2.06, Flat_loss 0.39, Train_acc 60.32, Test_acc 33.40
2025-02-17 12:30:35,271 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 1.26, Spatial_loss 1.88, Flat_loss 0.29, Train_acc 63.95, Test_acc 35.02
2025-02-17 12:30:37,539 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 1.15, Spatial_loss 1.81, Flat_loss 0.26, Train_acc 66.43, Test_acc 31.60
2025-02-17 12:30:39,832 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 1.06, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 69.68, Test_acc 33.40
2025-02-17 12:30:42,162 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 1.00, Spatial_loss 1.68, Flat_loss 0.23, Train_acc 72.11, Test_acc 31.35
2025-02-17 12:30:44,441 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 1.01, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 71.66, Test_acc 31.82
2025-02-17 12:30:46,812 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 0.95, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 73.32, Test_acc 37.80
2025-02-17 12:30:49,182 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 0.89, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 74.41, Test_acc 36.55
2025-02-17 12:30:51,503 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 0.89, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 75.39, Test_acc 38.72
2025-02-17 12:30:53,836 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.86, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 76.04, Test_acc 35.78
2025-02-17 12:30:56,012 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.85, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 76.21, Test_acc 36.08
2025-02-17 12:30:58,277 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.81, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 77.34, Test_acc 40.22
2025-02-17 12:31:00,513 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.79, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 77.57, Test_acc 36.72
2025-02-17 12:31:02,781 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.75, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 79.32, Test_acc 37.50
2025-02-17 12:31:05,033 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.77, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 78.52, Test_acc 33.65
2025-02-17 12:31:07,282 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.76, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 78.50, Test_acc 37.02
2025-02-17 12:31:09,527 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.69, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 80.84, Test_acc 38.98
2025-02-17 12:31:11,768 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.70, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 80.38, Test_acc 37.28
2025-02-17 12:31:13,983 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.70, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 80.75, Test_acc 35.22
2025-02-17 12:31:16,233 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.67, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 82.00, Test_acc 33.55
2025-02-17 12:31:18,449 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.65, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 82.36, Test_acc 36.20
2025-02-17 12:31:20,717 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.62, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 83.20, Test_acc 35.05
2025-02-17 12:31:22,993 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.64, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 82.52, Test_acc 38.85
2025-02-17 12:31:25,196 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.61, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 83.34, Test_acc 39.95
2025-02-17 12:31:27,425 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.62, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 83.11, Test_acc 38.20
2025-02-17 12:31:29,675 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.59, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 83.71, Test_acc 38.40
2025-02-17 12:31:31,938 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.56, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 84.64, Test_acc 37.85
2025-02-17 12:31:34,200 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.60, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 83.41, Test_acc 37.48
2025-02-17 12:31:36,468 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.58, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 84.20, Test_acc 36.78
2025-02-17 12:31:38,681 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.57, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 84.34, Test_acc 39.88
2025-02-17 12:31:40,909 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.52, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 85.70, Test_acc 39.30
2025-02-17 12:31:43,143 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.52, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 86.57, Test_acc 42.20
2025-02-17 12:31:45,364 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.56, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 84.62, Test_acc 36.48
2025-02-17 12:31:47,585 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.54, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 85.95, Test_acc 33.62
2025-02-17 12:31:49,841 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.52, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 86.32, Test_acc 42.48
2025-02-17 12:31:52,072 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.52, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 85.82, Test_acc 39.12
2025-02-17 12:31:54,302 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 85.98, Test_acc 36.88
2025-02-17 12:31:56,505 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.50, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 86.16, Test_acc 36.88
2025-02-17 12:31:58,735 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.50, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 86.93, Test_acc 40.08
2025-02-17 12:32:01,002 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.48, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 87.02, Test_acc 35.15
2025-02-17 12:32:03,263 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.49, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 86.55, Test_acc 39.65
2025-02-17 12:32:05,464 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.48, Spatial_loss 1.50, Flat_loss 0.23, Train_acc 87.12, Test_acc 39.45
2025-02-17 12:32:07,643 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.45, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 88.21, Test_acc 39.58
2025-02-17 12:32:09,857 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.47, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 87.62, Test_acc 38.80
2025-02-17 12:32:12,129 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.45, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 88.50, Test_acc 37.08
2025-02-17 12:32:14,406 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.44, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 88.64, Test_acc 38.72
2025-02-17 12:32:16,680 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.43, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 89.14, Test_acc 39.42
2025-02-17 12:32:18,938 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.43, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 88.77, Test_acc 38.78
2025-02-17 12:32:21,189 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.44, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 88.41, Test_acc 38.15
2025-02-17 12:32:23,420 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.42, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 89.61, Test_acc 39.33
2025-02-17 12:32:25,673 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.41, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 89.43, Test_acc 40.08
2025-02-17 12:32:27,926 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.40, Spatial_loss 1.45, Flat_loss 0.22, Train_acc 89.61, Test_acc 38.38
2025-02-17 12:32:30,247 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.41, Spatial_loss 1.45, Flat_loss 0.22, Train_acc 89.48, Test_acc 37.67
2025-02-17 12:32:32,474 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.40, Spatial_loss 1.43, Flat_loss 0.22, Train_acc 89.77, Test_acc 35.62
2025-02-17 12:32:34,693 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.39, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 90.20, Test_acc 37.10
2025-02-17 12:32:36,992 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.39, Spatial_loss 1.39, Flat_loss 0.22, Train_acc 90.46, Test_acc 35.35
2025-02-17 12:32:39,200 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.38, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 91.07, Test_acc 34.65
2025-02-17 12:32:41,447 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.37, Spatial_loss 1.41, Flat_loss 0.22, Train_acc 91.45, Test_acc 33.98
2025-02-17 12:32:43,705 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.36, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 91.96, Test_acc 35.88
2025-02-17 12:32:45,971 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.36, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 91.38, Test_acc 41.68
2025-02-17 12:32:48,222 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.37, Spatial_loss 1.42, Flat_loss 0.22, Train_acc 91.27, Test_acc 35.52
2025-02-17 12:32:50,507 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.37, Spatial_loss 1.40, Flat_loss 0.22, Train_acc 90.68, Test_acc 34.72
2025-02-17 12:32:52,726 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.34, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 91.80, Test_acc 42.82
2025-02-17 12:32:54,912 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.34, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 91.84, Test_acc 39.20
2025-02-17 12:32:57,179 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.37, Spatial_loss 1.38, Flat_loss 0.22, Train_acc 90.79, Test_acc 39.35
2025-02-17 12:32:59,418 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.33, Spatial_loss 1.38, Flat_loss 0.22, Train_acc 92.46, Test_acc 42.78
2025-02-17 12:33:01,646 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.35, Spatial_loss 1.37, Flat_loss 0.22, Train_acc 91.71, Test_acc 43.00
2025-02-17 12:33:03,956 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.35, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 91.70, Test_acc 38.60
2025-02-17 12:33:06,235 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.32, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 92.61, Test_acc 37.22
2025-02-17 12:33:08,432 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.31, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 93.02, Test_acc 41.22
2025-02-17 12:33:10,614 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.32, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 92.52, Test_acc 38.83
2025-02-17 12:33:12,837 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.32, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 92.59, Test_acc 40.78
2025-02-17 12:33:15,167 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.33, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 92.30, Test_acc 41.25
2025-02-17 12:33:17,321 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.32, Spatial_loss 1.33, Flat_loss 0.21, Train_acc 93.00, Test_acc 37.72
2025-02-17 12:33:19,511 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.32, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 92.84, Test_acc 41.05
2025-02-17 12:33:21,786 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.31, Spatial_loss 1.31, Flat_loss 0.21, Train_acc 93.04, Test_acc 41.32
2025-02-17 12:33:23,993 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.29, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 93.68, Test_acc 41.98
2025-02-17 12:33:26,273 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.27, Spatial_loss 1.30, Flat_loss 0.21, Train_acc 94.59, Test_acc 37.70
2025-02-17 12:33:28,508 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.21, Train_acc 93.88, Test_acc 39.83
2025-02-17 12:33:30,731 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.21, Train_acc 94.55, Test_acc 42.12
2025-02-17 12:33:32,976 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 94.66, Test_acc 41.52
2025-02-17 12:33:35,173 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.26, Spatial_loss 1.26, Flat_loss 0.21, Train_acc 94.91, Test_acc 39.48
2025-02-17 12:33:37,404 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.28, Spatial_loss 1.27, Flat_loss 0.20, Train_acc 94.14, Test_acc 44.08
2025-02-17 12:33:39,629 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.20, Train_acc 95.02, Test_acc 40.28
2025-02-17 12:33:41,840 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.20, Train_acc 95.02, Test_acc 42.22
2025-02-17 12:33:44,072 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.26, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 94.59, Test_acc 39.67
2025-02-17 12:33:46,288 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.20, Train_acc 94.93, Test_acc 40.67
2025-02-17 12:33:48,549 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.20, Train_acc 95.02, Test_acc 43.62
2025-02-17 12:33:50,789 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.20, Train_acc 95.57, Test_acc 40.25
2025-02-17 12:33:53,007 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.20, Train_acc 95.25, Test_acc 42.15
2025-02-17 12:33:55,307 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.20, Train_acc 95.39, Test_acc 44.48
2025-02-17 12:33:57,537 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.20, Train_acc 95.96, Test_acc 41.18
2025-02-17 12:33:59,748 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.25, Spatial_loss 1.17, Flat_loss 0.20, Train_acc 95.00, Test_acc 42.90
2025-02-17 12:34:01,949 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 96.41, Test_acc 37.90
2025-02-17 12:34:04,167 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 95.62, Test_acc 42.30
2025-02-17 12:34:06,428 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.20, Train_acc 95.91, Test_acc 40.15
2025-02-17 12:34:08,726 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 96.12, Test_acc 39.65
2025-02-17 12:34:10,962 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 96.64, Test_acc 42.88
2025-02-17 12:34:13,140 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 96.48, Test_acc 42.32
2025-02-17 12:34:15,335 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.19, Train_acc 96.32, Test_acc 40.22
2025-02-17 12:34:17,560 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.19, Train_acc 96.79, Test_acc 42.02
2025-02-17 12:34:19,779 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.19, Train_acc 96.80, Test_acc 43.15
2025-02-17 12:34:21,984 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.19, Train_acc 97.38, Test_acc 41.10
2025-02-17 12:34:24,229 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.19, Train_acc 97.18, Test_acc 42.28
2025-02-17 12:34:26,433 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.19, Train_acc 96.52, Test_acc 42.02
2025-02-17 12:34:28,670 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.19, Train_acc 96.70, Test_acc 42.32
2025-02-17 12:34:30,958 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.19, Train_acc 96.96, Test_acc 43.62
2025-02-17 12:34:33,251 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.19, Train_acc 96.89, Test_acc 41.90
2025-02-17 12:34:35,511 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 96.96, Test_acc 44.85
2025-02-17 12:34:37,798 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.18, Train_acc 97.70, Test_acc 42.12
2025-02-17 12:34:40,001 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.18, Train_acc 97.57, Test_acc 40.72
2025-02-17 12:34:42,197 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.18, Train_acc 97.71, Test_acc 44.82
2025-02-17 12:34:44,405 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.18, Train_acc 97.79, Test_acc 43.12
2025-02-17 12:34:46,655 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.18, Train_acc 98.12, Test_acc 43.58
2025-02-17 12:34:48,912 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.17, Spatial_loss 1.03, Flat_loss 0.18, Train_acc 97.71, Test_acc 41.12
2025-02-17 12:34:51,200 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.18, Train_acc 98.38, Test_acc 44.38
2025-02-17 12:34:53,457 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.18, Train_acc 97.84, Test_acc 43.82
2025-02-17 12:34:55,775 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.18, Train_acc 98.07, Test_acc 45.32
2025-02-17 12:34:58,026 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.18, Train_acc 98.27, Test_acc 42.68
2025-02-17 12:35:00,252 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.12, Test_acc 43.30
2025-02-17 12:35:02,561 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.18, Train_acc 98.16, Test_acc 44.12
2025-02-17 12:35:04,785 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.16, Test_acc 45.15
2025-02-17 12:35:07,045 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 98.11, Test_acc 43.78
2025-02-17 12:35:09,298 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 98.82, Test_acc 43.08
2025-02-17 12:35:11,600 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.17, Train_acc 98.32, Test_acc 44.10
2025-02-17 12:35:13,889 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.17, Train_acc 98.50, Test_acc 43.95
2025-02-17 12:35:16,116 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 98.29, Test_acc 44.30
2025-02-17 12:35:18,420 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.17, Train_acc 98.88, Test_acc 43.42
2025-02-17 12:35:20,623 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.17, Train_acc 98.39, Test_acc 42.90
2025-02-17 12:35:22,902 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.17, Train_acc 98.79, Test_acc 43.72
2025-02-17 12:35:25,154 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.17, Train_acc 98.71, Test_acc 43.35
2025-02-17 12:35:27,388 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.17, Train_acc 98.93, Test_acc 45.00
2025-02-17 12:35:29,672 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.17, Train_acc 98.70, Test_acc 43.98
2025-02-17 12:35:31,942 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.17, Train_acc 98.73, Test_acc 45.08
2025-02-17 12:35:34,224 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.17, Train_acc 98.80, Test_acc 44.48
2025-02-17 12:35:36,440 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.17, Train_acc 98.93, Test_acc 45.58
2025-02-17 12:35:38,735 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 98.77, Test_acc 44.62
2025-02-17 12:35:40,919 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.17, Train_acc 98.91, Test_acc 43.95
2025-02-17 12:35:43,153 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.17, Train_acc 98.98, Test_acc 44.68
2025-02-17 12:35:45,386 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 98.98, Test_acc 44.50
2025-02-17 12:35:47,588 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 99.14, Test_acc 44.75
2025-02-17 12:35:49,767 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 99.09, Test_acc 45.00
2025-02-17 12:35:52,052 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 99.00, Test_acc 44.68
2025-02-17 12:35:54,244 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.17, Train_acc 99.07, Test_acc 44.55
2025-02-17 12:35:56,528 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 98.91, Test_acc 44.82
2025-02-17 12:35:58,820 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 99.09, Test_acc 45.00
2025-02-17 12:36:01,113 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 99.05, Test_acc 45.22
2025-02-17 12:36:03,398 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 99.02, Test_acc 45.25
2025-02-17 12:36:05,587 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 99.16, Test_acc 45.42
2025-02-17 12:36:07,879 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 99.14, Test_acc 45.40
2025-02-17 12:36:10,150 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 0.83, Flat_loss 0.17, Train_acc 99.18, Test_acc 44.70
2025-02-17 12:36:12,398 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.17, Train_acc 99.32, Test_acc 44.82
2025-02-17 12:36:14,666 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 0.83, Flat_loss 0.17, Train_acc 99.23, Test_acc 45.28
2025-02-17 12:36:16,968 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 99.00, Test_acc 45.18
2025-02-17 12:36:19,285 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.13, Spatial_loss 0.83, Flat_loss 0.17, Train_acc 98.84, Test_acc 45.05
2025-02-17 12:36:21,643 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.17, Train_acc 99.23, Test_acc 45.28
2025-02-17 12:36:23,985 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.17, Train_acc 99.38, Test_acc 45.25
2025-02-17 12:36:26,321 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.13, Spatial_loss 0.83, Flat_loss 0.17, Train_acc 99.04, Test_acc 45.20
2025-02-17 12:36:28,597 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 0.82, Flat_loss 0.17, Train_acc 99.11, Test_acc 45.45
2025-02-17 12:36:28,597 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:36:28,598 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:36:46,697 [podnet.py] => The size of finetune dataset: 800
2025-02-17 12:36:47,897 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.30, Spatial_loss 1.00, Flat_loss 0.13, Train_acc 93.62, Test_acc 48.60
2025-02-17 12:36:49,012 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 98.00, Test_acc 49.72
2025-02-17 12:36:50,132 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.11, Train_acc 99.25, Test_acc 49.95
2025-02-17 12:36:51,302 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 98.38, Test_acc 48.72
2025-02-17 12:36:52,496 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.11, Train_acc 99.00, Test_acc 48.80
2025-02-17 12:36:53,676 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 99.25, Test_acc 49.22
2025-02-17 12:36:54,890 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.11, Train_acc 99.25, Test_acc 50.02
2025-02-17 12:36:56,015 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 99.12, Test_acc 49.48
2025-02-17 12:36:57,183 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.11, Train_acc 99.38, Test_acc 49.80
2025-02-17 12:36:58,331 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.38, Test_acc 49.48
2025-02-17 12:36:59,453 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.90, Flat_loss 0.10, Train_acc 99.62, Test_acc 49.92
2025-02-17 12:37:00,614 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.88, Flat_loss 0.11, Train_acc 99.50, Test_acc 49.88
2025-02-17 12:37:01,825 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.62, Test_acc 49.95
2025-02-17 12:37:03,002 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.10, Train_acc 99.50, Test_acc 49.88
2025-02-17 12:37:04,189 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.10, Train_acc 99.50, Test_acc 50.18
2025-02-17 12:37:05,344 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.10, Train_acc 99.88, Test_acc 50.05
2025-02-17 12:37:06,535 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.10, Train_acc 99.38, Test_acc 49.85
2025-02-17 12:37:07,724 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.93, Flat_loss 0.10, Train_acc 99.62, Test_acc 49.92
2025-02-17 12:37:08,944 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.10, Train_acc 99.38, Test_acc 50.05
2025-02-17 12:37:10,109 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.10, Train_acc 99.50, Test_acc 49.92
2025-02-17 12:37:10,110 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:37:29,283 [podnet.py] => Exemplar size: 800
2025-02-17 12:37:29,283 [trainer.py] => CNN: {'total': 49.92, '00-09': 61.3, '10-19': 25.9, '20-29': 43.9, '30-39': 68.6, 'old': 43.7, 'new': 68.6}
2025-02-17 12:37:29,283 [trainer.py] => NME: {'total': 50.18, '00-09': 71.9, '10-19': 25.3, '20-29': 43.9, '30-39': 59.6, 'old': 47.03, 'new': 59.6}
2025-02-17 12:37:29,283 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92]
2025-02-17 12:37:29,283 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78]
2025-02-17 12:37:29,283 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18]
2025-02-17 12:37:29,284 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35]

2025-02-17 12:37:29,284 [trainer.py] => Average Accuracy (CNN): 67.425
2025-02-17 12:37:29,284 [trainer.py] => Average Accuracy (NME): 67.2525
2025-02-17 12:37:29,284 [trainer.py] => All params: 491857
2025-02-17 12:37:29,284 [trainer.py] => Trainable params: 491857
2025-02-17 12:37:29,285 [podnet.py] => Learning on 40-50
2025-02-17 12:37:29,328 [podnet.py] => Adaptive factor: 2.23606797749979
2025-02-17 12:37:31,820 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 2.47, Spatial_loss 2.87, Flat_loss 0.99, Train_acc 55.14, Test_acc 26.66
2025-02-17 12:37:34,235 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 1.19, Spatial_loss 2.29, Flat_loss 0.47, Train_acc 69.71, Test_acc 27.78
2025-02-17 12:37:36,704 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 1.05, Spatial_loss 2.03, Flat_loss 0.33, Train_acc 72.79, Test_acc 32.48
2025-02-17 12:37:39,155 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 0.94, Spatial_loss 1.90, Flat_loss 0.29, Train_acc 75.45, Test_acc 31.68
2025-02-17 12:37:41,525 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 0.88, Spatial_loss 1.86, Flat_loss 0.26, Train_acc 76.90, Test_acc 32.78
2025-02-17 12:37:43,902 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.86, Spatial_loss 1.86, Flat_loss 0.25, Train_acc 77.53, Test_acc 37.80
2025-02-17 12:37:46,343 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.78, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 79.21, Test_acc 31.70
2025-02-17 12:37:48,771 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.77, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 80.09, Test_acc 35.64
2025-02-17 12:37:51,176 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.73, Spatial_loss 1.77, Flat_loss 0.23, Train_acc 81.17, Test_acc 35.58
2025-02-17 12:37:53,552 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.71, Spatial_loss 1.73, Flat_loss 0.23, Train_acc 81.78, Test_acc 33.82
2025-02-17 12:37:55,970 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.69, Spatial_loss 1.73, Flat_loss 0.22, Train_acc 82.19, Test_acc 31.48
2025-02-17 12:37:58,360 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.67, Spatial_loss 1.73, Flat_loss 0.23, Train_acc 82.97, Test_acc 34.80
2025-02-17 12:38:00,699 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.64, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 83.34, Test_acc 31.04
2025-02-17 12:38:03,037 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.62, Spatial_loss 1.69, Flat_loss 0.22, Train_acc 84.60, Test_acc 34.86
2025-02-17 12:38:05,409 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.63, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 83.66, Test_acc 35.02
2025-02-17 12:38:07,831 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.59, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 85.34, Test_acc 39.30
2025-02-17 12:38:10,287 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.58, Spatial_loss 1.69, Flat_loss 0.22, Train_acc 85.53, Test_acc 31.36
2025-02-17 12:38:12,805 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.59, Spatial_loss 1.72, Flat_loss 0.23, Train_acc 85.19, Test_acc 31.26
2025-02-17 12:38:15,223 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.55, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 85.93, Test_acc 36.08
2025-02-17 12:38:17,569 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.56, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 85.74, Test_acc 29.92
2025-02-17 12:38:19,935 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.53, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 87.12, Test_acc 32.08
2025-02-17 12:38:22,308 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.52, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 86.95, Test_acc 33.76
2025-02-17 12:38:24,627 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.51, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 87.17, Test_acc 36.14
2025-02-17 12:38:27,035 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.49, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 87.81, Test_acc 36.62
2025-02-17 12:38:29,413 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.49, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 87.90, Test_acc 35.96
2025-02-17 12:38:31,764 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.50, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 87.74, Test_acc 31.32
2025-02-17 12:38:34,036 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.49, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 88.09, Test_acc 37.62
2025-02-17 12:38:36,381 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.48, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 88.55, Test_acc 34.68
2025-02-17 12:38:38,758 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.48, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 87.97, Test_acc 36.96
2025-02-17 12:38:41,139 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.46, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 88.40, Test_acc 38.04
2025-02-17 12:38:43,559 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.46, Spatial_loss 1.65, Flat_loss 0.22, Train_acc 88.52, Test_acc 34.36
2025-02-17 12:38:45,835 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.45, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 88.71, Test_acc 37.50
2025-02-17 12:38:48,172 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.46, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 88.76, Test_acc 39.72
2025-02-17 12:38:50,529 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.42, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 89.97, Test_acc 36.04
2025-02-17 12:38:52,837 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.41, Spatial_loss 1.56, Flat_loss 0.22, Train_acc 90.24, Test_acc 38.72
2025-02-17 12:38:55,158 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.41, Spatial_loss 1.59, Flat_loss 0.22, Train_acc 89.74, Test_acc 35.90
2025-02-17 12:38:57,469 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 89.84, Test_acc 39.00
2025-02-17 12:38:59,750 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.44, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 88.98, Test_acc 41.62
2025-02-17 12:39:02,077 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.43, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 89.22, Test_acc 36.06
2025-02-17 12:39:04,454 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 90.45, Test_acc 35.00
2025-02-17 12:39:06,824 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.43, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 89.57, Test_acc 34.12
2025-02-17 12:39:09,190 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.39, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 90.66, Test_acc 36.52
2025-02-17 12:39:11,531 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.42, Spatial_loss 1.60, Flat_loss 0.22, Train_acc 89.71, Test_acc 33.92
2025-02-17 12:39:13,823 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.40, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 90.22, Test_acc 36.36
2025-02-17 12:39:16,164 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.37, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 91.72, Test_acc 31.90
2025-02-17 12:39:18,479 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.37, Spatial_loss 1.58, Flat_loss 0.22, Train_acc 91.59, Test_acc 32.52
2025-02-17 12:39:20,758 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.36, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 91.84, Test_acc 36.34
2025-02-17 12:39:23,061 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.37, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 91.10, Test_acc 36.12
2025-02-17 12:39:25,457 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.36, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 92.16, Test_acc 38.82
2025-02-17 12:39:27,840 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 92.53, Test_acc 40.36
2025-02-17 12:39:30,131 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 91.88, Test_acc 34.98
2025-02-17 12:39:32,540 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 92.60, Test_acc 39.58
2025-02-17 12:39:34,896 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.21, Train_acc 91.14, Test_acc 36.88
2025-02-17 12:39:37,274 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.36, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 91.43, Test_acc 35.16
2025-02-17 12:39:39,670 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.33, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 92.50, Test_acc 36.04
2025-02-17 12:39:42,011 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 93.14, Test_acc 37.98
2025-02-17 12:39:44,410 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.31, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 93.03, Test_acc 36.72
2025-02-17 12:39:46,719 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.31, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 93.09, Test_acc 39.34
2025-02-17 12:39:49,006 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 93.21, Test_acc 37.34
2025-02-17 12:39:51,344 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 93.00, Test_acc 38.04
2025-02-17 12:39:53,720 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 92.91, Test_acc 31.74
2025-02-17 12:39:56,044 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 92.62, Test_acc 37.08
2025-02-17 12:39:58,337 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.21, Train_acc 92.62, Test_acc 35.56
2025-02-17 12:40:00,658 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 92.64, Test_acc 37.18
2025-02-17 12:40:02,995 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.31, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 93.12, Test_acc 42.28
2025-02-17 12:40:05,292 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 93.72, Test_acc 32.76
2025-02-17 12:40:07,682 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.31, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 93.07, Test_acc 34.96
2025-02-17 12:40:10,020 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.28, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 93.95, Test_acc 36.04
2025-02-17 12:40:12,442 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.27, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 94.38, Test_acc 37.78
2025-02-17 12:40:14,765 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 93.79, Test_acc 32.96
2025-02-17 12:40:17,079 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.29, Spatial_loss 1.42, Flat_loss 0.21, Train_acc 93.71, Test_acc 37.80
2025-02-17 12:40:19,437 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.27, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 94.67, Test_acc 39.18
2025-02-17 12:40:21,750 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.26, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 94.88, Test_acc 39.44
2025-02-17 12:40:24,075 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.27, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 94.34, Test_acc 33.24
2025-02-17 12:40:26,408 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.27, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 94.28, Test_acc 38.76
2025-02-17 12:40:28,772 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.27, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 94.50, Test_acc 37.84
2025-02-17 12:40:31,120 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.27, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 94.59, Test_acc 38.32
2025-02-17 12:40:33,523 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.26, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 94.69, Test_acc 33.36
2025-02-17 12:40:35,880 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 94.91, Test_acc 38.66
2025-02-17 12:40:38,275 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.26, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 94.90, Test_acc 40.06
2025-02-17 12:40:40,617 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 95.57, Test_acc 38.76
2025-02-17 12:40:42,869 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.24, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 95.47, Test_acc 40.44
2025-02-17 12:40:45,221 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.23, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 95.45, Test_acc 39.06
2025-02-17 12:40:47,563 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.24, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 95.34, Test_acc 38.16
2025-02-17 12:40:49,984 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.24, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 95.43, Test_acc 39.66
2025-02-17 12:40:52,306 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.24, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 95.48, Test_acc 41.10
2025-02-17 12:40:54,654 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.25, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 95.07, Test_acc 37.40
2025-02-17 12:40:56,995 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.24, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 95.40, Test_acc 42.32
2025-02-17 12:40:59,301 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 96.12, Test_acc 39.96
2025-02-17 12:41:01,629 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 96.48, Test_acc 38.34
2025-02-17 12:41:04,042 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 96.14, Test_acc 38.96
2025-02-17 12:41:06,419 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 95.83, Test_acc 39.80
2025-02-17 12:41:08,750 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.19, Train_acc 95.64, Test_acc 41.28
2025-02-17 12:41:11,069 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.18, Train_acc 96.38, Test_acc 36.74
2025-02-17 12:41:13,422 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.21, Spatial_loss 1.21, Flat_loss 0.18, Train_acc 96.40, Test_acc 40.84
2025-02-17 12:41:15,711 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.21, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 96.69, Test_acc 38.92
2025-02-17 12:41:18,088 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 96.33, Test_acc 39.44
2025-02-17 12:41:20,414 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.21, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 96.79, Test_acc 39.04
2025-02-17 12:41:22,760 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.18, Train_acc 96.60, Test_acc 38.68
2025-02-17 12:41:25,134 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 97.17, Test_acc 39.52
2025-02-17 12:41:27,445 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 96.98, Test_acc 40.78
2025-02-17 12:41:29,806 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 97.38, Test_acc 39.26
2025-02-17 12:41:32,141 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.18, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 97.52, Test_acc 42.58
2025-02-17 12:41:34,478 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.18, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 97.36, Test_acc 43.22
2025-02-17 12:41:36,838 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.18, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 97.69, Test_acc 39.58
2025-02-17 12:41:39,207 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.17, Train_acc 97.45, Test_acc 40.96
2025-02-17 12:41:41,531 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.17, Spatial_loss 1.13, Flat_loss 0.17, Train_acc 97.74, Test_acc 42.88
2025-02-17 12:41:43,851 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.17, Spatial_loss 1.13, Flat_loss 0.17, Train_acc 97.55, Test_acc 39.44
2025-02-17 12:41:46,220 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 97.34, Test_acc 40.98
2025-02-17 12:41:48,553 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 97.74, Test_acc 38.52
2025-02-17 12:41:50,861 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.16, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 98.12, Test_acc 42.22
2025-02-17 12:41:53,209 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 97.97, Test_acc 40.48
2025-02-17 12:41:55,576 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 97.95, Test_acc 38.76
2025-02-17 12:41:57,911 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.16, Spatial_loss 1.08, Flat_loss 0.17, Train_acc 98.29, Test_acc 41.44
2025-02-17 12:42:00,179 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.17, Train_acc 98.43, Test_acc 43.38
2025-02-17 12:42:02,515 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.16, Train_acc 98.03, Test_acc 42.36
2025-02-17 12:42:04,864 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.16, Train_acc 98.24, Test_acc 43.76
2025-02-17 12:42:07,239 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.15, Spatial_loss 1.03, Flat_loss 0.16, Train_acc 98.52, Test_acc 41.60
2025-02-17 12:42:09,604 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.16, Train_acc 98.62, Test_acc 41.14
2025-02-17 12:42:11,861 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 98.24, Test_acc 40.72
2025-02-17 12:42:14,183 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 98.36, Test_acc 42.06
2025-02-17 12:42:16,517 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 98.29, Test_acc 40.88
2025-02-17 12:42:18,866 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.15, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 98.52, Test_acc 41.60
2025-02-17 12:42:21,229 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 98.43, Test_acc 42.64
2025-02-17 12:42:23,625 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 98.71, Test_acc 41.46
2025-02-17 12:42:25,902 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.14, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 98.66, Test_acc 43.26
2025-02-17 12:42:28,216 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.69, Test_acc 42.02
2025-02-17 12:42:30,620 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.74, Test_acc 43.48
2025-02-17 12:42:32,989 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.50, Test_acc 42.50
2025-02-17 12:42:35,360 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.84, Test_acc 42.70
2025-02-17 12:42:37,711 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 99.05, Test_acc 42.80
2025-02-17 12:42:40,093 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 98.71, Test_acc 43.28
2025-02-17 12:42:42,395 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.15, Train_acc 98.91, Test_acc 41.72
2025-02-17 12:42:44,727 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 98.55, Test_acc 42.32
2025-02-17 12:42:47,060 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.88, Test_acc 42.60
2025-02-17 12:42:49,390 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 99.10, Test_acc 43.14
2025-02-17 12:42:51,747 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.66, Test_acc 43.30
2025-02-17 12:42:54,116 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 98.93, Test_acc 43.24
2025-02-17 12:42:56,452 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 99.19, Test_acc 43.28
2025-02-17 12:42:58,743 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 99.00, Test_acc 42.94
2025-02-17 12:43:01,091 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 99.24, Test_acc 43.84
2025-02-17 12:43:03,446 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 99.03, Test_acc 43.34
2025-02-17 12:43:05,761 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.91, Test_acc 43.52
2025-02-17 12:43:08,064 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 99.09, Test_acc 42.92
2025-02-17 12:43:10,455 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.03, Test_acc 42.72
2025-02-17 12:43:12,773 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.33, Test_acc 43.72
2025-02-17 12:43:15,137 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.03, Test_acc 43.26
2025-02-17 12:43:17,549 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 99.17, Test_acc 43.42
2025-02-17 12:43:19,942 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.74, Test_acc 43.42
2025-02-17 12:43:22,348 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.17, Test_acc 43.42
2025-02-17 12:43:24,733 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 99.21, Test_acc 43.86
2025-02-17 12:43:27,064 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.38, Test_acc 43.50
2025-02-17 12:43:29,480 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 99.24, Test_acc 43.72
2025-02-17 12:43:31,906 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 98.98, Test_acc 43.38
2025-02-17 12:43:34,264 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 99.22, Test_acc 43.48
2025-02-17 12:43:36,671 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 99.31, Test_acc 43.74
2025-02-17 12:43:39,082 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.15, Train_acc 99.16, Test_acc 43.54
2025-02-17 12:43:41,519 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 99.09, Test_acc 43.76
2025-02-17 12:43:43,951 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.15, Train_acc 99.31, Test_acc 43.66
2025-02-17 12:43:46,385 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 0.82, Flat_loss 0.15, Train_acc 99.34, Test_acc 43.38
2025-02-17 12:43:46,386 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:43:46,387 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:44:07,645 [podnet.py] => The size of finetune dataset: 1000
2025-02-17 12:44:08,920 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.27, Spatial_loss 0.93, Flat_loss 0.12, Train_acc 95.80, Test_acc 45.48
2025-02-17 12:44:10,197 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.20, Test_acc 46.82
2025-02-17 12:44:11,446 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.10, Test_acc 47.40
2025-02-17 12:44:12,747 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 99.30, Test_acc 46.38
2025-02-17 12:44:13,974 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 99.40, Test_acc 46.38
2025-02-17 12:44:15,250 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.09, Train_acc 99.20, Test_acc 46.50
2025-02-17 12:44:16,526 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.60, Test_acc 46.12
2025-02-17 12:44:17,787 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 99.50, Test_acc 46.78
2025-02-17 12:44:19,017 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.40, Test_acc 46.76
2025-02-17 12:44:20,295 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 99.70, Test_acc 46.82
2025-02-17 12:44:21,549 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 0.83, Flat_loss 0.09, Train_acc 99.60, Test_acc 46.94
2025-02-17 12:44:22,785 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.09, Train_acc 99.40, Test_acc 47.26
2025-02-17 12:44:24,054 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.09, Train_acc 99.70, Test_acc 47.00
2025-02-17 12:44:25,365 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 99.50, Test_acc 47.10
2025-02-17 12:44:26,639 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 99.90, Test_acc 47.24
2025-02-17 12:44:27,891 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.09, Train_acc 99.40, Test_acc 47.12
2025-02-17 12:44:29,130 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.60, Test_acc 47.32
2025-02-17 12:44:30,334 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.09, Train_acc 99.70, Test_acc 47.32
2025-02-17 12:44:31,570 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 99.60, Test_acc 47.26
2025-02-17 12:44:32,833 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.40, Test_acc 47.20
2025-02-17 12:44:32,835 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:44:55,329 [podnet.py] => Exemplar size: 1000
2025-02-17 12:44:55,329 [trainer.py] => CNN: {'total': 47.2, '00-09': 57.6, '10-19': 20.1, '20-29': 38.7, '30-39': 41.0, '40-49': 78.6, 'old': 39.35, 'new': 78.6}
2025-02-17 12:44:55,329 [trainer.py] => NME: {'total': 47.42, '00-09': 68.8, '10-19': 18.7, '20-29': 39.9, '30-39': 38.9, '40-49': 70.8, 'old': 41.58, 'new': 70.8}
2025-02-17 12:44:55,329 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2]
2025-02-17 12:44:55,329 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22]
2025-02-17 12:44:55,329 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42]
2025-02-17 12:44:55,329 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78]

2025-02-17 12:44:55,329 [trainer.py] => Average Accuracy (CNN): 63.379999999999995
2025-02-17 12:44:55,329 [trainer.py] => Average Accuracy (NME): 63.286
2025-02-17 12:44:55,330 [trainer.py] => All params: 498257
2025-02-17 12:44:55,330 [trainer.py] => Trainable params: 498257
2025-02-17 12:44:55,331 [podnet.py] => Learning on 50-60
2025-02-17 12:44:55,378 [podnet.py] => Adaptive factor: 2.449489742783178
2025-02-17 12:44:57,871 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 2.82, Spatial_loss 3.05, Flat_loss 1.07, Train_acc 42.40, Test_acc 19.17
2025-02-17 12:45:00,361 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 1.59, Spatial_loss 2.43, Flat_loss 0.56, Train_acc 56.43, Test_acc 24.13
2025-02-17 12:45:02,853 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 1.36, Spatial_loss 2.18, Flat_loss 0.41, Train_acc 62.45, Test_acc 26.27
2025-02-17 12:45:05,345 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 1.28, Spatial_loss 2.14, Flat_loss 0.35, Train_acc 64.63, Test_acc 31.20
2025-02-17 12:45:07,826 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 1.16, Spatial_loss 1.94, Flat_loss 0.31, Train_acc 67.48, Test_acc 34.00
2025-02-17 12:45:10,288 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 1.11, Spatial_loss 1.97, Flat_loss 0.29, Train_acc 68.78, Test_acc 31.25
2025-02-17 12:45:12,746 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 1.06, Spatial_loss 1.92, Flat_loss 0.28, Train_acc 69.97, Test_acc 25.05
2025-02-17 12:45:15,273 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 1.03, Spatial_loss 1.90, Flat_loss 0.27, Train_acc 71.98, Test_acc 29.03
2025-02-17 12:45:17,790 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 0.99, Spatial_loss 1.90, Flat_loss 0.27, Train_acc 73.30, Test_acc 29.72
2025-02-17 12:45:20,316 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 0.94, Spatial_loss 1.83, Flat_loss 0.26, Train_acc 74.67, Test_acc 24.97
2025-02-17 12:45:22,750 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 0.92, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 74.93, Test_acc 30.37
2025-02-17 12:45:25,208 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.90, Spatial_loss 1.81, Flat_loss 0.26, Train_acc 75.47, Test_acc 31.67
2025-02-17 12:45:27,667 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.88, Spatial_loss 1.88, Flat_loss 0.27, Train_acc 76.20, Test_acc 34.13
2025-02-17 12:45:30,210 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.85, Spatial_loss 1.81, Flat_loss 0.26, Train_acc 78.02, Test_acc 31.12
2025-02-17 12:45:32,693 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.83, Spatial_loss 1.78, Flat_loss 0.27, Train_acc 77.35, Test_acc 36.57
2025-02-17 12:45:35,194 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.80, Spatial_loss 1.80, Flat_loss 0.26, Train_acc 78.58, Test_acc 33.32
2025-02-17 12:45:37,687 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.77, Spatial_loss 1.83, Flat_loss 0.26, Train_acc 79.22, Test_acc 30.80
2025-02-17 12:45:40,183 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.79, Spatial_loss 1.82, Flat_loss 0.27, Train_acc 79.33, Test_acc 33.90
2025-02-17 12:45:42,654 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.78, Spatial_loss 1.82, Flat_loss 0.27, Train_acc 79.08, Test_acc 34.48
2025-02-17 12:45:45,097 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.73, Spatial_loss 1.75, Flat_loss 0.26, Train_acc 80.48, Test_acc 33.70
2025-02-17 12:45:47,546 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.75, Spatial_loss 1.78, Flat_loss 0.26, Train_acc 79.93, Test_acc 30.05
2025-02-17 12:45:50,032 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.69, Spatial_loss 1.73, Flat_loss 0.25, Train_acc 81.97, Test_acc 33.35
2025-02-17 12:45:52,498 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.71, Spatial_loss 1.80, Flat_loss 0.27, Train_acc 81.03, Test_acc 29.97
2025-02-17 12:45:54,980 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.70, Spatial_loss 1.78, Flat_loss 0.26, Train_acc 81.60, Test_acc 34.38
2025-02-17 12:45:57,430 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.67, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 82.23, Test_acc 33.62
2025-02-17 12:45:59,859 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.67, Spatial_loss 1.77, Flat_loss 0.26, Train_acc 81.63, Test_acc 36.05
2025-02-17 12:46:02,242 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.65, Spatial_loss 1.73, Flat_loss 0.26, Train_acc 82.88, Test_acc 34.22
2025-02-17 12:46:04,673 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.64, Spatial_loss 1.73, Flat_loss 0.26, Train_acc 82.87, Test_acc 33.63
2025-02-17 12:46:07,129 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.63, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 83.63, Test_acc 35.05
2025-02-17 12:46:09,543 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.63, Spatial_loss 1.74, Flat_loss 0.26, Train_acc 83.82, Test_acc 30.50
2025-02-17 12:46:11,976 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.62, Spatial_loss 1.72, Flat_loss 0.26, Train_acc 84.07, Test_acc 28.12
2025-02-17 12:46:14,388 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.61, Spatial_loss 1.72, Flat_loss 0.26, Train_acc 84.52, Test_acc 34.53
2025-02-17 12:46:16,792 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.61, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 84.75, Test_acc 31.97
2025-02-17 12:46:19,258 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.59, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 85.03, Test_acc 32.58
2025-02-17 12:46:21,746 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.58, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 85.32, Test_acc 31.75
2025-02-17 12:46:24,247 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.60, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 84.47, Test_acc 33.47
2025-02-17 12:46:26,638 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.58, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 85.55, Test_acc 33.57
2025-02-17 12:46:29,066 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.56, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 85.60, Test_acc 35.53
2025-02-17 12:46:31,464 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.54, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 86.45, Test_acc 36.67
2025-02-17 12:46:33,874 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.57, Spatial_loss 1.69, Flat_loss 0.26, Train_acc 85.15, Test_acc 32.00
2025-02-17 12:46:36,287 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.53, Spatial_loss 1.68, Flat_loss 0.26, Train_acc 86.58, Test_acc 32.85
2025-02-17 12:46:38,698 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.54, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 86.43, Test_acc 32.83
2025-02-17 12:46:41,093 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.52, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 87.02, Test_acc 30.50
2025-02-17 12:46:43,561 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.51, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 87.37, Test_acc 30.90
2025-02-17 12:46:45,989 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.52, Spatial_loss 1.72, Flat_loss 0.26, Train_acc 87.08, Test_acc 35.22
2025-02-17 12:46:48,368 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.52, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 87.20, Test_acc 32.47
2025-02-17 12:46:50,845 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.50, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 87.53, Test_acc 31.70
2025-02-17 12:46:53,225 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.52, Spatial_loss 1.69, Flat_loss 0.27, Train_acc 86.82, Test_acc 35.32
2025-02-17 12:46:55,607 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.51, Spatial_loss 1.71, Flat_loss 0.26, Train_acc 87.68, Test_acc 34.63
2025-02-17 12:46:58,005 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.49, Spatial_loss 1.69, Flat_loss 0.26, Train_acc 88.28, Test_acc 33.98
2025-02-17 12:47:00,377 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.46, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 89.07, Test_acc 32.33
2025-02-17 12:47:02,788 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.47, Spatial_loss 1.59, Flat_loss 0.25, Train_acc 88.65, Test_acc 34.02
2025-02-17 12:47:05,179 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.48, Spatial_loss 1.63, Flat_loss 0.25, Train_acc 88.33, Test_acc 30.55
2025-02-17 12:47:07,599 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.48, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 88.45, Test_acc 31.50
2025-02-17 12:47:09,973 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.44, Spatial_loss 1.63, Flat_loss 0.26, Train_acc 89.23, Test_acc 34.67
2025-02-17 12:47:12,338 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.48, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 88.13, Test_acc 33.68
2025-02-17 12:47:14,750 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.46, Spatial_loss 1.59, Flat_loss 0.25, Train_acc 89.03, Test_acc 33.03
2025-02-17 12:47:17,202 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.45, Spatial_loss 1.62, Flat_loss 0.25, Train_acc 89.57, Test_acc 33.12
2025-02-17 12:47:19,646 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.41, Spatial_loss 1.59, Flat_loss 0.25, Train_acc 90.28, Test_acc 33.38
2025-02-17 12:47:22,088 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.45, Spatial_loss 1.59, Flat_loss 0.25, Train_acc 88.78, Test_acc 36.13
2025-02-17 12:47:24,446 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.25, Train_acc 90.77, Test_acc 36.53
2025-02-17 12:47:26,855 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.42, Spatial_loss 1.55, Flat_loss 0.25, Train_acc 90.43, Test_acc 33.37
2025-02-17 12:47:29,250 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.42, Spatial_loss 1.54, Flat_loss 0.25, Train_acc 90.02, Test_acc 35.30
2025-02-17 12:47:31,696 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.39, Spatial_loss 1.53, Flat_loss 0.25, Train_acc 90.97, Test_acc 33.70
2025-02-17 12:47:34,103 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.40, Spatial_loss 1.53, Flat_loss 0.25, Train_acc 90.53, Test_acc 35.65
2025-02-17 12:47:36,574 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.39, Spatial_loss 1.55, Flat_loss 0.25, Train_acc 91.18, Test_acc 35.85
2025-02-17 12:47:38,959 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.40, Spatial_loss 1.54, Flat_loss 0.25, Train_acc 90.48, Test_acc 32.23
2025-02-17 12:47:41,362 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.40, Spatial_loss 1.56, Flat_loss 0.25, Train_acc 91.20, Test_acc 33.65
2025-02-17 12:47:43,803 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.41, Spatial_loss 1.57, Flat_loss 0.25, Train_acc 90.63, Test_acc 35.80
2025-02-17 12:47:46,245 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.41, Spatial_loss 1.53, Flat_loss 0.25, Train_acc 90.33, Test_acc 35.13
2025-02-17 12:47:48,710 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.38, Spatial_loss 1.49, Flat_loss 0.24, Train_acc 92.02, Test_acc 35.13
2025-02-17 12:47:51,163 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.39, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 90.60, Test_acc 28.60
2025-02-17 12:47:53,550 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.24, Train_acc 91.78, Test_acc 37.53
2025-02-17 12:47:56,039 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.35, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 92.37, Test_acc 36.37
2025-02-17 12:47:58,436 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 92.20, Test_acc 34.18
2025-02-17 12:48:00,840 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 93.13, Test_acc 36.12
2025-02-17 12:48:03,275 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.47, Flat_loss 0.24, Train_acc 91.80, Test_acc 36.40
2025-02-17 12:48:05,697 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.34, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 92.65, Test_acc 34.68
2025-02-17 12:48:08,075 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.35, Spatial_loss 1.48, Flat_loss 0.24, Train_acc 92.48, Test_acc 34.95
2025-02-17 12:48:10,588 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.34, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 92.82, Test_acc 34.83
2025-02-17 12:48:12,979 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.24, Train_acc 92.67, Test_acc 36.88
2025-02-17 12:48:15,413 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 92.62, Test_acc 38.22
2025-02-17 12:48:17,850 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.24, Train_acc 93.33, Test_acc 35.83
2025-02-17 12:48:20,214 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.33, Spatial_loss 1.39, Flat_loss 0.23, Train_acc 92.82, Test_acc 35.12
2025-02-17 12:48:22,620 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.31, Spatial_loss 1.39, Flat_loss 0.24, Train_acc 93.77, Test_acc 36.05
2025-02-17 12:48:25,011 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.24, Train_acc 92.77, Test_acc 36.80
2025-02-17 12:48:27,462 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.31, Spatial_loss 1.40, Flat_loss 0.23, Train_acc 94.18, Test_acc 31.67
2025-02-17 12:48:29,857 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.29, Spatial_loss 1.39, Flat_loss 0.23, Train_acc 94.30, Test_acc 33.08
2025-02-17 12:48:32,286 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 94.25, Test_acc 32.82
2025-02-17 12:48:34,636 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.31, Spatial_loss 1.41, Flat_loss 0.23, Train_acc 93.88, Test_acc 37.37
2025-02-17 12:48:37,049 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 94.15, Test_acc 38.02
2025-02-17 12:48:39,513 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.29, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 94.47, Test_acc 36.40
2025-02-17 12:48:41,951 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 94.53, Test_acc 36.70
2025-02-17 12:48:44,343 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.29, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 94.12, Test_acc 32.55
2025-02-17 12:48:46,709 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 94.98, Test_acc 33.35
2025-02-17 12:48:49,220 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.23, Train_acc 95.42, Test_acc 37.53
2025-02-17 12:48:51,678 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.22, Train_acc 95.65, Test_acc 36.38
2025-02-17 12:48:54,079 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.22, Train_acc 95.30, Test_acc 35.37
2025-02-17 12:48:56,501 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.22, Train_acc 95.47, Test_acc 36.55
2025-02-17 12:48:58,896 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.25, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 95.58, Test_acc 35.15
2025-02-17 12:49:01,370 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.22, Train_acc 96.15, Test_acc 37.17
2025-02-17 12:49:03,817 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.22, Train_acc 95.32, Test_acc 34.75
2025-02-17 12:49:06,245 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.22, Test_acc 37.12
2025-02-17 12:49:08,644 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.53, Test_acc 36.85
2025-02-17 12:49:11,079 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 1.27, Flat_loss 0.22, Train_acc 96.55, Test_acc 36.88
2025-02-17 12:49:13,512 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 96.33, Test_acc 36.18
2025-02-17 12:49:15,906 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.22, Train_acc 96.13, Test_acc 37.70
2025-02-17 12:49:18,319 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.21, Train_acc 96.32, Test_acc 35.42
2025-02-17 12:49:20,719 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.13, Test_acc 41.05
2025-02-17 12:49:23,130 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.47, Test_acc 38.25
2025-02-17 12:49:25,556 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.21, Train_acc 97.17, Test_acc 37.78
2025-02-17 12:49:27,985 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.21, Train_acc 97.27, Test_acc 38.83
2025-02-17 12:49:30,382 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.21, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 96.95, Test_acc 40.32
2025-02-17 12:49:32,754 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.21, Train_acc 97.00, Test_acc 36.15
2025-02-17 12:49:35,193 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.21, Train_acc 96.93, Test_acc 37.98
2025-02-17 12:49:37,633 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.21, Train_acc 97.30, Test_acc 38.80
2025-02-17 12:49:40,075 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.21, Train_acc 97.22, Test_acc 35.40
2025-02-17 12:49:42,477 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 97.38, Test_acc 37.88
2025-02-17 12:49:44,857 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 97.48, Test_acc 38.17
2025-02-17 12:49:47,305 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.20, Train_acc 97.47, Test_acc 37.20
2025-02-17 12:49:49,715 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 98.03, Test_acc 38.48
2025-02-17 12:49:52,120 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.20, Train_acc 97.83, Test_acc 38.10
2025-02-17 12:49:54,493 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 97.65, Test_acc 37.87
2025-02-17 12:49:56,907 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 97.97, Test_acc 40.02
2025-02-17 12:49:59,292 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 97.70, Test_acc 39.82
2025-02-17 12:50:01,692 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 97.65, Test_acc 38.48
2025-02-17 12:50:04,100 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.23, Test_acc 39.88
2025-02-17 12:50:06,609 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.22, Test_acc 38.52
2025-02-17 12:50:09,046 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.20, Train_acc 97.98, Test_acc 40.22
2025-02-17 12:50:11,370 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.20, Train_acc 98.15, Test_acc 36.83
2025-02-17 12:50:13,810 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.13, Test_acc 40.32
2025-02-17 12:50:16,268 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.62, Test_acc 38.92
2025-02-17 12:50:18,621 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.19, Train_acc 98.18, Test_acc 38.35
2025-02-17 12:50:21,009 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.33, Test_acc 39.58
2025-02-17 12:50:23,436 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.33, Test_acc 39.62
2025-02-17 12:50:25,869 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.48, Test_acc 39.77
2025-02-17 12:50:28,267 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.52, Test_acc 39.63
2025-02-17 12:50:30,698 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.53, Test_acc 40.18
2025-02-17 12:50:33,170 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.83, Test_acc 38.85
2025-02-17 12:50:35,588 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.73, Test_acc 40.13
2025-02-17 12:50:37,972 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.73, Test_acc 39.43
2025-02-17 12:50:40,426 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.67, Test_acc 39.37
2025-02-17 12:50:42,862 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 98.62, Test_acc 39.12
2025-02-17 12:50:45,295 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.82, Test_acc 39.82
2025-02-17 12:50:47,672 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.88, Test_acc 39.87
2025-02-17 12:50:50,120 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.85, Test_acc 39.23
2025-02-17 12:50:52,584 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.72, Test_acc 39.63
2025-02-17 12:50:54,987 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.62, Test_acc 39.80
2025-02-17 12:50:57,328 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.83, Test_acc 39.72
2025-02-17 12:50:59,776 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.68, Test_acc 39.63
2025-02-17 12:51:02,239 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.92, Test_acc 39.77
2025-02-17 12:51:04,684 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 98.83, Test_acc 39.57
2025-02-17 12:51:07,137 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.97, Test_acc 39.73
2025-02-17 12:51:09,575 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 99.07, Test_acc 40.07
2025-02-17 12:51:11,973 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 98.73, Test_acc 39.95
2025-02-17 12:51:14,421 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 98.67, Test_acc 39.97
2025-02-17 12:51:16,874 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 99.02, Test_acc 39.77
2025-02-17 12:51:19,366 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.73, Test_acc 39.97
2025-02-17 12:51:21,861 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.18, Train_acc 98.82, Test_acc 39.88
2025-02-17 12:51:24,400 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 98.85, Test_acc 39.95
2025-02-17 12:51:24,400 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:51:24,400 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:51:48,953 [podnet.py] => The size of finetune dataset: 1200
2025-02-17 12:51:50,363 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.29, Spatial_loss 1.04, Flat_loss 0.14, Train_acc 95.42, Test_acc 43.30
2025-02-17 12:51:51,607 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.18, Spatial_loss 0.97, Flat_loss 0.12, Train_acc 99.00, Test_acc 44.30
2025-02-17 12:51:52,927 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.12, Train_acc 98.42, Test_acc 43.08
2025-02-17 12:51:54,283 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 99.25, Test_acc 42.42
2025-02-17 12:51:55,633 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 99.25, Test_acc 43.28
2025-02-17 12:51:56,984 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 98.75, Test_acc 43.63
2025-02-17 12:51:58,323 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 99.67, Test_acc 43.63
2025-02-17 12:51:59,639 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.11, Train_acc 99.17, Test_acc 43.47
2025-02-17 12:52:00,973 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 99.58, Test_acc 43.05
2025-02-17 12:52:02,317 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.11, Train_acc 99.50, Test_acc 43.58
2025-02-17 12:52:03,739 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.11, Train_acc 99.58, Test_acc 43.83
2025-02-17 12:52:05,110 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 99.42, Test_acc 43.97
2025-02-17 12:52:06,494 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.11, Train_acc 99.08, Test_acc 43.80
2025-02-17 12:52:07,840 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.92, Test_acc 44.03
2025-02-17 12:52:09,172 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 99.50, Test_acc 43.83
2025-02-17 12:52:10,523 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 99.58, Test_acc 43.83
2025-02-17 12:52:11,900 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.25, Test_acc 43.75
2025-02-17 12:52:13,263 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.17, Test_acc 43.75
2025-02-17 12:52:14,663 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.83, Test_acc 43.98
2025-02-17 12:52:16,058 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.93, Flat_loss 0.10, Train_acc 99.58, Test_acc 43.93
2025-02-17 12:52:16,059 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:52:42,183 [podnet.py] => Exemplar size: 1200
2025-02-17 12:52:42,183 [trainer.py] => CNN: {'total': 43.93, '00-09': 53.9, '10-19': 19.4, '20-29': 34.4, '30-39': 33.8, '40-49': 54.5, '50-59': 67.6, 'old': 39.2, 'new': 67.6}
2025-02-17 12:52:42,183 [trainer.py] => NME: {'total': 43.8, '00-09': 66.5, '10-19': 17.3, '20-29': 34.4, '30-39': 32.2, '40-49': 51.4, '50-59': 61.0, 'old': 40.36, 'new': 61.0}
2025-02-17 12:52:42,183 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2, 43.93]
2025-02-17 12:52:42,184 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22, 74.43]
2025-02-17 12:52:42,184 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42, 43.8]
2025-02-17 12:52:42,184 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78, 73.92]

2025-02-17 12:52:42,184 [trainer.py] => Average Accuracy (CNN): 60.13833333333333
2025-02-17 12:52:42,184 [trainer.py] => Average Accuracy (NME): 60.038333333333334
2025-02-17 12:52:42,184 [trainer.py] => All params: 504657
2025-02-17 12:52:42,184 [trainer.py] => Trainable params: 504657
2025-02-17 12:52:42,185 [podnet.py] => Learning on 60-70
2025-02-17 12:52:42,234 [podnet.py] => Adaptive factor: 2.6457513110645907
2025-02-17 12:52:44,865 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 2.76, Spatial_loss 2.91, Flat_loss 1.05, Train_acc 47.98, Test_acc 25.10
2025-02-17 12:52:47,463 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 1.45, Spatial_loss 2.30, Flat_loss 0.51, Train_acc 62.37, Test_acc 29.41
2025-02-17 12:52:50,088 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 1.27, Spatial_loss 2.17, Flat_loss 0.39, Train_acc 66.66, Test_acc 32.14
2025-02-17 12:52:52,702 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 1.13, Spatial_loss 2.09, Flat_loss 0.34, Train_acc 70.10, Test_acc 32.30
2025-02-17 12:52:55,329 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 1.07, Spatial_loss 2.01, Flat_loss 0.31, Train_acc 71.48, Test_acc 31.07
2025-02-17 12:52:58,013 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 1.00, Spatial_loss 1.94, Flat_loss 0.30, Train_acc 73.31, Test_acc 30.06
2025-02-17 12:53:00,559 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 0.98, Spatial_loss 1.98, Flat_loss 0.30, Train_acc 74.31, Test_acc 29.71
2025-02-17 12:53:03,168 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 0.95, Spatial_loss 1.97, Flat_loss 0.29, Train_acc 75.39, Test_acc 24.90
2025-02-17 12:53:05,773 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 0.91, Spatial_loss 1.92, Flat_loss 0.29, Train_acc 76.39, Test_acc 25.46
2025-02-17 12:53:08,332 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.90, Spatial_loss 1.93, Flat_loss 0.29, Train_acc 76.61, Test_acc 29.89
2025-02-17 12:53:10,874 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.83, Spatial_loss 1.88, Flat_loss 0.28, Train_acc 79.13, Test_acc 30.33
2025-02-17 12:53:13,433 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.85, Spatial_loss 1.91, Flat_loss 0.28, Train_acc 78.16, Test_acc 28.94
2025-02-17 12:53:16,060 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.82, Spatial_loss 1.90, Flat_loss 0.28, Train_acc 78.68, Test_acc 33.79
2025-02-17 12:53:18,707 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.79, Spatial_loss 1.88, Flat_loss 0.27, Train_acc 80.08, Test_acc 31.43
2025-02-17 12:53:21,313 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.79, Spatial_loss 1.89, Flat_loss 0.28, Train_acc 79.94, Test_acc 30.67
2025-02-17 12:53:23,938 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.75, Spatial_loss 1.88, Flat_loss 0.28, Train_acc 81.11, Test_acc 31.40
2025-02-17 12:53:26,499 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.74, Spatial_loss 1.80, Flat_loss 0.27, Train_acc 81.39, Test_acc 33.29
2025-02-17 12:53:28,993 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.72, Spatial_loss 1.84, Flat_loss 0.28, Train_acc 81.92, Test_acc 30.26
2025-02-17 12:53:31,508 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.70, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 82.26, Test_acc 30.23
2025-02-17 12:53:33,980 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.72, Spatial_loss 1.84, Flat_loss 0.28, Train_acc 81.31, Test_acc 33.16
2025-02-17 12:53:36,504 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.68, Spatial_loss 1.81, Flat_loss 0.28, Train_acc 83.23, Test_acc 29.83
2025-02-17 12:53:39,090 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.69, Spatial_loss 1.84, Flat_loss 0.28, Train_acc 82.53, Test_acc 28.31
2025-02-17 12:53:41,615 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.71, Spatial_loss 1.85, Flat_loss 0.28, Train_acc 81.48, Test_acc 29.56
2025-02-17 12:53:44,203 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.65, Spatial_loss 1.82, Flat_loss 0.27, Train_acc 83.61, Test_acc 33.46
2025-02-17 12:53:46,781 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.64, Spatial_loss 1.83, Flat_loss 0.27, Train_acc 84.34, Test_acc 31.63
2025-02-17 12:53:49,306 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.66, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 83.55, Test_acc 32.56
2025-02-17 12:53:51,812 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.62, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 84.58, Test_acc 31.70
2025-02-17 12:53:54,313 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.65, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 83.13, Test_acc 32.63
2025-02-17 12:53:56,832 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.59, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 86.05, Test_acc 33.10
2025-02-17 12:53:59,315 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.57, Spatial_loss 1.72, Flat_loss 0.27, Train_acc 86.10, Test_acc 25.86
2025-02-17 12:54:01,816 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.60, Spatial_loss 1.78, Flat_loss 0.27, Train_acc 84.95, Test_acc 30.04
2025-02-17 12:54:04,329 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.59, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 85.08, Test_acc 31.77
2025-02-17 12:54:06,876 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.58, Spatial_loss 1.76, Flat_loss 0.28, Train_acc 85.21, Test_acc 31.37
2025-02-17 12:54:09,368 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.60, Spatial_loss 1.82, Flat_loss 0.28, Train_acc 85.26, Test_acc 27.87
2025-02-17 12:54:11,902 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.55, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 86.47, Test_acc 31.31
2025-02-17 12:54:14,440 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.55, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 86.37, Test_acc 31.37
2025-02-17 12:54:16,925 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.54, Spatial_loss 1.69, Flat_loss 0.27, Train_acc 86.84, Test_acc 32.69
2025-02-17 12:54:19,493 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.52, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 87.31, Test_acc 32.13
2025-02-17 12:54:22,027 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.55, Spatial_loss 1.78, Flat_loss 0.27, Train_acc 86.77, Test_acc 32.50
2025-02-17 12:54:24,620 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.57, Spatial_loss 1.76, Flat_loss 0.28, Train_acc 85.56, Test_acc 32.59
2025-02-17 12:54:27,128 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.52, Spatial_loss 1.71, Flat_loss 0.27, Train_acc 87.65, Test_acc 32.73
2025-02-17 12:54:29,643 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.51, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 87.71, Test_acc 35.13
2025-02-17 12:54:32,204 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.51, Spatial_loss 1.70, Flat_loss 0.27, Train_acc 87.48, Test_acc 35.44
2025-02-17 12:54:34,806 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.50, Spatial_loss 1.69, Flat_loss 0.27, Train_acc 88.15, Test_acc 33.84
2025-02-17 12:54:37,307 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.52, Spatial_loss 1.71, Flat_loss 0.27, Train_acc 86.89, Test_acc 32.57
2025-02-17 12:54:39,861 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.51, Spatial_loss 1.72, Flat_loss 0.28, Train_acc 87.68, Test_acc 34.07
2025-02-17 12:54:42,417 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.51, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 87.82, Test_acc 33.09
2025-02-17 12:54:44,955 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.49, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 88.37, Test_acc 33.01
2025-02-17 12:54:47,437 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.46, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 89.69, Test_acc 31.16
2025-02-17 12:54:49,929 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.49, Spatial_loss 1.66, Flat_loss 0.27, Train_acc 88.60, Test_acc 30.69
2025-02-17 12:54:52,439 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.26, Train_acc 89.87, Test_acc 32.59
2025-02-17 12:54:54,961 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.47, Spatial_loss 1.67, Flat_loss 0.27, Train_acc 88.85, Test_acc 35.03
2025-02-17 12:54:57,433 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.45, Spatial_loss 1.61, Flat_loss 0.26, Train_acc 89.19, Test_acc 32.56
2025-02-17 12:54:59,983 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.47, Spatial_loss 1.67, Flat_loss 0.27, Train_acc 88.53, Test_acc 31.69
2025-02-17 12:55:02,480 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.45, Spatial_loss 1.65, Flat_loss 0.27, Train_acc 89.74, Test_acc 35.43
2025-02-17 12:55:04,979 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.47, Spatial_loss 1.61, Flat_loss 0.26, Train_acc 88.81, Test_acc 31.24
2025-02-17 12:55:07,539 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.44, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 89.81, Test_acc 32.67
2025-02-17 12:55:10,057 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.42, Spatial_loss 1.66, Flat_loss 0.27, Train_acc 90.53, Test_acc 32.16
2025-02-17 12:55:12,680 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.42, Spatial_loss 1.62, Flat_loss 0.26, Train_acc 90.27, Test_acc 27.93
2025-02-17 12:55:15,226 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.43, Spatial_loss 1.63, Flat_loss 0.27, Train_acc 90.10, Test_acc 30.74
2025-02-17 12:55:17,807 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.44, Spatial_loss 1.61, Flat_loss 0.27, Train_acc 89.71, Test_acc 33.44
2025-02-17 12:55:20,361 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.43, Spatial_loss 1.64, Flat_loss 0.27, Train_acc 89.94, Test_acc 31.21
2025-02-17 12:55:22,913 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.42, Spatial_loss 1.64, Flat_loss 0.27, Train_acc 90.56, Test_acc 30.39
2025-02-17 12:55:25,382 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.42, Spatial_loss 1.62, Flat_loss 0.26, Train_acc 90.48, Test_acc 32.20
2025-02-17 12:55:27,928 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.41, Spatial_loss 1.67, Flat_loss 0.26, Train_acc 90.21, Test_acc 34.53
2025-02-17 12:55:30,452 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.40, Spatial_loss 1.57, Flat_loss 0.26, Train_acc 90.90, Test_acc 29.10
2025-02-17 12:55:32,960 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.40, Spatial_loss 1.57, Flat_loss 0.26, Train_acc 90.98, Test_acc 28.83
2025-02-17 12:55:35,494 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.39, Spatial_loss 1.61, Flat_loss 0.26, Train_acc 91.19, Test_acc 30.76
2025-02-17 12:55:38,025 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.38, Spatial_loss 1.55, Flat_loss 0.26, Train_acc 91.60, Test_acc 34.60
2025-02-17 12:55:40,563 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.40, Spatial_loss 1.54, Flat_loss 0.26, Train_acc 90.98, Test_acc 33.70
2025-02-17 12:55:43,060 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.40, Spatial_loss 1.56, Flat_loss 0.26, Train_acc 91.21, Test_acc 33.59
2025-02-17 12:55:45,587 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.37, Spatial_loss 1.53, Flat_loss 0.26, Train_acc 91.81, Test_acc 33.30
2025-02-17 12:55:48,143 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.36, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 92.39, Test_acc 34.44
2025-02-17 12:55:50,639 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.36, Spatial_loss 1.58, Flat_loss 0.26, Train_acc 92.45, Test_acc 35.17
2025-02-17 12:55:53,196 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 92.98, Test_acc 36.54
2025-02-17 12:55:55,783 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.36, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 92.37, Test_acc 35.46
2025-02-17 12:55:58,251 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.50, Flat_loss 0.25, Train_acc 91.95, Test_acc 32.87
2025-02-17 12:56:00,699 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.25, Train_acc 92.77, Test_acc 35.20
2025-02-17 12:56:03,199 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.35, Spatial_loss 1.53, Flat_loss 0.26, Train_acc 92.15, Test_acc 32.61
2025-02-17 12:56:05,710 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.36, Spatial_loss 1.54, Flat_loss 0.26, Train_acc 92.34, Test_acc 34.01
2025-02-17 12:56:08,276 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.36, Spatial_loss 1.51, Flat_loss 0.25, Train_acc 91.98, Test_acc 34.39
2025-02-17 12:56:10,763 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.24, Train_acc 93.63, Test_acc 33.93
2025-02-17 12:56:13,309 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.25, Train_acc 93.08, Test_acc 33.26
2025-02-17 12:56:15,885 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.24, Train_acc 93.08, Test_acc 33.73
2025-02-17 12:56:18,395 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.31, Spatial_loss 1.47, Flat_loss 0.24, Train_acc 93.81, Test_acc 37.54
2025-02-17 12:56:20,871 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.24, Train_acc 94.63, Test_acc 35.56
2025-02-17 12:56:23,376 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.32, Spatial_loss 1.41, Flat_loss 0.24, Train_acc 93.60, Test_acc 35.59
2025-02-17 12:56:25,938 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.24, Train_acc 94.00, Test_acc 32.63
2025-02-17 12:56:28,495 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.29, Spatial_loss 1.39, Flat_loss 0.23, Train_acc 94.94, Test_acc 31.93
2025-02-17 12:56:30,997 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.24, Train_acc 94.42, Test_acc 34.89
2025-02-17 12:56:33,514 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.24, Train_acc 94.18, Test_acc 33.43
2025-02-17 12:56:36,070 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.24, Train_acc 95.11, Test_acc 32.96
2025-02-17 12:56:38,575 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.24, Train_acc 95.18, Test_acc 36.71
2025-02-17 12:56:41,137 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.24, Train_acc 94.79, Test_acc 36.57
2025-02-17 12:56:43,673 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 94.84, Test_acc 32.49
2025-02-17 12:56:46,204 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.29, Spatial_loss 1.34, Flat_loss 0.24, Train_acc 94.81, Test_acc 35.50
2025-02-17 12:56:48,754 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.24, Train_acc 95.15, Test_acc 31.76
2025-02-17 12:56:51,276 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.23, Train_acc 95.40, Test_acc 36.33
2025-02-17 12:56:53,801 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 95.65, Test_acc 34.64
2025-02-17 12:56:56,386 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.23, Train_acc 95.58, Test_acc 38.40
2025-02-17 12:56:58,939 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.23, Train_acc 95.68, Test_acc 39.40
2025-02-17 12:57:01,491 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.22, Train_acc 96.31, Test_acc 32.16
2025-02-17 12:57:03,990 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 95.44, Test_acc 34.40
2025-02-17 12:57:06,580 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.22, Train_acc 96.24, Test_acc 35.66
2025-02-17 12:57:09,117 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.22, Train_acc 95.97, Test_acc 34.33
2025-02-17 12:57:11,640 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.22, Train_acc 96.40, Test_acc 33.46
2025-02-17 12:57:14,202 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.53, Test_acc 34.83
2025-02-17 12:57:16,706 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.22, Train_acc 96.10, Test_acc 35.43
2025-02-17 12:57:19,251 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.22, Train_acc 96.00, Test_acc 38.21
2025-02-17 12:57:21,811 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.22, Spatial_loss 1.22, Flat_loss 0.22, Train_acc 96.90, Test_acc 36.96
2025-02-17 12:57:24,356 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.22, Train_acc 96.60, Test_acc 38.50
2025-02-17 12:57:26,841 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.21, Train_acc 97.05, Test_acc 37.53
2025-02-17 12:57:29,365 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 1.16, Flat_loss 0.21, Train_acc 97.39, Test_acc 34.27
2025-02-17 12:57:31,925 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 97.34, Test_acc 37.51
2025-02-17 12:57:34,381 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 97.31, Test_acc 36.69
2025-02-17 12:57:36,925 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.21, Train_acc 96.90, Test_acc 36.69
2025-02-17 12:57:39,418 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 97.31, Test_acc 35.76
2025-02-17 12:57:41,918 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.21, Train_acc 97.65, Test_acc 38.14
2025-02-17 12:57:44,437 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.21, Train_acc 97.35, Test_acc 34.84
2025-02-17 12:57:46,979 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.21, Train_acc 97.84, Test_acc 36.93
2025-02-17 12:57:49,489 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.21, Train_acc 97.95, Test_acc 38.56
2025-02-17 12:57:52,064 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.21, Train_acc 97.79, Test_acc 36.61
2025-02-17 12:57:54,607 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 97.74, Test_acc 36.89
2025-02-17 12:57:57,141 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.20, Train_acc 98.02, Test_acc 34.43
2025-02-17 12:57:59,660 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 98.05, Test_acc 37.74
2025-02-17 12:58:02,253 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.10, Test_acc 37.89
2025-02-17 12:58:04,802 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.20, Train_acc 98.23, Test_acc 37.37
2025-02-17 12:58:07,325 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.20, Train_acc 98.15, Test_acc 37.01
2025-02-17 12:58:09,850 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.20, Train_acc 98.15, Test_acc 37.27
2025-02-17 12:58:12,419 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.20, Train_acc 98.02, Test_acc 36.94
2025-02-17 12:58:14,938 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.20, Train_acc 98.26, Test_acc 38.06
2025-02-17 12:58:17,471 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.20, Train_acc 98.39, Test_acc 38.51
2025-02-17 12:58:19,992 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.15, Test_acc 37.96
2025-02-17 12:58:22,557 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.20, Train_acc 98.34, Test_acc 39.50
2025-02-17 12:58:25,145 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.19, Train_acc 98.42, Test_acc 37.67
2025-02-17 12:58:27,889 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.58, Test_acc 38.56
2025-02-17 12:58:30,472 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.47, Test_acc 38.33
2025-02-17 12:58:33,045 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.69, Test_acc 38.19
2025-02-17 12:58:35,635 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.53, Test_acc 38.16
2025-02-17 12:58:38,201 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.63, Test_acc 38.57
2025-02-17 12:58:40,757 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.55, Test_acc 39.30
2025-02-17 12:58:43,319 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.17, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 98.66, Test_acc 38.96
2025-02-17 12:58:45,923 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 98.47, Test_acc 38.29
2025-02-17 12:58:48,526 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.52, Test_acc 38.40
2025-02-17 12:58:51,108 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.97, Test_acc 39.31
2025-02-17 12:58:53,668 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.73, Test_acc 38.87
2025-02-17 12:58:56,286 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.60, Test_acc 38.24
2025-02-17 12:58:58,899 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 98.73, Test_acc 38.84
2025-02-17 12:59:01,442 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.87, Test_acc 38.89
2025-02-17 12:59:04,012 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.82, Test_acc 38.70
2025-02-17 12:59:06,563 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.89, Test_acc 38.59
2025-02-17 12:59:09,135 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 98.95, Test_acc 38.63
2025-02-17 12:59:11,699 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.73, Test_acc 38.67
2025-02-17 12:59:14,223 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 98.76, Test_acc 38.79
2025-02-17 12:59:16,806 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 0.89, Flat_loss 0.19, Train_acc 98.76, Test_acc 38.69
2025-02-17 12:59:19,407 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 98.92, Test_acc 38.53
2025-02-17 12:59:22,042 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.17, Spatial_loss 0.92, Flat_loss 0.19, Train_acc 98.69, Test_acc 38.51
2025-02-17 12:59:24,597 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.16, Spatial_loss 0.91, Flat_loss 0.19, Train_acc 98.65, Test_acc 38.73
2025-02-17 12:59:27,202 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 98.76, Test_acc 38.74
2025-02-17 12:59:29,776 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.19, Train_acc 98.82, Test_acc 39.01
2025-02-17 12:59:29,777 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 12:59:29,777 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 12:59:58,133 [podnet.py] => The size of finetune dataset: 1400
2025-02-17 12:59:59,550 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.31, Spatial_loss 1.04, Flat_loss 0.15, Train_acc 94.86, Test_acc 41.76
2025-02-17 13:00:01,015 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 98.79, Test_acc 42.16
2025-02-17 13:00:02,443 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.11, Train_acc 98.79, Test_acc 41.69
2025-02-17 13:00:03,858 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.10, Train_acc 99.07, Test_acc 41.27
2025-02-17 13:00:05,278 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.10, Train_acc 99.50, Test_acc 41.50
2025-02-17 13:00:06,706 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.10, Train_acc 99.50, Test_acc 41.74
2025-02-17 13:00:08,129 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.50, Test_acc 41.99
2025-02-17 13:00:09,538 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.36, Test_acc 41.74
2025-02-17 13:00:10,979 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 99.21, Test_acc 42.21
2025-02-17 13:00:12,420 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.43, Test_acc 42.20
2025-02-17 13:00:13,853 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.43, Test_acc 41.61
2025-02-17 13:00:15,230 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.10, Train_acc 99.36, Test_acc 41.93
2025-02-17 13:00:16,713 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.71, Test_acc 42.06
2025-02-17 13:00:18,129 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.57, Test_acc 41.86
2025-02-17 13:00:19,559 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 99.57, Test_acc 42.31
2025-02-17 13:00:21,025 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 98.93, Test_acc 42.37
2025-02-17 13:00:22,449 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 99.43, Test_acc 42.07
2025-02-17 13:00:23,889 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.64, Test_acc 42.09
2025-02-17 13:00:25,347 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.07, Test_acc 42.23
2025-02-17 13:00:26,792 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.43, Test_acc 41.94
2025-02-17 13:00:26,794 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:00:57,116 [podnet.py] => Exemplar size: 1400
2025-02-17 13:00:57,116 [trainer.py] => CNN: {'total': 41.94, '00-09': 52.8, '10-19': 16.2, '20-29': 32.8, '30-39': 30.1, '40-49': 47.7, '50-59': 39.9, '60-69': 74.1, 'old': 36.58, 'new': 74.1}
2025-02-17 13:00:57,116 [trainer.py] => NME: {'total': 41.47, '00-09': 62.8, '10-19': 15.3, '20-29': 33.5, '30-39': 29.0, '40-49': 45.0, '50-59': 36.8, '60-69': 67.9, 'old': 37.07, 'new': 67.9}
2025-02-17 13:00:57,116 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2, 43.93, 41.94]
2025-02-17 13:00:57,116 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22, 74.43, 72.57]
2025-02-17 13:00:57,116 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42, 43.8, 41.47]
2025-02-17 13:00:57,116 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78, 73.92, 71.16]

2025-02-17 13:00:57,116 [trainer.py] => Average Accuracy (CNN): 57.53857142857142
2025-02-17 13:00:57,116 [trainer.py] => Average Accuracy (NME): 57.38571428571429
2025-02-17 13:00:57,117 [trainer.py] => All params: 511057
2025-02-17 13:00:57,117 [trainer.py] => Trainable params: 511057
2025-02-17 13:00:57,118 [podnet.py] => Learning on 70-80
2025-02-17 13:00:57,166 [podnet.py] => Adaptive factor: 2.8284271247461903
2025-02-17 13:00:59,882 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 2.86, Spatial_loss 3.22, Flat_loss 1.13, Train_acc 47.16, Test_acc 21.05
2025-02-17 13:01:02,590 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 1.53, Spatial_loss 2.60, Flat_loss 0.64, Train_acc 59.50, Test_acc 20.52
2025-02-17 13:01:05,223 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 1.35, Spatial_loss 2.41, Flat_loss 0.50, Train_acc 64.14, Test_acc 21.85
2025-02-17 13:01:07,827 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 1.25, Spatial_loss 2.30, Flat_loss 0.43, Train_acc 65.39, Test_acc 28.68
2025-02-17 13:01:10,428 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 1.19, Spatial_loss 2.26, Flat_loss 0.40, Train_acc 67.48, Test_acc 22.39
2025-02-17 13:01:13,114 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 1.11, Spatial_loss 2.18, Flat_loss 0.37, Train_acc 69.69, Test_acc 29.48
2025-02-17 13:01:15,734 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 1.08, Spatial_loss 2.16, Flat_loss 0.35, Train_acc 70.61, Test_acc 27.26
2025-02-17 13:01:18,380 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 1.04, Spatial_loss 2.09, Flat_loss 0.34, Train_acc 71.27, Test_acc 27.29
2025-02-17 13:01:20,966 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 1.01, Spatial_loss 2.09, Flat_loss 0.33, Train_acc 71.84, Test_acc 31.04
2025-02-17 13:01:23,536 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 0.98, Spatial_loss 2.03, Flat_loss 0.33, Train_acc 72.66, Test_acc 27.91
2025-02-17 13:01:26,139 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 0.97, Spatial_loss 2.04, Flat_loss 0.32, Train_acc 73.61, Test_acc 29.48
2025-02-17 13:01:28,702 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 2.05, Flat_loss 0.33, Train_acc 73.45, Test_acc 29.85
2025-02-17 13:01:31,376 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 0.92, Spatial_loss 1.96, Flat_loss 0.31, Train_acc 74.55, Test_acc 25.95
2025-02-17 13:01:33,989 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.89, Spatial_loss 1.95, Flat_loss 0.31, Train_acc 75.62, Test_acc 30.11
2025-02-17 13:01:36,631 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.88, Spatial_loss 1.93, Flat_loss 0.31, Train_acc 76.09, Test_acc 25.14
2025-02-17 13:01:39,209 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.88, Spatial_loss 2.00, Flat_loss 0.31, Train_acc 76.00, Test_acc 31.38
2025-02-17 13:01:41,819 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.87, Spatial_loss 1.94, Flat_loss 0.31, Train_acc 76.44, Test_acc 29.94
2025-02-17 13:01:44,463 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.83, Spatial_loss 1.86, Flat_loss 0.30, Train_acc 77.55, Test_acc 25.98
2025-02-17 13:01:47,081 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.85, Spatial_loss 1.93, Flat_loss 0.31, Train_acc 77.45, Test_acc 31.00
2025-02-17 13:01:49,663 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.82, Spatial_loss 1.90, Flat_loss 0.30, Train_acc 77.88, Test_acc 31.26
2025-02-17 13:01:52,238 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.82, Spatial_loss 1.94, Flat_loss 0.31, Train_acc 77.62, Test_acc 27.74
2025-02-17 13:01:54,829 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.81, Spatial_loss 1.94, Flat_loss 0.31, Train_acc 78.20, Test_acc 26.72
2025-02-17 13:01:57,470 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.82, Spatial_loss 2.03, Flat_loss 0.32, Train_acc 77.84, Test_acc 27.79
2025-02-17 13:02:00,077 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.78, Spatial_loss 1.96, Flat_loss 0.31, Train_acc 78.62, Test_acc 30.14
2025-02-17 13:02:02,703 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.78, Spatial_loss 1.91, Flat_loss 0.30, Train_acc 79.48, Test_acc 29.80
2025-02-17 13:02:05,348 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.76, Spatial_loss 1.91, Flat_loss 0.30, Train_acc 79.62, Test_acc 28.39
2025-02-17 13:02:07,996 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.78, Spatial_loss 1.91, Flat_loss 0.31, Train_acc 78.59, Test_acc 26.00
2025-02-17 13:02:10,630 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.76, Spatial_loss 1.93, Flat_loss 0.31, Train_acc 79.25, Test_acc 24.11
2025-02-17 13:02:13,229 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.76, Spatial_loss 1.88, Flat_loss 0.30, Train_acc 79.06, Test_acc 25.11
2025-02-17 13:02:15,819 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.73, Spatial_loss 1.88, Flat_loss 0.30, Train_acc 80.61, Test_acc 31.62
2025-02-17 13:02:18,417 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.71, Spatial_loss 1.90, Flat_loss 0.31, Train_acc 81.11, Test_acc 28.26
2025-02-17 13:02:21,022 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.72, Spatial_loss 1.86, Flat_loss 0.30, Train_acc 80.83, Test_acc 27.90
2025-02-17 13:02:23,610 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.68, Spatial_loss 1.85, Flat_loss 0.30, Train_acc 81.88, Test_acc 29.70
2025-02-17 13:02:26,218 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.71, Spatial_loss 1.91, Flat_loss 0.31, Train_acc 81.25, Test_acc 28.34
2025-02-17 13:02:28,778 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.69, Spatial_loss 1.87, Flat_loss 0.30, Train_acc 81.36, Test_acc 27.26
2025-02-17 13:02:31,354 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.67, Spatial_loss 1.82, Flat_loss 0.30, Train_acc 82.05, Test_acc 28.11
2025-02-17 13:02:34,016 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.67, Spatial_loss 1.89, Flat_loss 0.30, Train_acc 82.38, Test_acc 24.31
2025-02-17 13:02:36,601 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.68, Spatial_loss 1.88, Flat_loss 0.30, Train_acc 82.17, Test_acc 28.06
2025-02-17 13:02:39,197 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.69, Spatial_loss 1.91, Flat_loss 0.31, Train_acc 81.45, Test_acc 32.20
2025-02-17 13:02:41,759 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.69, Spatial_loss 1.91, Flat_loss 0.31, Train_acc 81.53, Test_acc 30.99
2025-02-17 13:02:44,406 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.67, Spatial_loss 1.90, Flat_loss 0.31, Train_acc 82.34, Test_acc 28.10
2025-02-17 13:02:46,986 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.66, Spatial_loss 1.81, Flat_loss 0.30, Train_acc 82.84, Test_acc 29.22
2025-02-17 13:02:49,584 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.65, Spatial_loss 1.85, Flat_loss 0.31, Train_acc 82.95, Test_acc 32.22
2025-02-17 13:02:52,172 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.63, Spatial_loss 1.85, Flat_loss 0.30, Train_acc 83.73, Test_acc 29.34
2025-02-17 13:02:54,819 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.64, Spatial_loss 1.85, Flat_loss 0.30, Train_acc 83.34, Test_acc 27.96
2025-02-17 13:02:57,457 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.64, Spatial_loss 1.90, Flat_loss 0.31, Train_acc 82.80, Test_acc 27.30
2025-02-17 13:03:00,121 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.62, Spatial_loss 1.81, Flat_loss 0.30, Train_acc 83.72, Test_acc 28.91
2025-02-17 13:03:02,707 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.59, Spatial_loss 1.82, Flat_loss 0.30, Train_acc 84.66, Test_acc 27.46
2025-02-17 13:03:05,305 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.60, Spatial_loss 1.77, Flat_loss 0.30, Train_acc 84.83, Test_acc 30.65
2025-02-17 13:03:07,974 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.62, Spatial_loss 1.80, Flat_loss 0.30, Train_acc 84.19, Test_acc 25.95
2025-02-17 13:03:10,542 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.57, Spatial_loss 1.77, Flat_loss 0.29, Train_acc 85.78, Test_acc 25.04
2025-02-17 13:03:13,192 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 1.80, Flat_loss 0.29, Train_acc 85.41, Test_acc 25.06
2025-02-17 13:03:15,822 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.57, Spatial_loss 1.78, Flat_loss 0.30, Train_acc 85.39, Test_acc 29.64
2025-02-17 13:03:18,509 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.58, Spatial_loss 1.80, Flat_loss 0.30, Train_acc 85.14, Test_acc 29.58
2025-02-17 13:03:21,120 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.59, Spatial_loss 1.80, Flat_loss 0.30, Train_acc 85.03, Test_acc 26.05
2025-02-17 13:03:23,771 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.57, Spatial_loss 1.76, Flat_loss 0.30, Train_acc 85.34, Test_acc 27.70
2025-02-17 13:03:26,383 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.55, Spatial_loss 1.73, Flat_loss 0.30, Train_acc 86.55, Test_acc 25.20
2025-02-17 13:03:28,998 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.57, Spatial_loss 1.78, Flat_loss 0.30, Train_acc 85.22, Test_acc 26.24
2025-02-17 13:03:31,612 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.56, Spatial_loss 1.74, Flat_loss 0.30, Train_acc 85.64, Test_acc 27.75
2025-02-17 13:03:34,227 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.57, Spatial_loss 1.81, Flat_loss 0.30, Train_acc 85.69, Test_acc 30.30
2025-02-17 13:03:36,823 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.53, Spatial_loss 1.77, Flat_loss 0.30, Train_acc 86.52, Test_acc 27.51
2025-02-17 13:03:39,387 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.53, Spatial_loss 1.72, Flat_loss 0.29, Train_acc 86.69, Test_acc 30.04
2025-02-17 13:03:42,010 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.52, Spatial_loss 1.74, Flat_loss 0.29, Train_acc 87.48, Test_acc 26.65
2025-02-17 13:03:44,715 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.52, Spatial_loss 1.72, Flat_loss 0.29, Train_acc 86.66, Test_acc 32.60
2025-02-17 13:03:47,290 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.51, Spatial_loss 1.69, Flat_loss 0.29, Train_acc 87.61, Test_acc 30.80
2025-02-17 13:03:49,934 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.52, Spatial_loss 1.66, Flat_loss 0.29, Train_acc 87.47, Test_acc 30.32
2025-02-17 13:03:52,539 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.49, Spatial_loss 1.71, Flat_loss 0.29, Train_acc 88.12, Test_acc 27.68
2025-02-17 13:03:55,139 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.51, Spatial_loss 1.67, Flat_loss 0.29, Train_acc 87.08, Test_acc 28.81
2025-02-17 13:03:57,741 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.50, Spatial_loss 1.70, Flat_loss 0.29, Train_acc 88.00, Test_acc 29.00
2025-02-17 13:04:00,384 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.47, Spatial_loss 1.63, Flat_loss 0.28, Train_acc 88.77, Test_acc 29.84
2025-02-17 13:04:02,971 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.48, Spatial_loss 1.65, Flat_loss 0.29, Train_acc 88.06, Test_acc 30.05
2025-02-17 13:04:05,675 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 1.66, Flat_loss 0.29, Train_acc 87.62, Test_acc 29.01
2025-02-17 13:04:08,307 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.46, Spatial_loss 1.61, Flat_loss 0.28, Train_acc 88.88, Test_acc 29.86
2025-02-17 13:04:10,972 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.48, Spatial_loss 1.61, Flat_loss 0.29, Train_acc 88.34, Test_acc 28.30
2025-02-17 13:04:13,681 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.48, Spatial_loss 1.68, Flat_loss 0.29, Train_acc 88.31, Test_acc 28.20
2025-02-17 13:04:16,395 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.44, Spatial_loss 1.63, Flat_loss 0.29, Train_acc 89.91, Test_acc 31.01
2025-02-17 13:04:18,952 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.44, Spatial_loss 1.58, Flat_loss 0.28, Train_acc 89.58, Test_acc 28.98
2025-02-17 13:04:21,510 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.42, Spatial_loss 1.55, Flat_loss 0.28, Train_acc 90.69, Test_acc 32.94
2025-02-17 13:04:24,111 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.43, Spatial_loss 1.60, Flat_loss 0.28, Train_acc 89.66, Test_acc 29.54
2025-02-17 13:04:26,702 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.43, Spatial_loss 1.60, Flat_loss 0.28, Train_acc 90.17, Test_acc 31.75
2025-02-17 13:04:29,333 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.42, Spatial_loss 1.58, Flat_loss 0.28, Train_acc 90.67, Test_acc 30.46
2025-02-17 13:04:31,960 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.42, Spatial_loss 1.58, Flat_loss 0.28, Train_acc 90.09, Test_acc 27.54
2025-02-17 13:04:34,579 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.40, Spatial_loss 1.52, Flat_loss 0.28, Train_acc 91.36, Test_acc 32.83
2025-02-17 13:04:37,254 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.40, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 90.92, Test_acc 29.25
2025-02-17 13:04:39,927 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.40, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 90.92, Test_acc 29.09
2025-02-17 13:04:42,546 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.41, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 90.56, Test_acc 29.14
2025-02-17 13:04:45,154 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.40, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 90.95, Test_acc 30.65
2025-02-17 13:04:47,851 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.39, Spatial_loss 1.52, Flat_loss 0.28, Train_acc 91.34, Test_acc 28.29
2025-02-17 13:04:50,509 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.39, Spatial_loss 1.46, Flat_loss 0.27, Train_acc 91.72, Test_acc 30.85
2025-02-17 13:04:53,155 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.26, Train_acc 93.28, Test_acc 31.91
2025-02-17 13:04:55,779 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.38, Spatial_loss 1.48, Flat_loss 0.27, Train_acc 91.75, Test_acc 28.90
2025-02-17 13:04:58,358 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.39, Spatial_loss 1.52, Flat_loss 0.28, Train_acc 91.36, Test_acc 31.12
2025-02-17 13:05:00,952 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.36, Spatial_loss 1.50, Flat_loss 0.27, Train_acc 92.22, Test_acc 29.46
2025-02-17 13:05:03,577 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.27, Train_acc 92.42, Test_acc 30.58
2025-02-17 13:05:06,205 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.34, Spatial_loss 1.42, Flat_loss 0.26, Train_acc 92.97, Test_acc 32.15
2025-02-17 13:05:08,829 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.26, Train_acc 93.36, Test_acc 31.64
2025-02-17 13:05:11,418 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.32, Spatial_loss 1.38, Flat_loss 0.26, Train_acc 93.62, Test_acc 32.58
2025-02-17 13:05:13,997 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.27, Train_acc 92.81, Test_acc 29.00
2025-02-17 13:05:16,566 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.34, Spatial_loss 1.42, Flat_loss 0.27, Train_acc 92.94, Test_acc 32.99
2025-02-17 13:05:19,199 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.40, Flat_loss 0.26, Train_acc 93.16, Test_acc 31.58
2025-02-17 13:05:21,819 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.35, Flat_loss 0.26, Train_acc 93.31, Test_acc 30.90
2025-02-17 13:05:24,433 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.33, Spatial_loss 1.41, Flat_loss 0.26, Train_acc 93.38, Test_acc 32.50
2025-02-17 13:05:27,047 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.31, Spatial_loss 1.38, Flat_loss 0.26, Train_acc 93.97, Test_acc 31.79
2025-02-17 13:05:29,710 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.31, Spatial_loss 1.34, Flat_loss 0.25, Train_acc 94.12, Test_acc 32.12
2025-02-17 13:05:32,309 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.30, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 94.50, Test_acc 33.19
2025-02-17 13:05:34,916 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.31, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 94.12, Test_acc 33.04
2025-02-17 13:05:37,497 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.30, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 94.23, Test_acc 31.58
2025-02-17 13:05:40,122 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.28, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 94.88, Test_acc 31.78
2025-02-17 13:05:42,689 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.31, Flat_loss 0.25, Train_acc 95.31, Test_acc 30.01
2025-02-17 13:05:45,282 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 95.39, Test_acc 31.34
2025-02-17 13:05:47,868 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 94.80, Test_acc 34.39
2025-02-17 13:05:50,433 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.27, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 95.47, Test_acc 32.76
2025-02-17 13:05:53,093 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.24, Train_acc 95.91, Test_acc 31.44
2025-02-17 13:05:55,758 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 95.88, Test_acc 29.04
2025-02-17 13:05:58,433 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.27, Spatial_loss 1.28, Flat_loss 0.25, Train_acc 95.55, Test_acc 29.40
2025-02-17 13:06:01,034 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.23, Flat_loss 0.24, Train_acc 96.06, Test_acc 34.14
2025-02-17 13:06:03,686 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 1.25, Flat_loss 0.24, Train_acc 95.94, Test_acc 31.11
2025-02-17 13:06:06,421 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.24, Train_acc 96.09, Test_acc 33.66
2025-02-17 13:06:09,078 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 95.91, Test_acc 31.56
2025-02-17 13:06:11,693 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 96.14, Test_acc 33.66
2025-02-17 13:06:14,402 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.24, Train_acc 96.67, Test_acc 32.17
2025-02-17 13:06:17,061 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.23, Train_acc 96.81, Test_acc 31.62
2025-02-17 13:06:19,704 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.24, Train_acc 96.33, Test_acc 33.70
2025-02-17 13:06:22,421 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 96.70, Test_acc 33.95
2025-02-17 13:06:25,127 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 96.69, Test_acc 32.51
2025-02-17 13:06:27,845 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 96.66, Test_acc 34.10
2025-02-17 13:06:30,502 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 96.61, Test_acc 33.95
2025-02-17 13:06:33,173 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 97.17, Test_acc 34.10
2025-02-17 13:06:35,815 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 96.64, Test_acc 34.96
2025-02-17 13:06:38,479 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 97.11, Test_acc 34.41
2025-02-17 13:06:41,223 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 96.86, Test_acc 33.54
2025-02-17 13:06:43,942 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 97.30, Test_acc 33.39
2025-02-17 13:06:46,610 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 97.39, Test_acc 33.26
2025-02-17 13:06:49,264 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.09, Flat_loss 0.23, Train_acc 97.28, Test_acc 33.78
2025-02-17 13:06:51,910 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.09, Flat_loss 0.23, Train_acc 97.16, Test_acc 33.52
2025-02-17 13:06:54,606 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.21, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.97, Test_acc 33.83
2025-02-17 13:06:57,239 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 97.64, Test_acc 34.88
2025-02-17 13:06:59,881 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 97.53, Test_acc 32.54
2025-02-17 13:07:02,648 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 97.59, Test_acc 33.88
2025-02-17 13:07:05,312 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.78, Test_acc 33.70
2025-02-17 13:07:08,128 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 97.88, Test_acc 34.46
2025-02-17 13:07:10,881 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 97.88, Test_acc 33.66
2025-02-17 13:07:13,627 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.21, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 97.78, Test_acc 33.33
2025-02-17 13:07:16,326 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 97.89, Test_acc 34.26
2025-02-17 13:07:19,007 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 97.78, Test_acc 34.33
2025-02-17 13:07:21,732 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.22, Train_acc 98.03, Test_acc 34.41
2025-02-17 13:07:24,410 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 97.98, Test_acc 34.25
2025-02-17 13:07:27,116 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 97.98, Test_acc 34.64
2025-02-17 13:07:29,749 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 97.56, Test_acc 34.01
2025-02-17 13:07:32,393 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.22, Train_acc 97.61, Test_acc 33.88
2025-02-17 13:07:35,082 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.05, Test_acc 34.00
2025-02-17 13:07:37,811 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 97.86, Test_acc 34.22
2025-02-17 13:07:40,473 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 0.97, Flat_loss 0.21, Train_acc 98.05, Test_acc 34.25
2025-02-17 13:07:43,179 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.22, Train_acc 98.00, Test_acc 34.12
2025-02-17 13:07:45,855 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.03, Test_acc 34.02
2025-02-17 13:07:48,534 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.22, Train_acc 97.84, Test_acc 34.17
2025-02-17 13:07:51,185 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 0.97, Flat_loss 0.22, Train_acc 98.02, Test_acc 33.99
2025-02-17 13:07:53,827 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.22, Train_acc 98.00, Test_acc 34.16
2025-02-17 13:07:56,531 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.22, Train_acc 98.03, Test_acc 34.06
2025-02-17 13:07:59,190 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 0.97, Flat_loss 0.22, Train_acc 98.05, Test_acc 34.17
2025-02-17 13:07:59,190 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 13:07:59,191 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:08:31,375 [podnet.py] => The size of finetune dataset: 1600
2025-02-17 13:08:32,886 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.32, Spatial_loss 1.08, Flat_loss 0.16, Train_acc 94.38, Test_acc 38.49
2025-02-17 13:08:34,381 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.22, Spatial_loss 1.10, Flat_loss 0.12, Train_acc 97.62, Test_acc 37.91
2025-02-17 13:08:35,855 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.12, Train_acc 98.25, Test_acc 37.45
2025-02-17 13:08:37,384 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.12, Train_acc 98.94, Test_acc 37.92
2025-02-17 13:08:38,957 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.11, Train_acc 98.94, Test_acc 38.40
2025-02-17 13:08:40,518 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.11, Train_acc 98.56, Test_acc 38.25
2025-02-17 13:08:42,031 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.11, Train_acc 98.69, Test_acc 38.12
2025-02-17 13:08:43,520 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 98.94, Test_acc 38.24
2025-02-17 13:08:45,013 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.11, Train_acc 99.06, Test_acc 38.21
2025-02-17 13:08:46,516 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.11, Train_acc 98.81, Test_acc 38.92
2025-02-17 13:08:47,974 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.11, Train_acc 98.31, Test_acc 38.38
2025-02-17 13:08:49,478 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 98.94, Test_acc 38.39
2025-02-17 13:08:50,994 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 98.50, Test_acc 38.54
2025-02-17 13:08:52,502 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.11, Train_acc 99.00, Test_acc 38.65
2025-02-17 13:08:53,989 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 99.12, Test_acc 38.31
2025-02-17 13:08:55,555 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 99.12, Test_acc 38.26
2025-02-17 13:08:57,056 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 99.12, Test_acc 38.45
2025-02-17 13:08:58,562 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.11, Train_acc 99.25, Test_acc 38.58
2025-02-17 13:09:00,085 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.10, Train_acc 98.88, Test_acc 38.45
2025-02-17 13:09:01,580 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 99.44, Test_acc 38.49
2025-02-17 13:09:01,582 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:09:33,797 [podnet.py] => Exemplar size: 1600
2025-02-17 13:09:33,797 [trainer.py] => CNN: {'total': 38.49, '00-09': 50.8, '10-19': 15.8, '20-29': 30.8, '30-39': 26.1, '40-49': 42.1, '50-59': 27.3, '60-69': 50.8, '70-79': 64.2, 'old': 34.81, 'new': 64.2}
2025-02-17 13:09:33,797 [trainer.py] => NME: {'total': 38.49, '00-09': 60.9, '10-19': 14.4, '20-29': 30.0, '30-39': 26.8, '40-49': 41.7, '50-59': 27.7, '60-69': 50.1, '70-79': 56.3, 'old': 35.94, 'new': 56.3}
2025-02-17 13:09:33,797 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2, 43.93, 41.94, 38.49]
2025-02-17 13:09:33,797 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22, 74.43, 72.57, 69.22]
2025-02-17 13:09:33,797 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42, 43.8, 41.47, 38.49]
2025-02-17 13:09:33,797 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78, 73.92, 71.16, 68.14]

2025-02-17 13:09:33,797 [trainer.py] => Average Accuracy (CNN): 55.1575
2025-02-17 13:09:33,797 [trainer.py] => Average Accuracy (NME): 55.02375000000001
2025-02-17 13:09:33,798 [trainer.py] => All params: 517457
2025-02-17 13:09:33,798 [trainer.py] => Trainable params: 517457
2025-02-17 13:09:33,799 [podnet.py] => Learning on 80-90
2025-02-17 13:09:33,847 [podnet.py] => Adaptive factor: 3.0
2025-02-17 13:09:36,568 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 2.82, Spatial_loss 3.09, Flat_loss 1.13, Train_acc 44.42, Test_acc 22.57
2025-02-17 13:09:39,315 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 1.52, Spatial_loss 2.53, Flat_loss 0.60, Train_acc 59.71, Test_acc 26.80
2025-02-17 13:09:42,046 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 1.35, Spatial_loss 2.35, Flat_loss 0.48, Train_acc 64.45, Test_acc 24.24
2025-02-17 13:09:44,796 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 1.25, Spatial_loss 2.28, Flat_loss 0.42, Train_acc 66.77, Test_acc 25.34
2025-02-17 13:09:47,490 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 1.18, Spatial_loss 2.19, Flat_loss 0.40, Train_acc 68.82, Test_acc 21.67
2025-02-17 13:09:50,268 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 1.12, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 70.39, Test_acc 25.16
2025-02-17 13:09:53,035 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 1.09, Spatial_loss 2.13, Flat_loss 0.37, Train_acc 71.17, Test_acc 24.04
2025-02-17 13:09:55,813 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 1.04, Spatial_loss 2.12, Flat_loss 0.36, Train_acc 72.50, Test_acc 29.29
2025-02-17 13:09:58,536 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 1.03, Spatial_loss 2.17, Flat_loss 0.37, Train_acc 72.50, Test_acc 25.07
2025-02-17 13:10:01,247 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 0.98, Spatial_loss 2.10, Flat_loss 0.36, Train_acc 74.20, Test_acc 24.57
2025-02-17 13:10:03,933 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 0.96, Spatial_loss 2.11, Flat_loss 0.36, Train_acc 75.06, Test_acc 27.38
2025-02-17 13:10:06,699 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 2.12, Flat_loss 0.35, Train_acc 74.48, Test_acc 19.61
2025-02-17 13:10:09,375 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.95, Spatial_loss 2.09, Flat_loss 0.35, Train_acc 75.42, Test_acc 29.59
2025-02-17 13:10:12,073 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.90, Spatial_loss 2.04, Flat_loss 0.35, Train_acc 77.06, Test_acc 25.97
2025-02-17 13:10:14,813 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.88, Spatial_loss 2.04, Flat_loss 0.34, Train_acc 77.58, Test_acc 22.50
2025-02-17 13:10:17,563 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.87, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 77.18, Test_acc 21.04
2025-02-17 13:10:20,285 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.88, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 77.14, Test_acc 25.09
2025-02-17 13:10:22,985 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.83, Spatial_loss 2.02, Flat_loss 0.34, Train_acc 78.89, Test_acc 25.98
2025-02-17 13:10:25,780 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.84, Spatial_loss 1.96, Flat_loss 0.34, Train_acc 78.52, Test_acc 24.32
2025-02-17 13:10:28,465 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.82, Spatial_loss 1.98, Flat_loss 0.34, Train_acc 78.70, Test_acc 25.92
2025-02-17 13:10:31,178 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.81, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 79.20, Test_acc 25.91
2025-02-17 13:10:33,920 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.79, Spatial_loss 2.00, Flat_loss 0.35, Train_acc 80.38, Test_acc 28.84
2025-02-17 13:10:36,693 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.80, Spatial_loss 2.00, Flat_loss 0.35, Train_acc 79.23, Test_acc 27.10
2025-02-17 13:10:39,415 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.79, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 79.68, Test_acc 28.11
2025-02-17 13:10:42,106 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.80, Spatial_loss 1.98, Flat_loss 0.34, Train_acc 79.42, Test_acc 28.52
2025-02-17 13:10:44,831 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.74, Spatial_loss 1.97, Flat_loss 0.35, Train_acc 81.23, Test_acc 25.86
2025-02-17 13:10:47,544 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.75, Spatial_loss 1.95, Flat_loss 0.35, Train_acc 80.58, Test_acc 28.10
2025-02-17 13:10:50,254 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.74, Spatial_loss 1.96, Flat_loss 0.34, Train_acc 81.21, Test_acc 25.00
2025-02-17 13:10:52,926 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.74, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 80.47, Test_acc 26.58
2025-02-17 13:10:55,632 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.74, Spatial_loss 1.95, Flat_loss 0.34, Train_acc 80.71, Test_acc 24.94
2025-02-17 13:10:58,404 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.69, Spatial_loss 1.93, Flat_loss 0.34, Train_acc 82.58, Test_acc 29.18
2025-02-17 13:11:01,148 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.74, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 80.12, Test_acc 29.26
2025-02-17 13:11:03,922 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.73, Spatial_loss 1.98, Flat_loss 0.35, Train_acc 80.88, Test_acc 25.49
2025-02-17 13:11:06,658 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.72, Spatial_loss 1.93, Flat_loss 0.34, Train_acc 81.48, Test_acc 25.70
2025-02-17 13:11:09,370 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.71, Spatial_loss 1.91, Flat_loss 0.35, Train_acc 81.73, Test_acc 27.62
2025-02-17 13:11:12,069 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.73, Spatial_loss 2.01, Flat_loss 0.35, Train_acc 80.92, Test_acc 27.13
2025-02-17 13:11:14,771 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.67, Spatial_loss 1.92, Flat_loss 0.34, Train_acc 82.70, Test_acc 23.79
2025-02-17 13:11:17,472 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.66, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 83.24, Test_acc 26.40
2025-02-17 13:11:20,129 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.65, Spatial_loss 1.86, Flat_loss 0.33, Train_acc 83.50, Test_acc 23.14
2025-02-17 13:11:22,794 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.65, Spatial_loss 1.86, Flat_loss 0.34, Train_acc 83.53, Test_acc 27.14
2025-02-17 13:11:25,555 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.65, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 83.42, Test_acc 27.38
2025-02-17 13:11:28,264 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.63, Spatial_loss 1.89, Flat_loss 0.34, Train_acc 84.12, Test_acc 22.98
2025-02-17 13:11:30,971 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.65, Spatial_loss 1.87, Flat_loss 0.34, Train_acc 83.20, Test_acc 23.77
2025-02-17 13:11:33,716 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.65, Spatial_loss 1.95, Flat_loss 0.34, Train_acc 83.67, Test_acc 25.17
2025-02-17 13:11:36,422 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.64, Spatial_loss 1.88, Flat_loss 0.33, Train_acc 84.17, Test_acc 25.96
2025-02-17 13:11:39,089 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.64, Spatial_loss 1.93, Flat_loss 0.34, Train_acc 83.80, Test_acc 28.77
2025-02-17 13:11:41,798 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.62, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 84.53, Test_acc 25.89
2025-02-17 13:11:44,531 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.62, Spatial_loss 1.86, Flat_loss 0.34, Train_acc 84.11, Test_acc 26.00
2025-02-17 13:11:47,201 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.60, Spatial_loss 1.88, Flat_loss 0.33, Train_acc 85.29, Test_acc 28.58
2025-02-17 13:11:49,973 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.59, Spatial_loss 1.85, Flat_loss 0.33, Train_acc 85.45, Test_acc 24.74
2025-02-17 13:11:52,712 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.56, Spatial_loss 1.85, Flat_loss 0.33, Train_acc 86.65, Test_acc 29.08
2025-02-17 13:11:55,461 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.58, Spatial_loss 1.86, Flat_loss 0.33, Train_acc 85.47, Test_acc 26.49
2025-02-17 13:11:58,149 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.59, Spatial_loss 1.86, Flat_loss 0.34, Train_acc 84.76, Test_acc 27.60
2025-02-17 13:12:00,898 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.58, Spatial_loss 1.88, Flat_loss 0.33, Train_acc 85.20, Test_acc 29.57
2025-02-17 13:12:03,654 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.56, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 86.79, Test_acc 27.10
2025-02-17 13:12:06,327 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.56, Spatial_loss 1.86, Flat_loss 0.34, Train_acc 86.62, Test_acc 30.30
2025-02-17 13:12:09,064 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.57, Spatial_loss 1.81, Flat_loss 0.33, Train_acc 85.79, Test_acc 29.67
2025-02-17 13:12:11,713 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.54, Spatial_loss 1.83, Flat_loss 0.33, Train_acc 87.20, Test_acc 28.93
2025-02-17 13:12:14,411 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.56, Spatial_loss 1.83, Flat_loss 0.33, Train_acc 86.26, Test_acc 27.68
2025-02-17 13:12:17,109 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.54, Spatial_loss 1.85, Flat_loss 0.33, Train_acc 86.39, Test_acc 27.27
2025-02-17 13:12:19,777 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.52, Spatial_loss 1.78, Flat_loss 0.32, Train_acc 87.42, Test_acc 27.06
2025-02-17 13:12:22,449 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.52, Spatial_loss 1.78, Flat_loss 0.32, Train_acc 87.52, Test_acc 27.08
2025-02-17 13:12:25,171 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.54, Spatial_loss 1.77, Flat_loss 0.33, Train_acc 86.74, Test_acc 23.31
2025-02-17 13:12:27,989 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.54, Spatial_loss 1.79, Flat_loss 0.33, Train_acc 86.58, Test_acc 27.62
2025-02-17 13:12:30,691 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.54, Spatial_loss 1.80, Flat_loss 0.33, Train_acc 86.89, Test_acc 26.14
2025-02-17 13:12:33,466 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.50, Spatial_loss 1.73, Flat_loss 0.33, Train_acc 88.50, Test_acc 27.52
2025-02-17 13:12:36,235 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.48, Spatial_loss 1.67, Flat_loss 0.32, Train_acc 88.42, Test_acc 28.00
2025-02-17 13:12:39,003 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.47, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 88.79, Test_acc 22.34
2025-02-17 13:12:41,729 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.47, Spatial_loss 1.75, Flat_loss 0.32, Train_acc 88.92, Test_acc 29.72
2025-02-17 13:12:44,411 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.32, Train_acc 87.45, Test_acc 26.18
2025-02-17 13:12:47,103 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.49, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 88.68, Test_acc 24.60
2025-02-17 13:12:49,801 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.47, Spatial_loss 1.66, Flat_loss 0.32, Train_acc 88.45, Test_acc 28.31
2025-02-17 13:12:52,444 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.45, Spatial_loss 1.72, Flat_loss 0.32, Train_acc 89.79, Test_acc 28.91
2025-02-17 13:12:55,160 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.46, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 89.45, Test_acc 25.37
2025-02-17 13:12:57,846 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.31, Train_acc 89.06, Test_acc 27.16
2025-02-17 13:13:00,539 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.48, Spatial_loss 1.67, Flat_loss 0.32, Train_acc 88.58, Test_acc 27.21
2025-02-17 13:13:03,367 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.47, Spatial_loss 1.75, Flat_loss 0.32, Train_acc 89.02, Test_acc 25.51
2025-02-17 13:13:06,033 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.42, Spatial_loss 1.65, Flat_loss 0.31, Train_acc 90.76, Test_acc 27.52
2025-02-17 13:13:08,819 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.45, Spatial_loss 1.60, Flat_loss 0.31, Train_acc 89.15, Test_acc 31.31
2025-02-17 13:13:11,518 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.42, Spatial_loss 1.63, Flat_loss 0.31, Train_acc 90.74, Test_acc 27.06
2025-02-17 13:13:14,214 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.44, Spatial_loss 1.61, Flat_loss 0.31, Train_acc 89.68, Test_acc 25.76
2025-02-17 13:13:16,878 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.42, Spatial_loss 1.64, Flat_loss 0.31, Train_acc 90.65, Test_acc 31.29
2025-02-17 13:13:19,576 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.40, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 91.00, Test_acc 26.63
2025-02-17 13:13:22,345 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.39, Spatial_loss 1.61, Flat_loss 0.30, Train_acc 91.52, Test_acc 30.21
2025-02-17 13:13:25,082 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.39, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 91.48, Test_acc 29.32
2025-02-17 13:13:27,850 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.40, Spatial_loss 1.53, Flat_loss 0.30, Train_acc 91.26, Test_acc 30.18
2025-02-17 13:13:30,546 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.31, Train_acc 90.67, Test_acc 26.71
2025-02-17 13:13:33,265 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.39, Spatial_loss 1.59, Flat_loss 0.31, Train_acc 91.56, Test_acc 30.48
2025-02-17 13:13:35,932 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.40, Spatial_loss 1.59, Flat_loss 0.30, Train_acc 91.09, Test_acc 21.99
2025-02-17 13:13:38,677 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.40, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 91.12, Test_acc 29.06
2025-02-17 13:13:41,457 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.38, Spatial_loss 1.52, Flat_loss 0.30, Train_acc 92.12, Test_acc 30.64
2025-02-17 13:13:44,256 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.36, Spatial_loss 1.51, Flat_loss 0.29, Train_acc 92.85, Test_acc 31.09
2025-02-17 13:13:46,955 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.30, Train_acc 92.88, Test_acc 26.89
2025-02-17 13:13:49,749 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.29, Train_acc 93.26, Test_acc 31.17
2025-02-17 13:13:52,563 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.29, Train_acc 93.64, Test_acc 27.77
2025-02-17 13:13:55,351 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.29, Train_acc 93.47, Test_acc 26.21
2025-02-17 13:13:58,178 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.34, Spatial_loss 1.48, Flat_loss 0.29, Train_acc 93.33, Test_acc 29.54
2025-02-17 13:14:00,979 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 93.12, Test_acc 28.74
2025-02-17 13:14:03,750 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.29, Train_acc 93.70, Test_acc 29.10
2025-02-17 13:14:06,527 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.43, Flat_loss 0.28, Train_acc 93.64, Test_acc 28.73
2025-02-17 13:14:09,269 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.28, Train_acc 93.97, Test_acc 29.39
2025-02-17 13:14:12,088 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.32, Spatial_loss 1.42, Flat_loss 0.28, Train_acc 93.76, Test_acc 27.72
2025-02-17 13:14:14,881 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.34, Spatial_loss 1.41, Flat_loss 0.28, Train_acc 93.14, Test_acc 27.18
2025-02-17 13:14:17,621 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.32, Spatial_loss 1.42, Flat_loss 0.28, Train_acc 93.74, Test_acc 29.20
2025-02-17 13:14:20,384 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.27, Train_acc 94.71, Test_acc 30.30
2025-02-17 13:14:23,220 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.28, Train_acc 94.67, Test_acc 29.46
2025-02-17 13:14:25,888 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.31, Spatial_loss 1.33, Flat_loss 0.27, Train_acc 94.26, Test_acc 26.66
2025-02-17 13:14:28,613 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.28, Spatial_loss 1.37, Flat_loss 0.28, Train_acc 95.29, Test_acc 29.39
2025-02-17 13:14:31,360 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.27, Train_acc 95.17, Test_acc 32.29
2025-02-17 13:14:34,142 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.28, Spatial_loss 1.31, Flat_loss 0.27, Train_acc 95.15, Test_acc 29.16
2025-02-17 13:14:36,963 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 1.30, Flat_loss 0.27, Train_acc 95.11, Test_acc 31.18
2025-02-17 13:14:39,721 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.28, Spatial_loss 1.28, Flat_loss 0.27, Train_acc 95.32, Test_acc 31.20
2025-02-17 13:14:42,446 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 95.64, Test_acc 30.47
2025-02-17 13:14:45,267 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.27, Spatial_loss 1.28, Flat_loss 0.27, Train_acc 95.74, Test_acc 29.30
2025-02-17 13:14:48,111 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.26, Train_acc 96.11, Test_acc 32.10
2025-02-17 13:14:50,965 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 95.85, Test_acc 31.63
2025-02-17 13:14:53,769 [podnet.py] => Task 8, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.26, Train_acc 95.98, Test_acc 30.92
2025-02-17 13:14:56,572 [podnet.py] => Task 8, Epoch 118/160 (LR 0.01606) => LSC_loss 0.27, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 95.64, Test_acc 30.89
2025-02-17 13:14:59,342 [podnet.py] => Task 8, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 1.25, Flat_loss 0.26, Train_acc 96.00, Test_acc 31.31
2025-02-17 13:15:02,094 [podnet.py] => Task 8, Epoch 120/160 (LR 0.01464) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.26, Train_acc 96.50, Test_acc 31.89
2025-02-17 13:15:04,854 [podnet.py] => Task 8, Epoch 121/160 (LR 0.01396) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.25, Train_acc 96.26, Test_acc 29.88
2025-02-17 13:15:07,600 [podnet.py] => Task 8, Epoch 122/160 (LR 0.01328) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.26, Train_acc 96.55, Test_acc 31.31
2025-02-17 13:15:10,293 [podnet.py] => Task 8, Epoch 123/160 (LR 0.01262) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.26, Train_acc 96.50, Test_acc 31.26
2025-02-17 13:15:13,027 [podnet.py] => Task 8, Epoch 124/160 (LR 0.01198) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.25, Train_acc 96.79, Test_acc 30.96
2025-02-17 13:15:15,842 [podnet.py] => Task 8, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 96.65, Test_acc 31.59
2025-02-17 13:15:18,590 [podnet.py] => Task 8, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 1.13, Flat_loss 0.25, Train_acc 96.92, Test_acc 31.53
2025-02-17 13:15:21,392 [podnet.py] => Task 8, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 97.03, Test_acc 29.72
2025-02-17 13:15:24,194 [podnet.py] => Task 8, Epoch 128/160 (LR 0.00955) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.25, Train_acc 96.65, Test_acc 28.67
2025-02-17 13:15:26,980 [podnet.py] => Task 8, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 96.85, Test_acc 31.19
2025-02-17 13:15:29,736 [podnet.py] => Task 8, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 97.14, Test_acc 30.89
2025-02-17 13:15:32,545 [podnet.py] => Task 8, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.24, Train_acc 97.48, Test_acc 31.63
2025-02-17 13:15:35,345 [podnet.py] => Task 8, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.24, Train_acc 97.47, Test_acc 31.37
2025-02-17 13:15:38,106 [podnet.py] => Task 8, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.24, Train_acc 97.45, Test_acc 31.63
2025-02-17 13:15:40,789 [podnet.py] => Task 8, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.24, Train_acc 97.24, Test_acc 30.86
2025-02-17 13:15:43,538 [podnet.py] => Task 8, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.24, Train_acc 97.89, Test_acc 31.46
2025-02-17 13:15:46,322 [podnet.py] => Task 8, Epoch 136/160 (LR 0.00545) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.24, Train_acc 97.38, Test_acc 31.76
2025-02-17 13:15:49,093 [podnet.py] => Task 8, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.24, Train_acc 97.62, Test_acc 31.96
2025-02-17 13:15:51,854 [podnet.py] => Task 8, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.24, Train_acc 97.67, Test_acc 32.14
2025-02-17 13:15:54,551 [podnet.py] => Task 8, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.24, Train_acc 97.44, Test_acc 31.54
2025-02-17 13:15:57,319 [podnet.py] => Task 8, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.24, Train_acc 98.17, Test_acc 31.80
2025-02-17 13:16:00,103 [podnet.py] => Task 8, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.24, Train_acc 98.02, Test_acc 31.60
2025-02-17 13:16:02,890 [podnet.py] => Task 8, Epoch 142/160 (LR 0.00309) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.24, Train_acc 97.92, Test_acc 31.62
2025-02-17 13:16:05,703 [podnet.py] => Task 8, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.24, Train_acc 98.11, Test_acc 31.87
2025-02-17 13:16:08,500 [podnet.py] => Task 8, Epoch 144/160 (LR 0.00245) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.23, Train_acc 97.86, Test_acc 32.08
2025-02-17 13:16:11,252 [podnet.py] => Task 8, Epoch 145/160 (LR 0.00215) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.23, Train_acc 97.58, Test_acc 32.07
2025-02-17 13:16:14,025 [podnet.py] => Task 8, Epoch 146/160 (LR 0.00188) => LSC_loss 0.21, Spatial_loss 1.04, Flat_loss 0.24, Train_acc 97.74, Test_acc 31.99
2025-02-17 13:16:16,816 [podnet.py] => Task 8, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.24, Train_acc 97.95, Test_acc 32.01
2025-02-17 13:16:19,550 [podnet.py] => Task 8, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.23, Train_acc 97.95, Test_acc 32.16
2025-02-17 13:16:22,328 [podnet.py] => Task 8, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.23, Train_acc 97.50, Test_acc 31.79
2025-02-17 13:16:25,083 [podnet.py] => Task 8, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 97.97, Test_acc 31.82
2025-02-17 13:16:27,834 [podnet.py] => Task 8, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 98.02, Test_acc 31.83
2025-02-17 13:16:30,510 [podnet.py] => Task 8, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.23, Train_acc 98.27, Test_acc 31.90
2025-02-17 13:16:33,216 [podnet.py] => Task 8, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.23, Train_acc 98.06, Test_acc 31.67
2025-02-17 13:16:35,893 [podnet.py] => Task 8, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 98.05, Test_acc 31.91
2025-02-17 13:16:38,644 [podnet.py] => Task 8, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.23, Train_acc 97.98, Test_acc 31.83
2025-02-17 13:16:41,320 [podnet.py] => Task 8, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 0.98, Flat_loss 0.23, Train_acc 97.82, Test_acc 31.88
2025-02-17 13:16:44,039 [podnet.py] => Task 8, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 0.97, Flat_loss 0.23, Train_acc 98.27, Test_acc 31.91
2025-02-17 13:16:46,747 [podnet.py] => Task 8, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.23, Train_acc 98.26, Test_acc 31.83
2025-02-17 13:16:49,352 [podnet.py] => Task 8, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 98.03, Test_acc 31.86
2025-02-17 13:16:52,053 [podnet.py] => Task 8, Epoch 160/160 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.23, Train_acc 97.83, Test_acc 32.19
2025-02-17 13:16:52,055 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 13:16:52,055 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:17:25,966 [podnet.py] => The size of finetune dataset: 1800
2025-02-17 13:17:27,564 [podnet.py] => Task 8, Epoch 1/20 (LR 0.00497) => LSC_loss 0.38, Spatial_loss 1.20, Flat_loss 0.18, Train_acc 95.67, Test_acc 36.87
2025-02-17 13:17:29,132 [podnet.py] => Task 8, Epoch 2/20 (LR 0.00488) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.17, Train_acc 96.44, Test_acc 35.46
2025-02-17 13:17:30,719 [podnet.py] => Task 8, Epoch 3/20 (LR 0.00473) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.16, Train_acc 98.11, Test_acc 34.67
2025-02-17 13:17:32,328 [podnet.py] => Task 8, Epoch 4/20 (LR 0.00452) => LSC_loss 0.24, Spatial_loss 1.30, Flat_loss 0.16, Train_acc 97.17, Test_acc 35.29
2025-02-17 13:17:33,859 [podnet.py] => Task 8, Epoch 5/20 (LR 0.00427) => LSC_loss 0.21, Spatial_loss 1.21, Flat_loss 0.15, Train_acc 98.22, Test_acc 35.93
2025-02-17 13:17:35,469 [podnet.py] => Task 8, Epoch 6/20 (LR 0.00397) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.15, Train_acc 98.67, Test_acc 35.56
2025-02-17 13:17:37,093 [podnet.py] => Task 8, Epoch 7/20 (LR 0.00363) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 97.94, Test_acc 34.64
2025-02-17 13:17:38,743 [podnet.py] => Task 8, Epoch 8/20 (LR 0.00327) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.14, Train_acc 97.89, Test_acc 35.13
2025-02-17 13:17:40,338 [podnet.py] => Task 8, Epoch 9/20 (LR 0.00289) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 98.28, Test_acc 36.28
2025-02-17 13:17:41,953 [podnet.py] => Task 8, Epoch 10/20 (LR 0.00250) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.14, Train_acc 98.67, Test_acc 35.88
2025-02-17 13:17:43,589 [podnet.py] => Task 8, Epoch 11/20 (LR 0.00211) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.14, Train_acc 98.22, Test_acc 35.41
2025-02-17 13:17:45,206 [podnet.py] => Task 8, Epoch 12/20 (LR 0.00173) => LSC_loss 0.16, Spatial_loss 1.14, Flat_loss 0.14, Train_acc 98.78, Test_acc 35.96
2025-02-17 13:17:46,827 [podnet.py] => Task 8, Epoch 13/20 (LR 0.00137) => LSC_loss 0.21, Spatial_loss 1.25, Flat_loss 0.15, Train_acc 98.78, Test_acc 35.76
2025-02-17 13:17:48,437 [podnet.py] => Task 8, Epoch 14/20 (LR 0.00103) => LSC_loss 0.18, Spatial_loss 1.14, Flat_loss 0.14, Train_acc 98.44, Test_acc 35.57
2025-02-17 13:17:50,068 [podnet.py] => Task 8, Epoch 15/20 (LR 0.00073) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.14, Train_acc 98.78, Test_acc 35.66
2025-02-17 13:17:51,695 [podnet.py] => Task 8, Epoch 16/20 (LR 0.00048) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.13, Train_acc 98.61, Test_acc 35.90
2025-02-17 13:17:53,349 [podnet.py] => Task 8, Epoch 17/20 (LR 0.00027) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.13, Train_acc 99.06, Test_acc 35.47
2025-02-17 13:17:54,988 [podnet.py] => Task 8, Epoch 18/20 (LR 0.00012) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.13, Train_acc 99.06, Test_acc 35.56
2025-02-17 13:17:56,592 [podnet.py] => Task 8, Epoch 19/20 (LR 0.00003) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 99.06, Test_acc 35.81
2025-02-17 13:17:58,223 [podnet.py] => Task 8, Epoch 20/20 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.13, Train_acc 99.00, Test_acc 35.63
2025-02-17 13:17:58,225 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:18:34,200 [podnet.py] => Exemplar size: 1800
2025-02-17 13:18:34,200 [trainer.py] => CNN: {'total': 35.63, '00-09': 47.0, '10-19': 12.3, '20-29': 26.4, '30-39': 24.3, '40-49': 39.1, '50-59': 24.2, '60-69': 36.7, '70-79': 44.2, '80-89': 66.5, 'old': 31.78, 'new': 66.5}
2025-02-17 13:18:34,201 [trainer.py] => NME: {'total': 36.02, '00-09': 57.9, '10-19': 12.5, '20-29': 28.4, '30-39': 24.2, '40-49': 37.6, '50-59': 23.1, '60-69': 40.3, '70-79': 42.1, '80-89': 58.1, 'old': 33.26, 'new': 58.1}
2025-02-17 13:18:34,201 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2, 43.93, 41.94, 38.49, 35.63]
2025-02-17 13:18:34,202 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22, 74.43, 72.57, 69.22, 65.68]
2025-02-17 13:18:34,202 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42, 43.8, 41.47, 38.49, 36.02]
2025-02-17 13:18:34,202 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78, 73.92, 71.16, 68.14, 65.28]

2025-02-17 13:18:34,203 [trainer.py] => Average Accuracy (CNN): 52.98777777777778
2025-02-17 13:18:34,203 [trainer.py] => Average Accuracy (NME): 52.912222222222226
2025-02-17 13:18:34,204 [trainer.py] => All params: 523857
2025-02-17 13:18:34,204 [trainer.py] => Trainable params: 523857
2025-02-17 13:18:34,205 [podnet.py] => Learning on 90-100
2025-02-17 13:18:34,257 [podnet.py] => Adaptive factor: 3.1622776601683795
2025-02-17 13:18:37,056 [podnet.py] => Task 9, Epoch 1/160 (LR 0.09999) => LSC_loss 2.92, Spatial_loss 3.49, Flat_loss 1.26, Train_acc 41.97, Test_acc 15.02
2025-02-17 13:18:39,884 [podnet.py] => Task 9, Epoch 2/160 (LR 0.09996) => LSC_loss 1.73, Spatial_loss 2.94, Flat_loss 0.74, Train_acc 54.47, Test_acc 21.22
2025-02-17 13:18:42,693 [podnet.py] => Task 9, Epoch 3/160 (LR 0.09991) => LSC_loss 1.56, Spatial_loss 2.78, Flat_loss 0.60, Train_acc 58.29, Test_acc 17.79
2025-02-17 13:18:45,523 [podnet.py] => Task 9, Epoch 4/160 (LR 0.09985) => LSC_loss 1.40, Spatial_loss 2.52, Flat_loss 0.52, Train_acc 62.13, Test_acc 15.68
2025-02-17 13:18:48,336 [podnet.py] => Task 9, Epoch 5/160 (LR 0.09976) => LSC_loss 1.35, Spatial_loss 2.55, Flat_loss 0.49, Train_acc 63.50, Test_acc 27.25
2025-02-17 13:18:51,177 [podnet.py] => Task 9, Epoch 6/160 (LR 0.09965) => LSC_loss 1.30, Spatial_loss 2.46, Flat_loss 0.46, Train_acc 65.01, Test_acc 20.88
2025-02-17 13:18:54,038 [podnet.py] => Task 9, Epoch 7/160 (LR 0.09953) => LSC_loss 1.33, Spatial_loss 2.50, Flat_loss 0.46, Train_acc 64.74, Test_acc 17.02
2025-02-17 13:18:56,925 [podnet.py] => Task 9, Epoch 8/160 (LR 0.09938) => LSC_loss 1.32, Spatial_loss 2.55, Flat_loss 0.47, Train_acc 64.81, Test_acc 21.66
2025-02-17 13:18:59,782 [podnet.py] => Task 9, Epoch 9/160 (LR 0.09922) => LSC_loss 1.21, Spatial_loss 2.35, Flat_loss 0.43, Train_acc 68.32, Test_acc 25.28
2025-02-17 13:19:02,623 [podnet.py] => Task 9, Epoch 10/160 (LR 0.09904) => LSC_loss 1.20, Spatial_loss 2.45, Flat_loss 0.43, Train_acc 68.34, Test_acc 15.86
2025-02-17 13:19:05,508 [podnet.py] => Task 9, Epoch 11/160 (LR 0.09884) => LSC_loss 1.16, Spatial_loss 2.46, Flat_loss 0.43, Train_acc 69.44, Test_acc 25.01
2025-02-17 13:19:08,410 [podnet.py] => Task 9, Epoch 12/160 (LR 0.09862) => LSC_loss 1.11, Spatial_loss 2.24, Flat_loss 0.41, Train_acc 71.19, Test_acc 25.16
2025-02-17 13:19:11,264 [podnet.py] => Task 9, Epoch 13/160 (LR 0.09838) => LSC_loss 1.16, Spatial_loss 2.34, Flat_loss 0.43, Train_acc 69.22, Test_acc 23.90
2025-02-17 13:19:14,043 [podnet.py] => Task 9, Epoch 14/160 (LR 0.09812) => LSC_loss 1.11, Spatial_loss 2.36, Flat_loss 0.43, Train_acc 70.51, Test_acc 24.42
2025-02-17 13:19:16,914 [podnet.py] => Task 9, Epoch 15/160 (LR 0.09785) => LSC_loss 1.08, Spatial_loss 2.28, Flat_loss 0.41, Train_acc 71.41, Test_acc 23.17
2025-02-17 13:19:19,717 [podnet.py] => Task 9, Epoch 16/160 (LR 0.09755) => LSC_loss 1.09, Spatial_loss 2.33, Flat_loss 0.42, Train_acc 71.12, Test_acc 20.20
2025-02-17 13:19:22,486 [podnet.py] => Task 9, Epoch 17/160 (LR 0.09724) => LSC_loss 1.02, Spatial_loss 2.26, Flat_loss 0.41, Train_acc 73.15, Test_acc 21.78
2025-02-17 13:19:25,322 [podnet.py] => Task 9, Epoch 18/160 (LR 0.09691) => LSC_loss 1.07, Spatial_loss 2.29, Flat_loss 0.43, Train_acc 71.81, Test_acc 21.67
2025-02-17 13:19:28,213 [podnet.py] => Task 9, Epoch 19/160 (LR 0.09656) => LSC_loss 1.04, Spatial_loss 2.38, Flat_loss 0.43, Train_acc 71.90, Test_acc 24.64
2025-02-17 13:19:31,070 [podnet.py] => Task 9, Epoch 20/160 (LR 0.09619) => LSC_loss 0.98, Spatial_loss 2.22, Flat_loss 0.40, Train_acc 73.85, Test_acc 24.57
2025-02-17 13:19:33,905 [podnet.py] => Task 9, Epoch 21/160 (LR 0.09581) => LSC_loss 0.98, Spatial_loss 2.18, Flat_loss 0.40, Train_acc 74.03, Test_acc 24.65
2025-02-17 13:19:36,755 [podnet.py] => Task 9, Epoch 22/160 (LR 0.09541) => LSC_loss 1.00, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 74.47, Test_acc 27.02
2025-02-17 13:19:39,551 [podnet.py] => Task 9, Epoch 23/160 (LR 0.09499) => LSC_loss 0.98, Spatial_loss 2.23, Flat_loss 0.41, Train_acc 74.35, Test_acc 19.83
2025-02-17 13:19:42,359 [podnet.py] => Task 9, Epoch 24/160 (LR 0.09455) => LSC_loss 0.96, Spatial_loss 2.25, Flat_loss 0.41, Train_acc 74.74, Test_acc 21.40
2025-02-17 13:19:45,198 [podnet.py] => Task 9, Epoch 25/160 (LR 0.09410) => LSC_loss 0.97, Spatial_loss 2.31, Flat_loss 0.41, Train_acc 74.66, Test_acc 24.72
2025-02-17 13:19:47,973 [podnet.py] => Task 9, Epoch 26/160 (LR 0.09362) => LSC_loss 0.95, Spatial_loss 2.31, Flat_loss 0.41, Train_acc 75.00, Test_acc 21.35
2025-02-17 13:19:50,834 [podnet.py] => Task 9, Epoch 27/160 (LR 0.09314) => LSC_loss 0.95, Spatial_loss 2.25, Flat_loss 0.41, Train_acc 74.40, Test_acc 26.78
2025-02-17 13:19:53,674 [podnet.py] => Task 9, Epoch 28/160 (LR 0.09263) => LSC_loss 0.93, Spatial_loss 2.20, Flat_loss 0.40, Train_acc 75.12, Test_acc 19.19
2025-02-17 13:19:56,448 [podnet.py] => Task 9, Epoch 29/160 (LR 0.09211) => LSC_loss 0.97, Spatial_loss 2.25, Flat_loss 0.42, Train_acc 74.66, Test_acc 23.91
2025-02-17 13:19:59,297 [podnet.py] => Task 9, Epoch 30/160 (LR 0.09157) => LSC_loss 0.94, Spatial_loss 2.27, Flat_loss 0.42, Train_acc 74.49, Test_acc 25.79
2025-02-17 13:20:02,095 [podnet.py] => Task 9, Epoch 31/160 (LR 0.09102) => LSC_loss 0.91, Spatial_loss 2.23, Flat_loss 0.40, Train_acc 76.16, Test_acc 25.84
2025-02-17 13:20:04,956 [podnet.py] => Task 9, Epoch 32/160 (LR 0.09045) => LSC_loss 0.92, Spatial_loss 2.22, Flat_loss 0.41, Train_acc 76.04, Test_acc 25.11
2025-02-17 13:20:07,821 [podnet.py] => Task 9, Epoch 33/160 (LR 0.08987) => LSC_loss 0.88, Spatial_loss 2.17, Flat_loss 0.40, Train_acc 76.69, Test_acc 25.88
2025-02-17 13:20:10,613 [podnet.py] => Task 9, Epoch 34/160 (LR 0.08927) => LSC_loss 0.88, Spatial_loss 2.22, Flat_loss 0.40, Train_acc 76.93, Test_acc 25.87
2025-02-17 13:20:13,451 [podnet.py] => Task 9, Epoch 35/160 (LR 0.08865) => LSC_loss 0.90, Spatial_loss 2.26, Flat_loss 0.42, Train_acc 76.44, Test_acc 27.88
2025-02-17 13:20:16,270 [podnet.py] => Task 9, Epoch 36/160 (LR 0.08802) => LSC_loss 0.89, Spatial_loss 2.17, Flat_loss 0.41, Train_acc 76.59, Test_acc 21.44
2025-02-17 13:20:19,031 [podnet.py] => Task 9, Epoch 37/160 (LR 0.08738) => LSC_loss 0.91, Spatial_loss 2.21, Flat_loss 0.41, Train_acc 76.24, Test_acc 26.82
2025-02-17 13:20:21,869 [podnet.py] => Task 9, Epoch 38/160 (LR 0.08672) => LSC_loss 0.87, Spatial_loss 2.22, Flat_loss 0.41, Train_acc 77.19, Test_acc 27.27
2025-02-17 13:20:24,705 [podnet.py] => Task 9, Epoch 39/160 (LR 0.08604) => LSC_loss 0.88, Spatial_loss 2.24, Flat_loss 0.40, Train_acc 76.66, Test_acc 23.36
2025-02-17 13:20:27,466 [podnet.py] => Task 9, Epoch 40/160 (LR 0.08536) => LSC_loss 0.89, Spatial_loss 2.23, Flat_loss 0.42, Train_acc 75.81, Test_acc 25.26
2025-02-17 13:20:30,379 [podnet.py] => Task 9, Epoch 41/160 (LR 0.08465) => LSC_loss 0.82, Spatial_loss 2.15, Flat_loss 0.40, Train_acc 78.81, Test_acc 23.22
2025-02-17 13:20:33,314 [podnet.py] => Task 9, Epoch 42/160 (LR 0.08394) => LSC_loss 0.81, Spatial_loss 2.13, Flat_loss 0.40, Train_acc 78.87, Test_acc 23.39
2025-02-17 13:20:36,130 [podnet.py] => Task 9, Epoch 43/160 (LR 0.08321) => LSC_loss 0.82, Spatial_loss 2.17, Flat_loss 0.40, Train_acc 78.59, Test_acc 24.87
2025-02-17 13:20:38,914 [podnet.py] => Task 9, Epoch 44/160 (LR 0.08247) => LSC_loss 0.84, Spatial_loss 2.22, Flat_loss 0.41, Train_acc 77.56, Test_acc 26.21
2025-02-17 13:20:41,743 [podnet.py] => Task 9, Epoch 45/160 (LR 0.08172) => LSC_loss 0.81, Spatial_loss 2.18, Flat_loss 0.40, Train_acc 79.53, Test_acc 23.85
2025-02-17 13:20:44,574 [podnet.py] => Task 9, Epoch 46/160 (LR 0.08095) => LSC_loss 0.79, Spatial_loss 2.10, Flat_loss 0.40, Train_acc 79.57, Test_acc 22.93
2025-02-17 13:20:47,416 [podnet.py] => Task 9, Epoch 47/160 (LR 0.08018) => LSC_loss 0.81, Spatial_loss 2.19, Flat_loss 0.41, Train_acc 78.85, Test_acc 22.98
2025-02-17 13:20:50,222 [podnet.py] => Task 9, Epoch 48/160 (LR 0.07939) => LSC_loss 0.75, Spatial_loss 2.08, Flat_loss 0.39, Train_acc 80.53, Test_acc 27.03
2025-02-17 13:20:53,020 [podnet.py] => Task 9, Epoch 49/160 (LR 0.07859) => LSC_loss 0.76, Spatial_loss 2.14, Flat_loss 0.39, Train_acc 81.04, Test_acc 26.26
2025-02-17 13:20:55,935 [podnet.py] => Task 9, Epoch 50/160 (LR 0.07778) => LSC_loss 0.78, Spatial_loss 2.11, Flat_loss 0.40, Train_acc 79.57, Test_acc 24.96
2025-02-17 13:20:58,790 [podnet.py] => Task 9, Epoch 51/160 (LR 0.07696) => LSC_loss 0.78, Spatial_loss 2.12, Flat_loss 0.40, Train_acc 80.03, Test_acc 27.25
2025-02-17 13:21:01,679 [podnet.py] => Task 9, Epoch 52/160 (LR 0.07612) => LSC_loss 0.78, Spatial_loss 2.10, Flat_loss 0.40, Train_acc 79.63, Test_acc 25.29
2025-02-17 13:21:04,543 [podnet.py] => Task 9, Epoch 53/160 (LR 0.07528) => LSC_loss 0.74, Spatial_loss 2.13, Flat_loss 0.40, Train_acc 80.53, Test_acc 21.99
2025-02-17 13:21:07,451 [podnet.py] => Task 9, Epoch 54/160 (LR 0.07443) => LSC_loss 0.79, Spatial_loss 2.10, Flat_loss 0.40, Train_acc 79.65, Test_acc 21.54
2025-02-17 13:21:10,264 [podnet.py] => Task 9, Epoch 55/160 (LR 0.07357) => LSC_loss 0.78, Spatial_loss 2.13, Flat_loss 0.41, Train_acc 79.40, Test_acc 26.74
2025-02-17 13:21:13,061 [podnet.py] => Task 9, Epoch 56/160 (LR 0.07270) => LSC_loss 0.71, Spatial_loss 2.09, Flat_loss 0.39, Train_acc 81.87, Test_acc 20.60
2025-02-17 13:21:15,865 [podnet.py] => Task 9, Epoch 57/160 (LR 0.07182) => LSC_loss 0.74, Spatial_loss 2.07, Flat_loss 0.39, Train_acc 80.99, Test_acc 22.67
2025-02-17 13:21:18,701 [podnet.py] => Task 9, Epoch 58/160 (LR 0.07093) => LSC_loss 0.75, Spatial_loss 2.09, Flat_loss 0.40, Train_acc 80.93, Test_acc 24.08
2025-02-17 13:21:21,505 [podnet.py] => Task 9, Epoch 59/160 (LR 0.07004) => LSC_loss 0.74, Spatial_loss 2.08, Flat_loss 0.39, Train_acc 81.13, Test_acc 28.00
2025-02-17 13:21:24,367 [podnet.py] => Task 9, Epoch 60/160 (LR 0.06913) => LSC_loss 0.72, Spatial_loss 2.04, Flat_loss 0.39, Train_acc 81.88, Test_acc 23.56
2025-02-17 13:21:27,307 [podnet.py] => Task 9, Epoch 61/160 (LR 0.06822) => LSC_loss 0.74, Spatial_loss 2.06, Flat_loss 0.40, Train_acc 81.25, Test_acc 26.33
2025-02-17 13:21:30,179 [podnet.py] => Task 9, Epoch 62/160 (LR 0.06731) => LSC_loss 0.73, Spatial_loss 2.10, Flat_loss 0.41, Train_acc 81.03, Test_acc 27.01
2025-02-17 13:21:33,092 [podnet.py] => Task 9, Epoch 63/160 (LR 0.06638) => LSC_loss 0.71, Spatial_loss 2.07, Flat_loss 0.39, Train_acc 81.91, Test_acc 26.43
2025-02-17 13:21:35,936 [podnet.py] => Task 9, Epoch 64/160 (LR 0.06545) => LSC_loss 0.71, Spatial_loss 2.01, Flat_loss 0.40, Train_acc 81.75, Test_acc 21.43
2025-02-17 13:21:38,780 [podnet.py] => Task 9, Epoch 65/160 (LR 0.06451) => LSC_loss 0.69, Spatial_loss 1.99, Flat_loss 0.39, Train_acc 82.37, Test_acc 23.44
2025-02-17 13:21:41,674 [podnet.py] => Task 9, Epoch 66/160 (LR 0.06357) => LSC_loss 0.67, Spatial_loss 2.01, Flat_loss 0.39, Train_acc 83.03, Test_acc 19.85
2025-02-17 13:21:44,570 [podnet.py] => Task 9, Epoch 67/160 (LR 0.06262) => LSC_loss 0.67, Spatial_loss 1.95, Flat_loss 0.38, Train_acc 83.31, Test_acc 26.94
2025-02-17 13:21:47,486 [podnet.py] => Task 9, Epoch 68/160 (LR 0.06167) => LSC_loss 0.72, Spatial_loss 2.08, Flat_loss 0.40, Train_acc 81.38, Test_acc 28.40
2025-02-17 13:21:50,359 [podnet.py] => Task 9, Epoch 69/160 (LR 0.06072) => LSC_loss 0.66, Spatial_loss 2.02, Flat_loss 0.39, Train_acc 83.32, Test_acc 29.00
2025-02-17 13:21:53,284 [podnet.py] => Task 9, Epoch 70/160 (LR 0.05975) => LSC_loss 0.60, Spatial_loss 1.95, Flat_loss 0.37, Train_acc 85.13, Test_acc 26.69
2025-02-17 13:21:56,218 [podnet.py] => Task 9, Epoch 71/160 (LR 0.05879) => LSC_loss 0.60, Spatial_loss 1.96, Flat_loss 0.37, Train_acc 84.74, Test_acc 28.25
2025-02-17 13:21:59,146 [podnet.py] => Task 9, Epoch 72/160 (LR 0.05782) => LSC_loss 0.62, Spatial_loss 1.96, Flat_loss 0.38, Train_acc 84.44, Test_acc 26.20
2025-02-17 13:22:02,059 [podnet.py] => Task 9, Epoch 73/160 (LR 0.05685) => LSC_loss 0.67, Spatial_loss 1.98, Flat_loss 0.38, Train_acc 82.84, Test_acc 27.98
2025-02-17 13:22:04,970 [podnet.py] => Task 9, Epoch 74/160 (LR 0.05588) => LSC_loss 0.61, Spatial_loss 1.97, Flat_loss 0.38, Train_acc 84.76, Test_acc 25.90
2025-02-17 13:22:07,827 [podnet.py] => Task 9, Epoch 75/160 (LR 0.05490) => LSC_loss 0.58, Spatial_loss 1.92, Flat_loss 0.37, Train_acc 85.63, Test_acc 27.42
2025-02-17 13:22:10,768 [podnet.py] => Task 9, Epoch 76/160 (LR 0.05392) => LSC_loss 0.59, Spatial_loss 1.90, Flat_loss 0.37, Train_acc 85.12, Test_acc 25.80
2025-02-17 13:22:13,697 [podnet.py] => Task 9, Epoch 77/160 (LR 0.05294) => LSC_loss 0.59, Spatial_loss 1.86, Flat_loss 0.37, Train_acc 85.72, Test_acc 25.39
2025-02-17 13:22:16,641 [podnet.py] => Task 9, Epoch 78/160 (LR 0.05196) => LSC_loss 0.58, Spatial_loss 1.87, Flat_loss 0.37, Train_acc 85.97, Test_acc 26.35
2025-02-17 13:22:19,445 [podnet.py] => Task 9, Epoch 79/160 (LR 0.05098) => LSC_loss 0.58, Spatial_loss 1.91, Flat_loss 0.38, Train_acc 85.93, Test_acc 23.47
2025-02-17 13:22:22,330 [podnet.py] => Task 9, Epoch 80/160 (LR 0.05000) => LSC_loss 0.58, Spatial_loss 1.90, Flat_loss 0.38, Train_acc 85.51, Test_acc 28.58
2025-02-17 13:22:25,238 [podnet.py] => Task 9, Epoch 81/160 (LR 0.04902) => LSC_loss 0.55, Spatial_loss 1.84, Flat_loss 0.36, Train_acc 86.47, Test_acc 26.27
2025-02-17 13:22:28,177 [podnet.py] => Task 9, Epoch 82/160 (LR 0.04804) => LSC_loss 0.59, Spatial_loss 1.88, Flat_loss 0.38, Train_acc 85.10, Test_acc 23.88
2025-02-17 13:22:31,064 [podnet.py] => Task 9, Epoch 83/160 (LR 0.04706) => LSC_loss 0.57, Spatial_loss 1.93, Flat_loss 0.37, Train_acc 86.37, Test_acc 29.44
2025-02-17 13:22:33,951 [podnet.py] => Task 9, Epoch 84/160 (LR 0.04608) => LSC_loss 0.54, Spatial_loss 1.86, Flat_loss 0.37, Train_acc 87.21, Test_acc 28.58
2025-02-17 13:22:36,865 [podnet.py] => Task 9, Epoch 85/160 (LR 0.04510) => LSC_loss 0.55, Spatial_loss 1.85, Flat_loss 0.37, Train_acc 86.34, Test_acc 29.48
2025-02-17 13:22:39,781 [podnet.py] => Task 9, Epoch 86/160 (LR 0.04412) => LSC_loss 0.50, Spatial_loss 1.80, Flat_loss 0.35, Train_acc 88.18, Test_acc 28.89
2025-02-17 13:22:42,658 [podnet.py] => Task 9, Epoch 87/160 (LR 0.04315) => LSC_loss 0.54, Spatial_loss 1.80, Flat_loss 0.37, Train_acc 87.22, Test_acc 25.84
2025-02-17 13:22:45,529 [podnet.py] => Task 9, Epoch 88/160 (LR 0.04218) => LSC_loss 0.51, Spatial_loss 1.80, Flat_loss 0.36, Train_acc 88.18, Test_acc 24.12
2025-02-17 13:22:48,438 [podnet.py] => Task 9, Epoch 89/160 (LR 0.04121) => LSC_loss 0.54, Spatial_loss 1.84, Flat_loss 0.37, Train_acc 86.84, Test_acc 28.76
2025-02-17 13:22:51,362 [podnet.py] => Task 9, Epoch 90/160 (LR 0.04025) => LSC_loss 0.50, Spatial_loss 1.80, Flat_loss 0.36, Train_acc 88.34, Test_acc 26.89
2025-02-17 13:22:54,207 [podnet.py] => Task 9, Epoch 91/160 (LR 0.03928) => LSC_loss 0.49, Spatial_loss 1.80, Flat_loss 0.35, Train_acc 88.97, Test_acc 30.07
2025-02-17 13:22:57,105 [podnet.py] => Task 9, Epoch 92/160 (LR 0.03833) => LSC_loss 0.48, Spatial_loss 1.76, Flat_loss 0.35, Train_acc 88.93, Test_acc 28.75
2025-02-17 13:22:59,928 [podnet.py] => Task 9, Epoch 93/160 (LR 0.03738) => LSC_loss 0.54, Spatial_loss 1.81, Flat_loss 0.36, Train_acc 86.91, Test_acc 29.36
2025-02-17 13:23:02,793 [podnet.py] => Task 9, Epoch 94/160 (LR 0.03643) => LSC_loss 0.50, Spatial_loss 1.78, Flat_loss 0.36, Train_acc 88.72, Test_acc 26.19
2025-02-17 13:23:05,670 [podnet.py] => Task 9, Epoch 95/160 (LR 0.03549) => LSC_loss 0.52, Spatial_loss 1.82, Flat_loss 0.36, Train_acc 87.44, Test_acc 25.14
2025-02-17 13:23:08,569 [podnet.py] => Task 9, Epoch 96/160 (LR 0.03455) => LSC_loss 0.50, Spatial_loss 1.72, Flat_loss 0.35, Train_acc 88.22, Test_acc 32.09
2025-02-17 13:23:11,506 [podnet.py] => Task 9, Epoch 97/160 (LR 0.03362) => LSC_loss 0.45, Spatial_loss 1.72, Flat_loss 0.35, Train_acc 90.19, Test_acc 23.65
2025-02-17 13:23:14,388 [podnet.py] => Task 9, Epoch 98/160 (LR 0.03269) => LSC_loss 0.46, Spatial_loss 1.72, Flat_loss 0.35, Train_acc 89.85, Test_acc 28.09
2025-02-17 13:23:17,289 [podnet.py] => Task 9, Epoch 99/160 (LR 0.03178) => LSC_loss 0.46, Spatial_loss 1.79, Flat_loss 0.35, Train_acc 89.34, Test_acc 29.58
2025-02-17 13:23:20,286 [podnet.py] => Task 9, Epoch 100/160 (LR 0.03087) => LSC_loss 0.42, Spatial_loss 1.69, Flat_loss 0.34, Train_acc 90.94, Test_acc 28.73
2025-02-17 13:23:23,202 [podnet.py] => Task 9, Epoch 101/160 (LR 0.02996) => LSC_loss 0.41, Spatial_loss 1.67, Flat_loss 0.34, Train_acc 90.99, Test_acc 28.64
2025-02-17 13:23:26,174 [podnet.py] => Task 9, Epoch 102/160 (LR 0.02907) => LSC_loss 0.41, Spatial_loss 1.66, Flat_loss 0.33, Train_acc 91.60, Test_acc 26.19
2025-02-17 13:23:29,064 [podnet.py] => Task 9, Epoch 103/160 (LR 0.02818) => LSC_loss 0.44, Spatial_loss 1.69, Flat_loss 0.34, Train_acc 90.53, Test_acc 25.17
2025-02-17 13:23:31,963 [podnet.py] => Task 9, Epoch 104/160 (LR 0.02730) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.35, Train_acc 89.31, Test_acc 29.63
2025-02-17 13:23:34,772 [podnet.py] => Task 9, Epoch 105/160 (LR 0.02643) => LSC_loss 0.44, Spatial_loss 1.65, Flat_loss 0.34, Train_acc 89.97, Test_acc 29.36
2025-02-17 13:23:37,567 [podnet.py] => Task 9, Epoch 106/160 (LR 0.02557) => LSC_loss 0.38, Spatial_loss 1.62, Flat_loss 0.33, Train_acc 91.93, Test_acc 28.51
2025-02-17 13:23:40,377 [podnet.py] => Task 9, Epoch 107/160 (LR 0.02472) => LSC_loss 0.39, Spatial_loss 1.63, Flat_loss 0.33, Train_acc 92.43, Test_acc 28.81
2025-02-17 13:23:43,246 [podnet.py] => Task 9, Epoch 108/160 (LR 0.02388) => LSC_loss 0.42, Spatial_loss 1.65, Flat_loss 0.34, Train_acc 90.46, Test_acc 28.92
2025-02-17 13:23:46,043 [podnet.py] => Task 9, Epoch 109/160 (LR 0.02304) => LSC_loss 0.36, Spatial_loss 1.59, Flat_loss 0.32, Train_acc 92.91, Test_acc 26.63
2025-02-17 13:23:48,897 [podnet.py] => Task 9, Epoch 110/160 (LR 0.02222) => LSC_loss 0.39, Spatial_loss 1.55, Flat_loss 0.33, Train_acc 91.74, Test_acc 30.45
2025-02-17 13:23:51,712 [podnet.py] => Task 9, Epoch 111/160 (LR 0.02141) => LSC_loss 0.39, Spatial_loss 1.57, Flat_loss 0.33, Train_acc 91.85, Test_acc 29.05
2025-02-17 13:23:54,513 [podnet.py] => Task 9, Epoch 112/160 (LR 0.02061) => LSC_loss 0.37, Spatial_loss 1.57, Flat_loss 0.33, Train_acc 92.56, Test_acc 29.14
2025-02-17 13:23:57,355 [podnet.py] => Task 9, Epoch 113/160 (LR 0.01982) => LSC_loss 0.40, Spatial_loss 1.62, Flat_loss 0.33, Train_acc 92.06, Test_acc 30.04
2025-02-17 13:24:00,237 [podnet.py] => Task 9, Epoch 114/160 (LR 0.01905) => LSC_loss 0.38, Spatial_loss 1.58, Flat_loss 0.33, Train_acc 92.06, Test_acc 26.71
2025-02-17 13:24:03,099 [podnet.py] => Task 9, Epoch 115/160 (LR 0.01828) => LSC_loss 0.35, Spatial_loss 1.53, Flat_loss 0.32, Train_acc 92.66, Test_acc 30.84
2025-02-17 13:24:05,935 [podnet.py] => Task 9, Epoch 116/160 (LR 0.01753) => LSC_loss 0.34, Spatial_loss 1.53, Flat_loss 0.31, Train_acc 93.29, Test_acc 32.65
2025-02-17 13:24:08,736 [podnet.py] => Task 9, Epoch 117/160 (LR 0.01679) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.31, Train_acc 93.93, Test_acc 32.31
2025-02-17 13:24:11,618 [podnet.py] => Task 9, Epoch 118/160 (LR 0.01606) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.31, Train_acc 94.25, Test_acc 26.59
2025-02-17 13:24:14,492 [podnet.py] => Task 9, Epoch 119/160 (LR 0.01535) => LSC_loss 0.33, Spatial_loss 1.46, Flat_loss 0.30, Train_acc 94.12, Test_acc 29.50
2025-02-17 13:24:17,300 [podnet.py] => Task 9, Epoch 120/160 (LR 0.01464) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.31, Train_acc 94.04, Test_acc 28.94
2025-02-17 13:24:20,175 [podnet.py] => Task 9, Epoch 121/160 (LR 0.01396) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.31, Train_acc 94.12, Test_acc 28.18
2025-02-17 13:24:23,007 [podnet.py] => Task 9, Epoch 122/160 (LR 0.01328) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.31, Train_acc 94.29, Test_acc 29.82
2025-02-17 13:24:25,773 [podnet.py] => Task 9, Epoch 123/160 (LR 0.01262) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.30, Train_acc 94.84, Test_acc 27.33
2025-02-17 13:24:28,593 [podnet.py] => Task 9, Epoch 124/160 (LR 0.01198) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.30, Train_acc 95.07, Test_acc 30.15
2025-02-17 13:24:31,405 [podnet.py] => Task 9, Epoch 125/160 (LR 0.01135) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.30, Train_acc 94.18, Test_acc 30.62
2025-02-17 13:24:34,193 [podnet.py] => Task 9, Epoch 126/160 (LR 0.01073) => LSC_loss 0.28, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 95.41, Test_acc 30.84
2025-02-17 13:24:37,039 [podnet.py] => Task 9, Epoch 127/160 (LR 0.01013) => LSC_loss 0.31, Spatial_loss 1.36, Flat_loss 0.29, Train_acc 94.91, Test_acc 30.79
2025-02-17 13:24:39,901 [podnet.py] => Task 9, Epoch 128/160 (LR 0.00955) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.30, Train_acc 94.82, Test_acc 31.70
2025-02-17 13:24:42,683 [podnet.py] => Task 9, Epoch 129/160 (LR 0.00898) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.29, Train_acc 95.35, Test_acc 29.37
2025-02-17 13:24:45,539 [podnet.py] => Task 9, Epoch 130/160 (LR 0.00843) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.29, Train_acc 95.87, Test_acc 31.53
2025-02-17 13:24:48,329 [podnet.py] => Task 9, Epoch 131/160 (LR 0.00789) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.29, Train_acc 95.74, Test_acc 30.80
2025-02-17 13:24:51,212 [podnet.py] => Task 9, Epoch 132/160 (LR 0.00737) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.29, Train_acc 95.57, Test_acc 29.99
2025-02-17 13:24:53,967 [podnet.py] => Task 9, Epoch 133/160 (LR 0.00686) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.29, Train_acc 95.90, Test_acc 30.57
2025-02-17 13:24:56,830 [podnet.py] => Task 9, Epoch 134/160 (LR 0.00638) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.29, Train_acc 95.81, Test_acc 29.65
2025-02-17 13:24:59,593 [podnet.py] => Task 9, Epoch 135/160 (LR 0.00590) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.29, Train_acc 95.91, Test_acc 30.97
2025-02-17 13:25:02,363 [podnet.py] => Task 9, Epoch 136/160 (LR 0.00545) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.29, Train_acc 96.21, Test_acc 32.10
2025-02-17 13:25:05,180 [podnet.py] => Task 9, Epoch 137/160 (LR 0.00501) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.29, Train_acc 96.34, Test_acc 31.28
2025-02-17 13:25:07,981 [podnet.py] => Task 9, Epoch 138/160 (LR 0.00459) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.29, Train_acc 96.16, Test_acc 31.53
2025-02-17 13:25:10,789 [podnet.py] => Task 9, Epoch 139/160 (LR 0.00419) => LSC_loss 0.27, Spatial_loss 1.27, Flat_loss 0.28, Train_acc 96.31, Test_acc 30.25
2025-02-17 13:25:13,678 [podnet.py] => Task 9, Epoch 140/160 (LR 0.00381) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.28, Train_acc 96.72, Test_acc 30.97
2025-02-17 13:25:16,490 [podnet.py] => Task 9, Epoch 141/160 (LR 0.00344) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.28, Train_acc 96.54, Test_acc 31.01
2025-02-17 13:25:19,325 [podnet.py] => Task 9, Epoch 142/160 (LR 0.00309) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.28, Train_acc 96.76, Test_acc 30.82
2025-02-17 13:25:22,165 [podnet.py] => Task 9, Epoch 143/160 (LR 0.00276) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.28, Train_acc 96.84, Test_acc 31.16
2025-02-17 13:25:24,967 [podnet.py] => Task 9, Epoch 144/160 (LR 0.00245) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.28, Train_acc 96.49, Test_acc 31.15
2025-02-17 13:25:27,754 [podnet.py] => Task 9, Epoch 145/160 (LR 0.00215) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.28, Train_acc 96.63, Test_acc 31.51
2025-02-17 13:25:30,566 [podnet.py] => Task 9, Epoch 146/160 (LR 0.00188) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.28, Train_acc 96.81, Test_acc 31.79
2025-02-17 13:25:33,378 [podnet.py] => Task 9, Epoch 147/160 (LR 0.00162) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.28, Train_acc 96.96, Test_acc 32.31
2025-02-17 13:25:36,170 [podnet.py] => Task 9, Epoch 148/160 (LR 0.00138) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.28, Train_acc 96.81, Test_acc 31.44
2025-02-17 13:25:38,965 [podnet.py] => Task 9, Epoch 149/160 (LR 0.00116) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.27, Train_acc 97.04, Test_acc 31.49
2025-02-17 13:25:41,718 [podnet.py] => Task 9, Epoch 150/160 (LR 0.00096) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.28, Train_acc 96.79, Test_acc 31.47
2025-02-17 13:25:44,552 [podnet.py] => Task 9, Epoch 151/160 (LR 0.00078) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.28, Train_acc 97.01, Test_acc 31.27
2025-02-17 13:25:47,397 [podnet.py] => Task 9, Epoch 152/160 (LR 0.00062) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.27, Train_acc 96.87, Test_acc 31.84
2025-02-17 13:25:50,130 [podnet.py] => Task 9, Epoch 153/160 (LR 0.00047) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.27, Train_acc 96.75, Test_acc 31.21
2025-02-17 13:25:52,920 [podnet.py] => Task 9, Epoch 154/160 (LR 0.00035) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.27, Train_acc 97.15, Test_acc 31.74
2025-02-17 13:25:55,802 [podnet.py] => Task 9, Epoch 155/160 (LR 0.00024) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.28, Train_acc 97.09, Test_acc 31.54
2025-02-17 13:25:58,629 [podnet.py] => Task 9, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.27, Train_acc 97.21, Test_acc 31.87
2025-02-17 13:26:01,468 [podnet.py] => Task 9, Epoch 157/160 (LR 0.00009) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.27, Train_acc 97.25, Test_acc 31.70
2025-02-17 13:26:04,288 [podnet.py] => Task 9, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.27, Train_acc 97.10, Test_acc 31.74
2025-02-17 13:26:07,113 [podnet.py] => Task 9, Epoch 159/160 (LR 0.00001) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.27, Train_acc 97.07, Test_acc 31.97
2025-02-17 13:26:09,987 [podnet.py] => Task 9, Epoch 160/160 (LR 0.00000) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.27, Train_acc 96.81, Test_acc 31.57
2025-02-17 13:26:09,988 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-17 13:26:09,988 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:26:47,389 [podnet.py] => The size of finetune dataset: 2000
2025-02-17 13:26:49,040 [podnet.py] => Task 9, Epoch 1/20 (LR 0.00497) => LSC_loss 0.35, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 95.05, Test_acc 34.44
2025-02-17 13:26:50,739 [podnet.py] => Task 9, Epoch 2/20 (LR 0.00488) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.16, Train_acc 97.60, Test_acc 34.99
2025-02-17 13:26:52,395 [podnet.py] => Task 9, Epoch 3/20 (LR 0.00473) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.15, Train_acc 98.05, Test_acc 33.94
2025-02-17 13:26:54,125 [podnet.py] => Task 9, Epoch 4/20 (LR 0.00452) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.15, Train_acc 98.00, Test_acc 34.68
2025-02-17 13:26:55,827 [podnet.py] => Task 9, Epoch 5/20 (LR 0.00427) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.15, Train_acc 98.65, Test_acc 34.57
2025-02-17 13:26:57,549 [podnet.py] => Task 9, Epoch 6/20 (LR 0.00397) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.15, Train_acc 98.85, Test_acc 34.12
2025-02-17 13:26:59,230 [podnet.py] => Task 9, Epoch 7/20 (LR 0.00363) => LSC_loss 0.19, Spatial_loss 1.18, Flat_loss 0.15, Train_acc 98.95, Test_acc 34.64
2025-02-17 13:27:00,926 [podnet.py] => Task 9, Epoch 8/20 (LR 0.00327) => LSC_loss 0.18, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 98.80, Test_acc 34.70
2025-02-17 13:27:02,660 [podnet.py] => Task 9, Epoch 9/20 (LR 0.00289) => LSC_loss 0.18, Spatial_loss 1.14, Flat_loss 0.14, Train_acc 99.05, Test_acc 34.43
2025-02-17 13:27:04,312 [podnet.py] => Task 9, Epoch 10/20 (LR 0.00250) => LSC_loss 0.19, Spatial_loss 1.14, Flat_loss 0.14, Train_acc 98.65, Test_acc 34.84
2025-02-17 13:27:05,955 [podnet.py] => Task 9, Epoch 11/20 (LR 0.00211) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.14, Train_acc 98.70, Test_acc 34.46
2025-02-17 13:27:07,659 [podnet.py] => Task 9, Epoch 12/20 (LR 0.00173) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.14, Train_acc 98.80, Test_acc 34.55
2025-02-17 13:27:09,383 [podnet.py] => Task 9, Epoch 13/20 (LR 0.00137) => LSC_loss 0.19, Spatial_loss 1.12, Flat_loss 0.14, Train_acc 98.80, Test_acc 34.98
2025-02-17 13:27:11,107 [podnet.py] => Task 9, Epoch 14/20 (LR 0.00103) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.14, Train_acc 98.85, Test_acc 34.90
2025-02-17 13:27:12,772 [podnet.py] => Task 9, Epoch 15/20 (LR 0.00073) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.14, Train_acc 98.55, Test_acc 34.71
2025-02-17 13:27:14,467 [podnet.py] => Task 9, Epoch 16/20 (LR 0.00048) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 98.45, Test_acc 34.84
2025-02-17 13:27:16,159 [podnet.py] => Task 9, Epoch 17/20 (LR 0.00027) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.14, Train_acc 99.35, Test_acc 34.66
2025-02-17 13:27:17,891 [podnet.py] => Task 9, Epoch 18/20 (LR 0.00012) => LSC_loss 0.18, Spatial_loss 1.11, Flat_loss 0.14, Train_acc 98.90, Test_acc 34.68
2025-02-17 13:27:19,634 [podnet.py] => Task 9, Epoch 19/20 (LR 0.00003) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 98.85, Test_acc 34.74
2025-02-17 13:27:21,379 [podnet.py] => Task 9, Epoch 20/20 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.14, Train_acc 99.00, Test_acc 34.80
2025-02-17 13:27:21,382 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-17 13:28:01,753 [podnet.py] => Exemplar size: 2000
2025-02-17 13:28:01,753 [trainer.py] => CNN: {'total': 34.8, '00-09': 43.9, '10-19': 14.6, '20-29': 26.1, '30-39': 22.7, '40-49': 37.5, '50-59': 21.8, '60-69': 36.6, '70-79': 36.0, '80-89': 48.7, '90-99': 60.1, 'old': 31.99, 'new': 60.1}
2025-02-17 13:28:01,753 [trainer.py] => NME: {'total': 34.58, '00-09': 56.0, '10-19': 13.5, '20-29': 28.0, '30-39': 21.8, '40-49': 36.7, '50-59': 20.2, '60-69': 39.2, '70-79': 36.4, '80-89': 43.1, '90-99': 50.9, 'old': 32.77, 'new': 50.9}
2025-02-17 13:28:01,754 [trainer.py] => CNN top1 curve: [90.3, 70.25, 59.23, 49.92, 47.2, 43.93, 41.94, 38.49, 35.63, 34.8]
2025-02-17 13:28:01,754 [trainer.py] => CNN top5 curve: [99.3, 93.4, 88.03, 81.78, 78.22, 74.43, 72.57, 69.22, 65.68, 64.37]
2025-02-17 13:28:01,754 [trainer.py] => NME top1 curve: [89.9, 69.8, 59.13, 50.18, 47.42, 43.8, 41.47, 38.49, 36.02, 34.58]
2025-02-17 13:28:01,754 [trainer.py] => NME top5 curve: [99.3, 93.0, 87.07, 82.35, 78.78, 73.92, 71.16, 68.14, 65.28, 63.64]

2025-02-17 13:28:01,754 [trainer.py] => Average Accuracy (CNN): 51.169
2025-02-17 13:28:01,754 [trainer.py] => Average Accuracy (NME): 51.079