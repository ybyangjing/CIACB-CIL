2025-02-13 17:09:54,666 [trainer.py] => config: ./exps/podnet.json
2025-02-13 17:09:54,667 [trainer.py] => prefix: reproduce
2025-02-13 17:09:54,667 [trainer.py] => dataset: cifar100
2025-02-13 17:09:54,668 [trainer.py] => memory_size: 2000
2025-02-13 17:09:54,668 [trainer.py] => memory_per_class: 20
2025-02-13 17:09:54,668 [trainer.py] => fixed_memory: True
2025-02-13 17:09:54,668 [trainer.py] => shuffle: True
2025-02-13 17:09:54,668 [trainer.py] => init_cls: 50
2025-02-13 17:09:54,668 [trainer.py] => increment: 2
2025-02-13 17:09:54,668 [trainer.py] => model_name: podnet
2025-02-13 17:09:54,668 [trainer.py] => convnet_type: cosine_resnet32
2025-02-13 17:09:54,668 [trainer.py] => device: [device(type='cuda', index=0)]
2025-02-13 17:09:54,669 [trainer.py] => seed: 1993
2025-02-13 17:09:56,564 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-02-13 17:09:59,484 [trainer.py] => All params: 466256
2025-02-13 17:09:59,484 [trainer.py] => Trainable params: 466256
2025-02-13 17:09:59,485 [podnet.py] => Learning on 0-50
2025-02-13 17:09:59,539 [podnet.py] => Adaptive factor: 0
2025-02-13 17:10:07,267 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 3.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 5.80, Test_acc 5.94
2025-02-13 17:10:12,466 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 3.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 14.38, Test_acc 16.40
2025-02-13 17:10:17,576 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 2.95, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 21.41, Test_acc 24.70
2025-02-13 17:10:22,721 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 2.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 27.63, Test_acc 24.78
2025-02-13 17:10:27,859 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 2.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 33.52, Test_acc 26.42
2025-02-13 17:10:33,043 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 2.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 39.37, Test_acc 40.18
2025-02-13 17:10:38,187 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 2.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 44.68, Test_acc 40.06
2025-02-13 17:10:43,336 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 1.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 47.98, Test_acc 45.92
2025-02-13 17:10:48,518 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 1.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 51.09, Test_acc 43.40
2025-02-13 17:10:53,701 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 1.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 53.87, Test_acc 50.50
2025-02-13 17:10:58,827 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 1.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 55.47, Test_acc 50.70
2025-02-13 17:11:04,039 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 1.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 57.16, Test_acc 48.34
2025-02-13 17:11:09,223 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 1.49, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 58.43, Test_acc 52.92
2025-02-13 17:11:14,411 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 1.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 59.72, Test_acc 54.48
2025-02-13 17:11:19,645 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 1.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.96, Test_acc 51.06
2025-02-13 17:11:24,808 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 1.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 61.79, Test_acc 53.44
2025-02-13 17:11:30,028 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 1.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 63.04, Test_acc 54.56
2025-02-13 17:11:35,148 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 1.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 63.90, Test_acc 55.50
2025-02-13 17:11:40,286 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 1.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 64.37, Test_acc 55.64
2025-02-13 17:11:45,435 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 1.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 65.22, Test_acc 55.50
2025-02-13 17:11:50,564 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 1.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 65.21, Test_acc 58.10
2025-02-13 17:11:55,811 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 1.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 65.86, Test_acc 56.44
2025-02-13 17:12:01,018 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 1.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 66.24, Test_acc 52.04
2025-02-13 17:12:06,129 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 1.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.23, Test_acc 53.84
2025-02-13 17:12:11,298 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 1.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.48, Test_acc 57.28
2025-02-13 17:12:16,402 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 1.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.84, Test_acc 56.94
2025-02-13 17:12:21,601 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 1.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.98, Test_acc 50.48
2025-02-13 17:12:26,859 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 1.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 68.64, Test_acc 59.20
2025-02-13 17:12:32,088 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 1.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.24, Test_acc 61.20
2025-02-13 17:12:37,280 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 1.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.00, Test_acc 57.22
2025-02-13 17:12:42,442 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.35, Test_acc 60.94
2025-02-13 17:12:47,615 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 1.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.85, Test_acc 59.24
2025-02-13 17:12:52,801 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 1.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.77, Test_acc 57.96
2025-02-13 17:12:57,920 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 1.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 70.48, Test_acc 60.34
2025-02-13 17:13:03,154 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 1.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.84, Test_acc 54.54
2025-02-13 17:13:08,269 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 1.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 70.92, Test_acc 57.32
2025-02-13 17:13:13,384 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 1.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 70.68, Test_acc 60.76
2025-02-13 17:13:18,520 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 1.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.56, Test_acc 59.00
2025-02-13 17:13:23,747 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 1.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.10, Test_acc 63.64
2025-02-13 17:13:28,935 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 1.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.57, Test_acc 61.18
2025-02-13 17:13:34,114 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 1.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.65, Test_acc 63.02
2025-02-13 17:13:39,211 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 1.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.81, Test_acc 63.68
2025-02-13 17:13:44,405 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 1.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.06, Test_acc 60.52
2025-02-13 17:13:49,634 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.98, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.61, Test_acc 64.00
2025-02-13 17:13:54,819 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.98, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.84, Test_acc 57.18
2025-02-13 17:13:59,998 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.96, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.14, Test_acc 61.06
2025-02-13 17:14:05,125 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.97, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.99, Test_acc 62.66
2025-02-13 17:14:10,313 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.96, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.11, Test_acc 60.18
2025-02-13 17:14:15,448 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.95, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.14, Test_acc 64.28
2025-02-13 17:14:20,595 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.94, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.23, Test_acc 65.30
2025-02-13 17:14:25,765 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.94, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.60, Test_acc 61.48
2025-02-13 17:14:30,962 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.92, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.31, Test_acc 62.56
2025-02-13 17:14:36,136 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.91, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.40, Test_acc 61.44
2025-02-13 17:14:41,325 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.91, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.24, Test_acc 63.26
2025-02-13 17:14:46,430 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.91, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.45, Test_acc 65.12
2025-02-13 17:14:51,629 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.14, Test_acc 60.20
2025-02-13 17:14:56,819 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.90, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.02, Test_acc 62.46
2025-02-13 17:15:02,014 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.88, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.20, Test_acc 59.80
2025-02-13 17:15:07,213 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.86, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.93, Test_acc 64.40
2025-02-13 17:15:12,420 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.87, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.52, Test_acc 65.06
2025-02-13 17:15:17,575 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.86, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.01, Test_acc 62.32
2025-02-13 17:15:22,731 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.80, Test_acc 63.02
2025-02-13 17:15:27,909 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.84, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.33, Test_acc 58.36
2025-02-13 17:15:33,003 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.84, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.60, Test_acc 60.96
2025-02-13 17:15:38,196 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.85, Test_acc 63.92
2025-02-13 17:15:43,384 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.83, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.75, Test_acc 67.14
2025-02-13 17:15:48,479 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.81, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.34, Test_acc 63.74
2025-02-13 17:15:53,610 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.81, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.00, Test_acc 62.90
2025-02-13 17:15:58,814 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.80, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.66, Test_acc 65.02
2025-02-13 17:16:03,981 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.88, Test_acc 61.90
2025-02-13 17:16:09,179 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.01, Test_acc 60.48
2025-02-13 17:16:14,413 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.77, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.58, Test_acc 63.62
2025-02-13 17:16:19,536 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.43, Test_acc 64.56
2025-02-13 17:16:24,789 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.75, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.78, Test_acc 64.86
2025-02-13 17:16:29,915 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.75, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.96, Test_acc 63.08
2025-02-13 17:16:35,154 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.56, Test_acc 66.34
2025-02-13 17:16:40,308 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.72, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.67, Test_acc 63.52
2025-02-13 17:16:45,492 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.22, Test_acc 69.38
2025-02-13 17:16:50,665 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.71, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.85, Test_acc 66.28
2025-02-13 17:16:55,841 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.71, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.90, Test_acc 63.62
2025-02-13 17:17:01,029 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.05, Test_acc 65.04
2025-02-13 17:17:06,235 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.95, Test_acc 63.56
2025-02-13 17:17:11,424 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.12, Test_acc 69.22
2025-02-13 17:17:16,569 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.92, Test_acc 63.06
2025-02-13 17:17:21,698 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.66, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.31, Test_acc 68.78
2025-02-13 17:17:26,859 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.65, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.51, Test_acc 67.62
2025-02-13 17:17:31,993 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.12, Test_acc 68.04
2025-02-13 17:17:37,204 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.14, Test_acc 66.42
2025-02-13 17:17:42,406 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.83, Test_acc 64.18
2025-02-13 17:17:47,599 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.68, Test_acc 66.62
2025-02-13 17:17:52,825 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.06, Test_acc 67.34
2025-02-13 17:17:58,010 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.31, Test_acc 67.00
2025-02-13 17:18:03,195 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.66, Test_acc 67.96
2025-02-13 17:18:08,396 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.20, Test_acc 61.16
2025-02-13 17:18:13,648 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.76, Test_acc 66.52
2025-02-13 17:18:18,870 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.54, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.78, Test_acc 71.20
2025-02-13 17:18:23,959 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.04, Test_acc 67.96
2025-02-13 17:18:29,126 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.84, Test_acc 67.58
2025-02-13 17:18:34,252 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.19, Test_acc 66.90
2025-02-13 17:18:39,368 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.49, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.75, Test_acc 70.46
2025-02-13 17:18:44,532 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.49, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.04, Test_acc 68.36
2025-02-13 17:18:49,657 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.57, Test_acc 66.80
2025-02-13 17:18:54,809 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.50, Test_acc 70.78
2025-02-13 17:18:59,940 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.70, Test_acc 68.20
2025-02-13 17:19:05,099 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.21, Test_acc 70.92
2025-02-13 17:19:10,226 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.83, Test_acc 68.58
2025-02-13 17:19:15,327 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.31, Test_acc 71.20
2025-02-13 17:19:20,474 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.45, Test_acc 71.44
2025-02-13 17:19:25,624 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.88, Test_acc 68.30
2025-02-13 17:19:30,845 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.38, Test_acc 71.32
2025-02-13 17:19:35,980 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.64, Test_acc 72.72
2025-02-13 17:19:41,111 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.97, Test_acc 72.24
2025-02-13 17:19:46,188 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.01, Test_acc 70.94
2025-02-13 17:19:51,341 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.27, Test_acc 72.68
2025-02-13 17:19:56,487 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.02, Test_acc 72.28
2025-02-13 17:20:01,629 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.63, Test_acc 70.98
2025-02-13 17:20:06,785 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.96, Test_acc 71.24
2025-02-13 17:20:11,941 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.69, Test_acc 71.94
2025-02-13 17:20:17,082 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.83, Test_acc 72.42
2025-02-13 17:20:22,275 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.40, Test_acc 74.48
2025-02-13 17:20:27,371 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.76, Test_acc 74.18
2025-02-13 17:20:32,496 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.42, Test_acc 73.64
2025-02-13 17:20:37,665 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.74, Test_acc 72.58
2025-02-13 17:20:42,824 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.69, Test_acc 75.54
2025-02-13 17:20:48,019 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.36, Test_acc 75.46
2025-02-13 17:20:53,161 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.63, Test_acc 74.86
2025-02-13 17:20:58,374 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.15, Test_acc 74.60
2025-02-13 17:21:03,500 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.58, Test_acc 74.94
2025-02-13 17:21:08,649 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.92, Test_acc 75.24
2025-02-13 17:21:13,780 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.27, Test_acc 76.26
2025-02-13 17:21:18,991 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.26, Test_acc 75.82
2025-02-13 17:21:24,115 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.66, Test_acc 75.96
2025-02-13 17:21:29,272 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.89, Test_acc 76.62
2025-02-13 17:21:34,444 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 76.36
2025-02-13 17:21:39,559 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.21, Test_acc 77.00
2025-02-13 17:21:44,722 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.40, Test_acc 76.66
2025-02-13 17:21:49,898 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.69, Test_acc 77.08
2025-02-13 17:21:55,046 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.68, Test_acc 77.14
2025-02-13 17:22:00,201 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.96, Test_acc 77.02
2025-02-13 17:22:05,318 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.07, Test_acc 77.10
2025-02-13 17:22:10,446 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 77.54
2025-02-13 17:22:15,627 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 77.72
2025-02-13 17:22:20,768 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 77.38
2025-02-13 17:22:25,954 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.29, Test_acc 77.46
2025-02-13 17:22:31,079 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.41, Test_acc 77.58
2025-02-13 17:22:36,213 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.50, Test_acc 77.48
2025-02-13 17:22:41,350 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.45, Test_acc 77.84
2025-02-13 17:22:46,437 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 78.02
2025-02-13 17:22:51,590 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.61, Test_acc 78.12
2025-02-13 17:22:56,741 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 77.88
2025-02-13 17:23:01,884 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 77.54
2025-02-13 17:23:07,058 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.66, Test_acc 77.64
2025-02-13 17:23:12,206 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.66, Test_acc 77.88
2025-02-13 17:23:17,390 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 77.88
2025-02-13 17:23:22,583 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 77.92
2025-02-13 17:23:27,731 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 77.86
2025-02-13 17:23:32,816 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 77.78
2025-02-13 17:23:37,964 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 77.90
2025-02-13 17:23:43,023 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 77.98
2025-02-13 17:23:48,166 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 77.70
2025-02-13 17:23:48,167 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:24:21,476 [podnet.py] => Exemplar size: 1000
2025-02-13 17:24:21,476 [trainer.py] => CNN: {'total': 77.7, '00-09': 80.7, '10-19': 71.9, '20-29': 81.0, '30-39': 75.4, '40-49': 79.5, 'old': 0, 'new': 77.7}
2025-02-13 17:24:21,476 [trainer.py] => NME: {'total': 77.44, '00-09': 81.0, '10-19': 71.5, '20-29': 80.8, '30-39': 74.4, '40-49': 79.5, 'old': 0, 'new': 77.44}
2025-02-13 17:24:21,476 [trainer.py] => CNN top1 curve: [77.7]
2025-02-13 17:24:21,476 [trainer.py] => CNN top5 curve: [94.08]
2025-02-13 17:24:21,476 [trainer.py] => NME top1 curve: [77.44]
2025-02-13 17:24:21,476 [trainer.py] => NME top5 curve: [93.98]

2025-02-13 17:24:21,476 [trainer.py] => Average Accuracy (CNN): 77.7
2025-02-13 17:24:21,476 [trainer.py] => Average Accuracy (NME): 77.44
2025-02-13 17:24:21,476 [trainer.py] => All params: 498257
2025-02-13 17:24:21,477 [trainer.py] => Trainable params: 498257
2025-02-13 17:24:21,477 [podnet.py] => Learning on 50-52
2025-02-13 17:24:21,496 [podnet.py] => Adaptive factor: 5.0990195135927845
2025-02-13 17:24:22,980 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 2.16, Spatial_loss 12.19, Flat_loss 2.32, Train_acc 55.90, Test_acc 5.98
2025-02-13 17:24:24,292 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 1.19, Spatial_loss 10.32, Flat_loss 2.14, Train_acc 71.25, Test_acc 24.19
2025-02-13 17:24:25,684 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 0.74, Spatial_loss 8.77, Flat_loss 1.69, Train_acc 80.70, Test_acc 45.06
2025-02-13 17:24:27,067 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 0.54, Spatial_loss 8.03, Flat_loss 1.41, Train_acc 85.80, Test_acc 33.75
2025-02-13 17:24:28,456 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 0.49, Spatial_loss 7.53, Flat_loss 1.24, Train_acc 87.15, Test_acc 42.25
2025-02-13 17:24:29,836 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 0.39, Spatial_loss 7.22, Flat_loss 1.14, Train_acc 90.10, Test_acc 54.44
2025-02-13 17:24:31,165 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 0.31, Spatial_loss 6.91, Flat_loss 1.03, Train_acc 92.60, Test_acc 62.42
2025-02-13 17:24:32,539 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 0.29, Spatial_loss 6.47, Flat_loss 0.92, Train_acc 92.25, Test_acc 62.42
2025-02-13 17:24:33,878 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 0.30, Spatial_loss 6.60, Flat_loss 0.91, Train_acc 92.40, Test_acc 54.65
2025-02-13 17:24:35,197 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 0.27, Spatial_loss 6.24, Flat_loss 0.88, Train_acc 93.00, Test_acc 58.69
2025-02-13 17:24:36,619 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 0.23, Spatial_loss 6.00, Flat_loss 0.79, Train_acc 94.60, Test_acc 59.71
2025-02-13 17:24:37,961 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.24, Spatial_loss 6.08, Flat_loss 0.78, Train_acc 94.55, Test_acc 59.63
2025-02-13 17:24:39,310 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.22, Spatial_loss 6.04, Flat_loss 0.77, Train_acc 94.85, Test_acc 63.60
2025-02-13 17:24:40,680 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.20, Spatial_loss 5.79, Flat_loss 0.74, Train_acc 95.45, Test_acc 63.73
2025-02-13 17:24:42,028 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.20, Spatial_loss 5.75, Flat_loss 0.70, Train_acc 95.35, Test_acc 62.27
2025-02-13 17:24:43,349 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.22, Spatial_loss 5.66, Flat_loss 0.69, Train_acc 95.05, Test_acc 58.71
2025-02-13 17:24:44,711 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.20, Spatial_loss 5.57, Flat_loss 0.67, Train_acc 95.55, Test_acc 57.38
2025-02-13 17:24:46,130 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.18, Spatial_loss 5.45, Flat_loss 0.66, Train_acc 96.10, Test_acc 65.50
2025-02-13 17:24:47,486 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.19, Spatial_loss 5.26, Flat_loss 0.61, Train_acc 96.15, Test_acc 64.67
2025-02-13 17:24:48,848 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.17, Spatial_loss 5.21, Flat_loss 0.60, Train_acc 96.30, Test_acc 61.12
2025-02-13 17:24:50,269 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.17, Spatial_loss 5.22, Flat_loss 0.59, Train_acc 96.95, Test_acc 63.46
2025-02-13 17:24:51,586 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.20, Spatial_loss 5.03, Flat_loss 0.58, Train_acc 95.70, Test_acc 58.83
2025-02-13 17:24:52,908 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.17, Spatial_loss 5.14, Flat_loss 0.58, Train_acc 96.45, Test_acc 66.04
2025-02-13 17:24:54,300 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.18, Spatial_loss 5.03, Flat_loss 0.57, Train_acc 95.65, Test_acc 67.42
2025-02-13 17:24:55,692 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.18, Spatial_loss 5.20, Flat_loss 0.57, Train_acc 96.30, Test_acc 63.92
2025-02-13 17:24:57,071 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.16, Spatial_loss 4.95, Flat_loss 0.54, Train_acc 96.35, Test_acc 68.12
2025-02-13 17:24:58,455 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.16, Spatial_loss 4.79, Flat_loss 0.53, Train_acc 96.60, Test_acc 63.38
2025-02-13 17:24:59,840 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.16, Spatial_loss 4.85, Flat_loss 0.53, Train_acc 96.70, Test_acc 64.02
2025-02-13 17:25:01,211 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.16, Spatial_loss 4.79, Flat_loss 0.53, Train_acc 96.70, Test_acc 67.00
2025-02-13 17:25:02,552 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.18, Spatial_loss 4.76, Flat_loss 0.52, Train_acc 95.95, Test_acc 63.58
2025-02-13 17:25:03,947 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.16, Spatial_loss 4.77, Flat_loss 0.52, Train_acc 96.40, Test_acc 64.67
2025-02-13 17:25:05,297 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.16, Spatial_loss 4.92, Flat_loss 0.52, Train_acc 97.05, Test_acc 69.23
2025-02-13 17:25:06,662 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.17, Spatial_loss 4.73, Flat_loss 0.51, Train_acc 96.55, Test_acc 66.52
2025-02-13 17:25:07,995 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.16, Spatial_loss 4.71, Flat_loss 0.51, Train_acc 96.20, Test_acc 66.71
2025-02-13 17:25:09,366 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.17, Spatial_loss 4.71, Flat_loss 0.49, Train_acc 96.15, Test_acc 61.19
2025-02-13 17:25:10,693 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.16, Spatial_loss 4.63, Flat_loss 0.50, Train_acc 96.50, Test_acc 71.15
2025-02-13 17:25:12,065 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.16, Spatial_loss 4.62, Flat_loss 0.49, Train_acc 96.05, Test_acc 66.56
2025-02-13 17:25:13,436 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.17, Spatial_loss 4.61, Flat_loss 0.51, Train_acc 95.90, Test_acc 68.44
2025-02-13 17:25:14,766 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.15, Spatial_loss 4.49, Flat_loss 0.48, Train_acc 97.10, Test_acc 68.90
2025-02-13 17:25:16,162 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.15, Spatial_loss 4.54, Flat_loss 0.46, Train_acc 97.00, Test_acc 65.06
2025-02-13 17:25:17,563 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.14, Spatial_loss 4.47, Flat_loss 0.48, Train_acc 96.85, Test_acc 69.67
2025-02-13 17:25:18,950 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.16, Spatial_loss 4.53, Flat_loss 0.47, Train_acc 96.55, Test_acc 68.04
2025-02-13 17:25:20,304 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.16, Spatial_loss 4.43, Flat_loss 0.46, Train_acc 96.60, Test_acc 70.04
2025-02-13 17:25:21,709 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.15, Spatial_loss 4.46, Flat_loss 0.46, Train_acc 96.90, Test_acc 68.37
2025-02-13 17:25:23,051 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.17, Spatial_loss 4.50, Flat_loss 0.47, Train_acc 95.55, Test_acc 68.42
2025-02-13 17:25:24,395 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.14, Spatial_loss 4.45, Flat_loss 0.45, Train_acc 97.45, Test_acc 70.13
2025-02-13 17:25:25,754 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.15, Spatial_loss 4.32, Flat_loss 0.45, Train_acc 97.05, Test_acc 69.15
2025-02-13 17:25:27,138 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.15, Spatial_loss 4.35, Flat_loss 0.44, Train_acc 97.25, Test_acc 69.44
2025-02-13 17:25:28,544 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.16, Spatial_loss 4.26, Flat_loss 0.43, Train_acc 96.85, Test_acc 69.42
2025-02-13 17:25:29,923 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.16, Spatial_loss 4.33, Flat_loss 0.44, Train_acc 96.55, Test_acc 68.12
2025-02-13 17:25:31,314 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.14, Spatial_loss 4.23, Flat_loss 0.45, Train_acc 97.40, Test_acc 67.77
2025-02-13 17:25:32,731 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.16, Spatial_loss 4.07, Flat_loss 0.41, Train_acc 96.70, Test_acc 69.33
2025-02-13 17:25:34,125 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.15, Spatial_loss 4.15, Flat_loss 0.42, Train_acc 97.10, Test_acc 71.12
2025-02-13 17:25:35,512 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.15, Spatial_loss 4.18, Flat_loss 0.42, Train_acc 97.00, Test_acc 69.25
2025-02-13 17:25:36,893 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.15, Spatial_loss 4.16, Flat_loss 0.42, Train_acc 96.30, Test_acc 66.81
2025-02-13 17:25:38,312 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.13, Spatial_loss 4.31, Flat_loss 0.44, Train_acc 96.85, Test_acc 70.58
2025-02-13 17:25:39,657 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.15, Spatial_loss 4.26, Flat_loss 0.43, Train_acc 96.50, Test_acc 69.35
2025-02-13 17:25:41,010 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.15, Spatial_loss 4.11, Flat_loss 0.41, Train_acc 97.15, Test_acc 68.67
2025-02-13 17:25:42,360 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.15, Spatial_loss 4.04, Flat_loss 0.41, Train_acc 97.30, Test_acc 68.06
2025-02-13 17:25:43,683 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.16, Spatial_loss 4.08, Flat_loss 0.41, Train_acc 96.85, Test_acc 68.46
2025-02-13 17:25:45,094 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.13, Spatial_loss 4.13, Flat_loss 0.41, Train_acc 97.10, Test_acc 69.23
2025-02-13 17:25:46,463 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.15, Spatial_loss 3.99, Flat_loss 0.39, Train_acc 97.00, Test_acc 70.94
2025-02-13 17:25:47,853 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.15, Spatial_loss 4.01, Flat_loss 0.40, Train_acc 96.75, Test_acc 69.54
2025-02-13 17:25:49,166 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.15, Spatial_loss 4.01, Flat_loss 0.41, Train_acc 96.60, Test_acc 69.46
2025-02-13 17:25:50,586 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.15, Spatial_loss 4.14, Flat_loss 0.40, Train_acc 97.00, Test_acc 70.46
2025-02-13 17:25:51,959 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.16, Spatial_loss 4.05, Flat_loss 0.40, Train_acc 96.30, Test_acc 71.48
2025-02-13 17:25:53,300 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.15, Spatial_loss 3.84, Flat_loss 0.38, Train_acc 96.00, Test_acc 70.44
2025-02-13 17:25:54,674 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.13, Spatial_loss 3.82, Flat_loss 0.38, Train_acc 97.40, Test_acc 70.94
2025-02-13 17:25:56,024 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.15, Spatial_loss 3.79, Flat_loss 0.37, Train_acc 96.90, Test_acc 70.23
2025-02-13 17:25:57,330 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.14, Spatial_loss 3.85, Flat_loss 0.38, Train_acc 97.15, Test_acc 70.58
2025-02-13 17:25:58,659 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.15, Spatial_loss 3.81, Flat_loss 0.37, Train_acc 96.60, Test_acc 70.13
2025-02-13 17:26:00,077 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.13, Spatial_loss 3.90, Flat_loss 0.37, Train_acc 97.25, Test_acc 71.25
2025-02-13 17:26:01,440 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.14, Spatial_loss 3.77, Flat_loss 0.35, Train_acc 97.35, Test_acc 71.50
2025-02-13 17:26:02,807 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.14, Spatial_loss 3.82, Flat_loss 0.36, Train_acc 97.30, Test_acc 69.92
2025-02-13 17:26:04,218 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.15, Spatial_loss 3.73, Flat_loss 0.35, Train_acc 96.85, Test_acc 71.06
2025-02-13 17:26:05,646 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.13, Spatial_loss 3.72, Flat_loss 0.36, Train_acc 97.60, Test_acc 72.17
2025-02-13 17:26:07,015 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.14, Spatial_loss 3.65, Flat_loss 0.34, Train_acc 97.60, Test_acc 72.17
2025-02-13 17:26:08,369 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.15, Spatial_loss 3.79, Flat_loss 0.36, Train_acc 97.20, Test_acc 71.19
2025-02-13 17:26:09,827 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.13, Spatial_loss 3.72, Flat_loss 0.35, Train_acc 97.40, Test_acc 71.33
2025-02-13 17:26:11,218 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.14, Spatial_loss 3.65, Flat_loss 0.35, Train_acc 97.15, Test_acc 71.54
2025-02-13 17:26:12,606 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.16, Spatial_loss 3.74, Flat_loss 0.35, Train_acc 96.55, Test_acc 71.96
2025-02-13 17:26:14,013 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.14, Spatial_loss 3.64, Flat_loss 0.34, Train_acc 96.95, Test_acc 71.25
2025-02-13 17:26:15,445 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.14, Spatial_loss 3.66, Flat_loss 0.34, Train_acc 97.20, Test_acc 71.83
2025-02-13 17:26:16,828 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.15, Spatial_loss 3.56, Flat_loss 0.33, Train_acc 96.85, Test_acc 69.19
2025-02-13 17:26:18,192 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.13, Spatial_loss 3.62, Flat_loss 0.34, Train_acc 97.40, Test_acc 70.81
2025-02-13 17:26:19,570 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.13, Spatial_loss 3.47, Flat_loss 0.32, Train_acc 97.40, Test_acc 71.02
2025-02-13 17:26:20,905 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.14, Spatial_loss 3.51, Flat_loss 0.31, Train_acc 97.25, Test_acc 67.75
2025-02-13 17:26:22,269 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.14, Spatial_loss 3.48, Flat_loss 0.32, Train_acc 97.50, Test_acc 73.23
2025-02-13 17:26:23,610 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.13, Spatial_loss 3.36, Flat_loss 0.31, Train_acc 97.65, Test_acc 72.79
2025-02-13 17:26:24,971 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 3.51, Flat_loss 0.32, Train_acc 96.30, Test_acc 71.65
2025-02-13 17:26:26,323 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.14, Spatial_loss 3.51, Flat_loss 0.32, Train_acc 97.30, Test_acc 72.73
2025-02-13 17:26:27,724 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.15, Spatial_loss 3.34, Flat_loss 0.30, Train_acc 97.25, Test_acc 73.58
2025-02-13 17:26:29,103 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.13, Spatial_loss 3.29, Flat_loss 0.31, Train_acc 97.40, Test_acc 73.81
2025-02-13 17:26:30,500 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.14, Spatial_loss 3.37, Flat_loss 0.30, Train_acc 97.45, Test_acc 73.31
2025-02-13 17:26:31,838 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.14, Spatial_loss 3.30, Flat_loss 0.30, Train_acc 96.95, Test_acc 73.75
2025-02-13 17:26:33,223 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.15, Spatial_loss 3.23, Flat_loss 0.29, Train_acc 96.80, Test_acc 73.42
2025-02-13 17:26:34,588 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.14, Spatial_loss 3.22, Flat_loss 0.30, Train_acc 97.00, Test_acc 72.85
2025-02-13 17:26:35,920 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.14, Spatial_loss 3.35, Flat_loss 0.29, Train_acc 97.10, Test_acc 73.37
2025-02-13 17:26:37,283 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.13, Spatial_loss 3.17, Flat_loss 0.29, Train_acc 97.15, Test_acc 73.54
2025-02-13 17:26:38,638 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.14, Spatial_loss 3.17, Flat_loss 0.29, Train_acc 97.65, Test_acc 72.67
2025-02-13 17:26:40,005 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.15, Spatial_loss 3.26, Flat_loss 0.28, Train_acc 96.45, Test_acc 74.10
2025-02-13 17:26:41,389 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.14, Spatial_loss 3.23, Flat_loss 0.29, Train_acc 97.05, Test_acc 73.56
2025-02-13 17:26:42,676 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.14, Spatial_loss 3.12, Flat_loss 0.28, Train_acc 97.50, Test_acc 71.69
2025-02-13 17:26:44,037 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.15, Spatial_loss 3.11, Flat_loss 0.27, Train_acc 96.75, Test_acc 71.31
2025-02-13 17:26:45,424 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.14, Spatial_loss 3.23, Flat_loss 0.29, Train_acc 96.90, Test_acc 72.06
2025-02-13 17:26:46,837 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.13, Spatial_loss 3.06, Flat_loss 0.27, Train_acc 97.45, Test_acc 73.77
2025-02-13 17:26:48,189 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.13, Spatial_loss 3.06, Flat_loss 0.27, Train_acc 97.75, Test_acc 74.00
2025-02-13 17:26:49,580 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.15, Spatial_loss 2.97, Flat_loss 0.26, Train_acc 97.45, Test_acc 72.90
2025-02-13 17:26:51,000 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.14, Spatial_loss 3.11, Flat_loss 0.28, Train_acc 97.25, Test_acc 74.87
2025-02-13 17:26:52,368 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.14, Spatial_loss 2.92, Flat_loss 0.26, Train_acc 97.15, Test_acc 73.79
2025-02-13 17:26:53,763 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.13, Spatial_loss 2.97, Flat_loss 0.25, Train_acc 97.65, Test_acc 74.23
2025-02-13 17:26:55,117 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.13, Spatial_loss 2.87, Flat_loss 0.25, Train_acc 97.55, Test_acc 74.48
2025-02-13 17:26:56,476 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.14, Spatial_loss 2.84, Flat_loss 0.25, Train_acc 97.50, Test_acc 73.75
2025-02-13 17:26:57,811 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.13, Spatial_loss 2.92, Flat_loss 0.25, Train_acc 97.10, Test_acc 73.83
2025-02-13 17:26:59,178 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.14, Spatial_loss 2.87, Flat_loss 0.25, Train_acc 97.70, Test_acc 73.67
2025-02-13 17:27:00,499 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 2.84, Flat_loss 0.25, Train_acc 97.35, Test_acc 74.27
2025-02-13 17:27:01,833 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.14, Spatial_loss 2.79, Flat_loss 0.25, Train_acc 97.35, Test_acc 73.40
2025-02-13 17:27:03,200 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.13, Spatial_loss 2.72, Flat_loss 0.23, Train_acc 98.25, Test_acc 74.77
2025-02-13 17:27:04,622 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 2.77, Flat_loss 0.24, Train_acc 96.45, Test_acc 75.02
2025-02-13 17:27:06,058 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.13, Spatial_loss 2.64, Flat_loss 0.23, Train_acc 97.30, Test_acc 74.85
2025-02-13 17:27:07,447 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 2.79, Flat_loss 0.24, Train_acc 97.60, Test_acc 74.81
2025-02-13 17:27:08,814 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 2.67, Flat_loss 0.23, Train_acc 97.10, Test_acc 74.37
2025-02-13 17:27:10,191 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 2.70, Flat_loss 0.24, Train_acc 97.15, Test_acc 74.52
2025-02-13 17:27:11,529 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.14, Spatial_loss 2.67, Flat_loss 0.24, Train_acc 96.90, Test_acc 74.90
2025-02-13 17:27:12,909 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 2.58, Flat_loss 0.23, Train_acc 97.00, Test_acc 74.67
2025-02-13 17:27:14,263 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.14, Spatial_loss 2.59, Flat_loss 0.23, Train_acc 97.10, Test_acc 74.58
2025-02-13 17:27:15,609 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.13, Spatial_loss 2.65, Flat_loss 0.23, Train_acc 97.55, Test_acc 74.98
2025-02-13 17:27:17,053 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.14, Spatial_loss 2.60, Flat_loss 0.22, Train_acc 97.30, Test_acc 74.54
2025-02-13 17:27:18,458 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.13, Spatial_loss 2.67, Flat_loss 0.23, Train_acc 97.25, Test_acc 75.00
2025-02-13 17:27:19,868 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.15, Spatial_loss 2.49, Flat_loss 0.22, Train_acc 96.35, Test_acc 75.02
2025-02-13 17:27:21,292 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.13, Spatial_loss 2.54, Flat_loss 0.22, Train_acc 97.85, Test_acc 74.46
2025-02-13 17:27:22,641 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.13, Spatial_loss 2.44, Flat_loss 0.21, Train_acc 97.50, Test_acc 75.29
2025-02-13 17:27:24,018 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 2.55, Flat_loss 0.22, Train_acc 97.15, Test_acc 75.15
2025-02-13 17:27:25,397 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.13, Spatial_loss 2.54, Flat_loss 0.22, Train_acc 97.10, Test_acc 75.13
2025-02-13 17:27:26,766 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.13, Spatial_loss 2.41, Flat_loss 0.21, Train_acc 97.40, Test_acc 74.94
2025-02-13 17:27:28,141 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.15, Spatial_loss 2.46, Flat_loss 0.21, Train_acc 96.75, Test_acc 74.46
2025-02-13 17:27:29,510 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.13, Spatial_loss 2.53, Flat_loss 0.21, Train_acc 97.25, Test_acc 74.75
2025-02-13 17:27:30,811 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 2.51, Flat_loss 0.21, Train_acc 96.85, Test_acc 74.73
2025-02-13 17:27:32,152 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 2.38, Flat_loss 0.20, Train_acc 97.70, Test_acc 75.35
2025-02-13 17:27:33,521 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.13, Spatial_loss 2.34, Flat_loss 0.21, Train_acc 97.70, Test_acc 75.10
2025-02-13 17:27:34,867 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.14, Spatial_loss 2.33, Flat_loss 0.20, Train_acc 97.30, Test_acc 75.29
2025-02-13 17:27:36,242 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.14, Spatial_loss 2.34, Flat_loss 0.20, Train_acc 97.60, Test_acc 75.21
2025-02-13 17:27:37,582 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 2.38, Flat_loss 0.21, Train_acc 96.65, Test_acc 75.38
2025-02-13 17:27:38,969 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.14, Spatial_loss 2.23, Flat_loss 0.20, Train_acc 97.35, Test_acc 75.42
2025-02-13 17:27:40,338 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.13, Spatial_loss 2.34, Flat_loss 0.20, Train_acc 97.75, Test_acc 75.38
2025-02-13 17:27:41,695 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 2.29, Flat_loss 0.20, Train_acc 97.05, Test_acc 75.08
2025-02-13 17:27:43,070 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.14, Spatial_loss 2.24, Flat_loss 0.19, Train_acc 97.00, Test_acc 75.56
2025-02-13 17:27:44,413 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.13, Spatial_loss 2.34, Flat_loss 0.20, Train_acc 97.85, Test_acc 75.37
2025-02-13 17:27:45,758 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 2.29, Flat_loss 0.20, Train_acc 97.45, Test_acc 75.56
2025-02-13 17:27:47,190 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.14, Spatial_loss 2.25, Flat_loss 0.20, Train_acc 96.95, Test_acc 75.37
2025-02-13 17:27:48,625 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.14, Spatial_loss 2.32, Flat_loss 0.20, Train_acc 97.15, Test_acc 75.56
2025-02-13 17:27:50,000 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.13, Spatial_loss 2.30, Flat_loss 0.20, Train_acc 97.25, Test_acc 75.40
2025-02-13 17:27:51,400 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.13, Spatial_loss 2.27, Flat_loss 0.20, Train_acc 97.95, Test_acc 75.35
2025-02-13 17:27:52,732 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.13, Spatial_loss 2.22, Flat_loss 0.20, Train_acc 97.60, Test_acc 75.35
2025-02-13 17:27:54,115 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 2.23, Flat_loss 0.20, Train_acc 97.50, Test_acc 75.48
2025-02-13 17:27:55,529 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.14, Spatial_loss 2.26, Flat_loss 0.20, Train_acc 97.10, Test_acc 75.54
2025-02-13 17:27:56,852 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.14, Spatial_loss 2.22, Flat_loss 0.20, Train_acc 97.20, Test_acc 75.44
2025-02-13 17:27:58,202 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.13, Spatial_loss 2.23, Flat_loss 0.20, Train_acc 97.90, Test_acc 75.42
2025-02-13 17:27:59,549 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.14, Spatial_loss 2.25, Flat_loss 0.20, Train_acc 97.10, Test_acc 75.44
2025-02-13 17:28:00,951 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 2.23, Flat_loss 0.20, Train_acc 97.35, Test_acc 75.52
2025-02-13 17:28:00,952 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:28:00,952 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:28:16,838 [podnet.py] => The size of finetune dataset: 1040
2025-02-13 17:28:18,045 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.09, Spatial_loss 3.53, Flat_loss 0.31, Train_acc 97.02, Test_acc 73.40
2025-02-13 17:28:19,250 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.04, Spatial_loss 2.92, Flat_loss 0.24, Train_acc 99.33, Test_acc 74.21
2025-02-13 17:28:20,408 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.03, Spatial_loss 2.65, Flat_loss 0.17, Train_acc 99.62, Test_acc 75.40
2025-02-13 17:28:21,557 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.04, Spatial_loss 2.61, Flat_loss 0.17, Train_acc 99.52, Test_acc 75.13
2025-02-13 17:28:22,747 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.04, Spatial_loss 2.75, Flat_loss 0.17, Train_acc 99.62, Test_acc 75.73
2025-02-13 17:28:23,895 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.04, Spatial_loss 2.50, Flat_loss 0.14, Train_acc 99.33, Test_acc 75.77
2025-02-13 17:28:25,075 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.05, Spatial_loss 2.50, Flat_loss 0.13, Train_acc 99.42, Test_acc 75.60
2025-02-13 17:28:26,234 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.04, Spatial_loss 2.60, Flat_loss 0.14, Train_acc 99.52, Test_acc 75.75
2025-02-13 17:28:27,411 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.03, Spatial_loss 2.52, Flat_loss 0.14, Train_acc 99.71, Test_acc 75.87
2025-02-13 17:28:28,561 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.03, Spatial_loss 2.49, Flat_loss 0.13, Train_acc 99.62, Test_acc 76.50
2025-02-13 17:28:29,712 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.03, Spatial_loss 2.53, Flat_loss 0.14, Train_acc 99.52, Test_acc 76.27
2025-02-13 17:28:30,821 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.04, Spatial_loss 2.52, Flat_loss 0.15, Train_acc 99.33, Test_acc 75.62
2025-02-13 17:28:31,990 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.03, Spatial_loss 2.30, Flat_loss 0.12, Train_acc 99.42, Test_acc 75.94
2025-02-13 17:28:33,170 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.03, Spatial_loss 2.52, Flat_loss 0.15, Train_acc 99.81, Test_acc 76.13
2025-02-13 17:28:34,318 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.05, Spatial_loss 2.45, Flat_loss 0.14, Train_acc 99.04, Test_acc 75.96
2025-02-13 17:28:35,535 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 2.33, Flat_loss 0.12, Train_acc 98.94, Test_acc 76.23
2025-02-13 17:28:36,728 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.03, Spatial_loss 2.39, Flat_loss 0.13, Train_acc 99.23, Test_acc 75.96
2025-02-13 17:28:37,895 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.05, Spatial_loss 2.38, Flat_loss 0.12, Train_acc 99.23, Test_acc 76.10
2025-02-13 17:28:39,088 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.06, Spatial_loss 2.35, Flat_loss 0.13, Train_acc 99.13, Test_acc 76.04
2025-02-13 17:28:40,241 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.03, Spatial_loss 2.35, Flat_loss 0.13, Train_acc 99.81, Test_acc 76.12
2025-02-13 17:28:40,243 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:28:57,798 [podnet.py] => Exemplar size: 1040
2025-02-13 17:28:57,798 [trainer.py] => CNN: {'total': 76.12, '00-09': 79.0, '10-19': 70.5, '20-29': 79.5, '30-39': 73.2, '40-49': 78.5, '50-59': 75.5, 'old': 76.14, 'new': 75.5}
2025-02-13 17:28:57,798 [trainer.py] => NME: {'total': 75.6, '00-09': 79.7, '10-19': 70.2, '20-29': 78.7, '30-39': 73.6, '40-49': 78.8, '50-59': 60.5, 'old': 76.2, 'new': 60.5}
2025-02-13 17:28:57,798 [trainer.py] => CNN top1 curve: [77.7, 76.12]
2025-02-13 17:28:57,798 [trainer.py] => CNN top5 curve: [94.08, 93.71]
2025-02-13 17:28:57,798 [trainer.py] => NME top1 curve: [77.44, 75.6]
2025-02-13 17:28:57,799 [trainer.py] => NME top5 curve: [93.98, 93.54]

2025-02-13 17:28:57,799 [trainer.py] => Average Accuracy (CNN): 76.91
2025-02-13 17:28:57,799 [trainer.py] => Average Accuracy (NME): 76.52
2025-02-13 17:28:57,799 [trainer.py] => All params: 499537
2025-02-13 17:28:57,799 [trainer.py] => Trainable params: 499537
2025-02-13 17:28:57,800 [podnet.py] => Learning on 52-54
2025-02-13 17:28:57,816 [podnet.py] => Adaptive factor: 5.196152422706632
2025-02-13 17:28:59,298 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 1.40, Spatial_loss 4.77, Flat_loss 0.82, Train_acc 75.49, Test_acc 53.72
2025-02-13 17:29:00,676 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 0.37, Spatial_loss 5.33, Flat_loss 0.79, Train_acc 89.75, Test_acc 54.35
2025-02-13 17:29:02,125 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 0.32, Spatial_loss 5.17, Flat_loss 0.74, Train_acc 90.44, Test_acc 59.22
2025-02-13 17:29:03,530 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 0.27, Spatial_loss 4.90, Flat_loss 0.65, Train_acc 92.25, Test_acc 63.33
2025-02-13 17:29:04,908 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 0.24, Spatial_loss 4.69, Flat_loss 0.62, Train_acc 93.58, Test_acc 61.35
2025-02-13 17:29:06,340 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 0.25, Spatial_loss 4.58, Flat_loss 0.56, Train_acc 92.79, Test_acc 61.70
2025-02-13 17:29:07,743 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 0.21, Spatial_loss 4.25, Flat_loss 0.52, Train_acc 94.41, Test_acc 66.81
2025-02-13 17:29:09,149 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 0.20, Spatial_loss 4.47, Flat_loss 0.51, Train_acc 94.95, Test_acc 61.19
2025-02-13 17:29:10,533 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.23, Spatial_loss 4.48, Flat_loss 0.53, Train_acc 93.43, Test_acc 65.41
2025-02-13 17:29:11,928 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.21, Spatial_loss 4.31, Flat_loss 0.50, Train_acc 94.51, Test_acc 64.22
2025-02-13 17:29:13,331 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.20, Spatial_loss 4.20, Flat_loss 0.48, Train_acc 94.71, Test_acc 63.07
2025-02-13 17:29:14,744 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.21, Spatial_loss 4.31, Flat_loss 0.51, Train_acc 93.97, Test_acc 64.67
2025-02-13 17:29:16,124 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.19, Spatial_loss 4.33, Flat_loss 0.49, Train_acc 95.20, Test_acc 64.39
2025-02-13 17:29:17,546 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.20, Spatial_loss 4.23, Flat_loss 0.49, Train_acc 95.00, Test_acc 66.07
2025-02-13 17:29:18,877 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.21, Spatial_loss 4.28, Flat_loss 0.47, Train_acc 94.75, Test_acc 67.48
2025-02-13 17:29:20,229 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.19, Spatial_loss 4.20, Flat_loss 0.47, Train_acc 95.05, Test_acc 65.59
2025-02-13 17:29:21,589 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.19, Spatial_loss 4.33, Flat_loss 0.47, Train_acc 95.39, Test_acc 66.87
2025-02-13 17:29:22,947 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.18, Spatial_loss 4.15, Flat_loss 0.46, Train_acc 95.64, Test_acc 66.04
2025-02-13 17:29:24,375 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.18, Spatial_loss 4.18, Flat_loss 0.46, Train_acc 95.59, Test_acc 68.35
2025-02-13 17:29:25,757 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.19, Spatial_loss 4.11, Flat_loss 0.46, Train_acc 95.15, Test_acc 66.28
2025-02-13 17:29:27,152 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.17, Spatial_loss 4.05, Flat_loss 0.44, Train_acc 95.74, Test_acc 57.69
2025-02-13 17:29:28,542 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.19, Spatial_loss 4.20, Flat_loss 0.47, Train_acc 95.05, Test_acc 63.35
2025-02-13 17:29:29,958 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.20, Spatial_loss 4.23, Flat_loss 0.46, Train_acc 94.95, Test_acc 67.57
2025-02-13 17:29:31,326 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.17, Spatial_loss 4.25, Flat_loss 0.47, Train_acc 95.54, Test_acc 67.81
2025-02-13 17:29:32,686 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.19, Spatial_loss 4.17, Flat_loss 0.44, Train_acc 94.85, Test_acc 62.52
2025-02-13 17:29:34,073 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.17, Spatial_loss 4.13, Flat_loss 0.44, Train_acc 95.25, Test_acc 66.78
2025-02-13 17:29:35,426 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.17, Spatial_loss 4.08, Flat_loss 0.44, Train_acc 95.83, Test_acc 67.28
2025-02-13 17:29:36,814 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.17, Spatial_loss 4.18, Flat_loss 0.45, Train_acc 95.54, Test_acc 66.11
2025-02-13 17:29:38,169 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.16, Spatial_loss 3.90, Flat_loss 0.43, Train_acc 96.52, Test_acc 68.28
2025-02-13 17:29:39,621 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.17, Spatial_loss 3.84, Flat_loss 0.40, Train_acc 95.93, Test_acc 68.50
2025-02-13 17:29:40,968 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.17, Spatial_loss 3.86, Flat_loss 0.41, Train_acc 96.52, Test_acc 60.94
2025-02-13 17:29:42,384 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.18, Spatial_loss 4.00, Flat_loss 0.43, Train_acc 95.93, Test_acc 70.13
2025-02-13 17:29:43,809 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.17, Spatial_loss 3.98, Flat_loss 0.42, Train_acc 96.18, Test_acc 67.52
2025-02-13 17:29:45,218 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.17, Spatial_loss 3.77, Flat_loss 0.40, Train_acc 96.03, Test_acc 68.69
2025-02-13 17:29:46,607 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.17, Spatial_loss 3.87, Flat_loss 0.42, Train_acc 95.69, Test_acc 68.48
2025-02-13 17:29:47,982 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.17, Spatial_loss 3.94, Flat_loss 0.43, Train_acc 95.39, Test_acc 68.93
2025-02-13 17:29:49,359 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.18, Spatial_loss 3.94, Flat_loss 0.41, Train_acc 95.78, Test_acc 67.30
2025-02-13 17:29:50,754 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.16, Spatial_loss 3.87, Flat_loss 0.41, Train_acc 96.47, Test_acc 68.31
2025-02-13 17:29:52,115 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.18, Spatial_loss 3.80, Flat_loss 0.39, Train_acc 95.25, Test_acc 68.96
2025-02-13 17:29:53,529 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.16, Spatial_loss 3.95, Flat_loss 0.41, Train_acc 96.52, Test_acc 66.22
2025-02-13 17:29:54,917 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.16, Spatial_loss 3.63, Flat_loss 0.40, Train_acc 96.47, Test_acc 65.28
2025-02-13 17:29:56,331 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.17, Spatial_loss 3.79, Flat_loss 0.40, Train_acc 95.98, Test_acc 67.89
2025-02-13 17:29:57,702 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.16, Spatial_loss 3.72, Flat_loss 0.40, Train_acc 95.74, Test_acc 67.98
2025-02-13 17:29:59,078 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.17, Spatial_loss 3.74, Flat_loss 0.39, Train_acc 96.18, Test_acc 68.83
2025-02-13 17:30:00,455 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.17, Spatial_loss 3.66, Flat_loss 0.40, Train_acc 95.98, Test_acc 66.81
2025-02-13 17:30:01,862 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.16, Spatial_loss 3.73, Flat_loss 0.38, Train_acc 96.23, Test_acc 68.22
2025-02-13 17:30:03,266 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.16, Spatial_loss 3.72, Flat_loss 0.38, Train_acc 96.62, Test_acc 68.04
2025-02-13 17:30:04,683 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.17, Spatial_loss 3.69, Flat_loss 0.39, Train_acc 95.83, Test_acc 66.78
2025-02-13 17:30:06,033 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.16, Spatial_loss 3.64, Flat_loss 0.39, Train_acc 95.88, Test_acc 68.81
2025-02-13 17:30:07,448 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.17, Spatial_loss 3.67, Flat_loss 0.38, Train_acc 96.08, Test_acc 65.13
2025-02-13 17:30:08,868 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.16, Spatial_loss 3.63, Flat_loss 0.38, Train_acc 96.13, Test_acc 65.91
2025-02-13 17:30:10,237 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.15, Spatial_loss 3.72, Flat_loss 0.40, Train_acc 96.32, Test_acc 68.91
2025-02-13 17:30:11,638 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.16, Spatial_loss 3.70, Flat_loss 0.38, Train_acc 96.03, Test_acc 68.52
2025-02-13 17:30:13,068 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.17, Spatial_loss 3.56, Flat_loss 0.37, Train_acc 95.93, Test_acc 66.57
2025-02-13 17:30:14,538 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.15, Spatial_loss 3.57, Flat_loss 0.37, Train_acc 96.62, Test_acc 66.04
2025-02-13 17:30:15,978 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.17, Spatial_loss 3.60, Flat_loss 0.36, Train_acc 95.83, Test_acc 66.65
2025-02-13 17:30:17,379 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.15, Spatial_loss 3.54, Flat_loss 0.38, Train_acc 95.98, Test_acc 66.87
2025-02-13 17:30:18,759 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.16, Spatial_loss 3.42, Flat_loss 0.35, Train_acc 95.83, Test_acc 70.44
2025-02-13 17:30:20,182 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.16, Spatial_loss 3.51, Flat_loss 0.36, Train_acc 95.98, Test_acc 71.41
2025-02-13 17:30:21,610 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.15, Spatial_loss 3.37, Flat_loss 0.35, Train_acc 96.76, Test_acc 67.83
2025-02-13 17:30:23,041 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.14, Spatial_loss 3.40, Flat_loss 0.36, Train_acc 96.52, Test_acc 69.70
2025-02-13 17:30:24,421 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.17, Spatial_loss 3.56, Flat_loss 0.36, Train_acc 95.39, Test_acc 69.91
2025-02-13 17:30:25,827 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.16, Spatial_loss 3.35, Flat_loss 0.34, Train_acc 95.83, Test_acc 67.26
2025-02-13 17:30:27,217 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.15, Spatial_loss 3.51, Flat_loss 0.35, Train_acc 96.47, Test_acc 69.96
2025-02-13 17:30:28,638 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.17, Spatial_loss 3.34, Flat_loss 0.34, Train_acc 96.13, Test_acc 69.87
2025-02-13 17:30:29,977 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.16, Spatial_loss 3.46, Flat_loss 0.35, Train_acc 96.08, Test_acc 68.26
2025-02-13 17:30:31,408 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.15, Spatial_loss 3.46, Flat_loss 0.35, Train_acc 96.57, Test_acc 69.63
2025-02-13 17:30:32,819 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.15, Spatial_loss 3.44, Flat_loss 0.36, Train_acc 96.62, Test_acc 69.69
2025-02-13 17:30:34,257 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.16, Spatial_loss 3.28, Flat_loss 0.33, Train_acc 96.42, Test_acc 69.50
2025-02-13 17:30:35,712 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.15, Spatial_loss 3.24, Flat_loss 0.32, Train_acc 96.72, Test_acc 67.78
2025-02-13 17:30:37,057 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.17, Spatial_loss 3.34, Flat_loss 0.33, Train_acc 95.64, Test_acc 66.09
2025-02-13 17:30:38,424 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.15, Spatial_loss 3.25, Flat_loss 0.33, Train_acc 96.37, Test_acc 69.35
2025-02-13 17:30:39,865 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.16, Spatial_loss 3.35, Flat_loss 0.34, Train_acc 95.83, Test_acc 70.89
2025-02-13 17:30:41,320 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.15, Spatial_loss 3.23, Flat_loss 0.33, Train_acc 96.57, Test_acc 70.69
2025-02-13 17:30:42,689 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.14, Spatial_loss 3.17, Flat_loss 0.33, Train_acc 97.01, Test_acc 69.17
2025-02-13 17:30:44,099 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.17, Spatial_loss 3.27, Flat_loss 0.33, Train_acc 95.69, Test_acc 70.48
2025-02-13 17:30:45,496 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.14, Spatial_loss 3.09, Flat_loss 0.32, Train_acc 97.30, Test_acc 70.19
2025-02-13 17:30:46,815 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.15, Spatial_loss 3.24, Flat_loss 0.32, Train_acc 96.42, Test_acc 70.15
2025-02-13 17:30:48,147 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.14, Spatial_loss 3.24, Flat_loss 0.31, Train_acc 97.11, Test_acc 71.85
2025-02-13 17:30:49,559 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.16, Spatial_loss 3.25, Flat_loss 0.33, Train_acc 96.03, Test_acc 70.96
2025-02-13 17:30:50,969 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.15, Spatial_loss 3.31, Flat_loss 0.32, Train_acc 96.42, Test_acc 70.13
2025-02-13 17:30:52,365 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.31, Train_acc 95.74, Test_acc 67.78
2025-02-13 17:30:53,775 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.15, Spatial_loss 3.15, Flat_loss 0.32, Train_acc 96.76, Test_acc 68.63
2025-02-13 17:30:55,161 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 3.11, Flat_loss 0.31, Train_acc 96.57, Test_acc 71.19
2025-02-13 17:30:56,569 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.15, Spatial_loss 3.06, Flat_loss 0.30, Train_acc 96.18, Test_acc 68.76
2025-02-13 17:30:58,032 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.15, Spatial_loss 3.06, Flat_loss 0.30, Train_acc 96.27, Test_acc 70.93
2025-02-13 17:30:59,423 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.16, Spatial_loss 3.25, Flat_loss 0.31, Train_acc 95.98, Test_acc 67.85
2025-02-13 17:31:00,853 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.15, Spatial_loss 3.09, Flat_loss 0.31, Train_acc 96.52, Test_acc 69.44
2025-02-13 17:31:02,278 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.15, Spatial_loss 3.04, Flat_loss 0.31, Train_acc 96.18, Test_acc 69.31
2025-02-13 17:31:03,659 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.15, Spatial_loss 3.10, Flat_loss 0.31, Train_acc 96.62, Test_acc 71.61
2025-02-13 17:31:05,003 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.16, Spatial_loss 3.05, Flat_loss 0.30, Train_acc 96.27, Test_acc 69.50
2025-02-13 17:31:06,394 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.13, Spatial_loss 2.83, Flat_loss 0.28, Train_acc 97.21, Test_acc 71.43
2025-02-13 17:31:07,810 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.15, Spatial_loss 2.86, Flat_loss 0.28, Train_acc 96.72, Test_acc 70.83
2025-02-13 17:31:09,222 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.15, Spatial_loss 2.96, Flat_loss 0.29, Train_acc 96.91, Test_acc 71.98
2025-02-13 17:31:10,554 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.15, Spatial_loss 2.86, Flat_loss 0.29, Train_acc 96.32, Test_acc 71.69
2025-02-13 17:31:11,977 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.15, Spatial_loss 2.84, Flat_loss 0.27, Train_acc 96.62, Test_acc 71.76
2025-02-13 17:31:13,371 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.15, Spatial_loss 2.86, Flat_loss 0.28, Train_acc 96.52, Test_acc 71.26
2025-02-13 17:31:14,801 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.15, Spatial_loss 2.77, Flat_loss 0.28, Train_acc 95.98, Test_acc 71.63
2025-02-13 17:31:16,208 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.15, Spatial_loss 2.70, Flat_loss 0.26, Train_acc 96.47, Test_acc 71.98
2025-02-13 17:31:17,605 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.15, Spatial_loss 2.71, Flat_loss 0.26, Train_acc 96.81, Test_acc 71.85
2025-02-13 17:31:19,020 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 2.83, Flat_loss 0.26, Train_acc 96.23, Test_acc 72.72
2025-02-13 17:31:20,481 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.15, Spatial_loss 2.76, Flat_loss 0.27, Train_acc 96.62, Test_acc 71.85
2025-02-13 17:31:21,897 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 2.77, Flat_loss 0.26, Train_acc 96.27, Test_acc 71.85
2025-02-13 17:31:23,257 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.14, Spatial_loss 2.68, Flat_loss 0.27, Train_acc 96.72, Test_acc 72.31
2025-02-13 17:31:24,646 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 2.85, Flat_loss 0.27, Train_acc 96.23, Test_acc 70.57
2025-02-13 17:31:25,994 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.15, Spatial_loss 2.85, Flat_loss 0.27, Train_acc 96.23, Test_acc 68.80
2025-02-13 17:31:27,391 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.14, Spatial_loss 2.57, Flat_loss 0.25, Train_acc 96.91, Test_acc 71.81
2025-02-13 17:31:28,756 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 2.60, Flat_loss 0.25, Train_acc 96.32, Test_acc 71.13
2025-02-13 17:31:30,181 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 2.54, Flat_loss 0.24, Train_acc 96.72, Test_acc 71.02
2025-02-13 17:31:31,584 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.15, Spatial_loss 2.60, Flat_loss 0.25, Train_acc 96.47, Test_acc 71.96
2025-02-13 17:31:32,929 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.14, Spatial_loss 2.60, Flat_loss 0.25, Train_acc 96.91, Test_acc 71.65
2025-02-13 17:31:34,316 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 2.55, Flat_loss 0.24, Train_acc 96.76, Test_acc 72.54
2025-02-13 17:31:35,708 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 2.46, Flat_loss 0.24, Train_acc 96.42, Test_acc 70.76
2025-02-13 17:31:37,172 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.15, Spatial_loss 2.51, Flat_loss 0.24, Train_acc 96.81, Test_acc 71.96
2025-02-13 17:31:38,569 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.14, Spatial_loss 2.54, Flat_loss 0.25, Train_acc 97.30, Test_acc 72.28
2025-02-13 17:31:39,969 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.15, Spatial_loss 2.43, Flat_loss 0.24, Train_acc 96.62, Test_acc 72.17
2025-02-13 17:31:41,315 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 2.43, Flat_loss 0.24, Train_acc 96.08, Test_acc 72.72
2025-02-13 17:31:42,737 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.16, Spatial_loss 2.44, Flat_loss 0.24, Train_acc 96.23, Test_acc 73.15
2025-02-13 17:31:44,191 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 2.39, Flat_loss 0.23, Train_acc 96.27, Test_acc 72.96
2025-02-13 17:31:45,584 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 2.40, Flat_loss 0.23, Train_acc 96.27, Test_acc 72.09
2025-02-13 17:31:46,979 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 2.35, Flat_loss 0.23, Train_acc 96.67, Test_acc 72.93
2025-02-13 17:31:48,419 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 2.36, Flat_loss 0.23, Train_acc 97.21, Test_acc 73.46
2025-02-13 17:31:49,833 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.15, Spatial_loss 2.30, Flat_loss 0.22, Train_acc 96.96, Test_acc 73.26
2025-02-13 17:31:51,244 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 2.31, Flat_loss 0.23, Train_acc 96.37, Test_acc 72.69
2025-02-13 17:31:52,616 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 2.18, Flat_loss 0.22, Train_acc 96.52, Test_acc 73.20
2025-02-13 17:31:54,060 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 2.17, Flat_loss 0.22, Train_acc 96.67, Test_acc 73.46
2025-02-13 17:31:55,475 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.15, Spatial_loss 2.17, Flat_loss 0.22, Train_acc 96.37, Test_acc 73.28
2025-02-13 17:31:56,878 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.15, Spatial_loss 2.22, Flat_loss 0.22, Train_acc 96.91, Test_acc 73.24
2025-02-13 17:31:58,287 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.16, Spatial_loss 2.18, Flat_loss 0.22, Train_acc 96.03, Test_acc 73.91
2025-02-13 17:31:59,701 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 2.20, Flat_loss 0.22, Train_acc 96.57, Test_acc 73.63
2025-02-13 17:32:01,121 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 2.16, Flat_loss 0.22, Train_acc 97.11, Test_acc 73.02
2025-02-13 17:32:02,509 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.15, Spatial_loss 2.12, Flat_loss 0.21, Train_acc 95.98, Test_acc 73.50
2025-02-13 17:32:03,954 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.15, Spatial_loss 2.01, Flat_loss 0.21, Train_acc 96.62, Test_acc 73.09
2025-02-13 17:32:05,380 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.15, Spatial_loss 2.09, Flat_loss 0.21, Train_acc 96.72, Test_acc 74.28
2025-02-13 17:32:06,716 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.14, Spatial_loss 2.05, Flat_loss 0.20, Train_acc 97.25, Test_acc 73.46
2025-02-13 17:32:08,116 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 2.08, Flat_loss 0.20, Train_acc 96.23, Test_acc 73.94
2025-02-13 17:32:09,509 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.14, Spatial_loss 2.00, Flat_loss 0.21, Train_acc 97.40, Test_acc 74.07
2025-02-13 17:32:10,862 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.17, Spatial_loss 2.06, Flat_loss 0.20, Train_acc 95.69, Test_acc 73.26
2025-02-13 17:32:12,227 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.14, Spatial_loss 1.96, Flat_loss 0.21, Train_acc 97.30, Test_acc 73.80
2025-02-13 17:32:13,666 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 1.96, Flat_loss 0.20, Train_acc 96.81, Test_acc 73.70
2025-02-13 17:32:15,060 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.15, Spatial_loss 2.00, Flat_loss 0.20, Train_acc 96.67, Test_acc 73.94
2025-02-13 17:32:16,430 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 2.01, Flat_loss 0.20, Train_acc 96.42, Test_acc 73.93
2025-02-13 17:32:17,830 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 1.92, Flat_loss 0.19, Train_acc 96.67, Test_acc 73.78
2025-02-13 17:32:19,213 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 1.97, Flat_loss 0.19, Train_acc 96.47, Test_acc 74.07
2025-02-13 17:32:20,599 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 2.03, Flat_loss 0.20, Train_acc 95.93, Test_acc 73.81
2025-02-13 17:32:22,003 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 1.93, Flat_loss 0.20, Train_acc 96.91, Test_acc 74.07
2025-02-13 17:32:23,384 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 1.89, Flat_loss 0.19, Train_acc 96.42, Test_acc 74.04
2025-02-13 17:32:24,772 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 2.05, Flat_loss 0.20, Train_acc 96.76, Test_acc 73.96
2025-02-13 17:32:26,159 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.14, Spatial_loss 1.92, Flat_loss 0.19, Train_acc 96.86, Test_acc 74.13
2025-02-13 17:32:27,542 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 1.92, Flat_loss 0.20, Train_acc 96.27, Test_acc 74.06
2025-02-13 17:32:28,990 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.14, Spatial_loss 1.88, Flat_loss 0.20, Train_acc 97.06, Test_acc 74.04
2025-02-13 17:32:30,454 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 1.93, Flat_loss 0.20, Train_acc 96.76, Test_acc 74.15
2025-02-13 17:32:31,829 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 1.92, Flat_loss 0.19, Train_acc 96.91, Test_acc 74.26
2025-02-13 17:32:33,283 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 1.89, Flat_loss 0.20, Train_acc 96.37, Test_acc 74.13
2025-02-13 17:32:34,705 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.15, Spatial_loss 1.93, Flat_loss 0.20, Train_acc 96.62, Test_acc 74.09
2025-02-13 17:32:36,154 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 1.85, Flat_loss 0.19, Train_acc 96.27, Test_acc 74.09
2025-02-13 17:32:37,625 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 1.85, Flat_loss 0.19, Train_acc 96.13, Test_acc 74.09
2025-02-13 17:32:39,027 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 1.92, Flat_loss 0.20, Train_acc 96.62, Test_acc 74.17
2025-02-13 17:32:40,444 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 1.85, Flat_loss 0.19, Train_acc 96.67, Test_acc 74.17
2025-02-13 17:32:41,863 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.92, Flat_loss 0.19, Train_acc 96.18, Test_acc 74.07
2025-02-13 17:32:41,863 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:32:41,863 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:32:58,758 [podnet.py] => The size of finetune dataset: 1080
2025-02-13 17:32:59,972 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.07, Spatial_loss 2.54, Flat_loss 0.22, Train_acc 98.43, Test_acc 73.57
2025-02-13 17:33:01,147 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.04, Spatial_loss 2.21, Flat_loss 0.16, Train_acc 99.63, Test_acc 73.59
2025-02-13 17:33:02,384 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.04, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 99.54, Test_acc 74.00
2025-02-13 17:33:03,583 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.04, Spatial_loss 1.95, Flat_loss 0.10, Train_acc 99.44, Test_acc 74.19
2025-02-13 17:33:04,833 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.04, Spatial_loss 2.12, Flat_loss 0.11, Train_acc 99.26, Test_acc 74.31
2025-02-13 17:33:06,014 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.05, Spatial_loss 2.02, Flat_loss 0.09, Train_acc 98.98, Test_acc 74.57
2025-02-13 17:33:07,181 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.04, Spatial_loss 2.11, Flat_loss 0.09, Train_acc 99.35, Test_acc 74.31
2025-02-13 17:33:08,322 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.05, Spatial_loss 1.81, Flat_loss 0.08, Train_acc 99.07, Test_acc 74.31
2025-02-13 17:33:09,536 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.05, Spatial_loss 1.84, Flat_loss 0.09, Train_acc 98.98, Test_acc 74.50
2025-02-13 17:33:10,694 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.06, Spatial_loss 1.89, Flat_loss 0.08, Train_acc 98.80, Test_acc 74.43
2025-02-13 17:33:11,842 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.04, Spatial_loss 1.85, Flat_loss 0.08, Train_acc 99.26, Test_acc 74.48
2025-02-13 17:33:13,030 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.05, Spatial_loss 1.73, Flat_loss 0.07, Train_acc 99.35, Test_acc 74.91
2025-02-13 17:33:14,307 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.04, Spatial_loss 1.80, Flat_loss 0.08, Train_acc 99.54, Test_acc 74.78
2025-02-13 17:33:15,505 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.04, Spatial_loss 1.78, Flat_loss 0.08, Train_acc 99.35, Test_acc 74.65
2025-02-13 17:33:16,711 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.04, Spatial_loss 1.83, Flat_loss 0.08, Train_acc 99.63, Test_acc 74.67
2025-02-13 17:33:17,927 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.04, Spatial_loss 1.87, Flat_loss 0.08, Train_acc 99.35, Test_acc 74.80
2025-02-13 17:33:19,070 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 1.90, Flat_loss 0.08, Train_acc 99.35, Test_acc 74.69
2025-02-13 17:33:20,237 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.04, Spatial_loss 1.82, Flat_loss 0.08, Train_acc 99.07, Test_acc 74.59
2025-02-13 17:33:21,439 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.05, Spatial_loss 1.81, Flat_loss 0.07, Train_acc 99.26, Test_acc 74.83
2025-02-13 17:33:22,560 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.05, Spatial_loss 1.82, Flat_loss 0.08, Train_acc 98.98, Test_acc 74.70
2025-02-13 17:33:22,563 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:33:40,778 [podnet.py] => Exemplar size: 1080
2025-02-13 17:33:40,778 [trainer.py] => CNN: {'total': 74.7, '00-09': 78.8, '10-19': 68.3, '20-29': 78.5, '30-39': 73.5, '40-49': 76.7, '50-59': 69.0, 'old': 74.98, 'new': 67.5}
2025-02-13 17:33:40,778 [trainer.py] => NME: {'total': 74.07, '00-09': 79.8, '10-19': 68.5, '20-29': 78.2, '30-39': 73.2, '40-49': 76.5, '50-59': 59.5, 'old': 74.73, 'new': 57.0}
2025-02-13 17:33:40,781 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7]
2025-02-13 17:33:40,781 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09]
2025-02-13 17:33:40,781 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07]
2025-02-13 17:33:40,781 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09]

2025-02-13 17:33:40,781 [trainer.py] => Average Accuracy (CNN): 76.17333333333333
2025-02-13 17:33:40,781 [trainer.py] => Average Accuracy (NME): 75.70333333333333
2025-02-13 17:33:40,782 [trainer.py] => All params: 500817
2025-02-13 17:33:40,782 [trainer.py] => Trainable params: 500817
2025-02-13 17:33:40,783 [podnet.py] => Learning on 54-56
2025-02-13 17:33:40,801 [podnet.py] => Adaptive factor: 5.291502622129181
2025-02-13 17:33:42,376 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 1.31, Spatial_loss 4.19, Flat_loss 0.61, Train_acc 76.63, Test_acc 56.70
2025-02-13 17:33:43,793 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 0.32, Spatial_loss 4.91, Flat_loss 0.63, Train_acc 90.91, Test_acc 62.25
2025-02-13 17:33:45,193 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 0.30, Spatial_loss 4.92, Flat_loss 0.61, Train_acc 91.39, Test_acc 62.62
2025-02-13 17:33:46,663 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 0.26, Spatial_loss 4.86, Flat_loss 0.60, Train_acc 93.12, Test_acc 65.12
2025-02-13 17:33:48,113 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 0.24, Spatial_loss 4.73, Flat_loss 0.56, Train_acc 93.32, Test_acc 62.79
2025-02-13 17:33:49,505 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 0.23, Spatial_loss 4.48, Flat_loss 0.53, Train_acc 93.75, Test_acc 60.36
2025-02-13 17:33:50,907 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 0.24, Spatial_loss 4.48, Flat_loss 0.52, Train_acc 93.94, Test_acc 63.96
2025-02-13 17:33:52,353 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 0.22, Spatial_loss 4.47, Flat_loss 0.52, Train_acc 93.46, Test_acc 63.27
2025-02-13 17:33:53,772 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 0.19, Spatial_loss 4.47, Flat_loss 0.52, Train_acc 95.34, Test_acc 62.86
2025-02-13 17:33:55,178 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 0.22, Spatial_loss 4.41, Flat_loss 0.48, Train_acc 94.62, Test_acc 61.52
2025-02-13 17:33:56,575 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.21, Spatial_loss 4.44, Flat_loss 0.53, Train_acc 94.81, Test_acc 59.04
2025-02-13 17:33:57,996 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.20, Spatial_loss 4.35, Flat_loss 0.47, Train_acc 94.62, Test_acc 64.18
2025-02-13 17:33:59,415 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.19, Spatial_loss 4.28, Flat_loss 0.46, Train_acc 95.62, Test_acc 64.46
2025-02-13 17:34:00,817 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.20, Spatial_loss 4.12, Flat_loss 0.44, Train_acc 95.10, Test_acc 63.23
2025-02-13 17:34:02,215 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.18, Spatial_loss 4.11, Flat_loss 0.42, Train_acc 95.58, Test_acc 59.14
2025-02-13 17:34:03,636 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.17, Spatial_loss 4.11, Flat_loss 0.44, Train_acc 96.30, Test_acc 66.52
2025-02-13 17:34:05,049 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.19, Spatial_loss 4.08, Flat_loss 0.43, Train_acc 95.58, Test_acc 65.84
2025-02-13 17:34:06,411 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.18, Spatial_loss 4.03, Flat_loss 0.42, Train_acc 95.29, Test_acc 64.91
2025-02-13 17:34:07,828 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.18, Spatial_loss 4.06, Flat_loss 0.43, Train_acc 95.38, Test_acc 62.34
2025-02-13 17:34:09,243 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.18, Spatial_loss 4.15, Flat_loss 0.44, Train_acc 95.62, Test_acc 63.43
2025-02-13 17:34:10,677 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.19, Spatial_loss 4.14, Flat_loss 0.43, Train_acc 95.10, Test_acc 65.09
2025-02-13 17:34:12,064 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.19, Spatial_loss 4.10, Flat_loss 0.43, Train_acc 95.58, Test_acc 64.73
2025-02-13 17:34:13,505 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.18, Spatial_loss 4.19, Flat_loss 0.44, Train_acc 95.34, Test_acc 64.96
2025-02-13 17:34:14,922 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.20, Spatial_loss 4.01, Flat_loss 0.41, Train_acc 95.53, Test_acc 62.80
2025-02-13 17:34:16,327 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.16, Spatial_loss 4.17, Flat_loss 0.44, Train_acc 96.44, Test_acc 64.32
2025-02-13 17:34:17,691 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.17, Spatial_loss 3.96, Flat_loss 0.41, Train_acc 95.77, Test_acc 64.68
2025-02-13 17:34:19,120 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.18, Spatial_loss 4.01, Flat_loss 0.42, Train_acc 95.38, Test_acc 64.11
2025-02-13 17:34:20,514 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.18, Spatial_loss 3.95, Flat_loss 0.40, Train_acc 95.62, Test_acc 63.95
2025-02-13 17:34:22,023 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.16, Spatial_loss 3.96, Flat_loss 0.42, Train_acc 95.87, Test_acc 64.43
2025-02-13 17:34:23,492 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.18, Spatial_loss 3.84, Flat_loss 0.40, Train_acc 96.30, Test_acc 64.32
2025-02-13 17:34:24,897 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.17, Spatial_loss 3.91, Flat_loss 0.40, Train_acc 96.06, Test_acc 63.98
2025-02-13 17:34:26,345 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.19, Spatial_loss 3.99, Flat_loss 0.41, Train_acc 96.25, Test_acc 63.14
2025-02-13 17:34:27,791 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.16, Spatial_loss 4.08, Flat_loss 0.43, Train_acc 96.63, Test_acc 66.62
2025-02-13 17:34:29,202 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.17, Spatial_loss 3.99, Flat_loss 0.41, Train_acc 95.53, Test_acc 63.50
2025-02-13 17:34:30,670 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.18, Spatial_loss 3.91, Flat_loss 0.40, Train_acc 96.11, Test_acc 66.64
2025-02-13 17:34:32,144 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.17, Spatial_loss 3.94, Flat_loss 0.41, Train_acc 96.68, Test_acc 65.54
2025-02-13 17:34:33,603 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.17, Spatial_loss 3.91, Flat_loss 0.41, Train_acc 96.11, Test_acc 65.79
2025-02-13 17:34:35,049 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.16, Spatial_loss 3.77, Flat_loss 0.38, Train_acc 96.49, Test_acc 64.96
2025-02-13 17:34:36,473 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.15, Spatial_loss 3.79, Flat_loss 0.37, Train_acc 96.73, Test_acc 66.50
2025-02-13 17:34:37,891 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.17, Spatial_loss 3.79, Flat_loss 0.38, Train_acc 95.48, Test_acc 67.29
2025-02-13 17:34:39,280 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.17, Spatial_loss 3.88, Flat_loss 0.39, Train_acc 96.01, Test_acc 66.02
2025-02-13 17:34:40,717 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.17, Spatial_loss 3.71, Flat_loss 0.39, Train_acc 95.96, Test_acc 61.00
2025-02-13 17:34:42,075 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.16, Spatial_loss 3.75, Flat_loss 0.39, Train_acc 96.11, Test_acc 66.84
2025-02-13 17:34:43,507 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.17, Spatial_loss 3.70, Flat_loss 0.37, Train_acc 95.77, Test_acc 64.50
2025-02-13 17:34:44,871 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.16, Spatial_loss 3.69, Flat_loss 0.38, Train_acc 96.59, Test_acc 66.66
2025-02-13 17:34:46,350 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.15, Spatial_loss 3.65, Flat_loss 0.37, Train_acc 96.39, Test_acc 63.45
2025-02-13 17:34:47,791 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.17, Spatial_loss 3.70, Flat_loss 0.37, Train_acc 95.82, Test_acc 64.62
2025-02-13 17:34:49,226 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.16, Spatial_loss 3.62, Flat_loss 0.36, Train_acc 96.54, Test_acc 67.55
2025-02-13 17:34:50,629 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.17, Spatial_loss 3.66, Flat_loss 0.35, Train_acc 96.63, Test_acc 66.59
2025-02-13 17:34:52,053 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.16, Spatial_loss 3.79, Flat_loss 0.39, Train_acc 96.06, Test_acc 67.25
2025-02-13 17:34:53,471 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.16, Spatial_loss 3.84, Flat_loss 0.39, Train_acc 96.63, Test_acc 67.38
2025-02-13 17:34:54,912 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.17, Spatial_loss 3.76, Flat_loss 0.38, Train_acc 96.30, Test_acc 66.39
2025-02-13 17:34:56,346 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.16, Spatial_loss 3.51, Flat_loss 0.36, Train_acc 96.01, Test_acc 68.71
2025-02-13 17:34:57,699 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.16, Spatial_loss 3.57, Flat_loss 0.35, Train_acc 95.77, Test_acc 66.91
2025-02-13 17:34:59,108 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.16, Spatial_loss 3.46, Flat_loss 0.34, Train_acc 96.20, Test_acc 63.84
2025-02-13 17:35:00,514 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.15, Spatial_loss 3.57, Flat_loss 0.34, Train_acc 96.20, Test_acc 65.79
2025-02-13 17:35:01,952 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.14, Spatial_loss 3.62, Flat_loss 0.35, Train_acc 96.54, Test_acc 65.71
2025-02-13 17:35:03,355 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.15, Spatial_loss 3.51, Flat_loss 0.34, Train_acc 96.20, Test_acc 65.16
2025-02-13 17:35:04,790 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.16, Spatial_loss 3.64, Flat_loss 0.36, Train_acc 96.54, Test_acc 65.55
2025-02-13 17:35:06,212 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.15, Spatial_loss 3.62, Flat_loss 0.35, Train_acc 96.20, Test_acc 64.45
2025-02-13 17:35:07,647 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.17, Spatial_loss 3.64, Flat_loss 0.36, Train_acc 96.06, Test_acc 67.00
2025-02-13 17:35:09,094 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.15, Spatial_loss 3.46, Flat_loss 0.34, Train_acc 96.54, Test_acc 68.32
2025-02-13 17:35:10,521 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.14, Spatial_loss 3.44, Flat_loss 0.33, Train_acc 96.78, Test_acc 65.96
2025-02-13 17:35:11,894 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.14, Spatial_loss 3.41, Flat_loss 0.33, Train_acc 96.49, Test_acc 66.29
2025-02-13 17:35:13,315 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.16, Spatial_loss 3.35, Flat_loss 0.33, Train_acc 96.20, Test_acc 67.55
2025-02-13 17:35:14,738 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.14, Spatial_loss 3.48, Flat_loss 0.34, Train_acc 96.59, Test_acc 66.32
2025-02-13 17:35:16,175 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.15, Spatial_loss 3.31, Flat_loss 0.32, Train_acc 96.11, Test_acc 67.96
2025-02-13 17:35:17,584 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.17, Spatial_loss 3.26, Flat_loss 0.31, Train_acc 96.15, Test_acc 67.16
2025-02-13 17:35:18,978 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.14, Spatial_loss 3.26, Flat_loss 0.32, Train_acc 96.92, Test_acc 68.77
2025-02-13 17:35:20,392 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.16, Spatial_loss 3.39, Flat_loss 0.33, Train_acc 96.30, Test_acc 65.36
2025-02-13 17:35:21,866 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.14, Spatial_loss 3.28, Flat_loss 0.33, Train_acc 96.68, Test_acc 66.95
2025-02-13 17:35:23,314 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.15, Spatial_loss 3.31, Flat_loss 0.33, Train_acc 96.35, Test_acc 66.54
2025-02-13 17:35:24,720 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.16, Spatial_loss 3.22, Flat_loss 0.31, Train_acc 96.54, Test_acc 66.59
2025-02-13 17:35:26,185 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.15, Spatial_loss 3.25, Flat_loss 0.30, Train_acc 96.68, Test_acc 67.95
2025-02-13 17:35:27,591 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.16, Spatial_loss 3.17, Flat_loss 0.30, Train_acc 96.63, Test_acc 67.95
2025-02-13 17:35:29,057 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.14, Spatial_loss 3.22, Flat_loss 0.31, Train_acc 96.44, Test_acc 60.50
2025-02-13 17:35:30,485 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.15, Spatial_loss 3.33, Flat_loss 0.32, Train_acc 96.35, Test_acc 67.64
2025-02-13 17:35:31,891 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.14, Spatial_loss 3.23, Flat_loss 0.30, Train_acc 96.59, Test_acc 68.84
2025-02-13 17:35:33,356 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.15, Spatial_loss 3.11, Flat_loss 0.29, Train_acc 96.49, Test_acc 66.45
2025-02-13 17:35:34,787 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.15, Spatial_loss 3.08, Flat_loss 0.29, Train_acc 97.21, Test_acc 67.95
2025-02-13 17:35:36,180 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 3.19, Flat_loss 0.30, Train_acc 96.63, Test_acc 68.11
2025-02-13 17:35:37,637 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.14, Spatial_loss 3.11, Flat_loss 0.31, Train_acc 96.88, Test_acc 66.59
2025-02-13 17:35:39,050 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.14, Spatial_loss 3.06, Flat_loss 0.29, Train_acc 96.54, Test_acc 67.18
2025-02-13 17:35:40,469 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 3.10, Flat_loss 0.28, Train_acc 96.20, Test_acc 68.54
2025-02-13 17:35:41,871 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.13, Spatial_loss 3.07, Flat_loss 0.29, Train_acc 97.40, Test_acc 69.66
2025-02-13 17:35:43,240 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.15, Spatial_loss 2.99, Flat_loss 0.27, Train_acc 96.92, Test_acc 68.11
2025-02-13 17:35:44,658 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.16, Spatial_loss 3.15, Flat_loss 0.30, Train_acc 95.87, Test_acc 67.09
2025-02-13 17:35:46,018 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.15, Spatial_loss 3.15, Flat_loss 0.29, Train_acc 96.11, Test_acc 69.16
2025-02-13 17:35:47,428 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.14, Spatial_loss 2.96, Flat_loss 0.28, Train_acc 97.07, Test_acc 69.20
2025-02-13 17:35:48,903 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.16, Spatial_loss 3.02, Flat_loss 0.28, Train_acc 96.11, Test_acc 68.20
2025-02-13 17:35:50,300 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.14, Spatial_loss 2.99, Flat_loss 0.28, Train_acc 96.73, Test_acc 69.82
2025-02-13 17:35:51,771 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.14, Spatial_loss 2.85, Flat_loss 0.27, Train_acc 97.45, Test_acc 69.43
2025-02-13 17:35:53,205 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.15, Spatial_loss 2.74, Flat_loss 0.26, Train_acc 96.63, Test_acc 67.50
2025-02-13 17:35:54,660 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.15, Spatial_loss 2.79, Flat_loss 0.25, Train_acc 96.73, Test_acc 68.82
2025-02-13 17:35:56,058 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.15, Spatial_loss 2.80, Flat_loss 0.27, Train_acc 96.49, Test_acc 68.86
2025-02-13 17:35:57,492 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.14, Spatial_loss 2.83, Flat_loss 0.27, Train_acc 96.73, Test_acc 66.00
2025-02-13 17:35:58,903 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.15, Spatial_loss 2.82, Flat_loss 0.27, Train_acc 97.21, Test_acc 69.68
2025-02-13 17:36:00,352 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.14, Spatial_loss 2.72, Flat_loss 0.26, Train_acc 96.88, Test_acc 68.52
2025-02-13 17:36:01,735 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.15, Spatial_loss 2.76, Flat_loss 0.25, Train_acc 96.73, Test_acc 70.50
2025-02-13 17:36:03,168 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.15, Spatial_loss 2.57, Flat_loss 0.24, Train_acc 97.02, Test_acc 68.79
2025-02-13 17:36:04,638 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 2.56, Flat_loss 0.23, Train_acc 96.97, Test_acc 69.39
2025-02-13 17:36:06,055 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.14, Spatial_loss 2.76, Flat_loss 0.25, Train_acc 96.78, Test_acc 68.43
2025-02-13 17:36:07,496 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.15, Spatial_loss 2.57, Flat_loss 0.23, Train_acc 97.02, Test_acc 68.93
2025-02-13 17:36:08,908 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.14, Spatial_loss 2.58, Flat_loss 0.24, Train_acc 96.88, Test_acc 69.14
2025-02-13 17:36:10,342 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.14, Spatial_loss 2.64, Flat_loss 0.24, Train_acc 96.92, Test_acc 69.79
2025-02-13 17:36:11,734 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.14, Spatial_loss 2.59, Flat_loss 0.24, Train_acc 96.68, Test_acc 69.23
2025-02-13 17:36:13,156 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.14, Spatial_loss 2.58, Flat_loss 0.24, Train_acc 97.07, Test_acc 70.07
2025-02-13 17:36:14,580 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.14, Spatial_loss 2.65, Flat_loss 0.23, Train_acc 96.88, Test_acc 69.50
2025-02-13 17:36:15,990 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 2.57, Flat_loss 0.23, Train_acc 96.15, Test_acc 69.38
2025-02-13 17:36:17,427 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 2.52, Flat_loss 0.22, Train_acc 96.97, Test_acc 68.86
2025-02-13 17:36:18,849 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.13, Spatial_loss 2.51, Flat_loss 0.23, Train_acc 97.12, Test_acc 69.84
2025-02-13 17:36:20,249 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.15, Spatial_loss 2.48, Flat_loss 0.23, Train_acc 96.88, Test_acc 69.61
2025-02-13 17:36:21,724 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.14, Spatial_loss 2.42, Flat_loss 0.21, Train_acc 97.31, Test_acc 70.23
2025-02-13 17:36:23,166 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.15, Spatial_loss 2.44, Flat_loss 0.22, Train_acc 96.92, Test_acc 69.04
2025-02-13 17:36:24,636 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.16, Spatial_loss 2.43, Flat_loss 0.21, Train_acc 96.35, Test_acc 70.30
2025-02-13 17:36:26,079 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.15, Spatial_loss 2.42, Flat_loss 0.22, Train_acc 96.06, Test_acc 69.46
2025-02-13 17:36:27,515 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.14, Spatial_loss 2.37, Flat_loss 0.21, Train_acc 96.92, Test_acc 69.88
2025-02-13 17:36:28,961 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.15, Spatial_loss 2.35, Flat_loss 0.21, Train_acc 96.39, Test_acc 70.16
2025-02-13 17:36:30,327 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 2.26, Flat_loss 0.21, Train_acc 96.68, Test_acc 70.98
2025-02-13 17:36:31,771 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.15, Spatial_loss 2.25, Flat_loss 0.22, Train_acc 96.83, Test_acc 70.84
2025-02-13 17:36:33,232 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 2.29, Flat_loss 0.21, Train_acc 96.78, Test_acc 70.96
2025-02-13 17:36:34,673 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 2.30, Flat_loss 0.22, Train_acc 96.39, Test_acc 70.46
2025-02-13 17:36:36,089 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 2.23, Flat_loss 0.21, Train_acc 97.31, Test_acc 70.68
2025-02-13 17:36:37,514 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 2.17, Flat_loss 0.20, Train_acc 96.35, Test_acc 70.59
2025-02-13 17:36:38,944 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 2.17, Flat_loss 0.20, Train_acc 97.12, Test_acc 70.07
2025-02-13 17:36:40,362 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 2.21, Flat_loss 0.20, Train_acc 96.97, Test_acc 70.50
2025-02-13 17:36:41,778 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.15, Spatial_loss 2.21, Flat_loss 0.20, Train_acc 96.15, Test_acc 70.46
2025-02-13 17:36:43,231 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.16, Spatial_loss 2.15, Flat_loss 0.20, Train_acc 96.63, Test_acc 69.23
2025-02-13 17:36:44,678 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.12, Spatial_loss 2.08, Flat_loss 0.21, Train_acc 98.27, Test_acc 70.91
2025-02-13 17:36:46,086 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 2.05, Flat_loss 0.19, Train_acc 96.97, Test_acc 70.62
2025-02-13 17:36:47,533 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.15, Spatial_loss 2.04, Flat_loss 0.19, Train_acc 96.49, Test_acc 70.84
2025-02-13 17:36:48,939 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.15, Spatial_loss 2.18, Flat_loss 0.20, Train_acc 96.78, Test_acc 71.36
2025-02-13 17:36:50,393 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.14, Spatial_loss 2.01, Flat_loss 0.19, Train_acc 96.92, Test_acc 71.21
2025-02-13 17:36:51,818 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.14, Spatial_loss 2.04, Flat_loss 0.19, Train_acc 96.73, Test_acc 70.55
2025-02-13 17:36:53,259 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 2.12, Flat_loss 0.18, Train_acc 96.11, Test_acc 70.61
2025-02-13 17:36:54,721 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 2.07, Flat_loss 0.20, Train_acc 96.88, Test_acc 70.88
2025-02-13 17:36:56,158 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.15, Spatial_loss 1.94, Flat_loss 0.18, Train_acc 96.83, Test_acc 70.84
2025-02-13 17:36:57,668 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 2.02, Flat_loss 0.18, Train_acc 96.20, Test_acc 71.12
2025-02-13 17:36:59,152 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.14, Spatial_loss 1.93, Flat_loss 0.18, Train_acc 97.40, Test_acc 71.52
2025-02-13 17:37:00,614 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 1.91, Flat_loss 0.18, Train_acc 96.63, Test_acc 70.98
2025-02-13 17:37:02,022 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.14, Spatial_loss 1.94, Flat_loss 0.19, Train_acc 97.16, Test_acc 71.50
2025-02-13 17:37:03,423 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 1.98, Flat_loss 0.18, Train_acc 96.73, Test_acc 71.45
2025-02-13 17:37:04,905 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.14, Spatial_loss 1.87, Flat_loss 0.18, Train_acc 97.16, Test_acc 71.54
2025-02-13 17:37:06,310 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.14, Spatial_loss 1.92, Flat_loss 0.19, Train_acc 96.97, Test_acc 71.46
2025-02-13 17:37:07,770 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.14, Spatial_loss 1.93, Flat_loss 0.19, Train_acc 97.36, Test_acc 71.48
2025-02-13 17:37:09,221 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.16, Spatial_loss 1.95, Flat_loss 0.19, Train_acc 96.25, Test_acc 71.34
2025-02-13 17:37:10,636 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.16, Spatial_loss 1.87, Flat_loss 0.18, Train_acc 96.20, Test_acc 71.27
2025-02-13 17:37:12,039 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 1.94, Flat_loss 0.19, Train_acc 96.54, Test_acc 71.32
2025-02-13 17:37:13,502 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.13, Spatial_loss 1.84, Flat_loss 0.18, Train_acc 97.16, Test_acc 71.61
2025-02-13 17:37:14,972 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 1.90, Flat_loss 0.18, Train_acc 96.68, Test_acc 71.32
2025-02-13 17:37:16,408 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.15, Spatial_loss 1.80, Flat_loss 0.18, Train_acc 96.59, Test_acc 71.21
2025-02-13 17:37:17,824 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 1.85, Flat_loss 0.18, Train_acc 96.54, Test_acc 71.32
2025-02-13 17:37:19,243 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 1.87, Flat_loss 0.17, Train_acc 96.35, Test_acc 71.45
2025-02-13 17:37:20,656 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 1.84, Flat_loss 0.17, Train_acc 96.73, Test_acc 71.38
2025-02-13 17:37:22,078 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 1.80, Flat_loss 0.17, Train_acc 97.02, Test_acc 71.30
2025-02-13 17:37:23,530 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 1.85, Flat_loss 0.17, Train_acc 96.44, Test_acc 71.48
2025-02-13 17:37:24,957 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.16, Spatial_loss 1.77, Flat_loss 0.17, Train_acc 96.11, Test_acc 71.68
2025-02-13 17:37:26,363 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.14, Spatial_loss 1.82, Flat_loss 0.17, Train_acc 96.59, Test_acc 71.29
2025-02-13 17:37:27,804 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 1.77, Flat_loss 0.17, Train_acc 96.92, Test_acc 71.57
2025-02-13 17:37:29,246 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 1.81, Flat_loss 0.17, Train_acc 96.44, Test_acc 71.50
2025-02-13 17:37:29,246 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:37:29,247 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:37:46,827 [podnet.py] => The size of finetune dataset: 1120
2025-02-13 17:37:48,033 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.07, Spatial_loss 2.15, Flat_loss 0.19, Train_acc 98.66, Test_acc 70.79
2025-02-13 17:37:49,252 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.05, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 99.46, Test_acc 70.55
2025-02-13 17:37:50,478 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.04, Spatial_loss 1.76, Flat_loss 0.09, Train_acc 99.46, Test_acc 71.61
2025-02-13 17:37:51,691 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.05, Spatial_loss 1.74, Flat_loss 0.09, Train_acc 99.38, Test_acc 71.86
2025-02-13 17:37:52,831 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.05, Spatial_loss 1.75, Flat_loss 0.08, Train_acc 99.46, Test_acc 72.02
2025-02-13 17:37:54,028 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.05, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 99.20, Test_acc 71.66
2025-02-13 17:37:55,241 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.05, Spatial_loss 1.75, Flat_loss 0.07, Train_acc 99.02, Test_acc 72.36
2025-02-13 17:37:56,396 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.05, Spatial_loss 1.76, Flat_loss 0.07, Train_acc 99.29, Test_acc 72.02
2025-02-13 17:37:57,573 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.04, Spatial_loss 1.70, Flat_loss 0.07, Train_acc 99.64, Test_acc 72.23
2025-02-13 17:37:58,805 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.04, Spatial_loss 1.81, Flat_loss 0.07, Train_acc 99.46, Test_acc 72.45
2025-02-13 17:38:00,002 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.05, Spatial_loss 1.75, Flat_loss 0.07, Train_acc 98.93, Test_acc 72.43
2025-02-13 17:38:01,195 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.05, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.29, Test_acc 72.32
2025-02-13 17:38:02,442 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.05, Spatial_loss 1.64, Flat_loss 0.07, Train_acc 99.02, Test_acc 72.34
2025-02-13 17:38:03,633 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.05, Spatial_loss 1.60, Flat_loss 0.06, Train_acc 99.02, Test_acc 72.39
2025-02-13 17:38:04,793 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.05, Spatial_loss 1.62, Flat_loss 0.06, Train_acc 99.02, Test_acc 72.41
2025-02-13 17:38:05,988 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.05, Spatial_loss 1.61, Flat_loss 0.06, Train_acc 98.93, Test_acc 72.43
2025-02-13 17:38:07,146 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.05, Spatial_loss 1.75, Flat_loss 0.07, Train_acc 99.02, Test_acc 72.57
2025-02-13 17:38:08,411 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.05, Spatial_loss 1.58, Flat_loss 0.06, Train_acc 98.93, Test_acc 72.43
2025-02-13 17:38:09,634 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.05, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.29, Test_acc 72.45
2025-02-13 17:38:10,850 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 99.64, Test_acc 72.39
2025-02-13 17:38:10,852 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:38:29,940 [podnet.py] => Exemplar size: 1120
2025-02-13 17:38:29,940 [trainer.py] => CNN: {'total': 72.39, '00-09': 76.8, '10-19': 66.9, '20-29': 77.4, '30-39': 70.1, '40-49': 73.6, '50-59': 67.67, 'old': 72.76, 'new': 62.5}
2025-02-13 17:38:29,940 [trainer.py] => NME: {'total': 72.54, '00-09': 78.8, '10-19': 67.6, '20-29': 78.0, '30-39': 70.8, '40-49': 75.0, '50-59': 60.0, 'old': 73.07, 'new': 58.0}
2025-02-13 17:38:29,940 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39]
2025-02-13 17:38:29,940 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75]
2025-02-13 17:38:29,940 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54]
2025-02-13 17:38:29,940 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5]

2025-02-13 17:38:29,940 [trainer.py] => Average Accuracy (CNN): 75.22749999999999
2025-02-13 17:38:29,941 [trainer.py] => Average Accuracy (NME): 74.9125
2025-02-13 17:38:29,941 [trainer.py] => All params: 502097
2025-02-13 17:38:29,941 [trainer.py] => Trainable params: 502097
2025-02-13 17:38:29,942 [podnet.py] => Learning on 56-58
2025-02-13 17:38:29,959 [podnet.py] => Adaptive factor: 5.385164807134504
2025-02-13 17:38:31,450 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 1.39, Spatial_loss 3.85, Flat_loss 0.54, Train_acc 75.00, Test_acc 61.10
2025-02-13 17:38:32,881 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 0.39, Spatial_loss 4.37, Flat_loss 0.51, Train_acc 88.73, Test_acc 59.47
2025-02-13 17:38:34,336 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 0.34, Spatial_loss 4.26, Flat_loss 0.52, Train_acc 90.66, Test_acc 56.59
2025-02-13 17:38:35,799 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 0.32, Spatial_loss 4.37, Flat_loss 0.47, Train_acc 91.46, Test_acc 61.43
2025-02-13 17:38:37,212 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 0.28, Spatial_loss 4.16, Flat_loss 0.45, Train_acc 93.16, Test_acc 65.36
2025-02-13 17:38:38,627 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.28, Spatial_loss 4.13, Flat_loss 0.44, Train_acc 93.58, Test_acc 60.74
2025-02-13 17:38:40,023 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.26, Spatial_loss 3.96, Flat_loss 0.41, Train_acc 93.96, Test_acc 64.12
2025-02-13 17:38:41,460 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.26, Spatial_loss 3.93, Flat_loss 0.41, Train_acc 93.68, Test_acc 65.22
2025-02-13 17:38:42,869 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.26, Spatial_loss 3.96, Flat_loss 0.41, Train_acc 93.63, Test_acc 59.90
2025-02-13 17:38:44,252 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.27, Spatial_loss 4.04, Flat_loss 0.40, Train_acc 94.06, Test_acc 61.16
2025-02-13 17:38:45,742 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.26, Spatial_loss 4.04, Flat_loss 0.42, Train_acc 94.01, Test_acc 57.26
2025-02-13 17:38:47,176 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.25, Spatial_loss 3.92, Flat_loss 0.41, Train_acc 93.82, Test_acc 58.48
2025-02-13 17:38:48,658 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.24, Spatial_loss 3.93, Flat_loss 0.40, Train_acc 94.20, Test_acc 63.00
2025-02-13 17:38:50,123 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.23, Spatial_loss 3.88, Flat_loss 0.40, Train_acc 94.34, Test_acc 65.09
2025-02-13 17:38:51,572 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.23, Spatial_loss 3.82, Flat_loss 0.39, Train_acc 94.86, Test_acc 63.16
2025-02-13 17:38:53,008 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.23, Spatial_loss 3.85, Flat_loss 0.39, Train_acc 94.62, Test_acc 63.33
2025-02-13 17:38:54,437 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.23, Spatial_loss 3.87, Flat_loss 0.36, Train_acc 94.86, Test_acc 59.19
2025-02-13 17:38:55,909 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.23, Spatial_loss 3.73, Flat_loss 0.37, Train_acc 94.58, Test_acc 64.02
2025-02-13 17:38:57,402 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.22, Spatial_loss 3.89, Flat_loss 0.40, Train_acc 94.53, Test_acc 62.67
2025-02-13 17:38:58,813 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.21, Spatial_loss 3.87, Flat_loss 0.39, Train_acc 95.42, Test_acc 62.40
2025-02-13 17:39:00,273 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.20, Spatial_loss 3.79, Flat_loss 0.38, Train_acc 95.52, Test_acc 65.03
2025-02-13 17:39:01,732 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.22, Spatial_loss 3.80, Flat_loss 0.37, Train_acc 95.28, Test_acc 57.24
2025-02-13 17:39:03,238 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.20, Spatial_loss 3.75, Flat_loss 0.37, Train_acc 95.61, Test_acc 62.98
2025-02-13 17:39:04,689 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.21, Spatial_loss 3.70, Flat_loss 0.37, Train_acc 94.95, Test_acc 62.76
2025-02-13 17:39:06,143 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.21, Spatial_loss 3.69, Flat_loss 0.36, Train_acc 95.42, Test_acc 63.62
2025-02-13 17:39:07,570 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.20, Spatial_loss 3.71, Flat_loss 0.36, Train_acc 95.52, Test_acc 63.64
2025-02-13 17:39:08,998 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.22, Spatial_loss 3.77, Flat_loss 0.37, Train_acc 94.67, Test_acc 63.83
2025-02-13 17:39:10,441 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.21, Spatial_loss 3.85, Flat_loss 0.38, Train_acc 94.62, Test_acc 63.41
2025-02-13 17:39:11,921 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.21, Spatial_loss 3.53, Flat_loss 0.35, Train_acc 95.19, Test_acc 59.66
2025-02-13 17:39:13,384 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.19, Spatial_loss 3.66, Flat_loss 0.36, Train_acc 96.27, Test_acc 63.81
2025-02-13 17:39:14,776 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.20, Spatial_loss 3.70, Flat_loss 0.35, Train_acc 95.42, Test_acc 63.09
2025-02-13 17:39:16,212 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.19, Spatial_loss 3.78, Flat_loss 0.36, Train_acc 96.08, Test_acc 61.84
2025-02-13 17:39:17,652 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.19, Spatial_loss 3.77, Flat_loss 0.36, Train_acc 95.90, Test_acc 64.28
2025-02-13 17:39:19,107 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 3.64, Flat_loss 0.35, Train_acc 94.95, Test_acc 63.62
2025-02-13 17:39:20,526 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.19, Spatial_loss 3.61, Flat_loss 0.36, Train_acc 95.94, Test_acc 64.10
2025-02-13 17:39:21,954 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.19, Spatial_loss 3.61, Flat_loss 0.36, Train_acc 95.57, Test_acc 65.97
2025-02-13 17:39:23,346 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.20, Spatial_loss 3.69, Flat_loss 0.36, Train_acc 95.38, Test_acc 60.36
2025-02-13 17:39:24,779 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.21, Spatial_loss 3.69, Flat_loss 0.35, Train_acc 95.00, Test_acc 62.16
2025-02-13 17:39:26,238 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.21, Spatial_loss 3.69, Flat_loss 0.36, Train_acc 94.95, Test_acc 65.53
2025-02-13 17:39:27,701 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.20, Spatial_loss 3.72, Flat_loss 0.37, Train_acc 95.33, Test_acc 63.84
2025-02-13 17:39:29,133 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.19, Spatial_loss 3.66, Flat_loss 0.35, Train_acc 95.75, Test_acc 60.93
2025-02-13 17:39:30,553 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.19, Spatial_loss 3.58, Flat_loss 0.35, Train_acc 95.90, Test_acc 61.48
2025-02-13 17:39:32,018 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.18, Spatial_loss 3.54, Flat_loss 0.34, Train_acc 96.18, Test_acc 64.17
2025-02-13 17:39:33,484 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.18, Spatial_loss 3.35, Flat_loss 0.32, Train_acc 96.08, Test_acc 65.17
2025-02-13 17:39:34,952 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.19, Spatial_loss 3.46, Flat_loss 0.32, Train_acc 95.42, Test_acc 64.14
2025-02-13 17:39:36,406 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.18, Spatial_loss 3.43, Flat_loss 0.34, Train_acc 95.61, Test_acc 64.07
2025-02-13 17:39:37,846 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.19, Spatial_loss 3.45, Flat_loss 0.33, Train_acc 95.80, Test_acc 61.52
2025-02-13 17:39:39,261 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.20, Spatial_loss 3.46, Flat_loss 0.32, Train_acc 96.13, Test_acc 65.14
2025-02-13 17:39:40,721 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.18, Spatial_loss 3.46, Flat_loss 0.34, Train_acc 95.47, Test_acc 65.12
2025-02-13 17:39:42,161 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.18, Spatial_loss 3.48, Flat_loss 0.31, Train_acc 96.37, Test_acc 66.21
2025-02-13 17:39:43,636 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.19, Spatial_loss 3.31, Flat_loss 0.31, Train_acc 95.71, Test_acc 64.62
2025-02-13 17:39:45,078 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.18, Spatial_loss 3.24, Flat_loss 0.31, Train_acc 96.37, Test_acc 63.40
2025-02-13 17:39:46,476 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.19, Spatial_loss 3.27, Flat_loss 0.31, Train_acc 95.99, Test_acc 64.45
2025-02-13 17:39:47,905 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.19, Spatial_loss 3.36, Flat_loss 0.31, Train_acc 96.08, Test_acc 67.09
2025-02-13 17:39:49,350 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.19, Spatial_loss 3.30, Flat_loss 0.31, Train_acc 95.94, Test_acc 66.12
2025-02-13 17:39:50,765 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.19, Spatial_loss 3.24, Flat_loss 0.30, Train_acc 95.61, Test_acc 61.26
2025-02-13 17:39:52,195 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.18, Spatial_loss 3.25, Flat_loss 0.31, Train_acc 96.13, Test_acc 64.60
2025-02-13 17:39:53,589 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.17, Spatial_loss 3.24, Flat_loss 0.30, Train_acc 96.75, Test_acc 67.00
2025-02-13 17:39:55,024 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.17, Spatial_loss 3.09, Flat_loss 0.29, Train_acc 96.42, Test_acc 63.52
2025-02-13 17:39:56,487 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.19, Spatial_loss 3.31, Flat_loss 0.29, Train_acc 95.94, Test_acc 64.00
2025-02-13 17:39:57,896 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.19, Spatial_loss 3.32, Flat_loss 0.30, Train_acc 95.90, Test_acc 66.17
2025-02-13 17:39:59,338 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.18, Spatial_loss 3.16, Flat_loss 0.30, Train_acc 96.08, Test_acc 65.57
2025-02-13 17:40:00,785 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.19, Spatial_loss 3.17, Flat_loss 0.30, Train_acc 96.27, Test_acc 63.60
2025-02-13 17:40:02,243 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.17, Spatial_loss 3.18, Flat_loss 0.29, Train_acc 96.32, Test_acc 66.07
2025-02-13 17:40:03,625 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.19, Spatial_loss 3.11, Flat_loss 0.28, Train_acc 95.94, Test_acc 64.78
2025-02-13 17:40:05,095 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.19, Spatial_loss 3.16, Flat_loss 0.29, Train_acc 95.66, Test_acc 64.59
2025-02-13 17:40:06,489 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.30, Train_acc 96.27, Test_acc 65.48
2025-02-13 17:40:07,965 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.20, Spatial_loss 3.16, Flat_loss 0.30, Train_acc 95.00, Test_acc 65.98
2025-02-13 17:40:09,368 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.17, Spatial_loss 3.05, Flat_loss 0.28, Train_acc 96.51, Test_acc 63.26
2025-02-13 17:40:10,761 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.17, Spatial_loss 3.08, Flat_loss 0.28, Train_acc 96.37, Test_acc 63.79
2025-02-13 17:40:12,198 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.18, Spatial_loss 3.05, Flat_loss 0.28, Train_acc 96.70, Test_acc 63.71
2025-02-13 17:40:13,623 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.17, Spatial_loss 3.06, Flat_loss 0.28, Train_acc 96.51, Test_acc 64.72
2025-02-13 17:40:15,024 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.18, Spatial_loss 3.09, Flat_loss 0.28, Train_acc 96.70, Test_acc 62.91
2025-02-13 17:40:16,438 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.19, Spatial_loss 2.98, Flat_loss 0.27, Train_acc 95.90, Test_acc 66.74
2025-02-13 17:40:17,894 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.19, Spatial_loss 3.09, Flat_loss 0.28, Train_acc 96.04, Test_acc 66.40
2025-02-13 17:40:19,375 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.19, Spatial_loss 3.09, Flat_loss 0.27, Train_acc 95.90, Test_acc 65.48
2025-02-13 17:40:20,808 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.19, Spatial_loss 3.05, Flat_loss 0.28, Train_acc 95.94, Test_acc 64.22
2025-02-13 17:40:22,251 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.17, Spatial_loss 3.03, Flat_loss 0.28, Train_acc 96.42, Test_acc 66.45
2025-02-13 17:40:23,662 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.17, Spatial_loss 2.73, Flat_loss 0.25, Train_acc 96.04, Test_acc 65.60
2025-02-13 17:40:25,100 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.18, Spatial_loss 3.02, Flat_loss 0.27, Train_acc 96.13, Test_acc 65.34
2025-02-13 17:40:26,590 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 2.87, Flat_loss 0.27, Train_acc 96.60, Test_acc 66.33
2025-02-13 17:40:28,080 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.18, Spatial_loss 2.88, Flat_loss 0.26, Train_acc 96.23, Test_acc 66.36
2025-02-13 17:40:29,474 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.17, Spatial_loss 2.80, Flat_loss 0.26, Train_acc 96.32, Test_acc 65.76
2025-02-13 17:40:30,917 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.19, Spatial_loss 2.98, Flat_loss 0.26, Train_acc 96.18, Test_acc 62.22
2025-02-13 17:40:32,346 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.18, Spatial_loss 2.88, Flat_loss 0.26, Train_acc 96.23, Test_acc 66.17
2025-02-13 17:40:33,772 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 2.80, Flat_loss 0.25, Train_acc 96.37, Test_acc 66.72
2025-02-13 17:40:35,211 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 2.83, Flat_loss 0.25, Train_acc 96.04, Test_acc 65.90
2025-02-13 17:40:36,666 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.19, Spatial_loss 2.80, Flat_loss 0.25, Train_acc 95.61, Test_acc 66.97
2025-02-13 17:40:38,085 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.17, Spatial_loss 2.76, Flat_loss 0.25, Train_acc 96.42, Test_acc 66.45
2025-02-13 17:40:39,533 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 2.67, Flat_loss 0.24, Train_acc 96.42, Test_acc 67.41
2025-02-13 17:40:40,911 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.16, Spatial_loss 2.77, Flat_loss 0.24, Train_acc 96.79, Test_acc 67.07
2025-02-13 17:40:42,325 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.18, Spatial_loss 2.81, Flat_loss 0.25, Train_acc 96.51, Test_acc 65.48
2025-02-13 17:40:43,788 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.18, Spatial_loss 2.71, Flat_loss 0.24, Train_acc 96.42, Test_acc 67.52
2025-02-13 17:40:45,251 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 2.58, Flat_loss 0.23, Train_acc 96.04, Test_acc 67.74
2025-02-13 17:40:46,662 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.17, Spatial_loss 2.58, Flat_loss 0.23, Train_acc 96.13, Test_acc 67.00
2025-02-13 17:40:48,113 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.17, Spatial_loss 2.49, Flat_loss 0.23, Train_acc 96.04, Test_acc 66.28
2025-02-13 17:40:49,468 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 2.49, Flat_loss 0.23, Train_acc 96.75, Test_acc 67.47
2025-02-13 17:40:50,866 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.17, Spatial_loss 2.46, Flat_loss 0.22, Train_acc 96.32, Test_acc 66.64
2025-02-13 17:40:52,293 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 2.47, Flat_loss 0.22, Train_acc 96.93, Test_acc 64.84
2025-02-13 17:40:53,714 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.17, Spatial_loss 2.59, Flat_loss 0.22, Train_acc 96.51, Test_acc 64.93
2025-02-13 17:40:55,162 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.17, Spatial_loss 2.43, Flat_loss 0.21, Train_acc 96.60, Test_acc 66.91
2025-02-13 17:40:56,645 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 2.41, Flat_loss 0.21, Train_acc 96.18, Test_acc 66.91
2025-02-13 17:40:58,134 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.17, Spatial_loss 2.42, Flat_loss 0.21, Train_acc 96.79, Test_acc 67.09
2025-02-13 17:40:59,644 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.17, Spatial_loss 2.40, Flat_loss 0.22, Train_acc 96.98, Test_acc 67.60
2025-02-13 17:41:01,107 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 2.36, Flat_loss 0.21, Train_acc 96.27, Test_acc 67.05
2025-02-13 17:41:02,541 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.17, Spatial_loss 2.37, Flat_loss 0.20, Train_acc 96.79, Test_acc 67.76
2025-02-13 17:41:03,968 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 2.39, Flat_loss 0.21, Train_acc 96.98, Test_acc 67.31
2025-02-13 17:41:05,371 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.17, Spatial_loss 2.33, Flat_loss 0.21, Train_acc 96.23, Test_acc 66.07
2025-02-13 17:41:06,791 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 2.27, Flat_loss 0.20, Train_acc 96.13, Test_acc 67.03
2025-02-13 17:41:08,212 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.17, Spatial_loss 2.21, Flat_loss 0.20, Train_acc 96.32, Test_acc 67.93
2025-02-13 17:41:09,645 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 2.39, Flat_loss 0.21, Train_acc 95.99, Test_acc 68.21
2025-02-13 17:41:11,105 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.18, Spatial_loss 2.30, Flat_loss 0.19, Train_acc 95.85, Test_acc 67.02
2025-02-13 17:41:12,531 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.17, Spatial_loss 2.31, Flat_loss 0.21, Train_acc 96.70, Test_acc 66.26
2025-02-13 17:41:13,918 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.16, Spatial_loss 2.21, Flat_loss 0.20, Train_acc 96.70, Test_acc 68.14
2025-02-13 17:41:15,334 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 2.22, Flat_loss 0.19, Train_acc 96.70, Test_acc 67.24
2025-02-13 17:41:16,813 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.19, Spatial_loss 2.19, Flat_loss 0.19, Train_acc 95.47, Test_acc 68.19
2025-02-13 17:41:18,261 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 2.19, Flat_loss 0.20, Train_acc 97.26, Test_acc 66.83
2025-02-13 17:41:19,683 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.18, Spatial_loss 2.19, Flat_loss 0.20, Train_acc 95.85, Test_acc 67.36
2025-02-13 17:41:21,153 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 2.17, Flat_loss 0.19, Train_acc 96.60, Test_acc 67.38
2025-02-13 17:41:22,593 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 2.08, Flat_loss 0.18, Train_acc 96.27, Test_acc 68.10
2025-02-13 17:41:24,047 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 2.08, Flat_loss 0.18, Train_acc 96.32, Test_acc 68.07
2025-02-13 17:41:25,467 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 2.09, Flat_loss 0.18, Train_acc 96.65, Test_acc 68.57
2025-02-13 17:41:26,906 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 1.96, Flat_loss 0.18, Train_acc 96.84, Test_acc 67.98
2025-02-13 17:41:28,328 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.18, Spatial_loss 2.02, Flat_loss 0.18, Train_acc 96.23, Test_acc 68.48
2025-02-13 17:41:29,756 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 1.95, Flat_loss 0.18, Train_acc 96.08, Test_acc 67.98
2025-02-13 17:41:31,197 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 2.00, Flat_loss 0.17, Train_acc 96.42, Test_acc 68.28
2025-02-13 17:41:32,601 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 2.00, Flat_loss 0.18, Train_acc 96.27, Test_acc 67.88
2025-02-13 17:41:34,015 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 1.97, Flat_loss 0.17, Train_acc 96.79, Test_acc 67.83
2025-02-13 17:41:35,458 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 1.97, Flat_loss 0.17, Train_acc 96.37, Test_acc 68.29
2025-02-13 17:41:36,966 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.17, Spatial_loss 1.97, Flat_loss 0.18, Train_acc 96.46, Test_acc 68.05
2025-02-13 17:41:38,465 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.17, Spatial_loss 1.93, Flat_loss 0.18, Train_acc 96.37, Test_acc 68.67
2025-02-13 17:41:39,908 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 1.92, Flat_loss 0.16, Train_acc 96.70, Test_acc 68.64
2025-02-13 17:41:41,368 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.17, Spatial_loss 1.92, Flat_loss 0.17, Train_acc 97.03, Test_acc 67.97
2025-02-13 17:41:42,833 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.86, Flat_loss 0.17, Train_acc 96.70, Test_acc 68.28
2025-02-13 17:41:44,269 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 1.81, Flat_loss 0.17, Train_acc 96.08, Test_acc 68.59
2025-02-13 17:41:45,719 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 1.88, Flat_loss 0.18, Train_acc 96.79, Test_acc 68.29
2025-02-13 17:41:47,165 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.18, Spatial_loss 1.83, Flat_loss 0.16, Train_acc 95.99, Test_acc 68.03
2025-02-13 17:41:48,630 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.18, Spatial_loss 1.81, Flat_loss 0.17, Train_acc 95.85, Test_acc 68.86
2025-02-13 17:41:50,071 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.17, Spatial_loss 1.80, Flat_loss 0.17, Train_acc 96.65, Test_acc 68.93
2025-02-13 17:41:51,585 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.17, Spatial_loss 1.82, Flat_loss 0.17, Train_acc 96.60, Test_acc 69.00
2025-02-13 17:41:52,966 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 1.79, Flat_loss 0.16, Train_acc 96.04, Test_acc 68.78
2025-02-13 17:41:54,348 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.18, Spatial_loss 1.76, Flat_loss 0.16, Train_acc 96.51, Test_acc 68.71
2025-02-13 17:41:55,791 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.72, Flat_loss 0.16, Train_acc 95.75, Test_acc 68.86
2025-02-13 17:41:57,213 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 1.79, Flat_loss 0.17, Train_acc 96.37, Test_acc 68.62
2025-02-13 17:41:58,662 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 1.69, Flat_loss 0.16, Train_acc 96.65, Test_acc 69.31
2025-02-13 17:42:00,092 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.18, Spatial_loss 1.74, Flat_loss 0.16, Train_acc 95.99, Test_acc 68.67
2025-02-13 17:42:01,499 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.81, Flat_loss 0.16, Train_acc 95.85, Test_acc 69.07
2025-02-13 17:42:02,930 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.18, Spatial_loss 1.68, Flat_loss 0.16, Train_acc 96.42, Test_acc 68.88
2025-02-13 17:42:04,344 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.18, Spatial_loss 1.73, Flat_loss 0.16, Train_acc 96.60, Test_acc 69.07
2025-02-13 17:42:05,789 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 1.66, Flat_loss 0.16, Train_acc 96.51, Test_acc 68.78
2025-02-13 17:42:07,178 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.18, Spatial_loss 1.66, Flat_loss 0.16, Train_acc 96.56, Test_acc 68.95
2025-02-13 17:42:08,543 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.18, Spatial_loss 1.69, Flat_loss 0.17, Train_acc 96.13, Test_acc 68.67
2025-02-13 17:42:09,985 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 1.67, Flat_loss 0.16, Train_acc 96.27, Test_acc 68.83
2025-02-13 17:42:11,447 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 1.66, Flat_loss 0.16, Train_acc 96.70, Test_acc 68.93
2025-02-13 17:42:12,899 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 1.68, Flat_loss 0.16, Train_acc 96.27, Test_acc 68.93
2025-02-13 17:42:14,378 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 1.67, Flat_loss 0.16, Train_acc 96.04, Test_acc 68.76
2025-02-13 17:42:15,790 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.17, Spatial_loss 1.61, Flat_loss 0.16, Train_acc 96.79, Test_acc 68.88
2025-02-13 17:42:17,261 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.17, Spatial_loss 1.66, Flat_loss 0.16, Train_acc 96.75, Test_acc 68.84
2025-02-13 17:42:18,712 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.17, Spatial_loss 1.65, Flat_loss 0.16, Train_acc 96.65, Test_acc 69.10
2025-02-13 17:42:20,128 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 1.62, Flat_loss 0.16, Train_acc 96.65, Test_acc 69.03
2025-02-13 17:42:20,130 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:42:20,130 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:42:37,941 [podnet.py] => The size of finetune dataset: 1160
2025-02-13 17:42:39,181 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.11, Spatial_loss 2.75, Flat_loss 0.31, Train_acc 97.59, Test_acc 68.33
2025-02-13 17:42:40,405 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.06, Spatial_loss 2.47, Flat_loss 0.19, Train_acc 98.79, Test_acc 68.16
2025-02-13 17:42:41,603 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.06, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 98.79, Test_acc 68.81
2025-02-13 17:42:42,870 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.07, Spatial_loss 2.28, Flat_loss 0.14, Train_acc 98.62, Test_acc 69.81
2025-02-13 17:42:44,141 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.05, Spatial_loss 2.12, Flat_loss 0.11, Train_acc 99.05, Test_acc 70.12
2025-02-13 17:42:45,306 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 2.10, Flat_loss 0.11, Train_acc 99.48, Test_acc 70.09
2025-02-13 17:42:46,525 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.05, Spatial_loss 2.04, Flat_loss 0.10, Train_acc 98.97, Test_acc 69.98
2025-02-13 17:42:47,712 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 2.16, Flat_loss 0.13, Train_acc 98.97, Test_acc 70.12
2025-02-13 17:42:48,906 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.06, Spatial_loss 2.14, Flat_loss 0.10, Train_acc 98.79, Test_acc 70.36
2025-02-13 17:42:50,199 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.09, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 99.40, Test_acc 70.22
2025-02-13 17:42:51,427 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 2.18, Flat_loss 0.13, Train_acc 98.62, Test_acc 70.36
2025-02-13 17:42:52,660 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.07, Spatial_loss 2.04, Flat_loss 0.11, Train_acc 98.88, Test_acc 70.14
2025-02-13 17:42:53,908 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.06, Spatial_loss 2.09, Flat_loss 0.10, Train_acc 99.14, Test_acc 69.84
2025-02-13 17:42:55,206 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 2.04, Flat_loss 0.12, Train_acc 99.31, Test_acc 70.09
2025-02-13 17:42:56,455 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.06, Spatial_loss 1.95, Flat_loss 0.10, Train_acc 98.97, Test_acc 70.05
2025-02-13 17:42:57,714 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.06, Spatial_loss 2.03, Flat_loss 0.13, Train_acc 99.22, Test_acc 70.16
2025-02-13 17:42:58,934 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.06, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 98.97, Test_acc 70.48
2025-02-13 17:43:00,179 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.05, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 99.14, Test_acc 70.50
2025-02-13 17:43:01,370 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.07, Spatial_loss 2.00, Flat_loss 0.11, Train_acc 99.48, Test_acc 70.29
2025-02-13 17:43:02,684 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 2.01, Flat_loss 0.13, Train_acc 99.22, Test_acc 70.34
2025-02-13 17:43:02,687 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:43:22,242 [podnet.py] => Exemplar size: 1160
2025-02-13 17:43:22,242 [trainer.py] => CNN: {'total': 70.34, '00-09': 76.6, '10-19': 65.3, '20-29': 75.6, '30-39': 68.8, '40-49': 73.6, '50-59': 60.12, 'old': 70.84, 'new': 56.5}
2025-02-13 17:43:22,242 [trainer.py] => NME: {'total': 70.62, '00-09': 78.9, '10-19': 65.1, '20-29': 76.4, '30-39': 69.4, '40-49': 74.0, '50-59': 57.25, 'old': 71.18, 'new': 55.0}
2025-02-13 17:43:22,242 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34]
2025-02-13 17:43:22,242 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4]
2025-02-13 17:43:22,242 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62]
2025-02-13 17:43:22,242 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55]

2025-02-13 17:43:22,242 [trainer.py] => Average Accuracy (CNN): 74.25
2025-02-13 17:43:22,242 [trainer.py] => Average Accuracy (NME): 74.054
2025-02-13 17:43:22,243 [trainer.py] => All params: 503377
2025-02-13 17:43:22,243 [trainer.py] => Trainable params: 503377
2025-02-13 17:43:22,244 [podnet.py] => Learning on 58-60
2025-02-13 17:43:22,260 [podnet.py] => Adaptive factor: 5.477225575051661
2025-02-13 17:43:23,723 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 1.60, Spatial_loss 4.14, Flat_loss 0.51, Train_acc 70.09, Test_acc 53.92
2025-02-13 17:43:25,130 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 0.52, Spatial_loss 4.69, Flat_loss 0.50, Train_acc 84.49, Test_acc 56.82
2025-02-13 17:43:26,584 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 0.48, Spatial_loss 4.36, Flat_loss 0.46, Train_acc 86.44, Test_acc 59.42
2025-02-13 17:43:28,094 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 0.43, Spatial_loss 4.16, Flat_loss 0.41, Train_acc 87.36, Test_acc 58.00
2025-02-13 17:43:29,507 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 0.40, Spatial_loss 4.03, Flat_loss 0.38, Train_acc 89.21, Test_acc 57.87
2025-02-13 17:43:30,976 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 0.40, Spatial_loss 4.23, Flat_loss 0.41, Train_acc 87.78, Test_acc 59.28
2025-02-13 17:43:32,401 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 0.40, Spatial_loss 4.24, Flat_loss 0.40, Train_acc 88.94, Test_acc 59.10
2025-02-13 17:43:33,920 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 0.36, Spatial_loss 4.04, Flat_loss 0.39, Train_acc 90.28, Test_acc 55.08
2025-02-13 17:43:35,408 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 0.37, Spatial_loss 3.93, Flat_loss 0.38, Train_acc 90.88, Test_acc 58.90
2025-02-13 17:43:36,865 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 0.35, Spatial_loss 3.95, Flat_loss 0.37, Train_acc 90.65, Test_acc 56.98
2025-02-13 17:43:38,255 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 0.33, Spatial_loss 3.99, Flat_loss 0.36, Train_acc 91.94, Test_acc 60.25
2025-02-13 17:43:39,659 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.35, Spatial_loss 3.91, Flat_loss 0.37, Train_acc 90.19, Test_acc 62.40
2025-02-13 17:43:41,121 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.32, Spatial_loss 4.08, Flat_loss 0.38, Train_acc 91.76, Test_acc 60.02
2025-02-13 17:43:42,592 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.34, Spatial_loss 4.02, Flat_loss 0.36, Train_acc 91.67, Test_acc 59.02
2025-02-13 17:43:44,057 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.34, Spatial_loss 3.87, Flat_loss 0.36, Train_acc 91.57, Test_acc 59.62
2025-02-13 17:43:45,514 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.32, Spatial_loss 3.93, Flat_loss 0.36, Train_acc 91.48, Test_acc 62.40
2025-02-13 17:43:46,934 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.33, Spatial_loss 3.99, Flat_loss 0.36, Train_acc 91.53, Test_acc 58.90
2025-02-13 17:43:48,397 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.30, Spatial_loss 3.88, Flat_loss 0.35, Train_acc 91.94, Test_acc 61.75
2025-02-13 17:43:49,863 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.30, Spatial_loss 3.71, Flat_loss 0.33, Train_acc 92.04, Test_acc 57.77
2025-02-13 17:43:51,305 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.31, Spatial_loss 3.78, Flat_loss 0.34, Train_acc 92.59, Test_acc 59.25
2025-02-13 17:43:52,752 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.29, Spatial_loss 3.84, Flat_loss 0.34, Train_acc 93.70, Test_acc 56.93
2025-02-13 17:43:54,195 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.28, Spatial_loss 3.61, Flat_loss 0.33, Train_acc 93.75, Test_acc 59.95
2025-02-13 17:43:55,661 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.30, Spatial_loss 3.67, Flat_loss 0.34, Train_acc 91.99, Test_acc 62.03
2025-02-13 17:43:57,144 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.30, Spatial_loss 3.79, Flat_loss 0.34, Train_acc 92.41, Test_acc 57.42
2025-02-13 17:43:58,584 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.28, Spatial_loss 3.82, Flat_loss 0.34, Train_acc 92.96, Test_acc 59.72
2025-02-13 17:44:00,055 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.31, Spatial_loss 3.84, Flat_loss 0.35, Train_acc 91.90, Test_acc 61.30
2025-02-13 17:44:01,475 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.28, Spatial_loss 3.66, Flat_loss 0.33, Train_acc 93.61, Test_acc 60.43
2025-02-13 17:44:02,973 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.28, Spatial_loss 3.67, Flat_loss 0.33, Train_acc 93.24, Test_acc 62.18
2025-02-13 17:44:04,424 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.27, Spatial_loss 3.66, Flat_loss 0.31, Train_acc 94.17, Test_acc 58.77
2025-02-13 17:44:05,859 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.27, Spatial_loss 3.71, Flat_loss 0.33, Train_acc 93.94, Test_acc 60.43
2025-02-13 17:44:07,257 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.28, Spatial_loss 3.66, Flat_loss 0.32, Train_acc 93.15, Test_acc 58.88
2025-02-13 17:44:08,726 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.26, Spatial_loss 3.75, Flat_loss 0.34, Train_acc 93.98, Test_acc 58.03
2025-02-13 17:44:10,160 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.27, Spatial_loss 3.72, Flat_loss 0.33, Train_acc 93.19, Test_acc 62.73
2025-02-13 17:44:11,600 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.27, Spatial_loss 3.66, Flat_loss 0.32, Train_acc 93.66, Test_acc 60.93
2025-02-13 17:44:13,031 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.26, Spatial_loss 3.54, Flat_loss 0.32, Train_acc 94.26, Test_acc 60.37
2025-02-13 17:44:14,530 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.26, Spatial_loss 3.75, Flat_loss 0.33, Train_acc 93.29, Test_acc 55.40
2025-02-13 17:44:15,943 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.25, Spatial_loss 3.74, Flat_loss 0.33, Train_acc 94.21, Test_acc 61.83
2025-02-13 17:44:17,356 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.25, Spatial_loss 3.54, Flat_loss 0.32, Train_acc 93.94, Test_acc 62.27
2025-02-13 17:44:18,762 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.27, Spatial_loss 3.69, Flat_loss 0.32, Train_acc 93.94, Test_acc 61.78
2025-02-13 17:44:20,205 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.27, Spatial_loss 3.53, Flat_loss 0.31, Train_acc 93.52, Test_acc 60.55
2025-02-13 17:44:21,691 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.26, Spatial_loss 3.51, Flat_loss 0.31, Train_acc 93.56, Test_acc 62.28
2025-02-13 17:44:23,137 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.25, Spatial_loss 3.57, Flat_loss 0.31, Train_acc 94.58, Test_acc 61.42
2025-02-13 17:44:24,580 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.26, Spatial_loss 3.43, Flat_loss 0.30, Train_acc 94.12, Test_acc 59.03
2025-02-13 17:44:26,048 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.25, Spatial_loss 3.44, Flat_loss 0.31, Train_acc 93.94, Test_acc 61.55
2025-02-13 17:44:27,541 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.26, Spatial_loss 3.39, Flat_loss 0.30, Train_acc 93.52, Test_acc 62.15
2025-02-13 17:44:29,013 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.25, Spatial_loss 3.57, Flat_loss 0.31, Train_acc 93.89, Test_acc 61.30
2025-02-13 17:44:30,481 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.25, Spatial_loss 3.47, Flat_loss 0.30, Train_acc 94.12, Test_acc 60.07
2025-02-13 17:44:31,897 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.26, Spatial_loss 3.36, Flat_loss 0.29, Train_acc 94.49, Test_acc 61.33
2025-02-13 17:44:33,305 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.25, Spatial_loss 3.42, Flat_loss 0.29, Train_acc 94.07, Test_acc 61.50
2025-02-13 17:44:34,746 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.26, Spatial_loss 3.44, Flat_loss 0.30, Train_acc 93.66, Test_acc 58.30
2025-02-13 17:44:36,257 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.25, Spatial_loss 3.36, Flat_loss 0.29, Train_acc 93.89, Test_acc 62.55
2025-02-13 17:44:37,730 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.24, Spatial_loss 3.46, Flat_loss 0.30, Train_acc 94.91, Test_acc 64.43
2025-02-13 17:44:39,234 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.24, Spatial_loss 3.39, Flat_loss 0.29, Train_acc 94.77, Test_acc 62.33
2025-02-13 17:44:40,680 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.25, Spatial_loss 3.35, Flat_loss 0.29, Train_acc 94.21, Test_acc 62.07
2025-02-13 17:44:42,109 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.25, Spatial_loss 3.37, Flat_loss 0.30, Train_acc 94.31, Test_acc 62.15
2025-02-13 17:44:43,554 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.23, Spatial_loss 3.37, Flat_loss 0.29, Train_acc 94.91, Test_acc 61.62
2025-02-13 17:44:45,033 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.24, Spatial_loss 3.39, Flat_loss 0.29, Train_acc 94.40, Test_acc 63.00
2025-02-13 17:44:46,454 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.24, Spatial_loss 3.32, Flat_loss 0.28, Train_acc 93.98, Test_acc 62.22
2025-02-13 17:44:47,887 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.25, Spatial_loss 3.28, Flat_loss 0.28, Train_acc 94.26, Test_acc 61.63
2025-02-13 17:44:49,365 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.24, Spatial_loss 3.29, Flat_loss 0.27, Train_acc 95.00, Test_acc 62.72
2025-02-13 17:44:50,805 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.24, Spatial_loss 3.22, Flat_loss 0.28, Train_acc 94.58, Test_acc 60.20
2025-02-13 17:44:52,232 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.26, Spatial_loss 3.21, Flat_loss 0.28, Train_acc 94.03, Test_acc 61.62
2025-02-13 17:44:53,653 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.23, Spatial_loss 3.18, Flat_loss 0.27, Train_acc 94.86, Test_acc 63.15
2025-02-13 17:44:55,082 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.25, Spatial_loss 3.24, Flat_loss 0.27, Train_acc 94.91, Test_acc 61.92
2025-02-13 17:44:56,551 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.23, Spatial_loss 3.33, Flat_loss 0.28, Train_acc 95.00, Test_acc 63.18
2025-02-13 17:44:58,010 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.23, Spatial_loss 3.20, Flat_loss 0.27, Train_acc 94.68, Test_acc 63.50
2025-02-13 17:44:59,448 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 3.22, Flat_loss 0.27, Train_acc 94.54, Test_acc 63.23
2025-02-13 17:45:00,893 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.25, Spatial_loss 3.21, Flat_loss 0.27, Train_acc 94.21, Test_acc 61.10
2025-02-13 17:45:02,298 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.17, Flat_loss 0.26, Train_acc 94.54, Test_acc 56.42
2025-02-13 17:45:03,770 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.23, Spatial_loss 3.32, Flat_loss 0.28, Train_acc 95.23, Test_acc 59.55
2025-02-13 17:45:05,180 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 3.14, Flat_loss 0.26, Train_acc 95.23, Test_acc 60.95
2025-02-13 17:45:06,725 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.23, Spatial_loss 3.05, Flat_loss 0.26, Train_acc 95.09, Test_acc 64.93
2025-02-13 17:45:08,158 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.23, Spatial_loss 3.02, Flat_loss 0.25, Train_acc 95.32, Test_acc 61.92
2025-02-13 17:45:09,602 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.23, Spatial_loss 2.94, Flat_loss 0.25, Train_acc 94.81, Test_acc 64.23
2025-02-13 17:45:11,049 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.23, Spatial_loss 3.06, Flat_loss 0.27, Train_acc 94.81, Test_acc 65.10
2025-02-13 17:45:12,473 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.25, Spatial_loss 3.03, Flat_loss 0.25, Train_acc 94.40, Test_acc 61.50
2025-02-13 17:45:13,964 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 3.11, Flat_loss 0.26, Train_acc 94.49, Test_acc 61.63
2025-02-13 17:45:15,511 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 3.03, Flat_loss 0.26, Train_acc 95.00, Test_acc 62.78
2025-02-13 17:45:16,982 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 2.90, Flat_loss 0.24, Train_acc 96.11, Test_acc 61.63
2025-02-13 17:45:18,465 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.23, Spatial_loss 2.90, Flat_loss 0.24, Train_acc 94.58, Test_acc 64.63
2025-02-13 17:45:19,922 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.22, Spatial_loss 2.83, Flat_loss 0.23, Train_acc 95.74, Test_acc 62.98
2025-02-13 17:45:21,343 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.22, Spatial_loss 2.88, Flat_loss 0.24, Train_acc 95.65, Test_acc 64.77
2025-02-13 17:45:22,798 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.22, Spatial_loss 2.87, Flat_loss 0.22, Train_acc 95.05, Test_acc 63.17
2025-02-13 17:45:24,257 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.23, Spatial_loss 2.78, Flat_loss 0.23, Train_acc 95.14, Test_acc 62.60
2025-02-13 17:45:25,728 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.24, Spatial_loss 2.88, Flat_loss 0.23, Train_acc 94.40, Test_acc 61.45
2025-02-13 17:45:27,172 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.22, Spatial_loss 2.86, Flat_loss 0.23, Train_acc 94.91, Test_acc 62.23
2025-02-13 17:45:28,639 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.22, Spatial_loss 2.82, Flat_loss 0.23, Train_acc 95.93, Test_acc 64.18
2025-02-13 17:45:30,121 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.23, Spatial_loss 2.70, Flat_loss 0.22, Train_acc 95.42, Test_acc 63.65
2025-02-13 17:45:31,533 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.23, Spatial_loss 2.77, Flat_loss 0.22, Train_acc 95.83, Test_acc 64.35
2025-02-13 17:45:32,934 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.23, Spatial_loss 2.75, Flat_loss 0.22, Train_acc 95.60, Test_acc 65.05
2025-02-13 17:45:34,380 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.22, Spatial_loss 2.61, Flat_loss 0.22, Train_acc 95.14, Test_acc 63.80
2025-02-13 17:45:35,856 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.22, Spatial_loss 2.65, Flat_loss 0.21, Train_acc 94.91, Test_acc 64.78
2025-02-13 17:45:37,341 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.22, Spatial_loss 2.59, Flat_loss 0.21, Train_acc 94.91, Test_acc 63.27
2025-02-13 17:45:38,780 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.22, Spatial_loss 2.67, Flat_loss 0.21, Train_acc 95.32, Test_acc 62.68
2025-02-13 17:45:40,228 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.23, Spatial_loss 2.61, Flat_loss 0.21, Train_acc 94.72, Test_acc 61.37
2025-02-13 17:45:41,661 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 2.70, Flat_loss 0.22, Train_acc 94.72, Test_acc 64.15
2025-02-13 17:45:43,097 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.23, Spatial_loss 2.59, Flat_loss 0.20, Train_acc 95.32, Test_acc 63.83
2025-02-13 17:45:44,502 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 2.55, Flat_loss 0.21, Train_acc 96.02, Test_acc 61.68
2025-02-13 17:45:45,939 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 2.49, Flat_loss 0.20, Train_acc 95.88, Test_acc 64.37
2025-02-13 17:45:47,458 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.23, Spatial_loss 2.52, Flat_loss 0.20, Train_acc 95.09, Test_acc 64.77
2025-02-13 17:45:48,905 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 2.57, Flat_loss 0.20, Train_acc 95.32, Test_acc 63.85
2025-02-13 17:45:50,374 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.23, Spatial_loss 2.43, Flat_loss 0.20, Train_acc 95.56, Test_acc 62.13
2025-02-13 17:45:51,848 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.22, Spatial_loss 2.38, Flat_loss 0.19, Train_acc 95.32, Test_acc 63.32
2025-02-13 17:45:53,329 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 2.38, Flat_loss 0.19, Train_acc 95.60, Test_acc 64.62
2025-02-13 17:45:54,783 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.22, Spatial_loss 2.47, Flat_loss 0.20, Train_acc 95.00, Test_acc 64.93
2025-02-13 17:45:56,250 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 2.41, Flat_loss 0.19, Train_acc 95.60, Test_acc 63.93
2025-02-13 17:45:57,691 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.21, Spatial_loss 2.41, Flat_loss 0.20, Train_acc 95.74, Test_acc 64.17
2025-02-13 17:45:59,174 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.23, Spatial_loss 2.43, Flat_loss 0.19, Train_acc 94.86, Test_acc 61.52
2025-02-13 17:46:00,602 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.23, Spatial_loss 2.39, Flat_loss 0.20, Train_acc 95.37, Test_acc 65.92
2025-02-13 17:46:02,066 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.23, Spatial_loss 2.38, Flat_loss 0.19, Train_acc 95.05, Test_acc 63.07
2025-02-13 17:46:03,558 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 2.32, Flat_loss 0.19, Train_acc 95.42, Test_acc 63.85
2025-02-13 17:46:04,977 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 2.26, Flat_loss 0.19, Train_acc 95.93, Test_acc 65.72
2025-02-13 17:46:06,440 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 2.29, Flat_loss 0.18, Train_acc 95.32, Test_acc 64.48
2025-02-13 17:46:07,947 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 2.24, Flat_loss 0.18, Train_acc 95.42, Test_acc 63.68
2025-02-13 17:46:09,328 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.23, Spatial_loss 2.26, Flat_loss 0.18, Train_acc 95.09, Test_acc 64.88
2025-02-13 17:46:10,814 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 2.26, Flat_loss 0.18, Train_acc 95.23, Test_acc 64.88
2025-02-13 17:46:12,239 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 2.21, Flat_loss 0.17, Train_acc 95.32, Test_acc 64.15
2025-02-13 17:46:13,657 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.23, Spatial_loss 2.24, Flat_loss 0.18, Train_acc 95.23, Test_acc 63.97
2025-02-13 17:46:15,101 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.22, Spatial_loss 2.17, Flat_loss 0.17, Train_acc 95.65, Test_acc 64.18
2025-02-13 17:46:16,607 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.17, Train_acc 95.51, Test_acc 65.22
2025-02-13 17:46:18,023 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.22, Spatial_loss 2.17, Flat_loss 0.18, Train_acc 95.37, Test_acc 65.40
2025-02-13 17:46:19,462 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 2.10, Flat_loss 0.17, Train_acc 94.95, Test_acc 64.65
2025-02-13 17:46:20,921 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 2.12, Flat_loss 0.16, Train_acc 94.81, Test_acc 64.65
2025-02-13 17:46:22,377 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 2.10, Flat_loss 0.17, Train_acc 95.28, Test_acc 65.37
2025-02-13 17:46:23,868 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 2.05, Flat_loss 0.16, Train_acc 95.32, Test_acc 64.05
2025-02-13 17:46:25,349 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 2.13, Flat_loss 0.16, Train_acc 95.56, Test_acc 65.43
2025-02-13 17:46:26,794 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 2.05, Flat_loss 0.16, Train_acc 95.93, Test_acc 64.48
2025-02-13 17:46:28,247 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.24, Spatial_loss 2.08, Flat_loss 0.16, Train_acc 95.19, Test_acc 63.05
2025-02-13 17:46:29,659 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.95, Flat_loss 0.16, Train_acc 94.95, Test_acc 65.28
2025-02-13 17:46:31,078 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.23, Spatial_loss 1.97, Flat_loss 0.16, Train_acc 94.86, Test_acc 65.73
2025-02-13 17:46:32,589 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 1.96, Flat_loss 0.16, Train_acc 95.23, Test_acc 65.42
2025-02-13 17:46:34,060 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.92, Flat_loss 0.16, Train_acc 95.65, Test_acc 65.05
2025-02-13 17:46:35,529 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 1.97, Flat_loss 0.16, Train_acc 95.37, Test_acc 65.93
2025-02-13 17:46:37,005 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.23, Spatial_loss 1.98, Flat_loss 0.16, Train_acc 94.63, Test_acc 65.25
2025-02-13 17:46:38,442 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.23, Spatial_loss 1.94, Flat_loss 0.16, Train_acc 95.19, Test_acc 65.32
2025-02-13 17:46:39,894 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.23, Spatial_loss 1.87, Flat_loss 0.16, Train_acc 95.00, Test_acc 65.55
2025-02-13 17:46:41,354 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.23, Spatial_loss 1.81, Flat_loss 0.15, Train_acc 95.83, Test_acc 66.05
2025-02-13 17:46:42,811 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.23, Spatial_loss 1.88, Flat_loss 0.15, Train_acc 95.37, Test_acc 66.07
2025-02-13 17:46:44,235 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.23, Spatial_loss 1.89, Flat_loss 0.15, Train_acc 95.28, Test_acc 64.85
2025-02-13 17:46:45,647 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.23, Spatial_loss 1.85, Flat_loss 0.15, Train_acc 95.19, Test_acc 66.12
2025-02-13 17:46:47,153 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.24, Spatial_loss 1.85, Flat_loss 0.15, Train_acc 94.54, Test_acc 65.67
2025-02-13 17:46:48,630 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.22, Spatial_loss 1.77, Flat_loss 0.15, Train_acc 95.09, Test_acc 65.62
2025-02-13 17:46:50,047 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.23, Spatial_loss 1.84, Flat_loss 0.15, Train_acc 94.95, Test_acc 65.87
2025-02-13 17:46:51,500 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.15, Train_acc 95.60, Test_acc 66.02
2025-02-13 17:46:53,002 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.74, Flat_loss 0.15, Train_acc 95.32, Test_acc 65.58
2025-02-13 17:46:54,388 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.23, Spatial_loss 1.78, Flat_loss 0.15, Train_acc 95.14, Test_acc 65.93
2025-02-13 17:46:55,873 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.23, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 95.05, Test_acc 65.47
2025-02-13 17:46:57,349 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.23, Spatial_loss 1.69, Flat_loss 0.14, Train_acc 95.42, Test_acc 65.83
2025-02-13 17:46:58,781 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.23, Spatial_loss 1.74, Flat_loss 0.15, Train_acc 95.46, Test_acc 65.33
2025-02-13 17:47:00,279 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 1.71, Flat_loss 0.14, Train_acc 95.09, Test_acc 66.08
2025-02-13 17:47:01,688 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.24, Spatial_loss 1.67, Flat_loss 0.14, Train_acc 95.19, Test_acc 65.93
2025-02-13 17:47:03,201 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.23, Spatial_loss 1.61, Flat_loss 0.14, Train_acc 95.37, Test_acc 65.75
2025-02-13 17:47:04,698 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.23, Spatial_loss 1.67, Flat_loss 0.15, Train_acc 95.05, Test_acc 65.92
2025-02-13 17:47:06,144 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.23, Spatial_loss 1.69, Flat_loss 0.14, Train_acc 95.14, Test_acc 65.90
2025-02-13 17:47:07,610 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.69, Flat_loss 0.14, Train_acc 95.79, Test_acc 65.95
2025-02-13 17:47:09,067 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.24, Spatial_loss 1.74, Flat_loss 0.15, Train_acc 95.05, Test_acc 65.95
2025-02-13 17:47:10,516 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.70, Flat_loss 0.14, Train_acc 95.69, Test_acc 66.12
2025-02-13 17:47:11,972 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.68, Flat_loss 0.14, Train_acc 95.69, Test_acc 65.83
2025-02-13 17:47:13,471 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.23, Spatial_loss 1.65, Flat_loss 0.14, Train_acc 95.60, Test_acc 65.85
2025-02-13 17:47:14,910 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.69, Flat_loss 0.14, Train_acc 95.83, Test_acc 66.05
2025-02-13 17:47:14,911 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:47:14,911 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:47:33,470 [podnet.py] => The size of finetune dataset: 1200
2025-02-13 17:47:34,753 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.52, Flat_loss 0.24, Train_acc 96.25, Test_acc 65.35
2025-02-13 17:47:35,980 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.08, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 98.67, Test_acc 65.25
2025-02-13 17:47:37,274 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.07, Spatial_loss 1.95, Flat_loss 0.10, Train_acc 98.58, Test_acc 66.07
2025-02-13 17:47:38,505 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.05, Spatial_loss 1.73, Flat_loss 0.08, Train_acc 99.25, Test_acc 66.62
2025-02-13 17:47:39,826 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.06, Spatial_loss 1.83, Flat_loss 0.08, Train_acc 98.83, Test_acc 66.95
2025-02-13 17:47:41,077 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.06, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 98.50, Test_acc 66.80
2025-02-13 17:47:42,344 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.07, Spatial_loss 1.80, Flat_loss 0.07, Train_acc 98.83, Test_acc 67.13
2025-02-13 17:47:43,620 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.07, Spatial_loss 1.70, Flat_loss 0.06, Train_acc 98.83, Test_acc 67.13
2025-02-13 17:47:44,759 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.07, Spatial_loss 1.70, Flat_loss 0.07, Train_acc 98.42, Test_acc 67.00
2025-02-13 17:47:45,972 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.06, Spatial_loss 1.74, Flat_loss 0.07, Train_acc 99.25, Test_acc 66.97
2025-02-13 17:47:47,203 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.07, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 98.75, Test_acc 67.22
2025-02-13 17:47:48,471 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.06, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.00, Test_acc 66.98
2025-02-13 17:47:49,786 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.07, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 98.67, Test_acc 67.18
2025-02-13 17:47:50,996 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.06, Spatial_loss 1.69, Flat_loss 0.06, Train_acc 98.92, Test_acc 67.25
2025-02-13 17:47:52,215 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.06, Spatial_loss 1.61, Flat_loss 0.06, Train_acc 99.17, Test_acc 67.08
2025-02-13 17:47:53,506 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.06, Spatial_loss 1.76, Flat_loss 0.07, Train_acc 98.75, Test_acc 67.05
2025-02-13 17:47:54,737 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.06, Spatial_loss 1.72, Flat_loss 0.07, Train_acc 98.83, Test_acc 67.05
2025-02-13 17:47:56,027 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.07, Spatial_loss 1.63, Flat_loss 0.06, Train_acc 98.50, Test_acc 67.08
2025-02-13 17:47:57,251 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.06, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 99.25, Test_acc 67.00
2025-02-13 17:47:58,586 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.06, Spatial_loss 1.70, Flat_loss 0.06, Train_acc 99.00, Test_acc 67.30
2025-02-13 17:47:58,587 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:48:19,066 [podnet.py] => Exemplar size: 1200
2025-02-13 17:48:19,066 [trainer.py] => CNN: {'total': 67.3, '00-09': 74.2, '10-19': 60.9, '20-29': 73.1, '30-39': 67.3, '40-49': 72.4, '50-59': 55.9, 'old': 67.91, 'new': 49.5}
2025-02-13 17:48:19,066 [trainer.py] => NME: {'total': 67.82, '00-09': 76.4, '10-19': 62.8, '20-29': 74.9, '30-39': 67.8, '40-49': 72.8, '50-59': 52.2, 'old': 68.67, 'new': 43.0}
2025-02-13 17:48:19,066 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3]
2025-02-13 17:48:19,066 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47]
2025-02-13 17:48:19,066 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82]
2025-02-13 17:48:19,066 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72]

2025-02-13 17:48:19,067 [trainer.py] => Average Accuracy (CNN): 73.09166666666667
2025-02-13 17:48:19,067 [trainer.py] => Average Accuracy (NME): 73.015
2025-02-13 17:48:19,067 [trainer.py] => All params: 504657
2025-02-13 17:48:19,067 [trainer.py] => Trainable params: 504657
2025-02-13 17:48:19,068 [podnet.py] => Learning on 60-62
2025-02-13 17:48:19,085 [podnet.py] => Adaptive factor: 5.5677643628300215
2025-02-13 17:48:20,591 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 1.38, Spatial_loss 4.53, Flat_loss 0.61, Train_acc 76.18, Test_acc 49.81
2025-02-13 17:48:22,059 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 0.43, Spatial_loss 5.50, Flat_loss 0.63, Train_acc 88.23, Test_acc 50.39
2025-02-13 17:48:23,511 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 0.40, Spatial_loss 5.57, Flat_loss 0.67, Train_acc 89.36, Test_acc 57.98
2025-02-13 17:48:25,038 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 0.36, Spatial_loss 5.06, Flat_loss 0.56, Train_acc 90.86, Test_acc 54.98
2025-02-13 17:48:26,567 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 0.30, Spatial_loss 5.03, Flat_loss 0.55, Train_acc 92.41, Test_acc 55.84
2025-02-13 17:48:28,083 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 0.32, Spatial_loss 4.84, Flat_loss 0.50, Train_acc 91.95, Test_acc 56.27
2025-02-13 17:48:29,547 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 0.24, Spatial_loss 4.66, Flat_loss 0.46, Train_acc 93.91, Test_acc 56.50
2025-02-13 17:48:31,010 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 0.24, Spatial_loss 4.41, Flat_loss 0.41, Train_acc 94.68, Test_acc 52.15
2025-02-13 17:48:32,539 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 0.24, Spatial_loss 4.46, Flat_loss 0.42, Train_acc 94.23, Test_acc 56.60
2025-02-13 17:48:34,062 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.25, Spatial_loss 4.54, Flat_loss 0.43, Train_acc 94.41, Test_acc 56.16
2025-02-13 17:48:35,580 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.24, Spatial_loss 4.39, Flat_loss 0.42, Train_acc 94.59, Test_acc 59.15
2025-02-13 17:48:37,089 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.24, Spatial_loss 4.38, Flat_loss 0.42, Train_acc 94.64, Test_acc 59.02
2025-02-13 17:48:38,585 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.23, Spatial_loss 4.41, Flat_loss 0.41, Train_acc 94.59, Test_acc 57.27
2025-02-13 17:48:40,055 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.22, Spatial_loss 4.25, Flat_loss 0.39, Train_acc 95.09, Test_acc 56.23
2025-02-13 17:48:41,551 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.23, Spatial_loss 4.09, Flat_loss 0.37, Train_acc 94.64, Test_acc 52.74
2025-02-13 17:48:43,062 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.23, Spatial_loss 4.16, Flat_loss 0.37, Train_acc 94.77, Test_acc 56.87
2025-02-13 17:48:44,506 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.24, Spatial_loss 4.36, Flat_loss 0.40, Train_acc 95.05, Test_acc 57.63
2025-02-13 17:48:45,962 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.19, Spatial_loss 4.32, Flat_loss 0.40, Train_acc 96.05, Test_acc 58.48
2025-02-13 17:48:47,501 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.22, Spatial_loss 4.06, Flat_loss 0.36, Train_acc 95.18, Test_acc 58.03
2025-02-13 17:48:48,972 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.21, Spatial_loss 3.97, Flat_loss 0.35, Train_acc 95.45, Test_acc 55.37
2025-02-13 17:48:50,500 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.20, Spatial_loss 4.07, Flat_loss 0.35, Train_acc 95.91, Test_acc 59.74
2025-02-13 17:48:52,067 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.22, Spatial_loss 4.16, Flat_loss 0.36, Train_acc 95.68, Test_acc 58.10
2025-02-13 17:48:53,549 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.22, Spatial_loss 4.09, Flat_loss 0.35, Train_acc 95.32, Test_acc 55.97
2025-02-13 17:48:55,045 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.22, Spatial_loss 4.09, Flat_loss 0.37, Train_acc 96.00, Test_acc 57.92
2025-02-13 17:48:56,575 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.22, Spatial_loss 4.14, Flat_loss 0.38, Train_acc 94.91, Test_acc 57.24
2025-02-13 17:48:58,084 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.21, Spatial_loss 4.01, Flat_loss 0.34, Train_acc 95.50, Test_acc 57.71
2025-02-13 17:48:59,523 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.22, Spatial_loss 4.15, Flat_loss 0.37, Train_acc 94.91, Test_acc 59.19
2025-02-13 17:49:01,002 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.19, Spatial_loss 3.87, Flat_loss 0.34, Train_acc 96.32, Test_acc 57.32
2025-02-13 17:49:02,456 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.19, Spatial_loss 3.99, Flat_loss 0.34, Train_acc 96.18, Test_acc 59.73
2025-02-13 17:49:04,007 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.19, Spatial_loss 3.92, Flat_loss 0.34, Train_acc 96.27, Test_acc 59.90
2025-02-13 17:49:05,474 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.21, Spatial_loss 3.93, Flat_loss 0.33, Train_acc 95.59, Test_acc 56.42
2025-02-13 17:49:06,989 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.20, Spatial_loss 4.02, Flat_loss 0.34, Train_acc 95.55, Test_acc 57.97
2025-02-13 17:49:08,458 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.19, Spatial_loss 4.00, Flat_loss 0.33, Train_acc 95.95, Test_acc 53.89
2025-02-13 17:49:09,924 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.19, Spatial_loss 3.97, Flat_loss 0.33, Train_acc 95.86, Test_acc 59.39
2025-02-13 17:49:11,475 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.18, Spatial_loss 3.77, Flat_loss 0.31, Train_acc 96.41, Test_acc 57.05
2025-02-13 17:49:12,971 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.20, Spatial_loss 3.86, Flat_loss 0.33, Train_acc 96.18, Test_acc 61.71
2025-02-13 17:49:14,471 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.20, Spatial_loss 3.83, Flat_loss 0.33, Train_acc 96.00, Test_acc 56.11
2025-02-13 17:49:15,931 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.21, Spatial_loss 3.99, Flat_loss 0.34, Train_acc 95.64, Test_acc 55.13
2025-02-13 17:49:17,400 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.19, Spatial_loss 4.12, Flat_loss 0.36, Train_acc 96.50, Test_acc 58.23
2025-02-13 17:49:18,874 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.19, Spatial_loss 3.84, Flat_loss 0.31, Train_acc 95.64, Test_acc 57.89
2025-02-13 17:49:20,381 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.20, Spatial_loss 3.70, Flat_loss 0.30, Train_acc 95.91, Test_acc 56.84
2025-02-13 17:49:21,885 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.18, Spatial_loss 3.77, Flat_loss 0.30, Train_acc 96.50, Test_acc 55.65
2025-02-13 17:49:23,379 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.19, Spatial_loss 3.73, Flat_loss 0.31, Train_acc 96.41, Test_acc 57.13
2025-02-13 17:49:24,877 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.18, Spatial_loss 3.81, Flat_loss 0.32, Train_acc 96.14, Test_acc 62.02
2025-02-13 17:49:26,388 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.20, Spatial_loss 3.60, Flat_loss 0.30, Train_acc 95.64, Test_acc 57.06
2025-02-13 17:49:27,833 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.18, Spatial_loss 3.65, Flat_loss 0.30, Train_acc 95.82, Test_acc 60.11
2025-02-13 17:49:29,328 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.19, Spatial_loss 3.65, Flat_loss 0.29, Train_acc 96.09, Test_acc 59.66
2025-02-13 17:49:30,892 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.19, Spatial_loss 3.77, Flat_loss 0.31, Train_acc 96.45, Test_acc 57.68
2025-02-13 17:49:32,338 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.20, Spatial_loss 3.82, Flat_loss 0.31, Train_acc 96.23, Test_acc 57.76
2025-02-13 17:49:33,789 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.17, Spatial_loss 3.67, Flat_loss 0.30, Train_acc 96.41, Test_acc 59.73
2025-02-13 17:49:35,302 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.19, Spatial_loss 3.61, Flat_loss 0.28, Train_acc 96.05, Test_acc 59.60
2025-02-13 17:49:36,806 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.18, Spatial_loss 3.58, Flat_loss 0.28, Train_acc 96.86, Test_acc 58.45
2025-02-13 17:49:38,312 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.19, Spatial_loss 3.76, Flat_loss 0.30, Train_acc 96.50, Test_acc 57.60
2025-02-13 17:49:39,843 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.18, Spatial_loss 3.60, Flat_loss 0.28, Train_acc 96.50, Test_acc 55.56
2025-02-13 17:49:41,307 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.17, Spatial_loss 3.51, Flat_loss 0.28, Train_acc 97.00, Test_acc 61.18
2025-02-13 17:49:42,840 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.19, Spatial_loss 3.51, Flat_loss 0.28, Train_acc 96.18, Test_acc 58.63
2025-02-13 17:49:44,283 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.18, Spatial_loss 3.74, Flat_loss 0.30, Train_acc 96.32, Test_acc 59.45
2025-02-13 17:49:45,831 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.17, Spatial_loss 3.42, Flat_loss 0.27, Train_acc 96.41, Test_acc 62.24
2025-02-13 17:49:47,293 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.19, Spatial_loss 3.66, Flat_loss 0.29, Train_acc 96.18, Test_acc 62.32
2025-02-13 17:49:48,758 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.18, Spatial_loss 3.44, Flat_loss 0.27, Train_acc 96.50, Test_acc 57.32
2025-02-13 17:49:50,280 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.18, Spatial_loss 3.43, Flat_loss 0.27, Train_acc 97.00, Test_acc 61.00
2025-02-13 17:49:51,856 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.17, Spatial_loss 3.50, Flat_loss 0.28, Train_acc 96.68, Test_acc 61.74
2025-02-13 17:49:53,369 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.18, Spatial_loss 3.37, Flat_loss 0.25, Train_acc 96.36, Test_acc 62.27
2025-02-13 17:49:54,940 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.18, Spatial_loss 3.39, Flat_loss 0.26, Train_acc 96.82, Test_acc 61.69
2025-02-13 17:49:56,429 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.21, Spatial_loss 3.33, Flat_loss 0.26, Train_acc 96.73, Test_acc 60.82
2025-02-13 17:49:57,903 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.19, Spatial_loss 3.49, Flat_loss 0.29, Train_acc 96.91, Test_acc 57.21
2025-02-13 17:49:59,344 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.19, Spatial_loss 3.41, Flat_loss 0.28, Train_acc 96.41, Test_acc 61.05
2025-02-13 17:50:00,830 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.18, Spatial_loss 3.41, Flat_loss 0.26, Train_acc 97.14, Test_acc 61.02
2025-02-13 17:50:02,304 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.17, Spatial_loss 3.28, Flat_loss 0.25, Train_acc 96.59, Test_acc 62.84
2025-02-13 17:50:03,822 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.18, Spatial_loss 3.28, Flat_loss 0.25, Train_acc 96.50, Test_acc 58.79
2025-02-13 17:50:05,349 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.17, Spatial_loss 3.29, Flat_loss 0.25, Train_acc 97.32, Test_acc 53.31
2025-02-13 17:50:06,857 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.17, Spatial_loss 3.41, Flat_loss 0.26, Train_acc 97.18, Test_acc 59.81
2025-02-13 17:50:08,341 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.19, Spatial_loss 3.15, Flat_loss 0.23, Train_acc 96.68, Test_acc 59.74
2025-02-13 17:50:09,860 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.15, Spatial_loss 3.25, Flat_loss 0.24, Train_acc 97.73, Test_acc 62.48
2025-02-13 17:50:11,392 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.18, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 96.27, Test_acc 57.92
2025-02-13 17:50:12,882 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.18, Spatial_loss 3.41, Flat_loss 0.25, Train_acc 96.82, Test_acc 58.76
2025-02-13 17:50:14,350 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.19, Spatial_loss 3.35, Flat_loss 0.24, Train_acc 96.36, Test_acc 61.39
2025-02-13 17:50:15,825 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.17, Spatial_loss 3.14, Flat_loss 0.23, Train_acc 96.91, Test_acc 61.58
2025-02-13 17:50:17,216 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.19, Spatial_loss 3.15, Flat_loss 0.24, Train_acc 96.82, Test_acc 58.44
2025-02-13 17:50:18,760 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.17, Spatial_loss 3.36, Flat_loss 0.27, Train_acc 96.64, Test_acc 63.79
2025-02-13 17:50:20,248 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.16, Spatial_loss 3.18, Flat_loss 0.24, Train_acc 96.64, Test_acc 60.11
2025-02-13 17:50:21,735 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.16, Spatial_loss 2.98, Flat_loss 0.22, Train_acc 97.32, Test_acc 61.48
2025-02-13 17:50:23,261 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.17, Spatial_loss 2.96, Flat_loss 0.21, Train_acc 96.14, Test_acc 56.89
2025-02-13 17:50:24,726 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.17, Spatial_loss 3.08, Flat_loss 0.23, Train_acc 96.82, Test_acc 60.50
2025-02-13 17:50:26,266 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.17, Spatial_loss 3.13, Flat_loss 0.23, Train_acc 96.73, Test_acc 62.19
2025-02-13 17:50:27,725 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 2.93, Flat_loss 0.21, Train_acc 97.05, Test_acc 61.35
2025-02-13 17:50:29,254 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 2.99, Flat_loss 0.21, Train_acc 97.32, Test_acc 58.32
2025-02-13 17:50:30,708 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.16, Spatial_loss 2.99, Flat_loss 0.21, Train_acc 97.18, Test_acc 61.19
2025-02-13 17:50:32,162 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.16, Spatial_loss 3.00, Flat_loss 0.22, Train_acc 97.00, Test_acc 59.32
2025-02-13 17:50:33,590 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 2.95, Flat_loss 0.20, Train_acc 96.73, Test_acc 62.37
2025-02-13 17:50:35,109 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.17, Spatial_loss 2.81, Flat_loss 0.21, Train_acc 97.18, Test_acc 63.02
2025-02-13 17:50:36,618 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 2.89, Flat_loss 0.20, Train_acc 97.36, Test_acc 62.37
2025-02-13 17:50:38,057 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.15, Spatial_loss 2.82, Flat_loss 0.20, Train_acc 97.41, Test_acc 62.77
2025-02-13 17:50:39,523 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.17, Spatial_loss 2.82, Flat_loss 0.20, Train_acc 96.73, Test_acc 60.98
2025-02-13 17:50:41,002 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.17, Spatial_loss 2.91, Flat_loss 0.20, Train_acc 97.27, Test_acc 59.47
2025-02-13 17:50:42,526 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.16, Spatial_loss 2.70, Flat_loss 0.20, Train_acc 96.91, Test_acc 60.87
2025-02-13 17:50:44,026 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.18, Spatial_loss 2.67, Flat_loss 0.18, Train_acc 97.05, Test_acc 60.60
2025-02-13 17:50:45,566 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 2.79, Flat_loss 0.20, Train_acc 97.50, Test_acc 62.03
2025-02-13 17:50:47,042 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.18, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 96.18, Test_acc 61.77
2025-02-13 17:50:48,476 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 2.78, Flat_loss 0.20, Train_acc 97.05, Test_acc 61.23
2025-02-13 17:50:49,884 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.18, Spatial_loss 2.71, Flat_loss 0.19, Train_acc 96.91, Test_acc 62.95
2025-02-13 17:50:51,380 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.15, Spatial_loss 2.69, Flat_loss 0.19, Train_acc 97.91, Test_acc 60.18
2025-02-13 17:50:52,937 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.16, Spatial_loss 2.66, Flat_loss 0.18, Train_acc 97.00, Test_acc 59.02
2025-02-13 17:50:54,372 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.16, Spatial_loss 2.67, Flat_loss 0.18, Train_acc 97.27, Test_acc 62.00
2025-02-13 17:50:55,893 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.17, Spatial_loss 2.70, Flat_loss 0.18, Train_acc 97.18, Test_acc 59.10
2025-02-13 17:50:57,364 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 2.69, Flat_loss 0.19, Train_acc 97.00, Test_acc 61.05
2025-02-13 17:50:58,847 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 2.61, Flat_loss 0.19, Train_acc 97.14, Test_acc 62.24
2025-02-13 17:51:00,344 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.18, Spatial_loss 2.54, Flat_loss 0.19, Train_acc 96.91, Test_acc 64.16
2025-02-13 17:51:01,860 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.17, Spatial_loss 2.44, Flat_loss 0.18, Train_acc 97.82, Test_acc 63.42
2025-02-13 17:51:03,360 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 2.56, Flat_loss 0.18, Train_acc 97.68, Test_acc 63.10
2025-02-13 17:51:04,846 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.17, Spatial_loss 2.50, Flat_loss 0.17, Train_acc 97.09, Test_acc 62.11
2025-02-13 17:51:06,368 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.17, Spatial_loss 2.36, Flat_loss 0.16, Train_acc 96.82, Test_acc 63.77
2025-02-13 17:51:07,894 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 2.43, Flat_loss 0.16, Train_acc 96.50, Test_acc 61.23
2025-02-13 17:51:09,360 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.16, Spatial_loss 2.50, Flat_loss 0.18, Train_acc 97.41, Test_acc 62.21
2025-02-13 17:51:10,839 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 2.35, Flat_loss 0.16, Train_acc 96.95, Test_acc 61.19
2025-02-13 17:51:12,415 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.16, Spatial_loss 2.43, Flat_loss 0.16, Train_acc 97.32, Test_acc 60.45
2025-02-13 17:51:13,937 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.17, Spatial_loss 2.43, Flat_loss 0.17, Train_acc 96.50, Test_acc 62.84
2025-02-13 17:51:15,499 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.16, Spatial_loss 2.38, Flat_loss 0.16, Train_acc 96.82, Test_acc 63.13
2025-02-13 17:51:17,051 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 2.18, Flat_loss 0.15, Train_acc 97.64, Test_acc 64.03
2025-02-13 17:51:18,574 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 2.32, Flat_loss 0.15, Train_acc 96.95, Test_acc 63.68
2025-02-13 17:51:20,113 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 2.38, Flat_loss 0.17, Train_acc 96.59, Test_acc 62.65
2025-02-13 17:51:21,631 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.17, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 96.82, Test_acc 63.58
2025-02-13 17:51:23,133 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 2.18, Flat_loss 0.15, Train_acc 97.55, Test_acc 63.08
2025-02-13 17:51:24,652 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 2.28, Flat_loss 0.14, Train_acc 96.45, Test_acc 63.16
2025-02-13 17:51:26,185 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.16, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 97.14, Test_acc 62.56
2025-02-13 17:51:27,703 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 97.32, Test_acc 63.53
2025-02-13 17:51:29,200 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 2.22, Flat_loss 0.15, Train_acc 97.36, Test_acc 63.52
2025-02-13 17:51:30,699 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.16, Spatial_loss 2.24, Flat_loss 0.15, Train_acc 97.59, Test_acc 62.94
2025-02-13 17:51:32,216 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.15, Spatial_loss 2.06, Flat_loss 0.14, Train_acc 98.00, Test_acc 63.34
2025-02-13 17:51:33,705 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 2.11, Flat_loss 0.14, Train_acc 96.82, Test_acc 63.42
2025-02-13 17:51:35,164 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 97.45, Test_acc 63.26
2025-02-13 17:51:36,611 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.15, Spatial_loss 2.00, Flat_loss 0.14, Train_acc 97.95, Test_acc 64.08
2025-02-13 17:51:38,093 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 97.45, Test_acc 64.02
2025-02-13 17:51:39,617 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.16, Spatial_loss 2.00, Flat_loss 0.14, Train_acc 97.55, Test_acc 63.34
2025-02-13 17:51:41,119 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 97.50, Test_acc 63.45
2025-02-13 17:51:42,625 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 97.05, Test_acc 64.34
2025-02-13 17:51:44,106 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.18, Spatial_loss 2.01, Flat_loss 0.13, Train_acc 96.73, Test_acc 63.44
2025-02-13 17:51:45,622 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.16, Spatial_loss 1.97, Flat_loss 0.14, Train_acc 97.23, Test_acc 63.65
2025-02-13 17:51:47,101 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.17, Spatial_loss 1.95, Flat_loss 0.14, Train_acc 97.36, Test_acc 64.56
2025-02-13 17:51:48,565 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.93, Flat_loss 0.14, Train_acc 97.45, Test_acc 63.55
2025-02-13 17:51:50,055 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 1.83, Flat_loss 0.13, Train_acc 97.45, Test_acc 63.05
2025-02-13 17:51:51,551 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 1.83, Flat_loss 0.13, Train_acc 97.68, Test_acc 63.69
2025-02-13 17:51:53,045 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.17, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 97.41, Test_acc 63.61
2025-02-13 17:51:54,550 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 97.14, Test_acc 63.66
2025-02-13 17:51:56,066 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 97.45, Test_acc 63.85
2025-02-13 17:51:57,559 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 97.36, Test_acc 64.21
2025-02-13 17:51:59,037 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.16, Spatial_loss 1.82, Flat_loss 0.12, Train_acc 97.59, Test_acc 63.94
2025-02-13 17:52:00,479 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 97.14, Test_acc 64.03
2025-02-13 17:52:01,949 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.17, Spatial_loss 1.78, Flat_loss 0.12, Train_acc 97.36, Test_acc 64.31
2025-02-13 17:52:03,460 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 1.72, Flat_loss 0.12, Train_acc 97.32, Test_acc 64.18
2025-02-13 17:52:05,010 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.17, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 97.09, Test_acc 64.13
2025-02-13 17:52:06,540 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.95, Test_acc 64.13
2025-02-13 17:52:08,032 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.16, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 96.95, Test_acc 63.95
2025-02-13 17:52:09,533 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.16, Spatial_loss 1.88, Flat_loss 0.12, Train_acc 97.45, Test_acc 64.06
2025-02-13 17:52:11,030 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.17, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 97.09, Test_acc 64.00
2025-02-13 17:52:12,542 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 97.68, Test_acc 64.03
2025-02-13 17:52:14,083 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.18, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.64, Test_acc 64.08
2025-02-13 17:52:15,578 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 97.45, Test_acc 63.95
2025-02-13 17:52:17,092 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.16, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 97.27, Test_acc 64.26
2025-02-13 17:52:18,576 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 97.41, Test_acc 64.11
2025-02-13 17:52:18,577 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:52:18,577 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:52:37,793 [podnet.py] => The size of finetune dataset: 1240
2025-02-13 17:52:39,078 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.13, Spatial_loss 2.44, Flat_loss 0.19, Train_acc 97.26, Test_acc 64.05
2025-02-13 17:52:40,293 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.08, Spatial_loss 1.93, Flat_loss 0.11, Train_acc 98.95, Test_acc 63.73
2025-02-13 17:52:41,539 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.06, Spatial_loss 1.77, Flat_loss 0.08, Train_acc 99.27, Test_acc 63.73
2025-02-13 17:52:42,836 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.07, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 99.27, Test_acc 65.05
2025-02-13 17:52:44,089 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.06, Spatial_loss 1.86, Flat_loss 0.07, Train_acc 99.68, Test_acc 64.53
2025-02-13 17:52:45,344 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.07, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 98.95, Test_acc 65.08
2025-02-13 17:52:46,621 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.06, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.68, Test_acc 64.77
2025-02-13 17:52:47,818 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.06, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.44, Test_acc 64.11
2025-02-13 17:52:49,085 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.06, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 99.27, Test_acc 64.97
2025-02-13 17:52:50,324 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.07, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 98.95, Test_acc 65.23
2025-02-13 17:52:51,617 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.06, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.35, Test_acc 65.13
2025-02-13 17:52:52,845 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.06, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.60, Test_acc 64.97
2025-02-13 17:52:54,116 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.06, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.03, Test_acc 65.18
2025-02-13 17:52:55,403 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.06, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 99.19, Test_acc 64.92
2025-02-13 17:52:56,660 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.06, Spatial_loss 1.61, Flat_loss 0.06, Train_acc 99.44, Test_acc 65.11
2025-02-13 17:52:57,922 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.06, Spatial_loss 1.54, Flat_loss 0.05, Train_acc 99.27, Test_acc 65.00
2025-02-13 17:52:59,203 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.06, Spatial_loss 1.60, Flat_loss 0.05, Train_acc 99.19, Test_acc 64.89
2025-02-13 17:53:00,509 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.06, Spatial_loss 1.61, Flat_loss 0.05, Train_acc 99.52, Test_acc 65.02
2025-02-13 17:53:01,754 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.07, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.19, Test_acc 64.85
2025-02-13 17:53:02,980 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.06, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 99.19, Test_acc 64.94
2025-02-13 17:53:02,983 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:53:24,313 [podnet.py] => Exemplar size: 1240
2025-02-13 17:53:24,313 [trainer.py] => CNN: {'total': 64.94, '00-09': 72.6, '10-19': 56.8, '20-29': 71.5, '30-39': 64.4, '40-49': 69.6, '50-59': 54.3, '60-69': 67.0, 'old': 64.87, 'new': 67.0}
2025-02-13 17:53:24,313 [trainer.py] => NME: {'total': 65.68, '00-09': 74.9, '10-19': 61.8, '20-29': 73.9, '30-39': 64.4, '40-49': 70.3, '50-59': 50.3, '60-69': 58.0, 'old': 65.93, 'new': 58.0}
2025-02-13 17:53:24,313 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94]
2025-02-13 17:53:24,313 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66]
2025-02-13 17:53:24,313 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68]
2025-02-13 17:53:24,313 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6]

2025-02-13 17:53:24,313 [trainer.py] => Average Accuracy (CNN): 71.92714285714285
2025-02-13 17:53:24,313 [trainer.py] => Average Accuracy (NME): 71.96714285714286
2025-02-13 17:53:24,314 [trainer.py] => All params: 505937
2025-02-13 17:53:24,314 [trainer.py] => Trainable params: 505937
2025-02-13 17:53:24,315 [podnet.py] => Learning on 62-64
2025-02-13 17:53:24,332 [podnet.py] => Adaptive factor: 5.656854249492381
2025-02-13 17:53:25,870 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 1.39, Spatial_loss 3.71, Flat_loss 0.57, Train_acc 75.67, Test_acc 54.55
2025-02-13 17:53:27,410 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 0.41, Spatial_loss 4.25, Flat_loss 0.45, Train_acc 89.51, Test_acc 50.92
2025-02-13 17:53:28,951 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 0.37, Spatial_loss 4.31, Flat_loss 0.43, Train_acc 91.25, Test_acc 53.75
2025-02-13 17:53:30,460 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 0.35, Spatial_loss 4.13, Flat_loss 0.40, Train_acc 91.96, Test_acc 50.23
2025-02-13 17:53:31,989 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 0.34, Spatial_loss 4.21, Flat_loss 0.40, Train_acc 92.14, Test_acc 54.38
2025-02-13 17:53:33,492 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 0.31, Spatial_loss 3.98, Flat_loss 0.36, Train_acc 93.04, Test_acc 57.84
2025-02-13 17:53:35,049 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 0.31, Spatial_loss 3.86, Flat_loss 0.35, Train_acc 93.84, Test_acc 58.30
2025-02-13 17:53:36,598 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 0.30, Spatial_loss 4.12, Flat_loss 0.37, Train_acc 92.72, Test_acc 55.97
2025-02-13 17:53:38,109 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 0.32, Spatial_loss 3.90, Flat_loss 0.35, Train_acc 93.17, Test_acc 54.45
2025-02-13 17:53:39,667 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 0.29, Spatial_loss 3.92, Flat_loss 0.35, Train_acc 93.75, Test_acc 55.47
2025-02-13 17:53:41,139 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 0.29, Spatial_loss 4.02, Flat_loss 0.36, Train_acc 93.17, Test_acc 53.28
2025-02-13 17:53:42,650 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 0.29, Spatial_loss 3.92, Flat_loss 0.34, Train_acc 94.06, Test_acc 58.52
2025-02-13 17:53:44,171 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 0.28, Spatial_loss 3.76, Flat_loss 0.34, Train_acc 94.02, Test_acc 56.31
2025-02-13 17:53:45,639 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.28, Spatial_loss 3.70, Flat_loss 0.32, Train_acc 94.29, Test_acc 59.12
2025-02-13 17:53:47,154 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.27, Spatial_loss 3.82, Flat_loss 0.32, Train_acc 94.33, Test_acc 55.23
2025-02-13 17:53:48,629 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.27, Spatial_loss 3.87, Flat_loss 0.33, Train_acc 94.15, Test_acc 60.45
2025-02-13 17:53:50,110 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.27, Spatial_loss 3.76, Flat_loss 0.32, Train_acc 94.64, Test_acc 56.75
2025-02-13 17:53:51,662 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.27, Spatial_loss 3.88, Flat_loss 0.34, Train_acc 94.51, Test_acc 56.36
2025-02-13 17:53:53,190 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.27, Spatial_loss 3.75, Flat_loss 0.33, Train_acc 95.09, Test_acc 59.05
2025-02-13 17:53:54,729 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.26, Spatial_loss 3.87, Flat_loss 0.35, Train_acc 94.87, Test_acc 58.84
2025-02-13 17:53:56,261 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.28, Spatial_loss 3.75, Flat_loss 0.32, Train_acc 94.42, Test_acc 54.98
2025-02-13 17:53:57,783 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.26, Spatial_loss 3.69, Flat_loss 0.32, Train_acc 94.69, Test_acc 59.06
2025-02-13 17:53:59,269 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.25, Spatial_loss 3.60, Flat_loss 0.31, Train_acc 95.04, Test_acc 58.56
2025-02-13 17:54:00,787 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.27, Spatial_loss 3.55, Flat_loss 0.31, Train_acc 94.02, Test_acc 58.62
2025-02-13 17:54:02,325 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.26, Spatial_loss 3.74, Flat_loss 0.33, Train_acc 94.82, Test_acc 53.08
2025-02-13 17:54:03,798 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.25, Spatial_loss 3.72, Flat_loss 0.32, Train_acc 95.58, Test_acc 59.55
2025-02-13 17:54:05,295 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.24, Spatial_loss 3.54, Flat_loss 0.31, Train_acc 95.62, Test_acc 60.42
2025-02-13 17:54:06,788 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.24, Spatial_loss 3.55, Flat_loss 0.31, Train_acc 95.76, Test_acc 56.78
2025-02-13 17:54:08,304 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.26, Spatial_loss 3.69, Flat_loss 0.32, Train_acc 95.04, Test_acc 57.59
2025-02-13 17:54:09,858 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.25, Spatial_loss 3.60, Flat_loss 0.31, Train_acc 95.22, Test_acc 55.88
2025-02-13 17:54:11,363 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.23, Spatial_loss 3.58, Flat_loss 0.31, Train_acc 95.71, Test_acc 60.20
2025-02-13 17:54:12,874 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.24, Spatial_loss 3.54, Flat_loss 0.31, Train_acc 95.27, Test_acc 55.30
2025-02-13 17:54:14,381 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.24, Spatial_loss 3.58, Flat_loss 0.30, Train_acc 94.78, Test_acc 60.91
2025-02-13 17:54:15,883 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.24, Spatial_loss 3.52, Flat_loss 0.29, Train_acc 95.62, Test_acc 54.81
2025-02-13 17:54:17,404 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.25, Spatial_loss 3.72, Flat_loss 0.31, Train_acc 95.58, Test_acc 57.11
2025-02-13 17:54:18,860 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.25, Spatial_loss 3.79, Flat_loss 0.33, Train_acc 94.96, Test_acc 55.92
2025-02-13 17:54:20,336 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.24, Spatial_loss 3.50, Flat_loss 0.31, Train_acc 95.54, Test_acc 57.78
2025-02-13 17:54:21,852 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.25, Spatial_loss 3.57, Flat_loss 0.32, Train_acc 94.96, Test_acc 55.73
2025-02-13 17:54:23,358 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.23, Spatial_loss 3.45, Flat_loss 0.29, Train_acc 95.54, Test_acc 59.89
2025-02-13 17:54:24,849 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.24, Spatial_loss 3.46, Flat_loss 0.29, Train_acc 95.31, Test_acc 59.95
2025-02-13 17:54:26,317 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.23, Spatial_loss 3.30, Flat_loss 0.28, Train_acc 95.40, Test_acc 58.48
2025-02-13 17:54:27,834 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.23, Spatial_loss 3.51, Flat_loss 0.29, Train_acc 95.94, Test_acc 51.95
2025-02-13 17:54:29,372 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.23, Spatial_loss 3.56, Flat_loss 0.29, Train_acc 95.54, Test_acc 57.86
2025-02-13 17:54:30,886 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.23, Spatial_loss 3.55, Flat_loss 0.30, Train_acc 95.85, Test_acc 55.70
2025-02-13 17:54:32,380 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.23, Spatial_loss 3.42, Flat_loss 0.29, Train_acc 95.49, Test_acc 60.55
2025-02-13 17:54:33,929 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.23, Spatial_loss 3.32, Flat_loss 0.27, Train_acc 95.85, Test_acc 57.48
2025-02-13 17:54:35,445 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.22, Spatial_loss 3.27, Flat_loss 0.27, Train_acc 96.21, Test_acc 59.20
2025-02-13 17:54:36,943 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.22, Spatial_loss 3.42, Flat_loss 0.27, Train_acc 95.94, Test_acc 58.41
2025-02-13 17:54:38,453 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.22, Spatial_loss 3.32, Flat_loss 0.27, Train_acc 96.16, Test_acc 59.33
2025-02-13 17:54:39,986 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.23, Spatial_loss 3.47, Flat_loss 0.29, Train_acc 95.58, Test_acc 57.83
2025-02-13 17:54:41,516 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.22, Spatial_loss 3.35, Flat_loss 0.27, Train_acc 95.36, Test_acc 59.00
2025-02-13 17:54:42,982 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.22, Spatial_loss 3.19, Flat_loss 0.26, Train_acc 95.76, Test_acc 58.84
2025-02-13 17:54:44,481 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.23, Spatial_loss 3.24, Flat_loss 0.26, Train_acc 96.21, Test_acc 54.09
2025-02-13 17:54:45,984 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.22, Spatial_loss 3.27, Flat_loss 0.27, Train_acc 95.76, Test_acc 59.86
2025-02-13 17:54:47,543 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.24, Spatial_loss 3.31, Flat_loss 0.27, Train_acc 95.71, Test_acc 56.41
2025-02-13 17:54:49,090 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.23, Spatial_loss 3.37, Flat_loss 0.28, Train_acc 95.22, Test_acc 59.25
2025-02-13 17:54:50,588 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.22, Spatial_loss 3.20, Flat_loss 0.26, Train_acc 96.29, Test_acc 59.83
2025-02-13 17:54:52,107 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.23, Spatial_loss 3.12, Flat_loss 0.26, Train_acc 95.89, Test_acc 60.81
2025-02-13 17:54:53,585 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.22, Spatial_loss 3.19, Flat_loss 0.25, Train_acc 96.74, Test_acc 60.27
2025-02-13 17:54:55,061 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.21, Spatial_loss 3.17, Flat_loss 0.26, Train_acc 96.21, Test_acc 57.97
2025-02-13 17:54:56,623 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.21, Spatial_loss 3.09, Flat_loss 0.25, Train_acc 96.92, Test_acc 61.28
2025-02-13 17:54:58,120 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.21, Spatial_loss 3.07, Flat_loss 0.25, Train_acc 96.25, Test_acc 61.12
2025-02-13 17:54:59,596 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.22, Spatial_loss 3.23, Flat_loss 0.26, Train_acc 96.12, Test_acc 59.09
2025-02-13 17:55:01,067 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.21, Spatial_loss 3.26, Flat_loss 0.25, Train_acc 96.29, Test_acc 59.58
2025-02-13 17:55:02,520 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.22, Spatial_loss 3.11, Flat_loss 0.24, Train_acc 96.07, Test_acc 59.78
2025-02-13 17:55:03,995 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.20, Spatial_loss 3.09, Flat_loss 0.25, Train_acc 96.52, Test_acc 59.45
2025-02-13 17:55:05,500 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.21, Spatial_loss 3.02, Flat_loss 0.24, Train_acc 96.52, Test_acc 58.31
2025-02-13 17:55:07,038 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.21, Spatial_loss 2.97, Flat_loss 0.24, Train_acc 96.12, Test_acc 60.81
2025-02-13 17:55:08,579 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.22, Spatial_loss 2.97, Flat_loss 0.24, Train_acc 96.47, Test_acc 57.75
2025-02-13 17:55:10,076 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.22, Spatial_loss 3.06, Flat_loss 0.24, Train_acc 95.62, Test_acc 59.41
2025-02-13 17:55:11,568 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.20, Spatial_loss 2.97, Flat_loss 0.23, Train_acc 96.29, Test_acc 57.83
2025-02-13 17:55:13,105 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.21, Spatial_loss 2.90, Flat_loss 0.23, Train_acc 96.52, Test_acc 59.11
2025-02-13 17:55:14,640 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.21, Spatial_loss 2.96, Flat_loss 0.24, Train_acc 95.89, Test_acc 56.77
2025-02-13 17:55:16,096 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.21, Spatial_loss 2.96, Flat_loss 0.23, Train_acc 95.40, Test_acc 57.84
2025-02-13 17:55:17,653 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.22, Spatial_loss 2.97, Flat_loss 0.23, Train_acc 96.21, Test_acc 59.08
2025-02-13 17:55:19,115 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.22, Spatial_loss 2.98, Flat_loss 0.24, Train_acc 95.54, Test_acc 54.98
2025-02-13 17:55:20,625 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.21, Spatial_loss 3.07, Flat_loss 0.24, Train_acc 96.47, Test_acc 60.72
2025-02-13 17:55:22,101 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.20, Spatial_loss 2.97, Flat_loss 0.23, Train_acc 96.61, Test_acc 58.62
2025-02-13 17:55:23,547 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 2.81, Flat_loss 0.22, Train_acc 96.43, Test_acc 58.78
2025-02-13 17:55:24,997 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.21, Spatial_loss 2.79, Flat_loss 0.21, Train_acc 96.21, Test_acc 56.78
2025-02-13 17:55:26,510 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.21, Spatial_loss 2.90, Flat_loss 0.22, Train_acc 96.52, Test_acc 60.38
2025-02-13 17:55:28,014 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.21, Spatial_loss 2.84, Flat_loss 0.22, Train_acc 96.61, Test_acc 61.75
2025-02-13 17:55:29,585 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.21, Spatial_loss 2.83, Flat_loss 0.22, Train_acc 96.47, Test_acc 60.36
2025-02-13 17:55:31,107 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.22, Spatial_loss 2.69, Flat_loss 0.21, Train_acc 96.29, Test_acc 58.14
2025-02-13 17:55:32,615 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.20, Spatial_loss 2.72, Flat_loss 0.21, Train_acc 96.43, Test_acc 61.17
2025-02-13 17:55:34,130 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.22, Spatial_loss 2.68, Flat_loss 0.21, Train_acc 95.89, Test_acc 58.69
2025-02-13 17:55:35,656 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.20, Spatial_loss 2.78, Flat_loss 0.21, Train_acc 96.47, Test_acc 59.44
2025-02-13 17:55:37,174 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 2.69, Flat_loss 0.20, Train_acc 96.43, Test_acc 58.20
2025-02-13 17:55:38,716 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.21, Spatial_loss 2.72, Flat_loss 0.21, Train_acc 96.47, Test_acc 59.33
2025-02-13 17:55:40,270 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.21, Spatial_loss 2.71, Flat_loss 0.22, Train_acc 96.29, Test_acc 60.20
2025-02-13 17:55:41,757 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.22, Spatial_loss 2.63, Flat_loss 0.20, Train_acc 96.25, Test_acc 62.72
2025-02-13 17:55:43,198 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.20, Spatial_loss 2.60, Flat_loss 0.20, Train_acc 96.38, Test_acc 59.72
2025-02-13 17:55:44,659 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.20, Spatial_loss 2.53, Flat_loss 0.19, Train_acc 97.01, Test_acc 61.88
2025-02-13 17:55:46,146 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.20, Spatial_loss 2.64, Flat_loss 0.20, Train_acc 96.29, Test_acc 63.09
2025-02-13 17:55:47,659 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.21, Spatial_loss 2.55, Flat_loss 0.19, Train_acc 96.25, Test_acc 61.14
2025-02-13 17:55:49,168 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 2.67, Flat_loss 0.20, Train_acc 96.29, Test_acc 61.17
2025-02-13 17:55:50,637 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.20, Spatial_loss 2.68, Flat_loss 0.20, Train_acc 96.56, Test_acc 59.83
2025-02-13 17:55:52,100 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.21, Spatial_loss 2.53, Flat_loss 0.19, Train_acc 96.38, Test_acc 60.75
2025-02-13 17:55:53,524 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 2.52, Flat_loss 0.19, Train_acc 96.70, Test_acc 61.69
2025-02-13 17:55:54,969 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.21, Spatial_loss 2.53, Flat_loss 0.18, Train_acc 96.38, Test_acc 60.62
2025-02-13 17:55:56,434 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.20, Spatial_loss 2.55, Flat_loss 0.19, Train_acc 96.83, Test_acc 61.64
2025-02-13 17:55:57,939 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.22, Spatial_loss 2.45, Flat_loss 0.18, Train_acc 96.56, Test_acc 61.48
2025-02-13 17:55:59,448 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.21, Spatial_loss 2.41, Flat_loss 0.18, Train_acc 96.12, Test_acc 60.42
2025-02-13 17:56:00,948 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 2.47, Flat_loss 0.19, Train_acc 96.56, Test_acc 61.52
2025-02-13 17:56:02,482 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.22, Spatial_loss 2.36, Flat_loss 0.17, Train_acc 95.89, Test_acc 60.50
2025-02-13 17:56:03,964 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 2.33, Flat_loss 0.18, Train_acc 97.23, Test_acc 60.38
2025-02-13 17:56:05,529 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 2.34, Flat_loss 0.18, Train_acc 96.34, Test_acc 60.00
2025-02-13 17:56:07,074 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 2.33, Flat_loss 0.18, Train_acc 97.05, Test_acc 60.80
2025-02-13 17:56:08,540 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.20, Spatial_loss 2.22, Flat_loss 0.17, Train_acc 97.32, Test_acc 60.97
2025-02-13 17:56:10,062 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.22, Spatial_loss 2.29, Flat_loss 0.17, Train_acc 96.03, Test_acc 63.11
2025-02-13 17:56:11,545 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.20, Spatial_loss 2.29, Flat_loss 0.17, Train_acc 96.70, Test_acc 61.41
2025-02-13 17:56:13,056 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.20, Spatial_loss 2.20, Flat_loss 0.17, Train_acc 96.43, Test_acc 62.06
2025-02-13 17:56:14,553 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.21, Spatial_loss 2.19, Flat_loss 0.16, Train_acc 96.47, Test_acc 62.94
2025-02-13 17:56:16,015 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.20, Spatial_loss 2.21, Flat_loss 0.17, Train_acc 96.79, Test_acc 61.33
2025-02-13 17:56:17,578 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.21, Spatial_loss 2.16, Flat_loss 0.16, Train_acc 96.34, Test_acc 62.48
2025-02-13 17:56:19,072 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.21, Spatial_loss 2.17, Flat_loss 0.16, Train_acc 96.25, Test_acc 61.34
2025-02-13 17:56:20,593 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.20, Spatial_loss 2.00, Flat_loss 0.16, Train_acc 97.23, Test_acc 61.25
2025-02-13 17:56:22,164 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.21, Spatial_loss 2.09, Flat_loss 0.16, Train_acc 96.21, Test_acc 61.27
2025-02-13 17:56:23,662 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 2.07, Flat_loss 0.16, Train_acc 96.61, Test_acc 61.12
2025-02-13 17:56:25,178 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 2.09, Flat_loss 0.16, Train_acc 96.61, Test_acc 61.50
2025-02-13 17:56:26,699 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.20, Spatial_loss 2.06, Flat_loss 0.15, Train_acc 96.74, Test_acc 62.20
2025-02-13 17:56:28,247 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.20, Spatial_loss 2.02, Flat_loss 0.15, Train_acc 96.74, Test_acc 61.09
2025-02-13 17:56:29,782 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 2.06, Flat_loss 0.15, Train_acc 96.74, Test_acc 61.78
2025-02-13 17:56:31,296 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.21, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 95.98, Test_acc 62.69
2025-02-13 17:56:32,810 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 2.05, Flat_loss 0.15, Train_acc 95.94, Test_acc 61.36
2025-02-13 17:56:34,294 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.20, Spatial_loss 1.95, Flat_loss 0.15, Train_acc 96.56, Test_acc 61.22
2025-02-13 17:56:35,757 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 1.92, Flat_loss 0.14, Train_acc 96.56, Test_acc 61.75
2025-02-13 17:56:37,285 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.20, Spatial_loss 1.95, Flat_loss 0.15, Train_acc 97.10, Test_acc 61.30
2025-02-13 17:56:38,786 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.21, Spatial_loss 1.92, Flat_loss 0.14, Train_acc 96.29, Test_acc 62.25
2025-02-13 17:56:40,307 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 1.91, Flat_loss 0.15, Train_acc 96.56, Test_acc 62.58
2025-02-13 17:56:41,794 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.20, Spatial_loss 1.92, Flat_loss 0.15, Train_acc 97.19, Test_acc 63.02
2025-02-13 17:56:43,351 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 1.87, Flat_loss 0.14, Train_acc 96.12, Test_acc 62.45
2025-02-13 17:56:44,805 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.86, Flat_loss 0.14, Train_acc 96.83, Test_acc 62.77
2025-02-13 17:56:46,289 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.95, Flat_loss 0.15, Train_acc 96.65, Test_acc 62.38
2025-02-13 17:56:47,723 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.75, Flat_loss 0.14, Train_acc 96.79, Test_acc 62.27
2025-02-13 17:56:49,240 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.83, Flat_loss 0.14, Train_acc 96.47, Test_acc 62.47
2025-02-13 17:56:50,781 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.93, Flat_loss 0.15, Train_acc 95.71, Test_acc 62.16
2025-02-13 17:56:52,296 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.78, Flat_loss 0.14, Train_acc 97.23, Test_acc 63.00
2025-02-13 17:56:53,845 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.82, Flat_loss 0.14, Train_acc 96.47, Test_acc 62.22
2025-02-13 17:56:55,352 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.80, Flat_loss 0.14, Train_acc 96.65, Test_acc 63.05
2025-02-13 17:56:56,870 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.81, Flat_loss 0.14, Train_acc 96.70, Test_acc 62.42
2025-02-13 17:56:58,383 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.21, Spatial_loss 1.84, Flat_loss 0.14, Train_acc 96.38, Test_acc 62.72
2025-02-13 17:56:59,894 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.71, Flat_loss 0.13, Train_acc 96.96, Test_acc 62.23
2025-02-13 17:57:01,411 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.21, Spatial_loss 1.63, Flat_loss 0.13, Train_acc 96.65, Test_acc 62.61
2025-02-13 17:57:02,901 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.67, Flat_loss 0.13, Train_acc 95.76, Test_acc 62.66
2025-02-13 17:57:04,381 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.22, Spatial_loss 1.67, Flat_loss 0.13, Train_acc 96.25, Test_acc 62.47
2025-02-13 17:57:05,850 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.21, Spatial_loss 1.73, Flat_loss 0.13, Train_acc 96.25, Test_acc 62.66
2025-02-13 17:57:07,340 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 1.68, Flat_loss 0.13, Train_acc 96.07, Test_acc 62.66
2025-02-13 17:57:08,838 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.21, Spatial_loss 1.63, Flat_loss 0.13, Train_acc 96.47, Test_acc 62.36
2025-02-13 17:57:10,366 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.21, Spatial_loss 1.61, Flat_loss 0.13, Train_acc 96.47, Test_acc 62.98
2025-02-13 17:57:11,819 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.60, Flat_loss 0.13, Train_acc 96.56, Test_acc 62.64
2025-02-13 17:57:13,303 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.67, Flat_loss 0.13, Train_acc 96.83, Test_acc 62.75
2025-02-13 17:57:14,781 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.61, Flat_loss 0.13, Train_acc 97.14, Test_acc 62.92
2025-02-13 17:57:16,268 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.63, Flat_loss 0.13, Train_acc 97.23, Test_acc 62.31
2025-02-13 17:57:17,762 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.58, Flat_loss 0.13, Train_acc 96.03, Test_acc 62.62
2025-02-13 17:57:19,239 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.21, Spatial_loss 1.56, Flat_loss 0.13, Train_acc 95.89, Test_acc 62.78
2025-02-13 17:57:20,790 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.20, Spatial_loss 1.62, Flat_loss 0.13, Train_acc 96.92, Test_acc 62.80
2025-02-13 17:57:22,278 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.21, Spatial_loss 1.63, Flat_loss 0.13, Train_acc 96.83, Test_acc 62.64
2025-02-13 17:57:23,780 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.62, Flat_loss 0.13, Train_acc 96.47, Test_acc 62.69
2025-02-13 17:57:25,263 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.58, Flat_loss 0.13, Train_acc 96.07, Test_acc 62.83
2025-02-13 17:57:25,264 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 17:57:25,264 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:57:45,423 [podnet.py] => The size of finetune dataset: 1280
2025-02-13 17:57:46,711 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.13, Spatial_loss 2.29, Flat_loss 0.18, Train_acc 97.03, Test_acc 62.44
2025-02-13 17:57:47,990 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.08, Spatial_loss 1.93, Flat_loss 0.10, Train_acc 98.98, Test_acc 62.36
2025-02-13 17:57:49,255 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.08, Spatial_loss 1.79, Flat_loss 0.08, Train_acc 98.91, Test_acc 62.27
2025-02-13 17:57:50,525 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.07, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 99.06, Test_acc 63.66
2025-02-13 17:57:51,778 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.07, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 99.30, Test_acc 63.16
2025-02-13 17:57:53,023 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.07, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.91, Test_acc 63.14
2025-02-13 17:57:54,278 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.07, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 99.22, Test_acc 63.78
2025-02-13 17:57:55,551 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.07, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 99.22, Test_acc 63.38
2025-02-13 17:57:56,793 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.08, Spatial_loss 1.59, Flat_loss 0.05, Train_acc 98.75, Test_acc 63.30
2025-02-13 17:57:58,008 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.07, Spatial_loss 1.60, Flat_loss 0.06, Train_acc 99.30, Test_acc 63.30
2025-02-13 17:57:59,259 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.07, Spatial_loss 1.59, Flat_loss 0.05, Train_acc 99.14, Test_acc 63.30
2025-02-13 17:58:00,526 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.07, Spatial_loss 1.57, Flat_loss 0.06, Train_acc 98.91, Test_acc 63.42
2025-02-13 17:58:01,766 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.07, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 99.45, Test_acc 63.36
2025-02-13 17:58:03,068 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.07, Spatial_loss 1.56, Flat_loss 0.05, Train_acc 99.14, Test_acc 63.31
2025-02-13 17:58:04,361 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.56, Flat_loss 0.05, Train_acc 98.59, Test_acc 63.34
2025-02-13 17:58:05,613 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.08, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 98.83, Test_acc 63.33
2025-02-13 17:58:06,870 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.07, Spatial_loss 1.51, Flat_loss 0.05, Train_acc 98.91, Test_acc 63.39
2025-02-13 17:58:08,127 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.07, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 99.06, Test_acc 63.39
2025-02-13 17:58:09,365 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.07, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 99.22, Test_acc 63.44
2025-02-13 17:58:10,637 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.07, Spatial_loss 1.58, Flat_loss 0.06, Train_acc 98.83, Test_acc 63.50
2025-02-13 17:58:10,638 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 17:58:32,663 [podnet.py] => Exemplar size: 1280
2025-02-13 17:58:32,663 [trainer.py] => CNN: {'total': 63.5, '00-09': 72.1, '10-19': 55.8, '20-29': 70.5, '30-39': 62.4, '40-49': 69.1, '50-59': 50.9, '60-69': 64.0, 'old': 63.5, 'new': 63.5}
2025-02-13 17:58:32,663 [trainer.py] => NME: {'total': 64.06, '00-09': 74.5, '10-19': 60.1, '20-29': 73.2, '30-39': 63.1, '40-49': 69.1, '50-59': 47.4, '60-69': 56.5, 'old': 64.32, 'new': 56.0}
2025-02-13 17:58:32,663 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5]
2025-02-13 17:58:32,663 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2]
2025-02-13 17:58:32,663 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06]
2025-02-13 17:58:32,663 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47]

2025-02-13 17:58:32,663 [trainer.py] => Average Accuracy (CNN): 70.87375
2025-02-13 17:58:32,663 [trainer.py] => Average Accuracy (NME): 70.97874999999999
2025-02-13 17:58:32,664 [trainer.py] => All params: 507217
2025-02-13 17:58:32,664 [trainer.py] => Trainable params: 507217
2025-02-13 17:58:32,665 [podnet.py] => Learning on 64-66
2025-02-13 17:58:32,682 [podnet.py] => Adaptive factor: 5.744562646538029
2025-02-13 17:58:34,255 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 1.33, Spatial_loss 4.30, Flat_loss 0.59, Train_acc 78.64, Test_acc 53.29
2025-02-13 17:58:35,826 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 0.38, Spatial_loss 5.10, Flat_loss 0.55, Train_acc 90.31, Test_acc 54.11
2025-02-13 17:58:37,387 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 0.31, Spatial_loss 4.97, Flat_loss 0.50, Train_acc 91.80, Test_acc 51.73
2025-02-13 17:58:38,939 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 0.28, Spatial_loss 4.85, Flat_loss 0.48, Train_acc 92.81, Test_acc 49.41
2025-02-13 17:58:40,478 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 0.26, Spatial_loss 4.48, Flat_loss 0.42, Train_acc 94.17, Test_acc 54.73
2025-02-13 17:58:42,010 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 0.24, Spatial_loss 4.31, Flat_loss 0.39, Train_acc 94.69, Test_acc 55.17
2025-02-13 17:58:43,579 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 0.24, Spatial_loss 4.33, Flat_loss 0.39, Train_acc 94.25, Test_acc 55.97
2025-02-13 17:58:45,151 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 0.24, Spatial_loss 4.26, Flat_loss 0.36, Train_acc 94.82, Test_acc 56.91
2025-02-13 17:58:46,668 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 0.22, Spatial_loss 4.18, Flat_loss 0.36, Train_acc 95.57, Test_acc 58.91
2025-02-13 17:58:48,166 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 0.23, Spatial_loss 4.13, Flat_loss 0.36, Train_acc 95.13, Test_acc 53.59
2025-02-13 17:58:49,697 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 0.22, Spatial_loss 4.11, Flat_loss 0.35, Train_acc 95.22, Test_acc 55.89
2025-02-13 17:58:51,228 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.22, Spatial_loss 3.98, Flat_loss 0.33, Train_acc 95.13, Test_acc 54.32
2025-02-13 17:58:52,747 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.22, Spatial_loss 4.09, Flat_loss 0.34, Train_acc 95.22, Test_acc 56.86
2025-02-13 17:58:54,246 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.21, Spatial_loss 3.99, Flat_loss 0.33, Train_acc 95.96, Test_acc 53.59
2025-02-13 17:58:55,730 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.21, Spatial_loss 4.00, Flat_loss 0.33, Train_acc 95.88, Test_acc 57.68
2025-02-13 17:58:57,245 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.21, Spatial_loss 3.80, Flat_loss 0.32, Train_acc 95.88, Test_acc 56.82
2025-02-13 17:58:58,730 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.20, Spatial_loss 3.94, Flat_loss 0.33, Train_acc 96.36, Test_acc 55.12
2025-02-13 17:59:00,221 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.19, Spatial_loss 3.89, Flat_loss 0.32, Train_acc 96.10, Test_acc 53.58
2025-02-13 17:59:01,760 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.22, Spatial_loss 3.89, Flat_loss 0.32, Train_acc 95.09, Test_acc 55.76
2025-02-13 17:59:03,321 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.21, Spatial_loss 3.83, Flat_loss 0.32, Train_acc 96.05, Test_acc 57.56
2025-02-13 17:59:04,869 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.19, Spatial_loss 3.79, Flat_loss 0.31, Train_acc 96.14, Test_acc 54.33
2025-02-13 17:59:06,416 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.21, Spatial_loss 3.85, Flat_loss 0.30, Train_acc 96.01, Test_acc 57.29
2025-02-13 17:59:07,940 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.19, Spatial_loss 3.85, Flat_loss 0.31, Train_acc 96.58, Test_acc 55.97
2025-02-13 17:59:09,467 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.19, Spatial_loss 3.97, Flat_loss 0.32, Train_acc 96.49, Test_acc 56.33
2025-02-13 17:59:11,017 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.18, Spatial_loss 3.93, Flat_loss 0.31, Train_acc 96.75, Test_acc 56.89
2025-02-13 17:59:12,561 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.20, Spatial_loss 3.75, Flat_loss 0.29, Train_acc 95.79, Test_acc 58.15
2025-02-13 17:59:14,074 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.19, Spatial_loss 3.66, Flat_loss 0.28, Train_acc 96.45, Test_acc 55.50
2025-02-13 17:59:15,618 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.21, Spatial_loss 3.82, Flat_loss 0.30, Train_acc 96.01, Test_acc 56.83
2025-02-13 17:59:17,102 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.19, Spatial_loss 3.79, Flat_loss 0.30, Train_acc 96.18, Test_acc 56.42
2025-02-13 17:59:18,682 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.20, Spatial_loss 3.85, Flat_loss 0.30, Train_acc 96.58, Test_acc 57.12
2025-02-13 17:59:20,231 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.19, Spatial_loss 3.71, Flat_loss 0.29, Train_acc 95.96, Test_acc 59.03
2025-02-13 17:59:21,805 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.19, Spatial_loss 3.80, Flat_loss 0.30, Train_acc 96.62, Test_acc 55.56
2025-02-13 17:59:23,317 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.19, Spatial_loss 3.82, Flat_loss 0.30, Train_acc 96.75, Test_acc 58.59
2025-02-13 17:59:24,808 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.19, Spatial_loss 3.62, Flat_loss 0.29, Train_acc 97.28, Test_acc 59.03
2025-02-13 17:59:26,346 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.19, Spatial_loss 3.56, Flat_loss 0.28, Train_acc 96.40, Test_acc 59.92
2025-02-13 17:59:27,800 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.19, Spatial_loss 3.46, Flat_loss 0.27, Train_acc 96.49, Test_acc 57.64
2025-02-13 17:59:29,322 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.19, Spatial_loss 3.57, Flat_loss 0.28, Train_acc 96.49, Test_acc 56.73
2025-02-13 17:59:30,861 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.18, Spatial_loss 3.53, Flat_loss 0.27, Train_acc 96.71, Test_acc 58.79
2025-02-13 17:59:32,375 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.19, Spatial_loss 3.63, Flat_loss 0.27, Train_acc 96.45, Test_acc 57.24
2025-02-13 17:59:33,873 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.19, Spatial_loss 3.48, Flat_loss 0.27, Train_acc 96.40, Test_acc 60.09
2025-02-13 17:59:35,393 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.20, Spatial_loss 3.59, Flat_loss 0.27, Train_acc 96.45, Test_acc 56.59
2025-02-13 17:59:36,932 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.18, Spatial_loss 3.53, Flat_loss 0.28, Train_acc 97.02, Test_acc 57.05
2025-02-13 17:59:38,432 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.19, Spatial_loss 3.51, Flat_loss 0.26, Train_acc 96.80, Test_acc 55.41
2025-02-13 17:59:39,970 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.21, Spatial_loss 3.62, Flat_loss 0.29, Train_acc 96.10, Test_acc 56.62
2025-02-13 17:59:41,515 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.18, Spatial_loss 3.47, Flat_loss 0.26, Train_acc 96.49, Test_acc 58.06
2025-02-13 17:59:43,039 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.18, Spatial_loss 3.58, Flat_loss 0.27, Train_acc 96.84, Test_acc 59.36
2025-02-13 17:59:44,597 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.19, Spatial_loss 3.39, Flat_loss 0.26, Train_acc 96.54, Test_acc 58.33
2025-02-13 17:59:46,161 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.18, Spatial_loss 3.47, Flat_loss 0.26, Train_acc 96.89, Test_acc 58.88
2025-02-13 17:59:47,642 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.18, Spatial_loss 3.52, Flat_loss 0.26, Train_acc 96.84, Test_acc 56.73
2025-02-13 17:59:49,210 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.18, Spatial_loss 3.49, Flat_loss 0.26, Train_acc 96.62, Test_acc 57.64
2025-02-13 17:59:50,742 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.20, Spatial_loss 3.51, Flat_loss 0.27, Train_acc 96.10, Test_acc 57.62
2025-02-13 17:59:52,238 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.18, Spatial_loss 3.50, Flat_loss 0.27, Train_acc 97.06, Test_acc 58.11
2025-02-13 17:59:53,753 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.20, Spatial_loss 3.43, Flat_loss 0.26, Train_acc 96.67, Test_acc 59.55
2025-02-13 17:59:55,291 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.17, Spatial_loss 3.37, Flat_loss 0.26, Train_acc 97.15, Test_acc 58.14
2025-02-13 17:59:56,804 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.20, Spatial_loss 3.36, Flat_loss 0.25, Train_acc 96.45, Test_acc 54.29
2025-02-13 17:59:58,322 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.18, Spatial_loss 3.36, Flat_loss 0.26, Train_acc 96.36, Test_acc 59.20
2025-02-13 17:59:59,865 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.18, Spatial_loss 3.44, Flat_loss 0.25, Train_acc 96.71, Test_acc 54.59
2025-02-13 18:00:01,438 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.17, Spatial_loss 3.35, Flat_loss 0.25, Train_acc 97.15, Test_acc 56.73
2025-02-13 18:00:03,004 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.18, Spatial_loss 3.25, Flat_loss 0.24, Train_acc 97.06, Test_acc 58.26
2025-02-13 18:00:04,502 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.19, Spatial_loss 3.32, Flat_loss 0.24, Train_acc 96.18, Test_acc 58.73
2025-02-13 18:00:06,068 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.18, Spatial_loss 3.25, Flat_loss 0.23, Train_acc 96.49, Test_acc 56.42
2025-02-13 18:00:07,649 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.17, Spatial_loss 3.21, Flat_loss 0.23, Train_acc 97.50, Test_acc 58.41
2025-02-13 18:00:09,148 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.18, Spatial_loss 3.22, Flat_loss 0.24, Train_acc 96.89, Test_acc 56.61
2025-02-13 18:00:10,692 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.18, Spatial_loss 3.16, Flat_loss 0.23, Train_acc 96.97, Test_acc 60.21
2025-02-13 18:00:12,293 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.17, Spatial_loss 3.18, Flat_loss 0.23, Train_acc 97.02, Test_acc 60.50
2025-02-13 18:00:13,781 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.18, Spatial_loss 3.16, Flat_loss 0.23, Train_acc 96.80, Test_acc 55.73
2025-02-13 18:00:15,371 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.18, Spatial_loss 3.21, Flat_loss 0.24, Train_acc 96.67, Test_acc 59.61
2025-02-13 18:00:16,850 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.18, Spatial_loss 3.11, Flat_loss 0.23, Train_acc 96.97, Test_acc 57.21
2025-02-13 18:00:18,392 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.18, Spatial_loss 3.12, Flat_loss 0.22, Train_acc 96.89, Test_acc 56.48
2025-02-13 18:00:19,883 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.18, Spatial_loss 3.13, Flat_loss 0.23, Train_acc 97.15, Test_acc 58.95
2025-02-13 18:00:21,412 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.22, Train_acc 97.02, Test_acc 57.98
2025-02-13 18:00:22,900 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.17, Spatial_loss 2.98, Flat_loss 0.21, Train_acc 97.19, Test_acc 56.06
2025-02-13 18:00:24,411 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.17, Spatial_loss 2.97, Flat_loss 0.21, Train_acc 97.19, Test_acc 58.15
2025-02-13 18:00:25,918 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.22, Train_acc 97.24, Test_acc 59.14
2025-02-13 18:00:27,439 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.17, Spatial_loss 3.12, Flat_loss 0.22, Train_acc 97.19, Test_acc 59.67
2025-02-13 18:00:28,988 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.18, Spatial_loss 3.15, Flat_loss 0.23, Train_acc 97.02, Test_acc 57.92
2025-02-13 18:00:30,506 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.18, Spatial_loss 3.02, Flat_loss 0.21, Train_acc 96.80, Test_acc 58.61
2025-02-13 18:00:32,045 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.16, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 97.54, Test_acc 59.53
2025-02-13 18:00:33,552 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.17, Spatial_loss 2.87, Flat_loss 0.20, Train_acc 96.84, Test_acc 57.77
2025-02-13 18:00:35,116 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.17, Spatial_loss 2.96, Flat_loss 0.21, Train_acc 97.06, Test_acc 60.44
2025-02-13 18:00:36,704 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.18, Spatial_loss 2.94, Flat_loss 0.21, Train_acc 97.06, Test_acc 58.68
2025-02-13 18:00:38,224 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.17, Spatial_loss 2.90, Flat_loss 0.20, Train_acc 97.24, Test_acc 60.02
2025-02-13 18:00:39,681 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.17, Spatial_loss 2.91, Flat_loss 0.20, Train_acc 97.11, Test_acc 58.88
2025-02-13 18:00:41,229 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 2.80, Flat_loss 0.20, Train_acc 97.11, Test_acc 60.89
2025-02-13 18:00:42,802 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.18, Spatial_loss 2.78, Flat_loss 0.19, Train_acc 96.89, Test_acc 61.12
2025-02-13 18:00:44,405 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 2.84, Flat_loss 0.19, Train_acc 97.15, Test_acc 60.12
2025-02-13 18:00:45,905 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 2.72, Flat_loss 0.19, Train_acc 96.89, Test_acc 61.11
2025-02-13 18:00:47,464 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.16, Spatial_loss 2.73, Flat_loss 0.19, Train_acc 97.06, Test_acc 60.79
2025-02-13 18:00:48,986 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.18, Spatial_loss 2.74, Flat_loss 0.18, Train_acc 96.67, Test_acc 58.77
2025-02-13 18:00:50,583 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 2.67, Flat_loss 0.20, Train_acc 97.32, Test_acc 60.27
2025-02-13 18:00:52,085 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.17, Spatial_loss 2.64, Flat_loss 0.18, Train_acc 97.24, Test_acc 60.82
2025-02-13 18:00:53,638 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 2.56, Flat_loss 0.18, Train_acc 97.32, Test_acc 60.17
2025-02-13 18:00:55,154 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.17, Spatial_loss 2.56, Flat_loss 0.18, Train_acc 96.80, Test_acc 60.44
2025-02-13 18:00:56,626 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 2.60, Flat_loss 0.17, Train_acc 97.37, Test_acc 59.55
2025-02-13 18:00:58,142 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.16, Spatial_loss 2.54, Flat_loss 0.17, Train_acc 97.37, Test_acc 60.58
2025-02-13 18:00:59,611 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.17, Spatial_loss 2.55, Flat_loss 0.17, Train_acc 97.11, Test_acc 57.32
2025-02-13 18:01:01,082 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 97.68, Test_acc 62.20
2025-02-13 18:01:02,599 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 2.51, Flat_loss 0.17, Train_acc 97.81, Test_acc 61.79
2025-02-13 18:01:04,094 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 2.63, Flat_loss 0.17, Train_acc 97.06, Test_acc 60.26
2025-02-13 18:01:05,655 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.17, Spatial_loss 2.53, Flat_loss 0.17, Train_acc 97.15, Test_acc 59.11
2025-02-13 18:01:07,209 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.17, Spatial_loss 2.45, Flat_loss 0.17, Train_acc 97.19, Test_acc 60.95
2025-02-13 18:01:08,624 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.16, Spatial_loss 2.45, Flat_loss 0.17, Train_acc 97.76, Test_acc 60.82
2025-02-13 18:01:10,105 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.18, Spatial_loss 2.45, Flat_loss 0.16, Train_acc 96.93, Test_acc 58.94
2025-02-13 18:01:11,601 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.17, Spatial_loss 2.43, Flat_loss 0.16, Train_acc 97.28, Test_acc 60.26
2025-02-13 18:01:13,101 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.17, Spatial_loss 2.36, Flat_loss 0.16, Train_acc 97.28, Test_acc 59.85
2025-02-13 18:01:14,654 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.17, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 97.41, Test_acc 59.65
2025-02-13 18:01:16,142 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.17, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 97.28, Test_acc 61.83
2025-02-13 18:01:17,660 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.17, Spatial_loss 2.46, Flat_loss 0.16, Train_acc 97.37, Test_acc 59.89
2025-02-13 18:01:19,226 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.17, Spatial_loss 2.37, Flat_loss 0.16, Train_acc 97.41, Test_acc 60.73
2025-02-13 18:01:20,736 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 2.34, Flat_loss 0.15, Train_acc 97.54, Test_acc 61.06
2025-02-13 18:01:22,289 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.17, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 97.24, Test_acc 61.70
2025-02-13 18:01:23,782 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 2.33, Flat_loss 0.15, Train_acc 97.76, Test_acc 61.15
2025-02-13 18:01:25,282 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.17, Spatial_loss 2.25, Flat_loss 0.15, Train_acc 97.63, Test_acc 61.27
2025-02-13 18:01:26,797 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 2.15, Flat_loss 0.14, Train_acc 97.37, Test_acc 61.20
2025-02-13 18:01:28,321 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 2.23, Flat_loss 0.14, Train_acc 97.19, Test_acc 60.56
2025-02-13 18:01:29,858 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.16, Spatial_loss 2.25, Flat_loss 0.15, Train_acc 97.46, Test_acc 61.67
2025-02-13 18:01:31,357 [podnet.py] => Task 8, Epoch 117/160 (LR 0.01679) => LSC_loss 0.17, Spatial_loss 2.11, Flat_loss 0.14, Train_acc 97.11, Test_acc 61.29
2025-02-13 18:01:32,848 [podnet.py] => Task 8, Epoch 118/160 (LR 0.01606) => LSC_loss 0.18, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 96.80, Test_acc 60.08
2025-02-13 18:01:34,374 [podnet.py] => Task 8, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 97.59, Test_acc 59.02
2025-02-13 18:01:35,806 [podnet.py] => Task 8, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 97.37, Test_acc 60.61
2025-02-13 18:01:37,332 [podnet.py] => Task 8, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 2.20, Flat_loss 0.14, Train_acc 97.06, Test_acc 60.71
2025-02-13 18:01:38,841 [podnet.py] => Task 8, Epoch 122/160 (LR 0.01328) => LSC_loss 0.17, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 97.11, Test_acc 61.74
2025-02-13 18:01:40,379 [podnet.py] => Task 8, Epoch 123/160 (LR 0.01262) => LSC_loss 0.17, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 97.24, Test_acc 61.27
2025-02-13 18:01:41,966 [podnet.py] => Task 8, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 2.06, Flat_loss 0.13, Train_acc 97.06, Test_acc 61.02
2025-02-13 18:01:43,528 [podnet.py] => Task 8, Epoch 125/160 (LR 0.01135) => LSC_loss 0.17, Spatial_loss 1.96, Flat_loss 0.13, Train_acc 97.24, Test_acc 61.88
2025-02-13 18:01:45,067 [podnet.py] => Task 8, Epoch 126/160 (LR 0.01073) => LSC_loss 0.18, Spatial_loss 2.03, Flat_loss 0.13, Train_acc 97.32, Test_acc 60.59
2025-02-13 18:01:46,662 [podnet.py] => Task 8, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 97.24, Test_acc 61.24
2025-02-13 18:01:48,228 [podnet.py] => Task 8, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 96.97, Test_acc 60.95
2025-02-13 18:01:49,759 [podnet.py] => Task 8, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 1.96, Flat_loss 0.13, Train_acc 97.32, Test_acc 62.14
2025-02-13 18:01:51,227 [podnet.py] => Task 8, Epoch 130/160 (LR 0.00843) => LSC_loss 0.17, Spatial_loss 1.88, Flat_loss 0.12, Train_acc 97.02, Test_acc 61.48
2025-02-13 18:01:52,820 [podnet.py] => Task 8, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 1.87, Flat_loss 0.13, Train_acc 97.37, Test_acc 61.73
2025-02-13 18:01:54,285 [podnet.py] => Task 8, Epoch 132/160 (LR 0.00737) => LSC_loss 0.17, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 97.15, Test_acc 61.24
2025-02-13 18:01:55,837 [podnet.py] => Task 8, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 1.78, Flat_loss 0.12, Train_acc 97.06, Test_acc 61.39
2025-02-13 18:01:57,345 [podnet.py] => Task 8, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.84, Flat_loss 0.12, Train_acc 97.37, Test_acc 61.83
2025-02-13 18:01:58,780 [podnet.py] => Task 8, Epoch 135/160 (LR 0.00590) => LSC_loss 0.17, Spatial_loss 1.78, Flat_loss 0.12, Train_acc 97.11, Test_acc 61.08
2025-02-13 18:02:00,258 [podnet.py] => Task 8, Epoch 136/160 (LR 0.00545) => LSC_loss 0.18, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 96.71, Test_acc 61.65
2025-02-13 18:02:01,784 [podnet.py] => Task 8, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 97.15, Test_acc 61.82
2025-02-13 18:02:03,328 [podnet.py] => Task 8, Epoch 138/160 (LR 0.00459) => LSC_loss 0.17, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 97.32, Test_acc 61.59
2025-02-13 18:02:04,856 [podnet.py] => Task 8, Epoch 139/160 (LR 0.00419) => LSC_loss 0.17, Spatial_loss 1.80, Flat_loss 0.12, Train_acc 97.81, Test_acc 61.02
2025-02-13 18:02:06,399 [podnet.py] => Task 8, Epoch 140/160 (LR 0.00381) => LSC_loss 0.18, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 97.19, Test_acc 61.65
2025-02-13 18:02:07,952 [podnet.py] => Task 8, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 97.68, Test_acc 62.39
2025-02-13 18:02:09,413 [podnet.py] => Task 8, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 97.54, Test_acc 62.14
2025-02-13 18:02:10,924 [podnet.py] => Task 8, Epoch 143/160 (LR 0.00276) => LSC_loss 0.16, Spatial_loss 1.68, Flat_loss 0.11, Train_acc 97.50, Test_acc 61.74
2025-02-13 18:02:12,433 [podnet.py] => Task 8, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 97.24, Test_acc 62.06
2025-02-13 18:02:14,002 [podnet.py] => Task 8, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 1.62, Flat_loss 0.11, Train_acc 97.54, Test_acc 61.95
2025-02-13 18:02:15,545 [podnet.py] => Task 8, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 97.32, Test_acc 61.83
2025-02-13 18:02:17,136 [podnet.py] => Task 8, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 1.69, Flat_loss 0.11, Train_acc 97.41, Test_acc 61.97
2025-02-13 18:02:18,704 [podnet.py] => Task 8, Epoch 148/160 (LR 0.00138) => LSC_loss 0.18, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.67, Test_acc 61.88
2025-02-13 18:02:20,243 [podnet.py] => Task 8, Epoch 149/160 (LR 0.00116) => LSC_loss 0.17, Spatial_loss 1.68, Flat_loss 0.12, Train_acc 97.28, Test_acc 61.82
2025-02-13 18:02:21,778 [podnet.py] => Task 8, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 97.59, Test_acc 61.67
2025-02-13 18:02:23,272 [podnet.py] => Task 8, Epoch 151/160 (LR 0.00078) => LSC_loss 0.18, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 97.28, Test_acc 61.79
2025-02-13 18:02:24,776 [podnet.py] => Task 8, Epoch 152/160 (LR 0.00062) => LSC_loss 0.18, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 97.15, Test_acc 61.94
2025-02-13 18:02:26,330 [podnet.py] => Task 8, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 97.37, Test_acc 61.67
2025-02-13 18:02:27,863 [podnet.py] => Task 8, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 97.50, Test_acc 61.88
2025-02-13 18:02:29,397 [podnet.py] => Task 8, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 96.84, Test_acc 61.64
2025-02-13 18:02:30,905 [podnet.py] => Task 8, Epoch 156/160 (LR 0.00015) => LSC_loss 0.17, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 97.32, Test_acc 61.92
2025-02-13 18:02:32,378 [podnet.py] => Task 8, Epoch 157/160 (LR 0.00009) => LSC_loss 0.18, Spatial_loss 1.60, Flat_loss 0.11, Train_acc 96.97, Test_acc 61.86
2025-02-13 18:02:33,861 [podnet.py] => Task 8, Epoch 158/160 (LR 0.00004) => LSC_loss 0.17, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 97.28, Test_acc 61.76
2025-02-13 18:02:35,424 [podnet.py] => Task 8, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 97.11, Test_acc 61.94
2025-02-13 18:02:36,946 [podnet.py] => Task 8, Epoch 160/160 (LR 0.00000) => LSC_loss 0.18, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 97.19, Test_acc 61.89
2025-02-13 18:02:36,947 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:02:36,947 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:02:57,711 [podnet.py] => The size of finetune dataset: 1320
2025-02-13 18:02:59,022 [podnet.py] => Task 8, Epoch 1/20 (LR 0.00497) => LSC_loss 0.13, Spatial_loss 2.15, Flat_loss 0.16, Train_acc 97.05, Test_acc 61.38
2025-02-13 18:03:00,385 [podnet.py] => Task 8, Epoch 2/20 (LR 0.00488) => LSC_loss 0.09, Spatial_loss 1.93, Flat_loss 0.10, Train_acc 98.71, Test_acc 61.44
2025-02-13 18:03:01,768 [podnet.py] => Task 8, Epoch 3/20 (LR 0.00473) => LSC_loss 0.08, Spatial_loss 1.76, Flat_loss 0.07, Train_acc 99.47, Test_acc 62.71
2025-02-13 18:03:03,101 [podnet.py] => Task 8, Epoch 4/20 (LR 0.00452) => LSC_loss 0.08, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 99.55, Test_acc 62.94
2025-02-13 18:03:04,395 [podnet.py] => Task 8, Epoch 5/20 (LR 0.00427) => LSC_loss 0.08, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 99.32, Test_acc 62.79
2025-02-13 18:03:05,695 [podnet.py] => Task 8, Epoch 6/20 (LR 0.00397) => LSC_loss 0.08, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.02, Test_acc 62.67
2025-02-13 18:03:06,955 [podnet.py] => Task 8, Epoch 7/20 (LR 0.00363) => LSC_loss 0.08, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 98.94, Test_acc 62.89
2025-02-13 18:03:08,259 [podnet.py] => Task 8, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 1.72, Flat_loss 0.06, Train_acc 99.24, Test_acc 62.55
2025-02-13 18:03:09,550 [podnet.py] => Task 8, Epoch 9/20 (LR 0.00289) => LSC_loss 0.08, Spatial_loss 1.79, Flat_loss 0.06, Train_acc 99.47, Test_acc 62.95
2025-02-13 18:03:10,865 [podnet.py] => Task 8, Epoch 10/20 (LR 0.00250) => LSC_loss 0.07, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 99.70, Test_acc 62.62
2025-02-13 18:03:12,134 [podnet.py] => Task 8, Epoch 11/20 (LR 0.00211) => LSC_loss 0.07, Spatial_loss 1.64, Flat_loss 0.05, Train_acc 99.55, Test_acc 62.88
2025-02-13 18:03:13,376 [podnet.py] => Task 8, Epoch 12/20 (LR 0.00173) => LSC_loss 0.07, Spatial_loss 1.71, Flat_loss 0.07, Train_acc 99.62, Test_acc 62.77
2025-02-13 18:03:14,705 [podnet.py] => Task 8, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 99.39, Test_acc 63.30
2025-02-13 18:03:16,039 [podnet.py] => Task 8, Epoch 14/20 (LR 0.00103) => LSC_loss 0.07, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 99.62, Test_acc 63.15
2025-02-13 18:03:17,357 [podnet.py] => Task 8, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 98.94, Test_acc 63.06
2025-02-13 18:03:18,678 [podnet.py] => Task 8, Epoch 16/20 (LR 0.00048) => LSC_loss 0.07, Spatial_loss 1.58, Flat_loss 0.06, Train_acc 99.32, Test_acc 62.61
2025-02-13 18:03:19,999 [podnet.py] => Task 8, Epoch 17/20 (LR 0.00027) => LSC_loss 0.07, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 99.09, Test_acc 62.89
2025-02-13 18:03:21,338 [podnet.py] => Task 8, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 1.57, Flat_loss 0.05, Train_acc 99.47, Test_acc 62.55
2025-02-13 18:03:22,690 [podnet.py] => Task 8, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 99.24, Test_acc 62.92
2025-02-13 18:03:24,021 [podnet.py] => Task 8, Epoch 20/20 (LR 0.00000) => LSC_loss 0.07, Spatial_loss 1.63, Flat_loss 0.06, Train_acc 99.24, Test_acc 62.79
2025-02-13 18:03:24,022 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:03:46,822 [podnet.py] => Exemplar size: 1320
2025-02-13 18:03:46,822 [trainer.py] => CNN: {'total': 62.79, '00-09': 71.7, '10-19': 53.9, '20-29': 70.0, '30-39': 60.6, '40-49': 68.3, '50-59': 51.5, '60-69': 64.0, 'old': 62.55, 'new': 70.5}
2025-02-13 18:03:46,822 [trainer.py] => NME: {'total': 63.26, '00-09': 73.8, '10-19': 59.2, '20-29': 73.0, '30-39': 61.1, '40-49': 68.9, '50-59': 47.7, '60-69': 56.33, 'old': 63.39, 'new': 59.0}
2025-02-13 18:03:46,822 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79]
2025-02-13 18:03:46,822 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21]
2025-02-13 18:03:46,822 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26]
2025-02-13 18:03:46,822 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8]

2025-02-13 18:03:46,823 [trainer.py] => Average Accuracy (CNN): 69.97555555555556
2025-02-13 18:03:46,823 [trainer.py] => Average Accuracy (NME): 70.1211111111111
2025-02-13 18:03:46,823 [trainer.py] => All params: 508497
2025-02-13 18:03:46,823 [trainer.py] => Trainable params: 508497
2025-02-13 18:03:46,824 [podnet.py] => Learning on 66-68
2025-02-13 18:03:46,842 [podnet.py] => Adaptive factor: 5.830951894845301
2025-02-13 18:03:48,442 [podnet.py] => Task 9, Epoch 1/160 (LR 0.09999) => LSC_loss 1.24, Spatial_loss 4.08, Flat_loss 0.55, Train_acc 81.12, Test_acc 46.76
2025-02-13 18:03:50,055 [podnet.py] => Task 9, Epoch 2/160 (LR 0.09996) => LSC_loss 0.48, Spatial_loss 5.69, Flat_loss 0.70, Train_acc 87.16, Test_acc 47.07
2025-02-13 18:03:51,583 [podnet.py] => Task 9, Epoch 3/160 (LR 0.09991) => LSC_loss 0.47, Spatial_loss 6.13, Flat_loss 0.78, Train_acc 88.84, Test_acc 43.82
2025-02-13 18:03:53,175 [podnet.py] => Task 9, Epoch 4/160 (LR 0.09985) => LSC_loss 0.44, Spatial_loss 6.15, Flat_loss 0.75, Train_acc 89.35, Test_acc 50.78
2025-02-13 18:03:54,735 [podnet.py] => Task 9, Epoch 5/160 (LR 0.09976) => LSC_loss 0.42, Spatial_loss 5.90, Flat_loss 0.72, Train_acc 89.87, Test_acc 48.38
2025-02-13 18:03:56,312 [podnet.py] => Task 9, Epoch 6/160 (LR 0.09965) => LSC_loss 0.48, Spatial_loss 6.24, Flat_loss 0.79, Train_acc 88.53, Test_acc 45.75
2025-02-13 18:03:57,802 [podnet.py] => Task 9, Epoch 7/160 (LR 0.09953) => LSC_loss 0.39, Spatial_loss 5.77, Flat_loss 0.69, Train_acc 90.56, Test_acc 54.71
2025-02-13 18:03:59,337 [podnet.py] => Task 9, Epoch 8/160 (LR 0.09938) => LSC_loss 0.28, Spatial_loss 5.20, Flat_loss 0.54, Train_acc 93.41, Test_acc 55.10
2025-02-13 18:04:00,890 [podnet.py] => Task 9, Epoch 9/160 (LR 0.09922) => LSC_loss 0.24, Spatial_loss 4.86, Flat_loss 0.48, Train_acc 94.18, Test_acc 55.28
2025-02-13 18:04:02,400 [podnet.py] => Task 9, Epoch 10/160 (LR 0.09904) => LSC_loss 0.25, Spatial_loss 4.58, Flat_loss 0.43, Train_acc 94.18, Test_acc 51.04
2025-02-13 18:04:03,937 [podnet.py] => Task 9, Epoch 11/160 (LR 0.09884) => LSC_loss 0.26, Spatial_loss 4.86, Flat_loss 0.47, Train_acc 94.74, Test_acc 51.75
2025-02-13 18:04:05,506 [podnet.py] => Task 9, Epoch 12/160 (LR 0.09862) => LSC_loss 0.27, Spatial_loss 4.58, Flat_loss 0.43, Train_acc 95.00, Test_acc 56.19
2025-02-13 18:04:07,067 [podnet.py] => Task 9, Epoch 13/160 (LR 0.09838) => LSC_loss 0.26, Spatial_loss 4.58, Flat_loss 0.42, Train_acc 94.91, Test_acc 51.01
2025-02-13 18:04:08,639 [podnet.py] => Task 9, Epoch 14/160 (LR 0.09812) => LSC_loss 0.22, Spatial_loss 4.51, Flat_loss 0.42, Train_acc 95.39, Test_acc 54.97
2025-02-13 18:04:10,189 [podnet.py] => Task 9, Epoch 15/160 (LR 0.09785) => LSC_loss 0.22, Spatial_loss 4.49, Flat_loss 0.39, Train_acc 95.69, Test_acc 51.57
2025-02-13 18:04:11,691 [podnet.py] => Task 9, Epoch 16/160 (LR 0.09755) => LSC_loss 0.26, Spatial_loss 4.55, Flat_loss 0.42, Train_acc 95.60, Test_acc 53.59
2025-02-13 18:04:13,262 [podnet.py] => Task 9, Epoch 17/160 (LR 0.09724) => LSC_loss 0.27, Spatial_loss 4.77, Flat_loss 0.46, Train_acc 94.31, Test_acc 55.62
2025-02-13 18:04:14,794 [podnet.py] => Task 9, Epoch 18/160 (LR 0.09691) => LSC_loss 0.23, Spatial_loss 4.61, Flat_loss 0.42, Train_acc 95.52, Test_acc 53.41
2025-02-13 18:04:16,376 [podnet.py] => Task 9, Epoch 19/160 (LR 0.09656) => LSC_loss 0.21, Spatial_loss 4.37, Flat_loss 0.38, Train_acc 95.95, Test_acc 55.91
2025-02-13 18:04:17,987 [podnet.py] => Task 9, Epoch 20/160 (LR 0.09619) => LSC_loss 0.20, Spatial_loss 4.10, Flat_loss 0.34, Train_acc 96.51, Test_acc 54.60
2025-02-13 18:04:19,555 [podnet.py] => Task 9, Epoch 21/160 (LR 0.09581) => LSC_loss 0.21, Spatial_loss 4.12, Flat_loss 0.34, Train_acc 95.69, Test_acc 53.96
2025-02-13 18:04:21,109 [podnet.py] => Task 9, Epoch 22/160 (LR 0.09541) => LSC_loss 0.20, Spatial_loss 4.10, Flat_loss 0.34, Train_acc 95.86, Test_acc 56.96
2025-02-13 18:04:22,651 [podnet.py] => Task 9, Epoch 23/160 (LR 0.09499) => LSC_loss 0.23, Spatial_loss 4.38, Flat_loss 0.37, Train_acc 95.34, Test_acc 52.85
2025-02-13 18:04:24,181 [podnet.py] => Task 9, Epoch 24/160 (LR 0.09455) => LSC_loss 0.23, Spatial_loss 4.47, Flat_loss 0.40, Train_acc 95.43, Test_acc 50.72
2025-02-13 18:04:25,764 [podnet.py] => Task 9, Epoch 25/160 (LR 0.09410) => LSC_loss 0.22, Spatial_loss 4.49, Flat_loss 0.39, Train_acc 94.96, Test_acc 54.26
2025-02-13 18:04:27,283 [podnet.py] => Task 9, Epoch 26/160 (LR 0.09362) => LSC_loss 0.21, Spatial_loss 4.12, Flat_loss 0.34, Train_acc 96.59, Test_acc 55.62
2025-02-13 18:04:28,825 [podnet.py] => Task 9, Epoch 27/160 (LR 0.09314) => LSC_loss 0.20, Spatial_loss 4.23, Flat_loss 0.38, Train_acc 96.16, Test_acc 57.21
2025-02-13 18:04:30,438 [podnet.py] => Task 9, Epoch 28/160 (LR 0.09263) => LSC_loss 0.18, Spatial_loss 4.05, Flat_loss 0.33, Train_acc 96.81, Test_acc 57.12
2025-02-13 18:04:31,945 [podnet.py] => Task 9, Epoch 29/160 (LR 0.09211) => LSC_loss 0.18, Spatial_loss 3.97, Flat_loss 0.30, Train_acc 97.41, Test_acc 55.68
2025-02-13 18:04:33,501 [podnet.py] => Task 9, Epoch 30/160 (LR 0.09157) => LSC_loss 0.19, Spatial_loss 3.87, Flat_loss 0.30, Train_acc 96.34, Test_acc 57.04
2025-02-13 18:04:35,043 [podnet.py] => Task 9, Epoch 31/160 (LR 0.09102) => LSC_loss 0.18, Spatial_loss 3.85, Flat_loss 0.30, Train_acc 96.72, Test_acc 55.82
2025-02-13 18:04:36,646 [podnet.py] => Task 9, Epoch 32/160 (LR 0.09045) => LSC_loss 0.20, Spatial_loss 3.81, Flat_loss 0.29, Train_acc 96.64, Test_acc 56.21
2025-02-13 18:04:38,199 [podnet.py] => Task 9, Epoch 33/160 (LR 0.08987) => LSC_loss 0.23, Spatial_loss 4.02, Flat_loss 0.32, Train_acc 95.95, Test_acc 53.93
2025-02-13 18:04:39,805 [podnet.py] => Task 9, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 4.12, Flat_loss 0.36, Train_acc 95.22, Test_acc 54.90
2025-02-13 18:04:41,378 [podnet.py] => Task 9, Epoch 35/160 (LR 0.08865) => LSC_loss 0.21, Spatial_loss 4.20, Flat_loss 0.35, Train_acc 96.03, Test_acc 52.60
2025-02-13 18:04:42,888 [podnet.py] => Task 9, Epoch 36/160 (LR 0.08802) => LSC_loss 0.20, Spatial_loss 4.00, Flat_loss 0.33, Train_acc 96.59, Test_acc 58.60
2025-02-13 18:04:44,447 [podnet.py] => Task 9, Epoch 37/160 (LR 0.08738) => LSC_loss 0.19, Spatial_loss 3.97, Flat_loss 0.34, Train_acc 96.21, Test_acc 55.71
2025-02-13 18:04:45,981 [podnet.py] => Task 9, Epoch 38/160 (LR 0.08672) => LSC_loss 0.19, Spatial_loss 3.84, Flat_loss 0.29, Train_acc 96.77, Test_acc 57.96
2025-02-13 18:04:47,541 [podnet.py] => Task 9, Epoch 39/160 (LR 0.08604) => LSC_loss 0.18, Spatial_loss 3.79, Flat_loss 0.29, Train_acc 97.07, Test_acc 52.07
2025-02-13 18:04:49,084 [podnet.py] => Task 9, Epoch 40/160 (LR 0.08536) => LSC_loss 0.18, Spatial_loss 3.80, Flat_loss 0.29, Train_acc 97.03, Test_acc 54.28
2025-02-13 18:04:50,611 [podnet.py] => Task 9, Epoch 41/160 (LR 0.08465) => LSC_loss 0.20, Spatial_loss 3.76, Flat_loss 0.28, Train_acc 96.64, Test_acc 53.29
2025-02-13 18:04:52,146 [podnet.py] => Task 9, Epoch 42/160 (LR 0.08394) => LSC_loss 0.23, Spatial_loss 3.99, Flat_loss 0.36, Train_acc 96.29, Test_acc 52.78
2025-02-13 18:04:53,691 [podnet.py] => Task 9, Epoch 43/160 (LR 0.08321) => LSC_loss 0.24, Spatial_loss 4.55, Flat_loss 0.42, Train_acc 94.74, Test_acc 54.34
2025-02-13 18:04:55,249 [podnet.py] => Task 9, Epoch 44/160 (LR 0.08247) => LSC_loss 0.20, Spatial_loss 4.07, Flat_loss 0.34, Train_acc 96.42, Test_acc 56.06
2025-02-13 18:04:56,783 [podnet.py] => Task 9, Epoch 45/160 (LR 0.08172) => LSC_loss 0.18, Spatial_loss 3.97, Flat_loss 0.31, Train_acc 96.55, Test_acc 52.65
2025-02-13 18:04:58,326 [podnet.py] => Task 9, Epoch 46/160 (LR 0.08095) => LSC_loss 0.18, Spatial_loss 4.01, Flat_loss 0.30, Train_acc 96.81, Test_acc 54.81
2025-02-13 18:04:59,835 [podnet.py] => Task 9, Epoch 47/160 (LR 0.08018) => LSC_loss 0.22, Spatial_loss 3.96, Flat_loss 0.31, Train_acc 96.29, Test_acc 57.34
2025-02-13 18:05:01,406 [podnet.py] => Task 9, Epoch 48/160 (LR 0.07939) => LSC_loss 0.17, Spatial_loss 3.60, Flat_loss 0.28, Train_acc 97.03, Test_acc 59.34
2025-02-13 18:05:02,972 [podnet.py] => Task 9, Epoch 49/160 (LR 0.07859) => LSC_loss 0.17, Spatial_loss 3.62, Flat_loss 0.27, Train_acc 96.98, Test_acc 53.12
2025-02-13 18:05:04,558 [podnet.py] => Task 9, Epoch 50/160 (LR 0.07778) => LSC_loss 0.20, Spatial_loss 3.67, Flat_loss 0.28, Train_acc 96.98, Test_acc 54.28
2025-02-13 18:05:06,075 [podnet.py] => Task 9, Epoch 51/160 (LR 0.07696) => LSC_loss 0.18, Spatial_loss 3.80, Flat_loss 0.30, Train_acc 97.46, Test_acc 55.82
2025-02-13 18:05:07,636 [podnet.py] => Task 9, Epoch 52/160 (LR 0.07612) => LSC_loss 0.18, Spatial_loss 3.68, Flat_loss 0.27, Train_acc 96.72, Test_acc 57.78
2025-02-13 18:05:09,249 [podnet.py] => Task 9, Epoch 53/160 (LR 0.07528) => LSC_loss 0.17, Spatial_loss 3.70, Flat_loss 0.27, Train_acc 96.90, Test_acc 52.46
2025-02-13 18:05:10,785 [podnet.py] => Task 9, Epoch 54/160 (LR 0.07443) => LSC_loss 0.17, Spatial_loss 3.67, Flat_loss 0.27, Train_acc 96.51, Test_acc 55.31
2025-02-13 18:05:12,373 [podnet.py] => Task 9, Epoch 55/160 (LR 0.07357) => LSC_loss 0.18, Spatial_loss 3.50, Flat_loss 0.25, Train_acc 97.46, Test_acc 55.93
2025-02-13 18:05:14,025 [podnet.py] => Task 9, Epoch 56/160 (LR 0.07270) => LSC_loss 0.24, Spatial_loss 3.91, Flat_loss 0.33, Train_acc 95.30, Test_acc 55.28
2025-02-13 18:05:15,626 [podnet.py] => Task 9, Epoch 57/160 (LR 0.07182) => LSC_loss 0.18, Spatial_loss 3.75, Flat_loss 0.31, Train_acc 96.64, Test_acc 59.25
2025-02-13 18:05:17,122 [podnet.py] => Task 9, Epoch 58/160 (LR 0.07093) => LSC_loss 0.17, Spatial_loss 3.63, Flat_loss 0.27, Train_acc 97.33, Test_acc 56.19
2025-02-13 18:05:18,709 [podnet.py] => Task 9, Epoch 59/160 (LR 0.07004) => LSC_loss 0.18, Spatial_loss 3.41, Flat_loss 0.24, Train_acc 96.98, Test_acc 54.47
2025-02-13 18:05:20,258 [podnet.py] => Task 9, Epoch 60/160 (LR 0.06913) => LSC_loss 0.16, Spatial_loss 3.43, Flat_loss 0.25, Train_acc 97.20, Test_acc 57.51
2025-02-13 18:05:21,849 [podnet.py] => Task 9, Epoch 61/160 (LR 0.06822) => LSC_loss 0.19, Spatial_loss 3.59, Flat_loss 0.25, Train_acc 97.16, Test_acc 53.96
2025-02-13 18:05:23,441 [podnet.py] => Task 9, Epoch 62/160 (LR 0.06731) => LSC_loss 0.22, Spatial_loss 3.81, Flat_loss 0.33, Train_acc 95.69, Test_acc 59.10
2025-02-13 18:05:24,970 [podnet.py] => Task 9, Epoch 63/160 (LR 0.06638) => LSC_loss 0.23, Spatial_loss 3.61, Flat_loss 0.29, Train_acc 96.51, Test_acc 54.51
2025-02-13 18:05:26,611 [podnet.py] => Task 9, Epoch 64/160 (LR 0.06545) => LSC_loss 0.20, Spatial_loss 3.66, Flat_loss 0.31, Train_acc 96.94, Test_acc 59.13
2025-02-13 18:05:28,166 [podnet.py] => Task 9, Epoch 65/160 (LR 0.06451) => LSC_loss 0.18, Spatial_loss 3.45, Flat_loss 0.28, Train_acc 96.64, Test_acc 56.49
2025-02-13 18:05:29,809 [podnet.py] => Task 9, Epoch 66/160 (LR 0.06357) => LSC_loss 0.17, Spatial_loss 3.24, Flat_loss 0.24, Train_acc 97.07, Test_acc 57.63
2025-02-13 18:05:31,338 [podnet.py] => Task 9, Epoch 67/160 (LR 0.06262) => LSC_loss 0.18, Spatial_loss 3.35, Flat_loss 0.24, Train_acc 97.50, Test_acc 57.13
2025-02-13 18:05:32,869 [podnet.py] => Task 9, Epoch 68/160 (LR 0.06167) => LSC_loss 0.19, Spatial_loss 3.45, Flat_loss 0.26, Train_acc 96.38, Test_acc 55.71
2025-02-13 18:05:34,426 [podnet.py] => Task 9, Epoch 69/160 (LR 0.06072) => LSC_loss 0.18, Spatial_loss 3.49, Flat_loss 0.26, Train_acc 96.98, Test_acc 56.54
2025-02-13 18:05:35,941 [podnet.py] => Task 9, Epoch 70/160 (LR 0.05975) => LSC_loss 0.17, Spatial_loss 3.36, Flat_loss 0.26, Train_acc 97.24, Test_acc 57.35
2025-02-13 18:05:37,476 [podnet.py] => Task 9, Epoch 71/160 (LR 0.05879) => LSC_loss 0.17, Spatial_loss 3.51, Flat_loss 0.25, Train_acc 97.20, Test_acc 57.37
2025-02-13 18:05:39,027 [podnet.py] => Task 9, Epoch 72/160 (LR 0.05782) => LSC_loss 0.17, Spatial_loss 3.37, Flat_loss 0.24, Train_acc 97.20, Test_acc 57.63
2025-02-13 18:05:40,545 [podnet.py] => Task 9, Epoch 73/160 (LR 0.05685) => LSC_loss 0.16, Spatial_loss 3.32, Flat_loss 0.22, Train_acc 97.67, Test_acc 56.25
2025-02-13 18:05:42,124 [podnet.py] => Task 9, Epoch 74/160 (LR 0.05588) => LSC_loss 0.17, Spatial_loss 3.42, Flat_loss 0.23, Train_acc 97.20, Test_acc 57.38
2025-02-13 18:05:43,661 [podnet.py] => Task 9, Epoch 75/160 (LR 0.05490) => LSC_loss 0.16, Spatial_loss 3.28, Flat_loss 0.22, Train_acc 97.46, Test_acc 56.06
2025-02-13 18:05:45,232 [podnet.py] => Task 9, Epoch 76/160 (LR 0.05392) => LSC_loss 0.17, Spatial_loss 3.25, Flat_loss 0.22, Train_acc 97.50, Test_acc 59.26
2025-02-13 18:05:46,763 [podnet.py] => Task 9, Epoch 77/160 (LR 0.05294) => LSC_loss 0.16, Spatial_loss 3.10, Flat_loss 0.21, Train_acc 97.24, Test_acc 57.63
2025-02-13 18:05:48,326 [podnet.py] => Task 9, Epoch 78/160 (LR 0.05196) => LSC_loss 0.19, Spatial_loss 3.28, Flat_loss 0.23, Train_acc 97.76, Test_acc 57.10
2025-02-13 18:05:49,895 [podnet.py] => Task 9, Epoch 79/160 (LR 0.05098) => LSC_loss 0.18, Spatial_loss 3.33, Flat_loss 0.24, Train_acc 97.16, Test_acc 54.37
2025-02-13 18:05:51,505 [podnet.py] => Task 9, Epoch 80/160 (LR 0.05000) => LSC_loss 0.18, Spatial_loss 3.34, Flat_loss 0.23, Train_acc 97.20, Test_acc 53.84
2025-02-13 18:05:53,027 [podnet.py] => Task 9, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.21, Train_acc 97.54, Test_acc 58.72
2025-02-13 18:05:54,647 [podnet.py] => Task 9, Epoch 82/160 (LR 0.04804) => LSC_loss 0.16, Spatial_loss 3.14, Flat_loss 0.21, Train_acc 97.54, Test_acc 55.29
2025-02-13 18:05:56,228 [podnet.py] => Task 9, Epoch 83/160 (LR 0.04706) => LSC_loss 0.16, Spatial_loss 2.98, Flat_loss 0.20, Train_acc 97.28, Test_acc 57.43
2025-02-13 18:05:57,816 [podnet.py] => Task 9, Epoch 84/160 (LR 0.04608) => LSC_loss 0.17, Spatial_loss 3.19, Flat_loss 0.23, Train_acc 97.63, Test_acc 58.91
2025-02-13 18:05:59,372 [podnet.py] => Task 9, Epoch 85/160 (LR 0.04510) => LSC_loss 0.16, Spatial_loss 3.26, Flat_loss 0.22, Train_acc 97.63, Test_acc 56.63
2025-02-13 18:06:00,884 [podnet.py] => Task 9, Epoch 86/160 (LR 0.04412) => LSC_loss 0.18, Spatial_loss 3.19, Flat_loss 0.22, Train_acc 97.07, Test_acc 57.06
2025-02-13 18:06:02,451 [podnet.py] => Task 9, Epoch 87/160 (LR 0.04315) => LSC_loss 0.18, Spatial_loss 3.00, Flat_loss 0.21, Train_acc 97.33, Test_acc 56.63
2025-02-13 18:06:03,999 [podnet.py] => Task 9, Epoch 88/160 (LR 0.04218) => LSC_loss 0.16, Spatial_loss 3.01, Flat_loss 0.21, Train_acc 97.50, Test_acc 59.99
2025-02-13 18:06:05,521 [podnet.py] => Task 9, Epoch 89/160 (LR 0.04121) => LSC_loss 0.16, Spatial_loss 3.03, Flat_loss 0.21, Train_acc 97.33, Test_acc 56.71
2025-02-13 18:06:07,098 [podnet.py] => Task 9, Epoch 90/160 (LR 0.04025) => LSC_loss 0.17, Spatial_loss 2.97, Flat_loss 0.21, Train_acc 97.20, Test_acc 57.22
2025-02-13 18:06:08,618 [podnet.py] => Task 9, Epoch 91/160 (LR 0.03928) => LSC_loss 0.16, Spatial_loss 2.89, Flat_loss 0.20, Train_acc 97.50, Test_acc 58.56
2025-02-13 18:06:10,152 [podnet.py] => Task 9, Epoch 92/160 (LR 0.03833) => LSC_loss 0.16, Spatial_loss 2.87, Flat_loss 0.20, Train_acc 97.93, Test_acc 59.75
2025-02-13 18:06:11,687 [podnet.py] => Task 9, Epoch 93/160 (LR 0.03738) => LSC_loss 0.18, Spatial_loss 2.78, Flat_loss 0.19, Train_acc 97.20, Test_acc 57.54
2025-02-13 18:06:13,216 [podnet.py] => Task 9, Epoch 94/160 (LR 0.03643) => LSC_loss 0.17, Spatial_loss 2.75, Flat_loss 0.19, Train_acc 97.07, Test_acc 55.69
2025-02-13 18:06:14,725 [podnet.py] => Task 9, Epoch 95/160 (LR 0.03549) => LSC_loss 0.17, Spatial_loss 2.80, Flat_loss 0.18, Train_acc 97.72, Test_acc 60.50
2025-02-13 18:06:16,263 [podnet.py] => Task 9, Epoch 96/160 (LR 0.03455) => LSC_loss 0.16, Spatial_loss 2.75, Flat_loss 0.18, Train_acc 97.59, Test_acc 59.13
2025-02-13 18:06:17,849 [podnet.py] => Task 9, Epoch 97/160 (LR 0.03362) => LSC_loss 0.15, Spatial_loss 2.71, Flat_loss 0.17, Train_acc 97.97, Test_acc 58.66
2025-02-13 18:06:19,395 [podnet.py] => Task 9, Epoch 98/160 (LR 0.03269) => LSC_loss 0.16, Spatial_loss 2.71, Flat_loss 0.16, Train_acc 97.28, Test_acc 60.46
2025-02-13 18:06:20,954 [podnet.py] => Task 9, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 2.82, Flat_loss 0.18, Train_acc 97.54, Test_acc 59.63
2025-02-13 18:06:22,470 [podnet.py] => Task 9, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 2.68, Flat_loss 0.17, Train_acc 97.76, Test_acc 58.10
2025-02-13 18:06:24,051 [podnet.py] => Task 9, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 2.74, Flat_loss 0.18, Train_acc 97.59, Test_acc 60.82
2025-02-13 18:06:25,568 [podnet.py] => Task 9, Epoch 102/160 (LR 0.02907) => LSC_loss 0.17, Spatial_loss 2.73, Flat_loss 0.18, Train_acc 97.41, Test_acc 58.15
2025-02-13 18:06:27,089 [podnet.py] => Task 9, Epoch 103/160 (LR 0.02818) => LSC_loss 0.16, Spatial_loss 2.78, Flat_loss 0.17, Train_acc 97.50, Test_acc 57.56
2025-02-13 18:06:28,669 [podnet.py] => Task 9, Epoch 104/160 (LR 0.02730) => LSC_loss 0.16, Spatial_loss 2.56, Flat_loss 0.17, Train_acc 97.97, Test_acc 59.43
2025-02-13 18:06:30,236 [podnet.py] => Task 9, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 2.64, Flat_loss 0.17, Train_acc 97.24, Test_acc 57.69
2025-02-13 18:06:31,778 [podnet.py] => Task 9, Epoch 106/160 (LR 0.02557) => LSC_loss 0.15, Spatial_loss 2.47, Flat_loss 0.16, Train_acc 98.10, Test_acc 59.07
2025-02-13 18:06:33,307 [podnet.py] => Task 9, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 2.41, Flat_loss 0.15, Train_acc 97.80, Test_acc 60.18
2025-02-13 18:06:34,888 [podnet.py] => Task 9, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 2.50, Flat_loss 0.16, Train_acc 97.46, Test_acc 59.78
2025-02-13 18:06:36,479 [podnet.py] => Task 9, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 2.51, Flat_loss 0.15, Train_acc 97.93, Test_acc 58.35
2025-02-13 18:06:37,992 [podnet.py] => Task 9, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 2.47, Flat_loss 0.15, Train_acc 97.72, Test_acc 60.57
2025-02-13 18:06:39,570 [podnet.py] => Task 9, Epoch 111/160 (LR 0.02141) => LSC_loss 0.15, Spatial_loss 2.39, Flat_loss 0.15, Train_acc 97.93, Test_acc 59.94
2025-02-13 18:06:41,117 [podnet.py] => Task 9, Epoch 112/160 (LR 0.02061) => LSC_loss 0.15, Spatial_loss 2.40, Flat_loss 0.15, Train_acc 97.46, Test_acc 59.46
2025-02-13 18:06:42,651 [podnet.py] => Task 9, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 2.44, Flat_loss 0.15, Train_acc 97.59, Test_acc 60.88
2025-02-13 18:06:44,181 [podnet.py] => Task 9, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 97.67, Test_acc 59.34
2025-02-13 18:06:45,711 [podnet.py] => Task 9, Epoch 115/160 (LR 0.01828) => LSC_loss 0.16, Spatial_loss 2.53, Flat_loss 0.17, Train_acc 98.02, Test_acc 58.41
2025-02-13 18:06:47,289 [podnet.py] => Task 9, Epoch 116/160 (LR 0.01753) => LSC_loss 0.16, Spatial_loss 2.31, Flat_loss 0.15, Train_acc 97.46, Test_acc 59.72
2025-02-13 18:06:48,858 [podnet.py] => Task 9, Epoch 117/160 (LR 0.01679) => LSC_loss 0.15, Spatial_loss 2.32, Flat_loss 0.14, Train_acc 97.46, Test_acc 61.18
2025-02-13 18:06:50,328 [podnet.py] => Task 9, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 2.27, Flat_loss 0.13, Train_acc 97.72, Test_acc 58.32
2025-02-13 18:06:51,886 [podnet.py] => Task 9, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 2.35, Flat_loss 0.16, Train_acc 97.97, Test_acc 58.93
2025-02-13 18:06:53,455 [podnet.py] => Task 9, Epoch 120/160 (LR 0.01464) => LSC_loss 0.17, Spatial_loss 2.36, Flat_loss 0.15, Train_acc 97.97, Test_acc 58.51
2025-02-13 18:06:54,983 [podnet.py] => Task 9, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 2.40, Flat_loss 0.15, Train_acc 98.02, Test_acc 60.88
2025-02-13 18:06:56,554 [podnet.py] => Task 9, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 2.21, Flat_loss 0.13, Train_acc 97.67, Test_acc 60.18
2025-02-13 18:06:58,175 [podnet.py] => Task 9, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 2.25, Flat_loss 0.14, Train_acc 97.54, Test_acc 60.06
2025-02-13 18:06:59,741 [podnet.py] => Task 9, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 2.28, Flat_loss 0.13, Train_acc 97.37, Test_acc 60.47
2025-02-13 18:07:01,321 [podnet.py] => Task 9, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 2.16, Flat_loss 0.13, Train_acc 97.67, Test_acc 60.87
2025-02-13 18:07:02,850 [podnet.py] => Task 9, Epoch 126/160 (LR 0.01073) => LSC_loss 0.16, Spatial_loss 2.16, Flat_loss 0.13, Train_acc 97.28, Test_acc 60.15
2025-02-13 18:07:04,446 [podnet.py] => Task 9, Epoch 127/160 (LR 0.01013) => LSC_loss 0.15, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 97.93, Test_acc 60.37
2025-02-13 18:07:05,987 [podnet.py] => Task 9, Epoch 128/160 (LR 0.00955) => LSC_loss 0.15, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 98.23, Test_acc 60.63
2025-02-13 18:07:07,549 [podnet.py] => Task 9, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 2.12, Flat_loss 0.12, Train_acc 97.46, Test_acc 60.07
2025-02-13 18:07:09,086 [podnet.py] => Task 9, Epoch 130/160 (LR 0.00843) => LSC_loss 0.15, Spatial_loss 2.05, Flat_loss 0.12, Train_acc 97.76, Test_acc 59.72
2025-02-13 18:07:10,629 [podnet.py] => Task 9, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 2.08, Flat_loss 0.13, Train_acc 97.28, Test_acc 60.50
2025-02-13 18:07:12,163 [podnet.py] => Task 9, Epoch 132/160 (LR 0.00737) => LSC_loss 0.17, Spatial_loss 2.02, Flat_loss 0.12, Train_acc 97.97, Test_acc 60.50
2025-02-13 18:07:13,646 [podnet.py] => Task 9, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 1.97, Flat_loss 0.12, Train_acc 97.97, Test_acc 60.03
2025-02-13 18:07:15,194 [podnet.py] => Task 9, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.94, Flat_loss 0.12, Train_acc 97.67, Test_acc 60.76
2025-02-13 18:07:16,736 [podnet.py] => Task 9, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 97.59, Test_acc 61.03
2025-02-13 18:07:18,329 [podnet.py] => Task 9, Epoch 136/160 (LR 0.00545) => LSC_loss 0.16, Spatial_loss 1.87, Flat_loss 0.11, Train_acc 97.72, Test_acc 60.65
2025-02-13 18:07:19,942 [podnet.py] => Task 9, Epoch 137/160 (LR 0.00501) => LSC_loss 0.16, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 97.72, Test_acc 61.43
2025-02-13 18:07:21,523 [podnet.py] => Task 9, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 97.93, Test_acc 61.10
2025-02-13 18:07:23,132 [podnet.py] => Task 9, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 1.90, Flat_loss 0.12, Train_acc 97.50, Test_acc 61.19
2025-02-13 18:07:24,643 [podnet.py] => Task 9, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 97.54, Test_acc 60.16
2025-02-13 18:07:26,203 [podnet.py] => Task 9, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 1.84, Flat_loss 0.12, Train_acc 97.24, Test_acc 61.29
2025-02-13 18:07:27,755 [podnet.py] => Task 9, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 1.84, Flat_loss 0.11, Train_acc 97.93, Test_acc 60.96
2025-02-13 18:07:29,350 [podnet.py] => Task 9, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 97.41, Test_acc 61.25
2025-02-13 18:07:30,894 [podnet.py] => Task 9, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 1.88, Flat_loss 0.11, Train_acc 98.02, Test_acc 60.66
2025-02-13 18:07:32,412 [podnet.py] => Task 9, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 97.72, Test_acc 60.63
2025-02-13 18:07:33,980 [podnet.py] => Task 9, Epoch 146/160 (LR 0.00188) => LSC_loss 0.16, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 97.72, Test_acc 60.94
2025-02-13 18:07:35,556 [podnet.py] => Task 9, Epoch 147/160 (LR 0.00162) => LSC_loss 0.18, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 97.93, Test_acc 61.04
2025-02-13 18:07:37,093 [podnet.py] => Task 9, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 1.73, Flat_loss 0.10, Train_acc 97.41, Test_acc 60.76
2025-02-13 18:07:38,658 [podnet.py] => Task 9, Epoch 149/160 (LR 0.00116) => LSC_loss 0.18, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 97.84, Test_acc 60.84
2025-02-13 18:07:40,257 [podnet.py] => Task 9, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 97.63, Test_acc 61.00
2025-02-13 18:07:41,793 [podnet.py] => Task 9, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 97.76, Test_acc 60.68
2025-02-13 18:07:43,344 [podnet.py] => Task 9, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 97.84, Test_acc 61.09
2025-02-13 18:07:44,952 [podnet.py] => Task 9, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 98.19, Test_acc 60.91
2025-02-13 18:07:46,515 [podnet.py] => Task 9, Epoch 154/160 (LR 0.00035) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.10, Train_acc 98.10, Test_acc 60.85
2025-02-13 18:07:48,107 [podnet.py] => Task 9, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 97.97, Test_acc 60.87
2025-02-13 18:07:49,720 [podnet.py] => Task 9, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 97.54, Test_acc 60.94
2025-02-13 18:07:51,294 [podnet.py] => Task 9, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 1.70, Flat_loss 0.10, Train_acc 97.72, Test_acc 60.75
2025-02-13 18:07:52,897 [podnet.py] => Task 9, Epoch 158/160 (LR 0.00004) => LSC_loss 0.16, Spatial_loss 1.64, Flat_loss 0.10, Train_acc 97.46, Test_acc 60.94
2025-02-13 18:07:54,468 [podnet.py] => Task 9, Epoch 159/160 (LR 0.00001) => LSC_loss 0.16, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 97.84, Test_acc 60.53
2025-02-13 18:07:56,003 [podnet.py] => Task 9, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.80, Flat_loss 0.12, Train_acc 97.76, Test_acc 60.91
2025-02-13 18:07:56,004 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:07:56,004 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:08:17,103 [podnet.py] => The size of finetune dataset: 1360
2025-02-13 18:08:18,443 [podnet.py] => Task 9, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 2.31, Flat_loss 0.15, Train_acc 97.21, Test_acc 60.00
2025-02-13 18:08:19,774 [podnet.py] => Task 9, Epoch 2/20 (LR 0.00488) => LSC_loss 0.09, Spatial_loss 1.95, Flat_loss 0.09, Train_acc 99.12, Test_acc 60.19
2025-02-13 18:08:21,101 [podnet.py] => Task 9, Epoch 3/20 (LR 0.00473) => LSC_loss 0.08, Spatial_loss 1.81, Flat_loss 0.07, Train_acc 99.19, Test_acc 61.56
2025-02-13 18:08:22,454 [podnet.py] => Task 9, Epoch 4/20 (LR 0.00452) => LSC_loss 0.08, Spatial_loss 1.69, Flat_loss 0.06, Train_acc 99.41, Test_acc 61.28
2025-02-13 18:08:23,794 [podnet.py] => Task 9, Epoch 5/20 (LR 0.00427) => LSC_loss 0.08, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 99.19, Test_acc 61.69
2025-02-13 18:08:25,089 [podnet.py] => Task 9, Epoch 6/20 (LR 0.00397) => LSC_loss 0.08, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 99.49, Test_acc 61.75
2025-02-13 18:08:26,419 [podnet.py] => Task 9, Epoch 7/20 (LR 0.00363) => LSC_loss 0.08, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.26, Test_acc 61.63
2025-02-13 18:08:27,761 [podnet.py] => Task 9, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 1.72, Flat_loss 0.06, Train_acc 99.49, Test_acc 61.72
2025-02-13 18:08:29,056 [podnet.py] => Task 9, Epoch 9/20 (LR 0.00289) => LSC_loss 0.07, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.49, Test_acc 61.68
2025-02-13 18:08:30,370 [podnet.py] => Task 9, Epoch 10/20 (LR 0.00250) => LSC_loss 0.08, Spatial_loss 1.70, Flat_loss 0.06, Train_acc 99.34, Test_acc 61.66
2025-02-13 18:08:31,752 [podnet.py] => Task 9, Epoch 11/20 (LR 0.00211) => LSC_loss 0.08, Spatial_loss 1.63, Flat_loss 0.05, Train_acc 99.19, Test_acc 61.78
2025-02-13 18:08:33,132 [podnet.py] => Task 9, Epoch 12/20 (LR 0.00173) => LSC_loss 0.07, Spatial_loss 1.58, Flat_loss 0.05, Train_acc 99.71, Test_acc 61.53
2025-02-13 18:08:34,468 [podnet.py] => Task 9, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 1.66, Flat_loss 0.05, Train_acc 99.12, Test_acc 61.62
2025-02-13 18:08:35,748 [podnet.py] => Task 9, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 1.68, Flat_loss 0.05, Train_acc 99.04, Test_acc 61.74
2025-02-13 18:08:37,096 [podnet.py] => Task 9, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 99.41, Test_acc 61.74
2025-02-13 18:08:38,403 [podnet.py] => Task 9, Epoch 16/20 (LR 0.00048) => LSC_loss 0.07, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 99.41, Test_acc 61.54
2025-02-13 18:08:39,742 [podnet.py] => Task 9, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 1.60, Flat_loss 0.05, Train_acc 99.49, Test_acc 61.76
2025-02-13 18:08:41,026 [podnet.py] => Task 9, Epoch 18/20 (LR 0.00012) => LSC_loss 0.07, Spatial_loss 1.54, Flat_loss 0.05, Train_acc 99.49, Test_acc 61.69
2025-02-13 18:08:42,435 [podnet.py] => Task 9, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 1.51, Flat_loss 0.05, Train_acc 99.34, Test_acc 61.71
2025-02-13 18:08:43,793 [podnet.py] => Task 9, Epoch 20/20 (LR 0.00000) => LSC_loss 0.08, Spatial_loss 1.56, Flat_loss 0.05, Train_acc 99.12, Test_acc 61.54
2025-02-13 18:08:43,794 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:09:06,912 [podnet.py] => Exemplar size: 1360
2025-02-13 18:09:06,912 [trainer.py] => CNN: {'total': 61.54, '00-09': 70.8, '10-19': 51.0, '20-29': 69.4, '30-39': 59.8, '40-49': 67.0, '50-59': 50.0, '60-69': 63.12, 'old': 60.94, 'new': 81.5}
2025-02-13 18:09:06,912 [trainer.py] => NME: {'total': 62.16, '00-09': 73.4, '10-19': 55.6, '20-29': 72.3, '30-39': 61.0, '40-49': 67.9, '50-59': 45.3, '60-69': 59.0, 'old': 61.62, 'new': 80.0}
2025-02-13 18:09:06,912 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54]
2025-02-13 18:09:06,912 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71]
2025-02-13 18:09:06,912 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16]
2025-02-13 18:09:06,912 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16]

2025-02-13 18:09:06,912 [trainer.py] => Average Accuracy (CNN): 69.13199999999999
2025-02-13 18:09:06,912 [trainer.py] => Average Accuracy (NME): 69.32499999999999
2025-02-13 18:09:06,912 [trainer.py] => All params: 509777
2025-02-13 18:09:06,913 [trainer.py] => Trainable params: 509777
2025-02-13 18:09:06,913 [podnet.py] => Learning on 68-70
2025-02-13 18:09:06,932 [podnet.py] => Adaptive factor: 5.916079783099616
2025-02-13 18:09:08,492 [podnet.py] => Task 10, Epoch 1/160 (LR 0.09999) => LSC_loss 1.27, Spatial_loss 4.26, Flat_loss 0.56, Train_acc 81.53, Test_acc 48.96
2025-02-13 18:09:10,047 [podnet.py] => Task 10, Epoch 2/160 (LR 0.09996) => LSC_loss 0.34, Spatial_loss 4.74, Flat_loss 0.48, Train_acc 90.97, Test_acc 57.34
2025-02-13 18:09:11,568 [podnet.py] => Task 10, Epoch 3/160 (LR 0.09991) => LSC_loss 0.30, Spatial_loss 4.51, Flat_loss 0.41, Train_acc 92.92, Test_acc 49.90
2025-02-13 18:09:13,132 [podnet.py] => Task 10, Epoch 4/160 (LR 0.09985) => LSC_loss 0.27, Spatial_loss 4.67, Flat_loss 0.41, Train_acc 93.56, Test_acc 53.61
2025-02-13 18:09:14,664 [podnet.py] => Task 10, Epoch 5/160 (LR 0.09976) => LSC_loss 0.25, Spatial_loss 4.47, Flat_loss 0.39, Train_acc 94.45, Test_acc 57.16
2025-02-13 18:09:16,188 [podnet.py] => Task 10, Epoch 6/160 (LR 0.09965) => LSC_loss 0.24, Spatial_loss 4.28, Flat_loss 0.36, Train_acc 94.45, Test_acc 53.13
2025-02-13 18:09:17,780 [podnet.py] => Task 10, Epoch 7/160 (LR 0.09953) => LSC_loss 0.24, Spatial_loss 4.16, Flat_loss 0.34, Train_acc 95.25, Test_acc 52.11
2025-02-13 18:09:19,369 [podnet.py] => Task 10, Epoch 8/160 (LR 0.09938) => LSC_loss 0.24, Spatial_loss 4.26, Flat_loss 0.35, Train_acc 94.58, Test_acc 52.50
2025-02-13 18:09:20,906 [podnet.py] => Task 10, Epoch 9/160 (LR 0.09922) => LSC_loss 0.22, Spatial_loss 4.17, Flat_loss 0.35, Train_acc 95.64, Test_acc 56.01
2025-02-13 18:09:22,492 [podnet.py] => Task 10, Epoch 10/160 (LR 0.09904) => LSC_loss 0.21, Spatial_loss 4.15, Flat_loss 0.35, Train_acc 95.59, Test_acc 54.91
2025-02-13 18:09:24,035 [podnet.py] => Task 10, Epoch 11/160 (LR 0.09884) => LSC_loss 0.23, Spatial_loss 3.95, Flat_loss 0.31, Train_acc 95.89, Test_acc 57.71
2025-02-13 18:09:25,628 [podnet.py] => Task 10, Epoch 12/160 (LR 0.09862) => LSC_loss 0.21, Spatial_loss 4.00, Flat_loss 0.32, Train_acc 95.76, Test_acc 55.71
2025-02-13 18:09:27,204 [podnet.py] => Task 10, Epoch 13/160 (LR 0.09838) => LSC_loss 0.22, Spatial_loss 4.05, Flat_loss 0.33, Train_acc 95.30, Test_acc 54.66
2025-02-13 18:09:28,791 [podnet.py] => Task 10, Epoch 14/160 (LR 0.09812) => LSC_loss 0.22, Spatial_loss 3.97, Flat_loss 0.32, Train_acc 95.17, Test_acc 56.14
2025-02-13 18:09:30,287 [podnet.py] => Task 10, Epoch 15/160 (LR 0.09785) => LSC_loss 0.22, Spatial_loss 4.10, Flat_loss 0.34, Train_acc 95.42, Test_acc 54.99
2025-02-13 18:09:31,809 [podnet.py] => Task 10, Epoch 16/160 (LR 0.09755) => LSC_loss 0.21, Spatial_loss 4.00, Flat_loss 0.32, Train_acc 95.64, Test_acc 52.77
2025-02-13 18:09:33,377 [podnet.py] => Task 10, Epoch 17/160 (LR 0.09724) => LSC_loss 0.21, Spatial_loss 4.04, Flat_loss 0.34, Train_acc 95.51, Test_acc 54.06
2025-02-13 18:09:34,942 [podnet.py] => Task 10, Epoch 18/160 (LR 0.09691) => LSC_loss 0.21, Spatial_loss 4.05, Flat_loss 0.33, Train_acc 95.68, Test_acc 55.20
2025-02-13 18:09:36,521 [podnet.py] => Task 10, Epoch 19/160 (LR 0.09656) => LSC_loss 0.21, Spatial_loss 4.12, Flat_loss 0.33, Train_acc 95.72, Test_acc 55.87
2025-02-13 18:09:38,073 [podnet.py] => Task 10, Epoch 20/160 (LR 0.09619) => LSC_loss 0.20, Spatial_loss 4.02, Flat_loss 0.32, Train_acc 95.97, Test_acc 54.76
2025-02-13 18:09:39,611 [podnet.py] => Task 10, Epoch 21/160 (LR 0.09581) => LSC_loss 0.21, Spatial_loss 4.05, Flat_loss 0.32, Train_acc 95.59, Test_acc 49.50
2025-02-13 18:09:41,137 [podnet.py] => Task 10, Epoch 22/160 (LR 0.09541) => LSC_loss 0.20, Spatial_loss 4.17, Flat_loss 0.34, Train_acc 96.40, Test_acc 57.63
2025-02-13 18:09:42,775 [podnet.py] => Task 10, Epoch 23/160 (LR 0.09499) => LSC_loss 0.19, Spatial_loss 3.92, Flat_loss 0.30, Train_acc 96.48, Test_acc 59.31
2025-02-13 18:09:44,346 [podnet.py] => Task 10, Epoch 24/160 (LR 0.09455) => LSC_loss 0.20, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 95.89, Test_acc 54.33
2025-02-13 18:09:45,937 [podnet.py] => Task 10, Epoch 25/160 (LR 0.09410) => LSC_loss 0.19, Spatial_loss 3.80, Flat_loss 0.29, Train_acc 96.36, Test_acc 55.99
2025-02-13 18:09:47,517 [podnet.py] => Task 10, Epoch 26/160 (LR 0.09362) => LSC_loss 0.18, Spatial_loss 3.81, Flat_loss 0.30, Train_acc 96.65, Test_acc 57.23
2025-02-13 18:09:49,090 [podnet.py] => Task 10, Epoch 27/160 (LR 0.09314) => LSC_loss 0.19, Spatial_loss 3.90, Flat_loss 0.31, Train_acc 96.14, Test_acc 56.60
2025-02-13 18:09:50,661 [podnet.py] => Task 10, Epoch 28/160 (LR 0.09263) => LSC_loss 0.19, Spatial_loss 4.04, Flat_loss 0.31, Train_acc 96.10, Test_acc 50.47
2025-02-13 18:09:52,198 [podnet.py] => Task 10, Epoch 29/160 (LR 0.09211) => LSC_loss 0.19, Spatial_loss 3.83, Flat_loss 0.30, Train_acc 96.78, Test_acc 57.71
2025-02-13 18:09:53,709 [podnet.py] => Task 10, Epoch 30/160 (LR 0.09157) => LSC_loss 0.19, Spatial_loss 3.92, Flat_loss 0.30, Train_acc 96.02, Test_acc 55.10
2025-02-13 18:09:55,245 [podnet.py] => Task 10, Epoch 31/160 (LR 0.09102) => LSC_loss 0.19, Spatial_loss 3.95, Flat_loss 0.30, Train_acc 96.69, Test_acc 51.74
2025-02-13 18:09:56,825 [podnet.py] => Task 10, Epoch 32/160 (LR 0.09045) => LSC_loss 0.20, Spatial_loss 3.98, Flat_loss 0.31, Train_acc 96.40, Test_acc 49.67
2025-02-13 18:09:58,409 [podnet.py] => Task 10, Epoch 33/160 (LR 0.08987) => LSC_loss 0.18, Spatial_loss 3.81, Flat_loss 0.29, Train_acc 97.20, Test_acc 56.09
2025-02-13 18:10:00,032 [podnet.py] => Task 10, Epoch 34/160 (LR 0.08927) => LSC_loss 0.18, Spatial_loss 3.76, Flat_loss 0.30, Train_acc 97.20, Test_acc 57.81
2025-02-13 18:10:01,572 [podnet.py] => Task 10, Epoch 35/160 (LR 0.08865) => LSC_loss 0.18, Spatial_loss 3.79, Flat_loss 0.28, Train_acc 96.86, Test_acc 55.23
2025-02-13 18:10:03,135 [podnet.py] => Task 10, Epoch 36/160 (LR 0.08802) => LSC_loss 0.19, Spatial_loss 3.84, Flat_loss 0.29, Train_acc 96.06, Test_acc 53.76
2025-02-13 18:10:04,673 [podnet.py] => Task 10, Epoch 37/160 (LR 0.08738) => LSC_loss 0.18, Spatial_loss 3.88, Flat_loss 0.29, Train_acc 96.23, Test_acc 53.01
2025-02-13 18:10:06,267 [podnet.py] => Task 10, Epoch 38/160 (LR 0.08672) => LSC_loss 0.19, Spatial_loss 3.72, Flat_loss 0.29, Train_acc 96.69, Test_acc 56.69
2025-02-13 18:10:07,840 [podnet.py] => Task 10, Epoch 39/160 (LR 0.08604) => LSC_loss 0.19, Spatial_loss 3.72, Flat_loss 0.28, Train_acc 96.19, Test_acc 55.77
2025-02-13 18:10:09,352 [podnet.py] => Task 10, Epoch 40/160 (LR 0.08536) => LSC_loss 0.18, Spatial_loss 3.73, Flat_loss 0.29, Train_acc 96.91, Test_acc 55.46
2025-02-13 18:10:10,935 [podnet.py] => Task 10, Epoch 41/160 (LR 0.08465) => LSC_loss 0.19, Spatial_loss 3.78, Flat_loss 0.29, Train_acc 96.40, Test_acc 56.53
2025-02-13 18:10:12,456 [podnet.py] => Task 10, Epoch 42/160 (LR 0.08394) => LSC_loss 0.20, Spatial_loss 3.92, Flat_loss 0.30, Train_acc 96.23, Test_acc 57.09
2025-02-13 18:10:13,961 [podnet.py] => Task 10, Epoch 43/160 (LR 0.08321) => LSC_loss 0.17, Spatial_loss 3.74, Flat_loss 0.28, Train_acc 96.61, Test_acc 56.33
2025-02-13 18:10:15,520 [podnet.py] => Task 10, Epoch 44/160 (LR 0.08247) => LSC_loss 0.18, Spatial_loss 3.55, Flat_loss 0.26, Train_acc 96.57, Test_acc 56.31
2025-02-13 18:10:17,128 [podnet.py] => Task 10, Epoch 45/160 (LR 0.08172) => LSC_loss 0.19, Spatial_loss 3.87, Flat_loss 0.28, Train_acc 96.31, Test_acc 56.50
2025-02-13 18:10:18,740 [podnet.py] => Task 10, Epoch 46/160 (LR 0.08095) => LSC_loss 0.18, Spatial_loss 3.65, Flat_loss 0.27, Train_acc 96.82, Test_acc 55.14
2025-02-13 18:10:20,328 [podnet.py] => Task 10, Epoch 47/160 (LR 0.08018) => LSC_loss 0.17, Spatial_loss 3.57, Flat_loss 0.27, Train_acc 96.61, Test_acc 58.54
2025-02-13 18:10:21,857 [podnet.py] => Task 10, Epoch 48/160 (LR 0.07939) => LSC_loss 0.17, Spatial_loss 3.52, Flat_loss 0.26, Train_acc 96.99, Test_acc 57.63
2025-02-13 18:10:23,450 [podnet.py] => Task 10, Epoch 49/160 (LR 0.07859) => LSC_loss 0.18, Spatial_loss 3.57, Flat_loss 0.27, Train_acc 96.61, Test_acc 57.53
2025-02-13 18:10:25,027 [podnet.py] => Task 10, Epoch 50/160 (LR 0.07778) => LSC_loss 0.18, Spatial_loss 3.55, Flat_loss 0.26, Train_acc 96.86, Test_acc 56.01
2025-02-13 18:10:26,587 [podnet.py] => Task 10, Epoch 51/160 (LR 0.07696) => LSC_loss 0.18, Spatial_loss 3.55, Flat_loss 0.26, Train_acc 96.91, Test_acc 56.09
2025-02-13 18:10:28,136 [podnet.py] => Task 10, Epoch 52/160 (LR 0.07612) => LSC_loss 0.19, Spatial_loss 3.51, Flat_loss 0.26, Train_acc 96.31, Test_acc 57.03
2025-02-13 18:10:29,658 [podnet.py] => Task 10, Epoch 53/160 (LR 0.07528) => LSC_loss 0.18, Spatial_loss 3.39, Flat_loss 0.24, Train_acc 96.27, Test_acc 55.54
2025-02-13 18:10:31,208 [podnet.py] => Task 10, Epoch 54/160 (LR 0.07443) => LSC_loss 0.18, Spatial_loss 3.49, Flat_loss 0.26, Train_acc 96.78, Test_acc 57.26
2025-02-13 18:10:32,758 [podnet.py] => Task 10, Epoch 55/160 (LR 0.07357) => LSC_loss 0.18, Spatial_loss 3.56, Flat_loss 0.26, Train_acc 96.65, Test_acc 58.10
2025-02-13 18:10:34,315 [podnet.py] => Task 10, Epoch 56/160 (LR 0.07270) => LSC_loss 0.17, Spatial_loss 3.44, Flat_loss 0.25, Train_acc 97.12, Test_acc 57.31
2025-02-13 18:10:35,927 [podnet.py] => Task 10, Epoch 57/160 (LR 0.07182) => LSC_loss 0.19, Spatial_loss 3.42, Flat_loss 0.25, Train_acc 96.40, Test_acc 57.24
2025-02-13 18:10:37,517 [podnet.py] => Task 10, Epoch 58/160 (LR 0.07093) => LSC_loss 0.17, Spatial_loss 3.53, Flat_loss 0.24, Train_acc 97.16, Test_acc 57.87
2025-02-13 18:10:39,101 [podnet.py] => Task 10, Epoch 59/160 (LR 0.07004) => LSC_loss 0.16, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 97.08, Test_acc 57.07
2025-02-13 18:10:40,683 [podnet.py] => Task 10, Epoch 60/160 (LR 0.06913) => LSC_loss 0.17, Spatial_loss 3.30, Flat_loss 0.23, Train_acc 97.25, Test_acc 52.80
2025-02-13 18:10:42,271 [podnet.py] => Task 10, Epoch 61/160 (LR 0.06822) => LSC_loss 0.18, Spatial_loss 3.45, Flat_loss 0.25, Train_acc 96.74, Test_acc 59.37
2025-02-13 18:10:43,835 [podnet.py] => Task 10, Epoch 62/160 (LR 0.06731) => LSC_loss 0.18, Spatial_loss 3.32, Flat_loss 0.24, Train_acc 97.08, Test_acc 57.66
2025-02-13 18:10:45,403 [podnet.py] => Task 10, Epoch 63/160 (LR 0.06638) => LSC_loss 0.18, Spatial_loss 3.50, Flat_loss 0.25, Train_acc 96.74, Test_acc 59.31
2025-02-13 18:10:46,934 [podnet.py] => Task 10, Epoch 64/160 (LR 0.06545) => LSC_loss 0.17, Spatial_loss 3.46, Flat_loss 0.25, Train_acc 96.99, Test_acc 53.60
2025-02-13 18:10:48,510 [podnet.py] => Task 10, Epoch 65/160 (LR 0.06451) => LSC_loss 0.18, Spatial_loss 3.35, Flat_loss 0.24, Train_acc 96.53, Test_acc 53.59
2025-02-13 18:10:49,981 [podnet.py] => Task 10, Epoch 66/160 (LR 0.06357) => LSC_loss 0.17, Spatial_loss 3.42, Flat_loss 0.24, Train_acc 97.12, Test_acc 56.71
2025-02-13 18:10:51,572 [podnet.py] => Task 10, Epoch 67/160 (LR 0.06262) => LSC_loss 0.17, Spatial_loss 3.44, Flat_loss 0.24, Train_acc 96.86, Test_acc 56.54
2025-02-13 18:10:53,144 [podnet.py] => Task 10, Epoch 68/160 (LR 0.06167) => LSC_loss 0.18, Spatial_loss 3.29, Flat_loss 0.23, Train_acc 96.95, Test_acc 56.53
2025-02-13 18:10:54,692 [podnet.py] => Task 10, Epoch 69/160 (LR 0.06072) => LSC_loss 0.17, Spatial_loss 3.36, Flat_loss 0.23, Train_acc 97.20, Test_acc 56.24
2025-02-13 18:10:56,273 [podnet.py] => Task 10, Epoch 70/160 (LR 0.05975) => LSC_loss 0.16, Spatial_loss 3.14, Flat_loss 0.23, Train_acc 97.12, Test_acc 55.66
2025-02-13 18:10:57,857 [podnet.py] => Task 10, Epoch 71/160 (LR 0.05879) => LSC_loss 0.17, Spatial_loss 3.40, Flat_loss 0.24, Train_acc 97.16, Test_acc 58.44
2025-02-13 18:10:59,465 [podnet.py] => Task 10, Epoch 72/160 (LR 0.05782) => LSC_loss 0.18, Spatial_loss 3.18, Flat_loss 0.22, Train_acc 96.53, Test_acc 55.91
2025-02-13 18:11:01,049 [podnet.py] => Task 10, Epoch 73/160 (LR 0.05685) => LSC_loss 0.16, Spatial_loss 3.04, Flat_loss 0.22, Train_acc 97.37, Test_acc 59.13
2025-02-13 18:11:02,639 [podnet.py] => Task 10, Epoch 74/160 (LR 0.05588) => LSC_loss 0.16, Spatial_loss 3.06, Flat_loss 0.21, Train_acc 97.75, Test_acc 57.71
2025-02-13 18:11:04,228 [podnet.py] => Task 10, Epoch 75/160 (LR 0.05490) => LSC_loss 0.17, Spatial_loss 3.08, Flat_loss 0.21, Train_acc 96.78, Test_acc 57.40
2025-02-13 18:11:05,814 [podnet.py] => Task 10, Epoch 76/160 (LR 0.05392) => LSC_loss 0.17, Spatial_loss 3.12, Flat_loss 0.23, Train_acc 96.95, Test_acc 57.83
2025-02-13 18:11:07,426 [podnet.py] => Task 10, Epoch 77/160 (LR 0.05294) => LSC_loss 0.17, Spatial_loss 3.14, Flat_loss 0.21, Train_acc 96.95, Test_acc 57.44
2025-02-13 18:11:08,969 [podnet.py] => Task 10, Epoch 78/160 (LR 0.05196) => LSC_loss 0.17, Spatial_loss 3.11, Flat_loss 0.21, Train_acc 97.12, Test_acc 57.17
2025-02-13 18:11:10,504 [podnet.py] => Task 10, Epoch 79/160 (LR 0.05098) => LSC_loss 0.16, Spatial_loss 3.02, Flat_loss 0.20, Train_acc 97.16, Test_acc 53.87
2025-02-13 18:11:12,098 [podnet.py] => Task 10, Epoch 80/160 (LR 0.05000) => LSC_loss 0.17, Spatial_loss 3.15, Flat_loss 0.22, Train_acc 97.29, Test_acc 57.63
2025-02-13 18:11:13,651 [podnet.py] => Task 10, Epoch 81/160 (LR 0.04902) => LSC_loss 0.16, Spatial_loss 3.04, Flat_loss 0.21, Train_acc 97.03, Test_acc 57.17
2025-02-13 18:11:15,183 [podnet.py] => Task 10, Epoch 82/160 (LR 0.04804) => LSC_loss 0.17, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 96.65, Test_acc 58.53
2025-02-13 18:11:16,755 [podnet.py] => Task 10, Epoch 83/160 (LR 0.04706) => LSC_loss 0.17, Spatial_loss 3.04, Flat_loss 0.21, Train_acc 96.78, Test_acc 58.50
2025-02-13 18:11:18,343 [podnet.py] => Task 10, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 2.94, Flat_loss 0.20, Train_acc 97.25, Test_acc 57.36
2025-02-13 18:11:19,915 [podnet.py] => Task 10, Epoch 85/160 (LR 0.04510) => LSC_loss 0.16, Spatial_loss 2.98, Flat_loss 0.20, Train_acc 97.63, Test_acc 58.34
2025-02-13 18:11:21,438 [podnet.py] => Task 10, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 2.96, Flat_loss 0.20, Train_acc 97.29, Test_acc 61.26
2025-02-13 18:11:22,998 [podnet.py] => Task 10, Epoch 87/160 (LR 0.04315) => LSC_loss 0.16, Spatial_loss 2.87, Flat_loss 0.19, Train_acc 97.33, Test_acc 58.57
2025-02-13 18:11:24,662 [podnet.py] => Task 10, Epoch 88/160 (LR 0.04218) => LSC_loss 0.16, Spatial_loss 2.91, Flat_loss 0.19, Train_acc 97.33, Test_acc 54.47
2025-02-13 18:11:26,258 [podnet.py] => Task 10, Epoch 89/160 (LR 0.04121) => LSC_loss 0.16, Spatial_loss 2.94, Flat_loss 0.19, Train_acc 97.12, Test_acc 58.33
2025-02-13 18:11:27,835 [podnet.py] => Task 10, Epoch 90/160 (LR 0.04025) => LSC_loss 0.16, Spatial_loss 2.89, Flat_loss 0.19, Train_acc 97.12, Test_acc 58.80
2025-02-13 18:11:29,372 [podnet.py] => Task 10, Epoch 91/160 (LR 0.03928) => LSC_loss 0.17, Spatial_loss 2.87, Flat_loss 0.19, Train_acc 96.69, Test_acc 55.00
2025-02-13 18:11:30,932 [podnet.py] => Task 10, Epoch 92/160 (LR 0.03833) => LSC_loss 0.16, Spatial_loss 2.90, Flat_loss 0.20, Train_acc 97.46, Test_acc 59.67
2025-02-13 18:11:32,475 [podnet.py] => Task 10, Epoch 93/160 (LR 0.03738) => LSC_loss 0.17, Spatial_loss 2.75, Flat_loss 0.18, Train_acc 97.58, Test_acc 57.20
2025-02-13 18:11:33,997 [podnet.py] => Task 10, Epoch 94/160 (LR 0.03643) => LSC_loss 0.16, Spatial_loss 2.81, Flat_loss 0.19, Train_acc 97.37, Test_acc 60.30
2025-02-13 18:11:35,579 [podnet.py] => Task 10, Epoch 95/160 (LR 0.03549) => LSC_loss 0.16, Spatial_loss 2.74, Flat_loss 0.18, Train_acc 97.25, Test_acc 58.23
2025-02-13 18:11:37,117 [podnet.py] => Task 10, Epoch 96/160 (LR 0.03455) => LSC_loss 0.16, Spatial_loss 2.83, Flat_loss 0.19, Train_acc 97.63, Test_acc 58.70
2025-02-13 18:11:38,663 [podnet.py] => Task 10, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 2.71, Flat_loss 0.17, Train_acc 97.03, Test_acc 59.04
2025-02-13 18:11:40,247 [podnet.py] => Task 10, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 2.79, Flat_loss 0.18, Train_acc 97.42, Test_acc 58.26
2025-02-13 18:11:41,790 [podnet.py] => Task 10, Epoch 99/160 (LR 0.03178) => LSC_loss 0.16, Spatial_loss 2.67, Flat_loss 0.19, Train_acc 97.25, Test_acc 61.11
2025-02-13 18:11:43,349 [podnet.py] => Task 10, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 2.71, Flat_loss 0.18, Train_acc 97.54, Test_acc 58.13
2025-02-13 18:11:44,930 [podnet.py] => Task 10, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 97.29, Test_acc 59.31
2025-02-13 18:11:46,534 [podnet.py] => Task 10, Epoch 102/160 (LR 0.02907) => LSC_loss 0.16, Spatial_loss 2.59, Flat_loss 0.17, Train_acc 97.37, Test_acc 59.06
2025-02-13 18:11:48,121 [podnet.py] => Task 10, Epoch 103/160 (LR 0.02818) => LSC_loss 0.16, Spatial_loss 2.70, Flat_loss 0.17, Train_acc 97.33, Test_acc 58.87
2025-02-13 18:11:49,695 [podnet.py] => Task 10, Epoch 104/160 (LR 0.02730) => LSC_loss 0.16, Spatial_loss 2.58, Flat_loss 0.16, Train_acc 97.42, Test_acc 60.00
2025-02-13 18:11:51,290 [podnet.py] => Task 10, Epoch 105/160 (LR 0.02643) => LSC_loss 0.15, Spatial_loss 2.52, Flat_loss 0.16, Train_acc 97.54, Test_acc 59.93
2025-02-13 18:11:52,898 [podnet.py] => Task 10, Epoch 106/160 (LR 0.02557) => LSC_loss 0.16, Spatial_loss 2.47, Flat_loss 0.15, Train_acc 97.42, Test_acc 58.77
2025-02-13 18:11:54,469 [podnet.py] => Task 10, Epoch 107/160 (LR 0.02472) => LSC_loss 0.16, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 97.16, Test_acc 59.57
2025-02-13 18:11:56,040 [podnet.py] => Task 10, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 2.59, Flat_loss 0.16, Train_acc 97.12, Test_acc 59.07
2025-02-13 18:11:57,586 [podnet.py] => Task 10, Epoch 109/160 (LR 0.02304) => LSC_loss 0.15, Spatial_loss 2.44, Flat_loss 0.16, Train_acc 97.84, Test_acc 58.00
2025-02-13 18:11:59,160 [podnet.py] => Task 10, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 2.43, Flat_loss 0.15, Train_acc 97.63, Test_acc 58.26
2025-02-13 18:12:00,686 [podnet.py] => Task 10, Epoch 111/160 (LR 0.02141) => LSC_loss 0.16, Spatial_loss 2.38, Flat_loss 0.15, Train_acc 97.84, Test_acc 59.37
2025-02-13 18:12:02,307 [podnet.py] => Task 10, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 2.37, Flat_loss 0.15, Train_acc 97.03, Test_acc 60.21
2025-02-13 18:12:03,848 [podnet.py] => Task 10, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 2.37, Flat_loss 0.15, Train_acc 97.63, Test_acc 59.76
2025-02-13 18:12:05,435 [podnet.py] => Task 10, Epoch 114/160 (LR 0.01905) => LSC_loss 0.16, Spatial_loss 2.48, Flat_loss 0.15, Train_acc 97.46, Test_acc 59.21
2025-02-13 18:12:06,951 [podnet.py] => Task 10, Epoch 115/160 (LR 0.01828) => LSC_loss 0.15, Spatial_loss 2.29, Flat_loss 0.14, Train_acc 97.71, Test_acc 60.64
2025-02-13 18:12:08,522 [podnet.py] => Task 10, Epoch 116/160 (LR 0.01753) => LSC_loss 0.16, Spatial_loss 2.25, Flat_loss 0.14, Train_acc 97.63, Test_acc 58.91
2025-02-13 18:12:10,112 [podnet.py] => Task 10, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 2.22, Flat_loss 0.14, Train_acc 97.80, Test_acc 60.01
2025-02-13 18:12:11,675 [podnet.py] => Task 10, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 2.27, Flat_loss 0.14, Train_acc 97.16, Test_acc 59.76
2025-02-13 18:12:13,261 [podnet.py] => Task 10, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 2.29, Flat_loss 0.15, Train_acc 97.37, Test_acc 59.43
2025-02-13 18:12:14,804 [podnet.py] => Task 10, Epoch 120/160 (LR 0.01464) => LSC_loss 0.15, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 97.63, Test_acc 59.44
2025-02-13 18:12:16,350 [podnet.py] => Task 10, Epoch 121/160 (LR 0.01396) => LSC_loss 0.16, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 97.16, Test_acc 60.23
2025-02-13 18:12:17,886 [podnet.py] => Task 10, Epoch 122/160 (LR 0.01328) => LSC_loss 0.16, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 97.46, Test_acc 60.19
2025-02-13 18:12:19,506 [podnet.py] => Task 10, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 2.14, Flat_loss 0.14, Train_acc 97.54, Test_acc 59.47
2025-02-13 18:12:21,094 [podnet.py] => Task 10, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 2.15, Flat_loss 0.14, Train_acc 97.84, Test_acc 59.93
2025-02-13 18:12:22,714 [podnet.py] => Task 10, Epoch 125/160 (LR 0.01135) => LSC_loss 0.16, Spatial_loss 2.18, Flat_loss 0.13, Train_acc 97.50, Test_acc 59.36
2025-02-13 18:12:24,320 [podnet.py] => Task 10, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 2.13, Flat_loss 0.13, Train_acc 97.58, Test_acc 60.09
2025-02-13 18:12:25,887 [podnet.py] => Task 10, Epoch 127/160 (LR 0.01013) => LSC_loss 0.16, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 97.88, Test_acc 60.29
2025-02-13 18:12:27,416 [podnet.py] => Task 10, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 2.08, Flat_loss 0.13, Train_acc 97.25, Test_acc 60.16
2025-02-13 18:12:28,924 [podnet.py] => Task 10, Epoch 129/160 (LR 0.00898) => LSC_loss 0.16, Spatial_loss 2.25, Flat_loss 0.14, Train_acc 97.46, Test_acc 60.19
2025-02-13 18:12:30,471 [podnet.py] => Task 10, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 97.75, Test_acc 60.20
2025-02-13 18:12:32,026 [podnet.py] => Task 10, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 2.11, Flat_loss 0.13, Train_acc 97.25, Test_acc 59.99
2025-02-13 18:12:33,579 [podnet.py] => Task 10, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 2.08, Flat_loss 0.13, Train_acc 97.46, Test_acc 59.74
2025-02-13 18:12:35,161 [podnet.py] => Task 10, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 97.37, Test_acc 59.94
2025-02-13 18:12:36,756 [podnet.py] => Task 10, Epoch 134/160 (LR 0.00638) => LSC_loss 0.15, Spatial_loss 1.91, Flat_loss 0.12, Train_acc 97.54, Test_acc 59.93
2025-02-13 18:12:38,322 [podnet.py] => Task 10, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.92, Flat_loss 0.12, Train_acc 97.29, Test_acc 59.96
2025-02-13 18:12:39,931 [podnet.py] => Task 10, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 1.86, Flat_loss 0.12, Train_acc 97.20, Test_acc 60.29
2025-02-13 18:12:41,474 [podnet.py] => Task 10, Epoch 137/160 (LR 0.00501) => LSC_loss 0.15, Spatial_loss 1.90, Flat_loss 0.12, Train_acc 97.63, Test_acc 60.11
2025-02-13 18:12:42,957 [podnet.py] => Task 10, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 1.82, Flat_loss 0.11, Train_acc 97.88, Test_acc 60.71
2025-02-13 18:12:44,550 [podnet.py] => Task 10, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 1.86, Flat_loss 0.12, Train_acc 97.46, Test_acc 59.31
2025-02-13 18:12:46,070 [podnet.py] => Task 10, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 1.84, Flat_loss 0.12, Train_acc 97.54, Test_acc 60.00
2025-02-13 18:12:47,634 [podnet.py] => Task 10, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 1.89, Flat_loss 0.12, Train_acc 97.42, Test_acc 60.60
2025-02-13 18:12:49,179 [podnet.py] => Task 10, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 1.80, Flat_loss 0.12, Train_acc 97.50, Test_acc 59.74
2025-02-13 18:12:50,755 [podnet.py] => Task 10, Epoch 143/160 (LR 0.00276) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 97.29, Test_acc 60.44
2025-02-13 18:12:52,343 [podnet.py] => Task 10, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 1.83, Flat_loss 0.12, Train_acc 97.37, Test_acc 59.94
2025-02-13 18:12:53,926 [podnet.py] => Task 10, Epoch 145/160 (LR 0.00215) => LSC_loss 0.15, Spatial_loss 1.86, Flat_loss 0.11, Train_acc 97.92, Test_acc 60.57
2025-02-13 18:12:55,512 [podnet.py] => Task 10, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 97.29, Test_acc 60.59
2025-02-13 18:12:57,106 [podnet.py] => Task 10, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 97.54, Test_acc 60.49
2025-02-13 18:12:58,670 [podnet.py] => Task 10, Epoch 148/160 (LR 0.00138) => LSC_loss 0.16, Spatial_loss 1.83, Flat_loss 0.12, Train_acc 97.42, Test_acc 60.26
2025-02-13 18:13:00,249 [podnet.py] => Task 10, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 1.69, Flat_loss 0.11, Train_acc 97.20, Test_acc 60.43
2025-02-13 18:13:01,791 [podnet.py] => Task 10, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 97.58, Test_acc 60.64
2025-02-13 18:13:03,347 [podnet.py] => Task 10, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 97.50, Test_acc 60.26
2025-02-13 18:13:04,952 [podnet.py] => Task 10, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 1.83, Flat_loss 0.12, Train_acc 97.12, Test_acc 60.24
2025-02-13 18:13:06,538 [podnet.py] => Task 10, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 1.71, Flat_loss 0.11, Train_acc 96.74, Test_acc 60.76
2025-02-13 18:13:08,061 [podnet.py] => Task 10, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 1.78, Flat_loss 0.12, Train_acc 97.50, Test_acc 60.29
2025-02-13 18:13:09,611 [podnet.py] => Task 10, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 97.33, Test_acc 60.34
2025-02-13 18:13:11,162 [podnet.py] => Task 10, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 97.42, Test_acc 60.31
2025-02-13 18:13:12,713 [podnet.py] => Task 10, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 97.97, Test_acc 60.60
2025-02-13 18:13:14,239 [podnet.py] => Task 10, Epoch 158/160 (LR 0.00004) => LSC_loss 0.16, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 96.69, Test_acc 60.51
2025-02-13 18:13:15,745 [podnet.py] => Task 10, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 97.54, Test_acc 60.29
2025-02-13 18:13:17,270 [podnet.py] => Task 10, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 97.29, Test_acc 60.37
2025-02-13 18:13:17,271 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:13:17,271 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:13:39,650 [podnet.py] => The size of finetune dataset: 1400
2025-02-13 18:13:40,958 [podnet.py] => Task 10, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.62, Flat_loss 0.18, Train_acc 97.07, Test_acc 59.39
2025-02-13 18:13:42,294 [podnet.py] => Task 10, Epoch 2/20 (LR 0.00488) => LSC_loss 0.09, Spatial_loss 2.10, Flat_loss 0.10, Train_acc 99.43, Test_acc 59.41
2025-02-13 18:13:43,639 [podnet.py] => Task 10, Epoch 3/20 (LR 0.00473) => LSC_loss 0.09, Spatial_loss 1.88, Flat_loss 0.08, Train_acc 99.36, Test_acc 60.97
2025-02-13 18:13:44,982 [podnet.py] => Task 10, Epoch 4/20 (LR 0.00452) => LSC_loss 0.08, Spatial_loss 1.80, Flat_loss 0.07, Train_acc 99.14, Test_acc 60.93
2025-02-13 18:13:46,382 [podnet.py] => Task 10, Epoch 5/20 (LR 0.00427) => LSC_loss 0.08, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 99.29, Test_acc 61.06
2025-02-13 18:13:47,738 [podnet.py] => Task 10, Epoch 6/20 (LR 0.00397) => LSC_loss 0.08, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 99.43, Test_acc 60.94
2025-02-13 18:13:49,070 [podnet.py] => Task 10, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 98.79, Test_acc 60.97
2025-02-13 18:13:50,427 [podnet.py] => Task 10, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 1.71, Flat_loss 0.05, Train_acc 99.43, Test_acc 61.49
2025-02-13 18:13:51,792 [podnet.py] => Task 10, Epoch 9/20 (LR 0.00289) => LSC_loss 0.08, Spatial_loss 1.69, Flat_loss 0.06, Train_acc 99.64, Test_acc 61.07
2025-02-13 18:13:53,188 [podnet.py] => Task 10, Epoch 10/20 (LR 0.00250) => LSC_loss 0.08, Spatial_loss 1.70, Flat_loss 0.06, Train_acc 99.29, Test_acc 61.11
2025-02-13 18:13:54,529 [podnet.py] => Task 10, Epoch 11/20 (LR 0.00211) => LSC_loss 0.08, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.36, Test_acc 61.66
2025-02-13 18:13:55,901 [podnet.py] => Task 10, Epoch 12/20 (LR 0.00173) => LSC_loss 0.08, Spatial_loss 1.69, Flat_loss 0.06, Train_acc 99.50, Test_acc 61.00
2025-02-13 18:13:57,292 [podnet.py] => Task 10, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 1.60, Flat_loss 0.05, Train_acc 99.50, Test_acc 61.17
2025-02-13 18:13:58,694 [podnet.py] => Task 10, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.21, Test_acc 61.23
2025-02-13 18:14:00,040 [podnet.py] => Task 10, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.57, Flat_loss 0.05, Train_acc 99.07, Test_acc 61.43
2025-02-13 18:14:01,401 [podnet.py] => Task 10, Epoch 16/20 (LR 0.00048) => LSC_loss 0.08, Spatial_loss 1.53, Flat_loss 0.05, Train_acc 99.36, Test_acc 61.33
2025-02-13 18:14:02,738 [podnet.py] => Task 10, Epoch 17/20 (LR 0.00027) => LSC_loss 0.07, Spatial_loss 1.50, Flat_loss 0.05, Train_acc 99.57, Test_acc 61.20
2025-02-13 18:14:04,131 [podnet.py] => Task 10, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 1.59, Flat_loss 0.06, Train_acc 99.36, Test_acc 61.21
2025-02-13 18:14:05,497 [podnet.py] => Task 10, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 1.55, Flat_loss 0.05, Train_acc 99.43, Test_acc 61.11
2025-02-13 18:14:06,873 [podnet.py] => Task 10, Epoch 20/20 (LR 0.00000) => LSC_loss 0.08, Spatial_loss 1.62, Flat_loss 0.05, Train_acc 99.36, Test_acc 61.14
2025-02-13 18:14:06,876 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:14:30,440 [podnet.py] => Exemplar size: 1400
2025-02-13 18:14:30,441 [trainer.py] => CNN: {'total': 61.14, '00-09': 69.9, '10-19': 50.2, '20-29': 67.7, '30-39': 58.8, '40-49': 67.0, '50-59': 49.8, '60-69': 64.6, 'old': 60.76, 'new': 74.0}
2025-02-13 18:14:30,441 [trainer.py] => NME: {'total': 61.7, '00-09': 72.4, '10-19': 55.4, '20-29': 70.7, '30-39': 59.3, '40-49': 67.5, '50-59': 46.4, '60-69': 60.2, 'old': 61.63, 'new': 64.0}
2025-02-13 18:14:30,441 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14]
2025-02-13 18:14:30,441 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61]
2025-02-13 18:14:30,441 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7]
2025-02-13 18:14:30,441 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09]

2025-02-13 18:14:30,441 [trainer.py] => Average Accuracy (CNN): 68.40545454545453
2025-02-13 18:14:30,441 [trainer.py] => Average Accuracy (NME): 68.63181818181818
2025-02-13 18:14:30,441 [trainer.py] => All params: 511057
2025-02-13 18:14:30,442 [trainer.py] => Trainable params: 511057
2025-02-13 18:14:30,442 [podnet.py] => Learning on 70-72
2025-02-13 18:14:30,462 [podnet.py] => Adaptive factor: 6.0
2025-02-13 18:14:32,068 [podnet.py] => Task 11, Epoch 1/160 (LR 0.09999) => LSC_loss 1.26, Spatial_loss 3.97, Flat_loss 0.51, Train_acc 79.38, Test_acc 50.33
2025-02-13 18:14:33,697 [podnet.py] => Task 11, Epoch 2/160 (LR 0.09996) => LSC_loss 0.42, Spatial_loss 4.74, Flat_loss 0.49, Train_acc 89.25, Test_acc 48.67
2025-02-13 18:14:35,261 [podnet.py] => Task 11, Epoch 3/160 (LR 0.09991) => LSC_loss 0.38, Spatial_loss 4.77, Flat_loss 0.48, Train_acc 91.00, Test_acc 49.86
2025-02-13 18:14:36,870 [podnet.py] => Task 11, Epoch 4/160 (LR 0.09985) => LSC_loss 0.32, Spatial_loss 4.41, Flat_loss 0.42, Train_acc 93.25, Test_acc 55.32
2025-02-13 18:14:38,494 [podnet.py] => Task 11, Epoch 5/160 (LR 0.09976) => LSC_loss 0.33, Spatial_loss 4.23, Flat_loss 0.39, Train_acc 92.42, Test_acc 53.92
2025-02-13 18:14:40,122 [podnet.py] => Task 11, Epoch 6/160 (LR 0.09965) => LSC_loss 0.30, Spatial_loss 4.35, Flat_loss 0.40, Train_acc 93.54, Test_acc 56.58
2025-02-13 18:14:41,733 [podnet.py] => Task 11, Epoch 7/160 (LR 0.09953) => LSC_loss 0.30, Spatial_loss 4.38, Flat_loss 0.38, Train_acc 93.46, Test_acc 54.65
2025-02-13 18:14:43,338 [podnet.py] => Task 11, Epoch 8/160 (LR 0.09938) => LSC_loss 0.28, Spatial_loss 4.24, Flat_loss 0.36, Train_acc 94.38, Test_acc 53.43
2025-02-13 18:14:44,931 [podnet.py] => Task 11, Epoch 9/160 (LR 0.09922) => LSC_loss 0.28, Spatial_loss 4.02, Flat_loss 0.34, Train_acc 93.92, Test_acc 51.43
2025-02-13 18:14:46,497 [podnet.py] => Task 11, Epoch 10/160 (LR 0.09904) => LSC_loss 0.29, Spatial_loss 4.02, Flat_loss 0.35, Train_acc 94.38, Test_acc 50.54
2025-02-13 18:14:48,127 [podnet.py] => Task 11, Epoch 11/160 (LR 0.09884) => LSC_loss 0.29, Spatial_loss 4.21, Flat_loss 0.36, Train_acc 93.12, Test_acc 47.81
2025-02-13 18:14:49,732 [podnet.py] => Task 11, Epoch 12/160 (LR 0.09862) => LSC_loss 0.29, Spatial_loss 4.23, Flat_loss 0.36, Train_acc 93.62, Test_acc 49.81
2025-02-13 18:14:51,364 [podnet.py] => Task 11, Epoch 13/160 (LR 0.09838) => LSC_loss 0.27, Spatial_loss 4.18, Flat_loss 0.34, Train_acc 94.17, Test_acc 50.50
2025-02-13 18:14:52,962 [podnet.py] => Task 11, Epoch 14/160 (LR 0.09812) => LSC_loss 0.27, Spatial_loss 4.17, Flat_loss 0.35, Train_acc 94.67, Test_acc 53.36
2025-02-13 18:14:54,591 [podnet.py] => Task 11, Epoch 15/160 (LR 0.09785) => LSC_loss 0.26, Spatial_loss 4.03, Flat_loss 0.33, Train_acc 94.50, Test_acc 55.94
2025-02-13 18:14:56,191 [podnet.py] => Task 11, Epoch 16/160 (LR 0.09755) => LSC_loss 0.25, Spatial_loss 3.94, Flat_loss 0.32, Train_acc 94.88, Test_acc 52.69
2025-02-13 18:14:57,790 [podnet.py] => Task 11, Epoch 17/160 (LR 0.09724) => LSC_loss 0.25, Spatial_loss 4.04, Flat_loss 0.32, Train_acc 95.17, Test_acc 52.31
2025-02-13 18:14:59,395 [podnet.py] => Task 11, Epoch 18/160 (LR 0.09691) => LSC_loss 0.25, Spatial_loss 4.04, Flat_loss 0.32, Train_acc 94.88, Test_acc 55.15
2025-02-13 18:15:01,027 [podnet.py] => Task 11, Epoch 19/160 (LR 0.09656) => LSC_loss 0.25, Spatial_loss 3.99, Flat_loss 0.33, Train_acc 94.71, Test_acc 52.10
2025-02-13 18:15:02,581 [podnet.py] => Task 11, Epoch 20/160 (LR 0.09619) => LSC_loss 0.25, Spatial_loss 4.16, Flat_loss 0.34, Train_acc 95.21, Test_acc 52.12
2025-02-13 18:15:04,215 [podnet.py] => Task 11, Epoch 21/160 (LR 0.09581) => LSC_loss 0.25, Spatial_loss 4.04, Flat_loss 0.32, Train_acc 94.88, Test_acc 53.94
2025-02-13 18:15:05,891 [podnet.py] => Task 11, Epoch 22/160 (LR 0.09541) => LSC_loss 0.26, Spatial_loss 4.03, Flat_loss 0.32, Train_acc 94.88, Test_acc 53.31
2025-02-13 18:15:07,538 [podnet.py] => Task 11, Epoch 23/160 (LR 0.09499) => LSC_loss 0.26, Spatial_loss 3.87, Flat_loss 0.31, Train_acc 94.46, Test_acc 50.90
2025-02-13 18:15:09,173 [podnet.py] => Task 11, Epoch 24/160 (LR 0.09455) => LSC_loss 0.24, Spatial_loss 4.09, Flat_loss 0.33, Train_acc 95.38, Test_acc 52.44
2025-02-13 18:15:10,770 [podnet.py] => Task 11, Epoch 25/160 (LR 0.09410) => LSC_loss 0.26, Spatial_loss 4.20, Flat_loss 0.34, Train_acc 94.88, Test_acc 50.36
2025-02-13 18:15:12,388 [podnet.py] => Task 11, Epoch 26/160 (LR 0.09362) => LSC_loss 0.25, Spatial_loss 4.08, Flat_loss 0.32, Train_acc 95.08, Test_acc 50.56
2025-02-13 18:15:14,019 [podnet.py] => Task 11, Epoch 27/160 (LR 0.09314) => LSC_loss 0.23, Spatial_loss 4.06, Flat_loss 0.32, Train_acc 95.00, Test_acc 55.17
2025-02-13 18:15:15,634 [podnet.py] => Task 11, Epoch 28/160 (LR 0.09263) => LSC_loss 0.23, Spatial_loss 3.86, Flat_loss 0.30, Train_acc 95.25, Test_acc 53.07
2025-02-13 18:15:17,193 [podnet.py] => Task 11, Epoch 29/160 (LR 0.09211) => LSC_loss 0.24, Spatial_loss 3.85, Flat_loss 0.30, Train_acc 94.96, Test_acc 55.50
2025-02-13 18:15:18,839 [podnet.py] => Task 11, Epoch 30/160 (LR 0.09157) => LSC_loss 0.23, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 95.58, Test_acc 56.46
2025-02-13 18:15:20,476 [podnet.py] => Task 11, Epoch 31/160 (LR 0.09102) => LSC_loss 0.24, Spatial_loss 3.92, Flat_loss 0.31, Train_acc 95.12, Test_acc 53.01
2025-02-13 18:15:22,060 [podnet.py] => Task 11, Epoch 32/160 (LR 0.09045) => LSC_loss 0.24, Spatial_loss 3.95, Flat_loss 0.31, Train_acc 95.17, Test_acc 55.00
2025-02-13 18:15:23,698 [podnet.py] => Task 11, Epoch 33/160 (LR 0.08987) => LSC_loss 0.22, Spatial_loss 3.73, Flat_loss 0.29, Train_acc 95.75, Test_acc 56.72
2025-02-13 18:15:25,284 [podnet.py] => Task 11, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 3.62, Flat_loss 0.28, Train_acc 95.88, Test_acc 51.64
2025-02-13 18:15:26,871 [podnet.py] => Task 11, Epoch 35/160 (LR 0.08865) => LSC_loss 0.23, Spatial_loss 3.83, Flat_loss 0.30, Train_acc 95.42, Test_acc 51.00
2025-02-13 18:15:28,554 [podnet.py] => Task 11, Epoch 36/160 (LR 0.08802) => LSC_loss 0.23, Spatial_loss 3.81, Flat_loss 0.31, Train_acc 95.00, Test_acc 53.67
2025-02-13 18:15:30,166 [podnet.py] => Task 11, Epoch 37/160 (LR 0.08738) => LSC_loss 0.22, Spatial_loss 3.75, Flat_loss 0.29, Train_acc 95.50, Test_acc 53.92
2025-02-13 18:15:31,784 [podnet.py] => Task 11, Epoch 38/160 (LR 0.08672) => LSC_loss 0.22, Spatial_loss 3.76, Flat_loss 0.28, Train_acc 95.75, Test_acc 54.14
2025-02-13 18:15:33,411 [podnet.py] => Task 11, Epoch 39/160 (LR 0.08604) => LSC_loss 0.23, Spatial_loss 3.63, Flat_loss 0.28, Train_acc 95.17, Test_acc 53.35
2025-02-13 18:15:35,055 [podnet.py] => Task 11, Epoch 40/160 (LR 0.08536) => LSC_loss 0.22, Spatial_loss 3.73, Flat_loss 0.29, Train_acc 95.33, Test_acc 56.03
2025-02-13 18:15:36,671 [podnet.py] => Task 11, Epoch 41/160 (LR 0.08465) => LSC_loss 0.22, Spatial_loss 3.72, Flat_loss 0.28, Train_acc 95.96, Test_acc 53.25
2025-02-13 18:15:38,266 [podnet.py] => Task 11, Epoch 42/160 (LR 0.08394) => LSC_loss 0.24, Spatial_loss 3.75, Flat_loss 0.29, Train_acc 95.17, Test_acc 53.18
2025-02-13 18:15:39,856 [podnet.py] => Task 11, Epoch 43/160 (LR 0.08321) => LSC_loss 0.21, Spatial_loss 3.61, Flat_loss 0.27, Train_acc 95.71, Test_acc 54.56
2025-02-13 18:15:41,412 [podnet.py] => Task 11, Epoch 44/160 (LR 0.08247) => LSC_loss 0.23, Spatial_loss 3.68, Flat_loss 0.28, Train_acc 95.46, Test_acc 55.10
2025-02-13 18:15:42,986 [podnet.py] => Task 11, Epoch 45/160 (LR 0.08172) => LSC_loss 0.23, Spatial_loss 3.69, Flat_loss 0.29, Train_acc 95.62, Test_acc 57.22
2025-02-13 18:15:44,595 [podnet.py] => Task 11, Epoch 46/160 (LR 0.08095) => LSC_loss 0.24, Spatial_loss 3.74, Flat_loss 0.28, Train_acc 95.42, Test_acc 54.11
2025-02-13 18:15:46,271 [podnet.py] => Task 11, Epoch 47/160 (LR 0.08018) => LSC_loss 0.21, Spatial_loss 3.73, Flat_loss 0.28, Train_acc 96.38, Test_acc 58.53
2025-02-13 18:15:47,910 [podnet.py] => Task 11, Epoch 48/160 (LR 0.07939) => LSC_loss 0.20, Spatial_loss 3.48, Flat_loss 0.26, Train_acc 96.50, Test_acc 55.76
2025-02-13 18:15:49,501 [podnet.py] => Task 11, Epoch 49/160 (LR 0.07859) => LSC_loss 0.22, Spatial_loss 3.62, Flat_loss 0.26, Train_acc 95.75, Test_acc 54.76
2025-02-13 18:15:51,158 [podnet.py] => Task 11, Epoch 50/160 (LR 0.07778) => LSC_loss 0.21, Spatial_loss 3.61, Flat_loss 0.26, Train_acc 96.00, Test_acc 53.75
2025-02-13 18:15:52,699 [podnet.py] => Task 11, Epoch 51/160 (LR 0.07696) => LSC_loss 0.22, Spatial_loss 3.51, Flat_loss 0.26, Train_acc 96.29, Test_acc 55.71
2025-02-13 18:15:54,309 [podnet.py] => Task 11, Epoch 52/160 (LR 0.07612) => LSC_loss 0.21, Spatial_loss 3.57, Flat_loss 0.26, Train_acc 96.08, Test_acc 57.07
2025-02-13 18:15:55,869 [podnet.py] => Task 11, Epoch 53/160 (LR 0.07528) => LSC_loss 0.21, Spatial_loss 3.46, Flat_loss 0.26, Train_acc 96.04, Test_acc 52.94
2025-02-13 18:15:57,472 [podnet.py] => Task 11, Epoch 54/160 (LR 0.07443) => LSC_loss 0.20, Spatial_loss 3.46, Flat_loss 0.25, Train_acc 96.04, Test_acc 55.71
2025-02-13 18:15:59,069 [podnet.py] => Task 11, Epoch 55/160 (LR 0.07357) => LSC_loss 0.19, Spatial_loss 3.39, Flat_loss 0.24, Train_acc 96.92, Test_acc 54.00
2025-02-13 18:16:00,664 [podnet.py] => Task 11, Epoch 56/160 (LR 0.07270) => LSC_loss 0.23, Spatial_loss 3.54, Flat_loss 0.25, Train_acc 95.67, Test_acc 55.71
2025-02-13 18:16:02,319 [podnet.py] => Task 11, Epoch 57/160 (LR 0.07182) => LSC_loss 0.21, Spatial_loss 3.39, Flat_loss 0.25, Train_acc 95.88, Test_acc 57.96
2025-02-13 18:16:03,912 [podnet.py] => Task 11, Epoch 58/160 (LR 0.07093) => LSC_loss 0.21, Spatial_loss 3.34, Flat_loss 0.24, Train_acc 95.83, Test_acc 51.32
2025-02-13 18:16:05,500 [podnet.py] => Task 11, Epoch 59/160 (LR 0.07004) => LSC_loss 0.21, Spatial_loss 3.37, Flat_loss 0.25, Train_acc 95.67, Test_acc 55.92
2025-02-13 18:16:07,170 [podnet.py] => Task 11, Epoch 60/160 (LR 0.06913) => LSC_loss 0.21, Spatial_loss 3.37, Flat_loss 0.25, Train_acc 96.12, Test_acc 52.57
2025-02-13 18:16:08,744 [podnet.py] => Task 11, Epoch 61/160 (LR 0.06822) => LSC_loss 0.22, Spatial_loss 3.51, Flat_loss 0.26, Train_acc 95.71, Test_acc 55.96
2025-02-13 18:16:10,374 [podnet.py] => Task 11, Epoch 62/160 (LR 0.06731) => LSC_loss 0.21, Spatial_loss 3.33, Flat_loss 0.24, Train_acc 95.46, Test_acc 56.67
2025-02-13 18:16:11,958 [podnet.py] => Task 11, Epoch 63/160 (LR 0.06638) => LSC_loss 0.21, Spatial_loss 3.42, Flat_loss 0.24, Train_acc 95.75, Test_acc 55.76
2025-02-13 18:16:13,618 [podnet.py] => Task 11, Epoch 64/160 (LR 0.06545) => LSC_loss 0.21, Spatial_loss 3.19, Flat_loss 0.23, Train_acc 95.96, Test_acc 56.03
2025-02-13 18:16:15,232 [podnet.py] => Task 11, Epoch 65/160 (LR 0.06451) => LSC_loss 0.19, Spatial_loss 3.34, Flat_loss 0.24, Train_acc 96.54, Test_acc 53.78
2025-02-13 18:16:16,868 [podnet.py] => Task 11, Epoch 66/160 (LR 0.06357) => LSC_loss 0.21, Spatial_loss 3.39, Flat_loss 0.23, Train_acc 96.42, Test_acc 56.43
2025-02-13 18:16:18,457 [podnet.py] => Task 11, Epoch 67/160 (LR 0.06262) => LSC_loss 0.19, Spatial_loss 3.25, Flat_loss 0.24, Train_acc 96.50, Test_acc 57.53
2025-02-13 18:16:20,056 [podnet.py] => Task 11, Epoch 68/160 (LR 0.06167) => LSC_loss 0.21, Spatial_loss 3.14, Flat_loss 0.22, Train_acc 95.62, Test_acc 56.85
2025-02-13 18:16:21,634 [podnet.py] => Task 11, Epoch 69/160 (LR 0.06072) => LSC_loss 0.20, Spatial_loss 3.18, Flat_loss 0.22, Train_acc 96.50, Test_acc 54.57
2025-02-13 18:16:23,224 [podnet.py] => Task 11, Epoch 70/160 (LR 0.05975) => LSC_loss 0.21, Spatial_loss 3.23, Flat_loss 0.22, Train_acc 95.54, Test_acc 54.10
2025-02-13 18:16:24,821 [podnet.py] => Task 11, Epoch 71/160 (LR 0.05879) => LSC_loss 0.21, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 95.96, Test_acc 52.83
2025-02-13 18:16:26,375 [podnet.py] => Task 11, Epoch 72/160 (LR 0.05782) => LSC_loss 0.21, Spatial_loss 3.15, Flat_loss 0.22, Train_acc 96.12, Test_acc 58.76
2025-02-13 18:16:27,984 [podnet.py] => Task 11, Epoch 73/160 (LR 0.05685) => LSC_loss 0.20, Spatial_loss 3.06, Flat_loss 0.22, Train_acc 96.12, Test_acc 55.75
2025-02-13 18:16:29,595 [podnet.py] => Task 11, Epoch 74/160 (LR 0.05588) => LSC_loss 0.21, Spatial_loss 3.13, Flat_loss 0.22, Train_acc 96.00, Test_acc 57.12
2025-02-13 18:16:31,254 [podnet.py] => Task 11, Epoch 75/160 (LR 0.05490) => LSC_loss 0.20, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 96.54, Test_acc 54.32
2025-02-13 18:16:32,840 [podnet.py] => Task 11, Epoch 76/160 (LR 0.05392) => LSC_loss 0.19, Spatial_loss 2.96, Flat_loss 0.20, Train_acc 96.88, Test_acc 56.38
2025-02-13 18:16:34,481 [podnet.py] => Task 11, Epoch 77/160 (LR 0.05294) => LSC_loss 0.20, Spatial_loss 3.09, Flat_loss 0.21, Train_acc 96.21, Test_acc 56.56
2025-02-13 18:16:36,106 [podnet.py] => Task 11, Epoch 78/160 (LR 0.05196) => LSC_loss 0.20, Spatial_loss 3.02, Flat_loss 0.20, Train_acc 96.08, Test_acc 57.04
2025-02-13 18:16:37,718 [podnet.py] => Task 11, Epoch 79/160 (LR 0.05098) => LSC_loss 0.20, Spatial_loss 3.01, Flat_loss 0.20, Train_acc 96.50, Test_acc 53.47
2025-02-13 18:16:39,382 [podnet.py] => Task 11, Epoch 80/160 (LR 0.05000) => LSC_loss 0.20, Spatial_loss 3.04, Flat_loss 0.20, Train_acc 96.46, Test_acc 56.00
2025-02-13 18:16:41,019 [podnet.py] => Task 11, Epoch 81/160 (LR 0.04902) => LSC_loss 0.20, Spatial_loss 3.00, Flat_loss 0.20, Train_acc 96.33, Test_acc 56.74
2025-02-13 18:16:42,667 [podnet.py] => Task 11, Epoch 82/160 (LR 0.04804) => LSC_loss 0.20, Spatial_loss 2.96, Flat_loss 0.20, Train_acc 96.46, Test_acc 54.97
2025-02-13 18:16:44,309 [podnet.py] => Task 11, Epoch 83/160 (LR 0.04706) => LSC_loss 0.20, Spatial_loss 3.04, Flat_loss 0.21, Train_acc 96.62, Test_acc 55.97
2025-02-13 18:16:45,980 [podnet.py] => Task 11, Epoch 84/160 (LR 0.04608) => LSC_loss 0.19, Spatial_loss 2.88, Flat_loss 0.19, Train_acc 96.54, Test_acc 53.33
2025-02-13 18:16:47,575 [podnet.py] => Task 11, Epoch 85/160 (LR 0.04510) => LSC_loss 0.20, Spatial_loss 2.84, Flat_loss 0.19, Train_acc 96.50, Test_acc 56.14
2025-02-13 18:16:49,103 [podnet.py] => Task 11, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 2.88, Flat_loss 0.19, Train_acc 96.46, Test_acc 57.25
2025-02-13 18:16:50,674 [podnet.py] => Task 11, Epoch 87/160 (LR 0.04315) => LSC_loss 0.20, Spatial_loss 2.78, Flat_loss 0.19, Train_acc 96.00, Test_acc 54.89
2025-02-13 18:16:52,260 [podnet.py] => Task 11, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 2.87, Flat_loss 0.19, Train_acc 96.17, Test_acc 56.61
2025-02-13 18:16:53,909 [podnet.py] => Task 11, Epoch 89/160 (LR 0.04121) => LSC_loss 0.20, Spatial_loss 2.90, Flat_loss 0.19, Train_acc 96.79, Test_acc 56.47
2025-02-13 18:16:55,526 [podnet.py] => Task 11, Epoch 90/160 (LR 0.04025) => LSC_loss 0.20, Spatial_loss 2.80, Flat_loss 0.18, Train_acc 96.54, Test_acc 57.49
2025-02-13 18:16:57,110 [podnet.py] => Task 11, Epoch 91/160 (LR 0.03928) => LSC_loss 0.20, Spatial_loss 2.75, Flat_loss 0.18, Train_acc 96.33, Test_acc 56.04
2025-02-13 18:16:58,739 [podnet.py] => Task 11, Epoch 92/160 (LR 0.03833) => LSC_loss 0.21, Spatial_loss 2.84, Flat_loss 0.19, Train_acc 95.92, Test_acc 57.89
2025-02-13 18:17:00,373 [podnet.py] => Task 11, Epoch 93/160 (LR 0.03738) => LSC_loss 0.20, Spatial_loss 2.77, Flat_loss 0.18, Train_acc 96.46, Test_acc 56.43
2025-02-13 18:17:02,084 [podnet.py] => Task 11, Epoch 94/160 (LR 0.03643) => LSC_loss 0.20, Spatial_loss 2.72, Flat_loss 0.18, Train_acc 96.17, Test_acc 57.25
2025-02-13 18:17:03,691 [podnet.py] => Task 11, Epoch 95/160 (LR 0.03549) => LSC_loss 0.19, Spatial_loss 2.56, Flat_loss 0.17, Train_acc 96.46, Test_acc 56.75
2025-02-13 18:17:05,302 [podnet.py] => Task 11, Epoch 96/160 (LR 0.03455) => LSC_loss 0.20, Spatial_loss 2.53, Flat_loss 0.16, Train_acc 96.21, Test_acc 57.64
2025-02-13 18:17:06,946 [podnet.py] => Task 11, Epoch 97/160 (LR 0.03362) => LSC_loss 0.20, Spatial_loss 2.57, Flat_loss 0.16, Train_acc 96.62, Test_acc 59.31
2025-02-13 18:17:08,515 [podnet.py] => Task 11, Epoch 98/160 (LR 0.03269) => LSC_loss 0.19, Spatial_loss 2.51, Flat_loss 0.16, Train_acc 96.67, Test_acc 56.49
2025-02-13 18:17:10,099 [podnet.py] => Task 11, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 2.71, Flat_loss 0.17, Train_acc 96.08, Test_acc 57.10
2025-02-13 18:17:11,718 [podnet.py] => Task 11, Epoch 100/160 (LR 0.03087) => LSC_loss 0.19, Spatial_loss 2.52, Flat_loss 0.16, Train_acc 96.88, Test_acc 56.83
2025-02-13 18:17:13,355 [podnet.py] => Task 11, Epoch 101/160 (LR 0.02996) => LSC_loss 0.21, Spatial_loss 2.56, Flat_loss 0.16, Train_acc 95.88, Test_acc 57.89
2025-02-13 18:17:14,956 [podnet.py] => Task 11, Epoch 102/160 (LR 0.02907) => LSC_loss 0.19, Spatial_loss 2.46, Flat_loss 0.16, Train_acc 97.08, Test_acc 56.82
2025-02-13 18:17:16,563 [podnet.py] => Task 11, Epoch 103/160 (LR 0.02818) => LSC_loss 0.19, Spatial_loss 2.42, Flat_loss 0.16, Train_acc 96.88, Test_acc 58.78
2025-02-13 18:17:18,194 [podnet.py] => Task 11, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 2.44, Flat_loss 0.15, Train_acc 96.29, Test_acc 58.79
2025-02-13 18:17:19,842 [podnet.py] => Task 11, Epoch 105/160 (LR 0.02643) => LSC_loss 0.20, Spatial_loss 2.53, Flat_loss 0.16, Train_acc 96.50, Test_acc 58.56
2025-02-13 18:17:21,472 [podnet.py] => Task 11, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 2.54, Flat_loss 0.16, Train_acc 96.12, Test_acc 57.49
2025-02-13 18:17:23,053 [podnet.py] => Task 11, Epoch 107/160 (LR 0.02472) => LSC_loss 0.20, Spatial_loss 2.48, Flat_loss 0.16, Train_acc 96.17, Test_acc 58.53
2025-02-13 18:17:24,708 [podnet.py] => Task 11, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 2.41, Flat_loss 0.15, Train_acc 95.83, Test_acc 58.64
2025-02-13 18:17:26,286 [podnet.py] => Task 11, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 2.29, Flat_loss 0.15, Train_acc 96.71, Test_acc 57.85
2025-02-13 18:17:27,886 [podnet.py] => Task 11, Epoch 110/160 (LR 0.02222) => LSC_loss 0.20, Spatial_loss 2.50, Flat_loss 0.16, Train_acc 96.50, Test_acc 58.97
2025-02-13 18:17:29,539 [podnet.py] => Task 11, Epoch 111/160 (LR 0.02141) => LSC_loss 0.20, Spatial_loss 2.34, Flat_loss 0.15, Train_acc 96.38, Test_acc 58.28
2025-02-13 18:17:31,110 [podnet.py] => Task 11, Epoch 112/160 (LR 0.02061) => LSC_loss 0.18, Spatial_loss 2.32, Flat_loss 0.15, Train_acc 96.71, Test_acc 57.31
2025-02-13 18:17:32,691 [podnet.py] => Task 11, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 2.22, Flat_loss 0.14, Train_acc 96.33, Test_acc 58.79
2025-02-13 18:17:34,274 [podnet.py] => Task 11, Epoch 114/160 (LR 0.01905) => LSC_loss 0.19, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 96.50, Test_acc 58.47
2025-02-13 18:17:35,877 [podnet.py] => Task 11, Epoch 115/160 (LR 0.01828) => LSC_loss 0.20, Spatial_loss 2.27, Flat_loss 0.14, Train_acc 96.04, Test_acc 57.49
2025-02-13 18:17:37,471 [podnet.py] => Task 11, Epoch 116/160 (LR 0.01753) => LSC_loss 0.20, Spatial_loss 2.33, Flat_loss 0.15, Train_acc 96.38, Test_acc 58.46
2025-02-13 18:17:39,114 [podnet.py] => Task 11, Epoch 117/160 (LR 0.01679) => LSC_loss 0.19, Spatial_loss 2.23, Flat_loss 0.14, Train_acc 96.75, Test_acc 58.29
2025-02-13 18:17:40,720 [podnet.py] => Task 11, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 2.29, Flat_loss 0.14, Train_acc 96.38, Test_acc 59.35
2025-02-13 18:17:42,308 [podnet.py] => Task 11, Epoch 119/160 (LR 0.01535) => LSC_loss 0.19, Spatial_loss 2.14, Flat_loss 0.13, Train_acc 97.12, Test_acc 59.00
2025-02-13 18:17:43,885 [podnet.py] => Task 11, Epoch 120/160 (LR 0.01464) => LSC_loss 0.20, Spatial_loss 2.24, Flat_loss 0.14, Train_acc 96.04, Test_acc 57.65
2025-02-13 18:17:45,406 [podnet.py] => Task 11, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 2.16, Flat_loss 0.14, Train_acc 96.42, Test_acc 57.85
2025-02-13 18:17:46,949 [podnet.py] => Task 11, Epoch 122/160 (LR 0.01328) => LSC_loss 0.20, Spatial_loss 2.17, Flat_loss 0.13, Train_acc 96.21, Test_acc 59.10
2025-02-13 18:17:48,512 [podnet.py] => Task 11, Epoch 123/160 (LR 0.01262) => LSC_loss 0.19, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 96.08, Test_acc 58.81
2025-02-13 18:17:50,108 [podnet.py] => Task 11, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 1.99, Flat_loss 0.12, Train_acc 96.58, Test_acc 56.78
2025-02-13 18:17:51,675 [podnet.py] => Task 11, Epoch 125/160 (LR 0.01135) => LSC_loss 0.20, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 96.33, Test_acc 58.39
2025-02-13 18:17:53,283 [podnet.py] => Task 11, Epoch 126/160 (LR 0.01073) => LSC_loss 0.20, Spatial_loss 1.97, Flat_loss 0.12, Train_acc 96.25, Test_acc 58.15
2025-02-13 18:17:54,870 [podnet.py] => Task 11, Epoch 127/160 (LR 0.01013) => LSC_loss 0.19, Spatial_loss 1.92, Flat_loss 0.12, Train_acc 96.71, Test_acc 58.69
2025-02-13 18:17:56,483 [podnet.py] => Task 11, Epoch 128/160 (LR 0.00955) => LSC_loss 0.20, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 96.58, Test_acc 58.51
2025-02-13 18:17:58,081 [podnet.py] => Task 11, Epoch 129/160 (LR 0.00898) => LSC_loss 0.19, Spatial_loss 1.96, Flat_loss 0.13, Train_acc 96.71, Test_acc 58.11
2025-02-13 18:17:59,616 [podnet.py] => Task 11, Epoch 130/160 (LR 0.00843) => LSC_loss 0.20, Spatial_loss 2.02, Flat_loss 0.12, Train_acc 96.29, Test_acc 58.22
2025-02-13 18:18:01,238 [podnet.py] => Task 11, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 96.17, Test_acc 56.64
2025-02-13 18:18:02,792 [podnet.py] => Task 11, Epoch 132/160 (LR 0.00737) => LSC_loss 0.20, Spatial_loss 2.02, Flat_loss 0.12, Train_acc 96.29, Test_acc 59.56
2025-02-13 18:18:04,404 [podnet.py] => Task 11, Epoch 133/160 (LR 0.00686) => LSC_loss 0.19, Spatial_loss 1.95, Flat_loss 0.12, Train_acc 96.54, Test_acc 59.19
2025-02-13 18:18:06,016 [podnet.py] => Task 11, Epoch 134/160 (LR 0.00638) => LSC_loss 0.18, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 97.12, Test_acc 59.72
2025-02-13 18:18:07,668 [podnet.py] => Task 11, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 96.04, Test_acc 60.18
2025-02-13 18:18:09,306 [podnet.py] => Task 11, Epoch 136/160 (LR 0.00545) => LSC_loss 0.19, Spatial_loss 1.88, Flat_loss 0.12, Train_acc 96.33, Test_acc 59.25
2025-02-13 18:18:10,832 [podnet.py] => Task 11, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 96.33, Test_acc 59.10
2025-02-13 18:18:12,410 [podnet.py] => Task 11, Epoch 138/160 (LR 0.00459) => LSC_loss 0.19, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 96.42, Test_acc 58.99
2025-02-13 18:18:13,973 [podnet.py] => Task 11, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.97, Flat_loss 0.12, Train_acc 96.08, Test_acc 59.89
2025-02-13 18:18:15,531 [podnet.py] => Task 11, Epoch 140/160 (LR 0.00381) => LSC_loss 0.19, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 96.50, Test_acc 59.31
2025-02-13 18:18:17,089 [podnet.py] => Task 11, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 96.12, Test_acc 59.40
2025-02-13 18:18:18,668 [podnet.py] => Task 11, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.81, Flat_loss 0.11, Train_acc 96.33, Test_acc 59.26
2025-02-13 18:18:20,252 [podnet.py] => Task 11, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 96.29, Test_acc 59.12
2025-02-13 18:18:21,885 [podnet.py] => Task 11, Epoch 144/160 (LR 0.00245) => LSC_loss 0.20, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 96.04, Test_acc 58.69
2025-02-13 18:18:23,451 [podnet.py] => Task 11, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.71, Flat_loss 0.11, Train_acc 96.54, Test_acc 59.67
2025-02-13 18:18:24,981 [podnet.py] => Task 11, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.71, Flat_loss 0.11, Train_acc 96.42, Test_acc 59.33
2025-02-13 18:18:26,600 [podnet.py] => Task 11, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 96.12, Test_acc 59.22
2025-02-13 18:18:28,175 [podnet.py] => Task 11, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 96.29, Test_acc 59.29
2025-02-13 18:18:29,810 [podnet.py] => Task 11, Epoch 149/160 (LR 0.00116) => LSC_loss 0.21, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 96.42, Test_acc 59.50
2025-02-13 18:18:31,376 [podnet.py] => Task 11, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 96.29, Test_acc 59.47
2025-02-13 18:18:32,958 [podnet.py] => Task 11, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.63, Flat_loss 0.11, Train_acc 95.88, Test_acc 59.19
2025-02-13 18:18:34,566 [podnet.py] => Task 11, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 96.29, Test_acc 59.47
2025-02-13 18:18:36,150 [podnet.py] => Task 11, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 96.54, Test_acc 59.54
2025-02-13 18:18:37,772 [podnet.py] => Task 11, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.62, Flat_loss 0.11, Train_acc 96.92, Test_acc 59.54
2025-02-13 18:18:39,341 [podnet.py] => Task 11, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.61, Flat_loss 0.10, Train_acc 96.38, Test_acc 59.42
2025-02-13 18:18:40,853 [podnet.py] => Task 11, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 96.12, Test_acc 59.29
2025-02-13 18:18:42,380 [podnet.py] => Task 11, Epoch 157/160 (LR 0.00009) => LSC_loss 0.20, Spatial_loss 1.60, Flat_loss 0.10, Train_acc 96.54, Test_acc 59.17
2025-02-13 18:18:43,949 [podnet.py] => Task 11, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 1.66, Flat_loss 0.10, Train_acc 96.17, Test_acc 59.39
2025-02-13 18:18:45,511 [podnet.py] => Task 11, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 1.70, Flat_loss 0.10, Train_acc 96.67, Test_acc 59.36
2025-02-13 18:18:47,072 [podnet.py] => Task 11, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.65, Flat_loss 0.10, Train_acc 96.75, Test_acc 59.47
2025-02-13 18:18:47,073 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:18:47,073 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:19:09,167 [podnet.py] => The size of finetune dataset: 1440
2025-02-13 18:19:10,487 [podnet.py] => Task 11, Epoch 1/20 (LR 0.00497) => LSC_loss 0.13, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 97.64, Test_acc 57.11
2025-02-13 18:19:11,820 [podnet.py] => Task 11, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 2.01, Flat_loss 0.10, Train_acc 98.68, Test_acc 59.44
2025-02-13 18:19:13,167 [podnet.py] => Task 11, Epoch 3/20 (LR 0.00473) => LSC_loss 0.08, Spatial_loss 1.93, Flat_loss 0.08, Train_acc 99.51, Test_acc 60.32
2025-02-13 18:19:14,574 [podnet.py] => Task 11, Epoch 4/20 (LR 0.00452) => LSC_loss 0.08, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 99.31, Test_acc 60.68
2025-02-13 18:19:15,954 [podnet.py] => Task 11, Epoch 5/20 (LR 0.00427) => LSC_loss 0.08, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 98.96, Test_acc 60.14
2025-02-13 18:19:17,286 [podnet.py] => Task 11, Epoch 6/20 (LR 0.00397) => LSC_loss 0.08, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 99.10, Test_acc 60.28
2025-02-13 18:19:18,675 [podnet.py] => Task 11, Epoch 7/20 (LR 0.00363) => LSC_loss 0.08, Spatial_loss 1.74, Flat_loss 0.07, Train_acc 99.03, Test_acc 60.04
2025-02-13 18:19:20,082 [podnet.py] => Task 11, Epoch 8/20 (LR 0.00327) => LSC_loss 0.08, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.31, Test_acc 60.03
2025-02-13 18:19:21,520 [podnet.py] => Task 11, Epoch 9/20 (LR 0.00289) => LSC_loss 0.08, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 99.58, Test_acc 60.22
2025-02-13 18:19:22,933 [podnet.py] => Task 11, Epoch 10/20 (LR 0.00250) => LSC_loss 0.07, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.38, Test_acc 60.03
2025-02-13 18:19:24,363 [podnet.py] => Task 11, Epoch 11/20 (LR 0.00211) => LSC_loss 0.08, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 99.10, Test_acc 60.11
2025-02-13 18:19:25,739 [podnet.py] => Task 11, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 98.82, Test_acc 60.36
2025-02-13 18:19:27,146 [podnet.py] => Task 11, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 99.03, Test_acc 60.26
2025-02-13 18:19:28,574 [podnet.py] => Task 11, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.31, Test_acc 60.19
2025-02-13 18:19:29,987 [podnet.py] => Task 11, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.24, Test_acc 60.49
2025-02-13 18:19:31,345 [podnet.py] => Task 11, Epoch 16/20 (LR 0.00048) => LSC_loss 0.08, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 98.89, Test_acc 59.86
2025-02-13 18:19:32,780 [podnet.py] => Task 11, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 98.89, Test_acc 60.06
2025-02-13 18:19:34,189 [podnet.py] => Task 11, Epoch 18/20 (LR 0.00012) => LSC_loss 0.09, Spatial_loss 1.82, Flat_loss 0.07, Train_acc 98.96, Test_acc 60.08
2025-02-13 18:19:35,570 [podnet.py] => Task 11, Epoch 19/20 (LR 0.00003) => LSC_loss 0.07, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 99.24, Test_acc 60.10
2025-02-13 18:19:37,010 [podnet.py] => Task 11, Epoch 20/20 (LR 0.00000) => LSC_loss 0.08, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 99.31, Test_acc 60.00
2025-02-13 18:19:37,011 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:20:01,951 [podnet.py] => Exemplar size: 1440
2025-02-13 18:20:01,951 [trainer.py] => CNN: {'total': 60.0, '00-09': 69.1, '10-19': 48.4, '20-29': 66.6, '30-39': 57.1, '40-49': 65.6, '50-59': 49.6, '60-69': 62.4, '70-79': 66.0, 'old': 59.83, 'new': 66.0}
2025-02-13 18:20:01,951 [trainer.py] => NME: {'total': 60.69, '00-09': 71.4, '10-19': 53.1, '20-29': 70.0, '30-39': 58.2, '40-49': 66.5, '50-59': 46.3, '60-69': 58.5, '70-79': 65.0, 'old': 60.57, 'new': 65.0}
2025-02-13 18:20:01,951 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0]
2025-02-13 18:20:01,952 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53]
2025-02-13 18:20:01,952 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69]
2025-02-13 18:20:01,952 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32]

2025-02-13 18:20:01,952 [trainer.py] => Average Accuracy (CNN): 67.705
2025-02-13 18:20:01,952 [trainer.py] => Average Accuracy (NME): 67.96999999999998
2025-02-13 18:20:01,952 [trainer.py] => All params: 512337
2025-02-13 18:20:01,952 [trainer.py] => Trainable params: 512337
2025-02-13 18:20:01,953 [podnet.py] => Learning on 72-74
2025-02-13 18:20:01,973 [podnet.py] => Adaptive factor: 6.082762530298219
2025-02-13 18:20:03,678 [podnet.py] => Task 12, Epoch 1/160 (LR 0.09999) => LSC_loss 1.18, Spatial_loss 4.51, Flat_loss 0.60, Train_acc 82.30, Test_acc 34.80
2025-02-13 18:20:05,342 [podnet.py] => Task 12, Epoch 2/160 (LR 0.09996) => LSC_loss 0.56, Spatial_loss 6.27, Flat_loss 0.83, Train_acc 85.37, Test_acc 29.53
2025-02-13 18:20:06,941 [podnet.py] => Task 12, Epoch 3/160 (LR 0.09991) => LSC_loss 0.94, Spatial_loss 8.28, Flat_loss 1.32, Train_acc 75.78, Test_acc 28.41
2025-02-13 18:20:08,590 [podnet.py] => Task 12, Epoch 4/160 (LR 0.09985) => LSC_loss 0.79, Spatial_loss 7.83, Flat_loss 1.18, Train_acc 80.08, Test_acc 38.32
2025-02-13 18:20:10,258 [podnet.py] => Task 12, Epoch 5/160 (LR 0.09976) => LSC_loss 0.83, Spatial_loss 7.56, Flat_loss 1.17, Train_acc 79.63, Test_acc 38.30
2025-02-13 18:20:11,901 [podnet.py] => Task 12, Epoch 6/160 (LR 0.09965) => LSC_loss 0.64, Spatial_loss 7.19, Flat_loss 1.02, Train_acc 83.44, Test_acc 37.74
2025-02-13 18:20:13,598 [podnet.py] => Task 12, Epoch 7/160 (LR 0.09953) => LSC_loss 0.70, Spatial_loss 7.38, Flat_loss 1.07, Train_acc 83.40, Test_acc 27.26
2025-02-13 18:20:15,275 [podnet.py] => Task 12, Epoch 8/160 (LR 0.09938) => LSC_loss 0.64, Spatial_loss 7.39, Flat_loss 1.05, Train_acc 83.98, Test_acc 45.39
2025-02-13 18:20:16,925 [podnet.py] => Task 12, Epoch 9/160 (LR 0.09922) => LSC_loss 0.53, Spatial_loss 6.96, Flat_loss 0.93, Train_acc 85.41, Test_acc 48.59
2025-02-13 18:20:18,585 [podnet.py] => Task 12, Epoch 10/160 (LR 0.09904) => LSC_loss 0.40, Spatial_loss 6.33, Flat_loss 0.75, Train_acc 89.75, Test_acc 48.18
2025-02-13 18:20:20,201 [podnet.py] => Task 12, Epoch 11/160 (LR 0.09884) => LSC_loss 0.36, Spatial_loss 5.73, Flat_loss 0.63, Train_acc 92.83, Test_acc 51.16
2025-02-13 18:20:21,812 [podnet.py] => Task 12, Epoch 12/160 (LR 0.09862) => LSC_loss 0.33, Spatial_loss 5.74, Flat_loss 0.62, Train_acc 92.01, Test_acc 48.11
2025-02-13 18:20:23,464 [podnet.py] => Task 12, Epoch 13/160 (LR 0.09838) => LSC_loss 0.35, Spatial_loss 5.55, Flat_loss 0.57, Train_acc 93.07, Test_acc 40.35
2025-02-13 18:20:25,110 [podnet.py] => Task 12, Epoch 14/160 (LR 0.09812) => LSC_loss 0.43, Spatial_loss 6.20, Flat_loss 0.73, Train_acc 89.10, Test_acc 49.93
2025-02-13 18:20:26,696 [podnet.py] => Task 12, Epoch 15/160 (LR 0.09785) => LSC_loss 0.40, Spatial_loss 5.69, Flat_loss 0.62, Train_acc 92.13, Test_acc 43.43
2025-02-13 18:20:28,307 [podnet.py] => Task 12, Epoch 16/160 (LR 0.09755) => LSC_loss 0.37, Spatial_loss 5.70, Flat_loss 0.63, Train_acc 92.87, Test_acc 44.45
2025-02-13 18:20:29,902 [podnet.py] => Task 12, Epoch 17/160 (LR 0.09724) => LSC_loss 0.43, Spatial_loss 6.11, Flat_loss 0.77, Train_acc 89.80, Test_acc 50.18
2025-02-13 18:20:31,513 [podnet.py] => Task 12, Epoch 18/160 (LR 0.09691) => LSC_loss 0.34, Spatial_loss 5.66, Flat_loss 0.61, Train_acc 92.87, Test_acc 51.16
2025-02-13 18:20:33,176 [podnet.py] => Task 12, Epoch 19/160 (LR 0.09656) => LSC_loss 0.40, Spatial_loss 5.97, Flat_loss 0.74, Train_acc 89.84, Test_acc 46.14
2025-02-13 18:20:34,849 [podnet.py] => Task 12, Epoch 20/160 (LR 0.09619) => LSC_loss 0.42, Spatial_loss 6.19, Flat_loss 0.72, Train_acc 90.20, Test_acc 47.43
2025-02-13 18:20:36,497 [podnet.py] => Task 12, Epoch 21/160 (LR 0.09581) => LSC_loss 0.38, Spatial_loss 6.19, Flat_loss 0.72, Train_acc 91.43, Test_acc 49.19
2025-02-13 18:20:38,147 [podnet.py] => Task 12, Epoch 22/160 (LR 0.09541) => LSC_loss 0.36, Spatial_loss 5.68, Flat_loss 0.61, Train_acc 92.75, Test_acc 49.76
2025-02-13 18:20:39,829 [podnet.py] => Task 12, Epoch 23/160 (LR 0.09499) => LSC_loss 0.35, Spatial_loss 5.74, Flat_loss 0.63, Train_acc 91.56, Test_acc 46.15
2025-02-13 18:20:41,486 [podnet.py] => Task 12, Epoch 24/160 (LR 0.09455) => LSC_loss 0.33, Spatial_loss 5.68, Flat_loss 0.61, Train_acc 92.38, Test_acc 51.70
2025-02-13 18:20:43,139 [podnet.py] => Task 12, Epoch 25/160 (LR 0.09410) => LSC_loss 0.33, Spatial_loss 5.49, Flat_loss 0.55, Train_acc 93.77, Test_acc 46.23
2025-02-13 18:20:44,800 [podnet.py] => Task 12, Epoch 26/160 (LR 0.09362) => LSC_loss 0.34, Spatial_loss 5.71, Flat_loss 0.63, Train_acc 92.25, Test_acc 51.30
2025-02-13 18:20:46,443 [podnet.py] => Task 12, Epoch 27/160 (LR 0.09314) => LSC_loss 0.35, Spatial_loss 5.58, Flat_loss 0.59, Train_acc 93.57, Test_acc 49.84
2025-02-13 18:20:48,084 [podnet.py] => Task 12, Epoch 28/160 (LR 0.09263) => LSC_loss 0.40, Spatial_loss 6.06, Flat_loss 0.72, Train_acc 89.75, Test_acc 51.12
2025-02-13 18:20:49,720 [podnet.py] => Task 12, Epoch 29/160 (LR 0.09211) => LSC_loss 0.32, Spatial_loss 5.65, Flat_loss 0.62, Train_acc 92.21, Test_acc 52.47
2025-02-13 18:20:51,375 [podnet.py] => Task 12, Epoch 30/160 (LR 0.09157) => LSC_loss 0.29, Spatial_loss 5.37, Flat_loss 0.53, Train_acc 94.06, Test_acc 49.51
2025-02-13 18:20:53,000 [podnet.py] => Task 12, Epoch 31/160 (LR 0.09102) => LSC_loss 0.25, Spatial_loss 5.17, Flat_loss 0.50, Train_acc 93.73, Test_acc 50.28
2025-02-13 18:20:54,619 [podnet.py] => Task 12, Epoch 32/160 (LR 0.09045) => LSC_loss 0.20, Spatial_loss 4.74, Flat_loss 0.42, Train_acc 96.35, Test_acc 52.27
2025-02-13 18:20:56,330 [podnet.py] => Task 12, Epoch 33/160 (LR 0.08987) => LSC_loss 0.23, Spatial_loss 4.58, Flat_loss 0.39, Train_acc 96.72, Test_acc 51.55
2025-02-13 18:20:58,000 [podnet.py] => Task 12, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 4.70, Flat_loss 0.41, Train_acc 95.86, Test_acc 53.70
2025-02-13 18:20:59,634 [podnet.py] => Task 12, Epoch 35/160 (LR 0.08865) => LSC_loss 0.22, Spatial_loss 4.75, Flat_loss 0.43, Train_acc 95.90, Test_acc 53.27
2025-02-13 18:21:01,305 [podnet.py] => Task 12, Epoch 36/160 (LR 0.08802) => LSC_loss 0.28, Spatial_loss 4.90, Flat_loss 0.44, Train_acc 94.96, Test_acc 48.82
2025-02-13 18:21:02,938 [podnet.py] => Task 12, Epoch 37/160 (LR 0.08738) => LSC_loss 0.24, Spatial_loss 4.88, Flat_loss 0.44, Train_acc 94.88, Test_acc 53.15
2025-02-13 18:21:04,557 [podnet.py] => Task 12, Epoch 38/160 (LR 0.08672) => LSC_loss 0.21, Spatial_loss 4.75, Flat_loss 0.41, Train_acc 95.70, Test_acc 52.28
2025-02-13 18:21:06,205 [podnet.py] => Task 12, Epoch 39/160 (LR 0.08604) => LSC_loss 0.25, Spatial_loss 4.56, Flat_loss 0.40, Train_acc 95.12, Test_acc 52.04
2025-02-13 18:21:07,814 [podnet.py] => Task 12, Epoch 40/160 (LR 0.08536) => LSC_loss 0.32, Spatial_loss 4.72, Flat_loss 0.42, Train_acc 95.29, Test_acc 44.54
2025-02-13 18:21:09,472 [podnet.py] => Task 12, Epoch 41/160 (LR 0.08465) => LSC_loss 0.39, Spatial_loss 5.30, Flat_loss 0.56, Train_acc 91.80, Test_acc 46.34
2025-02-13 18:21:11,113 [podnet.py] => Task 12, Epoch 42/160 (LR 0.08394) => LSC_loss 0.29, Spatial_loss 4.81, Flat_loss 0.47, Train_acc 94.47, Test_acc 51.74
2025-02-13 18:21:12,835 [podnet.py] => Task 12, Epoch 43/160 (LR 0.08321) => LSC_loss 0.23, Spatial_loss 4.64, Flat_loss 0.40, Train_acc 95.61, Test_acc 51.47
2025-02-13 18:21:14,486 [podnet.py] => Task 12, Epoch 44/160 (LR 0.08247) => LSC_loss 0.22, Spatial_loss 4.55, Flat_loss 0.39, Train_acc 95.86, Test_acc 52.58
2025-02-13 18:21:16,154 [podnet.py] => Task 12, Epoch 45/160 (LR 0.08172) => LSC_loss 0.21, Spatial_loss 4.41, Flat_loss 0.37, Train_acc 95.98, Test_acc 55.77
2025-02-13 18:21:17,808 [podnet.py] => Task 12, Epoch 46/160 (LR 0.08095) => LSC_loss 0.21, Spatial_loss 4.22, Flat_loss 0.33, Train_acc 95.98, Test_acc 51.03
2025-02-13 18:21:19,412 [podnet.py] => Task 12, Epoch 47/160 (LR 0.08018) => LSC_loss 0.25, Spatial_loss 4.76, Flat_loss 0.44, Train_acc 94.71, Test_acc 55.07
2025-02-13 18:21:21,044 [podnet.py] => Task 12, Epoch 48/160 (LR 0.07939) => LSC_loss 0.21, Spatial_loss 4.45, Flat_loss 0.37, Train_acc 95.78, Test_acc 53.39
2025-02-13 18:21:22,670 [podnet.py] => Task 12, Epoch 49/160 (LR 0.07859) => LSC_loss 0.20, Spatial_loss 4.31, Flat_loss 0.35, Train_acc 96.43, Test_acc 52.30
2025-02-13 18:21:24,309 [podnet.py] => Task 12, Epoch 50/160 (LR 0.07778) => LSC_loss 0.23, Spatial_loss 4.23, Flat_loss 0.33, Train_acc 96.19, Test_acc 53.97
2025-02-13 18:21:25,965 [podnet.py] => Task 12, Epoch 51/160 (LR 0.07696) => LSC_loss 0.24, Spatial_loss 4.59, Flat_loss 0.42, Train_acc 95.78, Test_acc 52.81
2025-02-13 18:21:27,651 [podnet.py] => Task 12, Epoch 52/160 (LR 0.07612) => LSC_loss 0.24, Spatial_loss 4.27, Flat_loss 0.36, Train_acc 96.23, Test_acc 55.31
2025-02-13 18:21:29,261 [podnet.py] => Task 12, Epoch 53/160 (LR 0.07528) => LSC_loss 0.22, Spatial_loss 4.47, Flat_loss 0.39, Train_acc 95.41, Test_acc 55.11
2025-02-13 18:21:30,812 [podnet.py] => Task 12, Epoch 54/160 (LR 0.07443) => LSC_loss 0.20, Spatial_loss 4.26, Flat_loss 0.38, Train_acc 96.02, Test_acc 57.04
2025-02-13 18:21:32,442 [podnet.py] => Task 12, Epoch 55/160 (LR 0.07357) => LSC_loss 0.20, Spatial_loss 3.99, Flat_loss 0.32, Train_acc 96.43, Test_acc 53.47
2025-02-13 18:21:34,106 [podnet.py] => Task 12, Epoch 56/160 (LR 0.07270) => LSC_loss 0.21, Spatial_loss 4.37, Flat_loss 0.36, Train_acc 95.57, Test_acc 51.31
2025-02-13 18:21:35,759 [podnet.py] => Task 12, Epoch 57/160 (LR 0.07182) => LSC_loss 0.21, Spatial_loss 4.21, Flat_loss 0.36, Train_acc 96.07, Test_acc 54.53
2025-02-13 18:21:37,469 [podnet.py] => Task 12, Epoch 58/160 (LR 0.07093) => LSC_loss 0.23, Spatial_loss 3.98, Flat_loss 0.32, Train_acc 96.52, Test_acc 52.68
2025-02-13 18:21:39,125 [podnet.py] => Task 12, Epoch 59/160 (LR 0.07004) => LSC_loss 0.28, Spatial_loss 4.71, Flat_loss 0.44, Train_acc 93.73, Test_acc 53.30
2025-02-13 18:21:40,757 [podnet.py] => Task 12, Epoch 60/160 (LR 0.06913) => LSC_loss 0.22, Spatial_loss 4.41, Flat_loss 0.37, Train_acc 95.25, Test_acc 52.36
2025-02-13 18:21:42,423 [podnet.py] => Task 12, Epoch 61/160 (LR 0.06822) => LSC_loss 0.19, Spatial_loss 4.03, Flat_loss 0.33, Train_acc 97.05, Test_acc 54.51
2025-02-13 18:21:44,116 [podnet.py] => Task 12, Epoch 62/160 (LR 0.06731) => LSC_loss 0.22, Spatial_loss 4.16, Flat_loss 0.33, Train_acc 96.56, Test_acc 54.18
2025-02-13 18:21:45,832 [podnet.py] => Task 12, Epoch 63/160 (LR 0.06638) => LSC_loss 0.20, Spatial_loss 4.16, Flat_loss 0.33, Train_acc 96.52, Test_acc 56.59
2025-02-13 18:21:47,556 [podnet.py] => Task 12, Epoch 64/160 (LR 0.06545) => LSC_loss 0.20, Spatial_loss 3.93, Flat_loss 0.31, Train_acc 96.39, Test_acc 52.27
2025-02-13 18:21:49,184 [podnet.py] => Task 12, Epoch 65/160 (LR 0.06451) => LSC_loss 0.22, Spatial_loss 4.19, Flat_loss 0.33, Train_acc 96.23, Test_acc 53.35
2025-02-13 18:21:50,829 [podnet.py] => Task 12, Epoch 66/160 (LR 0.06357) => LSC_loss 0.20, Spatial_loss 4.30, Flat_loss 0.36, Train_acc 96.56, Test_acc 54.27
2025-02-13 18:21:52,470 [podnet.py] => Task 12, Epoch 67/160 (LR 0.06262) => LSC_loss 0.24, Spatial_loss 4.31, Flat_loss 0.38, Train_acc 94.96, Test_acc 52.73
2025-02-13 18:21:54,131 [podnet.py] => Task 12, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 4.44, Flat_loss 0.38, Train_acc 95.82, Test_acc 53.89
2025-02-13 18:21:55,810 [podnet.py] => Task 12, Epoch 69/160 (LR 0.06072) => LSC_loss 0.22, Spatial_loss 4.30, Flat_loss 0.35, Train_acc 96.19, Test_acc 51.99
2025-02-13 18:21:57,447 [podnet.py] => Task 12, Epoch 70/160 (LR 0.05975) => LSC_loss 0.21, Spatial_loss 4.22, Flat_loss 0.33, Train_acc 96.02, Test_acc 52.97
2025-02-13 18:21:59,098 [podnet.py] => Task 12, Epoch 71/160 (LR 0.05879) => LSC_loss 0.18, Spatial_loss 3.91, Flat_loss 0.31, Train_acc 96.84, Test_acc 55.76
2025-02-13 18:22:00,712 [podnet.py] => Task 12, Epoch 72/160 (LR 0.05782) => LSC_loss 0.20, Spatial_loss 3.95, Flat_loss 0.31, Train_acc 96.60, Test_acc 53.38
2025-02-13 18:22:02,332 [podnet.py] => Task 12, Epoch 73/160 (LR 0.05685) => LSC_loss 0.23, Spatial_loss 4.07, Flat_loss 0.34, Train_acc 96.15, Test_acc 51.53
2025-02-13 18:22:03,992 [podnet.py] => Task 12, Epoch 74/160 (LR 0.05588) => LSC_loss 0.22, Spatial_loss 4.14, Flat_loss 0.35, Train_acc 95.94, Test_acc 57.55
2025-02-13 18:22:05,651 [podnet.py] => Task 12, Epoch 75/160 (LR 0.05490) => LSC_loss 0.18, Spatial_loss 3.89, Flat_loss 0.30, Train_acc 96.68, Test_acc 53.36
2025-02-13 18:22:07,317 [podnet.py] => Task 12, Epoch 76/160 (LR 0.05392) => LSC_loss 0.17, Spatial_loss 3.62, Flat_loss 0.26, Train_acc 97.21, Test_acc 54.59
2025-02-13 18:22:08,954 [podnet.py] => Task 12, Epoch 77/160 (LR 0.05294) => LSC_loss 0.19, Spatial_loss 3.61, Flat_loss 0.26, Train_acc 96.93, Test_acc 51.16
2025-02-13 18:22:10,586 [podnet.py] => Task 12, Epoch 78/160 (LR 0.05196) => LSC_loss 0.21, Spatial_loss 3.96, Flat_loss 0.30, Train_acc 96.27, Test_acc 52.41
2025-02-13 18:22:12,260 [podnet.py] => Task 12, Epoch 79/160 (LR 0.05098) => LSC_loss 0.20, Spatial_loss 3.99, Flat_loss 0.31, Train_acc 96.31, Test_acc 56.26
2025-02-13 18:22:13,916 [podnet.py] => Task 12, Epoch 80/160 (LR 0.05000) => LSC_loss 0.18, Spatial_loss 3.75, Flat_loss 0.27, Train_acc 96.80, Test_acc 56.92
2025-02-13 18:22:15,535 [podnet.py] => Task 12, Epoch 81/160 (LR 0.04902) => LSC_loss 0.16, Spatial_loss 3.80, Flat_loss 0.26, Train_acc 97.70, Test_acc 56.34
2025-02-13 18:22:17,167 [podnet.py] => Task 12, Epoch 82/160 (LR 0.04804) => LSC_loss 0.20, Spatial_loss 3.58, Flat_loss 0.27, Train_acc 97.01, Test_acc 54.03
2025-02-13 18:22:18,814 [podnet.py] => Task 12, Epoch 83/160 (LR 0.04706) => LSC_loss 0.18, Spatial_loss 3.59, Flat_loss 0.26, Train_acc 96.64, Test_acc 55.28
2025-02-13 18:22:20,475 [podnet.py] => Task 12, Epoch 84/160 (LR 0.04608) => LSC_loss 0.20, Spatial_loss 3.54, Flat_loss 0.28, Train_acc 96.80, Test_acc 54.85
2025-02-13 18:22:22,144 [podnet.py] => Task 12, Epoch 85/160 (LR 0.04510) => LSC_loss 0.19, Spatial_loss 3.69, Flat_loss 0.27, Train_acc 96.72, Test_acc 55.51
2025-02-13 18:22:23,774 [podnet.py] => Task 12, Epoch 86/160 (LR 0.04412) => LSC_loss 0.19, Spatial_loss 3.43, Flat_loss 0.26, Train_acc 96.76, Test_acc 57.36
2025-02-13 18:22:25,496 [podnet.py] => Task 12, Epoch 87/160 (LR 0.04315) => LSC_loss 0.20, Spatial_loss 3.48, Flat_loss 0.26, Train_acc 96.76, Test_acc 55.70
2025-02-13 18:22:27,153 [podnet.py] => Task 12, Epoch 88/160 (LR 0.04218) => LSC_loss 0.18, Spatial_loss 3.41, Flat_loss 0.24, Train_acc 96.80, Test_acc 58.00
2025-02-13 18:22:28,788 [podnet.py] => Task 12, Epoch 89/160 (LR 0.04121) => LSC_loss 0.18, Spatial_loss 3.45, Flat_loss 0.24, Train_acc 96.72, Test_acc 54.16
2025-02-13 18:22:30,466 [podnet.py] => Task 12, Epoch 90/160 (LR 0.04025) => LSC_loss 0.20, Spatial_loss 3.33, Flat_loss 0.22, Train_acc 97.30, Test_acc 58.22
2025-02-13 18:22:32,141 [podnet.py] => Task 12, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 3.40, Flat_loss 0.25, Train_acc 97.13, Test_acc 54.51
2025-02-13 18:22:33,832 [podnet.py] => Task 12, Epoch 92/160 (LR 0.03833) => LSC_loss 0.17, Spatial_loss 3.28, Flat_loss 0.23, Train_acc 97.79, Test_acc 57.39
2025-02-13 18:22:35,477 [podnet.py] => Task 12, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 3.27, Flat_loss 0.23, Train_acc 96.80, Test_acc 56.81
2025-02-13 18:22:37,187 [podnet.py] => Task 12, Epoch 94/160 (LR 0.03643) => LSC_loss 0.16, Spatial_loss 3.21, Flat_loss 0.23, Train_acc 97.46, Test_acc 56.01
2025-02-13 18:22:38,867 [podnet.py] => Task 12, Epoch 95/160 (LR 0.03549) => LSC_loss 0.16, Spatial_loss 3.10, Flat_loss 0.21, Train_acc 97.50, Test_acc 57.86
2025-02-13 18:22:40,485 [podnet.py] => Task 12, Epoch 96/160 (LR 0.03455) => LSC_loss 0.17, Spatial_loss 3.22, Flat_loss 0.22, Train_acc 96.72, Test_acc 56.99
2025-02-13 18:22:42,114 [podnet.py] => Task 12, Epoch 97/160 (LR 0.03362) => LSC_loss 0.18, Spatial_loss 3.15, Flat_loss 0.21, Train_acc 97.25, Test_acc 57.82
2025-02-13 18:22:43,818 [podnet.py] => Task 12, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 3.09, Flat_loss 0.21, Train_acc 96.56, Test_acc 57.64
2025-02-13 18:22:45,456 [podnet.py] => Task 12, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 3.13, Flat_loss 0.21, Train_acc 97.34, Test_acc 58.39
2025-02-13 18:22:47,085 [podnet.py] => Task 12, Epoch 100/160 (LR 0.03087) => LSC_loss 0.19, Spatial_loss 3.10, Flat_loss 0.22, Train_acc 97.70, Test_acc 56.73
2025-02-13 18:22:48,738 [podnet.py] => Task 12, Epoch 101/160 (LR 0.02996) => LSC_loss 0.21, Spatial_loss 3.12, Flat_loss 0.22, Train_acc 96.89, Test_acc 55.49
2025-02-13 18:22:50,430 [podnet.py] => Task 12, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 3.31, Flat_loss 0.25, Train_acc 96.93, Test_acc 54.20
2025-02-13 18:22:52,145 [podnet.py] => Task 12, Epoch 103/160 (LR 0.02818) => LSC_loss 0.19, Spatial_loss 3.32, Flat_loss 0.25, Train_acc 96.72, Test_acc 57.14
2025-02-13 18:22:53,767 [podnet.py] => Task 12, Epoch 104/160 (LR 0.02730) => LSC_loss 0.19, Spatial_loss 3.23, Flat_loss 0.24, Train_acc 96.84, Test_acc 57.15
2025-02-13 18:22:55,411 [podnet.py] => Task 12, Epoch 105/160 (LR 0.02643) => LSC_loss 0.16, Spatial_loss 3.20, Flat_loss 0.23, Train_acc 97.75, Test_acc 57.08
2025-02-13 18:22:57,086 [podnet.py] => Task 12, Epoch 106/160 (LR 0.02557) => LSC_loss 0.21, Spatial_loss 3.12, Flat_loss 0.22, Train_acc 97.05, Test_acc 57.57
2025-02-13 18:22:58,746 [podnet.py] => Task 12, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 3.08, Flat_loss 0.22, Train_acc 96.76, Test_acc 58.41
2025-02-13 18:23:00,421 [podnet.py] => Task 12, Epoch 108/160 (LR 0.02388) => LSC_loss 0.18, Spatial_loss 3.04, Flat_loss 0.21, Train_acc 97.70, Test_acc 58.28
2025-02-13 18:23:02,114 [podnet.py] => Task 12, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 3.17, Flat_loss 0.22, Train_acc 97.58, Test_acc 57.55
2025-02-13 18:23:03,738 [podnet.py] => Task 12, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 2.91, Flat_loss 0.20, Train_acc 97.34, Test_acc 57.08
2025-02-13 18:23:05,429 [podnet.py] => Task 12, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 2.96, Flat_loss 0.20, Train_acc 97.38, Test_acc 58.18
2025-02-13 18:23:07,079 [podnet.py] => Task 12, Epoch 112/160 (LR 0.02061) => LSC_loss 0.19, Spatial_loss 2.84, Flat_loss 0.19, Train_acc 96.80, Test_acc 57.32
2025-02-13 18:23:08,722 [podnet.py] => Task 12, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 2.79, Flat_loss 0.19, Train_acc 97.30, Test_acc 57.43
2025-02-13 18:23:10,426 [podnet.py] => Task 12, Epoch 114/160 (LR 0.01905) => LSC_loss 0.19, Spatial_loss 2.90, Flat_loss 0.19, Train_acc 97.34, Test_acc 57.23
2025-02-13 18:23:12,132 [podnet.py] => Task 12, Epoch 115/160 (LR 0.01828) => LSC_loss 0.16, Spatial_loss 2.77, Flat_loss 0.19, Train_acc 97.79, Test_acc 57.00
2025-02-13 18:23:13,782 [podnet.py] => Task 12, Epoch 116/160 (LR 0.01753) => LSC_loss 0.17, Spatial_loss 2.73, Flat_loss 0.20, Train_acc 97.50, Test_acc 57.99
2025-02-13 18:23:15,509 [podnet.py] => Task 12, Epoch 117/160 (LR 0.01679) => LSC_loss 0.24, Spatial_loss 2.75, Flat_loss 0.19, Train_acc 97.13, Test_acc 57.62
2025-02-13 18:23:17,132 [podnet.py] => Task 12, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 2.84, Flat_loss 0.21, Train_acc 97.21, Test_acc 58.27
2025-02-13 18:23:18,734 [podnet.py] => Task 12, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 2.81, Flat_loss 0.18, Train_acc 97.30, Test_acc 57.89
2025-02-13 18:23:20,360 [podnet.py] => Task 12, Epoch 120/160 (LR 0.01464) => LSC_loss 0.17, Spatial_loss 2.67, Flat_loss 0.18, Train_acc 97.13, Test_acc 58.58
2025-02-13 18:23:22,036 [podnet.py] => Task 12, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 2.57, Flat_loss 0.16, Train_acc 97.46, Test_acc 57.30
2025-02-13 18:23:23,716 [podnet.py] => Task 12, Epoch 122/160 (LR 0.01328) => LSC_loss 0.19, Spatial_loss 2.53, Flat_loss 0.16, Train_acc 97.42, Test_acc 57.57
2025-02-13 18:23:25,374 [podnet.py] => Task 12, Epoch 123/160 (LR 0.01262) => LSC_loss 0.16, Spatial_loss 2.60, Flat_loss 0.17, Train_acc 97.62, Test_acc 56.81
2025-02-13 18:23:27,048 [podnet.py] => Task 12, Epoch 124/160 (LR 0.01198) => LSC_loss 0.16, Spatial_loss 2.59, Flat_loss 0.16, Train_acc 97.17, Test_acc 57.24
2025-02-13 18:23:28,686 [podnet.py] => Task 12, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 2.47, Flat_loss 0.16, Train_acc 98.07, Test_acc 57.20
2025-02-13 18:23:30,310 [podnet.py] => Task 12, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 2.46, Flat_loss 0.16, Train_acc 97.87, Test_acc 57.81
2025-02-13 18:23:31,985 [podnet.py] => Task 12, Epoch 127/160 (LR 0.01013) => LSC_loss 0.18, Spatial_loss 2.48, Flat_loss 0.15, Train_acc 97.01, Test_acc 58.03
2025-02-13 18:23:33,696 [podnet.py] => Task 12, Epoch 128/160 (LR 0.00955) => LSC_loss 0.16, Spatial_loss 2.46, Flat_loss 0.16, Train_acc 97.58, Test_acc 57.55
2025-02-13 18:23:35,365 [podnet.py] => Task 12, Epoch 129/160 (LR 0.00898) => LSC_loss 0.16, Spatial_loss 2.42, Flat_loss 0.15, Train_acc 97.62, Test_acc 57.69
2025-02-13 18:23:36,995 [podnet.py] => Task 12, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 2.43, Flat_loss 0.15, Train_acc 97.75, Test_acc 59.01
2025-02-13 18:23:38,625 [podnet.py] => Task 12, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 98.20, Test_acc 57.45
2025-02-13 18:23:40,353 [podnet.py] => Task 12, Epoch 132/160 (LR 0.00737) => LSC_loss 0.15, Spatial_loss 2.41, Flat_loss 0.15, Train_acc 97.91, Test_acc 58.86
2025-02-13 18:23:41,999 [podnet.py] => Task 12, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 2.25, Flat_loss 0.15, Train_acc 97.87, Test_acc 59.26
2025-02-13 18:23:43,652 [podnet.py] => Task 12, Epoch 134/160 (LR 0.00638) => LSC_loss 0.16, Spatial_loss 2.33, Flat_loss 0.15, Train_acc 97.91, Test_acc 58.76
2025-02-13 18:23:45,304 [podnet.py] => Task 12, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 2.29, Flat_loss 0.15, Train_acc 97.66, Test_acc 58.73
2025-02-13 18:23:46,959 [podnet.py] => Task 12, Epoch 136/160 (LR 0.00545) => LSC_loss 0.19, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 97.34, Test_acc 59.39
2025-02-13 18:23:48,566 [podnet.py] => Task 12, Epoch 137/160 (LR 0.00501) => LSC_loss 0.15, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 97.79, Test_acc 59.07
2025-02-13 18:23:50,240 [podnet.py] => Task 12, Epoch 138/160 (LR 0.00459) => LSC_loss 0.17, Spatial_loss 2.37, Flat_loss 0.15, Train_acc 97.99, Test_acc 58.74
2025-02-13 18:23:51,882 [podnet.py] => Task 12, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 2.26, Flat_loss 0.14, Train_acc 97.54, Test_acc 59.20
2025-02-13 18:23:53,502 [podnet.py] => Task 12, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 2.34, Flat_loss 0.16, Train_acc 97.83, Test_acc 58.47
2025-02-13 18:23:55,126 [podnet.py] => Task 12, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 2.23, Flat_loss 0.14, Train_acc 98.03, Test_acc 59.22
2025-02-13 18:23:56,738 [podnet.py] => Task 12, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 2.20, Flat_loss 0.14, Train_acc 97.46, Test_acc 58.78
2025-02-13 18:23:58,343 [podnet.py] => Task 12, Epoch 143/160 (LR 0.00276) => LSC_loss 0.18, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 97.58, Test_acc 59.24
2025-02-13 18:23:59,991 [podnet.py] => Task 12, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 2.20, Flat_loss 0.14, Train_acc 98.03, Test_acc 58.99
2025-02-13 18:24:01,661 [podnet.py] => Task 12, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 2.30, Flat_loss 0.15, Train_acc 97.42, Test_acc 59.42
2025-02-13 18:24:03,300 [podnet.py] => Task 12, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 97.95, Test_acc 58.97
2025-02-13 18:24:04,948 [podnet.py] => Task 12, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 2.10, Flat_loss 0.15, Train_acc 97.87, Test_acc 59.05
2025-02-13 18:24:06,606 [podnet.py] => Task 12, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 2.28, Flat_loss 0.15, Train_acc 97.62, Test_acc 58.11
2025-02-13 18:24:08,296 [podnet.py] => Task 12, Epoch 149/160 (LR 0.00116) => LSC_loss 0.16, Spatial_loss 2.15, Flat_loss 0.14, Train_acc 97.70, Test_acc 58.47
2025-02-13 18:24:09,988 [podnet.py] => Task 12, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 97.54, Test_acc 59.04
2025-02-13 18:24:11,682 [podnet.py] => Task 12, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 2.11, Flat_loss 0.13, Train_acc 97.62, Test_acc 59.01
2025-02-13 18:24:13,362 [podnet.py] => Task 12, Epoch 152/160 (LR 0.00062) => LSC_loss 0.16, Spatial_loss 2.18, Flat_loss 0.14, Train_acc 97.70, Test_acc 59.34
2025-02-13 18:24:14,989 [podnet.py] => Task 12, Epoch 153/160 (LR 0.00047) => LSC_loss 0.16, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 97.91, Test_acc 58.80
2025-02-13 18:24:16,645 [podnet.py] => Task 12, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 98.20, Test_acc 59.00
2025-02-13 18:24:18,271 [podnet.py] => Task 12, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 97.50, Test_acc 59.11
2025-02-13 18:24:19,903 [podnet.py] => Task 12, Epoch 156/160 (LR 0.00015) => LSC_loss 0.17, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 97.99, Test_acc 58.88
2025-02-13 18:24:21,560 [podnet.py] => Task 12, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 2.01, Flat_loss 0.13, Train_acc 97.95, Test_acc 59.28
2025-02-13 18:24:23,256 [podnet.py] => Task 12, Epoch 158/160 (LR 0.00004) => LSC_loss 0.17, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 97.66, Test_acc 59.08
2025-02-13 18:24:24,941 [podnet.py] => Task 12, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 97.66, Test_acc 59.27
2025-02-13 18:24:26,613 [podnet.py] => Task 12, Epoch 160/160 (LR 0.00000) => LSC_loss 0.16, Spatial_loss 2.14, Flat_loss 0.14, Train_acc 97.91, Test_acc 58.80
2025-02-13 18:24:26,614 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:24:26,614 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:24:50,368 [podnet.py] => The size of finetune dataset: 1480
2025-02-13 18:24:51,741 [podnet.py] => Task 12, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.61, Flat_loss 0.17, Train_acc 97.57, Test_acc 57.59
2025-02-13 18:24:53,109 [podnet.py] => Task 12, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 2.08, Flat_loss 0.10, Train_acc 99.19, Test_acc 58.28
2025-02-13 18:24:54,484 [podnet.py] => Task 12, Epoch 3/20 (LR 0.00473) => LSC_loss 0.09, Spatial_loss 1.97, Flat_loss 0.08, Train_acc 99.12, Test_acc 59.12
2025-02-13 18:24:55,872 [podnet.py] => Task 12, Epoch 4/20 (LR 0.00452) => LSC_loss 0.09, Spatial_loss 1.99, Flat_loss 0.08, Train_acc 99.12, Test_acc 59.64
2025-02-13 18:24:57,307 [podnet.py] => Task 12, Epoch 5/20 (LR 0.00427) => LSC_loss 0.09, Spatial_loss 1.94, Flat_loss 0.07, Train_acc 99.12, Test_acc 59.65
2025-02-13 18:24:58,738 [podnet.py] => Task 12, Epoch 6/20 (LR 0.00397) => LSC_loss 0.08, Spatial_loss 1.89, Flat_loss 0.07, Train_acc 99.66, Test_acc 59.72
2025-02-13 18:25:00,119 [podnet.py] => Task 12, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 1.90, Flat_loss 0.07, Train_acc 99.26, Test_acc 59.55
2025-02-13 18:25:01,544 [podnet.py] => Task 12, Epoch 8/20 (LR 0.00327) => LSC_loss 0.09, Spatial_loss 1.99, Flat_loss 0.08, Train_acc 99.19, Test_acc 59.46
2025-02-13 18:25:02,982 [podnet.py] => Task 12, Epoch 9/20 (LR 0.00289) => LSC_loss 0.08, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 99.32, Test_acc 59.70
2025-02-13 18:25:04,391 [podnet.py] => Task 12, Epoch 10/20 (LR 0.00250) => LSC_loss 0.08, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 99.26, Test_acc 59.77
2025-02-13 18:25:05,861 [podnet.py] => Task 12, Epoch 11/20 (LR 0.00211) => LSC_loss 0.09, Spatial_loss 1.81, Flat_loss 0.07, Train_acc 99.05, Test_acc 59.62
2025-02-13 18:25:07,268 [podnet.py] => Task 12, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 98.99, Test_acc 59.55
2025-02-13 18:25:08,701 [podnet.py] => Task 12, Epoch 13/20 (LR 0.00137) => LSC_loss 0.08, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 99.19, Test_acc 59.51
2025-02-13 18:25:10,125 [podnet.py] => Task 12, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 99.46, Test_acc 59.61
2025-02-13 18:25:11,532 [podnet.py] => Task 12, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 1.81, Flat_loss 0.07, Train_acc 99.12, Test_acc 59.45
2025-02-13 18:25:12,946 [podnet.py] => Task 12, Epoch 16/20 (LR 0.00048) => LSC_loss 0.08, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 99.59, Test_acc 59.66
2025-02-13 18:25:14,356 [podnet.py] => Task 12, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.26, Test_acc 59.58
2025-02-13 18:25:15,762 [podnet.py] => Task 12, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 1.83, Flat_loss 0.07, Train_acc 99.19, Test_acc 59.46
2025-02-13 18:25:17,187 [podnet.py] => Task 12, Epoch 19/20 (LR 0.00003) => LSC_loss 0.09, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 99.39, Test_acc 59.62
2025-02-13 18:25:18,641 [podnet.py] => Task 12, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 1.74, Flat_loss 0.07, Train_acc 99.39, Test_acc 59.61
2025-02-13 18:25:18,644 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:25:44,027 [podnet.py] => Exemplar size: 1480
2025-02-13 18:25:44,027 [trainer.py] => CNN: {'total': 59.61, '00-09': 68.1, '10-19': 48.8, '20-29': 66.1, '30-39': 56.6, '40-49': 64.2, '50-59': 49.5, '60-69': 59.0, '70-79': 72.0, 'old': 59.04, 'new': 80.0}
2025-02-13 18:25:44,028 [trainer.py] => NME: {'total': 59.7, '00-09': 71.1, '10-19': 52.4, '20-29': 68.9, '30-39': 57.7, '40-49': 65.1, '50-59': 44.3, '60-69': 55.6, '70-79': 66.75, 'old': 59.35, 'new': 72.5}
2025-02-13 18:25:44,028 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61]
2025-02-13 18:25:44,028 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82]
2025-02-13 18:25:44,029 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7]
2025-02-13 18:25:44,029 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08]

2025-02-13 18:25:44,029 [trainer.py] => Average Accuracy (CNN): 67.0823076923077
2025-02-13 18:25:44,029 [trainer.py] => Average Accuracy (NME): 67.33384615384615
2025-02-13 18:25:44,030 [trainer.py] => All params: 513617
2025-02-13 18:25:44,030 [trainer.py] => Trainable params: 513617
2025-02-13 18:25:44,031 [podnet.py] => Learning on 74-76
2025-02-13 18:25:44,051 [podnet.py] => Adaptive factor: 6.164414002968976
2025-02-13 18:25:45,918 [podnet.py] => Task 13, Epoch 1/160 (LR 0.09999) => LSC_loss 1.33, Spatial_loss 3.68, Flat_loss 0.51, Train_acc 78.10, Test_acc 42.04
2025-02-13 18:25:47,738 [podnet.py] => Task 13, Epoch 2/160 (LR 0.09996) => LSC_loss 0.47, Spatial_loss 4.36, Flat_loss 0.48, Train_acc 88.39, Test_acc 50.30
2025-02-13 18:25:49,586 [podnet.py] => Task 13, Epoch 3/160 (LR 0.09991) => LSC_loss 0.42, Spatial_loss 4.26, Flat_loss 0.46, Train_acc 90.36, Test_acc 47.32
2025-02-13 18:25:51,449 [podnet.py] => Task 13, Epoch 4/160 (LR 0.09985) => LSC_loss 0.37, Spatial_loss 4.15, Flat_loss 0.42, Train_acc 91.61, Test_acc 50.82
2025-02-13 18:25:53,291 [podnet.py] => Task 13, Epoch 5/160 (LR 0.09976) => LSC_loss 0.36, Spatial_loss 4.09, Flat_loss 0.39, Train_acc 92.50, Test_acc 51.17
2025-02-13 18:25:55,159 [podnet.py] => Task 13, Epoch 6/160 (LR 0.09965) => LSC_loss 0.36, Spatial_loss 4.07, Flat_loss 0.37, Train_acc 92.34, Test_acc 52.45
2025-02-13 18:25:56,972 [podnet.py] => Task 13, Epoch 7/160 (LR 0.09953) => LSC_loss 0.35, Spatial_loss 4.05, Flat_loss 0.38, Train_acc 92.30, Test_acc 50.42
2025-02-13 18:25:58,881 [podnet.py] => Task 13, Epoch 8/160 (LR 0.09938) => LSC_loss 0.35, Spatial_loss 4.02, Flat_loss 0.37, Train_acc 92.50, Test_acc 49.88
2025-02-13 18:26:00,770 [podnet.py] => Task 13, Epoch 9/160 (LR 0.09922) => LSC_loss 0.33, Spatial_loss 4.08, Flat_loss 0.38, Train_acc 93.02, Test_acc 47.16
2025-02-13 18:26:02,668 [podnet.py] => Task 13, Epoch 10/160 (LR 0.09904) => LSC_loss 0.33, Spatial_loss 4.08, Flat_loss 0.37, Train_acc 92.98, Test_acc 53.67
2025-02-13 18:26:04,528 [podnet.py] => Task 13, Epoch 11/160 (LR 0.09884) => LSC_loss 0.32, Spatial_loss 3.95, Flat_loss 0.35, Train_acc 93.23, Test_acc 48.55
2025-02-13 18:26:06,368 [podnet.py] => Task 13, Epoch 12/160 (LR 0.09862) => LSC_loss 0.33, Spatial_loss 3.92, Flat_loss 0.36, Train_acc 92.90, Test_acc 50.16
2025-02-13 18:26:08,163 [podnet.py] => Task 13, Epoch 13/160 (LR 0.09838) => LSC_loss 0.31, Spatial_loss 3.94, Flat_loss 0.35, Train_acc 93.47, Test_acc 54.09
2025-02-13 18:26:09,970 [podnet.py] => Task 13, Epoch 14/160 (LR 0.09812) => LSC_loss 0.30, Spatial_loss 4.03, Flat_loss 0.36, Train_acc 93.87, Test_acc 47.34
2025-02-13 18:26:11,840 [podnet.py] => Task 13, Epoch 15/160 (LR 0.09785) => LSC_loss 0.32, Spatial_loss 4.01, Flat_loss 0.36, Train_acc 93.15, Test_acc 51.55
2025-02-13 18:26:13,677 [podnet.py] => Task 13, Epoch 16/160 (LR 0.09755) => LSC_loss 0.30, Spatial_loss 3.90, Flat_loss 0.36, Train_acc 93.79, Test_acc 53.29
2025-02-13 18:26:15,514 [podnet.py] => Task 13, Epoch 17/160 (LR 0.09724) => LSC_loss 0.31, Spatial_loss 3.97, Flat_loss 0.36, Train_acc 92.98, Test_acc 52.82
2025-02-13 18:26:17,375 [podnet.py] => Task 13, Epoch 18/160 (LR 0.09691) => LSC_loss 0.29, Spatial_loss 3.90, Flat_loss 0.35, Train_acc 94.19, Test_acc 50.66
2025-02-13 18:26:19,210 [podnet.py] => Task 13, Epoch 19/160 (LR 0.09656) => LSC_loss 0.29, Spatial_loss 3.83, Flat_loss 0.35, Train_acc 93.95, Test_acc 45.46
2025-02-13 18:26:21,048 [podnet.py] => Task 13, Epoch 20/160 (LR 0.09619) => LSC_loss 0.30, Spatial_loss 4.08, Flat_loss 0.36, Train_acc 93.95, Test_acc 48.59
2025-02-13 18:26:22,886 [podnet.py] => Task 13, Epoch 21/160 (LR 0.09581) => LSC_loss 0.28, Spatial_loss 4.01, Flat_loss 0.36, Train_acc 94.40, Test_acc 50.63
2025-02-13 18:26:24,722 [podnet.py] => Task 13, Epoch 22/160 (LR 0.09541) => LSC_loss 0.30, Spatial_loss 3.95, Flat_loss 0.36, Train_acc 93.99, Test_acc 48.66
2025-02-13 18:26:26,659 [podnet.py] => Task 13, Epoch 23/160 (LR 0.09499) => LSC_loss 0.28, Spatial_loss 4.04, Flat_loss 0.37, Train_acc 94.44, Test_acc 55.70
2025-02-13 18:26:28,587 [podnet.py] => Task 13, Epoch 24/160 (LR 0.09455) => LSC_loss 0.29, Spatial_loss 3.86, Flat_loss 0.34, Train_acc 94.31, Test_acc 53.03
2025-02-13 18:26:30,477 [podnet.py] => Task 13, Epoch 25/160 (LR 0.09410) => LSC_loss 0.29, Spatial_loss 3.86, Flat_loss 0.34, Train_acc 94.27, Test_acc 50.01
2025-02-13 18:26:32,330 [podnet.py] => Task 13, Epoch 26/160 (LR 0.09362) => LSC_loss 0.27, Spatial_loss 3.74, Flat_loss 0.34, Train_acc 94.96, Test_acc 54.11
2025-02-13 18:26:34,190 [podnet.py] => Task 13, Epoch 27/160 (LR 0.09314) => LSC_loss 0.27, Spatial_loss 3.67, Flat_loss 0.33, Train_acc 94.76, Test_acc 50.74
2025-02-13 18:26:36,067 [podnet.py] => Task 13, Epoch 28/160 (LR 0.09263) => LSC_loss 0.28, Spatial_loss 3.87, Flat_loss 0.34, Train_acc 94.11, Test_acc 52.01
2025-02-13 18:26:37,893 [podnet.py] => Task 13, Epoch 29/160 (LR 0.09211) => LSC_loss 0.29, Spatial_loss 3.75, Flat_loss 0.34, Train_acc 94.23, Test_acc 53.34
2025-02-13 18:26:39,748 [podnet.py] => Task 13, Epoch 30/160 (LR 0.09157) => LSC_loss 0.28, Spatial_loss 3.99, Flat_loss 0.36, Train_acc 94.35, Test_acc 48.66
2025-02-13 18:26:41,569 [podnet.py] => Task 13, Epoch 31/160 (LR 0.09102) => LSC_loss 0.28, Spatial_loss 3.80, Flat_loss 0.35, Train_acc 94.27, Test_acc 52.12
2025-02-13 18:26:43,391 [podnet.py] => Task 13, Epoch 32/160 (LR 0.09045) => LSC_loss 0.28, Spatial_loss 3.69, Flat_loss 0.34, Train_acc 93.71, Test_acc 54.20
2025-02-13 18:26:45,260 [podnet.py] => Task 13, Epoch 33/160 (LR 0.08987) => LSC_loss 0.28, Spatial_loss 3.88, Flat_loss 0.34, Train_acc 94.31, Test_acc 47.72
2025-02-13 18:26:47,139 [podnet.py] => Task 13, Epoch 34/160 (LR 0.08927) => LSC_loss 0.28, Spatial_loss 3.87, Flat_loss 0.36, Train_acc 93.75, Test_acc 54.26
2025-02-13 18:26:48,984 [podnet.py] => Task 13, Epoch 35/160 (LR 0.08865) => LSC_loss 0.27, Spatial_loss 3.93, Flat_loss 0.33, Train_acc 95.32, Test_acc 52.89
2025-02-13 18:26:50,764 [podnet.py] => Task 13, Epoch 36/160 (LR 0.08802) => LSC_loss 0.26, Spatial_loss 3.87, Flat_loss 0.35, Train_acc 94.76, Test_acc 48.47
2025-02-13 18:26:52,623 [podnet.py] => Task 13, Epoch 37/160 (LR 0.08738) => LSC_loss 0.26, Spatial_loss 3.80, Flat_loss 0.35, Train_acc 94.52, Test_acc 51.08
2025-02-13 18:26:54,508 [podnet.py] => Task 13, Epoch 38/160 (LR 0.08672) => LSC_loss 0.27, Spatial_loss 3.79, Flat_loss 0.34, Train_acc 94.48, Test_acc 50.54
2025-02-13 18:26:56,375 [podnet.py] => Task 13, Epoch 39/160 (LR 0.08604) => LSC_loss 0.27, Spatial_loss 3.81, Flat_loss 0.34, Train_acc 94.72, Test_acc 48.64
2025-02-13 18:26:58,231 [podnet.py] => Task 13, Epoch 40/160 (LR 0.08536) => LSC_loss 0.25, Spatial_loss 3.75, Flat_loss 0.33, Train_acc 95.73, Test_acc 52.13
2025-02-13 18:27:00,123 [podnet.py] => Task 13, Epoch 41/160 (LR 0.08465) => LSC_loss 0.26, Spatial_loss 3.74, Flat_loss 0.32, Train_acc 95.16, Test_acc 48.95
2025-02-13 18:27:01,989 [podnet.py] => Task 13, Epoch 42/160 (LR 0.08394) => LSC_loss 0.26, Spatial_loss 3.72, Flat_loss 0.33, Train_acc 94.68, Test_acc 49.82
2025-02-13 18:27:03,833 [podnet.py] => Task 13, Epoch 43/160 (LR 0.08321) => LSC_loss 0.27, Spatial_loss 3.56, Flat_loss 0.31, Train_acc 94.72, Test_acc 51.79
2025-02-13 18:27:05,719 [podnet.py] => Task 13, Epoch 44/160 (LR 0.08247) => LSC_loss 0.25, Spatial_loss 3.57, Flat_loss 0.31, Train_acc 95.52, Test_acc 54.70
2025-02-13 18:27:07,574 [podnet.py] => Task 13, Epoch 45/160 (LR 0.08172) => LSC_loss 0.25, Spatial_loss 3.61, Flat_loss 0.31, Train_acc 95.48, Test_acc 52.93
2025-02-13 18:27:09,472 [podnet.py] => Task 13, Epoch 46/160 (LR 0.08095) => LSC_loss 0.24, Spatial_loss 3.66, Flat_loss 0.31, Train_acc 95.36, Test_acc 50.26
2025-02-13 18:27:11,334 [podnet.py] => Task 13, Epoch 47/160 (LR 0.08018) => LSC_loss 0.24, Spatial_loss 3.58, Flat_loss 0.31, Train_acc 95.40, Test_acc 51.53
2025-02-13 18:27:13,210 [podnet.py] => Task 13, Epoch 48/160 (LR 0.07939) => LSC_loss 0.26, Spatial_loss 3.51, Flat_loss 0.31, Train_acc 94.84, Test_acc 47.00
2025-02-13 18:27:14,996 [podnet.py] => Task 13, Epoch 49/160 (LR 0.07859) => LSC_loss 0.23, Spatial_loss 3.57, Flat_loss 0.31, Train_acc 96.05, Test_acc 53.32
2025-02-13 18:27:16,866 [podnet.py] => Task 13, Epoch 50/160 (LR 0.07778) => LSC_loss 0.26, Spatial_loss 3.48, Flat_loss 0.30, Train_acc 95.28, Test_acc 50.91
2025-02-13 18:27:18,722 [podnet.py] => Task 13, Epoch 51/160 (LR 0.07696) => LSC_loss 0.25, Spatial_loss 3.60, Flat_loss 0.32, Train_acc 95.77, Test_acc 53.39
2025-02-13 18:27:20,548 [podnet.py] => Task 13, Epoch 52/160 (LR 0.07612) => LSC_loss 0.24, Spatial_loss 3.61, Flat_loss 0.33, Train_acc 95.36, Test_acc 53.88
2025-02-13 18:27:22,421 [podnet.py] => Task 13, Epoch 53/160 (LR 0.07528) => LSC_loss 0.26, Spatial_loss 3.53, Flat_loss 0.31, Train_acc 94.84, Test_acc 53.42
2025-02-13 18:27:24,268 [podnet.py] => Task 13, Epoch 54/160 (LR 0.07443) => LSC_loss 0.25, Spatial_loss 3.62, Flat_loss 0.32, Train_acc 95.04, Test_acc 51.01
2025-02-13 18:27:26,121 [podnet.py] => Task 13, Epoch 55/160 (LR 0.07357) => LSC_loss 0.25, Spatial_loss 3.53, Flat_loss 0.30, Train_acc 95.52, Test_acc 50.24
2025-02-13 18:27:27,997 [podnet.py] => Task 13, Epoch 56/160 (LR 0.07270) => LSC_loss 0.25, Spatial_loss 3.52, Flat_loss 0.31, Train_acc 94.96, Test_acc 49.92
2025-02-13 18:27:29,904 [podnet.py] => Task 13, Epoch 57/160 (LR 0.07182) => LSC_loss 0.23, Spatial_loss 3.61, Flat_loss 0.31, Train_acc 95.77, Test_acc 52.57
2025-02-13 18:27:31,797 [podnet.py] => Task 13, Epoch 58/160 (LR 0.07093) => LSC_loss 0.26, Spatial_loss 3.51, Flat_loss 0.30, Train_acc 95.60, Test_acc 51.47
2025-02-13 18:27:33,657 [podnet.py] => Task 13, Epoch 59/160 (LR 0.07004) => LSC_loss 0.24, Spatial_loss 3.58, Flat_loss 0.32, Train_acc 95.28, Test_acc 52.75
2025-02-13 18:27:35,497 [podnet.py] => Task 13, Epoch 60/160 (LR 0.06913) => LSC_loss 0.25, Spatial_loss 3.59, Flat_loss 0.31, Train_acc 95.08, Test_acc 51.96
2025-02-13 18:27:37,336 [podnet.py] => Task 13, Epoch 61/160 (LR 0.06822) => LSC_loss 0.25, Spatial_loss 3.38, Flat_loss 0.30, Train_acc 94.96, Test_acc 53.17
2025-02-13 18:27:39,210 [podnet.py] => Task 13, Epoch 62/160 (LR 0.06731) => LSC_loss 0.23, Spatial_loss 3.39, Flat_loss 0.29, Train_acc 95.85, Test_acc 53.76
2025-02-13 18:27:41,062 [podnet.py] => Task 13, Epoch 63/160 (LR 0.06638) => LSC_loss 0.23, Spatial_loss 3.36, Flat_loss 0.28, Train_acc 95.77, Test_acc 52.89
2025-02-13 18:27:42,930 [podnet.py] => Task 13, Epoch 64/160 (LR 0.06545) => LSC_loss 0.24, Spatial_loss 3.24, Flat_loss 0.28, Train_acc 95.65, Test_acc 54.68
2025-02-13 18:27:44,779 [podnet.py] => Task 13, Epoch 65/160 (LR 0.06451) => LSC_loss 0.23, Spatial_loss 3.25, Flat_loss 0.29, Train_acc 95.44, Test_acc 52.97
2025-02-13 18:27:46,683 [podnet.py] => Task 13, Epoch 66/160 (LR 0.06357) => LSC_loss 0.24, Spatial_loss 3.21, Flat_loss 0.28, Train_acc 95.44, Test_acc 54.46
2025-02-13 18:27:48,532 [podnet.py] => Task 13, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 3.33, Flat_loss 0.28, Train_acc 95.08, Test_acc 52.70
2025-02-13 18:27:50,334 [podnet.py] => Task 13, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 3.34, Flat_loss 0.28, Train_acc 95.81, Test_acc 54.11
2025-02-13 18:27:52,241 [podnet.py] => Task 13, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.20, Flat_loss 0.27, Train_acc 95.56, Test_acc 51.21
2025-02-13 18:27:54,082 [podnet.py] => Task 13, Epoch 70/160 (LR 0.05975) => LSC_loss 0.23, Spatial_loss 3.14, Flat_loss 0.26, Train_acc 95.89, Test_acc 51.75
2025-02-13 18:27:55,871 [podnet.py] => Task 13, Epoch 71/160 (LR 0.05879) => LSC_loss 0.25, Spatial_loss 3.12, Flat_loss 0.27, Train_acc 95.28, Test_acc 52.57
2025-02-13 18:27:57,752 [podnet.py] => Task 13, Epoch 72/160 (LR 0.05782) => LSC_loss 0.22, Spatial_loss 3.23, Flat_loss 0.28, Train_acc 96.21, Test_acc 54.45
2025-02-13 18:27:59,582 [podnet.py] => Task 13, Epoch 73/160 (LR 0.05685) => LSC_loss 0.23, Spatial_loss 3.22, Flat_loss 0.27, Train_acc 96.05, Test_acc 54.13
2025-02-13 18:28:01,463 [podnet.py] => Task 13, Epoch 74/160 (LR 0.05588) => LSC_loss 0.22, Spatial_loss 3.21, Flat_loss 0.27, Train_acc 96.33, Test_acc 55.33
2025-02-13 18:28:03,205 [podnet.py] => Task 13, Epoch 75/160 (LR 0.05490) => LSC_loss 0.23, Spatial_loss 3.12, Flat_loss 0.25, Train_acc 95.65, Test_acc 52.42
2025-02-13 18:28:05,059 [podnet.py] => Task 13, Epoch 76/160 (LR 0.05392) => LSC_loss 0.23, Spatial_loss 3.25, Flat_loss 0.27, Train_acc 96.01, Test_acc 53.17
2025-02-13 18:28:06,916 [podnet.py] => Task 13, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 3.15, Flat_loss 0.26, Train_acc 95.44, Test_acc 54.14
2025-02-13 18:28:08,710 [podnet.py] => Task 13, Epoch 78/160 (LR 0.05196) => LSC_loss 0.25, Spatial_loss 3.10, Flat_loss 0.26, Train_acc 95.73, Test_acc 55.04
2025-02-13 18:28:10,487 [podnet.py] => Task 13, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 3.13, Flat_loss 0.26, Train_acc 95.81, Test_acc 54.70
2025-02-13 18:28:12,247 [podnet.py] => Task 13, Epoch 80/160 (LR 0.05000) => LSC_loss 0.23, Spatial_loss 3.11, Flat_loss 0.25, Train_acc 95.48, Test_acc 53.62
2025-02-13 18:28:14,049 [podnet.py] => Task 13, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 2.99, Flat_loss 0.25, Train_acc 95.65, Test_acc 54.91
2025-02-13 18:28:15,892 [podnet.py] => Task 13, Epoch 82/160 (LR 0.04804) => LSC_loss 0.24, Spatial_loss 2.97, Flat_loss 0.24, Train_acc 95.44, Test_acc 54.89
2025-02-13 18:28:17,767 [podnet.py] => Task 13, Epoch 83/160 (LR 0.04706) => LSC_loss 0.23, Spatial_loss 3.07, Flat_loss 0.25, Train_acc 95.97, Test_acc 53.87
2025-02-13 18:28:19,598 [podnet.py] => Task 13, Epoch 84/160 (LR 0.04608) => LSC_loss 0.24, Spatial_loss 2.96, Flat_loss 0.24, Train_acc 95.81, Test_acc 50.75
2025-02-13 18:28:21,428 [podnet.py] => Task 13, Epoch 85/160 (LR 0.04510) => LSC_loss 0.23, Spatial_loss 2.92, Flat_loss 0.25, Train_acc 96.25, Test_acc 54.75
2025-02-13 18:28:23,245 [podnet.py] => Task 13, Epoch 86/160 (LR 0.04412) => LSC_loss 0.22, Spatial_loss 2.86, Flat_loss 0.24, Train_acc 96.57, Test_acc 54.76
2025-02-13 18:28:25,017 [podnet.py] => Task 13, Epoch 87/160 (LR 0.04315) => LSC_loss 0.23, Spatial_loss 2.84, Flat_loss 0.23, Train_acc 95.81, Test_acc 55.53
2025-02-13 18:28:26,790 [podnet.py] => Task 13, Epoch 88/160 (LR 0.04218) => LSC_loss 0.24, Spatial_loss 2.84, Flat_loss 0.24, Train_acc 95.97, Test_acc 54.09
2025-02-13 18:28:28,648 [podnet.py] => Task 13, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 3.09, Flat_loss 0.26, Train_acc 95.89, Test_acc 55.17
2025-02-13 18:28:30,438 [podnet.py] => Task 13, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 2.95, Flat_loss 0.24, Train_acc 96.21, Test_acc 55.45
2025-02-13 18:28:32,253 [podnet.py] => Task 13, Epoch 91/160 (LR 0.03928) => LSC_loss 0.22, Spatial_loss 2.86, Flat_loss 0.23, Train_acc 96.21, Test_acc 56.61
2025-02-13 18:28:34,059 [podnet.py] => Task 13, Epoch 92/160 (LR 0.03833) => LSC_loss 0.24, Spatial_loss 2.99, Flat_loss 0.24, Train_acc 95.60, Test_acc 51.79
2025-02-13 18:28:35,875 [podnet.py] => Task 13, Epoch 93/160 (LR 0.03738) => LSC_loss 0.22, Spatial_loss 2.94, Flat_loss 0.24, Train_acc 96.01, Test_acc 52.72
2025-02-13 18:28:37,721 [podnet.py] => Task 13, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 2.84, Flat_loss 0.23, Train_acc 96.13, Test_acc 55.00
2025-02-13 18:28:39,536 [podnet.py] => Task 13, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 2.73, Flat_loss 0.23, Train_acc 96.21, Test_acc 55.97
2025-02-13 18:28:41,388 [podnet.py] => Task 13, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 2.72, Flat_loss 0.22, Train_acc 96.37, Test_acc 55.97
2025-02-13 18:28:43,218 [podnet.py] => Task 13, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 2.55, Flat_loss 0.21, Train_acc 96.09, Test_acc 55.37
2025-02-13 18:28:45,039 [podnet.py] => Task 13, Epoch 98/160 (LR 0.03269) => LSC_loss 0.24, Spatial_loss 2.65, Flat_loss 0.21, Train_acc 95.44, Test_acc 55.39
2025-02-13 18:28:46,893 [podnet.py] => Task 13, Epoch 99/160 (LR 0.03178) => LSC_loss 0.21, Spatial_loss 2.57, Flat_loss 0.21, Train_acc 96.45, Test_acc 56.83
2025-02-13 18:28:48,720 [podnet.py] => Task 13, Epoch 100/160 (LR 0.03087) => LSC_loss 0.23, Spatial_loss 2.57, Flat_loss 0.20, Train_acc 95.93, Test_acc 55.00
2025-02-13 18:28:50,524 [podnet.py] => Task 13, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 2.64, Flat_loss 0.22, Train_acc 96.57, Test_acc 55.63
2025-02-13 18:28:52,357 [podnet.py] => Task 13, Epoch 102/160 (LR 0.02907) => LSC_loss 0.23, Spatial_loss 2.64, Flat_loss 0.21, Train_acc 95.60, Test_acc 54.26
2025-02-13 18:28:54,226 [podnet.py] => Task 13, Epoch 103/160 (LR 0.02818) => LSC_loss 0.22, Spatial_loss 2.59, Flat_loss 0.21, Train_acc 96.09, Test_acc 53.96
2025-02-13 18:28:56,004 [podnet.py] => Task 13, Epoch 104/160 (LR 0.02730) => LSC_loss 0.22, Spatial_loss 2.61, Flat_loss 0.21, Train_acc 96.25, Test_acc 55.09
2025-02-13 18:28:57,813 [podnet.py] => Task 13, Epoch 105/160 (LR 0.02643) => LSC_loss 0.24, Spatial_loss 2.39, Flat_loss 0.19, Train_acc 95.73, Test_acc 56.37
2025-02-13 18:28:59,610 [podnet.py] => Task 13, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 2.55, Flat_loss 0.20, Train_acc 96.05, Test_acc 55.42
2025-02-13 18:29:01,456 [podnet.py] => Task 13, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 2.48, Flat_loss 0.20, Train_acc 95.93, Test_acc 55.07
2025-02-13 18:29:03,306 [podnet.py] => Task 13, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 2.47, Flat_loss 0.20, Train_acc 95.85, Test_acc 55.12
2025-02-13 18:29:05,175 [podnet.py] => Task 13, Epoch 109/160 (LR 0.02304) => LSC_loss 0.22, Spatial_loss 2.37, Flat_loss 0.19, Train_acc 95.89, Test_acc 55.78
2025-02-13 18:29:07,010 [podnet.py] => Task 13, Epoch 110/160 (LR 0.02222) => LSC_loss 0.23, Spatial_loss 2.32, Flat_loss 0.19, Train_acc 95.69, Test_acc 55.28
2025-02-13 18:29:08,834 [podnet.py] => Task 13, Epoch 111/160 (LR 0.02141) => LSC_loss 0.22, Spatial_loss 2.33, Flat_loss 0.20, Train_acc 95.81, Test_acc 56.39
2025-02-13 18:29:10,692 [podnet.py] => Task 13, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 2.28, Flat_loss 0.18, Train_acc 96.65, Test_acc 56.17
2025-02-13 18:29:12,534 [podnet.py] => Task 13, Epoch 113/160 (LR 0.01982) => LSC_loss 0.22, Spatial_loss 2.35, Flat_loss 0.18, Train_acc 96.25, Test_acc 55.32
2025-02-13 18:29:14,329 [podnet.py] => Task 13, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 2.29, Flat_loss 0.19, Train_acc 96.41, Test_acc 55.50
2025-02-13 18:29:16,162 [podnet.py] => Task 13, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 2.36, Flat_loss 0.19, Train_acc 96.13, Test_acc 54.67
2025-02-13 18:29:17,995 [podnet.py] => Task 13, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 2.31, Flat_loss 0.18, Train_acc 96.13, Test_acc 56.46
2025-02-13 18:29:19,813 [podnet.py] => Task 13, Epoch 117/160 (LR 0.01679) => LSC_loss 0.23, Spatial_loss 2.29, Flat_loss 0.18, Train_acc 96.01, Test_acc 57.18
2025-02-13 18:29:21,657 [podnet.py] => Task 13, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.18, Train_acc 96.33, Test_acc 55.08
2025-02-13 18:29:23,493 [podnet.py] => Task 13, Epoch 119/160 (LR 0.01535) => LSC_loss 0.23, Spatial_loss 2.12, Flat_loss 0.17, Train_acc 95.65, Test_acc 54.08
2025-02-13 18:29:25,329 [podnet.py] => Task 13, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 2.15, Flat_loss 0.18, Train_acc 96.17, Test_acc 56.64
2025-02-13 18:29:27,120 [podnet.py] => Task 13, Epoch 121/160 (LR 0.01396) => LSC_loss 0.22, Spatial_loss 2.19, Flat_loss 0.18, Train_acc 95.85, Test_acc 56.72
2025-02-13 18:29:28,943 [podnet.py] => Task 13, Epoch 122/160 (LR 0.01328) => LSC_loss 0.22, Spatial_loss 2.10, Flat_loss 0.17, Train_acc 96.37, Test_acc 57.14
2025-02-13 18:29:30,762 [podnet.py] => Task 13, Epoch 123/160 (LR 0.01262) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.18, Train_acc 96.05, Test_acc 55.14
2025-02-13 18:29:32,568 [podnet.py] => Task 13, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 2.07, Flat_loss 0.16, Train_acc 96.37, Test_acc 56.72
2025-02-13 18:29:34,369 [podnet.py] => Task 13, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 2.10, Flat_loss 0.17, Train_acc 95.65, Test_acc 56.00
2025-02-13 18:29:36,148 [podnet.py] => Task 13, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 2.11, Flat_loss 0.17, Train_acc 95.69, Test_acc 57.09
2025-02-13 18:29:37,960 [podnet.py] => Task 13, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 2.11, Flat_loss 0.18, Train_acc 96.05, Test_acc 56.80
2025-02-13 18:29:39,758 [podnet.py] => Task 13, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.17, Train_acc 95.97, Test_acc 56.34
2025-02-13 18:29:41,567 [podnet.py] => Task 13, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 2.02, Flat_loss 0.16, Train_acc 96.25, Test_acc 56.71
2025-02-13 18:29:43,461 [podnet.py] => Task 13, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 1.96, Flat_loss 0.16, Train_acc 95.93, Test_acc 57.38
2025-02-13 18:29:45,325 [podnet.py] => Task 13, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.93, Flat_loss 0.16, Train_acc 95.77, Test_acc 57.16
2025-02-13 18:29:47,216 [podnet.py] => Task 13, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.88, Flat_loss 0.15, Train_acc 95.93, Test_acc 56.64
2025-02-13 18:29:49,050 [podnet.py] => Task 13, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 1.85, Flat_loss 0.15, Train_acc 95.77, Test_acc 56.61
2025-02-13 18:29:50,912 [podnet.py] => Task 13, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 2.00, Flat_loss 0.16, Train_acc 96.05, Test_acc 56.92
2025-02-13 18:29:52,794 [podnet.py] => Task 13, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.95, Flat_loss 0.16, Train_acc 96.45, Test_acc 57.13
2025-02-13 18:29:54,632 [podnet.py] => Task 13, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.90, Flat_loss 0.16, Train_acc 95.97, Test_acc 56.66
2025-02-13 18:29:56,444 [podnet.py] => Task 13, Epoch 137/160 (LR 0.00501) => LSC_loss 0.23, Spatial_loss 1.81, Flat_loss 0.15, Train_acc 95.44, Test_acc 56.86
2025-02-13 18:29:58,340 [podnet.py] => Task 13, Epoch 138/160 (LR 0.00459) => LSC_loss 0.22, Spatial_loss 1.83, Flat_loss 0.16, Train_acc 96.05, Test_acc 56.79
2025-02-13 18:30:00,255 [podnet.py] => Task 13, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.82, Flat_loss 0.15, Train_acc 96.53, Test_acc 57.33
2025-02-13 18:30:02,108 [podnet.py] => Task 13, Epoch 140/160 (LR 0.00381) => LSC_loss 0.23, Spatial_loss 1.82, Flat_loss 0.15, Train_acc 96.05, Test_acc 57.41
2025-02-13 18:30:03,983 [podnet.py] => Task 13, Epoch 141/160 (LR 0.00344) => LSC_loss 0.23, Spatial_loss 1.82, Flat_loss 0.15, Train_acc 96.01, Test_acc 57.13
2025-02-13 18:30:05,827 [podnet.py] => Task 13, Epoch 142/160 (LR 0.00309) => LSC_loss 0.22, Spatial_loss 1.74, Flat_loss 0.15, Train_acc 96.41, Test_acc 56.89
2025-02-13 18:30:07,700 [podnet.py] => Task 13, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 1.82, Flat_loss 0.16, Train_acc 96.01, Test_acc 56.96
2025-02-13 18:30:09,529 [podnet.py] => Task 13, Epoch 144/160 (LR 0.00245) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.15, Train_acc 95.40, Test_acc 57.16
2025-02-13 18:30:11,376 [podnet.py] => Task 13, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 95.44, Test_acc 57.34
2025-02-13 18:30:13,273 [podnet.py] => Task 13, Epoch 146/160 (LR 0.00188) => LSC_loss 0.22, Spatial_loss 1.67, Flat_loss 0.15, Train_acc 96.17, Test_acc 57.43
2025-02-13 18:30:15,181 [podnet.py] => Task 13, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.71, Flat_loss 0.15, Train_acc 96.05, Test_acc 57.26
2025-02-13 18:30:17,064 [podnet.py] => Task 13, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 1.76, Flat_loss 0.15, Train_acc 96.01, Test_acc 57.58
2025-02-13 18:30:18,887 [podnet.py] => Task 13, Epoch 149/160 (LR 0.00116) => LSC_loss 0.24, Spatial_loss 1.74, Flat_loss 0.15, Train_acc 95.77, Test_acc 57.63
2025-02-13 18:30:20,759 [podnet.py] => Task 13, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 1.72, Flat_loss 0.15, Train_acc 95.81, Test_acc 57.41
2025-02-13 18:30:22,588 [podnet.py] => Task 13, Epoch 151/160 (LR 0.00078) => LSC_loss 0.23, Spatial_loss 1.73, Flat_loss 0.15, Train_acc 95.93, Test_acc 57.59
2025-02-13 18:30:24,483 [podnet.py] => Task 13, Epoch 152/160 (LR 0.00062) => LSC_loss 0.21, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 96.94, Test_acc 57.32
2025-02-13 18:30:26,296 [podnet.py] => Task 13, Epoch 153/160 (LR 0.00047) => LSC_loss 0.22, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 96.29, Test_acc 57.38
2025-02-13 18:30:28,161 [podnet.py] => Task 13, Epoch 154/160 (LR 0.00035) => LSC_loss 0.22, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 96.25, Test_acc 57.38
2025-02-13 18:30:30,002 [podnet.py] => Task 13, Epoch 155/160 (LR 0.00024) => LSC_loss 0.23, Spatial_loss 1.61, Flat_loss 0.14, Train_acc 95.77, Test_acc 57.61
2025-02-13 18:30:31,895 [podnet.py] => Task 13, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.68, Flat_loss 0.15, Train_acc 95.85, Test_acc 57.39
2025-02-13 18:30:33,733 [podnet.py] => Task 13, Epoch 157/160 (LR 0.00009) => LSC_loss 0.23, Spatial_loss 1.68, Flat_loss 0.15, Train_acc 95.93, Test_acc 57.33
2025-02-13 18:30:35,513 [podnet.py] => Task 13, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.70, Flat_loss 0.15, Train_acc 96.29, Test_acc 57.30
2025-02-13 18:30:37,346 [podnet.py] => Task 13, Epoch 159/160 (LR 0.00001) => LSC_loss 0.22, Spatial_loss 1.69, Flat_loss 0.15, Train_acc 96.37, Test_acc 57.34
2025-02-13 18:30:39,201 [podnet.py] => Task 13, Epoch 160/160 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.72, Flat_loss 0.15, Train_acc 96.37, Test_acc 57.64
2025-02-13 18:30:39,202 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:30:39,202 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:31:02,786 [podnet.py] => The size of finetune dataset: 1520
2025-02-13 18:31:04,366 [podnet.py] => Task 13, Epoch 1/20 (LR 0.00497) => LSC_loss 0.13, Spatial_loss 2.03, Flat_loss 0.14, Train_acc 97.57, Test_acc 56.39
2025-02-13 18:31:05,906 [podnet.py] => Task 13, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 1.88, Flat_loss 0.09, Train_acc 98.55, Test_acc 57.57
2025-02-13 18:31:07,466 [podnet.py] => Task 13, Epoch 3/20 (LR 0.00473) => LSC_loss 0.09, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 98.75, Test_acc 58.09
2025-02-13 18:31:09,084 [podnet.py] => Task 13, Epoch 4/20 (LR 0.00452) => LSC_loss 0.09, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.75, Test_acc 58.57
2025-02-13 18:31:10,692 [podnet.py] => Task 13, Epoch 5/20 (LR 0.00427) => LSC_loss 0.09, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 98.88, Test_acc 58.20
2025-02-13 18:31:12,292 [podnet.py] => Task 13, Epoch 6/20 (LR 0.00397) => LSC_loss 0.09, Spatial_loss 1.85, Flat_loss 0.06, Train_acc 98.82, Test_acc 58.70
2025-02-13 18:31:13,923 [podnet.py] => Task 13, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 99.01, Test_acc 58.41
2025-02-13 18:31:15,506 [podnet.py] => Task 13, Epoch 8/20 (LR 0.00327) => LSC_loss 0.09, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 98.68, Test_acc 58.55
2025-02-13 18:31:17,101 [podnet.py] => Task 13, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 1.79, Flat_loss 0.06, Train_acc 98.75, Test_acc 58.72
2025-02-13 18:31:18,742 [podnet.py] => Task 13, Epoch 10/20 (LR 0.00250) => LSC_loss 0.08, Spatial_loss 1.61, Flat_loss 0.05, Train_acc 99.21, Test_acc 58.39
2025-02-13 18:31:20,295 [podnet.py] => Task 13, Epoch 11/20 (LR 0.00211) => LSC_loss 0.09, Spatial_loss 1.65, Flat_loss 0.06, Train_acc 98.88, Test_acc 58.22
2025-02-13 18:31:21,855 [podnet.py] => Task 13, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 99.01, Test_acc 58.83
2025-02-13 18:31:23,461 [podnet.py] => Task 13, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 1.56, Flat_loss 0.06, Train_acc 98.82, Test_acc 58.61
2025-02-13 18:31:25,050 [podnet.py] => Task 13, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 1.62, Flat_loss 0.05, Train_acc 98.75, Test_acc 58.51
2025-02-13 18:31:26,558 [podnet.py] => Task 13, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 98.75, Test_acc 58.47
2025-02-13 18:31:28,140 [podnet.py] => Task 13, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 1.55, Flat_loss 0.05, Train_acc 98.22, Test_acc 58.53
2025-02-13 18:31:29,722 [podnet.py] => Task 13, Epoch 17/20 (LR 0.00027) => LSC_loss 0.08, Spatial_loss 1.66, Flat_loss 0.06, Train_acc 98.95, Test_acc 58.43
2025-02-13 18:31:31,314 [podnet.py] => Task 13, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 1.61, Flat_loss 0.06, Train_acc 98.95, Test_acc 58.41
2025-02-13 18:31:32,873 [podnet.py] => Task 13, Epoch 19/20 (LR 0.00003) => LSC_loss 0.09, Spatial_loss 1.56, Flat_loss 0.05, Train_acc 98.95, Test_acc 58.37
2025-02-13 18:31:34,446 [podnet.py] => Task 13, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 1.62, Flat_loss 0.05, Train_acc 98.95, Test_acc 58.47
2025-02-13 18:31:34,447 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:32:00,761 [podnet.py] => Exemplar size: 1520
2025-02-13 18:32:00,761 [trainer.py] => CNN: {'total': 58.47, '00-09': 66.6, '10-19': 47.4, '20-29': 64.3, '30-39': 55.8, '40-49': 63.7, '50-59': 48.1, '60-69': 58.3, '70-79': 67.0, 'old': 58.41, 'new': 61.0}
2025-02-13 18:32:00,761 [trainer.py] => NME: {'total': 58.7, '00-09': 69.4, '10-19': 51.9, '20-29': 67.7, '30-39': 56.6, '40-49': 64.5, '50-59': 42.3, '60-69': 54.4, '70-79': 65.5, 'old': 58.57, 'new': 63.5}
2025-02-13 18:32:00,761 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47]
2025-02-13 18:32:00,761 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68]
2025-02-13 18:32:00,762 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7]
2025-02-13 18:32:00,762 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13]

2025-02-13 18:32:00,762 [trainer.py] => Average Accuracy (CNN): 66.46714285714286
2025-02-13 18:32:00,762 [trainer.py] => Average Accuracy (NME): 66.71714285714286
2025-02-13 18:32:00,762 [trainer.py] => All params: 514897
2025-02-13 18:32:00,762 [trainer.py] => Trainable params: 514897
2025-02-13 18:32:00,763 [podnet.py] => Learning on 76-78
2025-02-13 18:32:00,784 [podnet.py] => Adaptive factor: 6.244997998398398
2025-02-13 18:32:02,449 [podnet.py] => Task 14, Epoch 1/160 (LR 0.09999) => LSC_loss 1.33, Spatial_loss 4.39, Flat_loss 0.66, Train_acc 80.12, Test_acc 45.05
2025-02-13 18:32:04,181 [podnet.py] => Task 14, Epoch 2/160 (LR 0.09996) => LSC_loss 0.38, Spatial_loss 4.87, Flat_loss 0.55, Train_acc 90.24, Test_acc 51.12
2025-02-13 18:32:05,874 [podnet.py] => Task 14, Epoch 3/160 (LR 0.09991) => LSC_loss 0.34, Spatial_loss 4.88, Flat_loss 0.50, Train_acc 90.83, Test_acc 49.28
2025-02-13 18:32:07,568 [podnet.py] => Task 14, Epoch 4/160 (LR 0.09985) => LSC_loss 0.31, Spatial_loss 4.65, Flat_loss 0.47, Train_acc 92.02, Test_acc 46.54
2025-02-13 18:32:09,260 [podnet.py] => Task 14, Epoch 5/160 (LR 0.09976) => LSC_loss 0.31, Spatial_loss 4.47, Flat_loss 0.43, Train_acc 92.54, Test_acc 50.63
2025-02-13 18:32:10,987 [podnet.py] => Task 14, Epoch 6/160 (LR 0.09965) => LSC_loss 0.28, Spatial_loss 4.56, Flat_loss 0.44, Train_acc 93.29, Test_acc 47.13
2025-02-13 18:32:12,659 [podnet.py] => Task 14, Epoch 7/160 (LR 0.09953) => LSC_loss 0.32, Spatial_loss 4.60, Flat_loss 0.44, Train_acc 92.18, Test_acc 49.69
2025-02-13 18:32:14,325 [podnet.py] => Task 14, Epoch 8/160 (LR 0.09938) => LSC_loss 0.28, Spatial_loss 4.48, Flat_loss 0.43, Train_acc 93.06, Test_acc 50.44
2025-02-13 18:32:16,080 [podnet.py] => Task 14, Epoch 9/160 (LR 0.09922) => LSC_loss 0.26, Spatial_loss 4.27, Flat_loss 0.38, Train_acc 93.57, Test_acc 51.00
2025-02-13 18:32:17,759 [podnet.py] => Task 14, Epoch 10/160 (LR 0.09904) => LSC_loss 0.27, Spatial_loss 4.22, Flat_loss 0.37, Train_acc 93.77, Test_acc 51.91
2025-02-13 18:32:19,400 [podnet.py] => Task 14, Epoch 11/160 (LR 0.09884) => LSC_loss 0.24, Spatial_loss 4.41, Flat_loss 0.39, Train_acc 94.76, Test_acc 49.37
2025-02-13 18:32:20,986 [podnet.py] => Task 14, Epoch 12/160 (LR 0.09862) => LSC_loss 0.26, Spatial_loss 4.28, Flat_loss 0.37, Train_acc 94.01, Test_acc 47.29
2025-02-13 18:32:22,694 [podnet.py] => Task 14, Epoch 13/160 (LR 0.09838) => LSC_loss 0.25, Spatial_loss 4.41, Flat_loss 0.38, Train_acc 94.09, Test_acc 51.06
2025-02-13 18:32:24,385 [podnet.py] => Task 14, Epoch 14/160 (LR 0.09812) => LSC_loss 0.28, Spatial_loss 4.46, Flat_loss 0.39, Train_acc 94.13, Test_acc 50.49
2025-02-13 18:32:26,063 [podnet.py] => Task 14, Epoch 15/160 (LR 0.09785) => LSC_loss 0.26, Spatial_loss 4.34, Flat_loss 0.39, Train_acc 94.05, Test_acc 47.17
2025-02-13 18:32:27,731 [podnet.py] => Task 14, Epoch 16/160 (LR 0.09755) => LSC_loss 0.25, Spatial_loss 4.29, Flat_loss 0.39, Train_acc 93.93, Test_acc 50.82
2025-02-13 18:32:29,434 [podnet.py] => Task 14, Epoch 17/160 (LR 0.09724) => LSC_loss 0.24, Spatial_loss 4.07, Flat_loss 0.34, Train_acc 94.52, Test_acc 52.82
2025-02-13 18:32:31,137 [podnet.py] => Task 14, Epoch 18/160 (LR 0.09691) => LSC_loss 0.23, Spatial_loss 4.06, Flat_loss 0.35, Train_acc 94.84, Test_acc 50.92
2025-02-13 18:32:32,819 [podnet.py] => Task 14, Epoch 19/160 (LR 0.09656) => LSC_loss 0.24, Spatial_loss 4.12, Flat_loss 0.34, Train_acc 95.40, Test_acc 49.31
2025-02-13 18:32:34,471 [podnet.py] => Task 14, Epoch 20/160 (LR 0.09619) => LSC_loss 0.24, Spatial_loss 4.20, Flat_loss 0.35, Train_acc 95.08, Test_acc 51.97
2025-02-13 18:32:36,169 [podnet.py] => Task 14, Epoch 21/160 (LR 0.09581) => LSC_loss 0.24, Spatial_loss 4.21, Flat_loss 0.34, Train_acc 94.33, Test_acc 46.35
2025-02-13 18:32:37,850 [podnet.py] => Task 14, Epoch 22/160 (LR 0.09541) => LSC_loss 0.24, Spatial_loss 4.09, Flat_loss 0.35, Train_acc 94.80, Test_acc 54.00
2025-02-13 18:32:39,503 [podnet.py] => Task 14, Epoch 23/160 (LR 0.09499) => LSC_loss 0.23, Spatial_loss 4.04, Flat_loss 0.34, Train_acc 95.36, Test_acc 48.95
2025-02-13 18:32:41,123 [podnet.py] => Task 14, Epoch 24/160 (LR 0.09455) => LSC_loss 0.24, Spatial_loss 3.97, Flat_loss 0.34, Train_acc 94.84, Test_acc 54.45
2025-02-13 18:32:42,784 [podnet.py] => Task 14, Epoch 25/160 (LR 0.09410) => LSC_loss 0.22, Spatial_loss 3.91, Flat_loss 0.31, Train_acc 95.91, Test_acc 48.67
2025-02-13 18:32:44,399 [podnet.py] => Task 14, Epoch 26/160 (LR 0.09362) => LSC_loss 0.24, Spatial_loss 4.04, Flat_loss 0.35, Train_acc 94.92, Test_acc 47.55
2025-02-13 18:32:46,077 [podnet.py] => Task 14, Epoch 27/160 (LR 0.09314) => LSC_loss 0.25, Spatial_loss 4.22, Flat_loss 0.36, Train_acc 94.80, Test_acc 51.81
2025-02-13 18:32:47,772 [podnet.py] => Task 14, Epoch 28/160 (LR 0.09263) => LSC_loss 0.22, Spatial_loss 4.09, Flat_loss 0.33, Train_acc 95.36, Test_acc 49.56
2025-02-13 18:32:49,490 [podnet.py] => Task 14, Epoch 29/160 (LR 0.09211) => LSC_loss 0.22, Spatial_loss 3.93, Flat_loss 0.31, Train_acc 95.48, Test_acc 53.60
2025-02-13 18:32:51,130 [podnet.py] => Task 14, Epoch 30/160 (LR 0.09157) => LSC_loss 0.23, Spatial_loss 3.76, Flat_loss 0.31, Train_acc 95.67, Test_acc 50.31
2025-02-13 18:32:52,709 [podnet.py] => Task 14, Epoch 31/160 (LR 0.09102) => LSC_loss 0.24, Spatial_loss 3.81, Flat_loss 0.31, Train_acc 95.20, Test_acc 51.19
2025-02-13 18:32:54,362 [podnet.py] => Task 14, Epoch 32/160 (LR 0.09045) => LSC_loss 0.23, Spatial_loss 3.87, Flat_loss 0.32, Train_acc 95.20, Test_acc 50.74
2025-02-13 18:32:56,016 [podnet.py] => Task 14, Epoch 33/160 (LR 0.08987) => LSC_loss 0.22, Spatial_loss 3.95, Flat_loss 0.32, Train_acc 95.60, Test_acc 53.79
2025-02-13 18:32:57,687 [podnet.py] => Task 14, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 3.84, Flat_loss 0.31, Train_acc 95.32, Test_acc 51.53
2025-02-13 18:32:59,315 [podnet.py] => Task 14, Epoch 35/160 (LR 0.08865) => LSC_loss 0.22, Spatial_loss 3.86, Flat_loss 0.31, Train_acc 95.08, Test_acc 50.41
2025-02-13 18:33:00,968 [podnet.py] => Task 14, Epoch 36/160 (LR 0.08802) => LSC_loss 0.21, Spatial_loss 3.90, Flat_loss 0.32, Train_acc 95.99, Test_acc 49.54
2025-02-13 18:33:02,629 [podnet.py] => Task 14, Epoch 37/160 (LR 0.08738) => LSC_loss 0.24, Spatial_loss 4.03, Flat_loss 0.32, Train_acc 95.04, Test_acc 51.13
2025-02-13 18:33:04,249 [podnet.py] => Task 14, Epoch 38/160 (LR 0.08672) => LSC_loss 0.24, Spatial_loss 3.96, Flat_loss 0.33, Train_acc 94.96, Test_acc 54.09
2025-02-13 18:33:05,865 [podnet.py] => Task 14, Epoch 39/160 (LR 0.08604) => LSC_loss 0.23, Spatial_loss 3.83, Flat_loss 0.32, Train_acc 95.12, Test_acc 51.04
2025-02-13 18:33:07,541 [podnet.py] => Task 14, Epoch 40/160 (LR 0.08536) => LSC_loss 0.23, Spatial_loss 3.86, Flat_loss 0.31, Train_acc 95.24, Test_acc 51.47
2025-02-13 18:33:09,183 [podnet.py] => Task 14, Epoch 41/160 (LR 0.08465) => LSC_loss 0.24, Spatial_loss 3.93, Flat_loss 0.32, Train_acc 94.84, Test_acc 52.10
2025-02-13 18:33:10,869 [podnet.py] => Task 14, Epoch 42/160 (LR 0.08394) => LSC_loss 0.21, Spatial_loss 3.81, Flat_loss 0.30, Train_acc 95.91, Test_acc 52.09
2025-02-13 18:33:12,573 [podnet.py] => Task 14, Epoch 43/160 (LR 0.08321) => LSC_loss 0.21, Spatial_loss 3.63, Flat_loss 0.28, Train_acc 95.24, Test_acc 52.38
2025-02-13 18:33:14,213 [podnet.py] => Task 14, Epoch 44/160 (LR 0.08247) => LSC_loss 0.21, Spatial_loss 3.64, Flat_loss 0.29, Train_acc 95.79, Test_acc 50.95
2025-02-13 18:33:15,881 [podnet.py] => Task 14, Epoch 45/160 (LR 0.08172) => LSC_loss 0.21, Spatial_loss 3.65, Flat_loss 0.28, Train_acc 96.07, Test_acc 51.81
2025-02-13 18:33:17,548 [podnet.py] => Task 14, Epoch 46/160 (LR 0.08095) => LSC_loss 0.23, Spatial_loss 3.80, Flat_loss 0.30, Train_acc 95.32, Test_acc 55.60
2025-02-13 18:33:19,213 [podnet.py] => Task 14, Epoch 47/160 (LR 0.08018) => LSC_loss 0.22, Spatial_loss 3.58, Flat_loss 0.29, Train_acc 95.36, Test_acc 52.32
2025-02-13 18:33:20,935 [podnet.py] => Task 14, Epoch 48/160 (LR 0.07939) => LSC_loss 0.21, Spatial_loss 3.65, Flat_loss 0.29, Train_acc 95.91, Test_acc 53.41
2025-02-13 18:33:22,580 [podnet.py] => Task 14, Epoch 49/160 (LR 0.07859) => LSC_loss 0.24, Spatial_loss 3.71, Flat_loss 0.30, Train_acc 94.33, Test_acc 52.59
2025-02-13 18:33:24,270 [podnet.py] => Task 14, Epoch 50/160 (LR 0.07778) => LSC_loss 0.22, Spatial_loss 3.60, Flat_loss 0.30, Train_acc 95.56, Test_acc 51.86
2025-02-13 18:33:25,923 [podnet.py] => Task 14, Epoch 51/160 (LR 0.07696) => LSC_loss 0.21, Spatial_loss 3.66, Flat_loss 0.28, Train_acc 96.19, Test_acc 50.63
2025-02-13 18:33:27,630 [podnet.py] => Task 14, Epoch 52/160 (LR 0.07612) => LSC_loss 0.21, Spatial_loss 3.62, Flat_loss 0.27, Train_acc 96.19, Test_acc 54.27
2025-02-13 18:33:29,269 [podnet.py] => Task 14, Epoch 53/160 (LR 0.07528) => LSC_loss 0.21, Spatial_loss 3.54, Flat_loss 0.27, Train_acc 95.67, Test_acc 55.09
2025-02-13 18:33:30,941 [podnet.py] => Task 14, Epoch 54/160 (LR 0.07443) => LSC_loss 0.22, Spatial_loss 3.68, Flat_loss 0.29, Train_acc 95.44, Test_acc 49.64
2025-02-13 18:33:32,620 [podnet.py] => Task 14, Epoch 55/160 (LR 0.07357) => LSC_loss 0.21, Spatial_loss 3.52, Flat_loss 0.27, Train_acc 96.23, Test_acc 49.54
2025-02-13 18:33:34,322 [podnet.py] => Task 14, Epoch 56/160 (LR 0.07270) => LSC_loss 0.21, Spatial_loss 3.53, Flat_loss 0.26, Train_acc 95.71, Test_acc 50.78
2025-02-13 18:33:35,996 [podnet.py] => Task 14, Epoch 57/160 (LR 0.07182) => LSC_loss 0.21, Spatial_loss 3.52, Flat_loss 0.27, Train_acc 95.83, Test_acc 51.55
2025-02-13 18:33:37,702 [podnet.py] => Task 14, Epoch 58/160 (LR 0.07093) => LSC_loss 0.22, Spatial_loss 3.59, Flat_loss 0.28, Train_acc 95.08, Test_acc 52.53
2025-02-13 18:33:39,312 [podnet.py] => Task 14, Epoch 59/160 (LR 0.07004) => LSC_loss 0.21, Spatial_loss 3.43, Flat_loss 0.27, Train_acc 95.99, Test_acc 52.13
2025-02-13 18:33:40,971 [podnet.py] => Task 14, Epoch 60/160 (LR 0.06913) => LSC_loss 0.21, Spatial_loss 3.50, Flat_loss 0.27, Train_acc 95.67, Test_acc 53.17
2025-02-13 18:33:42,596 [podnet.py] => Task 14, Epoch 61/160 (LR 0.06822) => LSC_loss 0.21, Spatial_loss 3.55, Flat_loss 0.27, Train_acc 96.11, Test_acc 54.51
2025-02-13 18:33:44,266 [podnet.py] => Task 14, Epoch 62/160 (LR 0.06731) => LSC_loss 0.21, Spatial_loss 3.49, Flat_loss 0.26, Train_acc 95.79, Test_acc 50.81
2025-02-13 18:33:46,008 [podnet.py] => Task 14, Epoch 63/160 (LR 0.06638) => LSC_loss 0.21, Spatial_loss 3.47, Flat_loss 0.27, Train_acc 95.83, Test_acc 52.74
2025-02-13 18:33:47,708 [podnet.py] => Task 14, Epoch 64/160 (LR 0.06545) => LSC_loss 0.22, Spatial_loss 3.39, Flat_loss 0.25, Train_acc 95.44, Test_acc 52.64
2025-02-13 18:33:49,368 [podnet.py] => Task 14, Epoch 65/160 (LR 0.06451) => LSC_loss 0.20, Spatial_loss 3.35, Flat_loss 0.25, Train_acc 96.23, Test_acc 53.01
2025-02-13 18:33:51,076 [podnet.py] => Task 14, Epoch 66/160 (LR 0.06357) => LSC_loss 0.21, Spatial_loss 3.31, Flat_loss 0.26, Train_acc 95.79, Test_acc 52.82
2025-02-13 18:33:52,732 [podnet.py] => Task 14, Epoch 67/160 (LR 0.06262) => LSC_loss 0.20, Spatial_loss 3.21, Flat_loss 0.25, Train_acc 96.15, Test_acc 51.21
2025-02-13 18:33:54,378 [podnet.py] => Task 14, Epoch 68/160 (LR 0.06167) => LSC_loss 0.21, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 95.63, Test_acc 52.65
2025-02-13 18:33:56,013 [podnet.py] => Task 14, Epoch 69/160 (LR 0.06072) => LSC_loss 0.22, Spatial_loss 3.56, Flat_loss 0.27, Train_acc 95.79, Test_acc 52.76
2025-02-13 18:33:57,683 [podnet.py] => Task 14, Epoch 70/160 (LR 0.05975) => LSC_loss 0.19, Spatial_loss 3.35, Flat_loss 0.25, Train_acc 96.55, Test_acc 51.62
2025-02-13 18:33:59,352 [podnet.py] => Task 14, Epoch 71/160 (LR 0.05879) => LSC_loss 0.20, Spatial_loss 3.15, Flat_loss 0.24, Train_acc 96.27, Test_acc 52.40
2025-02-13 18:34:01,010 [podnet.py] => Task 14, Epoch 72/160 (LR 0.05782) => LSC_loss 0.21, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 95.60, Test_acc 51.82
2025-02-13 18:34:02,678 [podnet.py] => Task 14, Epoch 73/160 (LR 0.05685) => LSC_loss 0.21, Spatial_loss 3.20, Flat_loss 0.24, Train_acc 96.23, Test_acc 53.15
2025-02-13 18:34:04,337 [podnet.py] => Task 14, Epoch 74/160 (LR 0.05588) => LSC_loss 0.20, Spatial_loss 3.20, Flat_loss 0.24, Train_acc 96.43, Test_acc 51.72
2025-02-13 18:34:06,029 [podnet.py] => Task 14, Epoch 75/160 (LR 0.05490) => LSC_loss 0.20, Spatial_loss 3.17, Flat_loss 0.23, Train_acc 96.27, Test_acc 55.24
2025-02-13 18:34:07,671 [podnet.py] => Task 14, Epoch 76/160 (LR 0.05392) => LSC_loss 0.20, Spatial_loss 3.07, Flat_loss 0.23, Train_acc 96.11, Test_acc 52.97
2025-02-13 18:34:09,335 [podnet.py] => Task 14, Epoch 77/160 (LR 0.05294) => LSC_loss 0.20, Spatial_loss 3.16, Flat_loss 0.24, Train_acc 96.35, Test_acc 53.54
2025-02-13 18:34:11,013 [podnet.py] => Task 14, Epoch 78/160 (LR 0.05196) => LSC_loss 0.20, Spatial_loss 3.08, Flat_loss 0.22, Train_acc 96.19, Test_acc 54.71
2025-02-13 18:34:12,712 [podnet.py] => Task 14, Epoch 79/160 (LR 0.05098) => LSC_loss 0.20, Spatial_loss 3.15, Flat_loss 0.22, Train_acc 96.07, Test_acc 55.17
2025-02-13 18:34:14,340 [podnet.py] => Task 14, Epoch 80/160 (LR 0.05000) => LSC_loss 0.20, Spatial_loss 2.99, Flat_loss 0.21, Train_acc 95.95, Test_acc 54.78
2025-02-13 18:34:16,019 [podnet.py] => Task 14, Epoch 81/160 (LR 0.04902) => LSC_loss 0.19, Spatial_loss 3.01, Flat_loss 0.22, Train_acc 96.27, Test_acc 51.64
2025-02-13 18:34:17,726 [podnet.py] => Task 14, Epoch 82/160 (LR 0.04804) => LSC_loss 0.20, Spatial_loss 3.00, Flat_loss 0.21, Train_acc 96.27, Test_acc 52.94
2025-02-13 18:34:19,394 [podnet.py] => Task 14, Epoch 83/160 (LR 0.04706) => LSC_loss 0.19, Spatial_loss 2.94, Flat_loss 0.21, Train_acc 96.63, Test_acc 53.77
2025-02-13 18:34:21,077 [podnet.py] => Task 14, Epoch 84/160 (LR 0.04608) => LSC_loss 0.21, Spatial_loss 2.96, Flat_loss 0.21, Train_acc 95.79, Test_acc 54.71
2025-02-13 18:34:22,775 [podnet.py] => Task 14, Epoch 85/160 (LR 0.04510) => LSC_loss 0.19, Spatial_loss 2.92, Flat_loss 0.21, Train_acc 96.07, Test_acc 53.86
2025-02-13 18:34:24,463 [podnet.py] => Task 14, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 2.88, Flat_loss 0.21, Train_acc 96.07, Test_acc 53.42
2025-02-13 18:34:26,166 [podnet.py] => Task 14, Epoch 87/160 (LR 0.04315) => LSC_loss 0.21, Spatial_loss 2.95, Flat_loss 0.21, Train_acc 96.27, Test_acc 51.90
2025-02-13 18:34:27,850 [podnet.py] => Task 14, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 2.97, Flat_loss 0.20, Train_acc 95.63, Test_acc 53.62
2025-02-13 18:34:29,510 [podnet.py] => Task 14, Epoch 89/160 (LR 0.04121) => LSC_loss 0.21, Spatial_loss 2.87, Flat_loss 0.20, Train_acc 95.48, Test_acc 54.90
2025-02-13 18:34:31,184 [podnet.py] => Task 14, Epoch 90/160 (LR 0.04025) => LSC_loss 0.19, Spatial_loss 2.96, Flat_loss 0.21, Train_acc 96.35, Test_acc 49.95
2025-02-13 18:34:32,853 [podnet.py] => Task 14, Epoch 91/160 (LR 0.03928) => LSC_loss 0.20, Spatial_loss 2.95, Flat_loss 0.21, Train_acc 96.31, Test_acc 52.35
2025-02-13 18:34:34,534 [podnet.py] => Task 14, Epoch 92/160 (LR 0.03833) => LSC_loss 0.19, Spatial_loss 3.04, Flat_loss 0.21, Train_acc 96.39, Test_acc 53.53
2025-02-13 18:34:36,249 [podnet.py] => Task 14, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 2.85, Flat_loss 0.19, Train_acc 96.47, Test_acc 51.67
2025-02-13 18:34:37,921 [podnet.py] => Task 14, Epoch 94/160 (LR 0.03643) => LSC_loss 0.20, Spatial_loss 2.72, Flat_loss 0.19, Train_acc 96.23, Test_acc 51.92
2025-02-13 18:34:39,492 [podnet.py] => Task 14, Epoch 95/160 (LR 0.03549) => LSC_loss 0.20, Spatial_loss 2.80, Flat_loss 0.20, Train_acc 96.27, Test_acc 52.22
2025-02-13 18:34:41,123 [podnet.py] => Task 14, Epoch 96/160 (LR 0.03455) => LSC_loss 0.20, Spatial_loss 2.79, Flat_loss 0.19, Train_acc 96.03, Test_acc 55.06
2025-02-13 18:34:42,799 [podnet.py] => Task 14, Epoch 97/160 (LR 0.03362) => LSC_loss 0.19, Spatial_loss 2.73, Flat_loss 0.20, Train_acc 96.67, Test_acc 53.28
2025-02-13 18:34:44,459 [podnet.py] => Task 14, Epoch 98/160 (LR 0.03269) => LSC_loss 0.19, Spatial_loss 2.74, Flat_loss 0.18, Train_acc 96.35, Test_acc 54.06
2025-02-13 18:34:46,099 [podnet.py] => Task 14, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 2.72, Flat_loss 0.19, Train_acc 96.11, Test_acc 53.29
2025-02-13 18:34:47,762 [podnet.py] => Task 14, Epoch 100/160 (LR 0.03087) => LSC_loss 0.20, Spatial_loss 2.67, Flat_loss 0.19, Train_acc 96.07, Test_acc 52.13
2025-02-13 18:34:49,492 [podnet.py] => Task 14, Epoch 101/160 (LR 0.02996) => LSC_loss 0.19, Spatial_loss 2.70, Flat_loss 0.18, Train_acc 96.39, Test_acc 55.71
2025-02-13 18:34:51,154 [podnet.py] => Task 14, Epoch 102/160 (LR 0.02907) => LSC_loss 0.20, Spatial_loss 2.55, Flat_loss 0.18, Train_acc 96.03, Test_acc 54.27
2025-02-13 18:34:52,890 [podnet.py] => Task 14, Epoch 103/160 (LR 0.02818) => LSC_loss 0.19, Spatial_loss 2.60, Flat_loss 0.18, Train_acc 96.87, Test_acc 54.41
2025-02-13 18:34:54,556 [podnet.py] => Task 14, Epoch 104/160 (LR 0.02730) => LSC_loss 0.21, Spatial_loss 2.66, Flat_loss 0.18, Train_acc 95.83, Test_acc 55.53
2025-02-13 18:34:56,153 [podnet.py] => Task 14, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 2.59, Flat_loss 0.18, Train_acc 96.59, Test_acc 53.01
2025-02-13 18:34:57,820 [podnet.py] => Task 14, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 2.57, Flat_loss 0.17, Train_acc 96.71, Test_acc 54.82
2025-02-13 18:34:59,494 [podnet.py] => Task 14, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 2.54, Flat_loss 0.17, Train_acc 96.19, Test_acc 54.91
2025-02-13 18:35:01,176 [podnet.py] => Task 14, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 2.57, Flat_loss 0.17, Train_acc 96.35, Test_acc 54.88
2025-02-13 18:35:02,883 [podnet.py] => Task 14, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 2.64, Flat_loss 0.18, Train_acc 95.95, Test_acc 55.13
2025-02-13 18:35:04,522 [podnet.py] => Task 14, Epoch 110/160 (LR 0.02222) => LSC_loss 0.20, Spatial_loss 2.48, Flat_loss 0.17, Train_acc 95.83, Test_acc 54.37
2025-02-13 18:35:06,242 [podnet.py] => Task 14, Epoch 111/160 (LR 0.02141) => LSC_loss 0.19, Spatial_loss 2.44, Flat_loss 0.16, Train_acc 96.59, Test_acc 55.59
2025-02-13 18:35:07,871 [podnet.py] => Task 14, Epoch 112/160 (LR 0.02061) => LSC_loss 0.20, Spatial_loss 2.31, Flat_loss 0.15, Train_acc 96.39, Test_acc 55.45
2025-02-13 18:35:09,536 [podnet.py] => Task 14, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 2.41, Flat_loss 0.17, Train_acc 96.35, Test_acc 54.63
2025-02-13 18:35:11,262 [podnet.py] => Task 14, Epoch 114/160 (LR 0.01905) => LSC_loss 0.20, Spatial_loss 2.33, Flat_loss 0.16, Train_acc 96.51, Test_acc 53.26
2025-02-13 18:35:12,886 [podnet.py] => Task 14, Epoch 115/160 (LR 0.01828) => LSC_loss 0.19, Spatial_loss 2.35, Flat_loss 0.16, Train_acc 96.39, Test_acc 54.73
2025-02-13 18:35:14,569 [podnet.py] => Task 14, Epoch 116/160 (LR 0.01753) => LSC_loss 0.19, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 96.75, Test_acc 54.45
2025-02-13 18:35:16,289 [podnet.py] => Task 14, Epoch 117/160 (LR 0.01679) => LSC_loss 0.19, Spatial_loss 2.28, Flat_loss 0.16, Train_acc 96.63, Test_acc 56.03
2025-02-13 18:35:17,977 [podnet.py] => Task 14, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 96.63, Test_acc 55.28
2025-02-13 18:35:19,633 [podnet.py] => Task 14, Epoch 119/160 (LR 0.01535) => LSC_loss 0.19, Spatial_loss 2.25, Flat_loss 0.15, Train_acc 96.71, Test_acc 55.92
2025-02-13 18:35:21,330 [podnet.py] => Task 14, Epoch 120/160 (LR 0.01464) => LSC_loss 0.19, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 96.67, Test_acc 54.44
2025-02-13 18:35:22,993 [podnet.py] => Task 14, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 2.24, Flat_loss 0.16, Train_acc 96.31, Test_acc 55.19
2025-02-13 18:35:24,707 [podnet.py] => Task 14, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 2.17, Flat_loss 0.15, Train_acc 96.63, Test_acc 55.35
2025-02-13 18:35:26,402 [podnet.py] => Task 14, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 2.03, Flat_loss 0.14, Train_acc 96.35, Test_acc 56.01
2025-02-13 18:35:28,081 [podnet.py] => Task 14, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 96.83, Test_acc 55.72
2025-02-13 18:35:29,740 [podnet.py] => Task 14, Epoch 125/160 (LR 0.01135) => LSC_loss 0.19, Spatial_loss 2.17, Flat_loss 0.15, Train_acc 96.35, Test_acc 55.21
2025-02-13 18:35:31,386 [podnet.py] => Task 14, Epoch 126/160 (LR 0.01073) => LSC_loss 0.20, Spatial_loss 2.09, Flat_loss 0.14, Train_acc 96.03, Test_acc 55.65
2025-02-13 18:35:33,059 [podnet.py] => Task 14, Epoch 127/160 (LR 0.01013) => LSC_loss 0.19, Spatial_loss 2.16, Flat_loss 0.14, Train_acc 96.63, Test_acc 54.56
2025-02-13 18:35:34,705 [podnet.py] => Task 14, Epoch 128/160 (LR 0.00955) => LSC_loss 0.20, Spatial_loss 2.08, Flat_loss 0.13, Train_acc 96.03, Test_acc 55.31
2025-02-13 18:35:36,345 [podnet.py] => Task 14, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 2.14, Flat_loss 0.15, Train_acc 97.14, Test_acc 54.82
2025-02-13 18:35:37,992 [podnet.py] => Task 14, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 96.59, Test_acc 56.06
2025-02-13 18:35:39,665 [podnet.py] => Task 14, Epoch 131/160 (LR 0.00789) => LSC_loss 0.19, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 96.43, Test_acc 54.68
2025-02-13 18:35:41,332 [podnet.py] => Task 14, Epoch 132/160 (LR 0.00737) => LSC_loss 0.20, Spatial_loss 1.99, Flat_loss 0.14, Train_acc 96.51, Test_acc 56.14
2025-02-13 18:35:43,000 [podnet.py] => Task 14, Epoch 133/160 (LR 0.00686) => LSC_loss 0.19, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 96.27, Test_acc 56.35
2025-02-13 18:35:44,677 [podnet.py] => Task 14, Epoch 134/160 (LR 0.00638) => LSC_loss 0.19, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 96.63, Test_acc 55.49
2025-02-13 18:35:46,373 [podnet.py] => Task 14, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 95.67, Test_acc 55.69
2025-02-13 18:35:48,075 [podnet.py] => Task 14, Epoch 136/160 (LR 0.00545) => LSC_loss 0.19, Spatial_loss 1.93, Flat_loss 0.13, Train_acc 96.51, Test_acc 55.67
2025-02-13 18:35:49,730 [podnet.py] => Task 14, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 96.15, Test_acc 55.62
2025-02-13 18:35:51,432 [podnet.py] => Task 14, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.91, Flat_loss 0.13, Train_acc 95.95, Test_acc 55.55
2025-02-13 18:35:53,148 [podnet.py] => Task 14, Epoch 139/160 (LR 0.00419) => LSC_loss 0.20, Spatial_loss 1.92, Flat_loss 0.14, Train_acc 96.07, Test_acc 55.79
2025-02-13 18:35:54,827 [podnet.py] => Task 14, Epoch 140/160 (LR 0.00381) => LSC_loss 0.19, Spatial_loss 1.92, Flat_loss 0.13, Train_acc 96.35, Test_acc 55.74
2025-02-13 18:35:56,470 [podnet.py] => Task 14, Epoch 141/160 (LR 0.00344) => LSC_loss 0.19, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 96.59, Test_acc 55.63
2025-02-13 18:35:58,099 [podnet.py] => Task 14, Epoch 142/160 (LR 0.00309) => LSC_loss 0.18, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 96.63, Test_acc 56.29
2025-02-13 18:35:59,823 [podnet.py] => Task 14, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 95.71, Test_acc 56.38
2025-02-13 18:36:01,472 [podnet.py] => Task 14, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 96.55, Test_acc 55.99
2025-02-13 18:36:03,152 [podnet.py] => Task 14, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.80, Flat_loss 0.12, Train_acc 96.15, Test_acc 56.06
2025-02-13 18:36:04,826 [podnet.py] => Task 14, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.19, Test_acc 56.29
2025-02-13 18:36:06,513 [podnet.py] => Task 14, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.86, Flat_loss 0.12, Train_acc 96.47, Test_acc 56.45
2025-02-13 18:36:08,173 [podnet.py] => Task 14, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 96.31, Test_acc 56.04
2025-02-13 18:36:09,838 [podnet.py] => Task 14, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.68, Flat_loss 0.12, Train_acc 96.27, Test_acc 56.19
2025-02-13 18:36:11,531 [podnet.py] => Task 14, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.64, Flat_loss 0.12, Train_acc 96.63, Test_acc 55.97
2025-02-13 18:36:13,246 [podnet.py] => Task 14, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 96.43, Test_acc 56.15
2025-02-13 18:36:14,923 [podnet.py] => Task 14, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 95.95, Test_acc 56.08
2025-02-13 18:36:16,599 [podnet.py] => Task 14, Epoch 153/160 (LR 0.00047) => LSC_loss 0.19, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 96.39, Test_acc 56.13
2025-02-13 18:36:18,309 [podnet.py] => Task 14, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.07, Test_acc 56.09
2025-02-13 18:36:19,906 [podnet.py] => Task 14, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 95.95, Test_acc 55.86
2025-02-13 18:36:21,559 [podnet.py] => Task 14, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.68, Flat_loss 0.12, Train_acc 96.59, Test_acc 56.21
2025-02-13 18:36:23,196 [podnet.py] => Task 14, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.75, Flat_loss 0.12, Train_acc 96.31, Test_acc 56.23
2025-02-13 18:36:24,823 [podnet.py] => Task 14, Epoch 158/160 (LR 0.00004) => LSC_loss 0.19, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 96.35, Test_acc 55.99
2025-02-13 18:36:26,447 [podnet.py] => Task 14, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 96.15, Test_acc 56.21
2025-02-13 18:36:28,094 [podnet.py] => Task 14, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 96.51, Test_acc 56.01
2025-02-13 18:36:28,095 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:36:28,095 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:36:52,788 [podnet.py] => The size of finetune dataset: 1560
2025-02-13 18:36:54,252 [podnet.py] => Task 14, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 2.15, Flat_loss 0.17, Train_acc 96.54, Test_acc 53.50
2025-02-13 18:36:55,718 [podnet.py] => Task 14, Epoch 2/20 (LR 0.00488) => LSC_loss 0.11, Spatial_loss 1.89, Flat_loss 0.10, Train_acc 98.27, Test_acc 55.85
2025-02-13 18:36:57,213 [podnet.py] => Task 14, Epoch 3/20 (LR 0.00473) => LSC_loss 0.10, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 99.17, Test_acc 56.68
2025-02-13 18:36:58,651 [podnet.py] => Task 14, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 1.97, Flat_loss 0.08, Train_acc 98.91, Test_acc 56.60
2025-02-13 18:37:00,099 [podnet.py] => Task 14, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 1.97, Flat_loss 0.09, Train_acc 98.46, Test_acc 57.10
2025-02-13 18:37:01,539 [podnet.py] => Task 14, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 99.23, Test_acc 56.53
2025-02-13 18:37:03,049 [podnet.py] => Task 14, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 98.97, Test_acc 57.03
2025-02-13 18:37:04,457 [podnet.py] => Task 14, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.77, Flat_loss 0.07, Train_acc 98.97, Test_acc 56.68
2025-02-13 18:37:05,920 [podnet.py] => Task 14, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 99.04, Test_acc 57.12
2025-02-13 18:37:07,406 [podnet.py] => Task 14, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 1.91, Flat_loss 0.07, Train_acc 98.40, Test_acc 57.17
2025-02-13 18:37:08,844 [podnet.py] => Task 14, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 98.72, Test_acc 57.19
2025-02-13 18:37:10,309 [podnet.py] => Task 14, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 99.10, Test_acc 56.77
2025-02-13 18:37:11,749 [podnet.py] => Task 14, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 98.97, Test_acc 57.21
2025-02-13 18:37:13,187 [podnet.py] => Task 14, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 1.76, Flat_loss 0.07, Train_acc 99.10, Test_acc 56.91
2025-02-13 18:37:14,644 [podnet.py] => Task 14, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 98.72, Test_acc 57.28
2025-02-13 18:37:16,122 [podnet.py] => Task 14, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 1.72, Flat_loss 0.07, Train_acc 99.04, Test_acc 57.21
2025-02-13 18:37:17,579 [podnet.py] => Task 14, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 98.53, Test_acc 57.21
2025-02-13 18:37:19,008 [podnet.py] => Task 14, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 1.73, Flat_loss 0.07, Train_acc 99.23, Test_acc 56.88
2025-02-13 18:37:20,566 [podnet.py] => Task 14, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 1.77, Flat_loss 0.07, Train_acc 99.04, Test_acc 57.09
2025-02-13 18:37:22,025 [podnet.py] => Task 14, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 99.17, Test_acc 57.29
2025-02-13 18:37:22,026 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:37:48,201 [podnet.py] => Exemplar size: 1560
2025-02-13 18:37:48,201 [trainer.py] => CNN: {'total': 57.29, '00-09': 66.2, '10-19': 47.2, '20-29': 64.8, '30-39': 55.3, '40-49': 61.5, '50-59': 45.2, '60-69': 57.0, '70-79': 62.12, 'old': 57.32, 'new': 56.5}
2025-02-13 18:37:48,201 [trainer.py] => NME: {'total': 57.65, '00-09': 68.5, '10-19': 51.9, '20-29': 67.9, '30-39': 56.2, '40-49': 62.5, '50-59': 39.5, '60-69': 53.9, '70-79': 61.62, 'old': 57.66, 'new': 57.5}
2025-02-13 18:37:48,201 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29]
2025-02-13 18:37:48,201 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6]
2025-02-13 18:37:48,201 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65]
2025-02-13 18:37:48,201 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74]

2025-02-13 18:37:48,201 [trainer.py] => Average Accuracy (CNN): 65.85533333333333
2025-02-13 18:37:48,201 [trainer.py] => Average Accuracy (NME): 66.11266666666667
2025-02-13 18:37:48,202 [trainer.py] => All params: 516177
2025-02-13 18:37:48,202 [trainer.py] => Trainable params: 516177
2025-02-13 18:37:48,203 [podnet.py] => Learning on 78-80
2025-02-13 18:37:48,224 [podnet.py] => Adaptive factor: 6.324555320336759
2025-02-13 18:37:49,985 [podnet.py] => Task 15, Epoch 1/160 (LR 0.09999) => LSC_loss 1.37, Spatial_loss 4.29, Flat_loss 0.61, Train_acc 78.59, Test_acc 44.85
2025-02-13 18:37:51,687 [podnet.py] => Task 15, Epoch 2/160 (LR 0.09996) => LSC_loss 0.41, Spatial_loss 4.79, Flat_loss 0.52, Train_acc 89.65, Test_acc 50.18
2025-02-13 18:37:53,365 [podnet.py] => Task 15, Epoch 3/160 (LR 0.09991) => LSC_loss 0.40, Spatial_loss 4.80, Flat_loss 0.50, Train_acc 90.82, Test_acc 50.00
2025-02-13 18:37:55,076 [podnet.py] => Task 15, Epoch 4/160 (LR 0.09985) => LSC_loss 0.37, Spatial_loss 4.64, Flat_loss 0.45, Train_acc 91.13, Test_acc 49.69
2025-02-13 18:37:56,725 [podnet.py] => Task 15, Epoch 5/160 (LR 0.09976) => LSC_loss 0.38, Spatial_loss 4.55, Flat_loss 0.42, Train_acc 91.13, Test_acc 49.21
2025-02-13 18:37:58,440 [podnet.py] => Task 15, Epoch 6/160 (LR 0.09965) => LSC_loss 0.38, Spatial_loss 4.79, Flat_loss 0.45, Train_acc 91.91, Test_acc 43.28
2025-02-13 18:38:00,180 [podnet.py] => Task 15, Epoch 7/160 (LR 0.09953) => LSC_loss 0.36, Spatial_loss 4.70, Flat_loss 0.43, Train_acc 92.42, Test_acc 46.90
2025-02-13 18:38:01,858 [podnet.py] => Task 15, Epoch 8/160 (LR 0.09938) => LSC_loss 0.35, Spatial_loss 4.52, Flat_loss 0.42, Train_acc 92.73, Test_acc 49.99
2025-02-13 18:38:03,579 [podnet.py] => Task 15, Epoch 9/160 (LR 0.09922) => LSC_loss 0.32, Spatial_loss 4.49, Flat_loss 0.40, Train_acc 93.52, Test_acc 51.04
2025-02-13 18:38:05,265 [podnet.py] => Task 15, Epoch 10/160 (LR 0.09904) => LSC_loss 0.33, Spatial_loss 4.45, Flat_loss 0.39, Train_acc 92.93, Test_acc 50.15
2025-02-13 18:38:06,944 [podnet.py] => Task 15, Epoch 11/160 (LR 0.09884) => LSC_loss 0.32, Spatial_loss 4.43, Flat_loss 0.39, Train_acc 93.28, Test_acc 49.00
2025-02-13 18:38:08,591 [podnet.py] => Task 15, Epoch 12/160 (LR 0.09862) => LSC_loss 0.32, Spatial_loss 4.24, Flat_loss 0.37, Train_acc 93.36, Test_acc 45.98
2025-02-13 18:38:10,264 [podnet.py] => Task 15, Epoch 13/160 (LR 0.09838) => LSC_loss 0.31, Spatial_loss 4.32, Flat_loss 0.37, Train_acc 93.67, Test_acc 47.74
2025-02-13 18:38:11,963 [podnet.py] => Task 15, Epoch 14/160 (LR 0.09812) => LSC_loss 0.31, Spatial_loss 4.29, Flat_loss 0.38, Train_acc 93.24, Test_acc 46.49
2025-02-13 18:38:13,667 [podnet.py] => Task 15, Epoch 15/160 (LR 0.09785) => LSC_loss 0.31, Spatial_loss 4.30, Flat_loss 0.36, Train_acc 93.32, Test_acc 47.81
2025-02-13 18:38:15,321 [podnet.py] => Task 15, Epoch 16/160 (LR 0.09755) => LSC_loss 0.30, Spatial_loss 4.31, Flat_loss 0.38, Train_acc 93.55, Test_acc 48.84
2025-02-13 18:38:17,036 [podnet.py] => Task 15, Epoch 17/160 (LR 0.09724) => LSC_loss 0.31, Spatial_loss 4.31, Flat_loss 0.37, Train_acc 93.40, Test_acc 40.66
2025-02-13 18:38:18,733 [podnet.py] => Task 15, Epoch 18/160 (LR 0.09691) => LSC_loss 0.29, Spatial_loss 4.18, Flat_loss 0.36, Train_acc 94.22, Test_acc 49.14
2025-02-13 18:38:20,467 [podnet.py] => Task 15, Epoch 19/160 (LR 0.09656) => LSC_loss 0.29, Spatial_loss 4.23, Flat_loss 0.36, Train_acc 93.91, Test_acc 47.74
2025-02-13 18:38:22,099 [podnet.py] => Task 15, Epoch 20/160 (LR 0.09619) => LSC_loss 0.28, Spatial_loss 4.21, Flat_loss 0.35, Train_acc 94.49, Test_acc 45.58
2025-02-13 18:38:23,835 [podnet.py] => Task 15, Epoch 21/160 (LR 0.09581) => LSC_loss 0.30, Spatial_loss 4.28, Flat_loss 0.37, Train_acc 93.83, Test_acc 51.69
2025-02-13 18:38:25,474 [podnet.py] => Task 15, Epoch 22/160 (LR 0.09541) => LSC_loss 0.29, Spatial_loss 4.19, Flat_loss 0.36, Train_acc 94.65, Test_acc 48.44
2025-02-13 18:38:27,130 [podnet.py] => Task 15, Epoch 23/160 (LR 0.09499) => LSC_loss 0.28, Spatial_loss 4.24, Flat_loss 0.35, Train_acc 94.38, Test_acc 49.95
2025-02-13 18:38:28,851 [podnet.py] => Task 15, Epoch 24/160 (LR 0.09455) => LSC_loss 0.27, Spatial_loss 4.13, Flat_loss 0.33, Train_acc 95.20, Test_acc 50.04
2025-02-13 18:38:30,533 [podnet.py] => Task 15, Epoch 25/160 (LR 0.09410) => LSC_loss 0.27, Spatial_loss 3.90, Flat_loss 0.32, Train_acc 95.12, Test_acc 52.90
2025-02-13 18:38:32,238 [podnet.py] => Task 15, Epoch 26/160 (LR 0.09362) => LSC_loss 0.29, Spatial_loss 4.07, Flat_loss 0.34, Train_acc 93.75, Test_acc 46.69
2025-02-13 18:38:33,945 [podnet.py] => Task 15, Epoch 27/160 (LR 0.09314) => LSC_loss 0.28, Spatial_loss 4.06, Flat_loss 0.33, Train_acc 94.69, Test_acc 51.30
2025-02-13 18:38:35,671 [podnet.py] => Task 15, Epoch 28/160 (LR 0.09263) => LSC_loss 0.26, Spatial_loss 4.01, Flat_loss 0.33, Train_acc 95.47, Test_acc 50.34
2025-02-13 18:38:37,309 [podnet.py] => Task 15, Epoch 29/160 (LR 0.09211) => LSC_loss 0.26, Spatial_loss 3.89, Flat_loss 0.31, Train_acc 94.77, Test_acc 47.46
2025-02-13 18:38:38,985 [podnet.py] => Task 15, Epoch 30/160 (LR 0.09157) => LSC_loss 0.26, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 94.77, Test_acc 49.59
2025-02-13 18:38:40,673 [podnet.py] => Task 15, Epoch 31/160 (LR 0.09102) => LSC_loss 0.27, Spatial_loss 3.91, Flat_loss 0.32, Train_acc 94.84, Test_acc 52.12
2025-02-13 18:38:42,377 [podnet.py] => Task 15, Epoch 32/160 (LR 0.09045) => LSC_loss 0.26, Spatial_loss 3.82, Flat_loss 0.31, Train_acc 95.04, Test_acc 52.45
2025-02-13 18:38:44,029 [podnet.py] => Task 15, Epoch 33/160 (LR 0.08987) => LSC_loss 0.27, Spatial_loss 3.88, Flat_loss 0.31, Train_acc 94.10, Test_acc 50.18
2025-02-13 18:38:45,665 [podnet.py] => Task 15, Epoch 34/160 (LR 0.08927) => LSC_loss 0.27, Spatial_loss 3.77, Flat_loss 0.31, Train_acc 95.04, Test_acc 52.40
2025-02-13 18:38:47,294 [podnet.py] => Task 15, Epoch 35/160 (LR 0.08865) => LSC_loss 0.26, Spatial_loss 3.71, Flat_loss 0.30, Train_acc 95.08, Test_acc 51.88
2025-02-13 18:38:49,022 [podnet.py] => Task 15, Epoch 36/160 (LR 0.08802) => LSC_loss 0.26, Spatial_loss 3.75, Flat_loss 0.29, Train_acc 94.57, Test_acc 46.51
2025-02-13 18:38:50,687 [podnet.py] => Task 15, Epoch 37/160 (LR 0.08738) => LSC_loss 0.26, Spatial_loss 3.99, Flat_loss 0.30, Train_acc 95.47, Test_acc 48.39
2025-02-13 18:38:52,371 [podnet.py] => Task 15, Epoch 38/160 (LR 0.08672) => LSC_loss 0.26, Spatial_loss 3.80, Flat_loss 0.30, Train_acc 95.35, Test_acc 49.94
2025-02-13 18:38:54,066 [podnet.py] => Task 15, Epoch 39/160 (LR 0.08604) => LSC_loss 0.27, Spatial_loss 3.74, Flat_loss 0.30, Train_acc 94.53, Test_acc 51.94
2025-02-13 18:38:55,688 [podnet.py] => Task 15, Epoch 40/160 (LR 0.08536) => LSC_loss 0.25, Spatial_loss 3.77, Flat_loss 0.29, Train_acc 95.55, Test_acc 50.11
2025-02-13 18:38:57,365 [podnet.py] => Task 15, Epoch 41/160 (LR 0.08465) => LSC_loss 0.26, Spatial_loss 3.70, Flat_loss 0.30, Train_acc 94.69, Test_acc 50.69
2025-02-13 18:38:59,039 [podnet.py] => Task 15, Epoch 42/160 (LR 0.08394) => LSC_loss 0.27, Spatial_loss 3.67, Flat_loss 0.29, Train_acc 94.49, Test_acc 51.56
2025-02-13 18:39:00,758 [podnet.py] => Task 15, Epoch 43/160 (LR 0.08321) => LSC_loss 0.25, Spatial_loss 3.85, Flat_loss 0.31, Train_acc 95.51, Test_acc 51.42
2025-02-13 18:39:02,538 [podnet.py] => Task 15, Epoch 44/160 (LR 0.08247) => LSC_loss 0.25, Spatial_loss 3.72, Flat_loss 0.29, Train_acc 95.31, Test_acc 51.19
2025-02-13 18:39:04,215 [podnet.py] => Task 15, Epoch 45/160 (LR 0.08172) => LSC_loss 0.26, Spatial_loss 3.71, Flat_loss 0.29, Train_acc 95.31, Test_acc 51.12
2025-02-13 18:39:05,910 [podnet.py] => Task 15, Epoch 46/160 (LR 0.08095) => LSC_loss 0.25, Spatial_loss 3.68, Flat_loss 0.29, Train_acc 95.70, Test_acc 51.39
2025-02-13 18:39:07,628 [podnet.py] => Task 15, Epoch 47/160 (LR 0.08018) => LSC_loss 0.27, Spatial_loss 3.75, Flat_loss 0.30, Train_acc 94.96, Test_acc 51.48
2025-02-13 18:39:09,271 [podnet.py] => Task 15, Epoch 48/160 (LR 0.07939) => LSC_loss 0.25, Spatial_loss 3.66, Flat_loss 0.29, Train_acc 95.59, Test_acc 50.22
2025-02-13 18:39:10,929 [podnet.py] => Task 15, Epoch 49/160 (LR 0.07859) => LSC_loss 0.25, Spatial_loss 3.65, Flat_loss 0.29, Train_acc 95.39, Test_acc 51.64
2025-02-13 18:39:12,599 [podnet.py] => Task 15, Epoch 50/160 (LR 0.07778) => LSC_loss 0.27, Spatial_loss 3.75, Flat_loss 0.29, Train_acc 94.65, Test_acc 48.81
2025-02-13 18:39:14,294 [podnet.py] => Task 15, Epoch 51/160 (LR 0.07696) => LSC_loss 0.25, Spatial_loss 3.88, Flat_loss 0.31, Train_acc 95.20, Test_acc 53.05
2025-02-13 18:39:15,941 [podnet.py] => Task 15, Epoch 52/160 (LR 0.07612) => LSC_loss 0.24, Spatial_loss 3.59, Flat_loss 0.27, Train_acc 95.62, Test_acc 51.89
2025-02-13 18:39:17,641 [podnet.py] => Task 15, Epoch 53/160 (LR 0.07528) => LSC_loss 0.25, Spatial_loss 3.62, Flat_loss 0.27, Train_acc 95.59, Test_acc 48.25
2025-02-13 18:39:19,305 [podnet.py] => Task 15, Epoch 54/160 (LR 0.07443) => LSC_loss 0.25, Spatial_loss 3.56, Flat_loss 0.27, Train_acc 95.39, Test_acc 51.31
2025-02-13 18:39:21,025 [podnet.py] => Task 15, Epoch 55/160 (LR 0.07357) => LSC_loss 0.24, Spatial_loss 3.54, Flat_loss 0.27, Train_acc 95.55, Test_acc 50.12
2025-02-13 18:39:22,670 [podnet.py] => Task 15, Epoch 56/160 (LR 0.07270) => LSC_loss 0.24, Spatial_loss 3.43, Flat_loss 0.26, Train_acc 95.90, Test_acc 52.96
2025-02-13 18:39:24,355 [podnet.py] => Task 15, Epoch 57/160 (LR 0.07182) => LSC_loss 0.25, Spatial_loss 3.64, Flat_loss 0.28, Train_acc 95.51, Test_acc 48.50
2025-02-13 18:39:26,019 [podnet.py] => Task 15, Epoch 58/160 (LR 0.07093) => LSC_loss 0.25, Spatial_loss 3.68, Flat_loss 0.28, Train_acc 94.65, Test_acc 49.32
2025-02-13 18:39:27,721 [podnet.py] => Task 15, Epoch 59/160 (LR 0.07004) => LSC_loss 0.24, Spatial_loss 3.51, Flat_loss 0.27, Train_acc 95.47, Test_acc 52.46
2025-02-13 18:39:29,418 [podnet.py] => Task 15, Epoch 60/160 (LR 0.06913) => LSC_loss 0.23, Spatial_loss 3.36, Flat_loss 0.26, Train_acc 96.41, Test_acc 51.88
2025-02-13 18:39:31,144 [podnet.py] => Task 15, Epoch 61/160 (LR 0.06822) => LSC_loss 0.25, Spatial_loss 3.56, Flat_loss 0.26, Train_acc 95.12, Test_acc 50.86
2025-02-13 18:39:32,816 [podnet.py] => Task 15, Epoch 62/160 (LR 0.06731) => LSC_loss 0.24, Spatial_loss 3.39, Flat_loss 0.25, Train_acc 95.78, Test_acc 49.76
2025-02-13 18:39:34,537 [podnet.py] => Task 15, Epoch 63/160 (LR 0.06638) => LSC_loss 0.23, Spatial_loss 3.37, Flat_loss 0.26, Train_acc 96.29, Test_acc 52.05
2025-02-13 18:39:36,246 [podnet.py] => Task 15, Epoch 64/160 (LR 0.06545) => LSC_loss 0.24, Spatial_loss 3.34, Flat_loss 0.26, Train_acc 95.31, Test_acc 50.06
2025-02-13 18:39:37,965 [podnet.py] => Task 15, Epoch 65/160 (LR 0.06451) => LSC_loss 0.24, Spatial_loss 3.39, Flat_loss 0.26, Train_acc 95.98, Test_acc 52.25
2025-02-13 18:39:39,688 [podnet.py] => Task 15, Epoch 66/160 (LR 0.06357) => LSC_loss 0.26, Spatial_loss 3.60, Flat_loss 0.26, Train_acc 94.69, Test_acc 48.59
2025-02-13 18:39:41,378 [podnet.py] => Task 15, Epoch 67/160 (LR 0.06262) => LSC_loss 0.23, Spatial_loss 3.42, Flat_loss 0.26, Train_acc 95.94, Test_acc 51.74
2025-02-13 18:39:43,029 [podnet.py] => Task 15, Epoch 68/160 (LR 0.06167) => LSC_loss 0.24, Spatial_loss 3.32, Flat_loss 0.25, Train_acc 95.70, Test_acc 51.41
2025-02-13 18:39:44,689 [podnet.py] => Task 15, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 95.62, Test_acc 48.09
2025-02-13 18:39:46,425 [podnet.py] => Task 15, Epoch 70/160 (LR 0.05975) => LSC_loss 0.23, Spatial_loss 3.30, Flat_loss 0.24, Train_acc 95.70, Test_acc 49.46
2025-02-13 18:39:48,106 [podnet.py] => Task 15, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 3.27, Flat_loss 0.24, Train_acc 96.25, Test_acc 54.35
2025-02-13 18:39:49,784 [podnet.py] => Task 15, Epoch 72/160 (LR 0.05782) => LSC_loss 0.23, Spatial_loss 3.13, Flat_loss 0.23, Train_acc 95.59, Test_acc 50.28
2025-02-13 18:39:51,403 [podnet.py] => Task 15, Epoch 73/160 (LR 0.05685) => LSC_loss 0.23, Spatial_loss 3.04, Flat_loss 0.22, Train_acc 96.17, Test_acc 51.79
2025-02-13 18:39:53,101 [podnet.py] => Task 15, Epoch 74/160 (LR 0.05588) => LSC_loss 0.25, Spatial_loss 3.28, Flat_loss 0.23, Train_acc 95.55, Test_acc 50.95
2025-02-13 18:39:54,762 [podnet.py] => Task 15, Epoch 75/160 (LR 0.05490) => LSC_loss 0.24, Spatial_loss 3.28, Flat_loss 0.23, Train_acc 95.55, Test_acc 50.80
2025-02-13 18:39:56,459 [podnet.py] => Task 15, Epoch 76/160 (LR 0.05392) => LSC_loss 0.23, Spatial_loss 3.26, Flat_loss 0.23, Train_acc 95.78, Test_acc 53.46
2025-02-13 18:39:58,146 [podnet.py] => Task 15, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 3.22, Flat_loss 0.23, Train_acc 95.16, Test_acc 50.24
2025-02-13 18:39:59,793 [podnet.py] => Task 15, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 3.13, Flat_loss 0.23, Train_acc 95.90, Test_acc 49.96
2025-02-13 18:40:01,521 [podnet.py] => Task 15, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 3.14, Flat_loss 0.22, Train_acc 96.52, Test_acc 53.36
2025-02-13 18:40:03,188 [podnet.py] => Task 15, Epoch 80/160 (LR 0.05000) => LSC_loss 0.24, Spatial_loss 3.15, Flat_loss 0.23, Train_acc 95.55, Test_acc 49.16
2025-02-13 18:40:04,871 [podnet.py] => Task 15, Epoch 81/160 (LR 0.04902) => LSC_loss 0.24, Spatial_loss 3.30, Flat_loss 0.23, Train_acc 95.62, Test_acc 51.10
2025-02-13 18:40:06,548 [podnet.py] => Task 15, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 3.13, Flat_loss 0.22, Train_acc 96.21, Test_acc 53.22
2025-02-13 18:40:08,263 [podnet.py] => Task 15, Epoch 83/160 (LR 0.04706) => LSC_loss 0.22, Spatial_loss 2.92, Flat_loss 0.21, Train_acc 96.17, Test_acc 52.61
2025-02-13 18:40:09,954 [podnet.py] => Task 15, Epoch 84/160 (LR 0.04608) => LSC_loss 0.23, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 96.21, Test_acc 52.79
2025-02-13 18:40:11,627 [podnet.py] => Task 15, Epoch 85/160 (LR 0.04510) => LSC_loss 0.22, Spatial_loss 2.77, Flat_loss 0.20, Train_acc 95.94, Test_acc 52.04
2025-02-13 18:40:13,325 [podnet.py] => Task 15, Epoch 86/160 (LR 0.04412) => LSC_loss 0.23, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 96.02, Test_acc 48.79
2025-02-13 18:40:15,037 [podnet.py] => Task 15, Epoch 87/160 (LR 0.04315) => LSC_loss 0.23, Spatial_loss 2.96, Flat_loss 0.20, Train_acc 96.29, Test_acc 53.50
2025-02-13 18:40:16,694 [podnet.py] => Task 15, Epoch 88/160 (LR 0.04218) => LSC_loss 0.23, Spatial_loss 3.04, Flat_loss 0.22, Train_acc 95.74, Test_acc 53.02
2025-02-13 18:40:18,419 [podnet.py] => Task 15, Epoch 89/160 (LR 0.04121) => LSC_loss 0.23, Spatial_loss 2.95, Flat_loss 0.21, Train_acc 96.13, Test_acc 52.48
2025-02-13 18:40:20,097 [podnet.py] => Task 15, Epoch 90/160 (LR 0.04025) => LSC_loss 0.22, Spatial_loss 2.93, Flat_loss 0.21, Train_acc 96.45, Test_acc 52.15
2025-02-13 18:40:21,743 [podnet.py] => Task 15, Epoch 91/160 (LR 0.03928) => LSC_loss 0.22, Spatial_loss 2.83, Flat_loss 0.20, Train_acc 96.48, Test_acc 53.25
2025-02-13 18:40:23,457 [podnet.py] => Task 15, Epoch 92/160 (LR 0.03833) => LSC_loss 0.23, Spatial_loss 2.90, Flat_loss 0.20, Train_acc 95.86, Test_acc 51.39
2025-02-13 18:40:25,068 [podnet.py] => Task 15, Epoch 93/160 (LR 0.03738) => LSC_loss 0.22, Spatial_loss 2.79, Flat_loss 0.19, Train_acc 96.17, Test_acc 52.94
2025-02-13 18:40:26,734 [podnet.py] => Task 15, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 2.79, Flat_loss 0.20, Train_acc 96.17, Test_acc 51.49
2025-02-13 18:40:28,431 [podnet.py] => Task 15, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 2.78, Flat_loss 0.20, Train_acc 95.86, Test_acc 51.50
2025-02-13 18:40:30,105 [podnet.py] => Task 15, Epoch 96/160 (LR 0.03455) => LSC_loss 0.23, Spatial_loss 2.87, Flat_loss 0.19, Train_acc 96.17, Test_acc 50.15
2025-02-13 18:40:31,818 [podnet.py] => Task 15, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 96.60, Test_acc 54.66
2025-02-13 18:40:33,525 [podnet.py] => Task 15, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 2.89, Flat_loss 0.20, Train_acc 96.33, Test_acc 51.88
2025-02-13 18:40:35,238 [podnet.py] => Task 15, Epoch 99/160 (LR 0.03178) => LSC_loss 0.22, Spatial_loss 2.79, Flat_loss 0.18, Train_acc 96.29, Test_acc 53.12
2025-02-13 18:40:36,944 [podnet.py] => Task 15, Epoch 100/160 (LR 0.03087) => LSC_loss 0.22, Spatial_loss 2.53, Flat_loss 0.17, Train_acc 96.60, Test_acc 52.55
2025-02-13 18:40:38,702 [podnet.py] => Task 15, Epoch 101/160 (LR 0.02996) => LSC_loss 0.22, Spatial_loss 2.59, Flat_loss 0.18, Train_acc 95.66, Test_acc 51.80
2025-02-13 18:40:40,373 [podnet.py] => Task 15, Epoch 102/160 (LR 0.02907) => LSC_loss 0.22, Spatial_loss 2.53, Flat_loss 0.17, Train_acc 96.21, Test_acc 53.26
2025-02-13 18:40:42,065 [podnet.py] => Task 15, Epoch 103/160 (LR 0.02818) => LSC_loss 0.23, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 95.59, Test_acc 51.15
2025-02-13 18:40:43,752 [podnet.py] => Task 15, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 2.49, Flat_loss 0.17, Train_acc 96.21, Test_acc 52.41
2025-02-13 18:40:45,456 [podnet.py] => Task 15, Epoch 105/160 (LR 0.02643) => LSC_loss 0.22, Spatial_loss 2.60, Flat_loss 0.18, Train_acc 96.48, Test_acc 53.59
2025-02-13 18:40:47,138 [podnet.py] => Task 15, Epoch 106/160 (LR 0.02557) => LSC_loss 0.23, Spatial_loss 2.57, Flat_loss 0.17, Train_acc 96.17, Test_acc 54.50
2025-02-13 18:40:48,795 [podnet.py] => Task 15, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 2.44, Flat_loss 0.17, Train_acc 96.25, Test_acc 54.49
2025-02-13 18:40:50,500 [podnet.py] => Task 15, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 2.38, Flat_loss 0.16, Train_acc 96.33, Test_acc 52.99
2025-02-13 18:40:52,190 [podnet.py] => Task 15, Epoch 109/160 (LR 0.02304) => LSC_loss 0.23, Spatial_loss 2.50, Flat_loss 0.17, Train_acc 95.59, Test_acc 51.95
2025-02-13 18:40:53,830 [podnet.py] => Task 15, Epoch 110/160 (LR 0.02222) => LSC_loss 0.22, Spatial_loss 2.47, Flat_loss 0.16, Train_acc 96.56, Test_acc 53.88
2025-02-13 18:40:55,538 [podnet.py] => Task 15, Epoch 111/160 (LR 0.02141) => LSC_loss 0.22, Spatial_loss 2.37, Flat_loss 0.16, Train_acc 96.21, Test_acc 53.72
2025-02-13 18:40:57,209 [podnet.py] => Task 15, Epoch 112/160 (LR 0.02061) => LSC_loss 0.22, Spatial_loss 2.37, Flat_loss 0.16, Train_acc 96.02, Test_acc 54.48
2025-02-13 18:40:58,875 [podnet.py] => Task 15, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 2.25, Flat_loss 0.15, Train_acc 95.94, Test_acc 51.68
2025-02-13 18:41:00,574 [podnet.py] => Task 15, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 2.30, Flat_loss 0.15, Train_acc 96.25, Test_acc 52.00
2025-02-13 18:41:02,289 [podnet.py] => Task 15, Epoch 115/160 (LR 0.01828) => LSC_loss 0.21, Spatial_loss 2.25, Flat_loss 0.16, Train_acc 96.72, Test_acc 53.71
2025-02-13 18:41:03,947 [podnet.py] => Task 15, Epoch 116/160 (LR 0.01753) => LSC_loss 0.21, Spatial_loss 2.16, Flat_loss 0.15, Train_acc 97.11, Test_acc 52.71
2025-02-13 18:41:05,583 [podnet.py] => Task 15, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 2.38, Flat_loss 0.15, Train_acc 96.56, Test_acc 54.64
2025-02-13 18:41:07,326 [podnet.py] => Task 15, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 2.19, Flat_loss 0.15, Train_acc 96.21, Test_acc 53.24
2025-02-13 18:41:09,037 [podnet.py] => Task 15, Epoch 119/160 (LR 0.01535) => LSC_loss 0.22, Spatial_loss 2.22, Flat_loss 0.15, Train_acc 96.29, Test_acc 52.90
2025-02-13 18:41:10,764 [podnet.py] => Task 15, Epoch 120/160 (LR 0.01464) => LSC_loss 0.23, Spatial_loss 2.24, Flat_loss 0.15, Train_acc 96.17, Test_acc 54.02
2025-02-13 18:41:12,459 [podnet.py] => Task 15, Epoch 121/160 (LR 0.01396) => LSC_loss 0.22, Spatial_loss 2.24, Flat_loss 0.15, Train_acc 96.29, Test_acc 53.71
2025-02-13 18:41:14,081 [podnet.py] => Task 15, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 2.24, Flat_loss 0.15, Train_acc 96.48, Test_acc 53.52
2025-02-13 18:41:15,793 [podnet.py] => Task 15, Epoch 123/160 (LR 0.01262) => LSC_loss 0.22, Spatial_loss 2.14, Flat_loss 0.14, Train_acc 96.09, Test_acc 55.00
2025-02-13 18:41:17,496 [podnet.py] => Task 15, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 2.17, Flat_loss 0.14, Train_acc 95.86, Test_acc 53.26
2025-02-13 18:41:19,152 [podnet.py] => Task 15, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 2.21, Flat_loss 0.14, Train_acc 96.45, Test_acc 54.15
2025-02-13 18:41:20,848 [podnet.py] => Task 15, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 2.12, Flat_loss 0.15, Train_acc 96.41, Test_acc 54.26
2025-02-13 18:41:22,455 [podnet.py] => Task 15, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 96.05, Test_acc 54.80
2025-02-13 18:41:24,127 [podnet.py] => Task 15, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 96.80, Test_acc 53.86
2025-02-13 18:41:25,790 [podnet.py] => Task 15, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 2.14, Flat_loss 0.14, Train_acc 96.02, Test_acc 54.30
2025-02-13 18:41:27,462 [podnet.py] => Task 15, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 97.07, Test_acc 54.70
2025-02-13 18:41:29,190 [podnet.py] => Task 15, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 96.72, Test_acc 55.20
2025-02-13 18:41:30,862 [podnet.py] => Task 15, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 96.13, Test_acc 54.62
2025-02-13 18:41:32,616 [podnet.py] => Task 15, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 96.21, Test_acc 54.18
2025-02-13 18:41:34,277 [podnet.py] => Task 15, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 96.33, Test_acc 54.44
2025-02-13 18:41:35,969 [podnet.py] => Task 15, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.93, Flat_loss 0.13, Train_acc 96.64, Test_acc 54.49
2025-02-13 18:41:37,650 [podnet.py] => Task 15, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 95.70, Test_acc 53.38
2025-02-13 18:41:39,291 [podnet.py] => Task 15, Epoch 137/160 (LR 0.00501) => LSC_loss 0.24, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 95.78, Test_acc 53.81
2025-02-13 18:41:40,905 [podnet.py] => Task 15, Epoch 138/160 (LR 0.00459) => LSC_loss 0.23, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 95.86, Test_acc 54.46
2025-02-13 18:41:42,597 [podnet.py] => Task 15, Epoch 139/160 (LR 0.00419) => LSC_loss 0.23, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 95.94, Test_acc 53.71
2025-02-13 18:41:44,302 [podnet.py] => Task 15, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 96.29, Test_acc 54.82
2025-02-13 18:41:45,971 [podnet.py] => Task 15, Epoch 141/160 (LR 0.00344) => LSC_loss 0.23, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 96.33, Test_acc 53.82
2025-02-13 18:41:47,664 [podnet.py] => Task 15, Epoch 142/160 (LR 0.00309) => LSC_loss 0.22, Spatial_loss 1.82, Flat_loss 0.12, Train_acc 96.17, Test_acc 54.86
2025-02-13 18:41:49,359 [podnet.py] => Task 15, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 1.82, Flat_loss 0.13, Train_acc 96.37, Test_acc 54.11
2025-02-13 18:41:51,062 [podnet.py] => Task 15, Epoch 144/160 (LR 0.00245) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 96.45, Test_acc 54.88
2025-02-13 18:41:52,698 [podnet.py] => Task 15, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.56, Test_acc 54.60
2025-02-13 18:41:54,383 [podnet.py] => Task 15, Epoch 146/160 (LR 0.00188) => LSC_loss 0.23, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 95.86, Test_acc 54.35
2025-02-13 18:41:56,063 [podnet.py] => Task 15, Epoch 147/160 (LR 0.00162) => LSC_loss 0.21, Spatial_loss 1.75, Flat_loss 0.12, Train_acc 96.72, Test_acc 55.04
2025-02-13 18:41:57,708 [podnet.py] => Task 15, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.13, Test_acc 54.88
2025-02-13 18:41:59,374 [podnet.py] => Task 15, Epoch 149/160 (LR 0.00116) => LSC_loss 0.22, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 96.56, Test_acc 54.55
2025-02-13 18:42:01,066 [podnet.py] => Task 15, Epoch 150/160 (LR 0.00096) => LSC_loss 0.22, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 96.72, Test_acc 54.69
2025-02-13 18:42:02,759 [podnet.py] => Task 15, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.60, Test_acc 54.79
2025-02-13 18:42:04,418 [podnet.py] => Task 15, Epoch 152/160 (LR 0.00062) => LSC_loss 0.22, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 96.45, Test_acc 54.62
2025-02-13 18:42:06,107 [podnet.py] => Task 15, Epoch 153/160 (LR 0.00047) => LSC_loss 0.22, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 96.13, Test_acc 54.58
2025-02-13 18:42:07,765 [podnet.py] => Task 15, Epoch 154/160 (LR 0.00035) => LSC_loss 0.23, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.09, Test_acc 55.01
2025-02-13 18:42:09,483 [podnet.py] => Task 15, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 96.25, Test_acc 54.39
2025-02-13 18:42:11,145 [podnet.py] => Task 15, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 1.66, Flat_loss 0.12, Train_acc 95.62, Test_acc 54.98
2025-02-13 18:42:12,818 [podnet.py] => Task 15, Epoch 157/160 (LR 0.00009) => LSC_loss 0.21, Spatial_loss 1.68, Flat_loss 0.12, Train_acc 96.84, Test_acc 54.75
2025-02-13 18:42:14,504 [podnet.py] => Task 15, Epoch 158/160 (LR 0.00004) => LSC_loss 0.21, Spatial_loss 1.72, Flat_loss 0.12, Train_acc 96.88, Test_acc 54.41
2025-02-13 18:42:16,134 [podnet.py] => Task 15, Epoch 159/160 (LR 0.00001) => LSC_loss 0.22, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 96.25, Test_acc 54.82
2025-02-13 18:42:17,844 [podnet.py] => Task 15, Epoch 160/160 (LR 0.00000) => LSC_loss 0.22, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 96.13, Test_acc 54.78
2025-02-13 18:42:17,845 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:42:17,845 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:42:43,656 [podnet.py] => The size of finetune dataset: 1600
2025-02-13 18:42:45,153 [podnet.py] => Task 15, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 2.49, Flat_loss 0.14, Train_acc 96.88, Test_acc 53.68
2025-02-13 18:42:46,568 [podnet.py] => Task 15, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 1.95, Flat_loss 0.07, Train_acc 98.75, Test_acc 55.29
2025-02-13 18:42:48,061 [podnet.py] => Task 15, Epoch 3/20 (LR 0.00473) => LSC_loss 0.10, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 98.50, Test_acc 55.86
2025-02-13 18:42:49,562 [podnet.py] => Task 15, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 1.83, Flat_loss 0.06, Train_acc 98.81, Test_acc 55.89
2025-02-13 18:42:51,035 [podnet.py] => Task 15, Epoch 5/20 (LR 0.00427) => LSC_loss 0.10, Spatial_loss 1.88, Flat_loss 0.06, Train_acc 98.62, Test_acc 55.81
2025-02-13 18:42:52,499 [podnet.py] => Task 15, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 99.00, Test_acc 55.88
2025-02-13 18:42:53,965 [podnet.py] => Task 15, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 1.87, Flat_loss 0.06, Train_acc 98.75, Test_acc 55.95
2025-02-13 18:42:55,415 [podnet.py] => Task 15, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 98.50, Test_acc 55.80
2025-02-13 18:42:56,906 [podnet.py] => Task 15, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 98.56, Test_acc 55.82
2025-02-13 18:42:58,388 [podnet.py] => Task 15, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 98.94, Test_acc 55.84
2025-02-13 18:42:59,885 [podnet.py] => Task 15, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 1.80, Flat_loss 0.06, Train_acc 99.00, Test_acc 55.94
2025-02-13 18:43:01,339 [podnet.py] => Task 15, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 98.50, Test_acc 55.75
2025-02-13 18:43:02,845 [podnet.py] => Task 15, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 98.88, Test_acc 55.82
2025-02-13 18:43:04,314 [podnet.py] => Task 15, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 1.64, Flat_loss 0.05, Train_acc 98.44, Test_acc 55.94
2025-02-13 18:43:05,742 [podnet.py] => Task 15, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 98.88, Test_acc 56.05
2025-02-13 18:43:07,227 [podnet.py] => Task 15, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 1.70, Flat_loss 0.06, Train_acc 98.81, Test_acc 55.69
2025-02-13 18:43:08,752 [podnet.py] => Task 15, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 1.72, Flat_loss 0.05, Train_acc 98.94, Test_acc 56.02
2025-02-13 18:43:10,188 [podnet.py] => Task 15, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 98.94, Test_acc 56.19
2025-02-13 18:43:11,625 [podnet.py] => Task 15, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 1.66, Flat_loss 0.05, Train_acc 98.88, Test_acc 56.02
2025-02-13 18:43:13,088 [podnet.py] => Task 15, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 1.63, Flat_loss 0.06, Train_acc 98.75, Test_acc 55.92
2025-02-13 18:43:13,089 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:43:40,104 [podnet.py] => Exemplar size: 1600
2025-02-13 18:43:40,105 [trainer.py] => CNN: {'total': 55.92, '00-09': 65.5, '10-19': 46.3, '20-29': 64.7, '30-39': 54.5, '40-49': 59.9, '50-59': 39.7, '60-69': 55.9, '70-79': 60.9, 'old': 55.64, 'new': 67.0}
2025-02-13 18:43:40,114 [trainer.py] => NME: {'total': 56.11, '00-09': 67.2, '10-19': 50.7, '20-29': 67.2, '30-39': 55.7, '40-49': 61.3, '50-59': 35.4, '60-69': 53.2, '70-79': 58.2, 'old': 55.99, 'new': 61.0}
2025-02-13 18:43:40,114 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92]
2025-02-13 18:43:40,114 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6]
2025-02-13 18:43:40,114 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11]
2025-02-13 18:43:40,114 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95]

2025-02-13 18:43:40,114 [trainer.py] => Average Accuracy (CNN): 65.234375
2025-02-13 18:43:40,114 [trainer.py] => Average Accuracy (NME): 65.4875
2025-02-13 18:43:40,114 [trainer.py] => All params: 517457
2025-02-13 18:43:40,115 [trainer.py] => Trainable params: 517457
2025-02-13 18:43:40,116 [podnet.py] => Learning on 80-82
2025-02-13 18:43:40,139 [podnet.py] => Adaptive factor: 6.4031242374328485
2025-02-13 18:43:41,917 [podnet.py] => Task 16, Epoch 1/160 (LR 0.09999) => LSC_loss 1.10, Spatial_loss 4.64, Flat_loss 0.56, Train_acc 83.19, Test_acc 48.01
2025-02-13 18:43:43,690 [podnet.py] => Task 16, Epoch 2/160 (LR 0.09996) => LSC_loss 0.43, Spatial_loss 5.56, Flat_loss 0.60, Train_acc 88.00, Test_acc 42.18
2025-02-13 18:43:45,389 [podnet.py] => Task 16, Epoch 3/160 (LR 0.09991) => LSC_loss 0.40, Spatial_loss 5.79, Flat_loss 0.62, Train_acc 89.62, Test_acc 45.66
2025-02-13 18:43:47,127 [podnet.py] => Task 16, Epoch 4/160 (LR 0.09985) => LSC_loss 0.36, Spatial_loss 5.54, Flat_loss 0.59, Train_acc 90.73, Test_acc 44.96
2025-02-13 18:43:48,829 [podnet.py] => Task 16, Epoch 5/160 (LR 0.09976) => LSC_loss 0.31, Spatial_loss 5.32, Flat_loss 0.55, Train_acc 91.58, Test_acc 46.26
2025-02-13 18:43:50,615 [podnet.py] => Task 16, Epoch 6/160 (LR 0.09965) => LSC_loss 0.30, Spatial_loss 5.21, Flat_loss 0.51, Train_acc 92.58, Test_acc 44.49
2025-02-13 18:43:52,363 [podnet.py] => Task 16, Epoch 7/160 (LR 0.09953) => LSC_loss 0.28, Spatial_loss 5.15, Flat_loss 0.48, Train_acc 92.92, Test_acc 48.52
2025-02-13 18:43:54,055 [podnet.py] => Task 16, Epoch 8/160 (LR 0.09938) => LSC_loss 0.27, Spatial_loss 5.01, Flat_loss 0.45, Train_acc 93.58, Test_acc 44.00
2025-02-13 18:43:55,747 [podnet.py] => Task 16, Epoch 9/160 (LR 0.09922) => LSC_loss 0.27, Spatial_loss 4.99, Flat_loss 0.45, Train_acc 93.96, Test_acc 45.22
2025-02-13 18:43:57,488 [podnet.py] => Task 16, Epoch 10/160 (LR 0.09904) => LSC_loss 0.26, Spatial_loss 4.91, Flat_loss 0.42, Train_acc 94.38, Test_acc 42.46
2025-02-13 18:43:59,207 [podnet.py] => Task 16, Epoch 11/160 (LR 0.09884) => LSC_loss 0.27, Spatial_loss 4.87, Flat_loss 0.43, Train_acc 94.00, Test_acc 49.26
2025-02-13 18:44:00,928 [podnet.py] => Task 16, Epoch 12/160 (LR 0.09862) => LSC_loss 0.25, Spatial_loss 4.67, Flat_loss 0.41, Train_acc 94.00, Test_acc 47.91
2025-02-13 18:44:02,691 [podnet.py] => Task 16, Epoch 13/160 (LR 0.09838) => LSC_loss 0.25, Spatial_loss 4.52, Flat_loss 0.39, Train_acc 94.38, Test_acc 46.84
2025-02-13 18:44:04,446 [podnet.py] => Task 16, Epoch 14/160 (LR 0.09812) => LSC_loss 0.25, Spatial_loss 4.52, Flat_loss 0.38, Train_acc 95.12, Test_acc 50.01
2025-02-13 18:44:06,161 [podnet.py] => Task 16, Epoch 15/160 (LR 0.09785) => LSC_loss 0.24, Spatial_loss 4.76, Flat_loss 0.40, Train_acc 94.85, Test_acc 50.09
2025-02-13 18:44:07,850 [podnet.py] => Task 16, Epoch 16/160 (LR 0.09755) => LSC_loss 0.24, Spatial_loss 4.67, Flat_loss 0.40, Train_acc 94.46, Test_acc 46.82
2025-02-13 18:44:09,576 [podnet.py] => Task 16, Epoch 17/160 (LR 0.09724) => LSC_loss 0.22, Spatial_loss 4.40, Flat_loss 0.37, Train_acc 95.46, Test_acc 49.63
2025-02-13 18:44:11,266 [podnet.py] => Task 16, Epoch 18/160 (LR 0.09691) => LSC_loss 0.25, Spatial_loss 4.73, Flat_loss 0.38, Train_acc 94.31, Test_acc 48.18
2025-02-13 18:44:12,979 [podnet.py] => Task 16, Epoch 19/160 (LR 0.09656) => LSC_loss 0.24, Spatial_loss 4.55, Flat_loss 0.38, Train_acc 94.38, Test_acc 50.39
2025-02-13 18:44:14,690 [podnet.py] => Task 16, Epoch 20/160 (LR 0.09619) => LSC_loss 0.25, Spatial_loss 4.61, Flat_loss 0.39, Train_acc 94.54, Test_acc 47.46
2025-02-13 18:44:16,391 [podnet.py] => Task 16, Epoch 21/160 (LR 0.09581) => LSC_loss 0.23, Spatial_loss 4.41, Flat_loss 0.35, Train_acc 95.27, Test_acc 46.73
2025-02-13 18:44:18,112 [podnet.py] => Task 16, Epoch 22/160 (LR 0.09541) => LSC_loss 0.23, Spatial_loss 4.40, Flat_loss 0.35, Train_acc 95.27, Test_acc 50.29
2025-02-13 18:44:19,821 [podnet.py] => Task 16, Epoch 23/160 (LR 0.09499) => LSC_loss 0.22, Spatial_loss 4.28, Flat_loss 0.34, Train_acc 95.58, Test_acc 48.94
2025-02-13 18:44:21,542 [podnet.py] => Task 16, Epoch 24/160 (LR 0.09455) => LSC_loss 0.24, Spatial_loss 4.33, Flat_loss 0.35, Train_acc 95.15, Test_acc 46.59
2025-02-13 18:44:23,247 [podnet.py] => Task 16, Epoch 25/160 (LR 0.09410) => LSC_loss 0.24, Spatial_loss 4.47, Flat_loss 0.36, Train_acc 93.62, Test_acc 49.63
2025-02-13 18:44:24,985 [podnet.py] => Task 16, Epoch 26/160 (LR 0.09362) => LSC_loss 0.21, Spatial_loss 4.26, Flat_loss 0.33, Train_acc 95.81, Test_acc 50.66
2025-02-13 18:44:26,719 [podnet.py] => Task 16, Epoch 27/160 (LR 0.09314) => LSC_loss 0.24, Spatial_loss 4.44, Flat_loss 0.34, Train_acc 94.73, Test_acc 49.65
2025-02-13 18:44:28,447 [podnet.py] => Task 16, Epoch 28/160 (LR 0.09263) => LSC_loss 0.22, Spatial_loss 4.41, Flat_loss 0.35, Train_acc 95.08, Test_acc 48.24
2025-02-13 18:44:30,140 [podnet.py] => Task 16, Epoch 29/160 (LR 0.09211) => LSC_loss 0.22, Spatial_loss 4.25, Flat_loss 0.33, Train_acc 95.15, Test_acc 45.87
2025-02-13 18:44:31,862 [podnet.py] => Task 16, Epoch 30/160 (LR 0.09157) => LSC_loss 0.22, Spatial_loss 4.35, Flat_loss 0.34, Train_acc 95.35, Test_acc 47.41
2025-02-13 18:44:33,537 [podnet.py] => Task 16, Epoch 31/160 (LR 0.09102) => LSC_loss 0.21, Spatial_loss 4.24, Flat_loss 0.32, Train_acc 95.69, Test_acc 49.11
2025-02-13 18:44:35,228 [podnet.py] => Task 16, Epoch 32/160 (LR 0.09045) => LSC_loss 0.22, Spatial_loss 4.33, Flat_loss 0.33, Train_acc 95.58, Test_acc 48.00
2025-02-13 18:44:36,955 [podnet.py] => Task 16, Epoch 33/160 (LR 0.08987) => LSC_loss 0.21, Spatial_loss 4.22, Flat_loss 0.33, Train_acc 95.81, Test_acc 50.13
2025-02-13 18:44:38,703 [podnet.py] => Task 16, Epoch 34/160 (LR 0.08927) => LSC_loss 0.22, Spatial_loss 4.18, Flat_loss 0.31, Train_acc 95.23, Test_acc 49.30
2025-02-13 18:44:40,419 [podnet.py] => Task 16, Epoch 35/160 (LR 0.08865) => LSC_loss 0.21, Spatial_loss 4.02, Flat_loss 0.32, Train_acc 96.15, Test_acc 44.72
2025-02-13 18:44:42,148 [podnet.py] => Task 16, Epoch 36/160 (LR 0.08802) => LSC_loss 0.22, Spatial_loss 4.09, Flat_loss 0.31, Train_acc 95.54, Test_acc 50.18
2025-02-13 18:44:43,905 [podnet.py] => Task 16, Epoch 37/160 (LR 0.08738) => LSC_loss 0.21, Spatial_loss 4.07, Flat_loss 0.32, Train_acc 96.12, Test_acc 49.07
2025-02-13 18:44:45,628 [podnet.py] => Task 16, Epoch 38/160 (LR 0.08672) => LSC_loss 0.22, Spatial_loss 4.00, Flat_loss 0.30, Train_acc 95.77, Test_acc 51.93
2025-02-13 18:44:47,359 [podnet.py] => Task 16, Epoch 39/160 (LR 0.08604) => LSC_loss 0.21, Spatial_loss 3.99, Flat_loss 0.30, Train_acc 96.31, Test_acc 48.22
2025-02-13 18:44:49,086 [podnet.py] => Task 16, Epoch 40/160 (LR 0.08536) => LSC_loss 0.23, Spatial_loss 4.13, Flat_loss 0.31, Train_acc 95.08, Test_acc 49.83
2025-02-13 18:44:50,834 [podnet.py] => Task 16, Epoch 41/160 (LR 0.08465) => LSC_loss 0.22, Spatial_loss 4.23, Flat_loss 0.33, Train_acc 95.46, Test_acc 49.52
2025-02-13 18:44:52,593 [podnet.py] => Task 16, Epoch 42/160 (LR 0.08394) => LSC_loss 0.23, Spatial_loss 4.07, Flat_loss 0.32, Train_acc 95.46, Test_acc 49.68
2025-02-13 18:44:54,311 [podnet.py] => Task 16, Epoch 43/160 (LR 0.08321) => LSC_loss 0.21, Spatial_loss 4.17, Flat_loss 0.33, Train_acc 95.73, Test_acc 52.29
2025-02-13 18:44:56,019 [podnet.py] => Task 16, Epoch 44/160 (LR 0.08247) => LSC_loss 0.22, Spatial_loss 4.06, Flat_loss 0.30, Train_acc 95.27, Test_acc 41.66
2025-02-13 18:44:57,702 [podnet.py] => Task 16, Epoch 45/160 (LR 0.08172) => LSC_loss 0.21, Spatial_loss 4.17, Flat_loss 0.32, Train_acc 95.81, Test_acc 48.96
2025-02-13 18:44:59,444 [podnet.py] => Task 16, Epoch 46/160 (LR 0.08095) => LSC_loss 0.20, Spatial_loss 4.13, Flat_loss 0.31, Train_acc 95.77, Test_acc 50.09
2025-02-13 18:45:01,149 [podnet.py] => Task 16, Epoch 47/160 (LR 0.08018) => LSC_loss 0.20, Spatial_loss 3.89, Flat_loss 0.29, Train_acc 95.77, Test_acc 45.93
2025-02-13 18:45:02,841 [podnet.py] => Task 16, Epoch 48/160 (LR 0.07939) => LSC_loss 0.21, Spatial_loss 3.98, Flat_loss 0.30, Train_acc 96.15, Test_acc 48.87
2025-02-13 18:45:04,554 [podnet.py] => Task 16, Epoch 49/160 (LR 0.07859) => LSC_loss 0.19, Spatial_loss 3.84, Flat_loss 0.28, Train_acc 96.19, Test_acc 50.29
2025-02-13 18:45:06,276 [podnet.py] => Task 16, Epoch 50/160 (LR 0.07778) => LSC_loss 0.20, Spatial_loss 3.84, Flat_loss 0.28, Train_acc 96.35, Test_acc 52.28
2025-02-13 18:45:07,990 [podnet.py] => Task 16, Epoch 51/160 (LR 0.07696) => LSC_loss 0.20, Spatial_loss 3.81, Flat_loss 0.28, Train_acc 96.19, Test_acc 51.06
2025-02-13 18:45:09,671 [podnet.py] => Task 16, Epoch 52/160 (LR 0.07612) => LSC_loss 0.19, Spatial_loss 3.92, Flat_loss 0.28, Train_acc 96.00, Test_acc 50.98
2025-02-13 18:45:11,409 [podnet.py] => Task 16, Epoch 53/160 (LR 0.07528) => LSC_loss 0.20, Spatial_loss 3.90, Flat_loss 0.27, Train_acc 96.19, Test_acc 43.60
2025-02-13 18:45:13,159 [podnet.py] => Task 16, Epoch 54/160 (LR 0.07443) => LSC_loss 0.21, Spatial_loss 4.09, Flat_loss 0.29, Train_acc 95.96, Test_acc 50.16
2025-02-13 18:45:14,903 [podnet.py] => Task 16, Epoch 55/160 (LR 0.07357) => LSC_loss 0.22, Spatial_loss 4.00, Flat_loss 0.30, Train_acc 95.42, Test_acc 50.39
2025-02-13 18:45:16,637 [podnet.py] => Task 16, Epoch 56/160 (LR 0.07270) => LSC_loss 0.21, Spatial_loss 3.77, Flat_loss 0.28, Train_acc 95.42, Test_acc 51.24
2025-02-13 18:45:18,376 [podnet.py] => Task 16, Epoch 57/160 (LR 0.07182) => LSC_loss 0.20, Spatial_loss 3.64, Flat_loss 0.26, Train_acc 96.27, Test_acc 51.52
2025-02-13 18:45:20,086 [podnet.py] => Task 16, Epoch 58/160 (LR 0.07093) => LSC_loss 0.19, Spatial_loss 3.73, Flat_loss 0.26, Train_acc 96.31, Test_acc 50.46
2025-02-13 18:45:21,864 [podnet.py] => Task 16, Epoch 59/160 (LR 0.07004) => LSC_loss 0.21, Spatial_loss 3.78, Flat_loss 0.27, Train_acc 95.81, Test_acc 49.18
2025-02-13 18:45:23,548 [podnet.py] => Task 16, Epoch 60/160 (LR 0.06913) => LSC_loss 0.20, Spatial_loss 3.78, Flat_loss 0.27, Train_acc 96.23, Test_acc 50.11
2025-02-13 18:45:25,225 [podnet.py] => Task 16, Epoch 61/160 (LR 0.06822) => LSC_loss 0.19, Spatial_loss 3.64, Flat_loss 0.26, Train_acc 96.96, Test_acc 49.73
2025-02-13 18:45:27,009 [podnet.py] => Task 16, Epoch 62/160 (LR 0.06731) => LSC_loss 0.21, Spatial_loss 3.52, Flat_loss 0.25, Train_acc 96.31, Test_acc 51.37
2025-02-13 18:45:28,694 [podnet.py] => Task 16, Epoch 63/160 (LR 0.06638) => LSC_loss 0.19, Spatial_loss 3.53, Flat_loss 0.25, Train_acc 96.46, Test_acc 49.90
2025-02-13 18:45:30,393 [podnet.py] => Task 16, Epoch 64/160 (LR 0.06545) => LSC_loss 0.20, Spatial_loss 3.57, Flat_loss 0.24, Train_acc 96.19, Test_acc 50.32
2025-02-13 18:45:32,128 [podnet.py] => Task 16, Epoch 65/160 (LR 0.06451) => LSC_loss 0.20, Spatial_loss 3.63, Flat_loss 0.24, Train_acc 96.19, Test_acc 50.71
2025-02-13 18:45:33,873 [podnet.py] => Task 16, Epoch 66/160 (LR 0.06357) => LSC_loss 0.18, Spatial_loss 3.57, Flat_loss 0.25, Train_acc 96.50, Test_acc 52.07
2025-02-13 18:45:35,612 [podnet.py] => Task 16, Epoch 67/160 (LR 0.06262) => LSC_loss 0.18, Spatial_loss 3.31, Flat_loss 0.23, Train_acc 96.62, Test_acc 50.73
2025-02-13 18:45:37,334 [podnet.py] => Task 16, Epoch 68/160 (LR 0.06167) => LSC_loss 0.19, Spatial_loss 3.35, Flat_loss 0.22, Train_acc 96.65, Test_acc 53.24
2025-02-13 18:45:39,076 [podnet.py] => Task 16, Epoch 69/160 (LR 0.06072) => LSC_loss 0.18, Spatial_loss 3.50, Flat_loss 0.23, Train_acc 96.58, Test_acc 52.82
2025-02-13 18:45:40,799 [podnet.py] => Task 16, Epoch 70/160 (LR 0.05975) => LSC_loss 0.20, Spatial_loss 3.79, Flat_loss 0.25, Train_acc 96.54, Test_acc 49.77
2025-02-13 18:45:42,509 [podnet.py] => Task 16, Epoch 71/160 (LR 0.05879) => LSC_loss 0.19, Spatial_loss 3.44, Flat_loss 0.24, Train_acc 96.69, Test_acc 52.67
2025-02-13 18:45:44,139 [podnet.py] => Task 16, Epoch 72/160 (LR 0.05782) => LSC_loss 0.19, Spatial_loss 3.51, Flat_loss 0.24, Train_acc 96.54, Test_acc 49.13
2025-02-13 18:45:45,852 [podnet.py] => Task 16, Epoch 73/160 (LR 0.05685) => LSC_loss 0.19, Spatial_loss 3.56, Flat_loss 0.25, Train_acc 96.54, Test_acc 50.96
2025-02-13 18:45:47,596 [podnet.py] => Task 16, Epoch 74/160 (LR 0.05588) => LSC_loss 0.20, Spatial_loss 3.34, Flat_loss 0.23, Train_acc 96.35, Test_acc 50.93
2025-02-13 18:45:49,346 [podnet.py] => Task 16, Epoch 75/160 (LR 0.05490) => LSC_loss 0.19, Spatial_loss 3.32, Flat_loss 0.22, Train_acc 96.65, Test_acc 52.20
2025-02-13 18:45:51,110 [podnet.py] => Task 16, Epoch 76/160 (LR 0.05392) => LSC_loss 0.18, Spatial_loss 3.35, Flat_loss 0.22, Train_acc 96.73, Test_acc 51.91
2025-02-13 18:45:52,835 [podnet.py] => Task 16, Epoch 77/160 (LR 0.05294) => LSC_loss 0.18, Spatial_loss 3.34, Flat_loss 0.23, Train_acc 97.04, Test_acc 49.39
2025-02-13 18:45:54,581 [podnet.py] => Task 16, Epoch 78/160 (LR 0.05196) => LSC_loss 0.19, Spatial_loss 3.32, Flat_loss 0.22, Train_acc 96.65, Test_acc 51.13
2025-02-13 18:45:56,265 [podnet.py] => Task 16, Epoch 79/160 (LR 0.05098) => LSC_loss 0.20, Spatial_loss 3.25, Flat_loss 0.21, Train_acc 96.54, Test_acc 51.98
2025-02-13 18:45:57,995 [podnet.py] => Task 16, Epoch 80/160 (LR 0.05000) => LSC_loss 0.19, Spatial_loss 3.20, Flat_loss 0.22, Train_acc 96.38, Test_acc 52.40
2025-02-13 18:45:59,733 [podnet.py] => Task 16, Epoch 81/160 (LR 0.04902) => LSC_loss 0.19, Spatial_loss 3.21, Flat_loss 0.22, Train_acc 96.58, Test_acc 51.23
2025-02-13 18:46:01,443 [podnet.py] => Task 16, Epoch 82/160 (LR 0.04804) => LSC_loss 0.17, Spatial_loss 3.18, Flat_loss 0.20, Train_acc 97.31, Test_acc 51.27
2025-02-13 18:46:03,230 [podnet.py] => Task 16, Epoch 83/160 (LR 0.04706) => LSC_loss 0.19, Spatial_loss 3.37, Flat_loss 0.22, Train_acc 96.38, Test_acc 50.91
2025-02-13 18:46:04,956 [podnet.py] => Task 16, Epoch 84/160 (LR 0.04608) => LSC_loss 0.19, Spatial_loss 3.19, Flat_loss 0.20, Train_acc 96.54, Test_acc 51.04
2025-02-13 18:46:06,730 [podnet.py] => Task 16, Epoch 85/160 (LR 0.04510) => LSC_loss 0.19, Spatial_loss 3.23, Flat_loss 0.21, Train_acc 96.54, Test_acc 50.01
2025-02-13 18:46:08,475 [podnet.py] => Task 16, Epoch 86/160 (LR 0.04412) => LSC_loss 0.19, Spatial_loss 3.24, Flat_loss 0.21, Train_acc 96.19, Test_acc 52.18
2025-02-13 18:46:10,199 [podnet.py] => Task 16, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 3.18, Flat_loss 0.21, Train_acc 97.15, Test_acc 52.84
2025-02-13 18:46:11,920 [podnet.py] => Task 16, Epoch 88/160 (LR 0.04218) => LSC_loss 0.19, Spatial_loss 3.17, Flat_loss 0.19, Train_acc 96.54, Test_acc 52.02
2025-02-13 18:46:13,667 [podnet.py] => Task 16, Epoch 89/160 (LR 0.04121) => LSC_loss 0.19, Spatial_loss 3.14, Flat_loss 0.20, Train_acc 96.65, Test_acc 50.63
2025-02-13 18:46:15,410 [podnet.py] => Task 16, Epoch 90/160 (LR 0.04025) => LSC_loss 0.19, Spatial_loss 3.23, Flat_loss 0.20, Train_acc 96.38, Test_acc 52.33
2025-02-13 18:46:17,118 [podnet.py] => Task 16, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 3.08, Flat_loss 0.20, Train_acc 96.62, Test_acc 50.90
2025-02-13 18:46:18,843 [podnet.py] => Task 16, Epoch 92/160 (LR 0.03833) => LSC_loss 0.18, Spatial_loss 2.92, Flat_loss 0.19, Train_acc 97.04, Test_acc 50.96
2025-02-13 18:46:20,581 [podnet.py] => Task 16, Epoch 93/160 (LR 0.03738) => LSC_loss 0.18, Spatial_loss 2.87, Flat_loss 0.18, Train_acc 97.04, Test_acc 49.48
2025-02-13 18:46:22,333 [podnet.py] => Task 16, Epoch 94/160 (LR 0.03643) => LSC_loss 0.18, Spatial_loss 2.96, Flat_loss 0.17, Train_acc 96.88, Test_acc 51.21
2025-02-13 18:46:24,067 [podnet.py] => Task 16, Epoch 95/160 (LR 0.03549) => LSC_loss 0.18, Spatial_loss 2.99, Flat_loss 0.18, Train_acc 97.08, Test_acc 52.84
2025-02-13 18:46:25,809 [podnet.py] => Task 16, Epoch 96/160 (LR 0.03455) => LSC_loss 0.17, Spatial_loss 2.85, Flat_loss 0.18, Train_acc 97.27, Test_acc 53.04
2025-02-13 18:46:27,525 [podnet.py] => Task 16, Epoch 97/160 (LR 0.03362) => LSC_loss 0.17, Spatial_loss 2.89, Flat_loss 0.18, Train_acc 97.12, Test_acc 53.20
2025-02-13 18:46:29,218 [podnet.py] => Task 16, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 2.91, Flat_loss 0.18, Train_acc 97.04, Test_acc 52.09
2025-02-13 18:46:30,960 [podnet.py] => Task 16, Epoch 99/160 (LR 0.03178) => LSC_loss 0.18, Spatial_loss 2.87, Flat_loss 0.18, Train_acc 96.88, Test_acc 51.98
2025-02-13 18:46:32,635 [podnet.py] => Task 16, Epoch 100/160 (LR 0.03087) => LSC_loss 0.17, Spatial_loss 3.00, Flat_loss 0.19, Train_acc 96.81, Test_acc 53.16
2025-02-13 18:46:34,384 [podnet.py] => Task 16, Epoch 101/160 (LR 0.02996) => LSC_loss 0.19, Spatial_loss 3.06, Flat_loss 0.18, Train_acc 96.65, Test_acc 52.90
2025-02-13 18:46:36,075 [podnet.py] => Task 16, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 2.97, Flat_loss 0.18, Train_acc 96.88, Test_acc 52.91
2025-02-13 18:46:37,842 [podnet.py] => Task 16, Epoch 103/160 (LR 0.02818) => LSC_loss 0.17, Spatial_loss 2.80, Flat_loss 0.17, Train_acc 97.27, Test_acc 51.28
2025-02-13 18:46:39,511 [podnet.py] => Task 16, Epoch 104/160 (LR 0.02730) => LSC_loss 0.18, Spatial_loss 2.82, Flat_loss 0.17, Train_acc 96.85, Test_acc 53.07
2025-02-13 18:46:41,283 [podnet.py] => Task 16, Epoch 105/160 (LR 0.02643) => LSC_loss 0.18, Spatial_loss 2.67, Flat_loss 0.16, Train_acc 97.12, Test_acc 53.29
2025-02-13 18:46:43,063 [podnet.py] => Task 16, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 2.70, Flat_loss 0.16, Train_acc 96.88, Test_acc 53.10
2025-02-13 18:46:44,790 [podnet.py] => Task 16, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 2.69, Flat_loss 0.15, Train_acc 96.81, Test_acc 53.41
2025-02-13 18:46:46,458 [podnet.py] => Task 16, Epoch 108/160 (LR 0.02388) => LSC_loss 0.16, Spatial_loss 2.55, Flat_loss 0.15, Train_acc 97.81, Test_acc 53.17
2025-02-13 18:46:48,242 [podnet.py] => Task 16, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 2.66, Flat_loss 0.16, Train_acc 96.54, Test_acc 51.41
2025-02-13 18:46:50,040 [podnet.py] => Task 16, Epoch 110/160 (LR 0.02222) => LSC_loss 0.18, Spatial_loss 2.69, Flat_loss 0.16, Train_acc 97.12, Test_acc 52.46
2025-02-13 18:46:51,754 [podnet.py] => Task 16, Epoch 111/160 (LR 0.02141) => LSC_loss 0.19, Spatial_loss 2.75, Flat_loss 0.16, Train_acc 96.19, Test_acc 53.63
2025-02-13 18:46:53,460 [podnet.py] => Task 16, Epoch 112/160 (LR 0.02061) => LSC_loss 0.17, Spatial_loss 2.58, Flat_loss 0.15, Train_acc 97.38, Test_acc 53.76
2025-02-13 18:46:55,149 [podnet.py] => Task 16, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 2.49, Flat_loss 0.14, Train_acc 96.77, Test_acc 53.01
2025-02-13 18:46:56,876 [podnet.py] => Task 16, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 2.61, Flat_loss 0.14, Train_acc 97.23, Test_acc 53.65
2025-02-13 18:46:58,630 [podnet.py] => Task 16, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 2.53, Flat_loss 0.15, Train_acc 97.19, Test_acc 52.84
2025-02-13 18:47:00,320 [podnet.py] => Task 16, Epoch 116/160 (LR 0.01753) => LSC_loss 0.17, Spatial_loss 2.50, Flat_loss 0.14, Train_acc 96.92, Test_acc 52.68
2025-02-13 18:47:02,069 [podnet.py] => Task 16, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 2.45, Flat_loss 0.14, Train_acc 97.08, Test_acc 53.32
2025-02-13 18:47:03,811 [podnet.py] => Task 16, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 2.44, Flat_loss 0.14, Train_acc 97.08, Test_acc 53.21
2025-02-13 18:47:05,531 [podnet.py] => Task 16, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 2.43, Flat_loss 0.15, Train_acc 96.73, Test_acc 53.77
2025-02-13 18:47:07,324 [podnet.py] => Task 16, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 2.42, Flat_loss 0.14, Train_acc 97.15, Test_acc 52.77
2025-02-13 18:47:09,014 [podnet.py] => Task 16, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 2.35, Flat_loss 0.14, Train_acc 96.65, Test_acc 53.98
2025-02-13 18:47:10,686 [podnet.py] => Task 16, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 2.42, Flat_loss 0.14, Train_acc 96.81, Test_acc 54.37
2025-02-13 18:47:12,370 [podnet.py] => Task 16, Epoch 123/160 (LR 0.01262) => LSC_loss 0.17, Spatial_loss 2.27, Flat_loss 0.13, Train_acc 97.27, Test_acc 53.20
2025-02-13 18:47:14,091 [podnet.py] => Task 16, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 2.24, Flat_loss 0.13, Train_acc 96.96, Test_acc 54.49
2025-02-13 18:47:15,760 [podnet.py] => Task 16, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 2.42, Flat_loss 0.14, Train_acc 97.31, Test_acc 54.45
2025-02-13 18:47:17,437 [podnet.py] => Task 16, Epoch 126/160 (LR 0.01073) => LSC_loss 0.18, Spatial_loss 2.28, Flat_loss 0.13, Train_acc 96.62, Test_acc 54.57
2025-02-13 18:47:19,207 [podnet.py] => Task 16, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 2.25, Flat_loss 0.13, Train_acc 97.12, Test_acc 54.50
2025-02-13 18:47:20,943 [podnet.py] => Task 16, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 2.26, Flat_loss 0.13, Train_acc 97.00, Test_acc 54.71
2025-02-13 18:47:22,684 [podnet.py] => Task 16, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 97.46, Test_acc 53.57
2025-02-13 18:47:24,383 [podnet.py] => Task 16, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 2.21, Flat_loss 0.12, Train_acc 97.00, Test_acc 54.23
2025-02-13 18:47:26,076 [podnet.py] => Task 16, Epoch 131/160 (LR 0.00789) => LSC_loss 0.18, Spatial_loss 2.12, Flat_loss 0.12, Train_acc 97.04, Test_acc 54.28
2025-02-13 18:47:27,775 [podnet.py] => Task 16, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 2.22, Flat_loss 0.12, Train_acc 97.00, Test_acc 54.87
2025-02-13 18:47:29,524 [podnet.py] => Task 16, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 96.92, Test_acc 54.85
2025-02-13 18:47:31,286 [podnet.py] => Task 16, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 2.12, Flat_loss 0.11, Train_acc 97.04, Test_acc 53.85
2025-02-13 18:47:33,043 [podnet.py] => Task 16, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 97.08, Test_acc 53.93
2025-02-13 18:47:34,747 [podnet.py] => Task 16, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 2.00, Flat_loss 0.11, Train_acc 96.81, Test_acc 53.95
2025-02-13 18:47:36,471 [podnet.py] => Task 16, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 2.01, Flat_loss 0.11, Train_acc 96.96, Test_acc 54.79
2025-02-13 18:47:38,187 [podnet.py] => Task 16, Epoch 138/160 (LR 0.00459) => LSC_loss 0.18, Spatial_loss 2.15, Flat_loss 0.12, Train_acc 97.00, Test_acc 54.66
2025-02-13 18:47:39,934 [podnet.py] => Task 16, Epoch 139/160 (LR 0.00419) => LSC_loss 0.17, Spatial_loss 2.00, Flat_loss 0.11, Train_acc 97.42, Test_acc 54.00
2025-02-13 18:47:41,712 [podnet.py] => Task 16, Epoch 140/160 (LR 0.00381) => LSC_loss 0.17, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 97.19, Test_acc 53.99
2025-02-13 18:47:43,450 [podnet.py] => Task 16, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 2.03, Flat_loss 0.11, Train_acc 97.15, Test_acc 54.71
2025-02-13 18:47:45,194 [podnet.py] => Task 16, Epoch 142/160 (LR 0.00309) => LSC_loss 0.17, Spatial_loss 1.94, Flat_loss 0.11, Train_acc 97.27, Test_acc 54.40
2025-02-13 18:47:46,968 [podnet.py] => Task 16, Epoch 143/160 (LR 0.00276) => LSC_loss 0.18, Spatial_loss 1.89, Flat_loss 0.11, Train_acc 96.88, Test_acc 54.67
2025-02-13 18:47:48,688 [podnet.py] => Task 16, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 96.73, Test_acc 54.71
2025-02-13 18:47:50,448 [podnet.py] => Task 16, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 97.00, Test_acc 54.71
2025-02-13 18:47:52,180 [podnet.py] => Task 16, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 1.93, Flat_loss 0.10, Train_acc 97.12, Test_acc 54.70
2025-02-13 18:47:53,886 [podnet.py] => Task 16, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 1.92, Flat_loss 0.11, Train_acc 97.65, Test_acc 54.96
2025-02-13 18:47:55,659 [podnet.py] => Task 16, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 96.88, Test_acc 55.01
2025-02-13 18:47:57,404 [podnet.py] => Task 16, Epoch 149/160 (LR 0.00116) => LSC_loss 0.18, Spatial_loss 1.87, Flat_loss 0.10, Train_acc 97.23, Test_acc 54.61
2025-02-13 18:47:59,069 [podnet.py] => Task 16, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 1.78, Flat_loss 0.10, Train_acc 97.50, Test_acc 54.82
2025-02-13 18:48:00,800 [podnet.py] => Task 16, Epoch 151/160 (LR 0.00078) => LSC_loss 0.17, Spatial_loss 1.87, Flat_loss 0.10, Train_acc 97.23, Test_acc 54.99
2025-02-13 18:48:02,479 [podnet.py] => Task 16, Epoch 152/160 (LR 0.00062) => LSC_loss 0.17, Spatial_loss 1.80, Flat_loss 0.10, Train_acc 96.77, Test_acc 54.72
2025-02-13 18:48:04,209 [podnet.py] => Task 16, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 1.87, Flat_loss 0.10, Train_acc 97.04, Test_acc 54.78
2025-02-13 18:48:05,917 [podnet.py] => Task 16, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 1.73, Flat_loss 0.10, Train_acc 96.92, Test_acc 55.02
2025-02-13 18:48:07,648 [podnet.py] => Task 16, Epoch 155/160 (LR 0.00024) => LSC_loss 0.17, Spatial_loss 1.77, Flat_loss 0.10, Train_acc 96.96, Test_acc 54.82
2025-02-13 18:48:09,430 [podnet.py] => Task 16, Epoch 156/160 (LR 0.00015) => LSC_loss 0.17, Spatial_loss 1.83, Flat_loss 0.10, Train_acc 97.15, Test_acc 54.74
2025-02-13 18:48:11,171 [podnet.py] => Task 16, Epoch 157/160 (LR 0.00009) => LSC_loss 0.18, Spatial_loss 1.84, Flat_loss 0.10, Train_acc 96.65, Test_acc 54.70
2025-02-13 18:48:12,888 [podnet.py] => Task 16, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 1.82, Flat_loss 0.10, Train_acc 97.38, Test_acc 54.87
2025-02-13 18:48:14,592 [podnet.py] => Task 16, Epoch 159/160 (LR 0.00001) => LSC_loss 0.17, Spatial_loss 1.75, Flat_loss 0.10, Train_acc 97.27, Test_acc 54.95
2025-02-13 18:48:16,312 [podnet.py] => Task 16, Epoch 160/160 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 1.89, Flat_loss 0.10, Train_acc 97.00, Test_acc 54.78
2025-02-13 18:48:16,313 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:48:16,313 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:48:42,160 [podnet.py] => The size of finetune dataset: 1640
2025-02-13 18:48:43,687 [podnet.py] => Task 16, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 2.47, Flat_loss 0.13, Train_acc 97.68, Test_acc 53.65
2025-02-13 18:48:45,144 [podnet.py] => Task 16, Epoch 2/20 (LR 0.00488) => LSC_loss 0.11, Spatial_loss 2.06, Flat_loss 0.08, Train_acc 99.33, Test_acc 54.32
2025-02-13 18:48:46,608 [podnet.py] => Task 16, Epoch 3/20 (LR 0.00473) => LSC_loss 0.11, Spatial_loss 1.89, Flat_loss 0.06, Train_acc 99.27, Test_acc 55.41
2025-02-13 18:48:48,120 [podnet.py] => Task 16, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 1.87, Flat_loss 0.06, Train_acc 99.15, Test_acc 54.87
2025-02-13 18:48:49,618 [podnet.py] => Task 16, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 1.86, Flat_loss 0.06, Train_acc 99.33, Test_acc 55.20
2025-02-13 18:48:51,127 [podnet.py] => Task 16, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.94, Flat_loss 0.07, Train_acc 98.72, Test_acc 55.06
2025-02-13 18:48:52,629 [podnet.py] => Task 16, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 1.72, Flat_loss 0.06, Train_acc 99.09, Test_acc 55.34
2025-02-13 18:48:54,095 [podnet.py] => Task 16, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 1.80, Flat_loss 0.06, Train_acc 99.27, Test_acc 55.41
2025-02-13 18:48:55,630 [podnet.py] => Task 16, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 1.79, Flat_loss 0.06, Train_acc 99.21, Test_acc 55.35
2025-02-13 18:48:57,164 [podnet.py] => Task 16, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 1.73, Flat_loss 0.05, Train_acc 99.27, Test_acc 55.35
2025-02-13 18:48:58,646 [podnet.py] => Task 16, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 99.09, Test_acc 55.17
2025-02-13 18:49:00,187 [podnet.py] => Task 16, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 99.33, Test_acc 55.21
2025-02-13 18:49:01,683 [podnet.py] => Task 16, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.71, Flat_loss 0.05, Train_acc 99.27, Test_acc 55.26
2025-02-13 18:49:03,206 [podnet.py] => Task 16, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 99.39, Test_acc 55.26
2025-02-13 18:49:04,667 [podnet.py] => Task 16, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 98.96, Test_acc 55.43
2025-02-13 18:49:06,129 [podnet.py] => Task 16, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 99.33, Test_acc 55.33
2025-02-13 18:49:07,565 [podnet.py] => Task 16, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 1.61, Flat_loss 0.05, Train_acc 99.39, Test_acc 55.20
2025-02-13 18:49:09,079 [podnet.py] => Task 16, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 1.60, Flat_loss 0.05, Train_acc 99.27, Test_acc 55.43
2025-02-13 18:49:10,572 [podnet.py] => Task 16, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 1.69, Flat_loss 0.05, Train_acc 99.21, Test_acc 55.30
2025-02-13 18:49:12,066 [podnet.py] => Task 16, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 1.65, Flat_loss 0.05, Train_acc 99.21, Test_acc 55.37
2025-02-13 18:49:12,067 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:49:39,208 [podnet.py] => Exemplar size: 1640
2025-02-13 18:49:39,208 [trainer.py] => CNN: {'total': 55.37, '00-09': 65.3, '10-19': 42.8, '20-29': 63.4, '30-39': 53.3, '40-49': 59.9, '50-59': 39.7, '60-69': 56.2, '70-79': 59.4, '80-89': 70.0, 'old': 55.0, 'new': 70.0}
2025-02-13 18:49:39,208 [trainer.py] => NME: {'total': 55.78, '00-09': 67.3, '10-19': 48.4, '20-29': 65.7, '30-39': 54.7, '40-49': 61.5, '50-59': 35.6, '60-69': 52.9, '70-79': 58.5, '80-89': 64.0, 'old': 55.58, 'new': 64.0}
2025-02-13 18:49:39,208 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37]
2025-02-13 18:49:39,208 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76]
2025-02-13 18:49:39,208 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78]
2025-02-13 18:49:39,208 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85]

2025-02-13 18:49:39,209 [trainer.py] => Average Accuracy (CNN): 64.65411764705881
2025-02-13 18:49:39,209 [trainer.py] => Average Accuracy (NME): 64.91647058823528
2025-02-13 18:49:39,209 [trainer.py] => All params: 518737
2025-02-13 18:49:39,209 [trainer.py] => Trainable params: 518737
2025-02-13 18:49:39,210 [podnet.py] => Learning on 82-84
2025-02-13 18:49:39,232 [podnet.py] => Adaptive factor: 6.48074069840786
2025-02-13 18:49:40,962 [podnet.py] => Task 17, Epoch 1/160 (LR 0.09999) => LSC_loss 1.16, Spatial_loss 4.26, Flat_loss 0.52, Train_acc 81.78, Test_acc 43.94
2025-02-13 18:49:42,744 [podnet.py] => Task 17, Epoch 2/160 (LR 0.09996) => LSC_loss 0.38, Spatial_loss 4.84, Flat_loss 0.50, Train_acc 90.57, Test_acc 45.56
2025-02-13 18:49:44,462 [podnet.py] => Task 17, Epoch 3/160 (LR 0.09991) => LSC_loss 0.36, Spatial_loss 4.68, Flat_loss 0.46, Train_acc 91.21, Test_acc 46.55
2025-02-13 18:49:46,259 [podnet.py] => Task 17, Epoch 4/160 (LR 0.09985) => LSC_loss 0.34, Spatial_loss 4.60, Flat_loss 0.43, Train_acc 92.39, Test_acc 41.73
2025-02-13 18:49:48,035 [podnet.py] => Task 17, Epoch 5/160 (LR 0.09976) => LSC_loss 0.31, Spatial_loss 4.69, Flat_loss 0.43, Train_acc 93.37, Test_acc 49.04
2025-02-13 18:49:49,807 [podnet.py] => Task 17, Epoch 6/160 (LR 0.09965) => LSC_loss 0.30, Spatial_loss 4.47, Flat_loss 0.39, Train_acc 93.83, Test_acc 47.57
2025-02-13 18:49:51,529 [podnet.py] => Task 17, Epoch 7/160 (LR 0.09953) => LSC_loss 0.30, Spatial_loss 4.32, Flat_loss 0.36, Train_acc 93.64, Test_acc 42.24
2025-02-13 18:49:53,321 [podnet.py] => Task 17, Epoch 8/160 (LR 0.09938) => LSC_loss 0.28, Spatial_loss 4.35, Flat_loss 0.36, Train_acc 94.28, Test_acc 48.71
2025-02-13 18:49:55,053 [podnet.py] => Task 17, Epoch 9/160 (LR 0.09922) => LSC_loss 0.28, Spatial_loss 4.33, Flat_loss 0.36, Train_acc 94.73, Test_acc 49.80
2025-02-13 18:49:56,764 [podnet.py] => Task 17, Epoch 10/160 (LR 0.09904) => LSC_loss 0.27, Spatial_loss 4.46, Flat_loss 0.35, Train_acc 94.58, Test_acc 49.36
2025-02-13 18:49:58,540 [podnet.py] => Task 17, Epoch 11/160 (LR 0.09884) => LSC_loss 0.28, Spatial_loss 4.15, Flat_loss 0.34, Train_acc 94.28, Test_acc 51.62
2025-02-13 18:50:00,283 [podnet.py] => Task 17, Epoch 12/160 (LR 0.09862) => LSC_loss 0.26, Spatial_loss 4.17, Flat_loss 0.34, Train_acc 94.77, Test_acc 48.44
2025-02-13 18:50:02,040 [podnet.py] => Task 17, Epoch 13/160 (LR 0.09838) => LSC_loss 0.28, Spatial_loss 4.32, Flat_loss 0.34, Train_acc 94.36, Test_acc 48.62
2025-02-13 18:50:03,784 [podnet.py] => Task 17, Epoch 14/160 (LR 0.09812) => LSC_loss 0.26, Spatial_loss 4.19, Flat_loss 0.34, Train_acc 94.81, Test_acc 48.39
2025-02-13 18:50:05,556 [podnet.py] => Task 17, Epoch 15/160 (LR 0.09785) => LSC_loss 0.26, Spatial_loss 4.10, Flat_loss 0.32, Train_acc 94.66, Test_acc 47.48
2025-02-13 18:50:07,324 [podnet.py] => Task 17, Epoch 16/160 (LR 0.09755) => LSC_loss 0.26, Spatial_loss 4.31, Flat_loss 0.35, Train_acc 94.77, Test_acc 48.31
2025-02-13 18:50:09,068 [podnet.py] => Task 17, Epoch 17/160 (LR 0.09724) => LSC_loss 0.25, Spatial_loss 4.22, Flat_loss 0.33, Train_acc 95.34, Test_acc 47.94
2025-02-13 18:50:10,819 [podnet.py] => Task 17, Epoch 18/160 (LR 0.09691) => LSC_loss 0.24, Spatial_loss 4.10, Flat_loss 0.32, Train_acc 95.91, Test_acc 49.64
2025-02-13 18:50:12,557 [podnet.py] => Task 17, Epoch 19/160 (LR 0.09656) => LSC_loss 0.25, Spatial_loss 4.26, Flat_loss 0.33, Train_acc 94.96, Test_acc 46.96
2025-02-13 18:50:14,279 [podnet.py] => Task 17, Epoch 20/160 (LR 0.09619) => LSC_loss 0.24, Spatial_loss 4.05, Flat_loss 0.31, Train_acc 95.91, Test_acc 51.71
2025-02-13 18:50:16,003 [podnet.py] => Task 17, Epoch 21/160 (LR 0.09581) => LSC_loss 0.24, Spatial_loss 3.96, Flat_loss 0.30, Train_acc 95.49, Test_acc 49.15
2025-02-13 18:50:17,753 [podnet.py] => Task 17, Epoch 22/160 (LR 0.09541) => LSC_loss 0.25, Spatial_loss 4.13, Flat_loss 0.33, Train_acc 95.27, Test_acc 50.38
2025-02-13 18:50:19,516 [podnet.py] => Task 17, Epoch 23/160 (LR 0.09499) => LSC_loss 0.24, Spatial_loss 4.03, Flat_loss 0.32, Train_acc 95.80, Test_acc 48.61
2025-02-13 18:50:21,253 [podnet.py] => Task 17, Epoch 24/160 (LR 0.09455) => LSC_loss 0.26, Spatial_loss 3.96, Flat_loss 0.31, Train_acc 94.96, Test_acc 48.98
2025-02-13 18:50:23,044 [podnet.py] => Task 17, Epoch 25/160 (LR 0.09410) => LSC_loss 0.23, Spatial_loss 4.02, Flat_loss 0.32, Train_acc 95.57, Test_acc 51.40
2025-02-13 18:50:24,742 [podnet.py] => Task 17, Epoch 26/160 (LR 0.09362) => LSC_loss 0.23, Spatial_loss 3.95, Flat_loss 0.30, Train_acc 95.49, Test_acc 50.58
2025-02-13 18:50:26,469 [podnet.py] => Task 17, Epoch 27/160 (LR 0.09314) => LSC_loss 0.24, Spatial_loss 3.94, Flat_loss 0.30, Train_acc 95.49, Test_acc 50.18
2025-02-13 18:50:28,166 [podnet.py] => Task 17, Epoch 28/160 (LR 0.09263) => LSC_loss 0.23, Spatial_loss 3.94, Flat_loss 0.30, Train_acc 95.72, Test_acc 47.49
2025-02-13 18:50:29,884 [podnet.py] => Task 17, Epoch 29/160 (LR 0.09211) => LSC_loss 0.23, Spatial_loss 3.97, Flat_loss 0.30, Train_acc 96.21, Test_acc 50.90
2025-02-13 18:50:31,669 [podnet.py] => Task 17, Epoch 30/160 (LR 0.09157) => LSC_loss 0.22, Spatial_loss 3.79, Flat_loss 0.28, Train_acc 95.68, Test_acc 49.06
2025-02-13 18:50:33,464 [podnet.py] => Task 17, Epoch 31/160 (LR 0.09102) => LSC_loss 0.23, Spatial_loss 3.84, Flat_loss 0.29, Train_acc 95.49, Test_acc 50.00
2025-02-13 18:50:35,161 [podnet.py] => Task 17, Epoch 32/160 (LR 0.09045) => LSC_loss 0.22, Spatial_loss 3.87, Flat_loss 0.28, Train_acc 96.59, Test_acc 48.38
2025-02-13 18:50:36,916 [podnet.py] => Task 17, Epoch 33/160 (LR 0.08987) => LSC_loss 0.22, Spatial_loss 3.86, Flat_loss 0.28, Train_acc 95.98, Test_acc 51.57
2025-02-13 18:50:38,661 [podnet.py] => Task 17, Epoch 34/160 (LR 0.08927) => LSC_loss 0.24, Spatial_loss 3.72, Flat_loss 0.27, Train_acc 95.61, Test_acc 46.50
2025-02-13 18:50:40,423 [podnet.py] => Task 17, Epoch 35/160 (LR 0.08865) => LSC_loss 0.23, Spatial_loss 3.84, Flat_loss 0.29, Train_acc 95.68, Test_acc 48.94
2025-02-13 18:50:42,143 [podnet.py] => Task 17, Epoch 36/160 (LR 0.08802) => LSC_loss 0.22, Spatial_loss 3.82, Flat_loss 0.29, Train_acc 95.72, Test_acc 48.62
2025-02-13 18:50:43,909 [podnet.py] => Task 17, Epoch 37/160 (LR 0.08738) => LSC_loss 0.22, Spatial_loss 3.76, Flat_loss 0.28, Train_acc 96.10, Test_acc 47.37
2025-02-13 18:50:45,638 [podnet.py] => Task 17, Epoch 38/160 (LR 0.08672) => LSC_loss 0.22, Spatial_loss 3.73, Flat_loss 0.27, Train_acc 95.91, Test_acc 50.48
2025-02-13 18:50:47,360 [podnet.py] => Task 17, Epoch 39/160 (LR 0.08604) => LSC_loss 0.22, Spatial_loss 3.84, Flat_loss 0.28, Train_acc 95.95, Test_acc 48.01
2025-02-13 18:50:49,107 [podnet.py] => Task 17, Epoch 40/160 (LR 0.08536) => LSC_loss 0.22, Spatial_loss 3.78, Flat_loss 0.28, Train_acc 96.36, Test_acc 48.10
2025-02-13 18:50:50,883 [podnet.py] => Task 17, Epoch 41/160 (LR 0.08465) => LSC_loss 0.22, Spatial_loss 3.75, Flat_loss 0.28, Train_acc 96.10, Test_acc 50.04
2025-02-13 18:50:52,621 [podnet.py] => Task 17, Epoch 42/160 (LR 0.08394) => LSC_loss 0.22, Spatial_loss 3.68, Flat_loss 0.26, Train_acc 96.40, Test_acc 51.07
2025-02-13 18:50:54,380 [podnet.py] => Task 17, Epoch 43/160 (LR 0.08321) => LSC_loss 0.22, Spatial_loss 3.74, Flat_loss 0.26, Train_acc 96.52, Test_acc 46.74
2025-02-13 18:50:56,124 [podnet.py] => Task 17, Epoch 44/160 (LR 0.08247) => LSC_loss 0.21, Spatial_loss 3.65, Flat_loss 0.25, Train_acc 96.36, Test_acc 48.79
2025-02-13 18:50:57,860 [podnet.py] => Task 17, Epoch 45/160 (LR 0.08172) => LSC_loss 0.22, Spatial_loss 3.69, Flat_loss 0.27, Train_acc 96.06, Test_acc 49.81
2025-02-13 18:50:59,606 [podnet.py] => Task 17, Epoch 46/160 (LR 0.08095) => LSC_loss 0.22, Spatial_loss 3.92, Flat_loss 0.29, Train_acc 96.02, Test_acc 49.18
2025-02-13 18:51:01,354 [podnet.py] => Task 17, Epoch 47/160 (LR 0.08018) => LSC_loss 0.22, Spatial_loss 3.70, Flat_loss 0.27, Train_acc 96.25, Test_acc 49.80
2025-02-13 18:51:03,106 [podnet.py] => Task 17, Epoch 48/160 (LR 0.07939) => LSC_loss 0.22, Spatial_loss 3.61, Flat_loss 0.25, Train_acc 95.87, Test_acc 51.01
2025-02-13 18:51:04,821 [podnet.py] => Task 17, Epoch 49/160 (LR 0.07859) => LSC_loss 0.22, Spatial_loss 3.76, Flat_loss 0.26, Train_acc 95.98, Test_acc 47.00
2025-02-13 18:51:06,523 [podnet.py] => Task 17, Epoch 50/160 (LR 0.07778) => LSC_loss 0.23, Spatial_loss 3.73, Flat_loss 0.27, Train_acc 95.91, Test_acc 47.81
2025-02-13 18:51:08,215 [podnet.py] => Task 17, Epoch 51/160 (LR 0.07696) => LSC_loss 0.20, Spatial_loss 3.55, Flat_loss 0.26, Train_acc 96.97, Test_acc 50.96
2025-02-13 18:51:09,949 [podnet.py] => Task 17, Epoch 52/160 (LR 0.07612) => LSC_loss 0.22, Spatial_loss 3.48, Flat_loss 0.24, Train_acc 96.33, Test_acc 50.79
2025-02-13 18:51:11,728 [podnet.py] => Task 17, Epoch 53/160 (LR 0.07528) => LSC_loss 0.20, Spatial_loss 3.55, Flat_loss 0.24, Train_acc 97.05, Test_acc 51.56
2025-02-13 18:51:13,504 [podnet.py] => Task 17, Epoch 54/160 (LR 0.07443) => LSC_loss 0.22, Spatial_loss 3.52, Flat_loss 0.25, Train_acc 96.10, Test_acc 51.15
2025-02-13 18:51:15,286 [podnet.py] => Task 17, Epoch 55/160 (LR 0.07357) => LSC_loss 0.21, Spatial_loss 3.56, Flat_loss 0.25, Train_acc 96.52, Test_acc 46.01
2025-02-13 18:51:17,066 [podnet.py] => Task 17, Epoch 56/160 (LR 0.07270) => LSC_loss 0.21, Spatial_loss 3.53, Flat_loss 0.25, Train_acc 96.25, Test_acc 50.25
2025-02-13 18:51:18,848 [podnet.py] => Task 17, Epoch 57/160 (LR 0.07182) => LSC_loss 0.21, Spatial_loss 3.55, Flat_loss 0.24, Train_acc 96.44, Test_acc 50.54
2025-02-13 18:51:20,611 [podnet.py] => Task 17, Epoch 58/160 (LR 0.07093) => LSC_loss 0.21, Spatial_loss 3.72, Flat_loss 0.25, Train_acc 96.52, Test_acc 51.82
2025-02-13 18:51:22,359 [podnet.py] => Task 17, Epoch 59/160 (LR 0.07004) => LSC_loss 0.20, Spatial_loss 3.46, Flat_loss 0.23, Train_acc 96.86, Test_acc 46.75
2025-02-13 18:51:24,075 [podnet.py] => Task 17, Epoch 60/160 (LR 0.06913) => LSC_loss 0.21, Spatial_loss 3.48, Flat_loss 0.24, Train_acc 96.21, Test_acc 48.58
2025-02-13 18:51:25,852 [podnet.py] => Task 17, Epoch 61/160 (LR 0.06822) => LSC_loss 0.21, Spatial_loss 3.43, Flat_loss 0.24, Train_acc 96.17, Test_acc 51.40
2025-02-13 18:51:27,602 [podnet.py] => Task 17, Epoch 62/160 (LR 0.06731) => LSC_loss 0.20, Spatial_loss 3.34, Flat_loss 0.23, Train_acc 96.78, Test_acc 50.79
2025-02-13 18:51:29,369 [podnet.py] => Task 17, Epoch 63/160 (LR 0.06638) => LSC_loss 0.21, Spatial_loss 3.39, Flat_loss 0.22, Train_acc 96.52, Test_acc 49.68
2025-02-13 18:51:31,085 [podnet.py] => Task 17, Epoch 64/160 (LR 0.06545) => LSC_loss 0.21, Spatial_loss 3.30, Flat_loss 0.23, Train_acc 96.14, Test_acc 51.99
2025-02-13 18:51:32,808 [podnet.py] => Task 17, Epoch 65/160 (LR 0.06451) => LSC_loss 0.21, Spatial_loss 3.52, Flat_loss 0.24, Train_acc 96.17, Test_acc 49.21
2025-02-13 18:51:34,522 [podnet.py] => Task 17, Epoch 66/160 (LR 0.06357) => LSC_loss 0.20, Spatial_loss 3.46, Flat_loss 0.23, Train_acc 96.67, Test_acc 50.99
2025-02-13 18:51:36,261 [podnet.py] => Task 17, Epoch 67/160 (LR 0.06262) => LSC_loss 0.21, Spatial_loss 3.24, Flat_loss 0.22, Train_acc 96.52, Test_acc 51.45
2025-02-13 18:51:38,016 [podnet.py] => Task 17, Epoch 68/160 (LR 0.06167) => LSC_loss 0.21, Spatial_loss 3.33, Flat_loss 0.23, Train_acc 96.21, Test_acc 46.13
2025-02-13 18:51:39,769 [podnet.py] => Task 17, Epoch 69/160 (LR 0.06072) => LSC_loss 0.20, Spatial_loss 3.38, Flat_loss 0.22, Train_acc 96.70, Test_acc 50.54
2025-02-13 18:51:41,485 [podnet.py] => Task 17, Epoch 70/160 (LR 0.05975) => LSC_loss 0.20, Spatial_loss 3.27, Flat_loss 0.21, Train_acc 96.55, Test_acc 50.19
2025-02-13 18:51:43,229 [podnet.py] => Task 17, Epoch 71/160 (LR 0.05879) => LSC_loss 0.21, Spatial_loss 3.12, Flat_loss 0.20, Train_acc 96.55, Test_acc 48.01
2025-02-13 18:51:44,966 [podnet.py] => Task 17, Epoch 72/160 (LR 0.05782) => LSC_loss 0.20, Spatial_loss 3.16, Flat_loss 0.22, Train_acc 96.78, Test_acc 50.92
2025-02-13 18:51:46,745 [podnet.py] => Task 17, Epoch 73/160 (LR 0.05685) => LSC_loss 0.20, Spatial_loss 3.13, Flat_loss 0.21, Train_acc 96.70, Test_acc 52.17
2025-02-13 18:51:48,488 [podnet.py] => Task 17, Epoch 74/160 (LR 0.05588) => LSC_loss 0.20, Spatial_loss 3.17, Flat_loss 0.21, Train_acc 96.97, Test_acc 50.08
2025-02-13 18:51:50,213 [podnet.py] => Task 17, Epoch 75/160 (LR 0.05490) => LSC_loss 0.20, Spatial_loss 3.12, Flat_loss 0.21, Train_acc 96.74, Test_acc 51.35
2025-02-13 18:51:51,968 [podnet.py] => Task 17, Epoch 76/160 (LR 0.05392) => LSC_loss 0.20, Spatial_loss 3.25, Flat_loss 0.20, Train_acc 96.52, Test_acc 51.20
2025-02-13 18:51:53,726 [podnet.py] => Task 17, Epoch 77/160 (LR 0.05294) => LSC_loss 0.20, Spatial_loss 3.22, Flat_loss 0.22, Train_acc 96.86, Test_acc 50.79
2025-02-13 18:51:55,466 [podnet.py] => Task 17, Epoch 78/160 (LR 0.05196) => LSC_loss 0.20, Spatial_loss 3.22, Flat_loss 0.21, Train_acc 96.29, Test_acc 54.00
2025-02-13 18:51:57,159 [podnet.py] => Task 17, Epoch 79/160 (LR 0.05098) => LSC_loss 0.19, Spatial_loss 3.04, Flat_loss 0.19, Train_acc 97.54, Test_acc 49.43
2025-02-13 18:51:58,859 [podnet.py] => Task 17, Epoch 80/160 (LR 0.05000) => LSC_loss 0.19, Spatial_loss 3.05, Flat_loss 0.20, Train_acc 97.39, Test_acc 51.11
2025-02-13 18:52:00,563 [podnet.py] => Task 17, Epoch 81/160 (LR 0.04902) => LSC_loss 0.20, Spatial_loss 3.14, Flat_loss 0.20, Train_acc 96.86, Test_acc 44.49
2025-02-13 18:52:02,331 [podnet.py] => Task 17, Epoch 82/160 (LR 0.04804) => LSC_loss 0.19, Spatial_loss 3.16, Flat_loss 0.20, Train_acc 96.86, Test_acc 51.99
2025-02-13 18:52:04,067 [podnet.py] => Task 17, Epoch 83/160 (LR 0.04706) => LSC_loss 0.20, Spatial_loss 3.00, Flat_loss 0.19, Train_acc 96.93, Test_acc 51.14
2025-02-13 18:52:05,792 [podnet.py] => Task 17, Epoch 84/160 (LR 0.04608) => LSC_loss 0.18, Spatial_loss 2.91, Flat_loss 0.18, Train_acc 97.31, Test_acc 50.83
2025-02-13 18:52:07,512 [podnet.py] => Task 17, Epoch 85/160 (LR 0.04510) => LSC_loss 0.19, Spatial_loss 2.86, Flat_loss 0.18, Train_acc 97.08, Test_acc 51.18
2025-02-13 18:52:09,296 [podnet.py] => Task 17, Epoch 86/160 (LR 0.04412) => LSC_loss 0.21, Spatial_loss 3.05, Flat_loss 0.19, Train_acc 96.74, Test_acc 51.65
2025-02-13 18:52:10,997 [podnet.py] => Task 17, Epoch 87/160 (LR 0.04315) => LSC_loss 0.19, Spatial_loss 2.98, Flat_loss 0.18, Train_acc 97.01, Test_acc 53.05
2025-02-13 18:52:12,720 [podnet.py] => Task 17, Epoch 88/160 (LR 0.04218) => LSC_loss 0.18, Spatial_loss 2.85, Flat_loss 0.17, Train_acc 97.35, Test_acc 49.82
2025-02-13 18:52:14,423 [podnet.py] => Task 17, Epoch 89/160 (LR 0.04121) => LSC_loss 0.19, Spatial_loss 2.84, Flat_loss 0.17, Train_acc 97.01, Test_acc 52.08
2025-02-13 18:52:16,175 [podnet.py] => Task 17, Epoch 90/160 (LR 0.04025) => LSC_loss 0.19, Spatial_loss 2.89, Flat_loss 0.18, Train_acc 96.97, Test_acc 52.36
2025-02-13 18:52:17,863 [podnet.py] => Task 17, Epoch 91/160 (LR 0.03928) => LSC_loss 0.19, Spatial_loss 3.00, Flat_loss 0.18, Train_acc 96.59, Test_acc 51.49
2025-02-13 18:52:19,594 [podnet.py] => Task 17, Epoch 92/160 (LR 0.03833) => LSC_loss 0.19, Spatial_loss 2.90, Flat_loss 0.18, Train_acc 97.05, Test_acc 51.27
2025-02-13 18:52:21,313 [podnet.py] => Task 17, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 3.03, Flat_loss 0.18, Train_acc 97.01, Test_acc 48.60
2025-02-13 18:52:23,015 [podnet.py] => Task 17, Epoch 94/160 (LR 0.03643) => LSC_loss 0.19, Spatial_loss 2.88, Flat_loss 0.17, Train_acc 97.58, Test_acc 51.55
2025-02-13 18:52:24,749 [podnet.py] => Task 17, Epoch 95/160 (LR 0.03549) => LSC_loss 0.20, Spatial_loss 2.69, Flat_loss 0.16, Train_acc 96.67, Test_acc 52.61
2025-02-13 18:52:26,528 [podnet.py] => Task 17, Epoch 96/160 (LR 0.03455) => LSC_loss 0.20, Spatial_loss 2.77, Flat_loss 0.17, Train_acc 97.01, Test_acc 51.31
2025-02-13 18:52:28,255 [podnet.py] => Task 17, Epoch 97/160 (LR 0.03362) => LSC_loss 0.19, Spatial_loss 2.79, Flat_loss 0.17, Train_acc 97.23, Test_acc 52.38
2025-02-13 18:52:30,001 [podnet.py] => Task 17, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 2.69, Flat_loss 0.16, Train_acc 97.46, Test_acc 52.29
2025-02-13 18:52:31,736 [podnet.py] => Task 17, Epoch 99/160 (LR 0.03178) => LSC_loss 0.19, Spatial_loss 2.56, Flat_loss 0.15, Train_acc 96.67, Test_acc 51.92
2025-02-13 18:52:33,460 [podnet.py] => Task 17, Epoch 100/160 (LR 0.03087) => LSC_loss 0.19, Spatial_loss 2.60, Flat_loss 0.16, Train_acc 97.12, Test_acc 49.30
2025-02-13 18:52:35,224 [podnet.py] => Task 17, Epoch 101/160 (LR 0.02996) => LSC_loss 0.19, Spatial_loss 2.71, Flat_loss 0.16, Train_acc 97.08, Test_acc 50.49
2025-02-13 18:52:36,965 [podnet.py] => Task 17, Epoch 102/160 (LR 0.02907) => LSC_loss 0.19, Spatial_loss 2.66, Flat_loss 0.15, Train_acc 96.89, Test_acc 53.02
2025-02-13 18:52:38,691 [podnet.py] => Task 17, Epoch 103/160 (LR 0.02818) => LSC_loss 0.18, Spatial_loss 2.62, Flat_loss 0.15, Train_acc 97.46, Test_acc 52.94
2025-02-13 18:52:40,442 [podnet.py] => Task 17, Epoch 104/160 (LR 0.02730) => LSC_loss 0.19, Spatial_loss 2.51, Flat_loss 0.15, Train_acc 96.74, Test_acc 52.57
2025-02-13 18:52:42,233 [podnet.py] => Task 17, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 2.66, Flat_loss 0.16, Train_acc 96.48, Test_acc 50.88
2025-02-13 18:52:43,966 [podnet.py] => Task 17, Epoch 106/160 (LR 0.02557) => LSC_loss 0.19, Spatial_loss 2.52, Flat_loss 0.14, Train_acc 97.05, Test_acc 52.45
2025-02-13 18:52:45,709 [podnet.py] => Task 17, Epoch 107/160 (LR 0.02472) => LSC_loss 0.19, Spatial_loss 2.46, Flat_loss 0.14, Train_acc 97.31, Test_acc 54.07
2025-02-13 18:52:47,464 [podnet.py] => Task 17, Epoch 108/160 (LR 0.02388) => LSC_loss 0.19, Spatial_loss 2.41, Flat_loss 0.14, Train_acc 96.86, Test_acc 53.32
2025-02-13 18:52:49,216 [podnet.py] => Task 17, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 2.45, Flat_loss 0.14, Train_acc 97.58, Test_acc 53.63
2025-02-13 18:52:50,905 [podnet.py] => Task 17, Epoch 110/160 (LR 0.02222) => LSC_loss 0.19, Spatial_loss 2.45, Flat_loss 0.14, Train_acc 97.39, Test_acc 52.35
2025-02-13 18:52:52,651 [podnet.py] => Task 17, Epoch 111/160 (LR 0.02141) => LSC_loss 0.19, Spatial_loss 2.33, Flat_loss 0.13, Train_acc 96.89, Test_acc 52.51
2025-02-13 18:52:54,407 [podnet.py] => Task 17, Epoch 112/160 (LR 0.02061) => LSC_loss 0.19, Spatial_loss 2.32, Flat_loss 0.14, Train_acc 97.27, Test_acc 52.45
2025-02-13 18:52:56,147 [podnet.py] => Task 17, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 2.25, Flat_loss 0.13, Train_acc 97.46, Test_acc 53.12
2025-02-13 18:52:57,878 [podnet.py] => Task 17, Epoch 114/160 (LR 0.01905) => LSC_loss 0.19, Spatial_loss 2.42, Flat_loss 0.13, Train_acc 96.93, Test_acc 52.95
2025-02-13 18:52:59,582 [podnet.py] => Task 17, Epoch 115/160 (LR 0.01828) => LSC_loss 0.18, Spatial_loss 2.25, Flat_loss 0.13, Train_acc 97.46, Test_acc 53.74
2025-02-13 18:53:01,318 [podnet.py] => Task 17, Epoch 116/160 (LR 0.01753) => LSC_loss 0.19, Spatial_loss 2.30, Flat_loss 0.13, Train_acc 96.93, Test_acc 52.58
2025-02-13 18:53:03,052 [podnet.py] => Task 17, Epoch 117/160 (LR 0.01679) => LSC_loss 0.20, Spatial_loss 2.28, Flat_loss 0.12, Train_acc 97.16, Test_acc 52.80
2025-02-13 18:53:04,804 [podnet.py] => Task 17, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 2.26, Flat_loss 0.13, Train_acc 97.20, Test_acc 53.21
2025-02-13 18:53:06,490 [podnet.py] => Task 17, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 2.23, Flat_loss 0.12, Train_acc 97.23, Test_acc 54.29
2025-02-13 18:53:08,234 [podnet.py] => Task 17, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 2.17, Flat_loss 0.12, Train_acc 97.01, Test_acc 53.32
2025-02-13 18:53:09,924 [podnet.py] => Task 17, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 2.17, Flat_loss 0.12, Train_acc 97.50, Test_acc 54.04
2025-02-13 18:53:11,651 [podnet.py] => Task 17, Epoch 122/160 (LR 0.01328) => LSC_loss 0.19, Spatial_loss 2.12, Flat_loss 0.12, Train_acc 96.97, Test_acc 51.87
2025-02-13 18:53:13,405 [podnet.py] => Task 17, Epoch 123/160 (LR 0.01262) => LSC_loss 0.18, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 97.12, Test_acc 52.43
2025-02-13 18:53:15,138 [podnet.py] => Task 17, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 2.17, Flat_loss 0.12, Train_acc 97.42, Test_acc 53.58
2025-02-13 18:53:16,851 [podnet.py] => Task 17, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 2.09, Flat_loss 0.12, Train_acc 97.46, Test_acc 53.56
2025-02-13 18:53:18,591 [podnet.py] => Task 17, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 2.03, Flat_loss 0.11, Train_acc 97.05, Test_acc 52.58
2025-02-13 18:53:20,341 [podnet.py] => Task 17, Epoch 127/160 (LR 0.01013) => LSC_loss 0.19, Spatial_loss 2.04, Flat_loss 0.11, Train_acc 97.01, Test_acc 53.92
2025-02-13 18:53:22,067 [podnet.py] => Task 17, Epoch 128/160 (LR 0.00955) => LSC_loss 0.19, Spatial_loss 2.14, Flat_loss 0.12, Train_acc 96.86, Test_acc 51.74
2025-02-13 18:53:23,833 [podnet.py] => Task 17, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 97.50, Test_acc 54.15
2025-02-13 18:53:25,543 [podnet.py] => Task 17, Epoch 130/160 (LR 0.00843) => LSC_loss 0.19, Spatial_loss 1.97, Flat_loss 0.11, Train_acc 97.27, Test_acc 53.68
2025-02-13 18:53:27,290 [podnet.py] => Task 17, Epoch 131/160 (LR 0.00789) => LSC_loss 0.19, Spatial_loss 2.01, Flat_loss 0.11, Train_acc 97.31, Test_acc 54.06
2025-02-13 18:53:29,035 [podnet.py] => Task 17, Epoch 132/160 (LR 0.00737) => LSC_loss 0.19, Spatial_loss 1.89, Flat_loss 0.11, Train_acc 97.01, Test_acc 53.63
2025-02-13 18:53:30,808 [podnet.py] => Task 17, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 1.91, Flat_loss 0.10, Train_acc 97.08, Test_acc 53.87
2025-02-13 18:53:32,583 [podnet.py] => Task 17, Epoch 134/160 (LR 0.00638) => LSC_loss 0.19, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 96.89, Test_acc 54.06
2025-02-13 18:53:34,364 [podnet.py] => Task 17, Epoch 135/160 (LR 0.00590) => LSC_loss 0.20, Spatial_loss 1.92, Flat_loss 0.10, Train_acc 96.97, Test_acc 53.55
2025-02-13 18:53:36,125 [podnet.py] => Task 17, Epoch 136/160 (LR 0.00545) => LSC_loss 0.18, Spatial_loss 1.93, Flat_loss 0.11, Train_acc 97.27, Test_acc 53.39
2025-02-13 18:53:37,815 [podnet.py] => Task 17, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 1.90, Flat_loss 0.10, Train_acc 97.20, Test_acc 53.48
2025-02-13 18:53:39,565 [podnet.py] => Task 17, Epoch 138/160 (LR 0.00459) => LSC_loss 0.19, Spatial_loss 1.87, Flat_loss 0.10, Train_acc 97.23, Test_acc 54.43
2025-02-13 18:53:41,354 [podnet.py] => Task 17, Epoch 139/160 (LR 0.00419) => LSC_loss 0.19, Spatial_loss 1.76, Flat_loss 0.10, Train_acc 97.20, Test_acc 54.25
2025-02-13 18:53:43,086 [podnet.py] => Task 17, Epoch 140/160 (LR 0.00381) => LSC_loss 0.18, Spatial_loss 1.80, Flat_loss 0.10, Train_acc 96.78, Test_acc 54.58
2025-02-13 18:53:44,802 [podnet.py] => Task 17, Epoch 141/160 (LR 0.00344) => LSC_loss 0.19, Spatial_loss 1.80, Flat_loss 0.10, Train_acc 97.16, Test_acc 54.23
2025-02-13 18:53:46,569 [podnet.py] => Task 17, Epoch 142/160 (LR 0.00309) => LSC_loss 0.18, Spatial_loss 1.76, Flat_loss 0.10, Train_acc 97.69, Test_acc 53.49
2025-02-13 18:53:48,351 [podnet.py] => Task 17, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.82, Flat_loss 0.10, Train_acc 97.20, Test_acc 54.01
2025-02-13 18:53:50,092 [podnet.py] => Task 17, Epoch 144/160 (LR 0.00245) => LSC_loss 0.18, Spatial_loss 1.83, Flat_loss 0.10, Train_acc 97.84, Test_acc 53.44
2025-02-13 18:53:51,843 [podnet.py] => Task 17, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.73, Flat_loss 0.09, Train_acc 97.16, Test_acc 54.30
2025-02-13 18:53:53,551 [podnet.py] => Task 17, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.72, Flat_loss 0.10, Train_acc 97.27, Test_acc 54.05
2025-02-13 18:53:55,302 [podnet.py] => Task 17, Epoch 147/160 (LR 0.00162) => LSC_loss 0.18, Spatial_loss 1.76, Flat_loss 0.10, Train_acc 97.42, Test_acc 54.07
2025-02-13 18:53:56,987 [podnet.py] => Task 17, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.69, Flat_loss 0.10, Train_acc 96.97, Test_acc 54.31
2025-02-13 18:53:58,746 [podnet.py] => Task 17, Epoch 149/160 (LR 0.00116) => LSC_loss 0.18, Spatial_loss 1.72, Flat_loss 0.10, Train_acc 97.20, Test_acc 54.02
2025-02-13 18:54:00,458 [podnet.py] => Task 17, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.68, Flat_loss 0.09, Train_acc 97.16, Test_acc 54.12
2025-02-13 18:54:02,194 [podnet.py] => Task 17, Epoch 151/160 (LR 0.00078) => LSC_loss 0.18, Spatial_loss 1.65, Flat_loss 0.09, Train_acc 96.93, Test_acc 53.99
2025-02-13 18:54:03,970 [podnet.py] => Task 17, Epoch 152/160 (LR 0.00062) => LSC_loss 0.18, Spatial_loss 1.61, Flat_loss 0.09, Train_acc 97.23, Test_acc 54.13
2025-02-13 18:54:05,692 [podnet.py] => Task 17, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 1.62, Flat_loss 0.09, Train_acc 97.12, Test_acc 54.10
2025-02-13 18:54:07,445 [podnet.py] => Task 17, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.71, Flat_loss 0.10, Train_acc 97.69, Test_acc 54.05
2025-02-13 18:54:09,130 [podnet.py] => Task 17, Epoch 155/160 (LR 0.00024) => LSC_loss 0.19, Spatial_loss 1.66, Flat_loss 0.09, Train_acc 96.78, Test_acc 54.46
2025-02-13 18:54:10,885 [podnet.py] => Task 17, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.61, Flat_loss 0.09, Train_acc 97.05, Test_acc 54.10
2025-02-13 18:54:12,587 [podnet.py] => Task 17, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.60, Flat_loss 0.09, Train_acc 97.20, Test_acc 54.25
2025-02-13 18:54:14,298 [podnet.py] => Task 17, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 1.61, Flat_loss 0.09, Train_acc 97.20, Test_acc 54.02
2025-02-13 18:54:16,005 [podnet.py] => Task 17, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 1.67, Flat_loss 0.09, Train_acc 96.67, Test_acc 54.18
2025-02-13 18:54:17,709 [podnet.py] => Task 17, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.62, Flat_loss 0.09, Train_acc 97.08, Test_acc 54.30
2025-02-13 18:54:17,709 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 18:54:17,709 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:54:44,687 [podnet.py] => The size of finetune dataset: 1680
2025-02-13 18:54:46,251 [podnet.py] => Task 17, Epoch 1/20 (LR 0.00497) => LSC_loss 0.16, Spatial_loss 2.38, Flat_loss 0.16, Train_acc 97.08, Test_acc 54.42
2025-02-13 18:54:47,743 [podnet.py] => Task 17, Epoch 2/20 (LR 0.00488) => LSC_loss 0.14, Spatial_loss 2.13, Flat_loss 0.10, Train_acc 98.93, Test_acc 54.05
2025-02-13 18:54:49,281 [podnet.py] => Task 17, Epoch 3/20 (LR 0.00473) => LSC_loss 0.10, Spatial_loss 2.05, Flat_loss 0.09, Train_acc 99.11, Test_acc 54.33
2025-02-13 18:54:50,784 [podnet.py] => Task 17, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 1.94, Flat_loss 0.09, Train_acc 99.35, Test_acc 54.12
2025-02-13 18:54:52,331 [podnet.py] => Task 17, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 1.91, Flat_loss 0.08, Train_acc 99.11, Test_acc 54.33
2025-02-13 18:54:53,821 [podnet.py] => Task 17, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.95, Flat_loss 0.08, Train_acc 99.17, Test_acc 54.43
2025-02-13 18:54:55,332 [podnet.py] => Task 17, Epoch 7/20 (LR 0.00363) => LSC_loss 0.14, Spatial_loss 2.04, Flat_loss 0.09, Train_acc 98.57, Test_acc 54.96
2025-02-13 18:54:56,841 [podnet.py] => Task 17, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 2.00, Flat_loss 0.08, Train_acc 99.35, Test_acc 53.73
2025-02-13 18:54:58,385 [podnet.py] => Task 17, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 1.93, Flat_loss 0.08, Train_acc 99.17, Test_acc 54.64
2025-02-13 18:54:59,874 [podnet.py] => Task 17, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 1.91, Flat_loss 0.08, Train_acc 99.40, Test_acc 54.31
2025-02-13 18:55:01,356 [podnet.py] => Task 17, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 1.83, Flat_loss 0.07, Train_acc 98.99, Test_acc 54.62
2025-02-13 18:55:02,849 [podnet.py] => Task 17, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 1.91, Flat_loss 0.08, Train_acc 99.17, Test_acc 54.73
2025-02-13 18:55:04,308 [podnet.py] => Task 17, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 98.93, Test_acc 54.89
2025-02-13 18:55:05,875 [podnet.py] => Task 17, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 99.46, Test_acc 54.58
2025-02-13 18:55:07,397 [podnet.py] => Task 17, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 1.94, Flat_loss 0.08, Train_acc 99.05, Test_acc 54.85
2025-02-13 18:55:08,939 [podnet.py] => Task 17, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 98.87, Test_acc 54.82
2025-02-13 18:55:10,428 [podnet.py] => Task 17, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 1.79, Flat_loss 0.07, Train_acc 99.46, Test_acc 54.88
2025-02-13 18:55:11,940 [podnet.py] => Task 17, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 99.23, Test_acc 54.94
2025-02-13 18:55:13,470 [podnet.py] => Task 17, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 1.80, Flat_loss 0.07, Train_acc 99.76, Test_acc 54.86
2025-02-13 18:55:14,997 [podnet.py] => Task 17, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 99.29, Test_acc 55.08
2025-02-13 18:55:15,000 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 18:55:42,558 [podnet.py] => Exemplar size: 1680
2025-02-13 18:55:42,558 [trainer.py] => CNN: {'total': 55.08, '00-09': 65.4, '10-19': 43.4, '20-29': 62.4, '30-39': 53.8, '40-49': 59.0, '50-59': 39.2, '60-69': 52.5, '70-79': 58.3, '80-89': 71.75, 'old': 54.7, 'new': 71.0}
2025-02-13 18:55:42,558 [trainer.py] => NME: {'total': 54.93, '00-09': 67.4, '10-19': 47.4, '20-29': 63.8, '30-39': 53.8, '40-49': 59.2, '50-59': 34.4, '60-69': 52.0, '70-79': 57.7, '80-89': 64.25, 'old': 54.73, 'new': 63.0}
2025-02-13 18:55:42,558 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08]
2025-02-13 18:55:42,558 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8]
2025-02-13 18:55:42,559 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93]
2025-02-13 18:55:42,559 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54]

2025-02-13 18:55:42,559 [trainer.py] => Average Accuracy (CNN): 64.1222222222222
2025-02-13 18:55:42,559 [trainer.py] => Average Accuracy (NME): 64.36166666666666
2025-02-13 18:55:42,559 [trainer.py] => All params: 520017
2025-02-13 18:55:42,559 [trainer.py] => Trainable params: 520017
2025-02-13 18:55:42,560 [podnet.py] => Learning on 84-86
2025-02-13 18:55:42,583 [podnet.py] => Adaptive factor: 6.557438524302
2025-02-13 18:55:44,404 [podnet.py] => Task 18, Epoch 1/160 (LR 0.09999) => LSC_loss 1.37, Spatial_loss 4.36, Flat_loss 0.61, Train_acc 78.25, Test_acc 42.60
2025-02-13 18:55:46,201 [podnet.py] => Task 18, Epoch 2/160 (LR 0.09996) => LSC_loss 0.48, Spatial_loss 5.33, Flat_loss 0.63, Train_acc 87.43, Test_acc 46.95
2025-02-13 18:55:47,992 [podnet.py] => Task 18, Epoch 3/160 (LR 0.09991) => LSC_loss 0.46, Spatial_loss 5.27, Flat_loss 0.61, Train_acc 88.02, Test_acc 46.15
2025-02-13 18:55:49,735 [podnet.py] => Task 18, Epoch 4/160 (LR 0.09985) => LSC_loss 0.43, Spatial_loss 5.22, Flat_loss 0.58, Train_acc 89.18, Test_acc 47.86
2025-02-13 18:55:51,459 [podnet.py] => Task 18, Epoch 5/160 (LR 0.09976) => LSC_loss 0.44, Spatial_loss 5.17, Flat_loss 0.57, Train_acc 88.62, Test_acc 42.03
2025-02-13 18:55:53,247 [podnet.py] => Task 18, Epoch 6/160 (LR 0.09965) => LSC_loss 0.40, Spatial_loss 5.23, Flat_loss 0.55, Train_acc 89.96, Test_acc 46.62
2025-02-13 18:55:54,976 [podnet.py] => Task 18, Epoch 7/160 (LR 0.09953) => LSC_loss 0.40, Spatial_loss 5.26, Flat_loss 0.53, Train_acc 90.41, Test_acc 43.62
2025-02-13 18:55:56,770 [podnet.py] => Task 18, Epoch 8/160 (LR 0.09938) => LSC_loss 0.35, Spatial_loss 4.86, Flat_loss 0.50, Train_acc 91.53, Test_acc 44.67
2025-02-13 18:55:58,562 [podnet.py] => Task 18, Epoch 9/160 (LR 0.09922) => LSC_loss 0.35, Spatial_loss 4.78, Flat_loss 0.47, Train_acc 92.35, Test_acc 49.42
2025-02-13 18:56:00,276 [podnet.py] => Task 18, Epoch 10/160 (LR 0.09904) => LSC_loss 0.36, Spatial_loss 4.83, Flat_loss 0.47, Train_acc 92.05, Test_acc 45.88
2025-02-13 18:56:02,022 [podnet.py] => Task 18, Epoch 11/160 (LR 0.09884) => LSC_loss 0.35, Spatial_loss 4.79, Flat_loss 0.47, Train_acc 92.05, Test_acc 47.24
2025-02-13 18:56:03,814 [podnet.py] => Task 18, Epoch 12/160 (LR 0.09862) => LSC_loss 0.33, Spatial_loss 4.56, Flat_loss 0.44, Train_acc 93.17, Test_acc 49.81
2025-02-13 18:56:05,563 [podnet.py] => Task 18, Epoch 13/160 (LR 0.09838) => LSC_loss 0.35, Spatial_loss 4.61, Flat_loss 0.44, Train_acc 92.24, Test_acc 48.65
2025-02-13 18:56:07,268 [podnet.py] => Task 18, Epoch 14/160 (LR 0.09812) => LSC_loss 0.33, Spatial_loss 4.56, Flat_loss 0.43, Train_acc 93.47, Test_acc 48.64
2025-02-13 18:56:09,059 [podnet.py] => Task 18, Epoch 15/160 (LR 0.09785) => LSC_loss 0.32, Spatial_loss 4.71, Flat_loss 0.43, Train_acc 93.06, Test_acc 45.01
2025-02-13 18:56:10,818 [podnet.py] => Task 18, Epoch 16/160 (LR 0.09755) => LSC_loss 0.32, Spatial_loss 4.53, Flat_loss 0.43, Train_acc 92.80, Test_acc 46.77
2025-02-13 18:56:12,596 [podnet.py] => Task 18, Epoch 17/160 (LR 0.09724) => LSC_loss 0.33, Spatial_loss 4.72, Flat_loss 0.42, Train_acc 92.35, Test_acc 45.06
2025-02-13 18:56:14,351 [podnet.py] => Task 18, Epoch 18/160 (LR 0.09691) => LSC_loss 0.34, Spatial_loss 4.71, Flat_loss 0.44, Train_acc 92.24, Test_acc 45.77
2025-02-13 18:56:16,117 [podnet.py] => Task 18, Epoch 19/160 (LR 0.09656) => LSC_loss 0.32, Spatial_loss 4.47, Flat_loss 0.41, Train_acc 93.32, Test_acc 46.93
2025-02-13 18:56:17,884 [podnet.py] => Task 18, Epoch 20/160 (LR 0.09619) => LSC_loss 0.29, Spatial_loss 4.27, Flat_loss 0.40, Train_acc 95.00, Test_acc 48.59
2025-02-13 18:56:19,701 [podnet.py] => Task 18, Epoch 21/160 (LR 0.09581) => LSC_loss 0.30, Spatial_loss 4.29, Flat_loss 0.39, Train_acc 94.10, Test_acc 47.16
2025-02-13 18:56:21,484 [podnet.py] => Task 18, Epoch 22/160 (LR 0.09541) => LSC_loss 0.31, Spatial_loss 4.23, Flat_loss 0.40, Train_acc 93.73, Test_acc 48.09
2025-02-13 18:56:23,247 [podnet.py] => Task 18, Epoch 23/160 (LR 0.09499) => LSC_loss 0.30, Spatial_loss 4.35, Flat_loss 0.41, Train_acc 93.96, Test_acc 47.03
2025-02-13 18:56:25,025 [podnet.py] => Task 18, Epoch 24/160 (LR 0.09455) => LSC_loss 0.30, Spatial_loss 4.21, Flat_loss 0.39, Train_acc 93.88, Test_acc 50.24
2025-02-13 18:56:26,783 [podnet.py] => Task 18, Epoch 25/160 (LR 0.09410) => LSC_loss 0.29, Spatial_loss 4.36, Flat_loss 0.39, Train_acc 93.81, Test_acc 47.53
2025-02-13 18:56:28,551 [podnet.py] => Task 18, Epoch 26/160 (LR 0.09362) => LSC_loss 0.31, Spatial_loss 4.33, Flat_loss 0.40, Train_acc 92.84, Test_acc 44.26
2025-02-13 18:56:30,275 [podnet.py] => Task 18, Epoch 27/160 (LR 0.09314) => LSC_loss 0.29, Spatial_loss 4.29, Flat_loss 0.39, Train_acc 94.03, Test_acc 47.86
2025-02-13 18:56:32,082 [podnet.py] => Task 18, Epoch 28/160 (LR 0.09263) => LSC_loss 0.30, Spatial_loss 4.29, Flat_loss 0.39, Train_acc 93.32, Test_acc 47.97
2025-02-13 18:56:33,813 [podnet.py] => Task 18, Epoch 29/160 (LR 0.09211) => LSC_loss 0.27, Spatial_loss 4.23, Flat_loss 0.37, Train_acc 94.59, Test_acc 44.55
2025-02-13 18:56:35,554 [podnet.py] => Task 18, Epoch 30/160 (LR 0.09157) => LSC_loss 0.27, Spatial_loss 4.13, Flat_loss 0.37, Train_acc 94.44, Test_acc 46.72
2025-02-13 18:56:37,286 [podnet.py] => Task 18, Epoch 31/160 (LR 0.09102) => LSC_loss 0.27, Spatial_loss 4.06, Flat_loss 0.36, Train_acc 94.37, Test_acc 47.80
2025-02-13 18:56:39,023 [podnet.py] => Task 18, Epoch 32/160 (LR 0.09045) => LSC_loss 0.29, Spatial_loss 4.17, Flat_loss 0.36, Train_acc 93.99, Test_acc 46.43
2025-02-13 18:56:40,749 [podnet.py] => Task 18, Epoch 33/160 (LR 0.08987) => LSC_loss 0.28, Spatial_loss 4.05, Flat_loss 0.36, Train_acc 94.33, Test_acc 46.66
2025-02-13 18:56:42,475 [podnet.py] => Task 18, Epoch 34/160 (LR 0.08927) => LSC_loss 0.27, Spatial_loss 4.03, Flat_loss 0.36, Train_acc 95.04, Test_acc 51.55
2025-02-13 18:56:44,256 [podnet.py] => Task 18, Epoch 35/160 (LR 0.08865) => LSC_loss 0.28, Spatial_loss 4.15, Flat_loss 0.35, Train_acc 94.70, Test_acc 45.03
2025-02-13 18:56:45,959 [podnet.py] => Task 18, Epoch 36/160 (LR 0.08802) => LSC_loss 0.28, Spatial_loss 4.11, Flat_loss 0.35, Train_acc 94.10, Test_acc 48.35
2025-02-13 18:56:47,678 [podnet.py] => Task 18, Epoch 37/160 (LR 0.08738) => LSC_loss 0.28, Spatial_loss 4.10, Flat_loss 0.37, Train_acc 94.37, Test_acc 46.94
2025-02-13 18:56:49,445 [podnet.py] => Task 18, Epoch 38/160 (LR 0.08672) => LSC_loss 0.26, Spatial_loss 3.96, Flat_loss 0.35, Train_acc 94.48, Test_acc 47.85
2025-02-13 18:56:51,179 [podnet.py] => Task 18, Epoch 39/160 (LR 0.08604) => LSC_loss 0.28, Spatial_loss 3.93, Flat_loss 0.34, Train_acc 93.99, Test_acc 50.56
2025-02-13 18:56:52,939 [podnet.py] => Task 18, Epoch 40/160 (LR 0.08536) => LSC_loss 0.28, Spatial_loss 4.05, Flat_loss 0.36, Train_acc 94.44, Test_acc 48.24
2025-02-13 18:56:54,698 [podnet.py] => Task 18, Epoch 41/160 (LR 0.08465) => LSC_loss 0.28, Spatial_loss 4.04, Flat_loss 0.35, Train_acc 94.18, Test_acc 46.45
2025-02-13 18:56:56,540 [podnet.py] => Task 18, Epoch 42/160 (LR 0.08394) => LSC_loss 0.25, Spatial_loss 3.95, Flat_loss 0.35, Train_acc 95.15, Test_acc 49.29
2025-02-13 18:56:58,323 [podnet.py] => Task 18, Epoch 43/160 (LR 0.08321) => LSC_loss 0.27, Spatial_loss 3.78, Flat_loss 0.33, Train_acc 94.85, Test_acc 49.08
2025-02-13 18:57:00,067 [podnet.py] => Task 18, Epoch 44/160 (LR 0.08247) => LSC_loss 0.28, Spatial_loss 3.95, Flat_loss 0.34, Train_acc 94.18, Test_acc 45.23
2025-02-13 18:57:01,832 [podnet.py] => Task 18, Epoch 45/160 (LR 0.08172) => LSC_loss 0.26, Spatial_loss 3.99, Flat_loss 0.35, Train_acc 95.19, Test_acc 49.08
2025-02-13 18:57:03,588 [podnet.py] => Task 18, Epoch 46/160 (LR 0.08095) => LSC_loss 0.27, Spatial_loss 3.95, Flat_loss 0.34, Train_acc 94.81, Test_acc 46.65
2025-02-13 18:57:05,406 [podnet.py] => Task 18, Epoch 47/160 (LR 0.08018) => LSC_loss 0.26, Spatial_loss 3.77, Flat_loss 0.33, Train_acc 94.55, Test_acc 50.41
2025-02-13 18:57:07,149 [podnet.py] => Task 18, Epoch 48/160 (LR 0.07939) => LSC_loss 0.26, Spatial_loss 3.81, Flat_loss 0.33, Train_acc 94.93, Test_acc 45.70
2025-02-13 18:57:08,939 [podnet.py] => Task 18, Epoch 49/160 (LR 0.07859) => LSC_loss 0.27, Spatial_loss 3.84, Flat_loss 0.33, Train_acc 94.78, Test_acc 47.58
2025-02-13 18:57:10,755 [podnet.py] => Task 18, Epoch 50/160 (LR 0.07778) => LSC_loss 0.27, Spatial_loss 3.73, Flat_loss 0.32, Train_acc 94.51, Test_acc 50.01
2025-02-13 18:57:12,502 [podnet.py] => Task 18, Epoch 51/160 (LR 0.07696) => LSC_loss 0.25, Spatial_loss 3.76, Flat_loss 0.31, Train_acc 95.04, Test_acc 46.53
2025-02-13 18:57:14,190 [podnet.py] => Task 18, Epoch 52/160 (LR 0.07612) => LSC_loss 0.26, Spatial_loss 3.73, Flat_loss 0.32, Train_acc 94.78, Test_acc 46.84
2025-02-13 18:57:15,853 [podnet.py] => Task 18, Epoch 53/160 (LR 0.07528) => LSC_loss 0.27, Spatial_loss 3.85, Flat_loss 0.31, Train_acc 94.51, Test_acc 48.71
2025-02-13 18:57:17,568 [podnet.py] => Task 18, Epoch 54/160 (LR 0.07443) => LSC_loss 0.23, Spatial_loss 3.85, Flat_loss 0.32, Train_acc 96.19, Test_acc 46.94
2025-02-13 18:57:19,301 [podnet.py] => Task 18, Epoch 55/160 (LR 0.07357) => LSC_loss 0.25, Spatial_loss 3.70, Flat_loss 0.31, Train_acc 94.81, Test_acc 46.50
2025-02-13 18:57:21,050 [podnet.py] => Task 18, Epoch 56/160 (LR 0.07270) => LSC_loss 0.25, Spatial_loss 3.62, Flat_loss 0.32, Train_acc 95.15, Test_acc 45.60
2025-02-13 18:57:22,805 [podnet.py] => Task 18, Epoch 57/160 (LR 0.07182) => LSC_loss 0.25, Spatial_loss 3.59, Flat_loss 0.30, Train_acc 95.37, Test_acc 50.00
2025-02-13 18:57:24,588 [podnet.py] => Task 18, Epoch 58/160 (LR 0.07093) => LSC_loss 0.26, Spatial_loss 3.69, Flat_loss 0.32, Train_acc 94.74, Test_acc 49.67
2025-02-13 18:57:26,355 [podnet.py] => Task 18, Epoch 59/160 (LR 0.07004) => LSC_loss 0.25, Spatial_loss 3.53, Flat_loss 0.30, Train_acc 95.07, Test_acc 52.08
2025-02-13 18:57:28,074 [podnet.py] => Task 18, Epoch 60/160 (LR 0.06913) => LSC_loss 0.24, Spatial_loss 3.59, Flat_loss 0.30, Train_acc 95.45, Test_acc 50.06
2025-02-13 18:57:29,805 [podnet.py] => Task 18, Epoch 61/160 (LR 0.06822) => LSC_loss 0.26, Spatial_loss 3.59, Flat_loss 0.30, Train_acc 95.07, Test_acc 51.14
2025-02-13 18:57:31,538 [podnet.py] => Task 18, Epoch 62/160 (LR 0.06731) => LSC_loss 0.25, Spatial_loss 3.44, Flat_loss 0.29, Train_acc 95.15, Test_acc 49.87
2025-02-13 18:57:33,338 [podnet.py] => Task 18, Epoch 63/160 (LR 0.06638) => LSC_loss 0.25, Spatial_loss 3.47, Flat_loss 0.29, Train_acc 94.81, Test_acc 48.05
2025-02-13 18:57:35,113 [podnet.py] => Task 18, Epoch 64/160 (LR 0.06545) => LSC_loss 0.25, Spatial_loss 3.58, Flat_loss 0.30, Train_acc 95.26, Test_acc 49.93
2025-02-13 18:57:36,837 [podnet.py] => Task 18, Epoch 65/160 (LR 0.06451) => LSC_loss 0.24, Spatial_loss 3.44, Flat_loss 0.28, Train_acc 95.67, Test_acc 48.76
2025-02-13 18:57:38,625 [podnet.py] => Task 18, Epoch 66/160 (LR 0.06357) => LSC_loss 0.25, Spatial_loss 3.59, Flat_loss 0.29, Train_acc 95.49, Test_acc 48.00
2025-02-13 18:57:40,424 [podnet.py] => Task 18, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 3.56, Flat_loss 0.28, Train_acc 95.37, Test_acc 49.64
2025-02-13 18:57:42,210 [podnet.py] => Task 18, Epoch 68/160 (LR 0.06167) => LSC_loss 0.26, Spatial_loss 3.55, Flat_loss 0.28, Train_acc 94.81, Test_acc 45.93
2025-02-13 18:57:43,984 [podnet.py] => Task 18, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.47, Flat_loss 0.28, Train_acc 95.56, Test_acc 49.62
2025-02-13 18:57:45,740 [podnet.py] => Task 18, Epoch 70/160 (LR 0.05975) => LSC_loss 0.26, Spatial_loss 3.42, Flat_loss 0.27, Train_acc 95.11, Test_acc 48.78
2025-02-13 18:57:47,468 [podnet.py] => Task 18, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 3.34, Flat_loss 0.28, Train_acc 95.37, Test_acc 49.98
2025-02-13 18:57:49,230 [podnet.py] => Task 18, Epoch 72/160 (LR 0.05782) => LSC_loss 0.25, Spatial_loss 3.50, Flat_loss 0.28, Train_acc 95.52, Test_acc 48.28
2025-02-13 18:57:50,980 [podnet.py] => Task 18, Epoch 73/160 (LR 0.05685) => LSC_loss 0.25, Spatial_loss 3.42, Flat_loss 0.28, Train_acc 95.00, Test_acc 51.02
2025-02-13 18:57:52,672 [podnet.py] => Task 18, Epoch 74/160 (LR 0.05588) => LSC_loss 0.24, Spatial_loss 3.48, Flat_loss 0.29, Train_acc 95.49, Test_acc 50.69
2025-02-13 18:57:54,366 [podnet.py] => Task 18, Epoch 75/160 (LR 0.05490) => LSC_loss 0.23, Spatial_loss 3.43, Flat_loss 0.27, Train_acc 96.19, Test_acc 47.90
2025-02-13 18:57:56,076 [podnet.py] => Task 18, Epoch 76/160 (LR 0.05392) => LSC_loss 0.24, Spatial_loss 3.25, Flat_loss 0.27, Train_acc 95.93, Test_acc 48.74
2025-02-13 18:57:57,785 [podnet.py] => Task 18, Epoch 77/160 (LR 0.05294) => LSC_loss 0.25, Spatial_loss 3.35, Flat_loss 0.26, Train_acc 94.96, Test_acc 49.40
2025-02-13 18:57:59,620 [podnet.py] => Task 18, Epoch 78/160 (LR 0.05196) => LSC_loss 0.24, Spatial_loss 3.20, Flat_loss 0.25, Train_acc 95.60, Test_acc 46.74
2025-02-13 18:58:01,380 [podnet.py] => Task 18, Epoch 79/160 (LR 0.05098) => LSC_loss 0.23, Spatial_loss 3.25, Flat_loss 0.26, Train_acc 95.52, Test_acc 49.29
2025-02-13 18:58:03,154 [podnet.py] => Task 18, Epoch 80/160 (LR 0.05000) => LSC_loss 0.24, Spatial_loss 3.33, Flat_loss 0.26, Train_acc 94.96, Test_acc 51.73
2025-02-13 18:58:04,880 [podnet.py] => Task 18, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 3.26, Flat_loss 0.26, Train_acc 96.19, Test_acc 50.33
2025-02-13 18:58:06,600 [podnet.py] => Task 18, Epoch 82/160 (LR 0.04804) => LSC_loss 0.25, Spatial_loss 3.29, Flat_loss 0.26, Train_acc 95.41, Test_acc 47.07
2025-02-13 18:58:08,301 [podnet.py] => Task 18, Epoch 83/160 (LR 0.04706) => LSC_loss 0.24, Spatial_loss 3.33, Flat_loss 0.26, Train_acc 95.37, Test_acc 49.15
2025-02-13 18:58:10,040 [podnet.py] => Task 18, Epoch 84/160 (LR 0.04608) => LSC_loss 0.22, Spatial_loss 3.07, Flat_loss 0.24, Train_acc 96.23, Test_acc 50.63
2025-02-13 18:58:11,778 [podnet.py] => Task 18, Epoch 85/160 (LR 0.04510) => LSC_loss 0.24, Spatial_loss 3.15, Flat_loss 0.24, Train_acc 95.60, Test_acc 48.93
2025-02-13 18:58:13,596 [podnet.py] => Task 18, Epoch 86/160 (LR 0.04412) => LSC_loss 0.25, Spatial_loss 3.10, Flat_loss 0.25, Train_acc 95.34, Test_acc 50.88
2025-02-13 18:58:15,340 [podnet.py] => Task 18, Epoch 87/160 (LR 0.04315) => LSC_loss 0.23, Spatial_loss 2.97, Flat_loss 0.24, Train_acc 95.86, Test_acc 50.30
2025-02-13 18:58:17,109 [podnet.py] => Task 18, Epoch 88/160 (LR 0.04218) => LSC_loss 0.23, Spatial_loss 2.91, Flat_loss 0.24, Train_acc 95.97, Test_acc 51.67
2025-02-13 18:58:18,880 [podnet.py] => Task 18, Epoch 89/160 (LR 0.04121) => LSC_loss 0.24, Spatial_loss 3.06, Flat_loss 0.23, Train_acc 95.63, Test_acc 50.17
2025-02-13 18:58:20,663 [podnet.py] => Task 18, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 3.11, Flat_loss 0.24, Train_acc 95.45, Test_acc 50.30
2025-02-13 18:58:22,434 [podnet.py] => Task 18, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 2.90, Flat_loss 0.23, Train_acc 96.16, Test_acc 51.29
2025-02-13 18:58:24,247 [podnet.py] => Task 18, Epoch 92/160 (LR 0.03833) => LSC_loss 0.24, Spatial_loss 3.01, Flat_loss 0.24, Train_acc 96.27, Test_acc 50.56
2025-02-13 18:58:25,988 [podnet.py] => Task 18, Epoch 93/160 (LR 0.03738) => LSC_loss 0.23, Spatial_loss 3.01, Flat_loss 0.23, Train_acc 95.78, Test_acc 51.37
2025-02-13 18:58:27,781 [podnet.py] => Task 18, Epoch 94/160 (LR 0.03643) => LSC_loss 0.24, Spatial_loss 2.92, Flat_loss 0.22, Train_acc 95.60, Test_acc 49.05
2025-02-13 18:58:29,564 [podnet.py] => Task 18, Epoch 95/160 (LR 0.03549) => LSC_loss 0.23, Spatial_loss 2.97, Flat_loss 0.23, Train_acc 95.37, Test_acc 48.65
2025-02-13 18:58:31,340 [podnet.py] => Task 18, Epoch 96/160 (LR 0.03455) => LSC_loss 0.23, Spatial_loss 3.01, Flat_loss 0.23, Train_acc 95.56, Test_acc 50.81
2025-02-13 18:58:33,092 [podnet.py] => Task 18, Epoch 97/160 (LR 0.03362) => LSC_loss 0.23, Spatial_loss 2.95, Flat_loss 0.22, Train_acc 95.97, Test_acc 51.48
2025-02-13 18:58:34,814 [podnet.py] => Task 18, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 2.87, Flat_loss 0.23, Train_acc 96.34, Test_acc 50.01
2025-02-13 18:58:36,610 [podnet.py] => Task 18, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 2.84, Flat_loss 0.22, Train_acc 96.01, Test_acc 50.01
2025-02-13 18:58:38,395 [podnet.py] => Task 18, Epoch 100/160 (LR 0.03087) => LSC_loss 0.22, Spatial_loss 2.76, Flat_loss 0.21, Train_acc 96.34, Test_acc 50.63
2025-02-13 18:58:40,161 [podnet.py] => Task 18, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 2.66, Flat_loss 0.20, Train_acc 95.71, Test_acc 49.36
2025-02-13 18:58:41,876 [podnet.py] => Task 18, Epoch 102/160 (LR 0.02907) => LSC_loss 0.23, Spatial_loss 2.70, Flat_loss 0.21, Train_acc 95.75, Test_acc 49.52
2025-02-13 18:58:43,648 [podnet.py] => Task 18, Epoch 103/160 (LR 0.02818) => LSC_loss 0.23, Spatial_loss 2.65, Flat_loss 0.20, Train_acc 95.86, Test_acc 50.66
2025-02-13 18:58:45,423 [podnet.py] => Task 18, Epoch 104/160 (LR 0.02730) => LSC_loss 0.22, Spatial_loss 2.71, Flat_loss 0.21, Train_acc 95.52, Test_acc 49.80
2025-02-13 18:58:47,219 [podnet.py] => Task 18, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 2.59, Flat_loss 0.20, Train_acc 95.56, Test_acc 51.13
2025-02-13 18:58:48,986 [podnet.py] => Task 18, Epoch 106/160 (LR 0.02557) => LSC_loss 0.24, Spatial_loss 2.57, Flat_loss 0.20, Train_acc 95.86, Test_acc 49.15
2025-02-13 18:58:50,749 [podnet.py] => Task 18, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 2.67, Flat_loss 0.21, Train_acc 96.04, Test_acc 51.65
2025-02-13 18:58:52,543 [podnet.py] => Task 18, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 2.56, Flat_loss 0.20, Train_acc 96.27, Test_acc 50.97
2025-02-13 18:58:54,309 [podnet.py] => Task 18, Epoch 109/160 (LR 0.02304) => LSC_loss 0.23, Spatial_loss 2.54, Flat_loss 0.19, Train_acc 95.82, Test_acc 50.90
2025-02-13 18:58:56,062 [podnet.py] => Task 18, Epoch 110/160 (LR 0.02222) => LSC_loss 0.24, Spatial_loss 2.51, Flat_loss 0.19, Train_acc 96.38, Test_acc 49.12
2025-02-13 18:58:57,798 [podnet.py] => Task 18, Epoch 111/160 (LR 0.02141) => LSC_loss 0.22, Spatial_loss 2.58, Flat_loss 0.20, Train_acc 96.27, Test_acc 51.76
2025-02-13 18:58:59,614 [podnet.py] => Task 18, Epoch 112/160 (LR 0.02061) => LSC_loss 0.22, Spatial_loss 2.59, Flat_loss 0.19, Train_acc 96.49, Test_acc 50.17
2025-02-13 18:59:01,309 [podnet.py] => Task 18, Epoch 113/160 (LR 0.01982) => LSC_loss 0.24, Spatial_loss 2.51, Flat_loss 0.19, Train_acc 95.45, Test_acc 50.34
2025-02-13 18:59:03,059 [podnet.py] => Task 18, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 2.44, Flat_loss 0.18, Train_acc 96.19, Test_acc 50.63
2025-02-13 18:59:04,790 [podnet.py] => Task 18, Epoch 115/160 (LR 0.01828) => LSC_loss 0.23, Spatial_loss 2.38, Flat_loss 0.19, Train_acc 95.90, Test_acc 50.74
2025-02-13 18:59:06,560 [podnet.py] => Task 18, Epoch 116/160 (LR 0.01753) => LSC_loss 0.23, Spatial_loss 2.31, Flat_loss 0.17, Train_acc 95.90, Test_acc 51.94
2025-02-13 18:59:08,291 [podnet.py] => Task 18, Epoch 117/160 (LR 0.01679) => LSC_loss 0.23, Spatial_loss 2.36, Flat_loss 0.18, Train_acc 95.75, Test_acc 51.98
2025-02-13 18:59:10,058 [podnet.py] => Task 18, Epoch 118/160 (LR 0.01606) => LSC_loss 0.23, Spatial_loss 2.39, Flat_loss 0.18, Train_acc 95.04, Test_acc 51.63
2025-02-13 18:59:11,796 [podnet.py] => Task 18, Epoch 119/160 (LR 0.01535) => LSC_loss 0.22, Spatial_loss 2.36, Flat_loss 0.18, Train_acc 96.27, Test_acc 51.95
2025-02-13 18:59:13,486 [podnet.py] => Task 18, Epoch 120/160 (LR 0.01464) => LSC_loss 0.24, Spatial_loss 2.28, Flat_loss 0.17, Train_acc 95.60, Test_acc 50.55
2025-02-13 18:59:15,245 [podnet.py] => Task 18, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 2.22, Flat_loss 0.17, Train_acc 96.01, Test_acc 50.76
2025-02-13 18:59:17,009 [podnet.py] => Task 18, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 2.25, Flat_loss 0.17, Train_acc 95.63, Test_acc 51.88
2025-02-13 18:59:18,789 [podnet.py] => Task 18, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 2.27, Flat_loss 0.17, Train_acc 95.67, Test_acc 50.65
2025-02-13 18:59:20,524 [podnet.py] => Task 18, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 2.18, Flat_loss 0.17, Train_acc 96.42, Test_acc 51.99
2025-02-13 18:59:22,238 [podnet.py] => Task 18, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 2.28, Flat_loss 0.17, Train_acc 95.86, Test_acc 50.80
2025-02-13 18:59:24,002 [podnet.py] => Task 18, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 2.17, Flat_loss 0.17, Train_acc 95.86, Test_acc 52.17
2025-02-13 18:59:25,742 [podnet.py] => Task 18, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 2.12, Flat_loss 0.17, Train_acc 96.08, Test_acc 52.23
2025-02-13 18:59:27,466 [podnet.py] => Task 18, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 2.10, Flat_loss 0.16, Train_acc 96.68, Test_acc 52.08
2025-02-13 18:59:29,187 [podnet.py] => Task 18, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 2.14, Flat_loss 0.16, Train_acc 95.97, Test_acc 52.21
2025-02-13 18:59:30,903 [podnet.py] => Task 18, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 2.06, Flat_loss 0.16, Train_acc 96.31, Test_acc 51.87
2025-02-13 18:59:32,692 [podnet.py] => Task 18, Epoch 131/160 (LR 0.00789) => LSC_loss 0.24, Spatial_loss 1.98, Flat_loss 0.16, Train_acc 95.52, Test_acc 52.28
2025-02-13 18:59:34,430 [podnet.py] => Task 18, Epoch 132/160 (LR 0.00737) => LSC_loss 0.23, Spatial_loss 2.03, Flat_loss 0.16, Train_acc 95.71, Test_acc 51.73
2025-02-13 18:59:36,202 [podnet.py] => Task 18, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 1.99, Flat_loss 0.16, Train_acc 96.46, Test_acc 52.14
2025-02-13 18:59:37,951 [podnet.py] => Task 18, Epoch 134/160 (LR 0.00638) => LSC_loss 0.23, Spatial_loss 1.96, Flat_loss 0.15, Train_acc 96.01, Test_acc 52.34
2025-02-13 18:59:39,730 [podnet.py] => Task 18, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 2.02, Flat_loss 0.16, Train_acc 95.86, Test_acc 51.73
2025-02-13 18:59:41,509 [podnet.py] => Task 18, Epoch 136/160 (LR 0.00545) => LSC_loss 0.24, Spatial_loss 2.00, Flat_loss 0.15, Train_acc 95.49, Test_acc 52.95
2025-02-13 18:59:43,297 [podnet.py] => Task 18, Epoch 137/160 (LR 0.00501) => LSC_loss 0.23, Spatial_loss 1.91, Flat_loss 0.15, Train_acc 96.27, Test_acc 52.36
2025-02-13 18:59:45,091 [podnet.py] => Task 18, Epoch 138/160 (LR 0.00459) => LSC_loss 0.23, Spatial_loss 2.03, Flat_loss 0.16, Train_acc 96.04, Test_acc 52.67
2025-02-13 18:59:46,809 [podnet.py] => Task 18, Epoch 139/160 (LR 0.00419) => LSC_loss 0.22, Spatial_loss 1.96, Flat_loss 0.16, Train_acc 96.12, Test_acc 52.30
2025-02-13 18:59:48,604 [podnet.py] => Task 18, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.90, Flat_loss 0.15, Train_acc 96.27, Test_acc 52.62
2025-02-13 18:59:50,388 [podnet.py] => Task 18, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.93, Flat_loss 0.15, Train_acc 96.23, Test_acc 51.93
2025-02-13 18:59:52,180 [podnet.py] => Task 18, Epoch 142/160 (LR 0.00309) => LSC_loss 0.23, Spatial_loss 1.86, Flat_loss 0.15, Train_acc 95.86, Test_acc 52.06
2025-02-13 18:59:53,983 [podnet.py] => Task 18, Epoch 143/160 (LR 0.00276) => LSC_loss 0.23, Spatial_loss 1.85, Flat_loss 0.14, Train_acc 95.93, Test_acc 51.99
2025-02-13 18:59:55,778 [podnet.py] => Task 18, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.80, Flat_loss 0.14, Train_acc 96.01, Test_acc 52.24
2025-02-13 18:59:57,563 [podnet.py] => Task 18, Epoch 145/160 (LR 0.00215) => LSC_loss 0.23, Spatial_loss 1.86, Flat_loss 0.15, Train_acc 96.23, Test_acc 52.26
2025-02-13 18:59:59,283 [podnet.py] => Task 18, Epoch 146/160 (LR 0.00188) => LSC_loss 0.23, Spatial_loss 1.85, Flat_loss 0.15, Train_acc 96.19, Test_acc 52.71
2025-02-13 19:00:01,080 [podnet.py] => Task 18, Epoch 147/160 (LR 0.00162) => LSC_loss 0.23, Spatial_loss 1.83, Flat_loss 0.14, Train_acc 96.04, Test_acc 52.13
2025-02-13 19:00:02,863 [podnet.py] => Task 18, Epoch 148/160 (LR 0.00138) => LSC_loss 0.23, Spatial_loss 1.84, Flat_loss 0.14, Train_acc 96.42, Test_acc 53.05
2025-02-13 19:00:04,607 [podnet.py] => Task 18, Epoch 149/160 (LR 0.00116) => LSC_loss 0.22, Spatial_loss 1.81, Flat_loss 0.14, Train_acc 95.97, Test_acc 52.07
2025-02-13 19:00:06,371 [podnet.py] => Task 18, Epoch 150/160 (LR 0.00096) => LSC_loss 0.22, Spatial_loss 1.73, Flat_loss 0.14, Train_acc 96.60, Test_acc 52.24
2025-02-13 19:00:08,149 [podnet.py] => Task 18, Epoch 151/160 (LR 0.00078) => LSC_loss 0.22, Spatial_loss 1.78, Flat_loss 0.14, Train_acc 96.42, Test_acc 52.41
2025-02-13 19:00:09,902 [podnet.py] => Task 18, Epoch 152/160 (LR 0.00062) => LSC_loss 0.24, Spatial_loss 1.73, Flat_loss 0.14, Train_acc 95.71, Test_acc 52.51
2025-02-13 19:00:11,600 [podnet.py] => Task 18, Epoch 153/160 (LR 0.00047) => LSC_loss 0.23, Spatial_loss 1.90, Flat_loss 0.15, Train_acc 96.04, Test_acc 52.52
2025-02-13 19:00:13,370 [podnet.py] => Task 18, Epoch 154/160 (LR 0.00035) => LSC_loss 0.23, Spatial_loss 1.78, Flat_loss 0.14, Train_acc 95.86, Test_acc 52.34
2025-02-13 19:00:15,135 [podnet.py] => Task 18, Epoch 155/160 (LR 0.00024) => LSC_loss 0.23, Spatial_loss 1.75, Flat_loss 0.14, Train_acc 96.01, Test_acc 52.41
2025-02-13 19:00:16,870 [podnet.py] => Task 18, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 1.73, Flat_loss 0.14, Train_acc 95.78, Test_acc 52.43
2025-02-13 19:00:18,605 [podnet.py] => Task 18, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.76, Flat_loss 0.14, Train_acc 96.34, Test_acc 52.15
2025-02-13 19:00:20,318 [podnet.py] => Task 18, Epoch 158/160 (LR 0.00004) => LSC_loss 0.23, Spatial_loss 1.71, Flat_loss 0.14, Train_acc 96.23, Test_acc 52.36
2025-02-13 19:00:22,061 [podnet.py] => Task 18, Epoch 159/160 (LR 0.00001) => LSC_loss 0.23, Spatial_loss 1.71, Flat_loss 0.14, Train_acc 95.93, Test_acc 52.55
2025-02-13 19:00:23,758 [podnet.py] => Task 18, Epoch 160/160 (LR 0.00000) => LSC_loss 0.23, Spatial_loss 1.76, Flat_loss 0.14, Train_acc 96.04, Test_acc 52.23
2025-02-13 19:00:23,759 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:00:23,759 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:00:51,098 [podnet.py] => The size of finetune dataset: 1720
2025-02-13 19:00:52,676 [podnet.py] => Task 18, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.27, Flat_loss 0.16, Train_acc 97.91, Test_acc 52.02
2025-02-13 19:00:54,224 [podnet.py] => Task 18, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 2.00, Flat_loss 0.09, Train_acc 99.19, Test_acc 52.88
2025-02-13 19:00:55,732 [podnet.py] => Task 18, Epoch 3/20 (LR 0.00473) => LSC_loss 0.10, Spatial_loss 1.99, Flat_loss 0.08, Train_acc 99.13, Test_acc 53.69
2025-02-13 19:00:57,289 [podnet.py] => Task 18, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 1.94, Flat_loss 0.07, Train_acc 99.01, Test_acc 53.41
2025-02-13 19:00:58,875 [podnet.py] => Task 18, Epoch 5/20 (LR 0.00427) => LSC_loss 0.10, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 98.84, Test_acc 53.49
2025-02-13 19:01:00,456 [podnet.py] => Task 18, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 99.07, Test_acc 53.70
2025-02-13 19:01:01,993 [podnet.py] => Task 18, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 1.85, Flat_loss 0.07, Train_acc 99.01, Test_acc 53.77
2025-02-13 19:01:03,555 [podnet.py] => Task 18, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 1.83, Flat_loss 0.07, Train_acc 99.13, Test_acc 53.64
2025-02-13 19:01:05,068 [podnet.py] => Task 18, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 98.95, Test_acc 53.78
2025-02-13 19:01:06,607 [podnet.py] => Task 18, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 1.83, Flat_loss 0.07, Train_acc 99.19, Test_acc 53.44
2025-02-13 19:01:08,136 [podnet.py] => Task 18, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 1.83, Flat_loss 0.06, Train_acc 99.07, Test_acc 53.67
2025-02-13 19:01:09,696 [podnet.py] => Task 18, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 98.84, Test_acc 53.71
2025-02-13 19:01:11,172 [podnet.py] => Task 18, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 98.90, Test_acc 53.58
2025-02-13 19:01:12,696 [podnet.py] => Task 18, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.24, Test_acc 54.01
2025-02-13 19:01:14,305 [podnet.py] => Task 18, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 1.75, Flat_loss 0.07, Train_acc 99.36, Test_acc 53.63
2025-02-13 19:01:15,864 [podnet.py] => Task 18, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 1.67, Flat_loss 0.06, Train_acc 98.95, Test_acc 53.84
2025-02-13 19:01:17,393 [podnet.py] => Task 18, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 1.72, Flat_loss 0.06, Train_acc 98.78, Test_acc 53.78
2025-02-13 19:01:18,924 [podnet.py] => Task 18, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 99.13, Test_acc 53.81
2025-02-13 19:01:20,480 [podnet.py] => Task 18, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 1.64, Flat_loss 0.06, Train_acc 98.84, Test_acc 53.94
2025-02-13 19:01:22,035 [podnet.py] => Task 18, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 1.61, Flat_loss 0.05, Train_acc 98.90, Test_acc 53.83
2025-02-13 19:01:22,037 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:01:51,337 [podnet.py] => Exemplar size: 1720
2025-02-13 19:01:51,337 [trainer.py] => CNN: {'total': 53.83, '00-09': 64.3, '10-19': 42.1, '20-29': 62.4, '30-39': 52.4, '40-49': 57.1, '50-59': 36.6, '60-69': 51.5, '70-79': 57.7, '80-89': 64.67, 'old': 53.88, 'new': 51.5}
2025-02-13 19:01:51,338 [trainer.py] => NME: {'total': 53.76, '00-09': 66.8, '10-19': 45.9, '20-29': 62.9, '30-39': 53.5, '40-49': 58.1, '50-59': 33.4, '60-69': 49.2, '70-79': 57.6, '80-89': 58.17, 'old': 53.98, 'new': 44.5}
2025-02-13 19:01:51,338 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83]
2025-02-13 19:01:51,338 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83]
2025-02-13 19:01:51,338 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76]
2025-02-13 19:01:51,338 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5]

2025-02-13 19:01:51,338 [trainer.py] => Average Accuracy (CNN): 63.58052631578946
2025-02-13 19:01:51,338 [trainer.py] => Average Accuracy (NME): 63.80368421052631
2025-02-13 19:01:51,338 [trainer.py] => All params: 521297
2025-02-13 19:01:51,338 [trainer.py] => Trainable params: 521297
2025-02-13 19:01:51,339 [podnet.py] => Learning on 86-88
2025-02-13 19:01:51,361 [podnet.py] => Adaptive factor: 6.6332495807108
2025-02-13 19:01:53,180 [podnet.py] => Task 19, Epoch 1/160 (LR 0.09999) => LSC_loss 1.28, Spatial_loss 4.54, Flat_loss 0.67, Train_acc 79.93, Test_acc 37.56
2025-02-13 19:01:54,985 [podnet.py] => Task 19, Epoch 2/160 (LR 0.09996) => LSC_loss 0.46, Spatial_loss 5.47, Flat_loss 0.69, Train_acc 86.95, Test_acc 42.70
2025-02-13 19:01:56,768 [podnet.py] => Task 19, Epoch 3/160 (LR 0.09991) => LSC_loss 0.43, Spatial_loss 5.52, Flat_loss 0.65, Train_acc 89.89, Test_acc 41.56
2025-02-13 19:01:58,526 [podnet.py] => Task 19, Epoch 4/160 (LR 0.09985) => LSC_loss 0.43, Spatial_loss 5.57, Flat_loss 0.66, Train_acc 89.04, Test_acc 45.06
2025-02-13 19:02:00,320 [podnet.py] => Task 19, Epoch 5/160 (LR 0.09976) => LSC_loss 0.41, Spatial_loss 5.59, Flat_loss 0.63, Train_acc 90.22, Test_acc 44.43
2025-02-13 19:02:02,174 [podnet.py] => Task 19, Epoch 6/160 (LR 0.09965) => LSC_loss 0.37, Spatial_loss 5.25, Flat_loss 0.56, Train_acc 91.80, Test_acc 44.09
2025-02-13 19:02:03,988 [podnet.py] => Task 19, Epoch 7/160 (LR 0.09953) => LSC_loss 0.34, Spatial_loss 4.99, Flat_loss 0.52, Train_acc 92.13, Test_acc 41.85
2025-02-13 19:02:05,815 [podnet.py] => Task 19, Epoch 8/160 (LR 0.09938) => LSC_loss 0.39, Spatial_loss 5.27, Flat_loss 0.54, Train_acc 91.47, Test_acc 45.05
2025-02-13 19:02:07,561 [podnet.py] => Task 19, Epoch 9/160 (LR 0.09922) => LSC_loss 0.35, Spatial_loss 5.16, Flat_loss 0.53, Train_acc 92.21, Test_acc 44.57
2025-02-13 19:02:09,317 [podnet.py] => Task 19, Epoch 10/160 (LR 0.09904) => LSC_loss 0.32, Spatial_loss 4.94, Flat_loss 0.50, Train_acc 92.72, Test_acc 44.43
2025-02-13 19:02:11,090 [podnet.py] => Task 19, Epoch 11/160 (LR 0.09884) => LSC_loss 0.32, Spatial_loss 4.64, Flat_loss 0.45, Train_acc 92.79, Test_acc 45.52
2025-02-13 19:02:12,906 [podnet.py] => Task 19, Epoch 12/160 (LR 0.09862) => LSC_loss 0.32, Spatial_loss 4.66, Flat_loss 0.44, Train_acc 93.38, Test_acc 41.48
2025-02-13 19:02:14,714 [podnet.py] => Task 19, Epoch 13/160 (LR 0.09838) => LSC_loss 0.32, Spatial_loss 4.78, Flat_loss 0.45, Train_acc 93.64, Test_acc 42.03
2025-02-13 19:02:16,565 [podnet.py] => Task 19, Epoch 14/160 (LR 0.09812) => LSC_loss 0.34, Spatial_loss 4.94, Flat_loss 0.49, Train_acc 92.94, Test_acc 43.92
2025-02-13 19:02:18,356 [podnet.py] => Task 19, Epoch 15/160 (LR 0.09785) => LSC_loss 0.33, Spatial_loss 4.92, Flat_loss 0.50, Train_acc 92.94, Test_acc 46.20
2025-02-13 19:02:20,146 [podnet.py] => Task 19, Epoch 16/160 (LR 0.09755) => LSC_loss 0.34, Spatial_loss 4.85, Flat_loss 0.48, Train_acc 91.95, Test_acc 44.27
2025-02-13 19:02:21,925 [podnet.py] => Task 19, Epoch 17/160 (LR 0.09724) => LSC_loss 0.30, Spatial_loss 4.61, Flat_loss 0.45, Train_acc 94.04, Test_acc 45.12
2025-02-13 19:02:23,749 [podnet.py] => Task 19, Epoch 18/160 (LR 0.09691) => LSC_loss 0.28, Spatial_loss 4.46, Flat_loss 0.42, Train_acc 94.60, Test_acc 46.73
2025-02-13 19:02:25,528 [podnet.py] => Task 19, Epoch 19/160 (LR 0.09656) => LSC_loss 0.30, Spatial_loss 4.43, Flat_loss 0.40, Train_acc 94.34, Test_acc 42.61
2025-02-13 19:02:27,311 [podnet.py] => Task 19, Epoch 20/160 (LR 0.09619) => LSC_loss 0.30, Spatial_loss 4.72, Flat_loss 0.44, Train_acc 93.86, Test_acc 47.33
2025-02-13 19:02:29,066 [podnet.py] => Task 19, Epoch 21/160 (LR 0.09581) => LSC_loss 0.31, Spatial_loss 4.74, Flat_loss 0.47, Train_acc 93.53, Test_acc 46.30
2025-02-13 19:02:30,858 [podnet.py] => Task 19, Epoch 22/160 (LR 0.09541) => LSC_loss 0.29, Spatial_loss 4.73, Flat_loss 0.44, Train_acc 93.79, Test_acc 45.19
2025-02-13 19:02:32,623 [podnet.py] => Task 19, Epoch 23/160 (LR 0.09499) => LSC_loss 0.28, Spatial_loss 4.57, Flat_loss 0.41, Train_acc 94.34, Test_acc 47.47
2025-02-13 19:02:34,350 [podnet.py] => Task 19, Epoch 24/160 (LR 0.09455) => LSC_loss 0.29, Spatial_loss 4.58, Flat_loss 0.41, Train_acc 94.19, Test_acc 45.48
2025-02-13 19:02:36,125 [podnet.py] => Task 19, Epoch 25/160 (LR 0.09410) => LSC_loss 0.30, Spatial_loss 4.65, Flat_loss 0.43, Train_acc 93.82, Test_acc 45.77
2025-02-13 19:02:37,877 [podnet.py] => Task 19, Epoch 26/160 (LR 0.09362) => LSC_loss 0.28, Spatial_loss 4.43, Flat_loss 0.41, Train_acc 94.34, Test_acc 42.77
2025-02-13 19:02:39,657 [podnet.py] => Task 19, Epoch 27/160 (LR 0.09314) => LSC_loss 0.30, Spatial_loss 4.33, Flat_loss 0.39, Train_acc 93.97, Test_acc 47.70
2025-02-13 19:02:41,443 [podnet.py] => Task 19, Epoch 28/160 (LR 0.09263) => LSC_loss 0.27, Spatial_loss 4.45, Flat_loss 0.42, Train_acc 94.89, Test_acc 46.52
2025-02-13 19:02:43,254 [podnet.py] => Task 19, Epoch 29/160 (LR 0.09211) => LSC_loss 0.29, Spatial_loss 4.33, Flat_loss 0.39, Train_acc 94.63, Test_acc 45.74
2025-02-13 19:02:45,033 [podnet.py] => Task 19, Epoch 30/160 (LR 0.09157) => LSC_loss 0.26, Spatial_loss 4.31, Flat_loss 0.40, Train_acc 95.00, Test_acc 47.75
2025-02-13 19:02:46,829 [podnet.py] => Task 19, Epoch 31/160 (LR 0.09102) => LSC_loss 0.27, Spatial_loss 4.27, Flat_loss 0.38, Train_acc 94.85, Test_acc 41.62
2025-02-13 19:02:48,621 [podnet.py] => Task 19, Epoch 32/160 (LR 0.09045) => LSC_loss 0.27, Spatial_loss 4.08, Flat_loss 0.36, Train_acc 94.89, Test_acc 46.18
2025-02-13 19:02:50,394 [podnet.py] => Task 19, Epoch 33/160 (LR 0.08987) => LSC_loss 0.27, Spatial_loss 4.17, Flat_loss 0.37, Train_acc 94.74, Test_acc 45.98
2025-02-13 19:02:52,175 [podnet.py] => Task 19, Epoch 34/160 (LR 0.08927) => LSC_loss 0.27, Spatial_loss 4.20, Flat_loss 0.38, Train_acc 95.26, Test_acc 47.70
2025-02-13 19:02:53,930 [podnet.py] => Task 19, Epoch 35/160 (LR 0.08865) => LSC_loss 0.27, Spatial_loss 4.28, Flat_loss 0.38, Train_acc 95.07, Test_acc 49.27
2025-02-13 19:02:55,652 [podnet.py] => Task 19, Epoch 36/160 (LR 0.08802) => LSC_loss 0.27, Spatial_loss 4.15, Flat_loss 0.36, Train_acc 94.04, Test_acc 47.76
2025-02-13 19:02:57,449 [podnet.py] => Task 19, Epoch 37/160 (LR 0.08738) => LSC_loss 0.26, Spatial_loss 4.19, Flat_loss 0.37, Train_acc 94.96, Test_acc 44.51
2025-02-13 19:02:59,180 [podnet.py] => Task 19, Epoch 38/160 (LR 0.08672) => LSC_loss 0.26, Spatial_loss 4.19, Flat_loss 0.35, Train_acc 94.89, Test_acc 45.26
2025-02-13 19:03:00,963 [podnet.py] => Task 19, Epoch 39/160 (LR 0.08604) => LSC_loss 0.27, Spatial_loss 4.02, Flat_loss 0.34, Train_acc 95.04, Test_acc 48.83
2025-02-13 19:03:02,753 [podnet.py] => Task 19, Epoch 40/160 (LR 0.08536) => LSC_loss 0.26, Spatial_loss 4.08, Flat_loss 0.36, Train_acc 95.37, Test_acc 45.26
2025-02-13 19:03:04,538 [podnet.py] => Task 19, Epoch 41/160 (LR 0.08465) => LSC_loss 0.26, Spatial_loss 4.11, Flat_loss 0.36, Train_acc 94.78, Test_acc 46.07
2025-02-13 19:03:06,311 [podnet.py] => Task 19, Epoch 42/160 (LR 0.08394) => LSC_loss 0.25, Spatial_loss 4.07, Flat_loss 0.35, Train_acc 95.40, Test_acc 46.27
2025-02-13 19:03:08,071 [podnet.py] => Task 19, Epoch 43/160 (LR 0.08321) => LSC_loss 0.26, Spatial_loss 4.11, Flat_loss 0.36, Train_acc 94.82, Test_acc 48.16
2025-02-13 19:03:09,927 [podnet.py] => Task 19, Epoch 44/160 (LR 0.08247) => LSC_loss 0.26, Spatial_loss 3.99, Flat_loss 0.34, Train_acc 95.33, Test_acc 46.34
2025-02-13 19:03:11,758 [podnet.py] => Task 19, Epoch 45/160 (LR 0.08172) => LSC_loss 0.25, Spatial_loss 3.95, Flat_loss 0.33, Train_acc 95.74, Test_acc 45.66
2025-02-13 19:03:13,525 [podnet.py] => Task 19, Epoch 46/160 (LR 0.08095) => LSC_loss 0.25, Spatial_loss 4.06, Flat_loss 0.34, Train_acc 94.93, Test_acc 47.42
2025-02-13 19:03:15,302 [podnet.py] => Task 19, Epoch 47/160 (LR 0.08018) => LSC_loss 0.25, Spatial_loss 4.07, Flat_loss 0.34, Train_acc 95.51, Test_acc 48.31
2025-02-13 19:03:17,164 [podnet.py] => Task 19, Epoch 48/160 (LR 0.07939) => LSC_loss 0.26, Spatial_loss 4.05, Flat_loss 0.33, Train_acc 94.63, Test_acc 46.42
2025-02-13 19:03:18,883 [podnet.py] => Task 19, Epoch 49/160 (LR 0.07859) => LSC_loss 0.24, Spatial_loss 4.01, Flat_loss 0.33, Train_acc 95.59, Test_acc 48.38
2025-02-13 19:03:20,685 [podnet.py] => Task 19, Epoch 50/160 (LR 0.07778) => LSC_loss 0.26, Spatial_loss 3.87, Flat_loss 0.32, Train_acc 94.82, Test_acc 48.80
2025-02-13 19:03:22,534 [podnet.py] => Task 19, Epoch 51/160 (LR 0.07696) => LSC_loss 0.26, Spatial_loss 4.00, Flat_loss 0.33, Train_acc 95.40, Test_acc 47.43
2025-02-13 19:03:24,236 [podnet.py] => Task 19, Epoch 52/160 (LR 0.07612) => LSC_loss 0.29, Spatial_loss 4.13, Flat_loss 0.37, Train_acc 94.26, Test_acc 49.42
2025-02-13 19:03:26,013 [podnet.py] => Task 19, Epoch 53/160 (LR 0.07528) => LSC_loss 0.27, Spatial_loss 3.96, Flat_loss 0.33, Train_acc 95.11, Test_acc 48.25
2025-02-13 19:03:27,812 [podnet.py] => Task 19, Epoch 54/160 (LR 0.07443) => LSC_loss 0.23, Spatial_loss 3.82, Flat_loss 0.32, Train_acc 96.07, Test_acc 47.24
2025-02-13 19:03:29,614 [podnet.py] => Task 19, Epoch 55/160 (LR 0.07357) => LSC_loss 0.26, Spatial_loss 3.89, Flat_loss 0.32, Train_acc 95.04, Test_acc 48.24
2025-02-13 19:03:31,368 [podnet.py] => Task 19, Epoch 56/160 (LR 0.07270) => LSC_loss 0.24, Spatial_loss 3.71, Flat_loss 0.30, Train_acc 96.18, Test_acc 49.30
2025-02-13 19:03:33,102 [podnet.py] => Task 19, Epoch 57/160 (LR 0.07182) => LSC_loss 0.26, Spatial_loss 3.77, Flat_loss 0.32, Train_acc 95.55, Test_acc 46.55
2025-02-13 19:03:34,849 [podnet.py] => Task 19, Epoch 58/160 (LR 0.07093) => LSC_loss 0.24, Spatial_loss 3.58, Flat_loss 0.29, Train_acc 96.07, Test_acc 48.14
2025-02-13 19:03:36,630 [podnet.py] => Task 19, Epoch 59/160 (LR 0.07004) => LSC_loss 0.25, Spatial_loss 3.70, Flat_loss 0.30, Train_acc 95.88, Test_acc 48.45
2025-02-13 19:03:38,442 [podnet.py] => Task 19, Epoch 60/160 (LR 0.06913) => LSC_loss 0.23, Spatial_loss 3.78, Flat_loss 0.32, Train_acc 95.99, Test_acc 49.12
2025-02-13 19:03:40,187 [podnet.py] => Task 19, Epoch 61/160 (LR 0.06822) => LSC_loss 0.25, Spatial_loss 3.73, Flat_loss 0.30, Train_acc 95.37, Test_acc 48.12
2025-02-13 19:03:41,977 [podnet.py] => Task 19, Epoch 62/160 (LR 0.06731) => LSC_loss 0.24, Spatial_loss 3.68, Flat_loss 0.29, Train_acc 95.77, Test_acc 46.09
2025-02-13 19:03:43,770 [podnet.py] => Task 19, Epoch 63/160 (LR 0.06638) => LSC_loss 0.25, Spatial_loss 3.71, Flat_loss 0.29, Train_acc 95.81, Test_acc 48.15
2025-02-13 19:03:45,567 [podnet.py] => Task 19, Epoch 64/160 (LR 0.06545) => LSC_loss 0.25, Spatial_loss 3.84, Flat_loss 0.32, Train_acc 95.22, Test_acc 45.81
2025-02-13 19:03:47,363 [podnet.py] => Task 19, Epoch 65/160 (LR 0.06451) => LSC_loss 0.23, Spatial_loss 3.73, Flat_loss 0.30, Train_acc 96.07, Test_acc 49.27
2025-02-13 19:03:49,120 [podnet.py] => Task 19, Epoch 66/160 (LR 0.06357) => LSC_loss 0.23, Spatial_loss 3.76, Flat_loss 0.30, Train_acc 96.10, Test_acc 47.69
2025-02-13 19:03:50,885 [podnet.py] => Task 19, Epoch 67/160 (LR 0.06262) => LSC_loss 0.24, Spatial_loss 3.67, Flat_loss 0.30, Train_acc 95.59, Test_acc 46.90
2025-02-13 19:03:52,684 [podnet.py] => Task 19, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 3.73, Flat_loss 0.29, Train_acc 96.18, Test_acc 48.94
2025-02-13 19:03:54,485 [podnet.py] => Task 19, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.57, Flat_loss 0.29, Train_acc 95.74, Test_acc 48.59
2025-02-13 19:03:56,235 [podnet.py] => Task 19, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 3.55, Flat_loss 0.28, Train_acc 96.14, Test_acc 46.99
2025-02-13 19:03:58,064 [podnet.py] => Task 19, Epoch 71/160 (LR 0.05879) => LSC_loss 0.23, Spatial_loss 3.66, Flat_loss 0.30, Train_acc 95.92, Test_acc 47.84
2025-02-13 19:03:59,827 [podnet.py] => Task 19, Epoch 72/160 (LR 0.05782) => LSC_loss 0.23, Spatial_loss 3.62, Flat_loss 0.28, Train_acc 96.32, Test_acc 49.84
2025-02-13 19:04:01,591 [podnet.py] => Task 19, Epoch 73/160 (LR 0.05685) => LSC_loss 0.24, Spatial_loss 3.46, Flat_loss 0.27, Train_acc 95.40, Test_acc 46.84
2025-02-13 19:04:03,433 [podnet.py] => Task 19, Epoch 74/160 (LR 0.05588) => LSC_loss 0.23, Spatial_loss 3.38, Flat_loss 0.26, Train_acc 95.81, Test_acc 47.20
2025-02-13 19:04:05,211 [podnet.py] => Task 19, Epoch 75/160 (LR 0.05490) => LSC_loss 0.23, Spatial_loss 3.45, Flat_loss 0.27, Train_acc 95.88, Test_acc 48.94
2025-02-13 19:04:07,051 [podnet.py] => Task 19, Epoch 76/160 (LR 0.05392) => LSC_loss 0.23, Spatial_loss 3.33, Flat_loss 0.25, Train_acc 96.40, Test_acc 48.84
2025-02-13 19:04:08,812 [podnet.py] => Task 19, Epoch 77/160 (LR 0.05294) => LSC_loss 0.24, Spatial_loss 3.37, Flat_loss 0.26, Train_acc 95.88, Test_acc 48.14
2025-02-13 19:04:10,626 [podnet.py] => Task 19, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 3.36, Flat_loss 0.27, Train_acc 95.88, Test_acc 50.24
2025-02-13 19:04:12,381 [podnet.py] => Task 19, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 3.35, Flat_loss 0.25, Train_acc 96.36, Test_acc 50.38
2025-02-13 19:04:14,203 [podnet.py] => Task 19, Epoch 80/160 (LR 0.05000) => LSC_loss 0.22, Spatial_loss 3.30, Flat_loss 0.25, Train_acc 96.25, Test_acc 47.92
2025-02-13 19:04:15,968 [podnet.py] => Task 19, Epoch 81/160 (LR 0.04902) => LSC_loss 0.24, Spatial_loss 3.22, Flat_loss 0.24, Train_acc 95.81, Test_acc 49.14
2025-02-13 19:04:17,728 [podnet.py] => Task 19, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 3.26, Flat_loss 0.25, Train_acc 95.74, Test_acc 48.68
2025-02-13 19:04:19,508 [podnet.py] => Task 19, Epoch 83/160 (LR 0.04706) => LSC_loss 0.23, Spatial_loss 3.17, Flat_loss 0.24, Train_acc 95.96, Test_acc 49.26
2025-02-13 19:04:21,308 [podnet.py] => Task 19, Epoch 84/160 (LR 0.04608) => LSC_loss 0.23, Spatial_loss 3.06, Flat_loss 0.23, Train_acc 96.32, Test_acc 47.82
2025-02-13 19:04:23,088 [podnet.py] => Task 19, Epoch 85/160 (LR 0.04510) => LSC_loss 0.23, Spatial_loss 3.21, Flat_loss 0.25, Train_acc 96.40, Test_acc 47.95
2025-02-13 19:04:24,892 [podnet.py] => Task 19, Epoch 86/160 (LR 0.04412) => LSC_loss 0.23, Spatial_loss 3.21, Flat_loss 0.24, Train_acc 95.99, Test_acc 50.51
2025-02-13 19:04:26,636 [podnet.py] => Task 19, Epoch 87/160 (LR 0.04315) => LSC_loss 0.23, Spatial_loss 3.15, Flat_loss 0.24, Train_acc 96.43, Test_acc 48.98
2025-02-13 19:04:28,416 [podnet.py] => Task 19, Epoch 88/160 (LR 0.04218) => LSC_loss 0.23, Spatial_loss 2.96, Flat_loss 0.23, Train_acc 96.58, Test_acc 48.07
2025-02-13 19:04:30,219 [podnet.py] => Task 19, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 3.10, Flat_loss 0.24, Train_acc 96.21, Test_acc 49.76
2025-02-13 19:04:31,984 [podnet.py] => Task 19, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 3.19, Flat_loss 0.24, Train_acc 95.66, Test_acc 52.31
2025-02-13 19:04:33,784 [podnet.py] => Task 19, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 3.15, Flat_loss 0.24, Train_acc 95.99, Test_acc 50.10
2025-02-13 19:04:35,573 [podnet.py] => Task 19, Epoch 92/160 (LR 0.03833) => LSC_loss 0.23, Spatial_loss 3.04, Flat_loss 0.23, Train_acc 96.36, Test_acc 49.41
2025-02-13 19:04:37,397 [podnet.py] => Task 19, Epoch 93/160 (LR 0.03738) => LSC_loss 0.23, Spatial_loss 3.15, Flat_loss 0.23, Train_acc 96.40, Test_acc 50.65
2025-02-13 19:04:39,211 [podnet.py] => Task 19, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 2.98, Flat_loss 0.22, Train_acc 95.88, Test_acc 49.85
2025-02-13 19:04:41,033 [podnet.py] => Task 19, Epoch 95/160 (LR 0.03549) => LSC_loss 0.23, Spatial_loss 2.85, Flat_loss 0.21, Train_acc 95.92, Test_acc 50.47
2025-02-13 19:04:42,792 [podnet.py] => Task 19, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 96.80, Test_acc 50.77
2025-02-13 19:04:44,579 [podnet.py] => Task 19, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 2.82, Flat_loss 0.20, Train_acc 96.21, Test_acc 50.45
2025-02-13 19:04:46,366 [podnet.py] => Task 19, Epoch 98/160 (LR 0.03269) => LSC_loss 0.22, Spatial_loss 2.79, Flat_loss 0.20, Train_acc 96.43, Test_acc 49.03
2025-02-13 19:04:48,127 [podnet.py] => Task 19, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 2.77, Flat_loss 0.20, Train_acc 96.18, Test_acc 49.93
2025-02-13 19:04:49,960 [podnet.py] => Task 19, Epoch 100/160 (LR 0.03087) => LSC_loss 0.22, Spatial_loss 2.93, Flat_loss 0.22, Train_acc 96.03, Test_acc 50.99
2025-02-13 19:04:51,785 [podnet.py] => Task 19, Epoch 101/160 (LR 0.02996) => LSC_loss 0.22, Spatial_loss 2.95, Flat_loss 0.21, Train_acc 96.51, Test_acc 51.28
2025-02-13 19:04:53,599 [podnet.py] => Task 19, Epoch 102/160 (LR 0.02907) => LSC_loss 0.22, Spatial_loss 2.81, Flat_loss 0.20, Train_acc 96.58, Test_acc 49.25
2025-02-13 19:04:55,408 [podnet.py] => Task 19, Epoch 103/160 (LR 0.02818) => LSC_loss 0.22, Spatial_loss 2.76, Flat_loss 0.20, Train_acc 96.14, Test_acc 49.64
2025-02-13 19:04:57,235 [podnet.py] => Task 19, Epoch 104/160 (LR 0.02730) => LSC_loss 0.22, Spatial_loss 2.75, Flat_loss 0.20, Train_acc 96.29, Test_acc 51.59
2025-02-13 19:04:59,049 [podnet.py] => Task 19, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 2.64, Flat_loss 0.19, Train_acc 95.96, Test_acc 51.45
2025-02-13 19:05:00,804 [podnet.py] => Task 19, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 2.69, Flat_loss 0.19, Train_acc 96.29, Test_acc 50.33
2025-02-13 19:05:02,678 [podnet.py] => Task 19, Epoch 107/160 (LR 0.02472) => LSC_loss 0.23, Spatial_loss 2.58, Flat_loss 0.18, Train_acc 96.29, Test_acc 50.59
2025-02-13 19:05:04,478 [podnet.py] => Task 19, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 2.61, Flat_loss 0.19, Train_acc 96.36, Test_acc 50.28
2025-02-13 19:05:06,265 [podnet.py] => Task 19, Epoch 109/160 (LR 0.02304) => LSC_loss 0.23, Spatial_loss 2.57, Flat_loss 0.18, Train_acc 96.36, Test_acc 49.43
2025-02-13 19:05:08,055 [podnet.py] => Task 19, Epoch 110/160 (LR 0.02222) => LSC_loss 0.21, Spatial_loss 2.65, Flat_loss 0.20, Train_acc 96.25, Test_acc 50.73
2025-02-13 19:05:09,809 [podnet.py] => Task 19, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 2.53, Flat_loss 0.18, Train_acc 95.99, Test_acc 50.20
2025-02-13 19:05:11,593 [podnet.py] => Task 19, Epoch 112/160 (LR 0.02061) => LSC_loss 0.23, Spatial_loss 2.54, Flat_loss 0.18, Train_acc 96.14, Test_acc 51.43
2025-02-13 19:05:13,407 [podnet.py] => Task 19, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 2.58, Flat_loss 0.19, Train_acc 96.14, Test_acc 49.83
2025-02-13 19:05:15,250 [podnet.py] => Task 19, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 2.48, Flat_loss 0.18, Train_acc 96.43, Test_acc 49.77
2025-02-13 19:05:17,102 [podnet.py] => Task 19, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 2.38, Flat_loss 0.17, Train_acc 96.36, Test_acc 52.07
2025-02-13 19:05:18,865 [podnet.py] => Task 19, Epoch 116/160 (LR 0.01753) => LSC_loss 0.21, Spatial_loss 2.40, Flat_loss 0.17, Train_acc 96.84, Test_acc 51.92
2025-02-13 19:05:20,662 [podnet.py] => Task 19, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 2.33, Flat_loss 0.16, Train_acc 96.14, Test_acc 50.82
2025-02-13 19:05:22,459 [podnet.py] => Task 19, Epoch 118/160 (LR 0.01606) => LSC_loss 0.21, Spatial_loss 2.36, Flat_loss 0.17, Train_acc 96.91, Test_acc 52.12
2025-02-13 19:05:24,242 [podnet.py] => Task 19, Epoch 119/160 (LR 0.01535) => LSC_loss 0.23, Spatial_loss 2.34, Flat_loss 0.16, Train_acc 96.10, Test_acc 50.25
2025-02-13 19:05:25,988 [podnet.py] => Task 19, Epoch 120/160 (LR 0.01464) => LSC_loss 0.22, Spatial_loss 2.34, Flat_loss 0.16, Train_acc 96.43, Test_acc 50.89
2025-02-13 19:05:27,789 [podnet.py] => Task 19, Epoch 121/160 (LR 0.01396) => LSC_loss 0.22, Spatial_loss 2.31, Flat_loss 0.16, Train_acc 96.58, Test_acc 50.45
2025-02-13 19:05:29,582 [podnet.py] => Task 19, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 2.31, Flat_loss 0.16, Train_acc 96.29, Test_acc 49.82
2025-02-13 19:05:31,388 [podnet.py] => Task 19, Epoch 123/160 (LR 0.01262) => LSC_loss 0.22, Spatial_loss 2.26, Flat_loss 0.16, Train_acc 95.81, Test_acc 51.45
2025-02-13 19:05:33,164 [podnet.py] => Task 19, Epoch 124/160 (LR 0.01198) => LSC_loss 0.21, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 96.32, Test_acc 50.94
2025-02-13 19:05:34,961 [podnet.py] => Task 19, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 96.36, Test_acc 51.68
2025-02-13 19:05:36,786 [podnet.py] => Task 19, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.16, Train_acc 96.54, Test_acc 51.77
2025-02-13 19:05:38,574 [podnet.py] => Task 19, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 2.05, Flat_loss 0.15, Train_acc 96.47, Test_acc 51.82
2025-02-13 19:05:40,347 [podnet.py] => Task 19, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 2.20, Flat_loss 0.16, Train_acc 96.58, Test_acc 51.35
2025-02-13 19:05:42,161 [podnet.py] => Task 19, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 96.25, Test_acc 51.26
2025-02-13 19:05:43,948 [podnet.py] => Task 19, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 2.17, Flat_loss 0.15, Train_acc 96.40, Test_acc 51.06
2025-02-13 19:05:45,690 [podnet.py] => Task 19, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 96.18, Test_acc 51.67
2025-02-13 19:05:47,473 [podnet.py] => Task 19, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 2.14, Flat_loss 0.15, Train_acc 96.58, Test_acc 51.69
2025-02-13 19:05:49,252 [podnet.py] => Task 19, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 2.00, Flat_loss 0.15, Train_acc 96.29, Test_acc 51.55
2025-02-13 19:05:51,004 [podnet.py] => Task 19, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 96.25, Test_acc 51.38
2025-02-13 19:05:52,817 [podnet.py] => Task 19, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 96.10, Test_acc 51.10
2025-02-13 19:05:54,563 [podnet.py] => Task 19, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 2.03, Flat_loss 0.14, Train_acc 96.43, Test_acc 51.53
2025-02-13 19:05:56,313 [podnet.py] => Task 19, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 2.00, Flat_loss 0.15, Train_acc 96.80, Test_acc 51.55
2025-02-13 19:05:58,182 [podnet.py] => Task 19, Epoch 138/160 (LR 0.00459) => LSC_loss 0.22, Spatial_loss 1.92, Flat_loss 0.14, Train_acc 96.62, Test_acc 52.27
2025-02-13 19:05:59,975 [podnet.py] => Task 19, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 2.00, Flat_loss 0.14, Train_acc 96.73, Test_acc 51.24
2025-02-13 19:06:01,730 [podnet.py] => Task 19, Epoch 140/160 (LR 0.00381) => LSC_loss 0.22, Spatial_loss 1.98, Flat_loss 0.14, Train_acc 96.58, Test_acc 51.94
2025-02-13 19:06:03,577 [podnet.py] => Task 19, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.98, Flat_loss 0.14, Train_acc 96.36, Test_acc 51.80
2025-02-13 19:06:05,290 [podnet.py] => Task 19, Epoch 142/160 (LR 0.00309) => LSC_loss 0.23, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 96.18, Test_acc 52.02
2025-02-13 19:06:07,159 [podnet.py] => Task 19, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 1.92, Flat_loss 0.13, Train_acc 96.03, Test_acc 51.84
2025-02-13 19:06:08,935 [podnet.py] => Task 19, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 96.40, Test_acc 51.99
2025-02-13 19:06:10,745 [podnet.py] => Task 19, Epoch 145/160 (LR 0.00215) => LSC_loss 0.21, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 96.65, Test_acc 51.65
2025-02-13 19:06:12,521 [podnet.py] => Task 19, Epoch 146/160 (LR 0.00188) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.47, Test_acc 51.90
2025-02-13 19:06:14,283 [podnet.py] => Task 19, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.88, Flat_loss 0.14, Train_acc 96.65, Test_acc 52.03
2025-02-13 19:06:16,086 [podnet.py] => Task 19, Epoch 148/160 (LR 0.00138) => LSC_loss 0.21, Spatial_loss 1.85, Flat_loss 0.14, Train_acc 96.47, Test_acc 51.64
2025-02-13 19:06:17,850 [podnet.py] => Task 19, Epoch 149/160 (LR 0.00116) => LSC_loss 0.22, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.07, Test_acc 52.20
2025-02-13 19:06:19,651 [podnet.py] => Task 19, Epoch 150/160 (LR 0.00096) => LSC_loss 0.24, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 95.44, Test_acc 51.88
2025-02-13 19:06:21,362 [podnet.py] => Task 19, Epoch 151/160 (LR 0.00078) => LSC_loss 0.22, Spatial_loss 1.82, Flat_loss 0.13, Train_acc 96.58, Test_acc 51.68
2025-02-13 19:06:23,180 [podnet.py] => Task 19, Epoch 152/160 (LR 0.00062) => LSC_loss 0.22, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 96.10, Test_acc 52.09
2025-02-13 19:06:24,985 [podnet.py] => Task 19, Epoch 153/160 (LR 0.00047) => LSC_loss 0.22, Spatial_loss 1.80, Flat_loss 0.13, Train_acc 96.03, Test_acc 51.85
2025-02-13 19:06:26,774 [podnet.py] => Task 19, Epoch 154/160 (LR 0.00035) => LSC_loss 0.21, Spatial_loss 1.77, Flat_loss 0.13, Train_acc 96.25, Test_acc 52.14
2025-02-13 19:06:28,536 [podnet.py] => Task 19, Epoch 155/160 (LR 0.00024) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.25, Test_acc 51.95
2025-02-13 19:06:30,339 [podnet.py] => Task 19, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.85, Flat_loss 0.13, Train_acc 96.29, Test_acc 52.10
2025-02-13 19:06:32,151 [podnet.py] => Task 19, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.32, Test_acc 51.93
2025-02-13 19:06:33,926 [podnet.py] => Task 19, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 1.83, Flat_loss 0.13, Train_acc 96.62, Test_acc 51.89
2025-02-13 19:06:35,703 [podnet.py] => Task 19, Epoch 159/160 (LR 0.00001) => LSC_loss 0.23, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.25, Test_acc 52.19
2025-02-13 19:06:37,542 [podnet.py] => Task 19, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.75, Flat_loss 0.13, Train_acc 96.84, Test_acc 52.12
2025-02-13 19:06:37,543 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:06:37,543 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:07:06,034 [podnet.py] => The size of finetune dataset: 1760
2025-02-13 19:07:07,574 [podnet.py] => Task 19, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.00, Flat_loss 0.12, Train_acc 98.24, Test_acc 51.30
2025-02-13 19:07:09,109 [podnet.py] => Task 19, Epoch 2/20 (LR 0.00488) => LSC_loss 0.11, Spatial_loss 1.98, Flat_loss 0.08, Train_acc 99.15, Test_acc 52.30
2025-02-13 19:07:10,676 [podnet.py] => Task 19, Epoch 3/20 (LR 0.00473) => LSC_loss 0.11, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 98.75, Test_acc 52.23
2025-02-13 19:07:12,201 [podnet.py] => Task 19, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 1.83, Flat_loss 0.06, Train_acc 98.69, Test_acc 52.30
2025-02-13 19:07:13,727 [podnet.py] => Task 19, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 98.58, Test_acc 52.32
2025-02-13 19:07:15,327 [podnet.py] => Task 19, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.64, Test_acc 52.47
2025-02-13 19:07:16,874 [podnet.py] => Task 19, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.75, Test_acc 52.68
2025-02-13 19:07:18,360 [podnet.py] => Task 19, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 98.64, Test_acc 52.57
2025-02-13 19:07:19,899 [podnet.py] => Task 19, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 1.84, Flat_loss 0.06, Train_acc 98.98, Test_acc 52.60
2025-02-13 19:07:21,432 [podnet.py] => Task 19, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 98.75, Test_acc 52.50
2025-02-13 19:07:22,980 [podnet.py] => Task 19, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.75, Test_acc 52.34
2025-02-13 19:07:24,535 [podnet.py] => Task 19, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 98.64, Test_acc 52.39
2025-02-13 19:07:26,113 [podnet.py] => Task 19, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 98.86, Test_acc 52.62
2025-02-13 19:07:27,655 [podnet.py] => Task 19, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 1.71, Flat_loss 0.05, Train_acc 98.64, Test_acc 52.64
2025-02-13 19:07:29,228 [podnet.py] => Task 19, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.86, Test_acc 52.65
2025-02-13 19:07:30,777 [podnet.py] => Task 19, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 98.75, Test_acc 52.60
2025-02-13 19:07:32,331 [podnet.py] => Task 19, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 99.20, Test_acc 52.85
2025-02-13 19:07:33,878 [podnet.py] => Task 19, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 1.69, Flat_loss 0.06, Train_acc 99.03, Test_acc 52.67
2025-02-13 19:07:35,414 [podnet.py] => Task 19, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 1.68, Flat_loss 0.06, Train_acc 98.92, Test_acc 52.74
2025-02-13 19:07:36,973 [podnet.py] => Task 19, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 98.58, Test_acc 52.74
2025-02-13 19:07:36,974 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:08:06,987 [podnet.py] => Exemplar size: 1760
2025-02-13 19:08:06,987 [trainer.py] => CNN: {'total': 52.74, '00-09': 62.3, '10-19': 40.9, '20-29': 60.7, '30-39': 52.2, '40-49': 56.5, '50-59': 36.4, '60-69': 49.7, '70-79': 55.4, '80-89': 62.5, 'old': 52.55, 'new': 61.0}
2025-02-13 19:08:06,987 [trainer.py] => NME: {'total': 52.51, '00-09': 64.9, '10-19': 45.1, '20-29': 62.2, '30-39': 53.3, '40-49': 56.9, '50-59': 32.7, '60-69': 47.9, '70-79': 54.9, '80-89': 55.25, 'old': 52.57, 'new': 50.0}
2025-02-13 19:08:06,988 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74]
2025-02-13 19:08:06,990 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18]
2025-02-13 19:08:06,990 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51]
2025-02-13 19:08:06,990 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85]

2025-02-13 19:08:06,990 [trainer.py] => Average Accuracy (CNN): 63.038499999999985
2025-02-13 19:08:06,990 [trainer.py] => Average Accuracy (NME): 63.239
2025-02-13 19:08:06,991 [trainer.py] => All params: 522577
2025-02-13 19:08:06,991 [trainer.py] => Trainable params: 522577
2025-02-13 19:08:06,992 [podnet.py] => Learning on 88-90
2025-02-13 19:08:07,016 [podnet.py] => Adaptive factor: 6.708203932499369
2025-02-13 19:08:08,750 [podnet.py] => Task 20, Epoch 1/160 (LR 0.09999) => LSC_loss 1.41, Spatial_loss 4.29, Flat_loss 0.65, Train_acc 77.14, Test_acc 45.20
2025-02-13 19:08:10,542 [podnet.py] => Task 20, Epoch 2/160 (LR 0.09996) => LSC_loss 0.62, Spatial_loss 5.44, Flat_loss 0.68, Train_acc 84.17, Test_acc 45.12
2025-02-13 19:08:12,348 [podnet.py] => Task 20, Epoch 3/160 (LR 0.09991) => LSC_loss 0.55, Spatial_loss 5.50, Flat_loss 0.65, Train_acc 85.11, Test_acc 39.70
2025-02-13 19:08:14,189 [podnet.py] => Task 20, Epoch 4/160 (LR 0.09985) => LSC_loss 0.53, Spatial_loss 5.43, Flat_loss 0.62, Train_acc 86.49, Test_acc 42.97
2025-02-13 19:08:16,066 [podnet.py] => Task 20, Epoch 5/160 (LR 0.09976) => LSC_loss 0.49, Spatial_loss 5.35, Flat_loss 0.60, Train_acc 87.75, Test_acc 44.89
2025-02-13 19:08:17,860 [podnet.py] => Task 20, Epoch 6/160 (LR 0.09965) => LSC_loss 0.47, Spatial_loss 5.19, Flat_loss 0.58, Train_acc 88.62, Test_acc 42.56
2025-02-13 19:08:19,672 [podnet.py] => Task 20, Epoch 7/160 (LR 0.09953) => LSC_loss 0.47, Spatial_loss 4.96, Flat_loss 0.54, Train_acc 88.15, Test_acc 45.73
2025-02-13 19:08:21,516 [podnet.py] => Task 20, Epoch 8/160 (LR 0.09938) => LSC_loss 0.46, Spatial_loss 5.06, Flat_loss 0.54, Train_acc 88.80, Test_acc 41.46
2025-02-13 19:08:23,323 [podnet.py] => Task 20, Epoch 9/160 (LR 0.09922) => LSC_loss 0.42, Spatial_loss 5.08, Flat_loss 0.53, Train_acc 89.71, Test_acc 43.18
2025-02-13 19:08:25,086 [podnet.py] => Task 20, Epoch 10/160 (LR 0.09904) => LSC_loss 0.39, Spatial_loss 4.78, Flat_loss 0.50, Train_acc 91.34, Test_acc 47.78
2025-02-13 19:08:26,907 [podnet.py] => Task 20, Epoch 11/160 (LR 0.09884) => LSC_loss 0.41, Spatial_loss 4.61, Flat_loss 0.46, Train_acc 90.43, Test_acc 44.09
2025-02-13 19:08:28,732 [podnet.py] => Task 20, Epoch 12/160 (LR 0.09862) => LSC_loss 0.38, Spatial_loss 4.68, Flat_loss 0.46, Train_acc 91.34, Test_acc 46.68
2025-02-13 19:08:30,518 [podnet.py] => Task 20, Epoch 13/160 (LR 0.09838) => LSC_loss 0.43, Spatial_loss 4.85, Flat_loss 0.49, Train_acc 90.07, Test_acc 42.21
2025-02-13 19:08:32,386 [podnet.py] => Task 20, Epoch 14/160 (LR 0.09812) => LSC_loss 0.41, Spatial_loss 4.78, Flat_loss 0.49, Train_acc 90.51, Test_acc 46.59
2025-02-13 19:08:34,165 [podnet.py] => Task 20, Epoch 15/160 (LR 0.09785) => LSC_loss 0.39, Spatial_loss 4.68, Flat_loss 0.47, Train_acc 91.12, Test_acc 44.51
2025-02-13 19:08:35,971 [podnet.py] => Task 20, Epoch 16/160 (LR 0.09755) => LSC_loss 0.38, Spatial_loss 4.65, Flat_loss 0.45, Train_acc 91.92, Test_acc 46.30
2025-02-13 19:08:37,734 [podnet.py] => Task 20, Epoch 17/160 (LR 0.09724) => LSC_loss 0.38, Spatial_loss 4.43, Flat_loss 0.44, Train_acc 90.91, Test_acc 47.59
2025-02-13 19:08:39,540 [podnet.py] => Task 20, Epoch 18/160 (LR 0.09691) => LSC_loss 0.37, Spatial_loss 4.49, Flat_loss 0.45, Train_acc 91.92, Test_acc 44.87
2025-02-13 19:08:41,387 [podnet.py] => Task 20, Epoch 19/160 (LR 0.09656) => LSC_loss 0.38, Spatial_loss 4.52, Flat_loss 0.44, Train_acc 91.27, Test_acc 44.53
2025-02-13 19:08:43,184 [podnet.py] => Task 20, Epoch 20/160 (LR 0.09619) => LSC_loss 0.37, Spatial_loss 4.63, Flat_loss 0.47, Train_acc 91.92, Test_acc 46.12
2025-02-13 19:08:45,014 [podnet.py] => Task 20, Epoch 21/160 (LR 0.09581) => LSC_loss 0.35, Spatial_loss 4.45, Flat_loss 0.44, Train_acc 91.78, Test_acc 46.40
2025-02-13 19:08:46,823 [podnet.py] => Task 20, Epoch 22/160 (LR 0.09541) => LSC_loss 0.37, Spatial_loss 4.46, Flat_loss 0.43, Train_acc 91.81, Test_acc 44.21
2025-02-13 19:08:48,604 [podnet.py] => Task 20, Epoch 23/160 (LR 0.09499) => LSC_loss 0.35, Spatial_loss 4.24, Flat_loss 0.40, Train_acc 91.88, Test_acc 43.87
2025-02-13 19:08:50,380 [podnet.py] => Task 20, Epoch 24/160 (LR 0.09455) => LSC_loss 0.34, Spatial_loss 4.23, Flat_loss 0.40, Train_acc 92.75, Test_acc 43.37
2025-02-13 19:08:52,201 [podnet.py] => Task 20, Epoch 25/160 (LR 0.09410) => LSC_loss 0.35, Spatial_loss 4.34, Flat_loss 0.40, Train_acc 92.54, Test_acc 48.49
2025-02-13 19:08:54,015 [podnet.py] => Task 20, Epoch 26/160 (LR 0.09362) => LSC_loss 0.33, Spatial_loss 4.28, Flat_loss 0.41, Train_acc 93.30, Test_acc 46.46
2025-02-13 19:08:55,794 [podnet.py] => Task 20, Epoch 27/160 (LR 0.09314) => LSC_loss 0.35, Spatial_loss 4.32, Flat_loss 0.42, Train_acc 92.32, Test_acc 41.16
2025-02-13 19:08:57,649 [podnet.py] => Task 20, Epoch 28/160 (LR 0.09263) => LSC_loss 0.36, Spatial_loss 4.47, Flat_loss 0.44, Train_acc 91.81, Test_acc 45.51
2025-02-13 19:08:59,419 [podnet.py] => Task 20, Epoch 29/160 (LR 0.09211) => LSC_loss 0.34, Spatial_loss 4.41, Flat_loss 0.43, Train_acc 93.12, Test_acc 39.77
2025-02-13 19:09:01,275 [podnet.py] => Task 20, Epoch 30/160 (LR 0.09157) => LSC_loss 0.33, Spatial_loss 4.36, Flat_loss 0.42, Train_acc 93.55, Test_acc 46.67
2025-02-13 19:09:03,095 [podnet.py] => Task 20, Epoch 31/160 (LR 0.09102) => LSC_loss 0.34, Spatial_loss 4.17, Flat_loss 0.40, Train_acc 93.08, Test_acc 46.14
2025-02-13 19:09:04,895 [podnet.py] => Task 20, Epoch 32/160 (LR 0.09045) => LSC_loss 0.32, Spatial_loss 4.20, Flat_loss 0.39, Train_acc 92.93, Test_acc 39.76
2025-02-13 19:09:06,701 [podnet.py] => Task 20, Epoch 33/160 (LR 0.08987) => LSC_loss 0.33, Spatial_loss 4.33, Flat_loss 0.40, Train_acc 93.55, Test_acc 44.83
2025-02-13 19:09:08,580 [podnet.py] => Task 20, Epoch 34/160 (LR 0.08927) => LSC_loss 0.34, Spatial_loss 4.16, Flat_loss 0.39, Train_acc 92.79, Test_acc 42.69
2025-02-13 19:09:10,397 [podnet.py] => Task 20, Epoch 35/160 (LR 0.08865) => LSC_loss 0.33, Spatial_loss 4.12, Flat_loss 0.39, Train_acc 92.75, Test_acc 45.26
2025-02-13 19:09:12,177 [podnet.py] => Task 20, Epoch 36/160 (LR 0.08802) => LSC_loss 0.32, Spatial_loss 4.17, Flat_loss 0.40, Train_acc 93.48, Test_acc 44.09
2025-02-13 19:09:13,986 [podnet.py] => Task 20, Epoch 37/160 (LR 0.08738) => LSC_loss 0.33, Spatial_loss 4.03, Flat_loss 0.38, Train_acc 92.86, Test_acc 45.36
2025-02-13 19:09:15,785 [podnet.py] => Task 20, Epoch 38/160 (LR 0.08672) => LSC_loss 0.33, Spatial_loss 4.07, Flat_loss 0.39, Train_acc 92.61, Test_acc 45.52
2025-02-13 19:09:17,625 [podnet.py] => Task 20, Epoch 39/160 (LR 0.08604) => LSC_loss 0.34, Spatial_loss 4.09, Flat_loss 0.40, Train_acc 91.99, Test_acc 43.49
2025-02-13 19:09:19,466 [podnet.py] => Task 20, Epoch 40/160 (LR 0.08536) => LSC_loss 0.34, Spatial_loss 4.21, Flat_loss 0.41, Train_acc 92.43, Test_acc 45.91
2025-02-13 19:09:21,308 [podnet.py] => Task 20, Epoch 41/160 (LR 0.08465) => LSC_loss 0.33, Spatial_loss 4.08, Flat_loss 0.38, Train_acc 93.48, Test_acc 44.61
2025-02-13 19:09:23,136 [podnet.py] => Task 20, Epoch 42/160 (LR 0.08394) => LSC_loss 0.32, Spatial_loss 4.08, Flat_loss 0.39, Train_acc 92.61, Test_acc 46.16
2025-02-13 19:09:24,939 [podnet.py] => Task 20, Epoch 43/160 (LR 0.08321) => LSC_loss 0.31, Spatial_loss 4.07, Flat_loss 0.36, Train_acc 93.77, Test_acc 48.16
2025-02-13 19:09:26,690 [podnet.py] => Task 20, Epoch 44/160 (LR 0.08247) => LSC_loss 0.31, Spatial_loss 3.98, Flat_loss 0.36, Train_acc 93.77, Test_acc 43.81
2025-02-13 19:09:28,517 [podnet.py] => Task 20, Epoch 45/160 (LR 0.08172) => LSC_loss 0.34, Spatial_loss 4.06, Flat_loss 0.39, Train_acc 92.79, Test_acc 47.17
2025-02-13 19:09:30,302 [podnet.py] => Task 20, Epoch 46/160 (LR 0.08095) => LSC_loss 0.31, Spatial_loss 4.05, Flat_loss 0.38, Train_acc 93.62, Test_acc 47.23
2025-02-13 19:09:32,098 [podnet.py] => Task 20, Epoch 47/160 (LR 0.08018) => LSC_loss 0.30, Spatial_loss 4.08, Flat_loss 0.37, Train_acc 94.09, Test_acc 41.67
2025-02-13 19:09:33,931 [podnet.py] => Task 20, Epoch 48/160 (LR 0.07939) => LSC_loss 0.30, Spatial_loss 4.02, Flat_loss 0.36, Train_acc 94.02, Test_acc 44.06
2025-02-13 19:09:35,739 [podnet.py] => Task 20, Epoch 49/160 (LR 0.07859) => LSC_loss 0.32, Spatial_loss 3.94, Flat_loss 0.36, Train_acc 93.08, Test_acc 45.97
2025-02-13 19:09:37,562 [podnet.py] => Task 20, Epoch 50/160 (LR 0.07778) => LSC_loss 0.31, Spatial_loss 4.15, Flat_loss 0.38, Train_acc 93.22, Test_acc 43.76
2025-02-13 19:09:39,361 [podnet.py] => Task 20, Epoch 51/160 (LR 0.07696) => LSC_loss 0.32, Spatial_loss 4.01, Flat_loss 0.37, Train_acc 92.75, Test_acc 44.70
2025-02-13 19:09:41,205 [podnet.py] => Task 20, Epoch 52/160 (LR 0.07612) => LSC_loss 0.32, Spatial_loss 4.13, Flat_loss 0.37, Train_acc 93.73, Test_acc 44.99
2025-02-13 19:09:42,991 [podnet.py] => Task 20, Epoch 53/160 (LR 0.07528) => LSC_loss 0.32, Spatial_loss 4.13, Flat_loss 0.37, Train_acc 93.59, Test_acc 46.66
2025-02-13 19:09:44,832 [podnet.py] => Task 20, Epoch 54/160 (LR 0.07443) => LSC_loss 0.31, Spatial_loss 3.92, Flat_loss 0.36, Train_acc 93.30, Test_acc 45.98
2025-02-13 19:09:46,623 [podnet.py] => Task 20, Epoch 55/160 (LR 0.07357) => LSC_loss 0.30, Spatial_loss 3.77, Flat_loss 0.35, Train_acc 93.66, Test_acc 46.86
2025-02-13 19:09:48,407 [podnet.py] => Task 20, Epoch 56/160 (LR 0.07270) => LSC_loss 0.31, Spatial_loss 3.77, Flat_loss 0.34, Train_acc 94.17, Test_acc 45.28
2025-02-13 19:09:50,267 [podnet.py] => Task 20, Epoch 57/160 (LR 0.07182) => LSC_loss 0.30, Spatial_loss 3.82, Flat_loss 0.35, Train_acc 93.99, Test_acc 45.87
2025-02-13 19:09:52,105 [podnet.py] => Task 20, Epoch 58/160 (LR 0.07093) => LSC_loss 0.29, Spatial_loss 3.76, Flat_loss 0.34, Train_acc 93.95, Test_acc 47.09
2025-02-13 19:09:53,912 [podnet.py] => Task 20, Epoch 59/160 (LR 0.07004) => LSC_loss 0.29, Spatial_loss 3.67, Flat_loss 0.32, Train_acc 94.53, Test_acc 47.69
2025-02-13 19:09:55,667 [podnet.py] => Task 20, Epoch 60/160 (LR 0.06913) => LSC_loss 0.32, Spatial_loss 3.71, Flat_loss 0.34, Train_acc 93.62, Test_acc 45.47
2025-02-13 19:09:57,478 [podnet.py] => Task 20, Epoch 61/160 (LR 0.06822) => LSC_loss 0.30, Spatial_loss 3.59, Flat_loss 0.33, Train_acc 93.48, Test_acc 46.32
2025-02-13 19:09:59,267 [podnet.py] => Task 20, Epoch 62/160 (LR 0.06731) => LSC_loss 0.29, Spatial_loss 3.72, Flat_loss 0.33, Train_acc 94.42, Test_acc 40.91
2025-02-13 19:10:01,092 [podnet.py] => Task 20, Epoch 63/160 (LR 0.06638) => LSC_loss 0.31, Spatial_loss 3.71, Flat_loss 0.35, Train_acc 93.51, Test_acc 47.78
2025-02-13 19:10:02,908 [podnet.py] => Task 20, Epoch 64/160 (LR 0.06545) => LSC_loss 0.28, Spatial_loss 3.62, Flat_loss 0.32, Train_acc 94.20, Test_acc 45.40
2025-02-13 19:10:04,693 [podnet.py] => Task 20, Epoch 65/160 (LR 0.06451) => LSC_loss 0.30, Spatial_loss 3.55, Flat_loss 0.32, Train_acc 94.02, Test_acc 45.46
2025-02-13 19:10:06,532 [podnet.py] => Task 20, Epoch 66/160 (LR 0.06357) => LSC_loss 0.29, Spatial_loss 3.70, Flat_loss 0.32, Train_acc 93.88, Test_acc 47.22
2025-02-13 19:10:08,366 [podnet.py] => Task 20, Epoch 67/160 (LR 0.06262) => LSC_loss 0.28, Spatial_loss 3.58, Flat_loss 0.32, Train_acc 94.64, Test_acc 47.07
2025-02-13 19:10:10,186 [podnet.py] => Task 20, Epoch 68/160 (LR 0.06167) => LSC_loss 0.29, Spatial_loss 3.65, Flat_loss 0.32, Train_acc 94.35, Test_acc 46.90
2025-02-13 19:10:11,959 [podnet.py] => Task 20, Epoch 69/160 (LR 0.06072) => LSC_loss 0.28, Spatial_loss 3.49, Flat_loss 0.31, Train_acc 94.28, Test_acc 50.23
2025-02-13 19:10:13,759 [podnet.py] => Task 20, Epoch 70/160 (LR 0.05975) => LSC_loss 0.29, Spatial_loss 3.58, Flat_loss 0.32, Train_acc 94.02, Test_acc 47.67
2025-02-13 19:10:15,529 [podnet.py] => Task 20, Epoch 71/160 (LR 0.05879) => LSC_loss 0.29, Spatial_loss 3.51, Flat_loss 0.31, Train_acc 94.53, Test_acc 45.81
2025-02-13 19:10:17,358 [podnet.py] => Task 20, Epoch 72/160 (LR 0.05782) => LSC_loss 0.27, Spatial_loss 3.54, Flat_loss 0.31, Train_acc 95.25, Test_acc 49.30
2025-02-13 19:10:19,148 [podnet.py] => Task 20, Epoch 73/160 (LR 0.05685) => LSC_loss 0.30, Spatial_loss 3.54, Flat_loss 0.31, Train_acc 93.88, Test_acc 47.11
2025-02-13 19:10:20,930 [podnet.py] => Task 20, Epoch 74/160 (LR 0.05588) => LSC_loss 0.28, Spatial_loss 3.42, Flat_loss 0.29, Train_acc 94.49, Test_acc 46.50
2025-02-13 19:10:22,716 [podnet.py] => Task 20, Epoch 75/160 (LR 0.05490) => LSC_loss 0.28, Spatial_loss 3.49, Flat_loss 0.30, Train_acc 94.35, Test_acc 47.82
2025-02-13 19:10:24,476 [podnet.py] => Task 20, Epoch 76/160 (LR 0.05392) => LSC_loss 0.29, Spatial_loss 3.35, Flat_loss 0.29, Train_acc 94.31, Test_acc 44.10
2025-02-13 19:10:26,297 [podnet.py] => Task 20, Epoch 77/160 (LR 0.05294) => LSC_loss 0.28, Spatial_loss 3.30, Flat_loss 0.29, Train_acc 94.60, Test_acc 44.77
2025-02-13 19:10:28,143 [podnet.py] => Task 20, Epoch 78/160 (LR 0.05196) => LSC_loss 0.29, Spatial_loss 3.29, Flat_loss 0.28, Train_acc 93.95, Test_acc 46.59
2025-02-13 19:10:29,940 [podnet.py] => Task 20, Epoch 79/160 (LR 0.05098) => LSC_loss 0.28, Spatial_loss 3.29, Flat_loss 0.29, Train_acc 94.28, Test_acc 48.04
2025-02-13 19:10:31,739 [podnet.py] => Task 20, Epoch 80/160 (LR 0.05000) => LSC_loss 0.30, Spatial_loss 3.34, Flat_loss 0.28, Train_acc 94.28, Test_acc 46.67
2025-02-13 19:10:33,547 [podnet.py] => Task 20, Epoch 81/160 (LR 0.04902) => LSC_loss 0.28, Spatial_loss 3.31, Flat_loss 0.28, Train_acc 94.35, Test_acc 45.37
2025-02-13 19:10:35,336 [podnet.py] => Task 20, Epoch 82/160 (LR 0.04804) => LSC_loss 0.28, Spatial_loss 3.33, Flat_loss 0.29, Train_acc 94.96, Test_acc 48.13
2025-02-13 19:10:37,088 [podnet.py] => Task 20, Epoch 83/160 (LR 0.04706) => LSC_loss 0.28, Spatial_loss 3.30, Flat_loss 0.28, Train_acc 94.17, Test_acc 45.99
2025-02-13 19:10:38,841 [podnet.py] => Task 20, Epoch 84/160 (LR 0.04608) => LSC_loss 0.28, Spatial_loss 3.24, Flat_loss 0.28, Train_acc 94.75, Test_acc 47.31
2025-02-13 19:10:40,656 [podnet.py] => Task 20, Epoch 85/160 (LR 0.04510) => LSC_loss 0.29, Spatial_loss 3.14, Flat_loss 0.27, Train_acc 93.84, Test_acc 49.03
2025-02-13 19:10:42,478 [podnet.py] => Task 20, Epoch 86/160 (LR 0.04412) => LSC_loss 0.27, Spatial_loss 3.15, Flat_loss 0.26, Train_acc 94.78, Test_acc 47.69
2025-02-13 19:10:44,282 [podnet.py] => Task 20, Epoch 87/160 (LR 0.04315) => LSC_loss 0.28, Spatial_loss 3.15, Flat_loss 0.26, Train_acc 94.53, Test_acc 47.62
2025-02-13 19:10:46,114 [podnet.py] => Task 20, Epoch 88/160 (LR 0.04218) => LSC_loss 0.28, Spatial_loss 3.17, Flat_loss 0.27, Train_acc 94.53, Test_acc 48.33
2025-02-13 19:10:47,932 [podnet.py] => Task 20, Epoch 89/160 (LR 0.04121) => LSC_loss 0.26, Spatial_loss 3.17, Flat_loss 0.26, Train_acc 95.25, Test_acc 45.34
2025-02-13 19:10:49,761 [podnet.py] => Task 20, Epoch 90/160 (LR 0.04025) => LSC_loss 0.27, Spatial_loss 3.10, Flat_loss 0.25, Train_acc 94.64, Test_acc 45.52
2025-02-13 19:10:51,519 [podnet.py] => Task 20, Epoch 91/160 (LR 0.03928) => LSC_loss 0.26, Spatial_loss 3.07, Flat_loss 0.25, Train_acc 94.82, Test_acc 47.71
2025-02-13 19:10:53,344 [podnet.py] => Task 20, Epoch 92/160 (LR 0.03833) => LSC_loss 0.28, Spatial_loss 2.96, Flat_loss 0.26, Train_acc 94.31, Test_acc 46.59
2025-02-13 19:10:55,158 [podnet.py] => Task 20, Epoch 93/160 (LR 0.03738) => LSC_loss 0.26, Spatial_loss 2.95, Flat_loss 0.24, Train_acc 94.93, Test_acc 46.43
2025-02-13 19:10:56,985 [podnet.py] => Task 20, Epoch 94/160 (LR 0.03643) => LSC_loss 0.28, Spatial_loss 2.98, Flat_loss 0.25, Train_acc 94.17, Test_acc 47.57
2025-02-13 19:10:58,782 [podnet.py] => Task 20, Epoch 95/160 (LR 0.03549) => LSC_loss 0.27, Spatial_loss 3.03, Flat_loss 0.26, Train_acc 95.14, Test_acc 48.49
2025-02-13 19:11:00,566 [podnet.py] => Task 20, Epoch 96/160 (LR 0.03455) => LSC_loss 0.28, Spatial_loss 3.02, Flat_loss 0.24, Train_acc 94.93, Test_acc 46.13
2025-02-13 19:11:02,383 [podnet.py] => Task 20, Epoch 97/160 (LR 0.03362) => LSC_loss 0.26, Spatial_loss 2.93, Flat_loss 0.25, Train_acc 95.00, Test_acc 46.46
2025-02-13 19:11:04,218 [podnet.py] => Task 20, Epoch 98/160 (LR 0.03269) => LSC_loss 0.26, Spatial_loss 2.90, Flat_loss 0.25, Train_acc 95.43, Test_acc 48.12
2025-02-13 19:11:06,047 [podnet.py] => Task 20, Epoch 99/160 (LR 0.03178) => LSC_loss 0.27, Spatial_loss 2.79, Flat_loss 0.23, Train_acc 94.42, Test_acc 48.99
2025-02-13 19:11:07,795 [podnet.py] => Task 20, Epoch 100/160 (LR 0.03087) => LSC_loss 0.27, Spatial_loss 2.84, Flat_loss 0.23, Train_acc 95.33, Test_acc 48.02
2025-02-13 19:11:09,621 [podnet.py] => Task 20, Epoch 101/160 (LR 0.02996) => LSC_loss 0.27, Spatial_loss 2.87, Flat_loss 0.24, Train_acc 94.53, Test_acc 47.88
2025-02-13 19:11:11,405 [podnet.py] => Task 20, Epoch 102/160 (LR 0.02907) => LSC_loss 0.26, Spatial_loss 2.84, Flat_loss 0.23, Train_acc 94.82, Test_acc 47.43
2025-02-13 19:11:13,189 [podnet.py] => Task 20, Epoch 103/160 (LR 0.02818) => LSC_loss 0.28, Spatial_loss 2.86, Flat_loss 0.23, Train_acc 94.42, Test_acc 48.83
2025-02-13 19:11:15,028 [podnet.py] => Task 20, Epoch 104/160 (LR 0.02730) => LSC_loss 0.27, Spatial_loss 2.72, Flat_loss 0.23, Train_acc 95.04, Test_acc 48.24
2025-02-13 19:11:16,868 [podnet.py] => Task 20, Epoch 105/160 (LR 0.02643) => LSC_loss 0.27, Spatial_loss 2.70, Flat_loss 0.22, Train_acc 94.89, Test_acc 48.59
2025-02-13 19:11:18,656 [podnet.py] => Task 20, Epoch 106/160 (LR 0.02557) => LSC_loss 0.26, Spatial_loss 2.69, Flat_loss 0.22, Train_acc 95.47, Test_acc 46.46
2025-02-13 19:11:20,423 [podnet.py] => Task 20, Epoch 107/160 (LR 0.02472) => LSC_loss 0.25, Spatial_loss 2.54, Flat_loss 0.21, Train_acc 95.80, Test_acc 49.50
2025-02-13 19:11:22,263 [podnet.py] => Task 20, Epoch 108/160 (LR 0.02388) => LSC_loss 0.27, Spatial_loss 2.66, Flat_loss 0.22, Train_acc 94.86, Test_acc 48.11
2025-02-13 19:11:24,042 [podnet.py] => Task 20, Epoch 109/160 (LR 0.02304) => LSC_loss 0.26, Spatial_loss 2.57, Flat_loss 0.21, Train_acc 95.07, Test_acc 49.80
2025-02-13 19:11:25,862 [podnet.py] => Task 20, Epoch 110/160 (LR 0.02222) => LSC_loss 0.27, Spatial_loss 2.51, Flat_loss 0.21, Train_acc 95.00, Test_acc 47.38
2025-02-13 19:11:27,656 [podnet.py] => Task 20, Epoch 111/160 (LR 0.02141) => LSC_loss 0.27, Spatial_loss 2.62, Flat_loss 0.21, Train_acc 94.89, Test_acc 48.99
2025-02-13 19:11:29,445 [podnet.py] => Task 20, Epoch 112/160 (LR 0.02061) => LSC_loss 0.26, Spatial_loss 2.50, Flat_loss 0.21, Train_acc 95.43, Test_acc 47.96
2025-02-13 19:11:31,209 [podnet.py] => Task 20, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 2.49, Flat_loss 0.21, Train_acc 94.57, Test_acc 48.52
2025-02-13 19:11:33,017 [podnet.py] => Task 20, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 2.48, Flat_loss 0.21, Train_acc 95.40, Test_acc 47.68
2025-02-13 19:11:34,827 [podnet.py] => Task 20, Epoch 115/160 (LR 0.01828) => LSC_loss 0.26, Spatial_loss 2.45, Flat_loss 0.20, Train_acc 95.22, Test_acc 49.27
2025-02-13 19:11:36,615 [podnet.py] => Task 20, Epoch 116/160 (LR 0.01753) => LSC_loss 0.27, Spatial_loss 2.40, Flat_loss 0.20, Train_acc 95.14, Test_acc 49.01
2025-02-13 19:11:38,429 [podnet.py] => Task 20, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 2.37, Flat_loss 0.20, Train_acc 95.04, Test_acc 48.59
2025-02-13 19:11:40,265 [podnet.py] => Task 20, Epoch 118/160 (LR 0.01606) => LSC_loss 0.27, Spatial_loss 2.37, Flat_loss 0.19, Train_acc 95.00, Test_acc 49.57
2025-02-13 19:11:42,020 [podnet.py] => Task 20, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 2.38, Flat_loss 0.19, Train_acc 94.96, Test_acc 48.67
2025-02-13 19:11:43,807 [podnet.py] => Task 20, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 2.29, Flat_loss 0.19, Train_acc 94.75, Test_acc 48.80
2025-02-13 19:11:45,630 [podnet.py] => Task 20, Epoch 121/160 (LR 0.01396) => LSC_loss 0.26, Spatial_loss 2.29, Flat_loss 0.19, Train_acc 95.36, Test_acc 46.98
2025-02-13 19:11:47,463 [podnet.py] => Task 20, Epoch 122/160 (LR 0.01328) => LSC_loss 0.26, Spatial_loss 2.28, Flat_loss 0.19, Train_acc 95.65, Test_acc 49.54
2025-02-13 19:11:49,271 [podnet.py] => Task 20, Epoch 123/160 (LR 0.01262) => LSC_loss 0.27, Spatial_loss 2.26, Flat_loss 0.18, Train_acc 94.71, Test_acc 49.20
2025-02-13 19:11:51,054 [podnet.py] => Task 20, Epoch 124/160 (LR 0.01198) => LSC_loss 0.27, Spatial_loss 2.23, Flat_loss 0.19, Train_acc 94.93, Test_acc 49.82
2025-02-13 19:11:52,874 [podnet.py] => Task 20, Epoch 125/160 (LR 0.01135) => LSC_loss 0.27, Spatial_loss 2.19, Flat_loss 0.18, Train_acc 95.62, Test_acc 49.41
2025-02-13 19:11:54,695 [podnet.py] => Task 20, Epoch 126/160 (LR 0.01073) => LSC_loss 0.27, Spatial_loss 2.29, Flat_loss 0.19, Train_acc 94.75, Test_acc 49.40
2025-02-13 19:11:56,541 [podnet.py] => Task 20, Epoch 127/160 (LR 0.01013) => LSC_loss 0.27, Spatial_loss 2.25, Flat_loss 0.18, Train_acc 94.49, Test_acc 49.73
2025-02-13 19:11:58,302 [podnet.py] => Task 20, Epoch 128/160 (LR 0.00955) => LSC_loss 0.27, Spatial_loss 2.22, Flat_loss 0.18, Train_acc 94.67, Test_acc 48.04
2025-02-13 19:12:00,124 [podnet.py] => Task 20, Epoch 129/160 (LR 0.00898) => LSC_loss 0.27, Spatial_loss 2.15, Flat_loss 0.18, Train_acc 94.89, Test_acc 48.71
2025-02-13 19:12:01,877 [podnet.py] => Task 20, Epoch 130/160 (LR 0.00843) => LSC_loss 0.26, Spatial_loss 2.16, Flat_loss 0.18, Train_acc 95.22, Test_acc 47.64
2025-02-13 19:12:03,608 [podnet.py] => Task 20, Epoch 131/160 (LR 0.00789) => LSC_loss 0.26, Spatial_loss 2.20, Flat_loss 0.18, Train_acc 95.00, Test_acc 50.01
2025-02-13 19:12:05,416 [podnet.py] => Task 20, Epoch 132/160 (LR 0.00737) => LSC_loss 0.27, Spatial_loss 2.10, Flat_loss 0.18, Train_acc 95.14, Test_acc 48.77
2025-02-13 19:12:07,221 [podnet.py] => Task 20, Epoch 133/160 (LR 0.00686) => LSC_loss 0.27, Spatial_loss 2.09, Flat_loss 0.18, Train_acc 94.78, Test_acc 49.34
2025-02-13 19:12:09,003 [podnet.py] => Task 20, Epoch 134/160 (LR 0.00638) => LSC_loss 0.25, Spatial_loss 2.06, Flat_loss 0.18, Train_acc 95.40, Test_acc 48.78
2025-02-13 19:12:10,811 [podnet.py] => Task 20, Epoch 135/160 (LR 0.00590) => LSC_loss 0.26, Spatial_loss 2.02, Flat_loss 0.17, Train_acc 94.49, Test_acc 49.09
2025-02-13 19:12:12,621 [podnet.py] => Task 20, Epoch 136/160 (LR 0.00545) => LSC_loss 0.27, Spatial_loss 1.99, Flat_loss 0.17, Train_acc 95.00, Test_acc 49.54
2025-02-13 19:12:14,455 [podnet.py] => Task 20, Epoch 137/160 (LR 0.00501) => LSC_loss 0.26, Spatial_loss 1.97, Flat_loss 0.17, Train_acc 95.14, Test_acc 49.36
2025-02-13 19:12:16,250 [podnet.py] => Task 20, Epoch 138/160 (LR 0.00459) => LSC_loss 0.27, Spatial_loss 2.03, Flat_loss 0.17, Train_acc 95.07, Test_acc 49.60
2025-02-13 19:12:18,016 [podnet.py] => Task 20, Epoch 139/160 (LR 0.00419) => LSC_loss 0.26, Spatial_loss 1.94, Flat_loss 0.17, Train_acc 95.11, Test_acc 49.27
2025-02-13 19:12:19,733 [podnet.py] => Task 20, Epoch 140/160 (LR 0.00381) => LSC_loss 0.27, Spatial_loss 1.88, Flat_loss 0.16, Train_acc 94.78, Test_acc 49.28
2025-02-13 19:12:21,602 [podnet.py] => Task 20, Epoch 141/160 (LR 0.00344) => LSC_loss 0.26, Spatial_loss 1.90, Flat_loss 0.17, Train_acc 94.96, Test_acc 49.87
2025-02-13 19:12:23,407 [podnet.py] => Task 20, Epoch 142/160 (LR 0.00309) => LSC_loss 0.26, Spatial_loss 1.99, Flat_loss 0.17, Train_acc 94.93, Test_acc 49.64
2025-02-13 19:12:25,213 [podnet.py] => Task 20, Epoch 143/160 (LR 0.00276) => LSC_loss 0.27, Spatial_loss 1.89, Flat_loss 0.16, Train_acc 94.60, Test_acc 49.52
2025-02-13 19:12:27,032 [podnet.py] => Task 20, Epoch 144/160 (LR 0.00245) => LSC_loss 0.26, Spatial_loss 1.94, Flat_loss 0.17, Train_acc 95.51, Test_acc 50.11
2025-02-13 19:12:28,810 [podnet.py] => Task 20, Epoch 145/160 (LR 0.00215) => LSC_loss 0.26, Spatial_loss 1.92, Flat_loss 0.16, Train_acc 95.58, Test_acc 49.58
2025-02-13 19:12:30,572 [podnet.py] => Task 20, Epoch 146/160 (LR 0.00188) => LSC_loss 0.26, Spatial_loss 1.77, Flat_loss 0.16, Train_acc 95.29, Test_acc 50.37
2025-02-13 19:12:32,367 [podnet.py] => Task 20, Epoch 147/160 (LR 0.00162) => LSC_loss 0.26, Spatial_loss 1.90, Flat_loss 0.16, Train_acc 95.25, Test_acc 49.61
2025-02-13 19:12:34,176 [podnet.py] => Task 20, Epoch 148/160 (LR 0.00138) => LSC_loss 0.26, Spatial_loss 1.83, Flat_loss 0.16, Train_acc 95.07, Test_acc 49.88
2025-02-13 19:12:35,986 [podnet.py] => Task 20, Epoch 149/160 (LR 0.00116) => LSC_loss 0.27, Spatial_loss 1.87, Flat_loss 0.16, Train_acc 94.86, Test_acc 49.92
2025-02-13 19:12:37,781 [podnet.py] => Task 20, Epoch 150/160 (LR 0.00096) => LSC_loss 0.25, Spatial_loss 1.84, Flat_loss 0.16, Train_acc 94.93, Test_acc 49.56
2025-02-13 19:12:39,564 [podnet.py] => Task 20, Epoch 151/160 (LR 0.00078) => LSC_loss 0.25, Spatial_loss 1.83, Flat_loss 0.16, Train_acc 95.40, Test_acc 49.82
2025-02-13 19:12:41,387 [podnet.py] => Task 20, Epoch 152/160 (LR 0.00062) => LSC_loss 0.27, Spatial_loss 1.86, Flat_loss 0.16, Train_acc 94.86, Test_acc 49.76
2025-02-13 19:12:43,143 [podnet.py] => Task 20, Epoch 153/160 (LR 0.00047) => LSC_loss 0.27, Spatial_loss 1.76, Flat_loss 0.16, Train_acc 94.86, Test_acc 50.08
2025-02-13 19:12:44,910 [podnet.py] => Task 20, Epoch 154/160 (LR 0.00035) => LSC_loss 0.27, Spatial_loss 1.83, Flat_loss 0.16, Train_acc 95.14, Test_acc 49.89
2025-02-13 19:12:46,693 [podnet.py] => Task 20, Epoch 155/160 (LR 0.00024) => LSC_loss 0.27, Spatial_loss 1.78, Flat_loss 0.16, Train_acc 95.07, Test_acc 49.87
2025-02-13 19:12:48,469 [podnet.py] => Task 20, Epoch 156/160 (LR 0.00015) => LSC_loss 0.27, Spatial_loss 1.80, Flat_loss 0.16, Train_acc 95.18, Test_acc 50.03
2025-02-13 19:12:50,301 [podnet.py] => Task 20, Epoch 157/160 (LR 0.00009) => LSC_loss 0.27, Spatial_loss 1.76, Flat_loss 0.16, Train_acc 94.31, Test_acc 49.76
2025-02-13 19:12:52,099 [podnet.py] => Task 20, Epoch 158/160 (LR 0.00004) => LSC_loss 0.26, Spatial_loss 1.76, Flat_loss 0.16, Train_acc 95.22, Test_acc 49.80
2025-02-13 19:12:53,923 [podnet.py] => Task 20, Epoch 159/160 (LR 0.00001) => LSC_loss 0.26, Spatial_loss 1.75, Flat_loss 0.16, Train_acc 95.11, Test_acc 49.69
2025-02-13 19:12:55,680 [podnet.py] => Task 20, Epoch 160/160 (LR 0.00000) => LSC_loss 0.26, Spatial_loss 1.81, Flat_loss 0.16, Train_acc 94.93, Test_acc 49.86
2025-02-13 19:12:55,682 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:12:55,682 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:13:24,611 [podnet.py] => The size of finetune dataset: 1800
2025-02-13 19:13:26,187 [podnet.py] => Task 20, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 2.35, Flat_loss 0.18, Train_acc 97.83, Test_acc 49.81
2025-02-13 19:13:27,756 [podnet.py] => Task 20, Epoch 2/20 (LR 0.00488) => LSC_loss 0.14, Spatial_loss 2.16, Flat_loss 0.11, Train_acc 98.94, Test_acc 51.14
2025-02-13 19:13:29,317 [podnet.py] => Task 20, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 2.19, Flat_loss 0.11, Train_acc 98.56, Test_acc 51.52
2025-02-13 19:13:30,891 [podnet.py] => Task 20, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 2.11, Flat_loss 0.10, Train_acc 99.06, Test_acc 51.64
2025-02-13 19:13:32,478 [podnet.py] => Task 20, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 2.31, Flat_loss 0.12, Train_acc 98.78, Test_acc 51.37
2025-02-13 19:13:34,093 [podnet.py] => Task 20, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 2.32, Flat_loss 0.13, Train_acc 98.61, Test_acc 50.96
2025-02-13 19:13:35,698 [podnet.py] => Task 20, Epoch 7/20 (LR 0.00363) => LSC_loss 0.17, Spatial_loss 2.16, Flat_loss 0.11, Train_acc 99.06, Test_acc 51.12
2025-02-13 19:13:37,282 [podnet.py] => Task 20, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 2.13, Flat_loss 0.11, Train_acc 98.89, Test_acc 50.54
2025-02-13 19:13:38,855 [podnet.py] => Task 20, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 2.12, Flat_loss 0.10, Train_acc 99.00, Test_acc 51.23
2025-02-13 19:13:40,456 [podnet.py] => Task 20, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 2.16, Flat_loss 0.10, Train_acc 98.89, Test_acc 51.39
2025-02-13 19:13:42,090 [podnet.py] => Task 20, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 2.27, Flat_loss 0.10, Train_acc 99.00, Test_acc 51.18
2025-02-13 19:13:43,687 [podnet.py] => Task 20, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 2.06, Flat_loss 0.09, Train_acc 98.83, Test_acc 51.34
2025-02-13 19:13:45,264 [podnet.py] => Task 20, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 1.99, Flat_loss 0.09, Train_acc 98.89, Test_acc 51.54
2025-02-13 19:13:46,840 [podnet.py] => Task 20, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 2.06, Flat_loss 0.10, Train_acc 98.94, Test_acc 51.22
2025-02-13 19:13:48,448 [podnet.py] => Task 20, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 2.24, Flat_loss 0.12, Train_acc 98.94, Test_acc 51.30
2025-02-13 19:13:50,011 [podnet.py] => Task 20, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 1.91, Flat_loss 0.09, Train_acc 98.83, Test_acc 51.16
2025-02-13 19:13:51,649 [podnet.py] => Task 20, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.95, Flat_loss 0.09, Train_acc 98.50, Test_acc 51.48
2025-02-13 19:13:53,297 [podnet.py] => Task 20, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 2.11, Flat_loss 0.12, Train_acc 98.89, Test_acc 51.48
2025-02-13 19:13:54,903 [podnet.py] => Task 20, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 1.94, Flat_loss 0.10, Train_acc 98.83, Test_acc 51.22
2025-02-13 19:13:56,490 [podnet.py] => Task 20, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 2.05, Flat_loss 0.11, Train_acc 98.78, Test_acc 51.29
2025-02-13 19:13:56,491 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:14:26,718 [podnet.py] => Exemplar size: 1800
2025-02-13 19:14:26,718 [trainer.py] => CNN: {'total': 51.29, '00-09': 62.1, '10-19': 40.2, '20-29': 60.5, '30-39': 49.6, '40-49': 55.5, '50-59': 35.7, '60-69': 48.2, '70-79': 54.0, '80-89': 55.8, 'old': 51.43, 'new': 45.0}
2025-02-13 19:14:26,718 [trainer.py] => NME: {'total': 51.26, '00-09': 64.3, '10-19': 43.4, '20-29': 61.6, '30-39': 52.4, '40-49': 56.0, '50-59': 31.5, '60-69': 46.0, '70-79': 54.5, '80-89': 51.6, 'old': 51.44, 'new': 43.0}
2025-02-13 19:14:26,718 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29]
2025-02-13 19:14:26,718 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13]
2025-02-13 19:14:26,718 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26]
2025-02-13 19:14:26,718 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44]

2025-02-13 19:14:26,718 [trainer.py] => Average Accuracy (CNN): 62.479047619047606
2025-02-13 19:14:26,719 [trainer.py] => Average Accuracy (NME): 62.668571428571425
2025-02-13 19:14:26,719 [trainer.py] => All params: 523857
2025-02-13 19:14:26,719 [trainer.py] => Trainable params: 523857
2025-02-13 19:14:26,720 [podnet.py] => Learning on 90-92
2025-02-13 19:14:26,744 [podnet.py] => Adaptive factor: 6.782329983125268
2025-02-13 19:14:28,589 [podnet.py] => Task 21, Epoch 1/160 (LR 0.09999) => LSC_loss 1.26, Spatial_loss 4.39, Flat_loss 0.58, Train_acc 80.68, Test_acc 43.48
2025-02-13 19:14:30,429 [podnet.py] => Task 21, Epoch 2/160 (LR 0.09996) => LSC_loss 0.45, Spatial_loss 5.27, Flat_loss 0.63, Train_acc 88.43, Test_acc 42.41
2025-02-13 19:14:32,282 [podnet.py] => Task 21, Epoch 3/160 (LR 0.09991) => LSC_loss 0.42, Spatial_loss 5.49, Flat_loss 0.65, Train_acc 89.43, Test_acc 40.26
2025-02-13 19:14:34,131 [podnet.py] => Task 21, Epoch 4/160 (LR 0.09985) => LSC_loss 0.39, Spatial_loss 5.40, Flat_loss 0.61, Train_acc 90.00, Test_acc 42.52
2025-02-13 19:14:35,941 [podnet.py] => Task 21, Epoch 5/160 (LR 0.09976) => LSC_loss 0.37, Spatial_loss 5.24, Flat_loss 0.58, Train_acc 91.68, Test_acc 39.21
2025-02-13 19:14:37,779 [podnet.py] => Task 21, Epoch 6/160 (LR 0.09965) => LSC_loss 0.35, Spatial_loss 5.19, Flat_loss 0.57, Train_acc 91.82, Test_acc 42.90
2025-02-13 19:14:39,570 [podnet.py] => Task 21, Epoch 7/160 (LR 0.09953) => LSC_loss 0.34, Spatial_loss 5.03, Flat_loss 0.53, Train_acc 91.93, Test_acc 42.70
2025-02-13 19:14:41,348 [podnet.py] => Task 21, Epoch 8/160 (LR 0.09938) => LSC_loss 0.32, Spatial_loss 4.96, Flat_loss 0.52, Train_acc 92.57, Test_acc 43.38
2025-02-13 19:14:43,157 [podnet.py] => Task 21, Epoch 9/160 (LR 0.09922) => LSC_loss 0.30, Spatial_loss 4.73, Flat_loss 0.48, Train_acc 93.36, Test_acc 42.15
2025-02-13 19:14:44,954 [podnet.py] => Task 21, Epoch 10/160 (LR 0.09904) => LSC_loss 0.32, Spatial_loss 4.83, Flat_loss 0.50, Train_acc 93.18, Test_acc 41.63
2025-02-13 19:14:46,766 [podnet.py] => Task 21, Epoch 11/160 (LR 0.09884) => LSC_loss 0.30, Spatial_loss 4.74, Flat_loss 0.47, Train_acc 93.43, Test_acc 46.58
2025-02-13 19:14:48,585 [podnet.py] => Task 21, Epoch 12/160 (LR 0.09862) => LSC_loss 0.29, Spatial_loss 4.59, Flat_loss 0.45, Train_acc 94.00, Test_acc 45.95
2025-02-13 19:14:50,425 [podnet.py] => Task 21, Epoch 13/160 (LR 0.09838) => LSC_loss 0.27, Spatial_loss 4.58, Flat_loss 0.46, Train_acc 94.50, Test_acc 46.10
2025-02-13 19:14:52,269 [podnet.py] => Task 21, Epoch 14/160 (LR 0.09812) => LSC_loss 0.27, Spatial_loss 4.51, Flat_loss 0.43, Train_acc 94.14, Test_acc 45.32
2025-02-13 19:14:54,131 [podnet.py] => Task 21, Epoch 15/160 (LR 0.09785) => LSC_loss 0.28, Spatial_loss 4.60, Flat_loss 0.43, Train_acc 93.61, Test_acc 44.23
2025-02-13 19:14:55,914 [podnet.py] => Task 21, Epoch 16/160 (LR 0.09755) => LSC_loss 0.27, Spatial_loss 4.50, Flat_loss 0.43, Train_acc 94.36, Test_acc 44.59
2025-02-13 19:14:57,750 [podnet.py] => Task 21, Epoch 17/160 (LR 0.09724) => LSC_loss 0.28, Spatial_loss 4.49, Flat_loss 0.44, Train_acc 93.82, Test_acc 45.27
2025-02-13 19:14:59,584 [podnet.py] => Task 21, Epoch 18/160 (LR 0.09691) => LSC_loss 0.29, Spatial_loss 4.61, Flat_loss 0.46, Train_acc 93.43, Test_acc 41.43
2025-02-13 19:15:01,447 [podnet.py] => Task 21, Epoch 19/160 (LR 0.09656) => LSC_loss 0.26, Spatial_loss 4.63, Flat_loss 0.45, Train_acc 94.64, Test_acc 42.59
2025-02-13 19:15:03,248 [podnet.py] => Task 21, Epoch 20/160 (LR 0.09619) => LSC_loss 0.27, Spatial_loss 4.51, Flat_loss 0.43, Train_acc 95.11, Test_acc 45.74
2025-02-13 19:15:05,061 [podnet.py] => Task 21, Epoch 21/160 (LR 0.09581) => LSC_loss 0.26, Spatial_loss 4.49, Flat_loss 0.42, Train_acc 94.79, Test_acc 43.70
2025-02-13 19:15:06,835 [podnet.py] => Task 21, Epoch 22/160 (LR 0.09541) => LSC_loss 0.27, Spatial_loss 4.50, Flat_loss 0.41, Train_acc 94.43, Test_acc 45.49
2025-02-13 19:15:08,619 [podnet.py] => Task 21, Epoch 23/160 (LR 0.09499) => LSC_loss 0.25, Spatial_loss 4.34, Flat_loss 0.41, Train_acc 94.61, Test_acc 44.20
2025-02-13 19:15:10,475 [podnet.py] => Task 21, Epoch 24/160 (LR 0.09455) => LSC_loss 0.26, Spatial_loss 4.40, Flat_loss 0.39, Train_acc 94.82, Test_acc 47.42
2025-02-13 19:15:12,284 [podnet.py] => Task 21, Epoch 25/160 (LR 0.09410) => LSC_loss 0.25, Spatial_loss 4.18, Flat_loss 0.39, Train_acc 94.89, Test_acc 44.66
2025-02-13 19:15:14,052 [podnet.py] => Task 21, Epoch 26/160 (LR 0.09362) => LSC_loss 0.24, Spatial_loss 4.19, Flat_loss 0.38, Train_acc 95.43, Test_acc 44.71
2025-02-13 19:15:15,836 [podnet.py] => Task 21, Epoch 27/160 (LR 0.09314) => LSC_loss 0.26, Spatial_loss 4.11, Flat_loss 0.37, Train_acc 95.07, Test_acc 46.42
2025-02-13 19:15:17,670 [podnet.py] => Task 21, Epoch 28/160 (LR 0.09263) => LSC_loss 0.25, Spatial_loss 4.12, Flat_loss 0.37, Train_acc 95.25, Test_acc 42.61
2025-02-13 19:15:19,481 [podnet.py] => Task 21, Epoch 29/160 (LR 0.09211) => LSC_loss 0.24, Spatial_loss 4.26, Flat_loss 0.39, Train_acc 95.36, Test_acc 42.84
2025-02-13 19:15:21,322 [podnet.py] => Task 21, Epoch 30/160 (LR 0.09157) => LSC_loss 0.25, Spatial_loss 4.13, Flat_loss 0.38, Train_acc 95.07, Test_acc 47.86
2025-02-13 19:15:23,210 [podnet.py] => Task 21, Epoch 31/160 (LR 0.09102) => LSC_loss 0.25, Spatial_loss 4.26, Flat_loss 0.39, Train_acc 94.82, Test_acc 42.11
2025-02-13 19:15:25,033 [podnet.py] => Task 21, Epoch 32/160 (LR 0.09045) => LSC_loss 0.26, Spatial_loss 4.29, Flat_loss 0.39, Train_acc 94.75, Test_acc 43.17
2025-02-13 19:15:26,883 [podnet.py] => Task 21, Epoch 33/160 (LR 0.08987) => LSC_loss 0.24, Spatial_loss 4.39, Flat_loss 0.41, Train_acc 94.96, Test_acc 46.21
2025-02-13 19:15:28,676 [podnet.py] => Task 21, Epoch 34/160 (LR 0.08927) => LSC_loss 0.26, Spatial_loss 4.24, Flat_loss 0.39, Train_acc 94.68, Test_acc 46.72
2025-02-13 19:15:30,485 [podnet.py] => Task 21, Epoch 35/160 (LR 0.08865) => LSC_loss 0.24, Spatial_loss 4.04, Flat_loss 0.37, Train_acc 95.68, Test_acc 45.87
2025-02-13 19:15:32,225 [podnet.py] => Task 21, Epoch 36/160 (LR 0.08802) => LSC_loss 0.23, Spatial_loss 4.10, Flat_loss 0.37, Train_acc 95.89, Test_acc 46.23
2025-02-13 19:15:34,092 [podnet.py] => Task 21, Epoch 37/160 (LR 0.08738) => LSC_loss 0.23, Spatial_loss 4.06, Flat_loss 0.34, Train_acc 95.82, Test_acc 45.38
2025-02-13 19:15:35,844 [podnet.py] => Task 21, Epoch 38/160 (LR 0.08672) => LSC_loss 0.24, Spatial_loss 4.06, Flat_loss 0.36, Train_acc 95.32, Test_acc 45.03
2025-02-13 19:15:37,630 [podnet.py] => Task 21, Epoch 39/160 (LR 0.08604) => LSC_loss 0.23, Spatial_loss 4.02, Flat_loss 0.37, Train_acc 95.32, Test_acc 47.73
2025-02-13 19:15:39,422 [podnet.py] => Task 21, Epoch 40/160 (LR 0.08536) => LSC_loss 0.23, Spatial_loss 3.98, Flat_loss 0.34, Train_acc 95.50, Test_acc 48.13
2025-02-13 19:15:41,245 [podnet.py] => Task 21, Epoch 41/160 (LR 0.08465) => LSC_loss 0.25, Spatial_loss 3.99, Flat_loss 0.35, Train_acc 95.21, Test_acc 45.03
2025-02-13 19:15:43,082 [podnet.py] => Task 21, Epoch 42/160 (LR 0.08394) => LSC_loss 0.25, Spatial_loss 4.05, Flat_loss 0.36, Train_acc 95.46, Test_acc 42.96
2025-02-13 19:15:44,915 [podnet.py] => Task 21, Epoch 43/160 (LR 0.08321) => LSC_loss 0.24, Spatial_loss 4.07, Flat_loss 0.38, Train_acc 95.11, Test_acc 44.59
2025-02-13 19:15:46,753 [podnet.py] => Task 21, Epoch 44/160 (LR 0.08247) => LSC_loss 0.23, Spatial_loss 4.01, Flat_loss 0.36, Train_acc 95.46, Test_acc 48.76
2025-02-13 19:15:48,507 [podnet.py] => Task 21, Epoch 45/160 (LR 0.08172) => LSC_loss 0.23, Spatial_loss 3.89, Flat_loss 0.34, Train_acc 95.82, Test_acc 45.14
2025-02-13 19:15:50,334 [podnet.py] => Task 21, Epoch 46/160 (LR 0.08095) => LSC_loss 0.23, Spatial_loss 4.06, Flat_loss 0.34, Train_acc 95.75, Test_acc 46.00
2025-02-13 19:15:52,116 [podnet.py] => Task 21, Epoch 47/160 (LR 0.08018) => LSC_loss 0.24, Spatial_loss 3.92, Flat_loss 0.34, Train_acc 94.96, Test_acc 47.68
2025-02-13 19:15:53,970 [podnet.py] => Task 21, Epoch 48/160 (LR 0.07939) => LSC_loss 0.23, Spatial_loss 3.83, Flat_loss 0.33, Train_acc 95.11, Test_acc 48.63
2025-02-13 19:15:55,780 [podnet.py] => Task 21, Epoch 49/160 (LR 0.07859) => LSC_loss 0.22, Spatial_loss 3.91, Flat_loss 0.33, Train_acc 96.04, Test_acc 47.60
2025-02-13 19:15:57,562 [podnet.py] => Task 21, Epoch 50/160 (LR 0.07778) => LSC_loss 0.24, Spatial_loss 3.94, Flat_loss 0.35, Train_acc 95.21, Test_acc 47.20
2025-02-13 19:15:59,410 [podnet.py] => Task 21, Epoch 51/160 (LR 0.07696) => LSC_loss 0.23, Spatial_loss 3.89, Flat_loss 0.34, Train_acc 95.43, Test_acc 45.58
2025-02-13 19:16:01,232 [podnet.py] => Task 21, Epoch 52/160 (LR 0.07612) => LSC_loss 0.23, Spatial_loss 3.97, Flat_loss 0.34, Train_acc 95.64, Test_acc 47.12
2025-02-13 19:16:02,996 [podnet.py] => Task 21, Epoch 53/160 (LR 0.07528) => LSC_loss 0.23, Spatial_loss 3.85, Flat_loss 0.33, Train_acc 95.86, Test_acc 46.21
2025-02-13 19:16:04,804 [podnet.py] => Task 21, Epoch 54/160 (LR 0.07443) => LSC_loss 0.23, Spatial_loss 3.78, Flat_loss 0.32, Train_acc 95.79, Test_acc 44.99
2025-02-13 19:16:06,620 [podnet.py] => Task 21, Epoch 55/160 (LR 0.07357) => LSC_loss 0.23, Spatial_loss 3.76, Flat_loss 0.32, Train_acc 95.75, Test_acc 46.26
2025-02-13 19:16:08,410 [podnet.py] => Task 21, Epoch 56/160 (LR 0.07270) => LSC_loss 0.24, Spatial_loss 3.84, Flat_loss 0.33, Train_acc 95.07, Test_acc 45.96
2025-02-13 19:16:10,190 [podnet.py] => Task 21, Epoch 57/160 (LR 0.07182) => LSC_loss 0.22, Spatial_loss 3.92, Flat_loss 0.33, Train_acc 95.79, Test_acc 47.07
2025-02-13 19:16:12,009 [podnet.py] => Task 21, Epoch 58/160 (LR 0.07093) => LSC_loss 0.23, Spatial_loss 3.88, Flat_loss 0.33, Train_acc 95.61, Test_acc 46.53
2025-02-13 19:16:13,863 [podnet.py] => Task 21, Epoch 59/160 (LR 0.07004) => LSC_loss 0.23, Spatial_loss 3.77, Flat_loss 0.32, Train_acc 95.71, Test_acc 46.88
2025-02-13 19:16:15,679 [podnet.py] => Task 21, Epoch 60/160 (LR 0.06913) => LSC_loss 0.22, Spatial_loss 3.67, Flat_loss 0.31, Train_acc 95.68, Test_acc 45.89
2025-02-13 19:16:17,522 [podnet.py] => Task 21, Epoch 61/160 (LR 0.06822) => LSC_loss 0.22, Spatial_loss 3.55, Flat_loss 0.30, Train_acc 95.64, Test_acc 48.84
2025-02-13 19:16:19,339 [podnet.py] => Task 21, Epoch 62/160 (LR 0.06731) => LSC_loss 0.22, Spatial_loss 3.55, Flat_loss 0.30, Train_acc 95.43, Test_acc 45.89
2025-02-13 19:16:21,112 [podnet.py] => Task 21, Epoch 63/160 (LR 0.06638) => LSC_loss 0.22, Spatial_loss 3.72, Flat_loss 0.30, Train_acc 96.07, Test_acc 48.07
2025-02-13 19:16:22,975 [podnet.py] => Task 21, Epoch 64/160 (LR 0.06545) => LSC_loss 0.23, Spatial_loss 3.62, Flat_loss 0.30, Train_acc 95.79, Test_acc 45.80
2025-02-13 19:16:24,780 [podnet.py] => Task 21, Epoch 65/160 (LR 0.06451) => LSC_loss 0.22, Spatial_loss 3.59, Flat_loss 0.30, Train_acc 95.57, Test_acc 48.73
2025-02-13 19:16:26,540 [podnet.py] => Task 21, Epoch 66/160 (LR 0.06357) => LSC_loss 0.22, Spatial_loss 3.59, Flat_loss 0.30, Train_acc 95.71, Test_acc 47.39
2025-02-13 19:16:28,379 [podnet.py] => Task 21, Epoch 67/160 (LR 0.06262) => LSC_loss 0.22, Spatial_loss 3.50, Flat_loss 0.29, Train_acc 95.86, Test_acc 47.26
2025-02-13 19:16:30,239 [podnet.py] => Task 21, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 3.58, Flat_loss 0.29, Train_acc 95.04, Test_acc 47.90
2025-02-13 19:16:32,114 [podnet.py] => Task 21, Epoch 69/160 (LR 0.06072) => LSC_loss 0.22, Spatial_loss 3.40, Flat_loss 0.28, Train_acc 96.11, Test_acc 47.14
2025-02-13 19:16:33,959 [podnet.py] => Task 21, Epoch 70/160 (LR 0.05975) => LSC_loss 0.22, Spatial_loss 3.40, Flat_loss 0.29, Train_acc 96.14, Test_acc 48.76
2025-02-13 19:16:35,859 [podnet.py] => Task 21, Epoch 71/160 (LR 0.05879) => LSC_loss 0.22, Spatial_loss 3.53, Flat_loss 0.29, Train_acc 96.25, Test_acc 46.15
2025-02-13 19:16:37,707 [podnet.py] => Task 21, Epoch 72/160 (LR 0.05782) => LSC_loss 0.22, Spatial_loss 3.41, Flat_loss 0.28, Train_acc 96.11, Test_acc 48.28
2025-02-13 19:16:39,530 [podnet.py] => Task 21, Epoch 73/160 (LR 0.05685) => LSC_loss 0.20, Spatial_loss 3.40, Flat_loss 0.27, Train_acc 96.86, Test_acc 48.50
2025-02-13 19:16:41,373 [podnet.py] => Task 21, Epoch 74/160 (LR 0.05588) => LSC_loss 0.22, Spatial_loss 3.30, Flat_loss 0.27, Train_acc 95.89, Test_acc 47.51
2025-02-13 19:16:43,225 [podnet.py] => Task 21, Epoch 75/160 (LR 0.05490) => LSC_loss 0.22, Spatial_loss 3.45, Flat_loss 0.27, Train_acc 95.93, Test_acc 46.67
2025-02-13 19:16:44,997 [podnet.py] => Task 21, Epoch 76/160 (LR 0.05392) => LSC_loss 0.22, Spatial_loss 3.46, Flat_loss 0.28, Train_acc 96.11, Test_acc 47.45
2025-02-13 19:16:46,823 [podnet.py] => Task 21, Epoch 77/160 (LR 0.05294) => LSC_loss 0.21, Spatial_loss 3.27, Flat_loss 0.26, Train_acc 96.36, Test_acc 47.89
2025-02-13 19:16:48,590 [podnet.py] => Task 21, Epoch 78/160 (LR 0.05196) => LSC_loss 0.22, Spatial_loss 3.22, Flat_loss 0.25, Train_acc 96.29, Test_acc 47.07
2025-02-13 19:16:50,410 [podnet.py] => Task 21, Epoch 79/160 (LR 0.05098) => LSC_loss 0.21, Spatial_loss 3.33, Flat_loss 0.26, Train_acc 96.04, Test_acc 48.86
2025-02-13 19:16:52,241 [podnet.py] => Task 21, Epoch 80/160 (LR 0.05000) => LSC_loss 0.21, Spatial_loss 3.20, Flat_loss 0.26, Train_acc 96.18, Test_acc 47.99
2025-02-13 19:16:54,081 [podnet.py] => Task 21, Epoch 81/160 (LR 0.04902) => LSC_loss 0.21, Spatial_loss 3.17, Flat_loss 0.24, Train_acc 96.75, Test_acc 47.74
2025-02-13 19:16:55,915 [podnet.py] => Task 21, Epoch 82/160 (LR 0.04804) => LSC_loss 0.20, Spatial_loss 3.05, Flat_loss 0.23, Train_acc 96.43, Test_acc 48.34
2025-02-13 19:16:57,700 [podnet.py] => Task 21, Epoch 83/160 (LR 0.04706) => LSC_loss 0.21, Spatial_loss 3.15, Flat_loss 0.25, Train_acc 96.18, Test_acc 47.92
2025-02-13 19:16:59,454 [podnet.py] => Task 21, Epoch 84/160 (LR 0.04608) => LSC_loss 0.20, Spatial_loss 3.02, Flat_loss 0.24, Train_acc 96.29, Test_acc 50.24
2025-02-13 19:17:01,291 [podnet.py] => Task 21, Epoch 85/160 (LR 0.04510) => LSC_loss 0.22, Spatial_loss 3.27, Flat_loss 0.25, Train_acc 95.75, Test_acc 49.00
2025-02-13 19:17:03,129 [podnet.py] => Task 21, Epoch 86/160 (LR 0.04412) => LSC_loss 0.21, Spatial_loss 3.28, Flat_loss 0.25, Train_acc 96.14, Test_acc 47.02
2025-02-13 19:17:04,948 [podnet.py] => Task 21, Epoch 87/160 (LR 0.04315) => LSC_loss 0.21, Spatial_loss 3.27, Flat_loss 0.26, Train_acc 96.04, Test_acc 48.02
2025-02-13 19:17:06,756 [podnet.py] => Task 21, Epoch 88/160 (LR 0.04218) => LSC_loss 0.21, Spatial_loss 3.21, Flat_loss 0.25, Train_acc 96.39, Test_acc 46.87
2025-02-13 19:17:08,577 [podnet.py] => Task 21, Epoch 89/160 (LR 0.04121) => LSC_loss 0.20, Spatial_loss 3.02, Flat_loss 0.24, Train_acc 96.43, Test_acc 46.72
2025-02-13 19:17:10,370 [podnet.py] => Task 21, Epoch 90/160 (LR 0.04025) => LSC_loss 0.22, Spatial_loss 3.07, Flat_loss 0.24, Train_acc 96.21, Test_acc 47.89
2025-02-13 19:17:12,226 [podnet.py] => Task 21, Epoch 91/160 (LR 0.03928) => LSC_loss 0.21, Spatial_loss 2.97, Flat_loss 0.22, Train_acc 96.04, Test_acc 49.00
2025-02-13 19:17:13,999 [podnet.py] => Task 21, Epoch 92/160 (LR 0.03833) => LSC_loss 0.22, Spatial_loss 3.02, Flat_loss 0.24, Train_acc 96.21, Test_acc 47.05
2025-02-13 19:17:15,822 [podnet.py] => Task 21, Epoch 93/160 (LR 0.03738) => LSC_loss 0.21, Spatial_loss 2.96, Flat_loss 0.23, Train_acc 96.32, Test_acc 47.24
2025-02-13 19:17:17,612 [podnet.py] => Task 21, Epoch 94/160 (LR 0.03643) => LSC_loss 0.21, Spatial_loss 2.89, Flat_loss 0.22, Train_acc 95.82, Test_acc 45.79
2025-02-13 19:17:19,428 [podnet.py] => Task 21, Epoch 95/160 (LR 0.03549) => LSC_loss 0.19, Spatial_loss 2.85, Flat_loss 0.22, Train_acc 97.57, Test_acc 48.42
2025-02-13 19:17:21,234 [podnet.py] => Task 21, Epoch 96/160 (LR 0.03455) => LSC_loss 0.21, Spatial_loss 2.93, Flat_loss 0.22, Train_acc 96.25, Test_acc 46.10
2025-02-13 19:17:23,023 [podnet.py] => Task 21, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 2.86, Flat_loss 0.22, Train_acc 96.36, Test_acc 48.68
2025-02-13 19:17:24,842 [podnet.py] => Task 21, Epoch 98/160 (LR 0.03269) => LSC_loss 0.20, Spatial_loss 2.84, Flat_loss 0.22, Train_acc 96.18, Test_acc 47.74
2025-02-13 19:17:26,610 [podnet.py] => Task 21, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 2.75, Flat_loss 0.22, Train_acc 96.36, Test_acc 47.93
2025-02-13 19:17:28,434 [podnet.py] => Task 21, Epoch 100/160 (LR 0.03087) => LSC_loss 0.21, Spatial_loss 2.83, Flat_loss 0.21, Train_acc 96.25, Test_acc 48.52
2025-02-13 19:17:30,272 [podnet.py] => Task 21, Epoch 101/160 (LR 0.02996) => LSC_loss 0.20, Spatial_loss 2.88, Flat_loss 0.21, Train_acc 96.43, Test_acc 45.55
2025-02-13 19:17:32,104 [podnet.py] => Task 21, Epoch 102/160 (LR 0.02907) => LSC_loss 0.21, Spatial_loss 2.89, Flat_loss 0.21, Train_acc 96.79, Test_acc 48.35
2025-02-13 19:17:33,902 [podnet.py] => Task 21, Epoch 103/160 (LR 0.02818) => LSC_loss 0.20, Spatial_loss 2.72, Flat_loss 0.21, Train_acc 96.68, Test_acc 49.43
2025-02-13 19:17:35,708 [podnet.py] => Task 21, Epoch 104/160 (LR 0.02730) => LSC_loss 0.20, Spatial_loss 2.63, Flat_loss 0.20, Train_acc 96.46, Test_acc 50.08
2025-02-13 19:17:37,576 [podnet.py] => Task 21, Epoch 105/160 (LR 0.02643) => LSC_loss 0.20, Spatial_loss 2.77, Flat_loss 0.21, Train_acc 96.43, Test_acc 49.25
2025-02-13 19:17:39,395 [podnet.py] => Task 21, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 2.60, Flat_loss 0.19, Train_acc 96.82, Test_acc 49.22
2025-02-13 19:17:41,183 [podnet.py] => Task 21, Epoch 107/160 (LR 0.02472) => LSC_loss 0.20, Spatial_loss 2.54, Flat_loss 0.19, Train_acc 96.21, Test_acc 49.22
2025-02-13 19:17:43,008 [podnet.py] => Task 21, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 2.64, Flat_loss 0.19, Train_acc 96.79, Test_acc 45.15
2025-02-13 19:17:44,836 [podnet.py] => Task 21, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 2.66, Flat_loss 0.19, Train_acc 96.64, Test_acc 49.27
2025-02-13 19:17:46,615 [podnet.py] => Task 21, Epoch 110/160 (LR 0.02222) => LSC_loss 0.20, Spatial_loss 2.56, Flat_loss 0.19, Train_acc 96.75, Test_acc 48.75
2025-02-13 19:17:48,429 [podnet.py] => Task 21, Epoch 111/160 (LR 0.02141) => LSC_loss 0.21, Spatial_loss 2.56, Flat_loss 0.19, Train_acc 95.96, Test_acc 47.50
2025-02-13 19:17:50,234 [podnet.py] => Task 21, Epoch 112/160 (LR 0.02061) => LSC_loss 0.20, Spatial_loss 2.36, Flat_loss 0.18, Train_acc 96.43, Test_acc 49.98
2025-02-13 19:17:52,019 [podnet.py] => Task 21, Epoch 113/160 (LR 0.01982) => LSC_loss 0.21, Spatial_loss 2.42, Flat_loss 0.18, Train_acc 96.25, Test_acc 48.80
2025-02-13 19:17:53,831 [podnet.py] => Task 21, Epoch 114/160 (LR 0.01905) => LSC_loss 0.20, Spatial_loss 2.40, Flat_loss 0.18, Train_acc 96.11, Test_acc 47.97
2025-02-13 19:17:55,640 [podnet.py] => Task 21, Epoch 115/160 (LR 0.01828) => LSC_loss 0.20, Spatial_loss 2.45, Flat_loss 0.18, Train_acc 96.79, Test_acc 48.36
2025-02-13 19:17:57,402 [podnet.py] => Task 21, Epoch 116/160 (LR 0.01753) => LSC_loss 0.20, Spatial_loss 2.40, Flat_loss 0.18, Train_acc 96.64, Test_acc 49.43
2025-02-13 19:17:59,194 [podnet.py] => Task 21, Epoch 117/160 (LR 0.01679) => LSC_loss 0.20, Spatial_loss 2.37, Flat_loss 0.17, Train_acc 96.50, Test_acc 49.65
2025-02-13 19:18:01,001 [podnet.py] => Task 21, Epoch 118/160 (LR 0.01606) => LSC_loss 0.20, Spatial_loss 2.49, Flat_loss 0.18, Train_acc 96.36, Test_acc 48.93
2025-02-13 19:18:02,832 [podnet.py] => Task 21, Epoch 119/160 (LR 0.01535) => LSC_loss 0.19, Spatial_loss 2.37, Flat_loss 0.18, Train_acc 96.39, Test_acc 48.27
2025-02-13 19:18:04,581 [podnet.py] => Task 21, Epoch 120/160 (LR 0.01464) => LSC_loss 0.20, Spatial_loss 2.30, Flat_loss 0.17, Train_acc 96.43, Test_acc 49.71
2025-02-13 19:18:06,435 [podnet.py] => Task 21, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 2.24, Flat_loss 0.16, Train_acc 97.04, Test_acc 49.71
2025-02-13 19:18:08,277 [podnet.py] => Task 21, Epoch 122/160 (LR 0.01328) => LSC_loss 0.21, Spatial_loss 2.27, Flat_loss 0.17, Train_acc 96.36, Test_acc 49.35
2025-02-13 19:18:10,073 [podnet.py] => Task 21, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 2.39, Flat_loss 0.17, Train_acc 96.93, Test_acc 49.07
2025-02-13 19:18:11,861 [podnet.py] => Task 21, Epoch 124/160 (LR 0.01198) => LSC_loss 0.20, Spatial_loss 2.26, Flat_loss 0.16, Train_acc 96.64, Test_acc 49.97
2025-02-13 19:18:13,623 [podnet.py] => Task 21, Epoch 125/160 (LR 0.01135) => LSC_loss 0.21, Spatial_loss 2.20, Flat_loss 0.16, Train_acc 95.89, Test_acc 49.11
2025-02-13 19:18:15,471 [podnet.py] => Task 21, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 2.11, Flat_loss 0.16, Train_acc 96.79, Test_acc 49.77
2025-02-13 19:18:17,280 [podnet.py] => Task 21, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 2.14, Flat_loss 0.16, Train_acc 96.07, Test_acc 49.66
2025-02-13 19:18:19,022 [podnet.py] => Task 21, Epoch 128/160 (LR 0.00955) => LSC_loss 0.20, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 96.93, Test_acc 49.49
2025-02-13 19:18:20,826 [podnet.py] => Task 21, Epoch 129/160 (LR 0.00898) => LSC_loss 0.20, Spatial_loss 2.07, Flat_loss 0.15, Train_acc 95.96, Test_acc 48.85
2025-02-13 19:18:22,707 [podnet.py] => Task 21, Epoch 130/160 (LR 0.00843) => LSC_loss 0.19, Spatial_loss 2.10, Flat_loss 0.15, Train_acc 96.89, Test_acc 50.17
2025-02-13 19:18:24,538 [podnet.py] => Task 21, Epoch 131/160 (LR 0.00789) => LSC_loss 0.20, Spatial_loss 2.12, Flat_loss 0.15, Train_acc 96.79, Test_acc 49.66
2025-02-13 19:18:26,301 [podnet.py] => Task 21, Epoch 132/160 (LR 0.00737) => LSC_loss 0.20, Spatial_loss 2.06, Flat_loss 0.16, Train_acc 96.82, Test_acc 49.53
2025-02-13 19:18:28,147 [podnet.py] => Task 21, Epoch 133/160 (LR 0.00686) => LSC_loss 0.20, Spatial_loss 1.94, Flat_loss 0.14, Train_acc 96.71, Test_acc 49.79
2025-02-13 19:18:30,028 [podnet.py] => Task 21, Epoch 134/160 (LR 0.00638) => LSC_loss 0.19, Spatial_loss 2.02, Flat_loss 0.15, Train_acc 96.54, Test_acc 50.11
2025-02-13 19:18:31,887 [podnet.py] => Task 21, Epoch 135/160 (LR 0.00590) => LSC_loss 0.19, Spatial_loss 1.92, Flat_loss 0.15, Train_acc 96.82, Test_acc 49.45
2025-02-13 19:18:33,676 [podnet.py] => Task 21, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.99, Flat_loss 0.15, Train_acc 96.29, Test_acc 49.77
2025-02-13 19:18:35,462 [podnet.py] => Task 21, Epoch 137/160 (LR 0.00501) => LSC_loss 0.20, Spatial_loss 1.96, Flat_loss 0.15, Train_acc 96.50, Test_acc 50.36
2025-02-13 19:18:37,334 [podnet.py] => Task 21, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.98, Flat_loss 0.15, Train_acc 96.32, Test_acc 49.92
2025-02-13 19:18:39,183 [podnet.py] => Task 21, Epoch 139/160 (LR 0.00419) => LSC_loss 0.19, Spatial_loss 1.91, Flat_loss 0.14, Train_acc 97.32, Test_acc 50.52
2025-02-13 19:18:40,995 [podnet.py] => Task 21, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.87, Flat_loss 0.14, Train_acc 96.21, Test_acc 50.26
2025-02-13 19:18:42,832 [podnet.py] => Task 21, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.93, Flat_loss 0.14, Train_acc 96.00, Test_acc 49.93
2025-02-13 19:18:44,661 [podnet.py] => Task 21, Epoch 142/160 (LR 0.00309) => LSC_loss 0.20, Spatial_loss 1.85, Flat_loss 0.14, Train_acc 96.18, Test_acc 49.86
2025-02-13 19:18:46,442 [podnet.py] => Task 21, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.83, Flat_loss 0.14, Train_acc 96.14, Test_acc 49.91
2025-02-13 19:18:48,264 [podnet.py] => Task 21, Epoch 144/160 (LR 0.00245) => LSC_loss 0.20, Spatial_loss 1.79, Flat_loss 0.14, Train_acc 96.29, Test_acc 50.30
2025-02-13 19:18:50,085 [podnet.py] => Task 21, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.90, Flat_loss 0.14, Train_acc 96.54, Test_acc 50.14
2025-02-13 19:18:51,879 [podnet.py] => Task 21, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.87, Flat_loss 0.14, Train_acc 96.64, Test_acc 50.10
2025-02-13 19:18:53,702 [podnet.py] => Task 21, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.82, Flat_loss 0.14, Train_acc 96.46, Test_acc 49.99
2025-02-13 19:18:55,482 [podnet.py] => Task 21, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.79, Flat_loss 0.13, Train_acc 96.61, Test_acc 50.35
2025-02-13 19:18:57,272 [podnet.py] => Task 21, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 96.39, Test_acc 50.40
2025-02-13 19:18:59,028 [podnet.py] => Task 21, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.83, Flat_loss 0.14, Train_acc 97.00, Test_acc 50.17
2025-02-13 19:19:00,788 [podnet.py] => Task 21, Epoch 151/160 (LR 0.00078) => LSC_loss 0.21, Spatial_loss 1.79, Flat_loss 0.14, Train_acc 96.07, Test_acc 50.21
2025-02-13 19:19:02,592 [podnet.py] => Task 21, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.81, Flat_loss 0.13, Train_acc 96.14, Test_acc 50.22
2025-02-13 19:19:04,354 [podnet.py] => Task 21, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.76, Flat_loss 0.14, Train_acc 96.11, Test_acc 50.40
2025-02-13 19:19:06,123 [podnet.py] => Task 21, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.71, Flat_loss 0.13, Train_acc 96.64, Test_acc 50.17
2025-02-13 19:19:07,941 [podnet.py] => Task 21, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.78, Flat_loss 0.14, Train_acc 96.21, Test_acc 50.11
2025-02-13 19:19:09,735 [podnet.py] => Task 21, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 1.75, Flat_loss 0.14, Train_acc 96.82, Test_acc 50.36
2025-02-13 19:19:11,613 [podnet.py] => Task 21, Epoch 157/160 (LR 0.00009) => LSC_loss 0.21, Spatial_loss 1.69, Flat_loss 0.13, Train_acc 96.21, Test_acc 50.38
2025-02-13 19:19:13,522 [podnet.py] => Task 21, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 1.78, Flat_loss 0.13, Train_acc 96.57, Test_acc 50.45
2025-02-13 19:19:15,221 [podnet.py] => Task 21, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.73, Flat_loss 0.13, Train_acc 96.29, Test_acc 50.20
2025-02-13 19:19:17,064 [podnet.py] => Task 21, Epoch 160/160 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.78, Flat_loss 0.13, Train_acc 96.64, Test_acc 50.08
2025-02-13 19:19:17,065 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:19:17,065 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:19:46,549 [podnet.py] => The size of finetune dataset: 1840
2025-02-13 19:19:48,090 [podnet.py] => Task 21, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 2.28, Flat_loss 0.14, Train_acc 98.26, Test_acc 49.49
2025-02-13 19:19:49,709 [podnet.py] => Task 21, Epoch 2/20 (LR 0.00488) => LSC_loss 0.12, Spatial_loss 2.02, Flat_loss 0.08, Train_acc 98.91, Test_acc 50.90
2025-02-13 19:19:51,277 [podnet.py] => Task 21, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 1.95, Flat_loss 0.08, Train_acc 98.97, Test_acc 51.22
2025-02-13 19:19:52,863 [podnet.py] => Task 21, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 1.89, Flat_loss 0.07, Train_acc 98.91, Test_acc 50.28
2025-02-13 19:19:54,508 [podnet.py] => Task 21, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 1.90, Flat_loss 0.07, Train_acc 98.86, Test_acc 50.62
2025-02-13 19:19:56,142 [podnet.py] => Task 21, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 1.95, Flat_loss 0.07, Train_acc 98.86, Test_acc 50.59
2025-02-13 19:19:57,741 [podnet.py] => Task 21, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 1.79, Flat_loss 0.07, Train_acc 98.75, Test_acc 50.87
2025-02-13 19:19:59,337 [podnet.py] => Task 21, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 1.89, Flat_loss 0.07, Train_acc 98.80, Test_acc 50.35
2025-02-13 19:20:00,890 [podnet.py] => Task 21, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 1.86, Flat_loss 0.07, Train_acc 99.29, Test_acc 51.08
2025-02-13 19:20:02,450 [podnet.py] => Task 21, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 1.99, Flat_loss 0.07, Train_acc 98.97, Test_acc 50.97
2025-02-13 19:20:04,095 [podnet.py] => Task 21, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 1.86, Flat_loss 0.07, Train_acc 99.29, Test_acc 50.91
2025-02-13 19:20:05,684 [podnet.py] => Task 21, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.83, Flat_loss 0.07, Train_acc 99.18, Test_acc 50.71
2025-02-13 19:20:07,205 [podnet.py] => Task 21, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 1.75, Flat_loss 0.07, Train_acc 98.97, Test_acc 50.80
2025-02-13 19:20:08,804 [podnet.py] => Task 21, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 1.80, Flat_loss 0.06, Train_acc 98.86, Test_acc 50.85
2025-02-13 19:20:10,385 [podnet.py] => Task 21, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 1.84, Flat_loss 0.07, Train_acc 98.80, Test_acc 50.87
2025-02-13 19:20:11,956 [podnet.py] => Task 21, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 1.76, Flat_loss 0.06, Train_acc 99.02, Test_acc 50.78
2025-02-13 19:20:13,567 [podnet.py] => Task 21, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.91, Test_acc 51.11
2025-02-13 19:20:15,193 [podnet.py] => Task 21, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 98.80, Test_acc 50.90
2025-02-13 19:20:16,826 [podnet.py] => Task 21, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 1.74, Flat_loss 0.07, Train_acc 99.13, Test_acc 50.84
2025-02-13 19:20:18,349 [podnet.py] => Task 21, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 1.73, Flat_loss 0.06, Train_acc 99.02, Test_acc 50.72
2025-02-13 19:20:18,350 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:20:49,092 [podnet.py] => Exemplar size: 1840
2025-02-13 19:20:49,092 [trainer.py] => CNN: {'total': 50.72, '00-09': 60.1, '10-19': 39.3, '20-29': 59.0, '30-39': 49.0, '40-49': 55.3, '50-59': 34.8, '60-69': 47.4, '70-79': 53.1, '80-89': 55.2, '90-99': 67.0, 'old': 50.36, 'new': 67.0}
2025-02-13 19:20:49,092 [trainer.py] => NME: {'total': 51.04, '00-09': 63.1, '10-19': 42.2, '20-29': 60.9, '30-39': 51.9, '40-49': 55.6, '50-59': 31.0, '60-69': 46.2, '70-79': 53.6, '80-89': 52.0, '90-99': 65.5, 'old': 50.72, 'new': 65.5}
2025-02-13 19:20:49,092 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29, 50.72]
2025-02-13 19:20:49,092 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13, 77.38]
2025-02-13 19:20:49,092 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26, 51.04]
2025-02-13 19:20:49,092 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44, 77.97]

2025-02-13 19:20:49,092 [trainer.py] => Average Accuracy (CNN): 61.94454545454544
2025-02-13 19:20:49,092 [trainer.py] => Average Accuracy (NME): 62.13999999999999
2025-02-13 19:20:49,093 [trainer.py] => All params: 525137
2025-02-13 19:20:49,093 [trainer.py] => Trainable params: 525137
2025-02-13 19:20:49,094 [podnet.py] => Learning on 92-94
2025-02-13 19:20:49,117 [podnet.py] => Adaptive factor: 6.855654600401044
2025-02-13 19:20:50,964 [podnet.py] => Task 22, Epoch 1/160 (LR 0.09999) => LSC_loss 1.35, Spatial_loss 5.40, Flat_loss 0.74, Train_acc 75.35, Test_acc 33.22
2025-02-13 19:20:52,714 [podnet.py] => Task 22, Epoch 2/160 (LR 0.09996) => LSC_loss 0.75, Spatial_loss 6.67, Flat_loss 0.88, Train_acc 78.94, Test_acc 38.57
2025-02-13 19:20:54,622 [podnet.py] => Task 22, Epoch 3/160 (LR 0.09991) => LSC_loss 0.79, Spatial_loss 6.88, Flat_loss 0.92, Train_acc 78.42, Test_acc 40.06
2025-02-13 19:20:56,419 [podnet.py] => Task 22, Epoch 4/160 (LR 0.09985) => LSC_loss 0.70, Spatial_loss 6.61, Flat_loss 0.82, Train_acc 81.13, Test_acc 39.63
2025-02-13 19:20:58,256 [podnet.py] => Task 22, Epoch 5/160 (LR 0.09976) => LSC_loss 0.65, Spatial_loss 6.46, Flat_loss 0.76, Train_acc 82.08, Test_acc 41.04
2025-02-13 19:21:00,124 [podnet.py] => Task 22, Epoch 6/160 (LR 0.09965) => LSC_loss 0.58, Spatial_loss 6.01, Flat_loss 0.67, Train_acc 84.15, Test_acc 37.56
2025-02-13 19:21:01,945 [podnet.py] => Task 22, Epoch 7/160 (LR 0.09953) => LSC_loss 0.53, Spatial_loss 5.72, Flat_loss 0.61, Train_acc 86.34, Test_acc 41.09
2025-02-13 19:21:03,828 [podnet.py] => Task 22, Epoch 8/160 (LR 0.09938) => LSC_loss 0.54, Spatial_loss 5.86, Flat_loss 0.61, Train_acc 86.20, Test_acc 43.16
2025-02-13 19:21:05,708 [podnet.py] => Task 22, Epoch 9/160 (LR 0.09922) => LSC_loss 0.50, Spatial_loss 5.68, Flat_loss 0.58, Train_acc 87.11, Test_acc 39.70
2025-02-13 19:21:07,622 [podnet.py] => Task 22, Epoch 10/160 (LR 0.09904) => LSC_loss 0.49, Spatial_loss 5.56, Flat_loss 0.54, Train_acc 87.96, Test_acc 38.46
2025-02-13 19:21:09,437 [podnet.py] => Task 22, Epoch 11/160 (LR 0.09884) => LSC_loss 0.47, Spatial_loss 5.52, Flat_loss 0.54, Train_acc 88.35, Test_acc 40.76
2025-02-13 19:21:11,310 [podnet.py] => Task 22, Epoch 12/160 (LR 0.09862) => LSC_loss 0.48, Spatial_loss 5.21, Flat_loss 0.51, Train_acc 88.10, Test_acc 43.88
2025-02-13 19:21:13,103 [podnet.py] => Task 22, Epoch 13/160 (LR 0.09838) => LSC_loss 0.47, Spatial_loss 5.32, Flat_loss 0.52, Train_acc 87.96, Test_acc 43.56
2025-02-13 19:21:15,037 [podnet.py] => Task 22, Epoch 14/160 (LR 0.09812) => LSC_loss 0.47, Spatial_loss 5.24, Flat_loss 0.52, Train_acc 88.27, Test_acc 42.31
2025-02-13 19:21:16,884 [podnet.py] => Task 22, Epoch 15/160 (LR 0.09785) => LSC_loss 0.45, Spatial_loss 5.21, Flat_loss 0.49, Train_acc 88.94, Test_acc 43.67
2025-02-13 19:21:18,714 [podnet.py] => Task 22, Epoch 16/160 (LR 0.09755) => LSC_loss 0.46, Spatial_loss 5.27, Flat_loss 0.49, Train_acc 88.45, Test_acc 43.46
2025-02-13 19:21:20,581 [podnet.py] => Task 22, Epoch 17/160 (LR 0.09724) => LSC_loss 0.43, Spatial_loss 5.05, Flat_loss 0.48, Train_acc 89.61, Test_acc 40.66
2025-02-13 19:21:22,470 [podnet.py] => Task 22, Epoch 18/160 (LR 0.09691) => LSC_loss 0.43, Spatial_loss 5.32, Flat_loss 0.49, Train_acc 89.12, Test_acc 44.56
2025-02-13 19:21:24,318 [podnet.py] => Task 22, Epoch 19/160 (LR 0.09656) => LSC_loss 0.42, Spatial_loss 5.05, Flat_loss 0.46, Train_acc 89.79, Test_acc 44.57
2025-02-13 19:21:26,147 [podnet.py] => Task 22, Epoch 20/160 (LR 0.09619) => LSC_loss 0.43, Spatial_loss 5.12, Flat_loss 0.46, Train_acc 89.19, Test_acc 44.06
2025-02-13 19:21:27,943 [podnet.py] => Task 22, Epoch 21/160 (LR 0.09581) => LSC_loss 0.40, Spatial_loss 5.06, Flat_loss 0.45, Train_acc 90.42, Test_acc 39.72
2025-02-13 19:21:29,842 [podnet.py] => Task 22, Epoch 22/160 (LR 0.09541) => LSC_loss 0.41, Spatial_loss 4.92, Flat_loss 0.44, Train_acc 90.04, Test_acc 37.59
2025-02-13 19:21:31,709 [podnet.py] => Task 22, Epoch 23/160 (LR 0.09499) => LSC_loss 0.38, Spatial_loss 4.90, Flat_loss 0.44, Train_acc 91.34, Test_acc 43.97
2025-02-13 19:21:33,549 [podnet.py] => Task 22, Epoch 24/160 (LR 0.09455) => LSC_loss 0.44, Spatial_loss 5.12, Flat_loss 0.45, Train_acc 89.47, Test_acc 42.09
2025-02-13 19:21:35,357 [podnet.py] => Task 22, Epoch 25/160 (LR 0.09410) => LSC_loss 0.42, Spatial_loss 5.14, Flat_loss 0.46, Train_acc 90.18, Test_acc 44.49
2025-02-13 19:21:37,243 [podnet.py] => Task 22, Epoch 26/160 (LR 0.09362) => LSC_loss 0.40, Spatial_loss 4.87, Flat_loss 0.45, Train_acc 90.60, Test_acc 44.22
2025-02-13 19:21:39,065 [podnet.py] => Task 22, Epoch 27/160 (LR 0.09314) => LSC_loss 0.41, Spatial_loss 4.79, Flat_loss 0.44, Train_acc 90.46, Test_acc 44.11
2025-02-13 19:21:40,892 [podnet.py] => Task 22, Epoch 28/160 (LR 0.09263) => LSC_loss 0.42, Spatial_loss 4.82, Flat_loss 0.44, Train_acc 89.68, Test_acc 43.73
2025-02-13 19:21:42,761 [podnet.py] => Task 22, Epoch 29/160 (LR 0.09211) => LSC_loss 0.39, Spatial_loss 4.83, Flat_loss 0.44, Train_acc 91.02, Test_acc 43.19
2025-02-13 19:21:44,554 [podnet.py] => Task 22, Epoch 30/160 (LR 0.09157) => LSC_loss 0.39, Spatial_loss 4.88, Flat_loss 0.43, Train_acc 91.09, Test_acc 42.06
2025-02-13 19:21:46,401 [podnet.py] => Task 22, Epoch 31/160 (LR 0.09102) => LSC_loss 0.36, Spatial_loss 4.48, Flat_loss 0.40, Train_acc 92.36, Test_acc 40.40
2025-02-13 19:21:48,273 [podnet.py] => Task 22, Epoch 32/160 (LR 0.09045) => LSC_loss 0.43, Spatial_loss 5.03, Flat_loss 0.44, Train_acc 89.40, Test_acc 37.20
2025-02-13 19:21:50,120 [podnet.py] => Task 22, Epoch 33/160 (LR 0.08987) => LSC_loss 0.38, Spatial_loss 4.80, Flat_loss 0.44, Train_acc 91.27, Test_acc 41.95
2025-02-13 19:21:51,974 [podnet.py] => Task 22, Epoch 34/160 (LR 0.08927) => LSC_loss 0.37, Spatial_loss 4.73, Flat_loss 0.41, Train_acc 91.62, Test_acc 42.22
2025-02-13 19:21:53,784 [podnet.py] => Task 22, Epoch 35/160 (LR 0.08865) => LSC_loss 0.39, Spatial_loss 4.73, Flat_loss 0.42, Train_acc 90.88, Test_acc 44.35
2025-02-13 19:21:55,635 [podnet.py] => Task 22, Epoch 36/160 (LR 0.08802) => LSC_loss 0.36, Spatial_loss 4.60, Flat_loss 0.41, Train_acc 92.04, Test_acc 45.63
2025-02-13 19:21:57,425 [podnet.py] => Task 22, Epoch 37/160 (LR 0.08738) => LSC_loss 0.37, Spatial_loss 4.53, Flat_loss 0.39, Train_acc 91.80, Test_acc 42.90
2025-02-13 19:21:59,284 [podnet.py] => Task 22, Epoch 38/160 (LR 0.08672) => LSC_loss 0.39, Spatial_loss 4.59, Flat_loss 0.42, Train_acc 90.77, Test_acc 41.73
2025-02-13 19:22:01,095 [podnet.py] => Task 22, Epoch 39/160 (LR 0.08604) => LSC_loss 0.41, Spatial_loss 4.68, Flat_loss 0.42, Train_acc 90.35, Test_acc 46.39
2025-02-13 19:22:02,972 [podnet.py] => Task 22, Epoch 40/160 (LR 0.08536) => LSC_loss 0.39, Spatial_loss 4.68, Flat_loss 0.42, Train_acc 90.39, Test_acc 42.14
2025-02-13 19:22:04,794 [podnet.py] => Task 22, Epoch 41/160 (LR 0.08465) => LSC_loss 0.37, Spatial_loss 4.65, Flat_loss 0.40, Train_acc 91.41, Test_acc 44.07
2025-02-13 19:22:06,605 [podnet.py] => Task 22, Epoch 42/160 (LR 0.08394) => LSC_loss 0.36, Spatial_loss 4.58, Flat_loss 0.39, Train_acc 92.04, Test_acc 44.34
2025-02-13 19:22:08,509 [podnet.py] => Task 22, Epoch 43/160 (LR 0.08321) => LSC_loss 0.38, Spatial_loss 4.53, Flat_loss 0.39, Train_acc 91.02, Test_acc 42.31
2025-02-13 19:22:10,360 [podnet.py] => Task 22, Epoch 44/160 (LR 0.08247) => LSC_loss 0.40, Spatial_loss 4.83, Flat_loss 0.44, Train_acc 91.30, Test_acc 46.53
2025-02-13 19:22:12,222 [podnet.py] => Task 22, Epoch 45/160 (LR 0.08172) => LSC_loss 0.38, Spatial_loss 4.70, Flat_loss 0.42, Train_acc 91.34, Test_acc 40.02
2025-02-13 19:22:14,104 [podnet.py] => Task 22, Epoch 46/160 (LR 0.08095) => LSC_loss 0.37, Spatial_loss 4.75, Flat_loss 0.42, Train_acc 92.11, Test_acc 44.68
2025-02-13 19:22:15,963 [podnet.py] => Task 22, Epoch 47/160 (LR 0.08018) => LSC_loss 0.35, Spatial_loss 4.44, Flat_loss 0.37, Train_acc 92.46, Test_acc 47.35
2025-02-13 19:22:17,771 [podnet.py] => Task 22, Epoch 48/160 (LR 0.07939) => LSC_loss 0.35, Spatial_loss 4.40, Flat_loss 0.37, Train_acc 92.61, Test_acc 41.98
2025-02-13 19:22:19,626 [podnet.py] => Task 22, Epoch 49/160 (LR 0.07859) => LSC_loss 0.36, Spatial_loss 4.38, Flat_loss 0.37, Train_acc 92.11, Test_acc 45.37
2025-02-13 19:22:21,512 [podnet.py] => Task 22, Epoch 50/160 (LR 0.07778) => LSC_loss 0.33, Spatial_loss 4.32, Flat_loss 0.37, Train_acc 93.20, Test_acc 45.38
2025-02-13 19:22:23,333 [podnet.py] => Task 22, Epoch 51/160 (LR 0.07696) => LSC_loss 0.36, Spatial_loss 4.36, Flat_loss 0.37, Train_acc 92.39, Test_acc 46.34
2025-02-13 19:22:25,219 [podnet.py] => Task 22, Epoch 52/160 (LR 0.07612) => LSC_loss 0.32, Spatial_loss 4.21, Flat_loss 0.36, Train_acc 93.13, Test_acc 45.03
2025-02-13 19:22:27,033 [podnet.py] => Task 22, Epoch 53/160 (LR 0.07528) => LSC_loss 0.35, Spatial_loss 4.23, Flat_loss 0.36, Train_acc 92.32, Test_acc 43.32
2025-02-13 19:22:28,876 [podnet.py] => Task 22, Epoch 54/160 (LR 0.07443) => LSC_loss 0.35, Spatial_loss 4.22, Flat_loss 0.36, Train_acc 92.78, Test_acc 44.88
2025-02-13 19:22:30,747 [podnet.py] => Task 22, Epoch 55/160 (LR 0.07357) => LSC_loss 0.34, Spatial_loss 4.23, Flat_loss 0.36, Train_acc 92.57, Test_acc 45.34
2025-02-13 19:22:32,628 [podnet.py] => Task 22, Epoch 56/160 (LR 0.07270) => LSC_loss 0.33, Spatial_loss 4.08, Flat_loss 0.33, Train_acc 92.57, Test_acc 46.73
2025-02-13 19:22:34,504 [podnet.py] => Task 22, Epoch 57/160 (LR 0.07182) => LSC_loss 0.33, Spatial_loss 4.18, Flat_loss 0.35, Train_acc 92.85, Test_acc 45.01
2025-02-13 19:22:36,391 [podnet.py] => Task 22, Epoch 58/160 (LR 0.07093) => LSC_loss 0.33, Spatial_loss 4.02, Flat_loss 0.33, Train_acc 92.89, Test_acc 48.43
2025-02-13 19:22:38,250 [podnet.py] => Task 22, Epoch 59/160 (LR 0.07004) => LSC_loss 0.33, Spatial_loss 4.14, Flat_loss 0.33, Train_acc 92.96, Test_acc 45.99
2025-02-13 19:22:40,101 [podnet.py] => Task 22, Epoch 60/160 (LR 0.06913) => LSC_loss 0.33, Spatial_loss 4.23, Flat_loss 0.34, Train_acc 91.90, Test_acc 41.35
2025-02-13 19:22:42,031 [podnet.py] => Task 22, Epoch 61/160 (LR 0.06822) => LSC_loss 0.33, Spatial_loss 4.20, Flat_loss 0.34, Train_acc 92.82, Test_acc 45.20
2025-02-13 19:22:43,882 [podnet.py] => Task 22, Epoch 62/160 (LR 0.06731) => LSC_loss 0.33, Spatial_loss 4.05, Flat_loss 0.32, Train_acc 93.31, Test_acc 40.31
2025-02-13 19:22:45,710 [podnet.py] => Task 22, Epoch 63/160 (LR 0.06638) => LSC_loss 0.34, Spatial_loss 4.22, Flat_loss 0.34, Train_acc 92.11, Test_acc 38.98
2025-02-13 19:22:47,543 [podnet.py] => Task 22, Epoch 64/160 (LR 0.06545) => LSC_loss 0.32, Spatial_loss 4.03, Flat_loss 0.32, Train_acc 93.20, Test_acc 44.09
2025-02-13 19:22:49,388 [podnet.py] => Task 22, Epoch 65/160 (LR 0.06451) => LSC_loss 0.32, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 92.99, Test_acc 43.89
2025-02-13 19:22:51,236 [podnet.py] => Task 22, Epoch 66/160 (LR 0.06357) => LSC_loss 0.33, Spatial_loss 3.95, Flat_loss 0.30, Train_acc 92.32, Test_acc 45.94
2025-02-13 19:22:53,155 [podnet.py] => Task 22, Epoch 67/160 (LR 0.06262) => LSC_loss 0.31, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 92.99, Test_acc 45.57
2025-02-13 19:22:54,977 [podnet.py] => Task 22, Epoch 68/160 (LR 0.06167) => LSC_loss 0.32, Spatial_loss 3.98, Flat_loss 0.32, Train_acc 93.38, Test_acc 41.82
2025-02-13 19:22:56,872 [podnet.py] => Task 22, Epoch 69/160 (LR 0.06072) => LSC_loss 0.32, Spatial_loss 3.82, Flat_loss 0.30, Train_acc 93.63, Test_acc 45.84
2025-02-13 19:22:58,735 [podnet.py] => Task 22, Epoch 70/160 (LR 0.05975) => LSC_loss 0.33, Spatial_loss 3.92, Flat_loss 0.31, Train_acc 92.89, Test_acc 47.65
2025-02-13 19:23:00,608 [podnet.py] => Task 22, Epoch 71/160 (LR 0.05879) => LSC_loss 0.33, Spatial_loss 3.83, Flat_loss 0.30, Train_acc 92.85, Test_acc 46.96
2025-02-13 19:23:02,476 [podnet.py] => Task 22, Epoch 72/160 (LR 0.05782) => LSC_loss 0.32, Spatial_loss 3.76, Flat_loss 0.30, Train_acc 93.38, Test_acc 43.82
2025-02-13 19:23:04,287 [podnet.py] => Task 22, Epoch 73/160 (LR 0.05685) => LSC_loss 0.31, Spatial_loss 4.05, Flat_loss 0.33, Train_acc 93.31, Test_acc 44.93
2025-02-13 19:23:06,111 [podnet.py] => Task 22, Epoch 74/160 (LR 0.05588) => LSC_loss 0.33, Spatial_loss 4.09, Flat_loss 0.32, Train_acc 92.75, Test_acc 44.31
2025-02-13 19:23:08,026 [podnet.py] => Task 22, Epoch 75/160 (LR 0.05490) => LSC_loss 0.30, Spatial_loss 3.76, Flat_loss 0.29, Train_acc 93.77, Test_acc 48.03
2025-02-13 19:23:09,923 [podnet.py] => Task 22, Epoch 76/160 (LR 0.05392) => LSC_loss 0.31, Spatial_loss 3.66, Flat_loss 0.28, Train_acc 93.52, Test_acc 48.76
2025-02-13 19:23:11,796 [podnet.py] => Task 22, Epoch 77/160 (LR 0.05294) => LSC_loss 0.32, Spatial_loss 3.69, Flat_loss 0.29, Train_acc 92.54, Test_acc 42.39
2025-02-13 19:23:13,594 [podnet.py] => Task 22, Epoch 78/160 (LR 0.05196) => LSC_loss 0.31, Spatial_loss 3.90, Flat_loss 0.29, Train_acc 93.20, Test_acc 46.64
2025-02-13 19:23:15,368 [podnet.py] => Task 22, Epoch 79/160 (LR 0.05098) => LSC_loss 0.30, Spatial_loss 3.67, Flat_loss 0.28, Train_acc 94.05, Test_acc 44.78
2025-02-13 19:23:17,218 [podnet.py] => Task 22, Epoch 80/160 (LR 0.05000) => LSC_loss 0.32, Spatial_loss 3.69, Flat_loss 0.28, Train_acc 93.20, Test_acc 48.23
2025-02-13 19:23:19,045 [podnet.py] => Task 22, Epoch 81/160 (LR 0.04902) => LSC_loss 0.29, Spatial_loss 3.52, Flat_loss 0.26, Train_acc 93.77, Test_acc 49.35
2025-02-13 19:23:20,906 [podnet.py] => Task 22, Epoch 82/160 (LR 0.04804) => LSC_loss 0.29, Spatial_loss 3.61, Flat_loss 0.26, Train_acc 94.37, Test_acc 48.72
2025-02-13 19:23:22,727 [podnet.py] => Task 22, Epoch 83/160 (LR 0.04706) => LSC_loss 0.33, Spatial_loss 3.54, Flat_loss 0.26, Train_acc 93.42, Test_acc 42.50
2025-02-13 19:23:24,622 [podnet.py] => Task 22, Epoch 84/160 (LR 0.04608) => LSC_loss 0.32, Spatial_loss 3.70, Flat_loss 0.28, Train_acc 92.75, Test_acc 45.18
2025-02-13 19:23:26,472 [podnet.py] => Task 22, Epoch 85/160 (LR 0.04510) => LSC_loss 0.31, Spatial_loss 3.55, Flat_loss 0.27, Train_acc 93.42, Test_acc 45.76
2025-02-13 19:23:28,322 [podnet.py] => Task 22, Epoch 86/160 (LR 0.04412) => LSC_loss 0.32, Spatial_loss 3.67, Flat_loss 0.28, Train_acc 93.63, Test_acc 48.44
2025-02-13 19:23:30,124 [podnet.py] => Task 22, Epoch 87/160 (LR 0.04315) => LSC_loss 0.31, Spatial_loss 3.71, Flat_loss 0.28, Train_acc 93.59, Test_acc 45.45
2025-02-13 19:23:31,954 [podnet.py] => Task 22, Epoch 88/160 (LR 0.04218) => LSC_loss 0.31, Spatial_loss 3.46, Flat_loss 0.27, Train_acc 93.42, Test_acc 47.53
2025-02-13 19:23:33,796 [podnet.py] => Task 22, Epoch 89/160 (LR 0.04121) => LSC_loss 0.31, Spatial_loss 3.49, Flat_loss 0.27, Train_acc 93.03, Test_acc 46.34
2025-02-13 19:23:35,628 [podnet.py] => Task 22, Epoch 90/160 (LR 0.04025) => LSC_loss 0.29, Spatial_loss 3.46, Flat_loss 0.27, Train_acc 93.98, Test_acc 50.09
2025-02-13 19:23:37,496 [podnet.py] => Task 22, Epoch 91/160 (LR 0.03928) => LSC_loss 0.30, Spatial_loss 3.53, Flat_loss 0.26, Train_acc 93.42, Test_acc 45.83
2025-02-13 19:23:39,397 [podnet.py] => Task 22, Epoch 92/160 (LR 0.03833) => LSC_loss 0.32, Spatial_loss 3.43, Flat_loss 0.25, Train_acc 92.43, Test_acc 43.63
2025-02-13 19:23:41,213 [podnet.py] => Task 22, Epoch 93/160 (LR 0.03738) => LSC_loss 0.31, Spatial_loss 3.41, Flat_loss 0.26, Train_acc 92.99, Test_acc 47.57
2025-02-13 19:23:43,043 [podnet.py] => Task 22, Epoch 94/160 (LR 0.03643) => LSC_loss 0.30, Spatial_loss 3.31, Flat_loss 0.24, Train_acc 93.56, Test_acc 47.85
2025-02-13 19:23:44,899 [podnet.py] => Task 22, Epoch 95/160 (LR 0.03549) => LSC_loss 0.29, Spatial_loss 3.19, Flat_loss 0.23, Train_acc 94.47, Test_acc 46.43
2025-02-13 19:23:46,741 [podnet.py] => Task 22, Epoch 96/160 (LR 0.03455) => LSC_loss 0.31, Spatial_loss 3.29, Flat_loss 0.24, Train_acc 93.31, Test_acc 48.21
2025-02-13 19:23:48,595 [podnet.py] => Task 22, Epoch 97/160 (LR 0.03362) => LSC_loss 0.30, Spatial_loss 3.35, Flat_loss 0.24, Train_acc 94.01, Test_acc 45.86
2025-02-13 19:23:50,447 [podnet.py] => Task 22, Epoch 98/160 (LR 0.03269) => LSC_loss 0.29, Spatial_loss 3.11, Flat_loss 0.22, Train_acc 93.94, Test_acc 47.72
2025-02-13 19:23:52,338 [podnet.py] => Task 22, Epoch 99/160 (LR 0.03178) => LSC_loss 0.29, Spatial_loss 3.05, Flat_loss 0.22, Train_acc 94.33, Test_acc 48.80
2025-02-13 19:23:54,239 [podnet.py] => Task 22, Epoch 100/160 (LR 0.03087) => LSC_loss 0.28, Spatial_loss 3.12, Flat_loss 0.23, Train_acc 95.00, Test_acc 46.48
2025-02-13 19:23:56,026 [podnet.py] => Task 22, Epoch 101/160 (LR 0.02996) => LSC_loss 0.28, Spatial_loss 3.06, Flat_loss 0.22, Train_acc 94.26, Test_acc 47.60
2025-02-13 19:23:57,916 [podnet.py] => Task 22, Epoch 102/160 (LR 0.02907) => LSC_loss 0.29, Spatial_loss 3.09, Flat_loss 0.21, Train_acc 94.08, Test_acc 44.33
2025-02-13 19:23:59,785 [podnet.py] => Task 22, Epoch 103/160 (LR 0.02818) => LSC_loss 0.28, Spatial_loss 3.06, Flat_loss 0.22, Train_acc 93.91, Test_acc 48.20
2025-02-13 19:24:01,622 [podnet.py] => Task 22, Epoch 104/160 (LR 0.02730) => LSC_loss 0.28, Spatial_loss 2.97, Flat_loss 0.21, Train_acc 94.23, Test_acc 48.24
2025-02-13 19:24:03,514 [podnet.py] => Task 22, Epoch 105/160 (LR 0.02643) => LSC_loss 0.29, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 94.15, Test_acc 48.33
2025-02-13 19:24:05,345 [podnet.py] => Task 22, Epoch 106/160 (LR 0.02557) => LSC_loss 0.30, Spatial_loss 3.00, Flat_loss 0.21, Train_acc 93.45, Test_acc 46.62
2025-02-13 19:24:07,212 [podnet.py] => Task 22, Epoch 107/160 (LR 0.02472) => LSC_loss 0.29, Spatial_loss 3.19, Flat_loss 0.22, Train_acc 94.01, Test_acc 47.60
2025-02-13 19:24:09,096 [podnet.py] => Task 22, Epoch 108/160 (LR 0.02388) => LSC_loss 0.27, Spatial_loss 2.94, Flat_loss 0.21, Train_acc 95.04, Test_acc 49.17
2025-02-13 19:24:10,910 [podnet.py] => Task 22, Epoch 109/160 (LR 0.02304) => LSC_loss 0.30, Spatial_loss 2.83, Flat_loss 0.19, Train_acc 93.27, Test_acc 47.83
2025-02-13 19:24:12,742 [podnet.py] => Task 22, Epoch 110/160 (LR 0.02222) => LSC_loss 0.29, Spatial_loss 2.80, Flat_loss 0.19, Train_acc 93.91, Test_acc 45.86
2025-02-13 19:24:14,605 [podnet.py] => Task 22, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 2.70, Flat_loss 0.19, Train_acc 93.66, Test_acc 48.10
2025-02-13 19:24:16,470 [podnet.py] => Task 22, Epoch 112/160 (LR 0.02061) => LSC_loss 0.30, Spatial_loss 2.75, Flat_loss 0.19, Train_acc 93.70, Test_acc 45.41
2025-02-13 19:24:18,377 [podnet.py] => Task 22, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 2.80, Flat_loss 0.20, Train_acc 94.68, Test_acc 48.55
2025-02-13 19:24:20,177 [podnet.py] => Task 22, Epoch 114/160 (LR 0.01905) => LSC_loss 0.29, Spatial_loss 2.79, Flat_loss 0.18, Train_acc 93.84, Test_acc 47.19
2025-02-13 19:24:22,021 [podnet.py] => Task 22, Epoch 115/160 (LR 0.01828) => LSC_loss 0.31, Spatial_loss 2.79, Flat_loss 0.19, Train_acc 93.63, Test_acc 48.83
2025-02-13 19:24:23,926 [podnet.py] => Task 22, Epoch 116/160 (LR 0.01753) => LSC_loss 0.28, Spatial_loss 2.65, Flat_loss 0.19, Train_acc 94.61, Test_acc 49.23
2025-02-13 19:24:25,789 [podnet.py] => Task 22, Epoch 117/160 (LR 0.01679) => LSC_loss 0.27, Spatial_loss 2.62, Flat_loss 0.18, Train_acc 94.93, Test_acc 48.82
2025-02-13 19:24:27,695 [podnet.py] => Task 22, Epoch 118/160 (LR 0.01606) => LSC_loss 0.29, Spatial_loss 2.73, Flat_loss 0.18, Train_acc 93.27, Test_acc 48.68
2025-02-13 19:24:29,515 [podnet.py] => Task 22, Epoch 119/160 (LR 0.01535) => LSC_loss 0.29, Spatial_loss 2.61, Flat_loss 0.18, Train_acc 93.91, Test_acc 46.87
2025-02-13 19:24:31,280 [podnet.py] => Task 22, Epoch 120/160 (LR 0.01464) => LSC_loss 0.29, Spatial_loss 2.63, Flat_loss 0.18, Train_acc 94.01, Test_acc 48.03
2025-02-13 19:24:33,153 [podnet.py] => Task 22, Epoch 121/160 (LR 0.01396) => LSC_loss 0.29, Spatial_loss 2.51, Flat_loss 0.17, Train_acc 94.44, Test_acc 49.34
2025-02-13 19:24:34,982 [podnet.py] => Task 22, Epoch 122/160 (LR 0.01328) => LSC_loss 0.29, Spatial_loss 2.59, Flat_loss 0.18, Train_acc 94.08, Test_acc 47.11
2025-02-13 19:24:36,855 [podnet.py] => Task 22, Epoch 123/160 (LR 0.01262) => LSC_loss 0.28, Spatial_loss 2.46, Flat_loss 0.17, Train_acc 94.75, Test_acc 49.63
2025-02-13 19:24:38,739 [podnet.py] => Task 22, Epoch 124/160 (LR 0.01198) => LSC_loss 0.30, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 93.63, Test_acc 48.30
2025-02-13 19:24:40,571 [podnet.py] => Task 22, Epoch 125/160 (LR 0.01135) => LSC_loss 0.29, Spatial_loss 2.47, Flat_loss 0.17, Train_acc 93.77, Test_acc 46.90
2025-02-13 19:24:42,468 [podnet.py] => Task 22, Epoch 126/160 (LR 0.01073) => LSC_loss 0.28, Spatial_loss 2.48, Flat_loss 0.17, Train_acc 94.54, Test_acc 47.37
2025-02-13 19:24:44,310 [podnet.py] => Task 22, Epoch 127/160 (LR 0.01013) => LSC_loss 0.29, Spatial_loss 2.36, Flat_loss 0.16, Train_acc 94.61, Test_acc 49.91
2025-02-13 19:24:46,147 [podnet.py] => Task 22, Epoch 128/160 (LR 0.00955) => LSC_loss 0.29, Spatial_loss 2.43, Flat_loss 0.16, Train_acc 93.42, Test_acc 48.63
2025-02-13 19:24:48,005 [podnet.py] => Task 22, Epoch 129/160 (LR 0.00898) => LSC_loss 0.28, Spatial_loss 2.32, Flat_loss 0.16, Train_acc 94.15, Test_acc 49.03
2025-02-13 19:24:49,851 [podnet.py] => Task 22, Epoch 130/160 (LR 0.00843) => LSC_loss 0.27, Spatial_loss 2.30, Flat_loss 0.15, Train_acc 94.37, Test_acc 48.91
2025-02-13 19:24:51,686 [podnet.py] => Task 22, Epoch 131/160 (LR 0.00789) => LSC_loss 0.28, Spatial_loss 2.29, Flat_loss 0.16, Train_acc 94.44, Test_acc 49.53
2025-02-13 19:24:53,554 [podnet.py] => Task 22, Epoch 132/160 (LR 0.00737) => LSC_loss 0.29, Spatial_loss 2.41, Flat_loss 0.17, Train_acc 94.19, Test_acc 48.13
2025-02-13 19:24:55,427 [podnet.py] => Task 22, Epoch 133/160 (LR 0.00686) => LSC_loss 0.29, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 93.70, Test_acc 48.07
2025-02-13 19:24:57,290 [podnet.py] => Task 22, Epoch 134/160 (LR 0.00638) => LSC_loss 0.28, Spatial_loss 2.34, Flat_loss 0.16, Train_acc 94.54, Test_acc 47.51
2025-02-13 19:24:59,132 [podnet.py] => Task 22, Epoch 135/160 (LR 0.00590) => LSC_loss 0.28, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 94.72, Test_acc 49.09
2025-02-13 19:25:00,983 [podnet.py] => Task 22, Epoch 136/160 (LR 0.00545) => LSC_loss 0.28, Spatial_loss 2.19, Flat_loss 0.15, Train_acc 94.40, Test_acc 48.28
2025-02-13 19:25:02,924 [podnet.py] => Task 22, Epoch 137/160 (LR 0.00501) => LSC_loss 0.28, Spatial_loss 2.30, Flat_loss 0.15, Train_acc 94.51, Test_acc 48.26
2025-02-13 19:25:04,767 [podnet.py] => Task 22, Epoch 138/160 (LR 0.00459) => LSC_loss 0.28, Spatial_loss 2.16, Flat_loss 0.15, Train_acc 94.01, Test_acc 48.51
2025-02-13 19:25:06,663 [podnet.py] => Task 22, Epoch 139/160 (LR 0.00419) => LSC_loss 0.29, Spatial_loss 2.26, Flat_loss 0.15, Train_acc 93.94, Test_acc 48.27
2025-02-13 19:25:08,525 [podnet.py] => Task 22, Epoch 140/160 (LR 0.00381) => LSC_loss 0.29, Spatial_loss 2.28, Flat_loss 0.15, Train_acc 93.49, Test_acc 48.94
2025-02-13 19:25:10,375 [podnet.py] => Task 22, Epoch 141/160 (LR 0.00344) => LSC_loss 0.29, Spatial_loss 2.24, Flat_loss 0.15, Train_acc 94.40, Test_acc 48.54
2025-02-13 19:25:12,219 [podnet.py] => Task 22, Epoch 142/160 (LR 0.00309) => LSC_loss 0.29, Spatial_loss 2.19, Flat_loss 0.14, Train_acc 94.37, Test_acc 48.98
2025-02-13 19:25:14,066 [podnet.py] => Task 22, Epoch 143/160 (LR 0.00276) => LSC_loss 0.29, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 94.12, Test_acc 48.99
2025-02-13 19:25:15,925 [podnet.py] => Task 22, Epoch 144/160 (LR 0.00245) => LSC_loss 0.28, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 94.19, Test_acc 48.78
2025-02-13 19:25:17,803 [podnet.py] => Task 22, Epoch 145/160 (LR 0.00215) => LSC_loss 0.29, Spatial_loss 2.19, Flat_loss 0.14, Train_acc 93.77, Test_acc 49.10
2025-02-13 19:25:19,652 [podnet.py] => Task 22, Epoch 146/160 (LR 0.00188) => LSC_loss 0.28, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 94.05, Test_acc 48.71
2025-02-13 19:25:21,518 [podnet.py] => Task 22, Epoch 147/160 (LR 0.00162) => LSC_loss 0.28, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 94.54, Test_acc 49.40
2025-02-13 19:25:23,328 [podnet.py] => Task 22, Epoch 148/160 (LR 0.00138) => LSC_loss 0.28, Spatial_loss 2.12, Flat_loss 0.15, Train_acc 94.51, Test_acc 48.74
2025-02-13 19:25:25,213 [podnet.py] => Task 22, Epoch 149/160 (LR 0.00116) => LSC_loss 0.28, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 94.47, Test_acc 48.37
2025-02-13 19:25:27,075 [podnet.py] => Task 22, Epoch 150/160 (LR 0.00096) => LSC_loss 0.28, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 94.08, Test_acc 48.76
2025-02-13 19:25:28,928 [podnet.py] => Task 22, Epoch 151/160 (LR 0.00078) => LSC_loss 0.28, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 94.30, Test_acc 49.27
2025-02-13 19:25:30,769 [podnet.py] => Task 22, Epoch 152/160 (LR 0.00062) => LSC_loss 0.29, Spatial_loss 2.00, Flat_loss 0.13, Train_acc 93.77, Test_acc 48.63
2025-02-13 19:25:32,584 [podnet.py] => Task 22, Epoch 153/160 (LR 0.00047) => LSC_loss 0.29, Spatial_loss 2.11, Flat_loss 0.14, Train_acc 94.65, Test_acc 48.82
2025-02-13 19:25:34,500 [podnet.py] => Task 22, Epoch 154/160 (LR 0.00035) => LSC_loss 0.28, Spatial_loss 2.06, Flat_loss 0.14, Train_acc 94.40, Test_acc 48.88
2025-02-13 19:25:36,390 [podnet.py] => Task 22, Epoch 155/160 (LR 0.00024) => LSC_loss 0.29, Spatial_loss 2.05, Flat_loss 0.14, Train_acc 94.19, Test_acc 49.16
2025-02-13 19:25:38,214 [podnet.py] => Task 22, Epoch 156/160 (LR 0.00015) => LSC_loss 0.28, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 94.47, Test_acc 48.84
2025-02-13 19:25:40,041 [podnet.py] => Task 22, Epoch 157/160 (LR 0.00009) => LSC_loss 0.28, Spatial_loss 2.02, Flat_loss 0.14, Train_acc 94.12, Test_acc 48.85
2025-02-13 19:25:41,849 [podnet.py] => Task 22, Epoch 158/160 (LR 0.00004) => LSC_loss 0.29, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 94.12, Test_acc 49.09
2025-02-13 19:25:43,719 [podnet.py] => Task 22, Epoch 159/160 (LR 0.00001) => LSC_loss 0.29, Spatial_loss 1.99, Flat_loss 0.14, Train_acc 94.08, Test_acc 48.85
2025-02-13 19:25:45,525 [podnet.py] => Task 22, Epoch 160/160 (LR 0.00000) => LSC_loss 0.28, Spatial_loss 1.94, Flat_loss 0.14, Train_acc 94.51, Test_acc 48.66
2025-02-13 19:25:45,526 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:25:45,526 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:26:14,991 [podnet.py] => The size of finetune dataset: 1880
2025-02-13 19:26:16,572 [podnet.py] => Task 22, Epoch 1/20 (LR 0.00497) => LSC_loss 0.19, Spatial_loss 2.98, Flat_loss 0.17, Train_acc 96.81, Test_acc 48.46
2025-02-13 19:26:18,214 [podnet.py] => Task 22, Epoch 2/20 (LR 0.00488) => LSC_loss 0.12, Spatial_loss 2.19, Flat_loss 0.09, Train_acc 98.51, Test_acc 49.81
2025-02-13 19:26:19,830 [podnet.py] => Task 22, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 2.02, Flat_loss 0.07, Train_acc 98.62, Test_acc 49.82
2025-02-13 19:26:21,482 [podnet.py] => Task 22, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 2.04, Flat_loss 0.08, Train_acc 98.94, Test_acc 50.51
2025-02-13 19:26:23,055 [podnet.py] => Task 22, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 2.03, Flat_loss 0.07, Train_acc 98.46, Test_acc 49.76
2025-02-13 19:26:24,630 [podnet.py] => Task 22, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 2.00, Flat_loss 0.07, Train_acc 98.51, Test_acc 49.81
2025-02-13 19:26:26,243 [podnet.py] => Task 22, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 2.02, Flat_loss 0.07, Train_acc 99.04, Test_acc 50.12
2025-02-13 19:26:27,850 [podnet.py] => Task 22, Epoch 8/20 (LR 0.00327) => LSC_loss 0.11, Spatial_loss 1.92, Flat_loss 0.07, Train_acc 98.67, Test_acc 49.77
2025-02-13 19:26:29,361 [podnet.py] => Task 22, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 1.86, Flat_loss 0.07, Train_acc 98.99, Test_acc 49.83
2025-02-13 19:26:30,992 [podnet.py] => Task 22, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.83, Test_acc 49.79
2025-02-13 19:26:32,616 [podnet.py] => Task 22, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 1.93, Flat_loss 0.07, Train_acc 98.67, Test_acc 49.86
2025-02-13 19:26:34,173 [podnet.py] => Task 22, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.83, Flat_loss 0.06, Train_acc 98.88, Test_acc 49.70
2025-02-13 19:26:35,737 [podnet.py] => Task 22, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 1.85, Flat_loss 0.06, Train_acc 98.35, Test_acc 49.79
2025-02-13 19:26:37,383 [podnet.py] => Task 22, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 99.04, Test_acc 49.68
2025-02-13 19:26:38,944 [podnet.py] => Task 22, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 1.86, Flat_loss 0.06, Train_acc 98.94, Test_acc 49.69
2025-02-13 19:26:40,557 [podnet.py] => Task 22, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 98.78, Test_acc 49.83
2025-02-13 19:26:42,218 [podnet.py] => Task 22, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 1.89, Flat_loss 0.06, Train_acc 98.99, Test_acc 49.76
2025-02-13 19:26:43,807 [podnet.py] => Task 22, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 99.04, Test_acc 49.95
2025-02-13 19:26:45,398 [podnet.py] => Task 22, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 1.79, Flat_loss 0.06, Train_acc 98.99, Test_acc 49.81
2025-02-13 19:26:47,007 [podnet.py] => Task 22, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 1.85, Flat_loss 0.06, Train_acc 98.83, Test_acc 49.73
2025-02-13 19:26:47,008 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:27:18,675 [podnet.py] => Exemplar size: 1880
2025-02-13 19:27:18,675 [trainer.py] => CNN: {'total': 49.73, '00-09': 58.6, '10-19': 38.6, '20-29': 57.4, '30-39': 48.2, '40-49': 54.0, '50-59': 34.1, '60-69': 47.2, '70-79': 50.9, '80-89': 54.8, '90-99': 59.25, 'old': 49.67, 'new': 52.5}
2025-02-13 19:27:18,676 [trainer.py] => NME: {'total': 49.72, '00-09': 62.3, '10-19': 41.2, '20-29': 59.9, '30-39': 51.0, '40-49': 55.1, '50-59': 29.9, '60-69': 46.3, '70-79': 49.6, '80-89': 51.1, '90-99': 52.5, 'old': 49.83, 'new': 45.0}
2025-02-13 19:27:18,676 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29, 50.72, 49.73]
2025-02-13 19:27:18,676 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13, 77.38, 76.49]
2025-02-13 19:27:18,676 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26, 51.04, 49.72]
2025-02-13 19:27:18,676 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44, 77.97, 77.11]

2025-02-13 19:27:18,676 [trainer.py] => Average Accuracy (CNN): 61.41347826086955
2025-02-13 19:27:18,676 [trainer.py] => Average Accuracy (NME): 61.6
2025-02-13 19:27:18,676 [trainer.py] => All params: 526417
2025-02-13 19:27:18,676 [trainer.py] => Trainable params: 526417
2025-02-13 19:27:18,677 [podnet.py] => Learning on 94-96
2025-02-13 19:27:18,702 [podnet.py] => Adaptive factor: 6.928203230275509
2025-02-13 19:27:20,529 [podnet.py] => Task 23, Epoch 1/160 (LR 0.09999) => LSC_loss 1.36, Spatial_loss 4.98, Flat_loss 0.71, Train_acc 77.95, Test_acc 39.78
2025-02-13 19:27:22,326 [podnet.py] => Task 23, Epoch 2/160 (LR 0.09996) => LSC_loss 0.56, Spatial_loss 5.70, Flat_loss 0.68, Train_acc 86.32, Test_acc 36.92
2025-02-13 19:27:24,193 [podnet.py] => Task 23, Epoch 3/160 (LR 0.09991) => LSC_loss 0.54, Spatial_loss 5.81, Flat_loss 0.69, Train_acc 86.18, Test_acc 38.00
2025-02-13 19:27:26,062 [podnet.py] => Task 23, Epoch 4/160 (LR 0.09985) => LSC_loss 0.52, Spatial_loss 5.63, Flat_loss 0.64, Train_acc 86.91, Test_acc 40.34
2025-02-13 19:27:27,910 [podnet.py] => Task 23, Epoch 5/160 (LR 0.09976) => LSC_loss 0.45, Spatial_loss 5.44, Flat_loss 0.58, Train_acc 89.90, Test_acc 40.88
2025-02-13 19:27:29,762 [podnet.py] => Task 23, Epoch 6/160 (LR 0.09965) => LSC_loss 0.46, Spatial_loss 5.36, Flat_loss 0.55, Train_acc 89.38, Test_acc 41.85
2025-02-13 19:27:31,604 [podnet.py] => Task 23, Epoch 7/160 (LR 0.09953) => LSC_loss 0.43, Spatial_loss 5.28, Flat_loss 0.54, Train_acc 90.17, Test_acc 39.46
2025-02-13 19:27:33,504 [podnet.py] => Task 23, Epoch 8/160 (LR 0.09938) => LSC_loss 0.46, Spatial_loss 5.28, Flat_loss 0.54, Train_acc 89.83, Test_acc 39.59
2025-02-13 19:27:35,358 [podnet.py] => Task 23, Epoch 9/160 (LR 0.09922) => LSC_loss 0.42, Spatial_loss 5.24, Flat_loss 0.51, Train_acc 90.83, Test_acc 35.22
2025-02-13 19:27:37,216 [podnet.py] => Task 23, Epoch 10/160 (LR 0.09904) => LSC_loss 0.42, Spatial_loss 5.15, Flat_loss 0.51, Train_acc 91.01, Test_acc 43.54
2025-02-13 19:27:39,107 [podnet.py] => Task 23, Epoch 11/160 (LR 0.09884) => LSC_loss 0.40, Spatial_loss 5.20, Flat_loss 0.50, Train_acc 91.35, Test_acc 43.47
2025-02-13 19:27:40,936 [podnet.py] => Task 23, Epoch 12/160 (LR 0.09862) => LSC_loss 0.39, Spatial_loss 5.11, Flat_loss 0.52, Train_acc 91.28, Test_acc 41.93
2025-02-13 19:27:42,757 [podnet.py] => Task 23, Epoch 13/160 (LR 0.09838) => LSC_loss 0.40, Spatial_loss 5.20, Flat_loss 0.48, Train_acc 91.39, Test_acc 39.30
2025-02-13 19:27:44,634 [podnet.py] => Task 23, Epoch 14/160 (LR 0.09812) => LSC_loss 0.42, Spatial_loss 5.08, Flat_loss 0.49, Train_acc 90.38, Test_acc 40.07
2025-02-13 19:27:46,479 [podnet.py] => Task 23, Epoch 15/160 (LR 0.09785) => LSC_loss 0.39, Spatial_loss 5.23, Flat_loss 0.51, Train_acc 91.94, Test_acc 41.14
2025-02-13 19:27:48,333 [podnet.py] => Task 23, Epoch 16/160 (LR 0.09755) => LSC_loss 0.40, Spatial_loss 5.09, Flat_loss 0.50, Train_acc 91.35, Test_acc 38.47
2025-02-13 19:27:50,212 [podnet.py] => Task 23, Epoch 17/160 (LR 0.09724) => LSC_loss 0.39, Spatial_loss 5.12, Flat_loss 0.49, Train_acc 91.46, Test_acc 43.58
2025-02-13 19:27:52,111 [podnet.py] => Task 23, Epoch 18/160 (LR 0.09691) => LSC_loss 0.36, Spatial_loss 4.93, Flat_loss 0.46, Train_acc 92.43, Test_acc 44.71
2025-02-13 19:27:53,928 [podnet.py] => Task 23, Epoch 19/160 (LR 0.09656) => LSC_loss 0.35, Spatial_loss 4.78, Flat_loss 0.44, Train_acc 92.47, Test_acc 43.19
2025-02-13 19:27:55,803 [podnet.py] => Task 23, Epoch 20/160 (LR 0.09619) => LSC_loss 0.36, Spatial_loss 4.90, Flat_loss 0.43, Train_acc 91.91, Test_acc 43.98
2025-02-13 19:27:57,643 [podnet.py] => Task 23, Epoch 21/160 (LR 0.09581) => LSC_loss 0.35, Spatial_loss 4.81, Flat_loss 0.44, Train_acc 92.50, Test_acc 41.21
2025-02-13 19:27:59,591 [podnet.py] => Task 23, Epoch 22/160 (LR 0.09541) => LSC_loss 0.37, Spatial_loss 4.94, Flat_loss 0.44, Train_acc 92.08, Test_acc 42.12
2025-02-13 19:28:01,462 [podnet.py] => Task 23, Epoch 23/160 (LR 0.09499) => LSC_loss 0.36, Spatial_loss 4.80, Flat_loss 0.45, Train_acc 92.15, Test_acc 43.44
2025-02-13 19:28:03,327 [podnet.py] => Task 23, Epoch 24/160 (LR 0.09455) => LSC_loss 0.34, Spatial_loss 4.75, Flat_loss 0.45, Train_acc 92.74, Test_acc 41.65
2025-02-13 19:28:05,181 [podnet.py] => Task 23, Epoch 25/160 (LR 0.09410) => LSC_loss 0.34, Spatial_loss 4.76, Flat_loss 0.43, Train_acc 92.60, Test_acc 42.32
2025-02-13 19:28:07,078 [podnet.py] => Task 23, Epoch 26/160 (LR 0.09362) => LSC_loss 0.35, Spatial_loss 4.68, Flat_loss 0.43, Train_acc 92.64, Test_acc 41.56
2025-02-13 19:28:08,960 [podnet.py] => Task 23, Epoch 27/160 (LR 0.09314) => LSC_loss 0.34, Spatial_loss 4.78, Flat_loss 0.44, Train_acc 93.09, Test_acc 38.56
2025-02-13 19:28:10,827 [podnet.py] => Task 23, Epoch 28/160 (LR 0.09263) => LSC_loss 0.33, Spatial_loss 4.73, Flat_loss 0.43, Train_acc 93.16, Test_acc 41.62
2025-02-13 19:28:12,709 [podnet.py] => Task 23, Epoch 29/160 (LR 0.09211) => LSC_loss 0.34, Spatial_loss 4.58, Flat_loss 0.40, Train_acc 93.72, Test_acc 43.68
2025-02-13 19:28:14,533 [podnet.py] => Task 23, Epoch 30/160 (LR 0.09157) => LSC_loss 0.32, Spatial_loss 4.65, Flat_loss 0.41, Train_acc 93.33, Test_acc 38.91
2025-02-13 19:28:16,384 [podnet.py] => Task 23, Epoch 31/160 (LR 0.09102) => LSC_loss 0.37, Spatial_loss 4.89, Flat_loss 0.46, Train_acc 91.81, Test_acc 43.96
2025-02-13 19:28:18,202 [podnet.py] => Task 23, Epoch 32/160 (LR 0.09045) => LSC_loss 0.34, Spatial_loss 4.77, Flat_loss 0.43, Train_acc 92.88, Test_acc 44.35
2025-02-13 19:28:20,018 [podnet.py] => Task 23, Epoch 33/160 (LR 0.08987) => LSC_loss 0.34, Spatial_loss 4.55, Flat_loss 0.41, Train_acc 93.26, Test_acc 44.24
2025-02-13 19:28:21,825 [podnet.py] => Task 23, Epoch 34/160 (LR 0.08927) => LSC_loss 0.32, Spatial_loss 4.53, Flat_loss 0.40, Train_acc 93.19, Test_acc 43.39
2025-02-13 19:28:23,680 [podnet.py] => Task 23, Epoch 35/160 (LR 0.08865) => LSC_loss 0.33, Spatial_loss 4.57, Flat_loss 0.40, Train_acc 93.16, Test_acc 45.16
2025-02-13 19:28:25,617 [podnet.py] => Task 23, Epoch 36/160 (LR 0.08802) => LSC_loss 0.35, Spatial_loss 4.56, Flat_loss 0.41, Train_acc 92.36, Test_acc 43.89
2025-02-13 19:28:27,502 [podnet.py] => Task 23, Epoch 37/160 (LR 0.08738) => LSC_loss 0.31, Spatial_loss 4.38, Flat_loss 0.38, Train_acc 93.89, Test_acc 44.54
2025-02-13 19:28:29,335 [podnet.py] => Task 23, Epoch 38/160 (LR 0.08672) => LSC_loss 0.33, Spatial_loss 4.51, Flat_loss 0.39, Train_acc 93.09, Test_acc 42.53
2025-02-13 19:28:31,170 [podnet.py] => Task 23, Epoch 39/160 (LR 0.08604) => LSC_loss 0.33, Spatial_loss 4.61, Flat_loss 0.41, Train_acc 93.16, Test_acc 41.68
2025-02-13 19:28:33,040 [podnet.py] => Task 23, Epoch 40/160 (LR 0.08536) => LSC_loss 0.31, Spatial_loss 4.46, Flat_loss 0.38, Train_acc 94.03, Test_acc 46.26
2025-02-13 19:28:34,928 [podnet.py] => Task 23, Epoch 41/160 (LR 0.08465) => LSC_loss 0.33, Spatial_loss 4.39, Flat_loss 0.39, Train_acc 93.16, Test_acc 44.80
2025-02-13 19:28:36,853 [podnet.py] => Task 23, Epoch 42/160 (LR 0.08394) => LSC_loss 0.31, Spatial_loss 4.33, Flat_loss 0.37, Train_acc 94.17, Test_acc 44.61
2025-02-13 19:28:38,766 [podnet.py] => Task 23, Epoch 43/160 (LR 0.08321) => LSC_loss 0.31, Spatial_loss 4.39, Flat_loss 0.38, Train_acc 94.13, Test_acc 39.92
2025-02-13 19:28:40,621 [podnet.py] => Task 23, Epoch 44/160 (LR 0.08247) => LSC_loss 0.31, Spatial_loss 4.36, Flat_loss 0.39, Train_acc 93.54, Test_acc 44.07
2025-02-13 19:28:42,477 [podnet.py] => Task 23, Epoch 45/160 (LR 0.08172) => LSC_loss 0.32, Spatial_loss 4.35, Flat_loss 0.37, Train_acc 93.33, Test_acc 42.11
2025-02-13 19:28:44,313 [podnet.py] => Task 23, Epoch 46/160 (LR 0.08095) => LSC_loss 0.31, Spatial_loss 4.34, Flat_loss 0.38, Train_acc 93.82, Test_acc 43.24
2025-02-13 19:28:46,168 [podnet.py] => Task 23, Epoch 47/160 (LR 0.08018) => LSC_loss 0.31, Spatial_loss 4.36, Flat_loss 0.38, Train_acc 94.03, Test_acc 45.95
2025-02-13 19:28:48,041 [podnet.py] => Task 23, Epoch 48/160 (LR 0.07939) => LSC_loss 0.30, Spatial_loss 4.28, Flat_loss 0.35, Train_acc 94.44, Test_acc 43.25
2025-02-13 19:28:49,892 [podnet.py] => Task 23, Epoch 49/160 (LR 0.07859) => LSC_loss 0.31, Spatial_loss 4.20, Flat_loss 0.35, Train_acc 93.44, Test_acc 42.53
2025-02-13 19:28:51,745 [podnet.py] => Task 23, Epoch 50/160 (LR 0.07778) => LSC_loss 0.30, Spatial_loss 4.13, Flat_loss 0.34, Train_acc 93.58, Test_acc 44.23
2025-02-13 19:28:53,651 [podnet.py] => Task 23, Epoch 51/160 (LR 0.07696) => LSC_loss 0.30, Spatial_loss 4.15, Flat_loss 0.34, Train_acc 94.48, Test_acc 44.51
2025-02-13 19:28:55,496 [podnet.py] => Task 23, Epoch 52/160 (LR 0.07612) => LSC_loss 0.31, Spatial_loss 4.15, Flat_loss 0.35, Train_acc 93.78, Test_acc 43.03
2025-02-13 19:28:57,387 [podnet.py] => Task 23, Epoch 53/160 (LR 0.07528) => LSC_loss 0.31, Spatial_loss 4.18, Flat_loss 0.36, Train_acc 94.13, Test_acc 44.21
2025-02-13 19:28:59,243 [podnet.py] => Task 23, Epoch 54/160 (LR 0.07443) => LSC_loss 0.31, Spatial_loss 4.16, Flat_loss 0.36, Train_acc 93.72, Test_acc 44.98
2025-02-13 19:29:01,108 [podnet.py] => Task 23, Epoch 55/160 (LR 0.07357) => LSC_loss 0.31, Spatial_loss 4.20, Flat_loss 0.34, Train_acc 93.68, Test_acc 39.30
2025-02-13 19:29:02,991 [podnet.py] => Task 23, Epoch 56/160 (LR 0.07270) => LSC_loss 0.30, Spatial_loss 4.24, Flat_loss 0.36, Train_acc 94.20, Test_acc 44.98
2025-02-13 19:29:04,865 [podnet.py] => Task 23, Epoch 57/160 (LR 0.07182) => LSC_loss 0.29, Spatial_loss 4.03, Flat_loss 0.34, Train_acc 94.76, Test_acc 42.76
2025-02-13 19:29:06,741 [podnet.py] => Task 23, Epoch 58/160 (LR 0.07093) => LSC_loss 0.30, Spatial_loss 4.16, Flat_loss 0.34, Train_acc 94.55, Test_acc 45.25
2025-02-13 19:29:08,612 [podnet.py] => Task 23, Epoch 59/160 (LR 0.07004) => LSC_loss 0.30, Spatial_loss 4.00, Flat_loss 0.34, Train_acc 94.41, Test_acc 45.74
2025-02-13 19:29:10,463 [podnet.py] => Task 23, Epoch 60/160 (LR 0.06913) => LSC_loss 0.29, Spatial_loss 3.96, Flat_loss 0.33, Train_acc 93.99, Test_acc 42.97
2025-02-13 19:29:12,321 [podnet.py] => Task 23, Epoch 61/160 (LR 0.06822) => LSC_loss 0.30, Spatial_loss 3.95, Flat_loss 0.33, Train_acc 94.10, Test_acc 44.83
2025-02-13 19:29:14,174 [podnet.py] => Task 23, Epoch 62/160 (LR 0.06731) => LSC_loss 0.30, Spatial_loss 4.07, Flat_loss 0.33, Train_acc 93.96, Test_acc 45.52
2025-02-13 19:29:16,055 [podnet.py] => Task 23, Epoch 63/160 (LR 0.06638) => LSC_loss 0.30, Spatial_loss 4.14, Flat_loss 0.34, Train_acc 94.13, Test_acc 45.10
2025-02-13 19:29:17,920 [podnet.py] => Task 23, Epoch 64/160 (LR 0.06545) => LSC_loss 0.29, Spatial_loss 3.91, Flat_loss 0.32, Train_acc 94.62, Test_acc 45.73
2025-02-13 19:29:19,781 [podnet.py] => Task 23, Epoch 65/160 (LR 0.06451) => LSC_loss 0.29, Spatial_loss 3.87, Flat_loss 0.31, Train_acc 94.55, Test_acc 43.75
2025-02-13 19:29:21,612 [podnet.py] => Task 23, Epoch 66/160 (LR 0.06357) => LSC_loss 0.28, Spatial_loss 3.82, Flat_loss 0.31, Train_acc 94.44, Test_acc 47.67
2025-02-13 19:29:23,516 [podnet.py] => Task 23, Epoch 67/160 (LR 0.06262) => LSC_loss 0.30, Spatial_loss 3.78, Flat_loss 0.31, Train_acc 94.58, Test_acc 45.49
2025-02-13 19:29:25,377 [podnet.py] => Task 23, Epoch 68/160 (LR 0.06167) => LSC_loss 0.30, Spatial_loss 4.00, Flat_loss 0.33, Train_acc 93.85, Test_acc 44.49
2025-02-13 19:29:27,226 [podnet.py] => Task 23, Epoch 69/160 (LR 0.06072) => LSC_loss 0.28, Spatial_loss 3.97, Flat_loss 0.32, Train_acc 94.90, Test_acc 46.43
2025-02-13 19:29:29,073 [podnet.py] => Task 23, Epoch 70/160 (LR 0.05975) => LSC_loss 0.28, Spatial_loss 3.90, Flat_loss 0.31, Train_acc 95.00, Test_acc 44.60
2025-02-13 19:29:30,943 [podnet.py] => Task 23, Epoch 71/160 (LR 0.05879) => LSC_loss 0.29, Spatial_loss 3.82, Flat_loss 0.30, Train_acc 94.55, Test_acc 42.00
2025-02-13 19:29:32,820 [podnet.py] => Task 23, Epoch 72/160 (LR 0.05782) => LSC_loss 0.28, Spatial_loss 3.74, Flat_loss 0.30, Train_acc 94.72, Test_acc 45.62
2025-02-13 19:29:34,689 [podnet.py] => Task 23, Epoch 73/160 (LR 0.05685) => LSC_loss 0.28, Spatial_loss 3.78, Flat_loss 0.30, Train_acc 94.86, Test_acc 44.74
2025-02-13 19:29:36,597 [podnet.py] => Task 23, Epoch 74/160 (LR 0.05588) => LSC_loss 0.28, Spatial_loss 3.87, Flat_loss 0.31, Train_acc 94.86, Test_acc 46.77
2025-02-13 19:29:38,469 [podnet.py] => Task 23, Epoch 75/160 (LR 0.05490) => LSC_loss 0.29, Spatial_loss 3.87, Flat_loss 0.30, Train_acc 94.97, Test_acc 43.23
2025-02-13 19:29:40,349 [podnet.py] => Task 23, Epoch 76/160 (LR 0.05392) => LSC_loss 0.28, Spatial_loss 3.77, Flat_loss 0.30, Train_acc 95.07, Test_acc 48.17
2025-02-13 19:29:42,227 [podnet.py] => Task 23, Epoch 77/160 (LR 0.05294) => LSC_loss 0.29, Spatial_loss 3.83, Flat_loss 0.30, Train_acc 94.62, Test_acc 42.72
2025-02-13 19:29:44,117 [podnet.py] => Task 23, Epoch 78/160 (LR 0.05196) => LSC_loss 0.28, Spatial_loss 3.60, Flat_loss 0.29, Train_acc 94.76, Test_acc 43.08
2025-02-13 19:29:46,015 [podnet.py] => Task 23, Epoch 79/160 (LR 0.05098) => LSC_loss 0.27, Spatial_loss 3.93, Flat_loss 0.30, Train_acc 94.97, Test_acc 45.11
2025-02-13 19:29:47,832 [podnet.py] => Task 23, Epoch 80/160 (LR 0.05000) => LSC_loss 0.27, Spatial_loss 3.64, Flat_loss 0.28, Train_acc 94.86, Test_acc 45.72
2025-02-13 19:29:49,652 [podnet.py] => Task 23, Epoch 81/160 (LR 0.04902) => LSC_loss 0.27, Spatial_loss 3.74, Flat_loss 0.29, Train_acc 95.10, Test_acc 46.59
2025-02-13 19:29:51,534 [podnet.py] => Task 23, Epoch 82/160 (LR 0.04804) => LSC_loss 0.27, Spatial_loss 3.63, Flat_loss 0.28, Train_acc 94.79, Test_acc 47.17
2025-02-13 19:29:53,358 [podnet.py] => Task 23, Epoch 83/160 (LR 0.04706) => LSC_loss 0.27, Spatial_loss 3.46, Flat_loss 0.26, Train_acc 94.90, Test_acc 46.90
2025-02-13 19:29:55,242 [podnet.py] => Task 23, Epoch 84/160 (LR 0.04608) => LSC_loss 0.28, Spatial_loss 3.56, Flat_loss 0.27, Train_acc 94.79, Test_acc 46.36
2025-02-13 19:29:57,153 [podnet.py] => Task 23, Epoch 85/160 (LR 0.04510) => LSC_loss 0.29, Spatial_loss 3.42, Flat_loss 0.27, Train_acc 94.79, Test_acc 44.43
2025-02-13 19:29:58,972 [podnet.py] => Task 23, Epoch 86/160 (LR 0.04412) => LSC_loss 0.27, Spatial_loss 3.49, Flat_loss 0.27, Train_acc 95.07, Test_acc 45.80
2025-02-13 19:30:00,881 [podnet.py] => Task 23, Epoch 87/160 (LR 0.04315) => LSC_loss 0.27, Spatial_loss 3.31, Flat_loss 0.25, Train_acc 95.28, Test_acc 44.35
2025-02-13 19:30:02,804 [podnet.py] => Task 23, Epoch 88/160 (LR 0.04218) => LSC_loss 0.27, Spatial_loss 3.44, Flat_loss 0.25, Train_acc 95.49, Test_acc 45.52
2025-02-13 19:30:04,694 [podnet.py] => Task 23, Epoch 89/160 (LR 0.04121) => LSC_loss 0.27, Spatial_loss 3.37, Flat_loss 0.24, Train_acc 95.80, Test_acc 46.73
2025-02-13 19:30:06,633 [podnet.py] => Task 23, Epoch 90/160 (LR 0.04025) => LSC_loss 0.28, Spatial_loss 3.37, Flat_loss 0.26, Train_acc 94.69, Test_acc 46.11
2025-02-13 19:30:08,485 [podnet.py] => Task 23, Epoch 91/160 (LR 0.03928) => LSC_loss 0.27, Spatial_loss 3.42, Flat_loss 0.26, Train_acc 94.62, Test_acc 46.09
2025-02-13 19:30:10,339 [podnet.py] => Task 23, Epoch 92/160 (LR 0.03833) => LSC_loss 0.28, Spatial_loss 3.37, Flat_loss 0.25, Train_acc 94.58, Test_acc 46.86
2025-02-13 19:30:12,228 [podnet.py] => Task 23, Epoch 93/160 (LR 0.03738) => LSC_loss 0.26, Spatial_loss 3.30, Flat_loss 0.24, Train_acc 95.87, Test_acc 46.64
2025-02-13 19:30:14,045 [podnet.py] => Task 23, Epoch 94/160 (LR 0.03643) => LSC_loss 0.28, Spatial_loss 3.32, Flat_loss 0.25, Train_acc 94.76, Test_acc 47.09
2025-02-13 19:30:15,926 [podnet.py] => Task 23, Epoch 95/160 (LR 0.03549) => LSC_loss 0.26, Spatial_loss 3.36, Flat_loss 0.25, Train_acc 95.62, Test_acc 41.62
2025-02-13 19:30:17,798 [podnet.py] => Task 23, Epoch 96/160 (LR 0.03455) => LSC_loss 0.29, Spatial_loss 3.36, Flat_loss 0.25, Train_acc 94.69, Test_acc 43.68
2025-02-13 19:30:19,629 [podnet.py] => Task 23, Epoch 97/160 (LR 0.03362) => LSC_loss 0.25, Spatial_loss 3.24, Flat_loss 0.23, Train_acc 95.66, Test_acc 46.96
2025-02-13 19:30:21,480 [podnet.py] => Task 23, Epoch 98/160 (LR 0.03269) => LSC_loss 0.27, Spatial_loss 3.12, Flat_loss 0.23, Train_acc 94.83, Test_acc 48.04
2025-02-13 19:30:23,311 [podnet.py] => Task 23, Epoch 99/160 (LR 0.03178) => LSC_loss 0.27, Spatial_loss 3.07, Flat_loss 0.22, Train_acc 95.10, Test_acc 47.45
2025-02-13 19:30:25,117 [podnet.py] => Task 23, Epoch 100/160 (LR 0.03087) => LSC_loss 0.25, Spatial_loss 3.16, Flat_loss 0.23, Train_acc 95.38, Test_acc 47.72
2025-02-13 19:30:26,949 [podnet.py] => Task 23, Epoch 101/160 (LR 0.02996) => LSC_loss 0.27, Spatial_loss 3.16, Flat_loss 0.23, Train_acc 95.17, Test_acc 46.07
2025-02-13 19:30:28,794 [podnet.py] => Task 23, Epoch 102/160 (LR 0.02907) => LSC_loss 0.27, Spatial_loss 3.07, Flat_loss 0.23, Train_acc 94.93, Test_acc 46.79
2025-02-13 19:30:30,631 [podnet.py] => Task 23, Epoch 103/160 (LR 0.02818) => LSC_loss 0.26, Spatial_loss 3.13, Flat_loss 0.23, Train_acc 95.28, Test_acc 45.86
2025-02-13 19:30:32,480 [podnet.py] => Task 23, Epoch 104/160 (LR 0.02730) => LSC_loss 0.27, Spatial_loss 3.10, Flat_loss 0.23, Train_acc 94.65, Test_acc 46.93
2025-02-13 19:30:34,350 [podnet.py] => Task 23, Epoch 105/160 (LR 0.02643) => LSC_loss 0.27, Spatial_loss 3.09, Flat_loss 0.23, Train_acc 95.07, Test_acc 46.77
2025-02-13 19:30:36,231 [podnet.py] => Task 23, Epoch 106/160 (LR 0.02557) => LSC_loss 0.25, Spatial_loss 2.94, Flat_loss 0.21, Train_acc 95.42, Test_acc 45.85
2025-02-13 19:30:38,107 [podnet.py] => Task 23, Epoch 107/160 (LR 0.02472) => LSC_loss 0.25, Spatial_loss 2.88, Flat_loss 0.21, Train_acc 95.59, Test_acc 47.33
2025-02-13 19:30:39,909 [podnet.py] => Task 23, Epoch 108/160 (LR 0.02388) => LSC_loss 0.26, Spatial_loss 2.87, Flat_loss 0.20, Train_acc 95.42, Test_acc 47.32
2025-02-13 19:30:41,755 [podnet.py] => Task 23, Epoch 109/160 (LR 0.02304) => LSC_loss 0.27, Spatial_loss 2.86, Flat_loss 0.20, Train_acc 95.14, Test_acc 47.31
2025-02-13 19:30:43,595 [podnet.py] => Task 23, Epoch 110/160 (LR 0.02222) => LSC_loss 0.25, Spatial_loss 2.74, Flat_loss 0.20, Train_acc 96.22, Test_acc 48.66
2025-02-13 19:30:45,408 [podnet.py] => Task 23, Epoch 111/160 (LR 0.02141) => LSC_loss 0.27, Spatial_loss 2.82, Flat_loss 0.20, Train_acc 95.28, Test_acc 47.75
2025-02-13 19:30:47,281 [podnet.py] => Task 23, Epoch 112/160 (LR 0.02061) => LSC_loss 0.27, Spatial_loss 2.74, Flat_loss 0.20, Train_acc 95.14, Test_acc 45.28
2025-02-13 19:30:49,171 [podnet.py] => Task 23, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 2.83, Flat_loss 0.20, Train_acc 95.56, Test_acc 46.56
2025-02-13 19:30:51,050 [podnet.py] => Task 23, Epoch 114/160 (LR 0.01905) => LSC_loss 0.27, Spatial_loss 2.87, Flat_loss 0.20, Train_acc 94.90, Test_acc 46.27
2025-02-13 19:30:52,947 [podnet.py] => Task 23, Epoch 115/160 (LR 0.01828) => LSC_loss 0.26, Spatial_loss 2.74, Flat_loss 0.19, Train_acc 95.17, Test_acc 48.14
2025-02-13 19:30:54,791 [podnet.py] => Task 23, Epoch 116/160 (LR 0.01753) => LSC_loss 0.27, Spatial_loss 2.72, Flat_loss 0.19, Train_acc 94.90, Test_acc 48.14
2025-02-13 19:30:56,673 [podnet.py] => Task 23, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 2.78, Flat_loss 0.19, Train_acc 95.45, Test_acc 48.98
2025-02-13 19:30:58,562 [podnet.py] => Task 23, Epoch 118/160 (LR 0.01606) => LSC_loss 0.27, Spatial_loss 2.71, Flat_loss 0.18, Train_acc 95.45, Test_acc 45.89
2025-02-13 19:31:00,426 [podnet.py] => Task 23, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 2.71, Flat_loss 0.20, Train_acc 95.31, Test_acc 47.88
2025-02-13 19:31:02,240 [podnet.py] => Task 23, Epoch 120/160 (LR 0.01464) => LSC_loss 0.26, Spatial_loss 2.65, Flat_loss 0.18, Train_acc 95.97, Test_acc 47.64
2025-02-13 19:31:04,042 [podnet.py] => Task 23, Epoch 121/160 (LR 0.01396) => LSC_loss 0.27, Spatial_loss 2.62, Flat_loss 0.18, Train_acc 94.83, Test_acc 45.57
2025-02-13 19:31:05,918 [podnet.py] => Task 23, Epoch 122/160 (LR 0.01328) => LSC_loss 0.26, Spatial_loss 2.54, Flat_loss 0.18, Train_acc 95.59, Test_acc 48.41
2025-02-13 19:31:07,758 [podnet.py] => Task 23, Epoch 123/160 (LR 0.01262) => LSC_loss 0.25, Spatial_loss 2.54, Flat_loss 0.19, Train_acc 95.76, Test_acc 47.25
2025-02-13 19:31:09,588 [podnet.py] => Task 23, Epoch 124/160 (LR 0.01198) => LSC_loss 0.26, Spatial_loss 2.53, Flat_loss 0.17, Train_acc 95.66, Test_acc 45.38
2025-02-13 19:31:11,416 [podnet.py] => Task 23, Epoch 125/160 (LR 0.01135) => LSC_loss 0.25, Spatial_loss 2.46, Flat_loss 0.18, Train_acc 95.59, Test_acc 47.09
2025-02-13 19:31:13,273 [podnet.py] => Task 23, Epoch 126/160 (LR 0.01073) => LSC_loss 0.26, Spatial_loss 2.47, Flat_loss 0.17, Train_acc 95.49, Test_acc 47.02
2025-02-13 19:31:15,142 [podnet.py] => Task 23, Epoch 127/160 (LR 0.01013) => LSC_loss 0.26, Spatial_loss 2.35, Flat_loss 0.17, Train_acc 95.49, Test_acc 48.93
2025-02-13 19:31:17,007 [podnet.py] => Task 23, Epoch 128/160 (LR 0.00955) => LSC_loss 0.27, Spatial_loss 2.44, Flat_loss 0.17, Train_acc 95.07, Test_acc 47.91
2025-02-13 19:31:18,820 [podnet.py] => Task 23, Epoch 129/160 (LR 0.00898) => LSC_loss 0.25, Spatial_loss 2.35, Flat_loss 0.17, Train_acc 95.69, Test_acc 47.59
2025-02-13 19:31:20,695 [podnet.py] => Task 23, Epoch 130/160 (LR 0.00843) => LSC_loss 0.25, Spatial_loss 2.42, Flat_loss 0.17, Train_acc 95.21, Test_acc 47.25
2025-02-13 19:31:22,576 [podnet.py] => Task 23, Epoch 131/160 (LR 0.00789) => LSC_loss 0.26, Spatial_loss 2.40, Flat_loss 0.17, Train_acc 95.38, Test_acc 46.64
2025-02-13 19:31:24,372 [podnet.py] => Task 23, Epoch 132/160 (LR 0.00737) => LSC_loss 0.26, Spatial_loss 2.37, Flat_loss 0.17, Train_acc 95.24, Test_acc 48.15
2025-02-13 19:31:26,231 [podnet.py] => Task 23, Epoch 133/160 (LR 0.00686) => LSC_loss 0.26, Spatial_loss 2.32, Flat_loss 0.16, Train_acc 95.42, Test_acc 47.51
2025-02-13 19:31:28,091 [podnet.py] => Task 23, Epoch 134/160 (LR 0.00638) => LSC_loss 0.25, Spatial_loss 2.28, Flat_loss 0.16, Train_acc 95.42, Test_acc 47.26
2025-02-13 19:31:29,910 [podnet.py] => Task 23, Epoch 135/160 (LR 0.00590) => LSC_loss 0.26, Spatial_loss 2.19, Flat_loss 0.16, Train_acc 95.35, Test_acc 47.49
2025-02-13 19:31:31,760 [podnet.py] => Task 23, Epoch 136/160 (LR 0.00545) => LSC_loss 0.26, Spatial_loss 2.15, Flat_loss 0.16, Train_acc 94.90, Test_acc 47.89
2025-02-13 19:31:33,571 [podnet.py] => Task 23, Epoch 137/160 (LR 0.00501) => LSC_loss 0.26, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 95.07, Test_acc 47.69
2025-02-13 19:31:35,421 [podnet.py] => Task 23, Epoch 138/160 (LR 0.00459) => LSC_loss 0.25, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 95.73, Test_acc 47.77
2025-02-13 19:31:37,294 [podnet.py] => Task 23, Epoch 139/160 (LR 0.00419) => LSC_loss 0.26, Spatial_loss 2.20, Flat_loss 0.15, Train_acc 95.62, Test_acc 48.69
2025-02-13 19:31:39,154 [podnet.py] => Task 23, Epoch 140/160 (LR 0.00381) => LSC_loss 0.25, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 95.03, Test_acc 47.92
2025-02-13 19:31:41,024 [podnet.py] => Task 23, Epoch 141/160 (LR 0.00344) => LSC_loss 0.26, Spatial_loss 2.04, Flat_loss 0.15, Train_acc 95.21, Test_acc 48.30
2025-02-13 19:31:42,857 [podnet.py] => Task 23, Epoch 142/160 (LR 0.00309) => LSC_loss 0.27, Spatial_loss 2.22, Flat_loss 0.15, Train_acc 95.03, Test_acc 48.08
2025-02-13 19:31:44,695 [podnet.py] => Task 23, Epoch 143/160 (LR 0.00276) => LSC_loss 0.27, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 95.17, Test_acc 47.80
2025-02-13 19:31:46,533 [podnet.py] => Task 23, Epoch 144/160 (LR 0.00245) => LSC_loss 0.27, Spatial_loss 2.12, Flat_loss 0.15, Train_acc 94.93, Test_acc 48.25
2025-02-13 19:31:48,402 [podnet.py] => Task 23, Epoch 145/160 (LR 0.00215) => LSC_loss 0.26, Spatial_loss 2.03, Flat_loss 0.15, Train_acc 95.17, Test_acc 47.82
2025-02-13 19:31:50,250 [podnet.py] => Task 23, Epoch 146/160 (LR 0.00188) => LSC_loss 0.26, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 95.62, Test_acc 47.70
2025-02-13 19:31:52,086 [podnet.py] => Task 23, Epoch 147/160 (LR 0.00162) => LSC_loss 0.26, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 95.42, Test_acc 48.38
2025-02-13 19:31:53,958 [podnet.py] => Task 23, Epoch 148/160 (LR 0.00138) => LSC_loss 0.27, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 95.03, Test_acc 47.60
2025-02-13 19:31:55,828 [podnet.py] => Task 23, Epoch 149/160 (LR 0.00116) => LSC_loss 0.26, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 94.83, Test_acc 48.22
2025-02-13 19:31:57,701 [podnet.py] => Task 23, Epoch 150/160 (LR 0.00096) => LSC_loss 0.27, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 95.21, Test_acc 48.10
2025-02-13 19:31:59,510 [podnet.py] => Task 23, Epoch 151/160 (LR 0.00078) => LSC_loss 0.26, Spatial_loss 2.02, Flat_loss 0.14, Train_acc 95.45, Test_acc 48.50
2025-02-13 19:32:01,316 [podnet.py] => Task 23, Epoch 152/160 (LR 0.00062) => LSC_loss 0.26, Spatial_loss 1.94, Flat_loss 0.14, Train_acc 95.17, Test_acc 48.51
2025-02-13 19:32:03,228 [podnet.py] => Task 23, Epoch 153/160 (LR 0.00047) => LSC_loss 0.26, Spatial_loss 2.01, Flat_loss 0.14, Train_acc 95.80, Test_acc 48.45
2025-02-13 19:32:05,053 [podnet.py] => Task 23, Epoch 154/160 (LR 0.00035) => LSC_loss 0.26, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 95.14, Test_acc 48.48
2025-02-13 19:32:06,951 [podnet.py] => Task 23, Epoch 155/160 (LR 0.00024) => LSC_loss 0.25, Spatial_loss 1.99, Flat_loss 0.15, Train_acc 96.01, Test_acc 48.11
2025-02-13 19:32:08,861 [podnet.py] => Task 23, Epoch 156/160 (LR 0.00015) => LSC_loss 0.25, Spatial_loss 2.07, Flat_loss 0.15, Train_acc 95.69, Test_acc 48.11
2025-02-13 19:32:10,707 [podnet.py] => Task 23, Epoch 157/160 (LR 0.00009) => LSC_loss 0.26, Spatial_loss 1.98, Flat_loss 0.14, Train_acc 95.45, Test_acc 48.36
2025-02-13 19:32:12,587 [podnet.py] => Task 23, Epoch 158/160 (LR 0.00004) => LSC_loss 0.26, Spatial_loss 1.93, Flat_loss 0.14, Train_acc 94.69, Test_acc 48.49
2025-02-13 19:32:14,481 [podnet.py] => Task 23, Epoch 159/160 (LR 0.00001) => LSC_loss 0.26, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 95.21, Test_acc 48.25
2025-02-13 19:32:16,317 [podnet.py] => Task 23, Epoch 160/160 (LR 0.00000) => LSC_loss 0.25, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 95.62, Test_acc 48.34
2025-02-13 19:32:16,317 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:32:16,318 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:32:46,624 [podnet.py] => The size of finetune dataset: 1920
2025-02-13 19:32:48,243 [podnet.py] => Task 23, Epoch 1/20 (LR 0.00497) => LSC_loss 0.17, Spatial_loss 2.34, Flat_loss 0.15, Train_acc 97.40, Test_acc 48.17
2025-02-13 19:32:49,861 [podnet.py] => Task 23, Epoch 2/20 (LR 0.00488) => LSC_loss 0.12, Spatial_loss 1.99, Flat_loss 0.08, Train_acc 98.59, Test_acc 48.85
2025-02-13 19:32:51,528 [podnet.py] => Task 23, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 2.03, Flat_loss 0.08, Train_acc 98.33, Test_acc 49.61
2025-02-13 19:32:53,171 [podnet.py] => Task 23, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 2.04, Flat_loss 0.07, Train_acc 98.23, Test_acc 48.94
2025-02-13 19:32:54,788 [podnet.py] => Task 23, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 1.93, Flat_loss 0.07, Train_acc 98.65, Test_acc 48.82
2025-02-13 19:32:56,417 [podnet.py] => Task 23, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 1.96, Flat_loss 0.07, Train_acc 98.54, Test_acc 49.55
2025-02-13 19:32:58,027 [podnet.py] => Task 23, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 1.89, Flat_loss 0.07, Train_acc 98.70, Test_acc 48.74
2025-02-13 19:32:59,649 [podnet.py] => Task 23, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.33, Test_acc 48.92
2025-02-13 19:33:01,286 [podnet.py] => Task 23, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 98.75, Test_acc 48.95
2025-02-13 19:33:02,937 [podnet.py] => Task 23, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 1.82, Flat_loss 0.06, Train_acc 98.70, Test_acc 49.27
2025-02-13 19:33:04,572 [podnet.py] => Task 23, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.75, Test_acc 49.15
2025-02-13 19:33:06,149 [podnet.py] => Task 23, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.86, Flat_loss 0.06, Train_acc 98.65, Test_acc 49.10
2025-02-13 19:33:07,783 [podnet.py] => Task 23, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 1.71, Flat_loss 0.06, Train_acc 98.28, Test_acc 48.97
2025-02-13 19:33:09,372 [podnet.py] => Task 23, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 1.78, Flat_loss 0.06, Train_acc 98.49, Test_acc 49.34
2025-02-13 19:33:10,977 [podnet.py] => Task 23, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 1.75, Flat_loss 0.06, Train_acc 98.75, Test_acc 48.95
2025-02-13 19:33:12,591 [podnet.py] => Task 23, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 98.85, Test_acc 48.82
2025-02-13 19:33:14,170 [podnet.py] => Task 23, Epoch 17/20 (LR 0.00027) => LSC_loss 0.13, Spatial_loss 1.90, Flat_loss 0.06, Train_acc 98.33, Test_acc 49.09
2025-02-13 19:33:15,785 [podnet.py] => Task 23, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 1.83, Flat_loss 0.06, Train_acc 98.65, Test_acc 49.08
2025-02-13 19:33:17,381 [podnet.py] => Task 23, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 1.74, Flat_loss 0.06, Train_acc 98.59, Test_acc 48.94
2025-02-13 19:33:18,988 [podnet.py] => Task 23, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 1.87, Flat_loss 0.06, Train_acc 98.80, Test_acc 49.04
2025-02-13 19:33:18,991 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:33:51,404 [podnet.py] => Exemplar size: 1920
2025-02-13 19:33:51,405 [trainer.py] => CNN: {'total': 49.04, '00-09': 57.6, '10-19': 38.9, '20-29': 57.3, '30-39': 47.9, '40-49': 53.7, '50-59': 33.8, '60-69': 46.4, '70-79': 49.4, '80-89': 54.7, '90-99': 51.83, 'old': 49.03, 'new': 49.5}
2025-02-13 19:33:51,405 [trainer.py] => NME: {'total': 49.07, '00-09': 61.2, '10-19': 41.1, '20-29': 59.4, '30-39': 50.4, '40-49': 54.6, '50-59': 30.6, '60-69': 45.7, '70-79': 48.6, '80-89': 51.1, '90-99': 47.33, 'old': 49.2, 'new': 43.0}
2025-02-13 19:33:51,407 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29, 50.72, 49.73, 49.04]
2025-02-13 19:33:51,407 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13, 77.38, 76.49, 75.92]
2025-02-13 19:33:51,407 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26, 51.04, 49.72, 49.07]
2025-02-13 19:33:51,407 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44, 77.97, 77.11, 76.41]

2025-02-13 19:33:51,407 [trainer.py] => Average Accuracy (CNN): 60.89791666666665
2025-02-13 19:33:51,407 [trainer.py] => Average Accuracy (NME): 61.07791666666666
2025-02-13 19:33:51,408 [trainer.py] => All params: 527697
2025-02-13 19:33:51,408 [trainer.py] => Trainable params: 527697
2025-02-13 19:33:51,409 [podnet.py] => Learning on 96-98
2025-02-13 19:33:51,434 [podnet.py] => Adaptive factor: 7.0
2025-02-13 19:33:53,346 [podnet.py] => Task 24, Epoch 1/160 (LR 0.09999) => LSC_loss 1.17, Spatial_loss 4.59, Flat_loss 0.69, Train_acc 81.30, Test_acc 40.27
2025-02-13 19:33:55,278 [podnet.py] => Task 24, Epoch 2/160 (LR 0.09996) => LSC_loss 0.48, Spatial_loss 5.54, Flat_loss 0.68, Train_acc 88.01, Test_acc 40.13
2025-02-13 19:33:57,141 [podnet.py] => Task 24, Epoch 3/160 (LR 0.09991) => LSC_loss 0.47, Spatial_loss 5.65, Flat_loss 0.68, Train_acc 88.32, Test_acc 39.88
2025-02-13 19:33:58,985 [podnet.py] => Task 24, Epoch 4/160 (LR 0.09985) => LSC_loss 0.47, Spatial_loss 5.77, Flat_loss 0.69, Train_acc 88.39, Test_acc 41.32
2025-02-13 19:34:00,814 [podnet.py] => Task 24, Epoch 5/160 (LR 0.09976) => LSC_loss 0.41, Spatial_loss 5.56, Flat_loss 0.62, Train_acc 90.14, Test_acc 42.28
2025-02-13 19:34:02,717 [podnet.py] => Task 24, Epoch 6/160 (LR 0.09965) => LSC_loss 0.40, Spatial_loss 5.54, Flat_loss 0.59, Train_acc 90.96, Test_acc 42.28
2025-02-13 19:34:04,604 [podnet.py] => Task 24, Epoch 7/160 (LR 0.09953) => LSC_loss 0.37, Spatial_loss 5.19, Flat_loss 0.55, Train_acc 91.44, Test_acc 40.64
2025-02-13 19:34:06,518 [podnet.py] => Task 24, Epoch 8/160 (LR 0.09938) => LSC_loss 0.37, Spatial_loss 5.12, Flat_loss 0.54, Train_acc 91.30, Test_acc 41.72
2025-02-13 19:34:08,430 [podnet.py] => Task 24, Epoch 9/160 (LR 0.09922) => LSC_loss 0.34, Spatial_loss 5.10, Flat_loss 0.52, Train_acc 93.12, Test_acc 38.88
2025-02-13 19:34:10,361 [podnet.py] => Task 24, Epoch 10/160 (LR 0.09904) => LSC_loss 0.34, Spatial_loss 5.12, Flat_loss 0.52, Train_acc 93.49, Test_acc 39.88
2025-02-13 19:34:12,204 [podnet.py] => Task 24, Epoch 11/160 (LR 0.09884) => LSC_loss 0.34, Spatial_loss 5.15, Flat_loss 0.51, Train_acc 92.84, Test_acc 41.04
2025-02-13 19:34:14,078 [podnet.py] => Task 24, Epoch 12/160 (LR 0.09862) => LSC_loss 0.35, Spatial_loss 4.95, Flat_loss 0.49, Train_acc 92.19, Test_acc 43.74
2025-02-13 19:34:15,940 [podnet.py] => Task 24, Epoch 13/160 (LR 0.09838) => LSC_loss 0.32, Spatial_loss 4.97, Flat_loss 0.49, Train_acc 93.32, Test_acc 40.94
2025-02-13 19:34:17,785 [podnet.py] => Task 24, Epoch 14/160 (LR 0.09812) => LSC_loss 0.33, Spatial_loss 4.90, Flat_loss 0.48, Train_acc 93.18, Test_acc 43.07
2025-02-13 19:34:19,647 [podnet.py] => Task 24, Epoch 15/160 (LR 0.09785) => LSC_loss 0.32, Spatial_loss 4.85, Flat_loss 0.48, Train_acc 92.77, Test_acc 42.27
2025-02-13 19:34:21,517 [podnet.py] => Task 24, Epoch 16/160 (LR 0.09755) => LSC_loss 0.32, Spatial_loss 4.86, Flat_loss 0.47, Train_acc 93.60, Test_acc 42.35
2025-02-13 19:34:23,443 [podnet.py] => Task 24, Epoch 17/160 (LR 0.09724) => LSC_loss 0.31, Spatial_loss 4.73, Flat_loss 0.45, Train_acc 93.97, Test_acc 39.17
2025-02-13 19:34:25,330 [podnet.py] => Task 24, Epoch 18/160 (LR 0.09691) => LSC_loss 0.32, Spatial_loss 4.81, Flat_loss 0.45, Train_acc 93.29, Test_acc 42.58
2025-02-13 19:34:27,215 [podnet.py] => Task 24, Epoch 19/160 (LR 0.09656) => LSC_loss 0.29, Spatial_loss 4.71, Flat_loss 0.44, Train_acc 93.87, Test_acc 45.65
2025-02-13 19:34:29,096 [podnet.py] => Task 24, Epoch 20/160 (LR 0.09619) => LSC_loss 0.31, Spatial_loss 4.65, Flat_loss 0.44, Train_acc 93.36, Test_acc 40.63
2025-02-13 19:34:30,961 [podnet.py] => Task 24, Epoch 21/160 (LR 0.09581) => LSC_loss 0.30, Spatial_loss 4.80, Flat_loss 0.45, Train_acc 93.56, Test_acc 42.79
2025-02-13 19:34:32,766 [podnet.py] => Task 24, Epoch 22/160 (LR 0.09541) => LSC_loss 0.29, Spatial_loss 4.71, Flat_loss 0.44, Train_acc 94.18, Test_acc 41.74
2025-02-13 19:34:34,660 [podnet.py] => Task 24, Epoch 23/160 (LR 0.09499) => LSC_loss 0.29, Spatial_loss 4.58, Flat_loss 0.43, Train_acc 93.63, Test_acc 42.93
2025-02-13 19:34:36,486 [podnet.py] => Task 24, Epoch 24/160 (LR 0.09455) => LSC_loss 0.29, Spatial_loss 4.47, Flat_loss 0.41, Train_acc 94.25, Test_acc 43.48
2025-02-13 19:34:38,370 [podnet.py] => Task 24, Epoch 25/160 (LR 0.09410) => LSC_loss 0.29, Spatial_loss 4.46, Flat_loss 0.41, Train_acc 93.94, Test_acc 43.26
2025-02-13 19:34:40,226 [podnet.py] => Task 24, Epoch 26/160 (LR 0.09362) => LSC_loss 0.29, Spatial_loss 4.53, Flat_loss 0.41, Train_acc 94.04, Test_acc 40.56
2025-02-13 19:34:42,051 [podnet.py] => Task 24, Epoch 27/160 (LR 0.09314) => LSC_loss 0.30, Spatial_loss 4.41, Flat_loss 0.41, Train_acc 93.70, Test_acc 42.41
2025-02-13 19:34:43,935 [podnet.py] => Task 24, Epoch 28/160 (LR 0.09263) => LSC_loss 0.29, Spatial_loss 4.46, Flat_loss 0.41, Train_acc 93.94, Test_acc 43.38
2025-02-13 19:34:45,800 [podnet.py] => Task 24, Epoch 29/160 (LR 0.09211) => LSC_loss 0.27, Spatial_loss 4.36, Flat_loss 0.40, Train_acc 94.59, Test_acc 45.51
2025-02-13 19:34:47,692 [podnet.py] => Task 24, Epoch 30/160 (LR 0.09157) => LSC_loss 0.28, Spatial_loss 4.38, Flat_loss 0.40, Train_acc 94.45, Test_acc 42.52
2025-02-13 19:34:49,612 [podnet.py] => Task 24, Epoch 31/160 (LR 0.09102) => LSC_loss 0.28, Spatial_loss 4.48, Flat_loss 0.39, Train_acc 94.38, Test_acc 43.62
2025-02-13 19:34:51,474 [podnet.py] => Task 24, Epoch 32/160 (LR 0.09045) => LSC_loss 0.28, Spatial_loss 4.38, Flat_loss 0.40, Train_acc 94.69, Test_acc 45.32
2025-02-13 19:34:53,350 [podnet.py] => Task 24, Epoch 33/160 (LR 0.08987) => LSC_loss 0.26, Spatial_loss 4.26, Flat_loss 0.37, Train_acc 95.07, Test_acc 42.12
2025-02-13 19:34:55,181 [podnet.py] => Task 24, Epoch 34/160 (LR 0.08927) => LSC_loss 0.29, Spatial_loss 4.41, Flat_loss 0.39, Train_acc 94.45, Test_acc 43.48
2025-02-13 19:34:57,022 [podnet.py] => Task 24, Epoch 35/160 (LR 0.08865) => LSC_loss 0.27, Spatial_loss 4.48, Flat_loss 0.40, Train_acc 94.62, Test_acc 43.35
2025-02-13 19:34:58,897 [podnet.py] => Task 24, Epoch 36/160 (LR 0.08802) => LSC_loss 0.31, Spatial_loss 4.52, Flat_loss 0.41, Train_acc 93.60, Test_acc 44.52
2025-02-13 19:35:00,779 [podnet.py] => Task 24, Epoch 37/160 (LR 0.08738) => LSC_loss 0.27, Spatial_loss 4.37, Flat_loss 0.40, Train_acc 95.14, Test_acc 43.23
2025-02-13 19:35:02,677 [podnet.py] => Task 24, Epoch 38/160 (LR 0.08672) => LSC_loss 0.28, Spatial_loss 4.30, Flat_loss 0.39, Train_acc 94.01, Test_acc 40.32
2025-02-13 19:35:04,458 [podnet.py] => Task 24, Epoch 39/160 (LR 0.08604) => LSC_loss 0.28, Spatial_loss 4.22, Flat_loss 0.38, Train_acc 94.42, Test_acc 46.66
2025-02-13 19:35:06,306 [podnet.py] => Task 24, Epoch 40/160 (LR 0.08536) => LSC_loss 0.26, Spatial_loss 4.17, Flat_loss 0.37, Train_acc 95.00, Test_acc 42.38
2025-02-13 19:35:08,090 [podnet.py] => Task 24, Epoch 41/160 (LR 0.08465) => LSC_loss 0.28, Spatial_loss 4.23, Flat_loss 0.38, Train_acc 94.49, Test_acc 40.95
2025-02-13 19:35:09,969 [podnet.py] => Task 24, Epoch 42/160 (LR 0.08394) => LSC_loss 0.27, Spatial_loss 4.37, Flat_loss 0.39, Train_acc 94.97, Test_acc 45.68
2025-02-13 19:35:11,859 [podnet.py] => Task 24, Epoch 43/160 (LR 0.08321) => LSC_loss 0.27, Spatial_loss 4.15, Flat_loss 0.36, Train_acc 95.03, Test_acc 44.46
2025-02-13 19:35:13,746 [podnet.py] => Task 24, Epoch 44/160 (LR 0.08247) => LSC_loss 0.26, Spatial_loss 4.02, Flat_loss 0.34, Train_acc 95.38, Test_acc 44.27
2025-02-13 19:35:15,615 [podnet.py] => Task 24, Epoch 45/160 (LR 0.08172) => LSC_loss 0.24, Spatial_loss 3.99, Flat_loss 0.34, Train_acc 95.58, Test_acc 41.62
2025-02-13 19:35:17,509 [podnet.py] => Task 24, Epoch 46/160 (LR 0.08095) => LSC_loss 0.26, Spatial_loss 4.21, Flat_loss 0.35, Train_acc 94.73, Test_acc 42.33
2025-02-13 19:35:19,386 [podnet.py] => Task 24, Epoch 47/160 (LR 0.08018) => LSC_loss 0.25, Spatial_loss 4.26, Flat_loss 0.36, Train_acc 94.86, Test_acc 43.92
2025-02-13 19:35:21,148 [podnet.py] => Task 24, Epoch 48/160 (LR 0.07939) => LSC_loss 0.25, Spatial_loss 4.12, Flat_loss 0.36, Train_acc 95.41, Test_acc 45.36
2025-02-13 19:35:23,090 [podnet.py] => Task 24, Epoch 49/160 (LR 0.07859) => LSC_loss 0.27, Spatial_loss 4.07, Flat_loss 0.35, Train_acc 94.86, Test_acc 44.43
2025-02-13 19:35:24,955 [podnet.py] => Task 24, Epoch 50/160 (LR 0.07778) => LSC_loss 0.27, Spatial_loss 4.34, Flat_loss 0.36, Train_acc 94.90, Test_acc 44.94
2025-02-13 19:35:26,814 [podnet.py] => Task 24, Epoch 51/160 (LR 0.07696) => LSC_loss 0.25, Spatial_loss 4.08, Flat_loss 0.35, Train_acc 95.21, Test_acc 44.15
2025-02-13 19:35:28,671 [podnet.py] => Task 24, Epoch 52/160 (LR 0.07612) => LSC_loss 0.25, Spatial_loss 3.83, Flat_loss 0.33, Train_acc 94.73, Test_acc 46.37
2025-02-13 19:35:30,572 [podnet.py] => Task 24, Epoch 53/160 (LR 0.07528) => LSC_loss 0.26, Spatial_loss 3.94, Flat_loss 0.33, Train_acc 95.24, Test_acc 43.31
2025-02-13 19:35:32,395 [podnet.py] => Task 24, Epoch 54/160 (LR 0.07443) => LSC_loss 0.25, Spatial_loss 3.92, Flat_loss 0.32, Train_acc 95.41, Test_acc 40.68
2025-02-13 19:35:34,248 [podnet.py] => Task 24, Epoch 55/160 (LR 0.07357) => LSC_loss 0.27, Spatial_loss 4.16, Flat_loss 0.35, Train_acc 94.49, Test_acc 44.55
2025-02-13 19:35:36,095 [podnet.py] => Task 24, Epoch 56/160 (LR 0.07270) => LSC_loss 0.25, Spatial_loss 4.14, Flat_loss 0.35, Train_acc 95.38, Test_acc 43.55
2025-02-13 19:35:37,981 [podnet.py] => Task 24, Epoch 57/160 (LR 0.07182) => LSC_loss 0.24, Spatial_loss 3.96, Flat_loss 0.33, Train_acc 95.82, Test_acc 44.43
2025-02-13 19:35:39,868 [podnet.py] => Task 24, Epoch 58/160 (LR 0.07093) => LSC_loss 0.25, Spatial_loss 3.92, Flat_loss 0.33, Train_acc 95.65, Test_acc 46.35
2025-02-13 19:35:41,798 [podnet.py] => Task 24, Epoch 59/160 (LR 0.07004) => LSC_loss 0.24, Spatial_loss 3.85, Flat_loss 0.32, Train_acc 96.06, Test_acc 43.59
2025-02-13 19:35:43,679 [podnet.py] => Task 24, Epoch 60/160 (LR 0.06913) => LSC_loss 0.25, Spatial_loss 3.80, Flat_loss 0.31, Train_acc 95.03, Test_acc 40.41
2025-02-13 19:35:45,514 [podnet.py] => Task 24, Epoch 61/160 (LR 0.06822) => LSC_loss 0.24, Spatial_loss 3.73, Flat_loss 0.31, Train_acc 95.75, Test_acc 42.76
2025-02-13 19:35:47,393 [podnet.py] => Task 24, Epoch 62/160 (LR 0.06731) => LSC_loss 0.25, Spatial_loss 3.78, Flat_loss 0.31, Train_acc 95.62, Test_acc 44.30
2025-02-13 19:35:49,242 [podnet.py] => Task 24, Epoch 63/160 (LR 0.06638) => LSC_loss 0.24, Spatial_loss 3.91, Flat_loss 0.32, Train_acc 95.72, Test_acc 44.55
2025-02-13 19:35:51,119 [podnet.py] => Task 24, Epoch 64/160 (LR 0.06545) => LSC_loss 0.25, Spatial_loss 3.67, Flat_loss 0.30, Train_acc 95.82, Test_acc 42.85
2025-02-13 19:35:52,961 [podnet.py] => Task 24, Epoch 65/160 (LR 0.06451) => LSC_loss 0.25, Spatial_loss 3.75, Flat_loss 0.31, Train_acc 95.48, Test_acc 44.71
2025-02-13 19:35:54,819 [podnet.py] => Task 24, Epoch 66/160 (LR 0.06357) => LSC_loss 0.24, Spatial_loss 3.64, Flat_loss 0.30, Train_acc 95.17, Test_acc 45.58
2025-02-13 19:35:56,692 [podnet.py] => Task 24, Epoch 67/160 (LR 0.06262) => LSC_loss 0.25, Spatial_loss 3.62, Flat_loss 0.30, Train_acc 95.24, Test_acc 47.06
2025-02-13 19:35:58,565 [podnet.py] => Task 24, Epoch 68/160 (LR 0.06167) => LSC_loss 0.23, Spatial_loss 3.65, Flat_loss 0.30, Train_acc 95.62, Test_acc 43.00
2025-02-13 19:36:00,460 [podnet.py] => Task 24, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 3.72, Flat_loss 0.30, Train_acc 95.45, Test_acc 46.39
2025-02-13 19:36:02,371 [podnet.py] => Task 24, Epoch 70/160 (LR 0.05975) => LSC_loss 0.26, Spatial_loss 3.87, Flat_loss 0.32, Train_acc 95.03, Test_acc 44.99
2025-02-13 19:36:04,235 [podnet.py] => Task 24, Epoch 71/160 (LR 0.05879) => LSC_loss 0.24, Spatial_loss 3.65, Flat_loss 0.29, Train_acc 95.86, Test_acc 43.02
2025-02-13 19:36:06,134 [podnet.py] => Task 24, Epoch 72/160 (LR 0.05782) => LSC_loss 0.23, Spatial_loss 3.62, Flat_loss 0.29, Train_acc 95.62, Test_acc 45.35
2025-02-13 19:36:07,993 [podnet.py] => Task 24, Epoch 73/160 (LR 0.05685) => LSC_loss 0.24, Spatial_loss 3.67, Flat_loss 0.28, Train_acc 95.68, Test_acc 44.07
2025-02-13 19:36:09,890 [podnet.py] => Task 24, Epoch 74/160 (LR 0.05588) => LSC_loss 0.22, Spatial_loss 3.48, Flat_loss 0.28, Train_acc 96.20, Test_acc 45.87
2025-02-13 19:36:11,766 [podnet.py] => Task 24, Epoch 75/160 (LR 0.05490) => LSC_loss 0.24, Spatial_loss 3.56, Flat_loss 0.27, Train_acc 96.06, Test_acc 47.35
2025-02-13 19:36:13,653 [podnet.py] => Task 24, Epoch 76/160 (LR 0.05392) => LSC_loss 0.24, Spatial_loss 3.60, Flat_loss 0.28, Train_acc 95.10, Test_acc 44.97
2025-02-13 19:36:15,507 [podnet.py] => Task 24, Epoch 77/160 (LR 0.05294) => LSC_loss 0.23, Spatial_loss 3.55, Flat_loss 0.29, Train_acc 96.37, Test_acc 42.29
2025-02-13 19:36:17,325 [podnet.py] => Task 24, Epoch 78/160 (LR 0.05196) => LSC_loss 0.23, Spatial_loss 3.50, Flat_loss 0.28, Train_acc 96.03, Test_acc 45.87
2025-02-13 19:36:19,305 [podnet.py] => Task 24, Epoch 79/160 (LR 0.05098) => LSC_loss 0.24, Spatial_loss 3.55, Flat_loss 0.28, Train_acc 95.99, Test_acc 45.42
2025-02-13 19:36:21,203 [podnet.py] => Task 24, Epoch 80/160 (LR 0.05000) => LSC_loss 0.24, Spatial_loss 3.67, Flat_loss 0.29, Train_acc 95.86, Test_acc 45.14
2025-02-13 19:36:23,050 [podnet.py] => Task 24, Epoch 81/160 (LR 0.04902) => LSC_loss 0.23, Spatial_loss 3.51, Flat_loss 0.27, Train_acc 96.44, Test_acc 43.94
2025-02-13 19:36:24,910 [podnet.py] => Task 24, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 3.33, Flat_loss 0.25, Train_acc 95.86, Test_acc 45.38
2025-02-13 19:36:26,783 [podnet.py] => Task 24, Epoch 83/160 (LR 0.04706) => LSC_loss 0.24, Spatial_loss 3.33, Flat_loss 0.26, Train_acc 95.62, Test_acc 46.55
2025-02-13 19:36:28,674 [podnet.py] => Task 24, Epoch 84/160 (LR 0.04608) => LSC_loss 0.22, Spatial_loss 3.19, Flat_loss 0.25, Train_acc 96.64, Test_acc 45.71
2025-02-13 19:36:30,551 [podnet.py] => Task 24, Epoch 85/160 (LR 0.04510) => LSC_loss 0.23, Spatial_loss 3.36, Flat_loss 0.26, Train_acc 96.10, Test_acc 45.54
2025-02-13 19:36:32,459 [podnet.py] => Task 24, Epoch 86/160 (LR 0.04412) => LSC_loss 0.23, Spatial_loss 3.30, Flat_loss 0.26, Train_acc 95.79, Test_acc 44.92
2025-02-13 19:36:34,275 [podnet.py] => Task 24, Epoch 87/160 (LR 0.04315) => LSC_loss 0.23, Spatial_loss 3.27, Flat_loss 0.25, Train_acc 95.89, Test_acc 44.41
2025-02-13 19:36:36,104 [podnet.py] => Task 24, Epoch 88/160 (LR 0.04218) => LSC_loss 0.23, Spatial_loss 3.28, Flat_loss 0.25, Train_acc 96.13, Test_acc 45.38
2025-02-13 19:36:38,001 [podnet.py] => Task 24, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 3.12, Flat_loss 0.24, Train_acc 96.37, Test_acc 44.98
2025-02-13 19:36:39,831 [podnet.py] => Task 24, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 3.35, Flat_loss 0.26, Train_acc 95.82, Test_acc 46.30
2025-02-13 19:36:41,733 [podnet.py] => Task 24, Epoch 91/160 (LR 0.03928) => LSC_loss 0.23, Spatial_loss 3.07, Flat_loss 0.23, Train_acc 96.06, Test_acc 45.94
2025-02-13 19:36:43,614 [podnet.py] => Task 24, Epoch 92/160 (LR 0.03833) => LSC_loss 0.24, Spatial_loss 3.22, Flat_loss 0.24, Train_acc 95.21, Test_acc 44.94
2025-02-13 19:36:45,496 [podnet.py] => Task 24, Epoch 93/160 (LR 0.03738) => LSC_loss 0.22, Spatial_loss 3.07, Flat_loss 0.23, Train_acc 96.23, Test_acc 45.07
2025-02-13 19:36:47,309 [podnet.py] => Task 24, Epoch 94/160 (LR 0.03643) => LSC_loss 0.23, Spatial_loss 3.00, Flat_loss 0.22, Train_acc 96.03, Test_acc 47.17
2025-02-13 19:36:49,229 [podnet.py] => Task 24, Epoch 95/160 (LR 0.03549) => LSC_loss 0.23, Spatial_loss 2.97, Flat_loss 0.23, Train_acc 95.96, Test_acc 45.79
2025-02-13 19:36:51,096 [podnet.py] => Task 24, Epoch 96/160 (LR 0.03455) => LSC_loss 0.22, Spatial_loss 3.06, Flat_loss 0.22, Train_acc 96.44, Test_acc 43.42
2025-02-13 19:36:52,972 [podnet.py] => Task 24, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 3.12, Flat_loss 0.23, Train_acc 96.30, Test_acc 46.17
2025-02-13 19:36:54,833 [podnet.py] => Task 24, Epoch 98/160 (LR 0.03269) => LSC_loss 0.24, Spatial_loss 3.10, Flat_loss 0.23, Train_acc 95.58, Test_acc 45.42
2025-02-13 19:36:56,754 [podnet.py] => Task 24, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 3.07, Flat_loss 0.23, Train_acc 96.10, Test_acc 45.76
2025-02-13 19:36:58,582 [podnet.py] => Task 24, Epoch 100/160 (LR 0.03087) => LSC_loss 0.22, Spatial_loss 3.02, Flat_loss 0.22, Train_acc 96.30, Test_acc 46.62
2025-02-13 19:37:00,476 [podnet.py] => Task 24, Epoch 101/160 (LR 0.02996) => LSC_loss 0.22, Spatial_loss 3.08, Flat_loss 0.22, Train_acc 95.96, Test_acc 47.29
2025-02-13 19:37:02,333 [podnet.py] => Task 24, Epoch 102/160 (LR 0.02907) => LSC_loss 0.22, Spatial_loss 2.96, Flat_loss 0.21, Train_acc 96.44, Test_acc 46.61
2025-02-13 19:37:04,174 [podnet.py] => Task 24, Epoch 103/160 (LR 0.02818) => LSC_loss 0.23, Spatial_loss 2.81, Flat_loss 0.21, Train_acc 95.92, Test_acc 45.52
2025-02-13 19:37:06,029 [podnet.py] => Task 24, Epoch 104/160 (LR 0.02730) => LSC_loss 0.21, Spatial_loss 2.87, Flat_loss 0.21, Train_acc 96.37, Test_acc 44.53
2025-02-13 19:37:07,948 [podnet.py] => Task 24, Epoch 105/160 (LR 0.02643) => LSC_loss 0.22, Spatial_loss 2.79, Flat_loss 0.21, Train_acc 95.82, Test_acc 47.36
2025-02-13 19:37:09,763 [podnet.py] => Task 24, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 96.47, Test_acc 47.00
2025-02-13 19:37:11,650 [podnet.py] => Task 24, Epoch 107/160 (LR 0.02472) => LSC_loss 0.21, Spatial_loss 2.80, Flat_loss 0.20, Train_acc 96.16, Test_acc 45.83
2025-02-13 19:37:13,570 [podnet.py] => Task 24, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 2.75, Flat_loss 0.19, Train_acc 96.44, Test_acc 47.70
2025-02-13 19:37:15,468 [podnet.py] => Task 24, Epoch 109/160 (LR 0.02304) => LSC_loss 0.22, Spatial_loss 2.74, Flat_loss 0.20, Train_acc 95.92, Test_acc 47.65
2025-02-13 19:37:17,345 [podnet.py] => Task 24, Epoch 110/160 (LR 0.02222) => LSC_loss 0.22, Spatial_loss 2.81, Flat_loss 0.19, Train_acc 96.30, Test_acc 45.97
2025-02-13 19:37:19,206 [podnet.py] => Task 24, Epoch 111/160 (LR 0.02141) => LSC_loss 0.22, Spatial_loss 2.70, Flat_loss 0.19, Train_acc 96.10, Test_acc 46.42
2025-02-13 19:37:21,066 [podnet.py] => Task 24, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 2.59, Flat_loss 0.19, Train_acc 96.44, Test_acc 44.33
2025-02-13 19:37:22,867 [podnet.py] => Task 24, Epoch 113/160 (LR 0.01982) => LSC_loss 0.22, Spatial_loss 2.60, Flat_loss 0.18, Train_acc 96.51, Test_acc 46.67
2025-02-13 19:37:24,745 [podnet.py] => Task 24, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 2.58, Flat_loss 0.19, Train_acc 96.10, Test_acc 45.91
2025-02-13 19:37:26,601 [podnet.py] => Task 24, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 2.48, Flat_loss 0.18, Train_acc 96.37, Test_acc 46.28
2025-02-13 19:37:28,440 [podnet.py] => Task 24, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 2.56, Flat_loss 0.18, Train_acc 96.34, Test_acc 47.09
2025-02-13 19:37:30,341 [podnet.py] => Task 24, Epoch 117/160 (LR 0.01679) => LSC_loss 0.21, Spatial_loss 2.30, Flat_loss 0.17, Train_acc 96.27, Test_acc 47.62
2025-02-13 19:37:32,180 [podnet.py] => Task 24, Epoch 118/160 (LR 0.01606) => LSC_loss 0.23, Spatial_loss 2.36, Flat_loss 0.17, Train_acc 95.75, Test_acc 47.60
2025-02-13 19:37:34,057 [podnet.py] => Task 24, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 2.43, Flat_loss 0.17, Train_acc 96.44, Test_acc 44.08
2025-02-13 19:37:35,935 [podnet.py] => Task 24, Epoch 120/160 (LR 0.01464) => LSC_loss 0.23, Spatial_loss 2.51, Flat_loss 0.18, Train_acc 95.86, Test_acc 47.15
2025-02-13 19:37:37,828 [podnet.py] => Task 24, Epoch 121/160 (LR 0.01396) => LSC_loss 0.21, Spatial_loss 2.59, Flat_loss 0.18, Train_acc 96.34, Test_acc 48.23
2025-02-13 19:37:39,708 [podnet.py] => Task 24, Epoch 122/160 (LR 0.01328) => LSC_loss 0.21, Spatial_loss 2.41, Flat_loss 0.17, Train_acc 96.30, Test_acc 47.49
2025-02-13 19:37:41,577 [podnet.py] => Task 24, Epoch 123/160 (LR 0.01262) => LSC_loss 0.22, Spatial_loss 2.26, Flat_loss 0.16, Train_acc 96.10, Test_acc 46.83
2025-02-13 19:37:43,442 [podnet.py] => Task 24, Epoch 124/160 (LR 0.01198) => LSC_loss 0.21, Spatial_loss 2.35, Flat_loss 0.17, Train_acc 96.78, Test_acc 47.06
2025-02-13 19:37:45,289 [podnet.py] => Task 24, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 2.31, Flat_loss 0.16, Train_acc 96.03, Test_acc 48.37
2025-02-13 19:37:47,113 [podnet.py] => Task 24, Epoch 126/160 (LR 0.01073) => LSC_loss 0.21, Spatial_loss 2.31, Flat_loss 0.16, Train_acc 96.44, Test_acc 47.84
2025-02-13 19:37:48,973 [podnet.py] => Task 24, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 2.30, Flat_loss 0.16, Train_acc 96.13, Test_acc 46.45
2025-02-13 19:37:50,887 [podnet.py] => Task 24, Epoch 128/160 (LR 0.00955) => LSC_loss 0.21, Spatial_loss 2.29, Flat_loss 0.16, Train_acc 96.23, Test_acc 46.84
2025-02-13 19:37:52,772 [podnet.py] => Task 24, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 2.32, Flat_loss 0.16, Train_acc 95.99, Test_acc 48.05
2025-02-13 19:37:54,653 [podnet.py] => Task 24, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 96.71, Test_acc 47.68
2025-02-13 19:37:56,505 [podnet.py] => Task 24, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 2.14, Flat_loss 0.15, Train_acc 96.23, Test_acc 46.80
2025-02-13 19:37:58,362 [podnet.py] => Task 24, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 2.06, Flat_loss 0.15, Train_acc 96.40, Test_acc 47.63
2025-02-13 19:38:00,260 [podnet.py] => Task 24, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 2.16, Flat_loss 0.15, Train_acc 96.06, Test_acc 48.05
2025-02-13 19:38:02,051 [podnet.py] => Task 24, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 96.47, Test_acc 47.36
2025-02-13 19:38:03,908 [podnet.py] => Task 24, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 2.10, Flat_loss 0.15, Train_acc 95.96, Test_acc 46.40
2025-02-13 19:38:05,777 [podnet.py] => Task 24, Epoch 136/160 (LR 0.00545) => LSC_loss 0.21, Spatial_loss 2.12, Flat_loss 0.14, Train_acc 96.16, Test_acc 47.41
2025-02-13 19:38:07,714 [podnet.py] => Task 24, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 2.01, Flat_loss 0.14, Train_acc 96.78, Test_acc 47.59
2025-02-13 19:38:09,571 [podnet.py] => Task 24, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 2.00, Flat_loss 0.14, Train_acc 96.88, Test_acc 47.67
2025-02-13 19:38:11,425 [podnet.py] => Task 24, Epoch 139/160 (LR 0.00419) => LSC_loss 0.22, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 96.44, Test_acc 47.89
2025-02-13 19:38:13,260 [podnet.py] => Task 24, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.97, Flat_loss 0.14, Train_acc 96.40, Test_acc 47.94
2025-02-13 19:38:15,092 [podnet.py] => Task 24, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.99, Flat_loss 0.14, Train_acc 96.23, Test_acc 47.91
2025-02-13 19:38:16,968 [podnet.py] => Task 24, Epoch 142/160 (LR 0.00309) => LSC_loss 0.21, Spatial_loss 1.99, Flat_loss 0.14, Train_acc 96.82, Test_acc 47.78
2025-02-13 19:38:18,854 [podnet.py] => Task 24, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 2.02, Flat_loss 0.14, Train_acc 96.44, Test_acc 47.57
2025-02-13 19:38:20,743 [podnet.py] => Task 24, Epoch 144/160 (LR 0.00245) => LSC_loss 0.21, Spatial_loss 1.96, Flat_loss 0.14, Train_acc 96.30, Test_acc 48.07
2025-02-13 19:38:22,587 [podnet.py] => Task 24, Epoch 145/160 (LR 0.00215) => LSC_loss 0.22, Spatial_loss 1.89, Flat_loss 0.13, Train_acc 95.82, Test_acc 47.81
2025-02-13 19:38:24,417 [podnet.py] => Task 24, Epoch 146/160 (LR 0.00188) => LSC_loss 0.21, Spatial_loss 1.91, Flat_loss 0.13, Train_acc 96.58, Test_acc 47.95
2025-02-13 19:38:26,269 [podnet.py] => Task 24, Epoch 147/160 (LR 0.00162) => LSC_loss 0.22, Spatial_loss 1.94, Flat_loss 0.14, Train_acc 96.27, Test_acc 47.71
2025-02-13 19:38:28,091 [podnet.py] => Task 24, Epoch 148/160 (LR 0.00138) => LSC_loss 0.21, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.34, Test_acc 47.97
2025-02-13 19:38:29,977 [podnet.py] => Task 24, Epoch 149/160 (LR 0.00116) => LSC_loss 0.21, Spatial_loss 1.85, Flat_loss 0.13, Train_acc 96.64, Test_acc 48.04
2025-02-13 19:38:31,833 [podnet.py] => Task 24, Epoch 150/160 (LR 0.00096) => LSC_loss 0.22, Spatial_loss 1.90, Flat_loss 0.14, Train_acc 96.16, Test_acc 47.96
2025-02-13 19:38:33,704 [podnet.py] => Task 24, Epoch 151/160 (LR 0.00078) => LSC_loss 0.22, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 96.06, Test_acc 48.14
2025-02-13 19:38:35,561 [podnet.py] => Task 24, Epoch 152/160 (LR 0.00062) => LSC_loss 0.21, Spatial_loss 1.90, Flat_loss 0.14, Train_acc 96.75, Test_acc 47.91
2025-02-13 19:38:37,521 [podnet.py] => Task 24, Epoch 153/160 (LR 0.00047) => LSC_loss 0.21, Spatial_loss 1.84, Flat_loss 0.13, Train_acc 96.20, Test_acc 47.98
2025-02-13 19:38:39,395 [podnet.py] => Task 24, Epoch 154/160 (LR 0.00035) => LSC_loss 0.21, Spatial_loss 1.84, Flat_loss 0.14, Train_acc 96.37, Test_acc 47.96
2025-02-13 19:38:41,287 [podnet.py] => Task 24, Epoch 155/160 (LR 0.00024) => LSC_loss 0.21, Spatial_loss 1.75, Flat_loss 0.13, Train_acc 96.34, Test_acc 47.88
2025-02-13 19:38:43,188 [podnet.py] => Task 24, Epoch 156/160 (LR 0.00015) => LSC_loss 0.22, Spatial_loss 1.82, Flat_loss 0.13, Train_acc 96.10, Test_acc 48.16
2025-02-13 19:38:45,024 [podnet.py] => Task 24, Epoch 157/160 (LR 0.00009) => LSC_loss 0.22, Spatial_loss 1.87, Flat_loss 0.13, Train_acc 96.51, Test_acc 48.16
2025-02-13 19:38:46,886 [podnet.py] => Task 24, Epoch 158/160 (LR 0.00004) => LSC_loss 0.21, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 96.78, Test_acc 48.11
2025-02-13 19:38:48,729 [podnet.py] => Task 24, Epoch 159/160 (LR 0.00001) => LSC_loss 0.21, Spatial_loss 1.91, Flat_loss 0.13, Train_acc 96.78, Test_acc 47.92
2025-02-13 19:38:50,617 [podnet.py] => Task 24, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 1.80, Flat_loss 0.13, Train_acc 96.47, Test_acc 48.10
2025-02-13 19:38:50,617 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:38:50,617 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:39:22,348 [podnet.py] => The size of finetune dataset: 1960
2025-02-13 19:39:24,018 [podnet.py] => Task 24, Epoch 1/20 (LR 0.00497) => LSC_loss 0.16, Spatial_loss 2.22, Flat_loss 0.13, Train_acc 98.01, Test_acc 48.00
2025-02-13 19:39:25,680 [podnet.py] => Task 24, Epoch 2/20 (LR 0.00488) => LSC_loss 0.13, Spatial_loss 2.04, Flat_loss 0.08, Train_acc 98.72, Test_acc 48.33
2025-02-13 19:39:27,376 [podnet.py] => Task 24, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 2.09, Flat_loss 0.08, Train_acc 98.78, Test_acc 48.49
2025-02-13 19:39:29,007 [podnet.py] => Task 24, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 2.03, Flat_loss 0.08, Train_acc 98.62, Test_acc 48.68
2025-02-13 19:39:30,671 [podnet.py] => Task 24, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 2.03, Flat_loss 0.08, Train_acc 98.72, Test_acc 47.95
2025-02-13 19:39:32,369 [podnet.py] => Task 24, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 1.97, Flat_loss 0.07, Train_acc 98.78, Test_acc 48.45
2025-02-13 19:39:34,026 [podnet.py] => Task 24, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 98.98, Test_acc 48.48
2025-02-13 19:39:35,689 [podnet.py] => Task 24, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 1.92, Flat_loss 0.07, Train_acc 98.83, Test_acc 48.74
2025-02-13 19:39:37,423 [podnet.py] => Task 24, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 2.05, Flat_loss 0.08, Train_acc 98.88, Test_acc 48.79
2025-02-13 19:39:39,047 [podnet.py] => Task 24, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 1.88, Flat_loss 0.07, Train_acc 98.98, Test_acc 49.02
2025-02-13 19:39:40,707 [podnet.py] => Task 24, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 98.78, Test_acc 48.65
2025-02-13 19:39:42,368 [podnet.py] => Task 24, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 1.92, Flat_loss 0.07, Train_acc 98.62, Test_acc 48.84
2025-02-13 19:39:43,991 [podnet.py] => Task 24, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 1.97, Flat_loss 0.07, Train_acc 99.23, Test_acc 48.64
2025-02-13 19:39:45,673 [podnet.py] => Task 24, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 1.96, Flat_loss 0.07, Train_acc 98.93, Test_acc 48.66
2025-02-13 19:39:47,371 [podnet.py] => Task 24, Epoch 15/20 (LR 0.00073) => LSC_loss 0.13, Spatial_loss 1.93, Flat_loss 0.07, Train_acc 98.57, Test_acc 48.83
2025-02-13 19:39:49,058 [podnet.py] => Task 24, Epoch 16/20 (LR 0.00048) => LSC_loss 0.13, Spatial_loss 1.90, Flat_loss 0.07, Train_acc 98.62, Test_acc 48.98
2025-02-13 19:39:50,766 [podnet.py] => Task 24, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.78, Test_acc 48.89
2025-02-13 19:39:52,354 [podnet.py] => Task 24, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 1.77, Flat_loss 0.06, Train_acc 98.62, Test_acc 48.99
2025-02-13 19:39:53,981 [podnet.py] => Task 24, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 1.78, Flat_loss 0.07, Train_acc 98.88, Test_acc 48.97
2025-02-13 19:39:55,619 [podnet.py] => Task 24, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 1.81, Flat_loss 0.06, Train_acc 98.98, Test_acc 48.91
2025-02-13 19:39:55,620 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:40:28,777 [podnet.py] => Exemplar size: 1960
2025-02-13 19:40:28,777 [trainer.py] => CNN: {'total': 48.91, '00-09': 56.9, '10-19': 37.8, '20-29': 57.3, '30-39': 46.1, '40-49': 53.6, '50-59': 33.8, '60-69': 46.3, '70-79': 49.6, '80-89': 54.4, '90-99': 54.38, 'old': 48.68, 'new': 60.0}
2025-02-13 19:40:28,777 [trainer.py] => NME: {'total': 48.5, '00-09': 60.9, '10-19': 40.4, '20-29': 59.0, '30-39': 49.2, '40-49': 53.6, '50-59': 29.9, '60-69': 45.0, '70-79': 49.0, '80-89': 49.8, '90-99': 48.12, 'old': 48.4, 'new': 53.5}
2025-02-13 19:40:28,777 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29, 50.72, 49.73, 49.04, 48.91]
2025-02-13 19:40:28,778 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13, 77.38, 76.49, 75.92, 75.18]
2025-02-13 19:40:28,778 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26, 51.04, 49.72, 49.07, 48.5]
2025-02-13 19:40:28,778 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44, 77.97, 77.11, 76.41, 76.11]

2025-02-13 19:40:28,778 [trainer.py] => Average Accuracy (CNN): 60.41839999999999
2025-02-13 19:40:28,778 [trainer.py] => Average Accuracy (NME): 60.574799999999996
2025-02-13 19:40:28,778 [trainer.py] => All params: 528977
2025-02-13 19:40:28,778 [trainer.py] => Trainable params: 528977
2025-02-13 19:40:28,779 [podnet.py] => Learning on 98-100
2025-02-13 19:40:28,803 [podnet.py] => Adaptive factor: 7.0710678118654755
2025-02-13 19:40:30,725 [podnet.py] => Task 25, Epoch 1/160 (LR 0.09999) => LSC_loss 1.08, Spatial_loss 4.69, Flat_loss 0.61, Train_acc 82.70, Test_acc 32.70
2025-02-13 19:40:32,652 [podnet.py] => Task 25, Epoch 2/160 (LR 0.09996) => LSC_loss 0.82, Spatial_loss 7.24, Flat_loss 1.06, Train_acc 79.26, Test_acc 32.86
2025-02-13 19:40:34,571 [podnet.py] => Task 25, Epoch 3/160 (LR 0.09991) => LSC_loss 0.88, Spatial_loss 7.79, Flat_loss 1.19, Train_acc 78.01, Test_acc 33.56
2025-02-13 19:40:36,464 [podnet.py] => Task 25, Epoch 4/160 (LR 0.09985) => LSC_loss 0.95, Spatial_loss 8.29, Flat_loss 1.29, Train_acc 75.24, Test_acc 33.08
2025-02-13 19:40:38,392 [podnet.py] => Task 25, Epoch 5/160 (LR 0.09976) => LSC_loss 0.83, Spatial_loss 7.75, Flat_loss 1.15, Train_acc 77.16, Test_acc 32.96
2025-02-13 19:40:40,325 [podnet.py] => Task 25, Epoch 6/160 (LR 0.09965) => LSC_loss 0.65, Spatial_loss 7.27, Flat_loss 1.00, Train_acc 82.03, Test_acc 40.49
2025-02-13 19:40:42,269 [podnet.py] => Task 25, Epoch 7/160 (LR 0.09953) => LSC_loss 0.59, Spatial_loss 6.68, Flat_loss 0.85, Train_acc 85.98, Test_acc 37.90
2025-02-13 19:40:44,205 [podnet.py] => Task 25, Epoch 8/160 (LR 0.09938) => LSC_loss 0.56, Spatial_loss 6.81, Flat_loss 0.85, Train_acc 85.57, Test_acc 38.60
2025-02-13 19:40:46,135 [podnet.py] => Task 25, Epoch 9/160 (LR 0.09922) => LSC_loss 0.54, Spatial_loss 6.44, Flat_loss 0.79, Train_acc 86.42, Test_acc 41.51
2025-02-13 19:40:48,004 [podnet.py] => Task 25, Epoch 10/160 (LR 0.09904) => LSC_loss 0.43, Spatial_loss 6.12, Flat_loss 0.69, Train_acc 89.66, Test_acc 40.79
2025-02-13 19:40:49,872 [podnet.py] => Task 25, Epoch 11/160 (LR 0.09884) => LSC_loss 0.45, Spatial_loss 5.78, Flat_loss 0.63, Train_acc 88.92, Test_acc 36.60
2025-02-13 19:40:51,804 [podnet.py] => Task 25, Epoch 12/160 (LR 0.09862) => LSC_loss 0.43, Spatial_loss 5.72, Flat_loss 0.62, Train_acc 90.30, Test_acc 42.68
2025-02-13 19:40:53,677 [podnet.py] => Task 25, Epoch 13/160 (LR 0.09838) => LSC_loss 0.40, Spatial_loss 5.64, Flat_loss 0.59, Train_acc 91.25, Test_acc 38.81
2025-02-13 19:40:55,604 [podnet.py] => Task 25, Epoch 14/160 (LR 0.09812) => LSC_loss 0.40, Spatial_loss 5.73, Flat_loss 0.62, Train_acc 90.61, Test_acc 40.01
2025-02-13 19:40:57,572 [podnet.py] => Task 25, Epoch 15/160 (LR 0.09785) => LSC_loss 0.39, Spatial_loss 5.36, Flat_loss 0.55, Train_acc 91.72, Test_acc 41.87
2025-02-13 19:40:59,541 [podnet.py] => Task 25, Epoch 16/160 (LR 0.09755) => LSC_loss 0.40, Spatial_loss 5.68, Flat_loss 0.61, Train_acc 90.78, Test_acc 42.24
2025-02-13 19:41:01,500 [podnet.py] => Task 25, Epoch 17/160 (LR 0.09724) => LSC_loss 0.39, Spatial_loss 5.36, Flat_loss 0.54, Train_acc 91.79, Test_acc 41.09
2025-02-13 19:41:03,364 [podnet.py] => Task 25, Epoch 18/160 (LR 0.09691) => LSC_loss 0.37, Spatial_loss 5.45, Flat_loss 0.55, Train_acc 91.55, Test_acc 38.41
2025-02-13 19:41:05,283 [podnet.py] => Task 25, Epoch 19/160 (LR 0.09656) => LSC_loss 0.38, Spatial_loss 5.43, Flat_loss 0.55, Train_acc 91.11, Test_acc 35.90
2025-02-13 19:41:07,236 [podnet.py] => Task 25, Epoch 20/160 (LR 0.09619) => LSC_loss 0.38, Spatial_loss 5.53, Flat_loss 0.56, Train_acc 92.03, Test_acc 41.86
2025-02-13 19:41:09,201 [podnet.py] => Task 25, Epoch 21/160 (LR 0.09581) => LSC_loss 0.37, Spatial_loss 5.50, Flat_loss 0.56, Train_acc 91.86, Test_acc 41.27
2025-02-13 19:41:11,086 [podnet.py] => Task 25, Epoch 22/160 (LR 0.09541) => LSC_loss 0.36, Spatial_loss 5.27, Flat_loss 0.53, Train_acc 92.13, Test_acc 36.22
2025-02-13 19:41:12,949 [podnet.py] => Task 25, Epoch 23/160 (LR 0.09499) => LSC_loss 0.37, Spatial_loss 5.23, Flat_loss 0.52, Train_acc 92.57, Test_acc 33.69
2025-02-13 19:41:14,849 [podnet.py] => Task 25, Epoch 24/160 (LR 0.09455) => LSC_loss 0.45, Spatial_loss 5.80, Flat_loss 0.65, Train_acc 89.05, Test_acc 39.16
2025-02-13 19:41:16,719 [podnet.py] => Task 25, Epoch 25/160 (LR 0.09410) => LSC_loss 0.42, Spatial_loss 5.71, Flat_loss 0.63, Train_acc 89.90, Test_acc 39.66
2025-02-13 19:41:18,679 [podnet.py] => Task 25, Epoch 26/160 (LR 0.09362) => LSC_loss 0.38, Spatial_loss 5.45, Flat_loss 0.56, Train_acc 91.08, Test_acc 41.00
2025-02-13 19:41:20,559 [podnet.py] => Task 25, Epoch 27/160 (LR 0.09314) => LSC_loss 0.35, Spatial_loss 5.35, Flat_loss 0.56, Train_acc 91.93, Test_acc 39.62
2025-02-13 19:41:22,499 [podnet.py] => Task 25, Epoch 28/160 (LR 0.09263) => LSC_loss 0.35, Spatial_loss 5.30, Flat_loss 0.52, Train_acc 92.33, Test_acc 38.68
2025-02-13 19:41:24,414 [podnet.py] => Task 25, Epoch 29/160 (LR 0.09211) => LSC_loss 0.33, Spatial_loss 5.19, Flat_loss 0.50, Train_acc 93.38, Test_acc 38.80
2025-02-13 19:41:26,266 [podnet.py] => Task 25, Epoch 30/160 (LR 0.09157) => LSC_loss 0.32, Spatial_loss 5.05, Flat_loss 0.47, Train_acc 93.41, Test_acc 42.11
2025-02-13 19:41:28,192 [podnet.py] => Task 25, Epoch 31/160 (LR 0.09102) => LSC_loss 0.33, Spatial_loss 5.09, Flat_loss 0.49, Train_acc 93.21, Test_acc 42.29
2025-02-13 19:41:30,141 [podnet.py] => Task 25, Epoch 32/160 (LR 0.09045) => LSC_loss 0.32, Spatial_loss 4.85, Flat_loss 0.45, Train_acc 93.21, Test_acc 44.22
2025-02-13 19:41:32,017 [podnet.py] => Task 25, Epoch 33/160 (LR 0.08987) => LSC_loss 0.32, Spatial_loss 4.98, Flat_loss 0.46, Train_acc 93.48, Test_acc 39.48
2025-02-13 19:41:33,944 [podnet.py] => Task 25, Epoch 34/160 (LR 0.08927) => LSC_loss 0.38, Spatial_loss 5.14, Flat_loss 0.50, Train_acc 92.23, Test_acc 36.07
2025-02-13 19:41:35,913 [podnet.py] => Task 25, Epoch 35/160 (LR 0.08865) => LSC_loss 0.35, Spatial_loss 5.06, Flat_loss 0.53, Train_acc 92.20, Test_acc 40.91
2025-02-13 19:41:37,835 [podnet.py] => Task 25, Epoch 36/160 (LR 0.08802) => LSC_loss 0.36, Spatial_loss 5.04, Flat_loss 0.49, Train_acc 92.13, Test_acc 43.79
2025-02-13 19:41:39,698 [podnet.py] => Task 25, Epoch 37/160 (LR 0.08738) => LSC_loss 0.34, Spatial_loss 5.03, Flat_loss 0.48, Train_acc 93.21, Test_acc 40.31
2025-02-13 19:41:41,636 [podnet.py] => Task 25, Epoch 38/160 (LR 0.08672) => LSC_loss 0.33, Spatial_loss 4.93, Flat_loss 0.47, Train_acc 92.53, Test_acc 43.28
2025-02-13 19:41:43,590 [podnet.py] => Task 25, Epoch 39/160 (LR 0.08604) => LSC_loss 0.29, Spatial_loss 4.72, Flat_loss 0.44, Train_acc 93.78, Test_acc 39.14
2025-02-13 19:41:45,477 [podnet.py] => Task 25, Epoch 40/160 (LR 0.08536) => LSC_loss 0.30, Spatial_loss 4.67, Flat_loss 0.42, Train_acc 93.99, Test_acc 43.35
2025-02-13 19:41:47,391 [podnet.py] => Task 25, Epoch 41/160 (LR 0.08465) => LSC_loss 0.29, Spatial_loss 4.50, Flat_loss 0.40, Train_acc 93.95, Test_acc 44.24
2025-02-13 19:41:49,282 [podnet.py] => Task 25, Epoch 42/160 (LR 0.08394) => LSC_loss 0.29, Spatial_loss 4.58, Flat_loss 0.41, Train_acc 94.19, Test_acc 39.10
2025-02-13 19:41:51,223 [podnet.py] => Task 25, Epoch 43/160 (LR 0.08321) => LSC_loss 0.34, Spatial_loss 4.77, Flat_loss 0.45, Train_acc 93.38, Test_acc 42.70
2025-02-13 19:41:53,121 [podnet.py] => Task 25, Epoch 44/160 (LR 0.08247) => LSC_loss 0.30, Spatial_loss 5.00, Flat_loss 0.48, Train_acc 93.95, Test_acc 37.88
2025-02-13 19:41:55,016 [podnet.py] => Task 25, Epoch 45/160 (LR 0.08172) => LSC_loss 0.33, Spatial_loss 5.01, Flat_loss 0.47, Train_acc 92.97, Test_acc 40.08
2025-02-13 19:41:56,956 [podnet.py] => Task 25, Epoch 46/160 (LR 0.08095) => LSC_loss 0.31, Spatial_loss 4.87, Flat_loss 0.45, Train_acc 93.38, Test_acc 43.28
2025-02-13 19:41:58,875 [podnet.py] => Task 25, Epoch 47/160 (LR 0.08018) => LSC_loss 0.29, Spatial_loss 4.62, Flat_loss 0.43, Train_acc 94.53, Test_acc 38.25
2025-02-13 19:42:00,787 [podnet.py] => Task 25, Epoch 48/160 (LR 0.07939) => LSC_loss 0.29, Spatial_loss 4.53, Flat_loss 0.42, Train_acc 93.92, Test_acc 41.66
2025-02-13 19:42:02,654 [podnet.py] => Task 25, Epoch 49/160 (LR 0.07859) => LSC_loss 0.28, Spatial_loss 4.58, Flat_loss 0.40, Train_acc 93.85, Test_acc 42.01
2025-02-13 19:42:04,536 [podnet.py] => Task 25, Epoch 50/160 (LR 0.07778) => LSC_loss 0.29, Spatial_loss 4.52, Flat_loss 0.40, Train_acc 93.78, Test_acc 43.38
2025-02-13 19:42:06,518 [podnet.py] => Task 25, Epoch 51/160 (LR 0.07696) => LSC_loss 0.28, Spatial_loss 4.51, Flat_loss 0.38, Train_acc 94.29, Test_acc 41.52
2025-02-13 19:42:08,435 [podnet.py] => Task 25, Epoch 52/160 (LR 0.07612) => LSC_loss 0.27, Spatial_loss 4.59, Flat_loss 0.41, Train_acc 94.93, Test_acc 45.84
2025-02-13 19:42:10,398 [podnet.py] => Task 25, Epoch 53/160 (LR 0.07528) => LSC_loss 0.29, Spatial_loss 4.49, Flat_loss 0.39, Train_acc 93.24, Test_acc 42.19
2025-02-13 19:42:12,364 [podnet.py] => Task 25, Epoch 54/160 (LR 0.07443) => LSC_loss 0.27, Spatial_loss 4.41, Flat_loss 0.38, Train_acc 94.12, Test_acc 46.49
2025-02-13 19:42:14,267 [podnet.py] => Task 25, Epoch 55/160 (LR 0.07357) => LSC_loss 0.29, Spatial_loss 4.27, Flat_loss 0.37, Train_acc 93.78, Test_acc 37.38
2025-02-13 19:42:16,217 [podnet.py] => Task 25, Epoch 56/160 (LR 0.07270) => LSC_loss 0.28, Spatial_loss 4.47, Flat_loss 0.40, Train_acc 94.39, Test_acc 44.94
2025-02-13 19:42:18,096 [podnet.py] => Task 25, Epoch 57/160 (LR 0.07182) => LSC_loss 0.29, Spatial_loss 4.42, Flat_loss 0.40, Train_acc 94.12, Test_acc 43.94
2025-02-13 19:42:20,041 [podnet.py] => Task 25, Epoch 58/160 (LR 0.07093) => LSC_loss 0.29, Spatial_loss 4.42, Flat_loss 0.40, Train_acc 94.16, Test_acc 43.18
2025-02-13 19:42:22,004 [podnet.py] => Task 25, Epoch 59/160 (LR 0.07004) => LSC_loss 0.28, Spatial_loss 4.49, Flat_loss 0.40, Train_acc 94.36, Test_acc 41.73
2025-02-13 19:42:23,868 [podnet.py] => Task 25, Epoch 60/160 (LR 0.06913) => LSC_loss 0.30, Spatial_loss 4.40, Flat_loss 0.40, Train_acc 94.22, Test_acc 43.89
2025-02-13 19:42:25,743 [podnet.py] => Task 25, Epoch 61/160 (LR 0.06822) => LSC_loss 0.30, Spatial_loss 4.51, Flat_loss 0.41, Train_acc 93.61, Test_acc 43.57
2025-02-13 19:42:27,674 [podnet.py] => Task 25, Epoch 62/160 (LR 0.06731) => LSC_loss 0.25, Spatial_loss 4.29, Flat_loss 0.38, Train_acc 95.24, Test_acc 44.68
2025-02-13 19:42:29,593 [podnet.py] => Task 25, Epoch 63/160 (LR 0.06638) => LSC_loss 0.26, Spatial_loss 4.13, Flat_loss 0.35, Train_acc 95.17, Test_acc 44.03
2025-02-13 19:42:31,533 [podnet.py] => Task 25, Epoch 64/160 (LR 0.06545) => LSC_loss 0.30, Spatial_loss 4.24, Flat_loss 0.35, Train_acc 93.99, Test_acc 41.19
2025-02-13 19:42:33,482 [podnet.py] => Task 25, Epoch 65/160 (LR 0.06451) => LSC_loss 0.28, Spatial_loss 4.53, Flat_loss 0.40, Train_acc 94.29, Test_acc 44.61
2025-02-13 19:42:35,373 [podnet.py] => Task 25, Epoch 66/160 (LR 0.06357) => LSC_loss 0.25, Spatial_loss 4.21, Flat_loss 0.37, Train_acc 95.17, Test_acc 43.42
2025-02-13 19:42:37,313 [podnet.py] => Task 25, Epoch 67/160 (LR 0.06262) => LSC_loss 0.28, Spatial_loss 4.07, Flat_loss 0.35, Train_acc 94.90, Test_acc 42.97
2025-02-13 19:42:39,238 [podnet.py] => Task 25, Epoch 68/160 (LR 0.06167) => LSC_loss 0.27, Spatial_loss 4.29, Flat_loss 0.37, Train_acc 94.29, Test_acc 42.73
2025-02-13 19:42:41,154 [podnet.py] => Task 25, Epoch 69/160 (LR 0.06072) => LSC_loss 0.27, Spatial_loss 4.33, Flat_loss 0.37, Train_acc 94.90, Test_acc 41.88
2025-02-13 19:42:43,104 [podnet.py] => Task 25, Epoch 70/160 (LR 0.05975) => LSC_loss 0.28, Spatial_loss 4.19, Flat_loss 0.36, Train_acc 93.75, Test_acc 43.78
2025-02-13 19:42:44,987 [podnet.py] => Task 25, Epoch 71/160 (LR 0.05879) => LSC_loss 0.28, Spatial_loss 3.96, Flat_loss 0.32, Train_acc 94.63, Test_acc 45.89
2025-02-13 19:42:46,877 [podnet.py] => Task 25, Epoch 72/160 (LR 0.05782) => LSC_loss 0.28, Spatial_loss 4.16, Flat_loss 0.36, Train_acc 95.03, Test_acc 44.66
2025-02-13 19:42:48,862 [podnet.py] => Task 25, Epoch 73/160 (LR 0.05685) => LSC_loss 0.31, Spatial_loss 4.39, Flat_loss 0.40, Train_acc 94.66, Test_acc 43.63
2025-02-13 19:42:50,768 [podnet.py] => Task 25, Epoch 74/160 (LR 0.05588) => LSC_loss 0.29, Spatial_loss 4.36, Flat_loss 0.39, Train_acc 94.36, Test_acc 41.24
2025-02-13 19:42:52,659 [podnet.py] => Task 25, Epoch 75/160 (LR 0.05490) => LSC_loss 0.29, Spatial_loss 4.25, Flat_loss 0.39, Train_acc 94.02, Test_acc 41.27
2025-02-13 19:42:54,537 [podnet.py] => Task 25, Epoch 76/160 (LR 0.05392) => LSC_loss 0.27, Spatial_loss 4.27, Flat_loss 0.37, Train_acc 94.56, Test_acc 45.33
2025-02-13 19:42:56,453 [podnet.py] => Task 25, Epoch 77/160 (LR 0.05294) => LSC_loss 0.26, Spatial_loss 4.03, Flat_loss 0.34, Train_acc 95.10, Test_acc 43.54
2025-02-13 19:42:58,362 [podnet.py] => Task 25, Epoch 78/160 (LR 0.05196) => LSC_loss 0.26, Spatial_loss 4.09, Flat_loss 0.34, Train_acc 94.80, Test_acc 46.11
2025-02-13 19:43:00,347 [podnet.py] => Task 25, Epoch 79/160 (LR 0.05098) => LSC_loss 0.26, Spatial_loss 3.94, Flat_loss 0.31, Train_acc 95.07, Test_acc 45.13
2025-02-13 19:43:02,292 [podnet.py] => Task 25, Epoch 80/160 (LR 0.05000) => LSC_loss 0.26, Spatial_loss 4.15, Flat_loss 0.36, Train_acc 94.76, Test_acc 45.49
2025-02-13 19:43:04,175 [podnet.py] => Task 25, Epoch 81/160 (LR 0.04902) => LSC_loss 0.24, Spatial_loss 3.74, Flat_loss 0.30, Train_acc 95.88, Test_acc 45.47
2025-02-13 19:43:06,107 [podnet.py] => Task 25, Epoch 82/160 (LR 0.04804) => LSC_loss 0.27, Spatial_loss 3.85, Flat_loss 0.31, Train_acc 95.30, Test_acc 45.33
2025-02-13 19:43:08,050 [podnet.py] => Task 25, Epoch 83/160 (LR 0.04706) => LSC_loss 0.28, Spatial_loss 3.86, Flat_loss 0.33, Train_acc 94.59, Test_acc 40.52
2025-02-13 19:43:09,922 [podnet.py] => Task 25, Epoch 84/160 (LR 0.04608) => LSC_loss 0.26, Spatial_loss 3.80, Flat_loss 0.31, Train_acc 95.57, Test_acc 45.05
2025-02-13 19:43:11,912 [podnet.py] => Task 25, Epoch 85/160 (LR 0.04510) => LSC_loss 0.26, Spatial_loss 3.63, Flat_loss 0.29, Train_acc 94.83, Test_acc 44.05
2025-02-13 19:43:13,827 [podnet.py] => Task 25, Epoch 86/160 (LR 0.04412) => LSC_loss 0.25, Spatial_loss 3.78, Flat_loss 0.31, Train_acc 95.30, Test_acc 41.54
2025-02-13 19:43:15,706 [podnet.py] => Task 25, Epoch 87/160 (LR 0.04315) => LSC_loss 0.24, Spatial_loss 3.62, Flat_loss 0.29, Train_acc 95.27, Test_acc 41.71
2025-02-13 19:43:17,657 [podnet.py] => Task 25, Epoch 88/160 (LR 0.04218) => LSC_loss 0.25, Spatial_loss 3.73, Flat_loss 0.28, Train_acc 95.41, Test_acc 43.93
2025-02-13 19:43:19,540 [podnet.py] => Task 25, Epoch 89/160 (LR 0.04121) => LSC_loss 0.25, Spatial_loss 3.65, Flat_loss 0.30, Train_acc 95.64, Test_acc 46.11
2025-02-13 19:43:21,444 [podnet.py] => Task 25, Epoch 90/160 (LR 0.04025) => LSC_loss 0.25, Spatial_loss 3.62, Flat_loss 0.28, Train_acc 95.34, Test_acc 46.17
2025-02-13 19:43:23,370 [podnet.py] => Task 25, Epoch 91/160 (LR 0.03928) => LSC_loss 0.27, Spatial_loss 3.45, Flat_loss 0.27, Train_acc 95.47, Test_acc 39.76
2025-02-13 19:43:25,260 [podnet.py] => Task 25, Epoch 92/160 (LR 0.03833) => LSC_loss 0.25, Spatial_loss 3.73, Flat_loss 0.31, Train_acc 95.30, Test_acc 43.51
2025-02-13 19:43:27,194 [podnet.py] => Task 25, Epoch 93/160 (LR 0.03738) => LSC_loss 0.24, Spatial_loss 3.72, Flat_loss 0.29, Train_acc 95.68, Test_acc 45.23
2025-02-13 19:43:29,060 [podnet.py] => Task 25, Epoch 94/160 (LR 0.03643) => LSC_loss 0.25, Spatial_loss 3.59, Flat_loss 0.27, Train_acc 96.11, Test_acc 43.78
2025-02-13 19:43:31,038 [podnet.py] => Task 25, Epoch 95/160 (LR 0.03549) => LSC_loss 0.25, Spatial_loss 3.59, Flat_loss 0.28, Train_acc 95.61, Test_acc 45.75
2025-02-13 19:43:32,924 [podnet.py] => Task 25, Epoch 96/160 (LR 0.03455) => LSC_loss 0.26, Spatial_loss 3.51, Flat_loss 0.28, Train_acc 94.80, Test_acc 43.77
2025-02-13 19:43:34,826 [podnet.py] => Task 25, Epoch 97/160 (LR 0.03362) => LSC_loss 0.23, Spatial_loss 3.54, Flat_loss 0.28, Train_acc 96.01, Test_acc 46.55
2025-02-13 19:43:36,730 [podnet.py] => Task 25, Epoch 98/160 (LR 0.03269) => LSC_loss 0.24, Spatial_loss 3.43, Flat_loss 0.26, Train_acc 95.64, Test_acc 45.79
2025-02-13 19:43:38,667 [podnet.py] => Task 25, Epoch 99/160 (LR 0.03178) => LSC_loss 0.23, Spatial_loss 3.47, Flat_loss 0.25, Train_acc 96.01, Test_acc 45.97
2025-02-13 19:43:40,589 [podnet.py] => Task 25, Epoch 100/160 (LR 0.03087) => LSC_loss 0.24, Spatial_loss 3.36, Flat_loss 0.25, Train_acc 95.44, Test_acc 45.09
2025-02-13 19:43:42,526 [podnet.py] => Task 25, Epoch 101/160 (LR 0.02996) => LSC_loss 0.25, Spatial_loss 3.32, Flat_loss 0.24, Train_acc 95.37, Test_acc 43.07
2025-02-13 19:43:44,457 [podnet.py] => Task 25, Epoch 102/160 (LR 0.02907) => LSC_loss 0.25, Spatial_loss 3.29, Flat_loss 0.26, Train_acc 95.57, Test_acc 43.98
2025-02-13 19:43:46,370 [podnet.py] => Task 25, Epoch 103/160 (LR 0.02818) => LSC_loss 0.24, Spatial_loss 3.22, Flat_loss 0.25, Train_acc 95.64, Test_acc 44.85
2025-02-13 19:43:48,303 [podnet.py] => Task 25, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 3.19, Flat_loss 0.24, Train_acc 96.08, Test_acc 46.93
2025-02-13 19:43:50,136 [podnet.py] => Task 25, Epoch 105/160 (LR 0.02643) => LSC_loss 0.25, Spatial_loss 3.25, Flat_loss 0.24, Train_acc 95.61, Test_acc 44.22
2025-02-13 19:43:52,052 [podnet.py] => Task 25, Epoch 106/160 (LR 0.02557) => LSC_loss 0.25, Spatial_loss 3.33, Flat_loss 0.24, Train_acc 95.57, Test_acc 45.56
2025-02-13 19:43:54,005 [podnet.py] => Task 25, Epoch 107/160 (LR 0.02472) => LSC_loss 0.24, Spatial_loss 3.17, Flat_loss 0.23, Train_acc 95.64, Test_acc 45.85
2025-02-13 19:43:55,914 [podnet.py] => Task 25, Epoch 108/160 (LR 0.02388) => LSC_loss 0.23, Spatial_loss 3.02, Flat_loss 0.23, Train_acc 95.95, Test_acc 46.24
2025-02-13 19:43:57,820 [podnet.py] => Task 25, Epoch 109/160 (LR 0.02304) => LSC_loss 0.24, Spatial_loss 3.05, Flat_loss 0.21, Train_acc 95.78, Test_acc 46.19
2025-02-13 19:43:59,752 [podnet.py] => Task 25, Epoch 110/160 (LR 0.02222) => LSC_loss 0.24, Spatial_loss 2.97, Flat_loss 0.21, Train_acc 95.71, Test_acc 45.32
2025-02-13 19:44:01,609 [podnet.py] => Task 25, Epoch 111/160 (LR 0.02141) => LSC_loss 0.22, Spatial_loss 2.91, Flat_loss 0.21, Train_acc 95.95, Test_acc 47.60
2025-02-13 19:44:03,499 [podnet.py] => Task 25, Epoch 112/160 (LR 0.02061) => LSC_loss 0.22, Spatial_loss 2.85, Flat_loss 0.20, Train_acc 96.18, Test_acc 45.32
2025-02-13 19:44:05,377 [podnet.py] => Task 25, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 2.97, Flat_loss 0.21, Train_acc 95.81, Test_acc 46.37
2025-02-13 19:44:07,314 [podnet.py] => Task 25, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 2.92, Flat_loss 0.21, Train_acc 96.11, Test_acc 46.68
2025-02-13 19:44:09,249 [podnet.py] => Task 25, Epoch 115/160 (LR 0.01828) => LSC_loss 0.23, Spatial_loss 2.95, Flat_loss 0.22, Train_acc 95.71, Test_acc 44.47
2025-02-13 19:44:11,147 [podnet.py] => Task 25, Epoch 116/160 (LR 0.01753) => LSC_loss 0.23, Spatial_loss 2.84, Flat_loss 0.20, Train_acc 95.95, Test_acc 44.92
2025-02-13 19:44:13,101 [podnet.py] => Task 25, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 2.81, Flat_loss 0.20, Train_acc 95.81, Test_acc 47.16
2025-02-13 19:44:15,040 [podnet.py] => Task 25, Epoch 118/160 (LR 0.01606) => LSC_loss 0.23, Spatial_loss 2.82, Flat_loss 0.21, Train_acc 95.95, Test_acc 46.86
2025-02-13 19:44:16,964 [podnet.py] => Task 25, Epoch 119/160 (LR 0.01535) => LSC_loss 0.23, Spatial_loss 2.83, Flat_loss 0.20, Train_acc 95.95, Test_acc 45.83
2025-02-13 19:44:18,865 [podnet.py] => Task 25, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 2.71, Flat_loss 0.19, Train_acc 95.98, Test_acc 46.82
2025-02-13 19:44:20,771 [podnet.py] => Task 25, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 2.72, Flat_loss 0.19, Train_acc 95.98, Test_acc 46.35
2025-02-13 19:44:22,711 [podnet.py] => Task 25, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 2.69, Flat_loss 0.19, Train_acc 95.64, Test_acc 47.64
2025-02-13 19:44:24,680 [podnet.py] => Task 25, Epoch 123/160 (LR 0.01262) => LSC_loss 0.24, Spatial_loss 2.66, Flat_loss 0.19, Train_acc 95.61, Test_acc 46.63
2025-02-13 19:44:26,565 [podnet.py] => Task 25, Epoch 124/160 (LR 0.01198) => LSC_loss 0.23, Spatial_loss 2.64, Flat_loss 0.19, Train_acc 95.95, Test_acc 46.21
2025-02-13 19:44:28,513 [podnet.py] => Task 25, Epoch 125/160 (LR 0.01135) => LSC_loss 0.24, Spatial_loss 2.63, Flat_loss 0.19, Train_acc 95.44, Test_acc 46.57
2025-02-13 19:44:30,395 [podnet.py] => Task 25, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 2.66, Flat_loss 0.18, Train_acc 96.01, Test_acc 46.79
2025-02-13 19:44:32,299 [podnet.py] => Task 25, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 2.59, Flat_loss 0.18, Train_acc 96.25, Test_acc 46.47
2025-02-13 19:44:34,248 [podnet.py] => Task 25, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 2.60, Flat_loss 0.19, Train_acc 96.28, Test_acc 45.91
2025-02-13 19:44:36,098 [podnet.py] => Task 25, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 2.58, Flat_loss 0.17, Train_acc 95.81, Test_acc 46.96
2025-02-13 19:44:37,978 [podnet.py] => Task 25, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 2.55, Flat_loss 0.18, Train_acc 95.74, Test_acc 45.84
2025-02-13 19:44:39,874 [podnet.py] => Task 25, Epoch 131/160 (LR 0.00789) => LSC_loss 0.24, Spatial_loss 2.54, Flat_loss 0.18, Train_acc 96.15, Test_acc 46.77
2025-02-13 19:44:41,804 [podnet.py] => Task 25, Epoch 132/160 (LR 0.00737) => LSC_loss 0.23, Spatial_loss 2.56, Flat_loss 0.18, Train_acc 96.01, Test_acc 47.55
2025-02-13 19:44:43,715 [podnet.py] => Task 25, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 2.41, Flat_loss 0.17, Train_acc 95.91, Test_acc 47.27
2025-02-13 19:44:45,633 [podnet.py] => Task 25, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 2.40, Flat_loss 0.16, Train_acc 96.01, Test_acc 47.67
2025-02-13 19:44:47,532 [podnet.py] => Task 25, Epoch 135/160 (LR 0.00590) => LSC_loss 0.23, Spatial_loss 2.37, Flat_loss 0.16, Train_acc 95.81, Test_acc 46.86
2025-02-13 19:44:49,383 [podnet.py] => Task 25, Epoch 136/160 (LR 0.00545) => LSC_loss 0.23, Spatial_loss 2.37, Flat_loss 0.17, Train_acc 96.25, Test_acc 46.78
2025-02-13 19:44:51,289 [podnet.py] => Task 25, Epoch 137/160 (LR 0.00501) => LSC_loss 0.22, Spatial_loss 2.33, Flat_loss 0.16, Train_acc 95.88, Test_acc 47.57
2025-02-13 19:44:53,180 [podnet.py] => Task 25, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 2.33, Flat_loss 0.16, Train_acc 96.45, Test_acc 47.09
2025-02-13 19:44:55,102 [podnet.py] => Task 25, Epoch 139/160 (LR 0.00419) => LSC_loss 0.24, Spatial_loss 2.38, Flat_loss 0.16, Train_acc 95.68, Test_acc 47.06
2025-02-13 19:44:57,025 [podnet.py] => Task 25, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 2.32, Flat_loss 0.17, Train_acc 96.35, Test_acc 47.15
2025-02-13 19:44:59,010 [podnet.py] => Task 25, Epoch 141/160 (LR 0.00344) => LSC_loss 0.23, Spatial_loss 2.27, Flat_loss 0.15, Train_acc 95.81, Test_acc 46.93
2025-02-13 19:45:00,907 [podnet.py] => Task 25, Epoch 142/160 (LR 0.00309) => LSC_loss 0.22, Spatial_loss 2.28, Flat_loss 0.16, Train_acc 96.05, Test_acc 46.95
2025-02-13 19:45:02,760 [podnet.py] => Task 25, Epoch 143/160 (LR 0.00276) => LSC_loss 0.22, Spatial_loss 2.27, Flat_loss 0.17, Train_acc 95.81, Test_acc 47.16
2025-02-13 19:45:04,720 [podnet.py] => Task 25, Epoch 144/160 (LR 0.00245) => LSC_loss 0.22, Spatial_loss 2.26, Flat_loss 0.16, Train_acc 96.01, Test_acc 46.62
2025-02-13 19:45:06,595 [podnet.py] => Task 25, Epoch 145/160 (LR 0.00215) => LSC_loss 0.21, Spatial_loss 2.20, Flat_loss 0.15, Train_acc 96.25, Test_acc 47.19
2025-02-13 19:45:08,564 [podnet.py] => Task 25, Epoch 146/160 (LR 0.00188) => LSC_loss 0.24, Spatial_loss 2.26, Flat_loss 0.15, Train_acc 95.30, Test_acc 47.46
2025-02-13 19:45:10,506 [podnet.py] => Task 25, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 2.17, Flat_loss 0.16, Train_acc 96.69, Test_acc 46.88
2025-02-13 19:45:12,422 [podnet.py] => Task 25, Epoch 148/160 (LR 0.00138) => LSC_loss 0.22, Spatial_loss 2.23, Flat_loss 0.15, Train_acc 95.51, Test_acc 46.95
2025-02-13 19:45:14,352 [podnet.py] => Task 25, Epoch 149/160 (LR 0.00116) => LSC_loss 0.22, Spatial_loss 2.14, Flat_loss 0.15, Train_acc 95.88, Test_acc 47.53
2025-02-13 19:45:16,278 [podnet.py] => Task 25, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 95.57, Test_acc 47.66
2025-02-13 19:45:18,193 [podnet.py] => Task 25, Epoch 151/160 (LR 0.00078) => LSC_loss 0.25, Spatial_loss 2.20, Flat_loss 0.15, Train_acc 96.22, Test_acc 47.48
2025-02-13 19:45:20,089 [podnet.py] => Task 25, Epoch 152/160 (LR 0.00062) => LSC_loss 0.24, Spatial_loss 2.18, Flat_loss 0.15, Train_acc 95.84, Test_acc 47.49
2025-02-13 19:45:21,991 [podnet.py] => Task 25, Epoch 153/160 (LR 0.00047) => LSC_loss 0.22, Spatial_loss 2.24, Flat_loss 0.16, Train_acc 96.55, Test_acc 47.18
2025-02-13 19:45:23,918 [podnet.py] => Task 25, Epoch 154/160 (LR 0.00035) => LSC_loss 0.22, Spatial_loss 2.15, Flat_loss 0.15, Train_acc 95.88, Test_acc 47.28
2025-02-13 19:45:25,828 [podnet.py] => Task 25, Epoch 155/160 (LR 0.00024) => LSC_loss 0.23, Spatial_loss 2.15, Flat_loss 0.15, Train_acc 95.88, Test_acc 47.56
2025-02-13 19:45:27,773 [podnet.py] => Task 25, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 2.22, Flat_loss 0.16, Train_acc 96.15, Test_acc 47.30
2025-02-13 19:45:29,706 [podnet.py] => Task 25, Epoch 157/160 (LR 0.00009) => LSC_loss 0.23, Spatial_loss 2.17, Flat_loss 0.15, Train_acc 96.08, Test_acc 47.76
2025-02-13 19:45:31,656 [podnet.py] => Task 25, Epoch 158/160 (LR 0.00004) => LSC_loss 0.22, Spatial_loss 2.09, Flat_loss 0.15, Train_acc 96.39, Test_acc 47.74
2025-02-13 19:45:33,545 [podnet.py] => Task 25, Epoch 159/160 (LR 0.00001) => LSC_loss 0.22, Spatial_loss 2.13, Flat_loss 0.15, Train_acc 95.81, Test_acc 47.62
2025-02-13 19:45:35,503 [podnet.py] => Task 25, Epoch 160/160 (LR 0.00000) => LSC_loss 0.21, Spatial_loss 2.05, Flat_loss 0.15, Train_acc 96.28, Test_acc 47.24
2025-02-13 19:45:35,504 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2025-02-13 19:45:35,504 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:46:08,111 [podnet.py] => The size of finetune dataset: 2000
2025-02-13 19:46:09,725 [podnet.py] => Task 25, Epoch 1/20 (LR 0.00497) => LSC_loss 0.16, Spatial_loss 2.33, Flat_loss 0.15, Train_acc 98.35, Test_acc 45.63
2025-02-13 19:46:11,439 [podnet.py] => Task 25, Epoch 2/20 (LR 0.00488) => LSC_loss 0.13, Spatial_loss 2.14, Flat_loss 0.10, Train_acc 98.80, Test_acc 48.08
2025-02-13 19:46:13,104 [podnet.py] => Task 25, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 2.09, Flat_loss 0.09, Train_acc 98.90, Test_acc 47.43
2025-02-13 19:46:14,789 [podnet.py] => Task 25, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 2.03, Flat_loss 0.08, Train_acc 98.60, Test_acc 47.86
2025-02-13 19:46:16,411 [podnet.py] => Task 25, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 2.02, Flat_loss 0.08, Train_acc 98.95, Test_acc 48.04
2025-02-13 19:46:18,119 [podnet.py] => Task 25, Epoch 6/20 (LR 0.00397) => LSC_loss 0.12, Spatial_loss 2.09, Flat_loss 0.08, Train_acc 99.00, Test_acc 47.97
2025-02-13 19:46:19,776 [podnet.py] => Task 25, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 2.01, Flat_loss 0.08, Train_acc 98.70, Test_acc 47.97
2025-02-13 19:46:21,455 [podnet.py] => Task 25, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 2.03, Flat_loss 0.08, Train_acc 99.15, Test_acc 47.97
2025-02-13 19:46:23,121 [podnet.py] => Task 25, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 2.02, Flat_loss 0.08, Train_acc 99.15, Test_acc 47.63
2025-02-13 19:46:24,757 [podnet.py] => Task 25, Epoch 10/20 (LR 0.00250) => LSC_loss 0.13, Spatial_loss 1.96, Flat_loss 0.08, Train_acc 99.00, Test_acc 48.16
2025-02-13 19:46:26,399 [podnet.py] => Task 25, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 1.94, Flat_loss 0.07, Train_acc 98.75, Test_acc 47.94
2025-02-13 19:46:28,100 [podnet.py] => Task 25, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 1.99, Flat_loss 0.08, Train_acc 99.10, Test_acc 48.26
2025-02-13 19:46:29,819 [podnet.py] => Task 25, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 1.97, Flat_loss 0.07, Train_acc 98.65, Test_acc 48.19
2025-02-13 19:46:31,510 [podnet.py] => Task 25, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 1.87, Flat_loss 0.07, Train_acc 99.10, Test_acc 47.94
2025-02-13 19:46:33,187 [podnet.py] => Task 25, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 2.01, Flat_loss 0.08, Train_acc 99.05, Test_acc 48.12
2025-02-13 19:46:34,887 [podnet.py] => Task 25, Epoch 16/20 (LR 0.00048) => LSC_loss 0.13, Spatial_loss 1.91, Flat_loss 0.07, Train_acc 98.85, Test_acc 48.29
2025-02-13 19:46:36,510 [podnet.py] => Task 25, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 1.89, Flat_loss 0.07, Train_acc 99.10, Test_acc 48.37
2025-02-13 19:46:38,221 [podnet.py] => Task 25, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 1.82, Flat_loss 0.07, Train_acc 99.05, Test_acc 48.24
2025-02-13 19:46:39,876 [podnet.py] => Task 25, Epoch 19/20 (LR 0.00003) => LSC_loss 0.13, Spatial_loss 2.01, Flat_loss 0.08, Train_acc 98.60, Test_acc 48.21
2025-02-13 19:46:41,554 [podnet.py] => Task 25, Epoch 20/20 (LR 0.00000) => LSC_loss 0.13, Spatial_loss 1.92, Flat_loss 0.07, Train_acc 98.85, Test_acc 48.09
2025-02-13 19:46:41,557 [base.py] => Constructing exemplars for new classes...(20 per classes)
2025-02-13 19:47:15,460 [podnet.py] => Exemplar size: 2000
2025-02-13 19:47:15,460 [trainer.py] => CNN: {'total': 48.09, '00-09': 55.0, '10-19': 37.4, '20-29': 56.5, '30-39': 45.8, '40-49': 53.5, '50-59': 31.9, '60-69': 45.0, '70-79': 48.6, '80-89': 53.4, '90-99': 53.8, 'old': 47.81, 'new': 62.0}
2025-02-13 19:47:15,460 [trainer.py] => NME: {'total': 48.17, '00-09': 59.3, '10-19': 40.8, '20-29': 57.9, '30-39': 47.9, '40-49': 53.8, '50-59': 29.7, '60-69': 45.2, '70-79': 48.4, '80-89': 49.7, '90-99': 49.0, 'old': 48.01, 'new': 56.0}
2025-02-13 19:47:15,460 [trainer.py] => CNN top1 curve: [77.7, 76.12, 74.7, 72.39, 70.34, 67.3, 64.94, 63.5, 62.79, 61.54, 61.14, 60.0, 59.61, 58.47, 57.29, 55.92, 55.37, 55.08, 53.83, 52.74, 51.29, 50.72, 49.73, 49.04, 48.91, 48.09]
2025-02-13 19:47:15,460 [trainer.py] => CNN top5 curve: [94.08, 93.71, 93.09, 92.75, 91.4, 89.47, 87.66, 86.2, 85.21, 84.71, 84.61, 83.53, 82.82, 81.68, 81.6, 80.6, 80.76, 80.8, 79.83, 79.18, 78.13, 77.38, 76.49, 75.92, 75.18, 75.15]
2025-02-13 19:47:15,461 [trainer.py] => NME top1 curve: [77.44, 75.6, 74.07, 72.54, 70.62, 67.82, 65.68, 64.06, 63.26, 62.16, 61.7, 60.69, 59.7, 58.7, 57.65, 56.11, 55.78, 54.93, 53.76, 52.51, 51.26, 51.04, 49.72, 49.07, 48.5, 48.17]
2025-02-13 19:47:15,461 [trainer.py] => NME top5 curve: [93.98, 93.54, 93.09, 92.5, 91.55, 89.72, 88.6, 87.47, 86.8, 86.16, 86.09, 85.32, 84.08, 83.13, 82.74, 81.95, 81.85, 81.54, 80.5, 79.85, 78.44, 77.97, 77.11, 76.41, 76.11, 75.61]

2025-02-13 19:47:15,461 [trainer.py] => Average Accuracy (CNN): 59.94423076923076
2025-02-13 19:47:15,461 [trainer.py] => Average Accuracy (NME): 60.097692307692306